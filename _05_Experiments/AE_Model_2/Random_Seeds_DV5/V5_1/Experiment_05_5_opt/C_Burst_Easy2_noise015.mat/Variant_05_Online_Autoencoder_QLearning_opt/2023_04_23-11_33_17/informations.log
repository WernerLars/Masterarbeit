Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_5_opt
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_5_opt/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt/2023_04_23-11_33_17
Punishment_Coefficient: 0.9
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000105B7882550>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.19637731835246086
Online_Training [2/700]: mean_loss=0.2699493505060673
Online_Training [3/700]: mean_loss=0.2145647592842579
Online_Training [4/700]: mean_loss=0.08330627158284187
Online_Training [5/700]: mean_loss=0.2569534257054329
Online_Training [6/700]: mean_loss=0.1289422083646059
Online_Training [7/700]: mean_loss=0.16154845990240574
Online_Training [8/700]: mean_loss=0.07893185317516327
Online_Training [9/700]: mean_loss=0.2580884099006653
Online_Training [10/700]: mean_loss=0.15357394330203533
Online_Training [11/700]: mean_loss=0.10589547920972109
Online_Training [12/700]: mean_loss=0.0727920401841402
Online_Training [13/700]: mean_loss=0.11263484042137861
Online_Training [14/700]: mean_loss=0.08183771185576916
Online_Training [15/700]: mean_loss=0.03943064156919718
Online_Training [16/700]: mean_loss=0.16444841772317886
Online_Training [17/700]: mean_loss=0.13699156418442726
Online_Training [18/700]: mean_loss=0.08146517165005207
Online_Training [19/700]: mean_loss=0.028125223238021135
Online_Training [20/700]: mean_loss=0.18240386806428432
Online_Training [21/700]: mean_loss=0.13462532870471478
Online_Training [22/700]: mean_loss=0.051720247603952885
Online_Training [23/700]: mean_loss=0.022866394370794296
Online_Training [24/700]: mean_loss=0.08748394809663296
Online_Training [25/700]: mean_loss=0.045334643218666315
Online_Training [26/700]: mean_loss=0.06586662633344531
Online_Training [27/700]: mean_loss=0.09924027137458324
Online_Training [28/700]: mean_loss=0.0431422614492476
Online_Training [29/700]: mean_loss=0.04677288932725787
Online_Training [30/700]: mean_loss=0.03130364674143493
Online_Training [31/700]: mean_loss=0.026241437764838338
Online_Training [32/700]: mean_loss=0.04278846876695752
Online_Training [33/700]: mean_loss=0.023135778261348605
Online_Training [34/700]: mean_loss=0.17769860662519932
Online_Training [35/700]: mean_loss=0.06255025835707784
Online_Training [36/700]: mean_loss=0.08590720873326063
Online_Training [37/700]: mean_loss=0.052582832518965006
Online_Training [38/700]: mean_loss=0.03763118525967002
Online_Training [39/700]: mean_loss=0.11854861211031675
Online_Training [40/700]: mean_loss=0.03391275042667985
Online_Training [41/700]: mean_loss=0.02892331825569272
Online_Training [42/700]: mean_loss=0.05590505665168166
Online_Training [43/700]: mean_loss=0.12195468600839376
Online_Training [44/700]: mean_loss=0.1437425184994936
Online_Training [45/700]: mean_loss=0.08555234409868717
Online_Training [46/700]: mean_loss=0.04737699776887894
Online_Training [47/700]: mean_loss=0.08965051174163818
Online_Training [48/700]: mean_loss=0.07074866350740194
Online_Training [49/700]: mean_loss=0.0925081530585885
Online_Training [50/700]: mean_loss=0.11014985013753176
Online_Training [51/700]: mean_loss=0.028136915527284145
Online_Training [52/700]: mean_loss=0.16163325868546963
Online_Training [53/700]: mean_loss=0.021423124242573977
Online_Training [54/700]: mean_loss=0.07830823119729757
Online_Training [55/700]: mean_loss=0.043068003840744495
Online_Training [56/700]: mean_loss=0.04736929200589657
Online_Training [57/700]: mean_loss=0.09089074935764074
Online_Training [58/700]: mean_loss=0.3046474978327751
Online_Training [59/700]: mean_loss=0.08471610210835934
Online_Training [60/700]: mean_loss=0.062392531894147396
Online_Training [61/700]: mean_loss=0.03585687093436718
Online_Training [62/700]: mean_loss=0.10714845918118954
Online_Training [63/700]: mean_loss=0.05726163741201162
Online_Training [64/700]: mean_loss=0.004637587000615895
Online_Training [65/700]: mean_loss=0.06314303074032068
Online_Training [66/700]: mean_loss=0.05088371457532048
Online_Training [67/700]: mean_loss=0.06743950536474586
Online_Training [68/700]: mean_loss=0.04895559512078762
Online_Training [69/700]: mean_loss=0.08477944694459438
Online_Training [70/700]: mean_loss=0.03594518546015024
Online_Training [71/700]: mean_loss=0.07510503195226192
Online_Training [72/700]: mean_loss=0.08281084522604942
Online_Training [73/700]: mean_loss=0.04259959189221263
Online_Training [74/700]: mean_loss=0.04336202424019575
Online_Training [75/700]: mean_loss=0.029507195111364126
Online_Training [76/700]: mean_loss=0.01947228447534144
Online_Training [77/700]: mean_loss=0.03303929418325424
Online_Training [78/700]: mean_loss=0.02840756974183023
Online_Training [79/700]: mean_loss=0.045158205553889275
Online_Training [80/700]: mean_loss=0.03979223733767867
Online_Training [81/700]: mean_loss=0.019318463979288936
Online_Training [82/700]: mean_loss=0.030520083382725716
Online_Training [83/700]: mean_loss=0.042000272776931524
Online_Training [84/700]: mean_loss=0.03423169394955039
Online_Training [85/700]: mean_loss=0.023633339907974005
Online_Training [86/700]: mean_loss=0.04119643312878907
Online_Training [87/700]: mean_loss=0.01946978410705924
Online_Training [88/700]: mean_loss=0.02512935665436089
Online_Training [89/700]: mean_loss=0.042589399963617325
Online_Training [90/700]: mean_loss=0.019315415062010288
Online_Training [91/700]: mean_loss=0.034305202309042215
Online_Training [92/700]: mean_loss=0.042007384821772575
Online_Training [93/700]: mean_loss=0.03347895457409322
Online_Training [94/700]: mean_loss=0.050144309643656015
Online_Training [95/700]: mean_loss=0.04459991119801998
Online_Training [96/700]: mean_loss=0.020068536279723048
Online_Training [97/700]: mean_loss=0.05342924455180764
Online_Training [98/700]: mean_loss=0.05181527556851506
Online_Training [99/700]: mean_loss=0.02864817576482892
Online_Training [100/700]: mean_loss=0.048314348328858614
Online_Training [101/700]: mean_loss=0.016865286277607083
Online_Training [102/700]: mean_loss=0.05880406638607383
Online_Training [103/700]: mean_loss=0.04737826995551586
Online_Training [104/700]: mean_loss=0.04826284013688564
Online_Training [105/700]: mean_loss=0.04104418633505702
Online_Training [106/700]: mean_loss=0.017629222013056278
Online_Training [107/700]: mean_loss=0.019033252727240324
Online_Training [108/700]: mean_loss=0.03389528696425259
Online_Training [109/700]: mean_loss=0.030488200951367617
Online_Training [110/700]: mean_loss=0.026343755889683962
Online_Training [111/700]: mean_loss=0.028843654319643974
Online_Training [112/700]: mean_loss=0.15874350257217884
Online_Training [113/700]: mean_loss=0.021967160515487194
Online_Training [114/700]: mean_loss=0.050346712581813335
Online_Training [115/700]: mean_loss=0.05019567767158151
Online_Training [116/700]: mean_loss=0.02352374978363514
Online_Training [117/700]: mean_loss=0.06255228025838733
Online_Training [118/700]: mean_loss=0.05802553938701749
Online_Training [119/700]: mean_loss=0.131448139436543
Online_Training [120/700]: mean_loss=0.06277351453900337
Online_Training [121/700]: mean_loss=0.07878390606492758
Online_Training [122/700]: mean_loss=0.07925731968134642
Online_Training [123/700]: mean_loss=0.03697453858330846
Online_Training [124/700]: mean_loss=0.015985274454578757
Online_Training [125/700]: mean_loss=0.08489829627797008
Online_Training [126/700]: mean_loss=0.04650972969830036
Online_Training [127/700]: mean_loss=0.07906730473041534
Online_Training [128/700]: mean_loss=0.030846114037558436
Online_Training [129/700]: mean_loss=0.037904208060353994
Online_Training [130/700]: mean_loss=0.019279753789305687
Online_Training [131/700]: mean_loss=0.026303403545171022
Online_Training [132/700]: mean_loss=0.017519108252599835
Online_Training [133/700]: mean_loss=0.029992627911269665
Online_Training [134/700]: mean_loss=0.02500919043086469
Online_Training [135/700]: mean_loss=0.12253465224057436
Online_Training [136/700]: mean_loss=0.02873656526207924
Online_Training [137/700]: mean_loss=0.020220893435180187
Online_Training [138/700]: mean_loss=0.012060593930073082
Online_Training [139/700]: mean_loss=0.021537807770073414
Online_Training [140/700]: mean_loss=0.03421309683471918
Online_Training [141/700]: mean_loss=0.04935442050918937
Online_Training [142/700]: mean_loss=0.01405357662588358
Online_Training [143/700]: mean_loss=0.021646668901667
Online_Training [144/700]: mean_loss=0.0141534119611606
Online_Training [145/700]: mean_loss=0.06807319214567542
Online_Training [146/700]: mean_loss=0.02279384504072368
Online_Training [147/700]: mean_loss=0.01732111640740186
Online_Training [148/700]: mean_loss=0.04897794546559453
Online_Training [149/700]: mean_loss=0.09782886411994696
Online_Training [150/700]: mean_loss=0.11940385308116674
Online_Training [151/700]: mean_loss=0.028342564124614
Online_Training [152/700]: mean_loss=0.01914484752342105
Online_Training [153/700]: mean_loss=0.08846861775964499
Online_Training [154/700]: mean_loss=0.02737193275243044
Online_Training [155/700]: mean_loss=0.02203479059971869
Online_Training [156/700]: mean_loss=0.023410890949890018
Online_Training [157/700]: mean_loss=0.20540617406368256
Online_Training [158/700]: mean_loss=0.007792291697114706
Online_Training [159/700]: mean_loss=0.016908492194488645
Online_Training [160/700]: mean_loss=0.04341276176273823
Online_Training [161/700]: mean_loss=0.033063813811168075
Online_Training [162/700]: mean_loss=0.01918139518238604
Online_Training [163/700]: mean_loss=0.06280066538602114
Online_Training [164/700]: mean_loss=0.013123814249411225
Online_Training [165/700]: mean_loss=0.016250023967586458
Online_Training [166/700]: mean_loss=0.029155804309993982
Online_Training [167/700]: mean_loss=0.0473174056969583
Online_Training [168/700]: mean_loss=0.04003885807469487
Online_Training [169/700]: mean_loss=0.057365118991583586
Online_Training [170/700]: mean_loss=0.1777661181986332
Online_Training [171/700]: mean_loss=0.01801813708152622
Online_Training [172/700]: mean_loss=0.016325465170666575
Online_Training [173/700]: mean_loss=0.04553544847294688
Online_Training [174/700]: mean_loss=0.014230761211365461
Online_Training [175/700]: mean_loss=0.012270877719856799
Online_Training [176/700]: mean_loss=0.007031151209957898
Online_Training [177/700]: mean_loss=0.03306120540946722
Online_Training [178/700]: mean_loss=0.04098415421321988
Online_Training [179/700]: mean_loss=0.024989142082631588
Online_Training [180/700]: mean_loss=0.03683599457144737
Online_Training [181/700]: mean_loss=0.03867707261815667
Online_Training [182/700]: mean_loss=0.034052268136292696
Online_Training [183/700]: mean_loss=0.014097102335654199
Online_Training [184/700]: mean_loss=0.010311255580745637
Online_Training [185/700]: mean_loss=0.05653475224971771
Online_Training [186/700]: mean_loss=0.03822652134113014
Online_Training [187/700]: mean_loss=0.028193895239382982
Online_Training [188/700]: mean_loss=0.028808724135160446
Online_Training [189/700]: mean_loss=0.0553131029009819
Online_Training [190/700]: mean_loss=0.026701857801526785
Online_Training [191/700]: mean_loss=0.15872428007423878
Online_Training [192/700]: mean_loss=0.02150938007980585
Online_Training [193/700]: mean_loss=0.02500377013348043
Online_Training [194/700]: mean_loss=0.02908629458397627
Online_Training [195/700]: mean_loss=0.0274860099889338
Online_Training [196/700]: mean_loss=0.01655495713930577
Online_Training [197/700]: mean_loss=0.05298516480252147
Online_Training [198/700]: mean_loss=0.01752975000999868
Online_Training [199/700]: mean_loss=0.09919807221740484
Online_Training [200/700]: mean_loss=0.015843442757613957
Online_Training [201/700]: mean_loss=0.03460595291107893
Online_Training [202/700]: mean_loss=0.036467937752604485
Online_Training [203/700]: mean_loss=0.010958660393953323
Online_Training [204/700]: mean_loss=0.018108565593138337
Online_Training [205/700]: mean_loss=0.08213700354099274
Online_Training [206/700]: mean_loss=0.02240092004649341
Online_Training [207/700]: mean_loss=0.05329684913158417
Online_Training [208/700]: mean_loss=0.046084731351584196
Online_Training [209/700]: mean_loss=0.052188627421855927
Online_Training [210/700]: mean_loss=0.03092258726246655
Online_Training [211/700]: mean_loss=0.027820400660857558
Online_Training [212/700]: mean_loss=0.11065225396305323
Online_Training [213/700]: mean_loss=0.06841309741139412
Online_Training [214/700]: mean_loss=0.029018904315307736
Online_Training [215/700]: mean_loss=0.029413010692223907
Online_Training [216/700]: mean_loss=0.07201827690005302
Online_Training [217/700]: mean_loss=0.013539490522816777
Online_Training [218/700]: mean_loss=0.008903816575184464
Online_Training [219/700]: mean_loss=0.058332884684205055
Online_Training [220/700]: mean_loss=0.012052460573613644
Online_Training [221/700]: mean_loss=0.028291559545323253
Online_Training [222/700]: mean_loss=0.03705972246825695
Online_Training [223/700]: mean_loss=0.03124092286452651
Online_Training [224/700]: mean_loss=0.008560518152080476
Online_Training [225/700]: mean_loss=0.03756700409576297
Online_Training [226/700]: mean_loss=0.033283289754763246
Online_Training [227/700]: mean_loss=0.01668014330789447
Online_Training [228/700]: mean_loss=0.03447105106897652
Online_Training [229/700]: mean_loss=0.053355562034994364
Online_Training [230/700]: mean_loss=0.01499369100201875
Online_Training [231/700]: mean_loss=0.02690528496168554
Online_Training [232/700]: mean_loss=0.021352380979806185
Online_Training [233/700]: mean_loss=0.032087473664432764
Online_Training [234/700]: mean_loss=0.039819310419261456
Online_Training [235/700]: mean_loss=0.11792989633977413
Online_Training [236/700]: mean_loss=0.05639387387782335
Online_Training [237/700]: mean_loss=0.026008832966908813
Online_Training [238/700]: mean_loss=0.09834196418523788
Online_Training [239/700]: mean_loss=0.28236932680010796
Online_Training [240/700]: mean_loss=0.035338937072083354
Online_Training [241/700]: mean_loss=0.03557759802788496
Online_Training [242/700]: mean_loss=0.01870391343254596
Online_Training [243/700]: mean_loss=0.030912701273337007
Online_Training [244/700]: mean_loss=0.042115761898458004
Online_Training [245/700]: mean_loss=0.05931058619171381
Online_Training [246/700]: mean_loss=0.028309035813435912
Online_Training [247/700]: mean_loss=0.013234651298262179
Online_Training [248/700]: mean_loss=0.09314091969281435
Online_Training [249/700]: mean_loss=0.06638568826019764
Online_Training [250/700]: mean_loss=0.014723949832841754
Online_Training [251/700]: mean_loss=0.018724367022514343
Online_Training [252/700]: mean_loss=0.01920052245259285
Online_Training [253/700]: mean_loss=0.010881394846364856
Online_Training [254/700]: mean_loss=0.018632502062246203
Online_Training [255/700]: mean_loss=0.03775801695883274
Online_Training [256/700]: mean_loss=0.017939676414243877
Online_Training [257/700]: mean_loss=0.029125418746843934
Online_Training [258/700]: mean_loss=0.012857683119364083
Online_Training [259/700]: mean_loss=0.011518453829921782
Online_Training [260/700]: mean_loss=0.023239349015057087
Online_Training [261/700]: mean_loss=0.026513903634622693
Online_Training [262/700]: mean_loss=0.030821703374385834
Online_Training [263/700]: mean_loss=0.018977331928908825
Online_Training [264/700]: mean_loss=0.04249506676569581
Online_Training [265/700]: mean_loss=0.01932250475510955
Online_Training [266/700]: mean_loss=0.014272636268287897
Online_Training [267/700]: mean_loss=0.028330863919109106
Online_Training [268/700]: mean_loss=0.011009433190338314
Online_Training [269/700]: mean_loss=0.02977058244869113
Online_Training [270/700]: mean_loss=0.023580395616590977
Online_Training [271/700]: mean_loss=0.024115961510688066
Online_Training [272/700]: mean_loss=0.006211479834746569
Online_Training [273/700]: mean_loss=0.018833063542842865
Online_Training [274/700]: mean_loss=0.0346274240873754
Online_Training [275/700]: mean_loss=0.011114316526800394
Online_Training [276/700]: mean_loss=0.019377184798941016
Online_Training [277/700]: mean_loss=0.09111125208437443
Online_Training [278/700]: mean_loss=0.023634599056094885
Online_Training [279/700]: mean_loss=0.02547208685427904
Online_Training [280/700]: mean_loss=0.030141781782731414
Online_Training [281/700]: mean_loss=0.035787437576800585
Online_Training [282/700]: mean_loss=0.03315382613800466
Online_Training [283/700]: mean_loss=0.022709951736032963
Online_Training [284/700]: mean_loss=0.026858556549996138
Online_Training [285/700]: mean_loss=0.03217620635405183
Online_Training [286/700]: mean_loss=0.017034572432748973
Online_Training [287/700]: mean_loss=0.014830963453277946
Online_Training [288/700]: mean_loss=0.01558406453114003
Online_Training [289/700]: mean_loss=0.033756852615624666
Online_Training [290/700]: mean_loss=0.008091774419881403
Online_Training [291/700]: mean_loss=0.011942930519580841
Online_Training [292/700]: mean_loss=0.008159792050719261
Online_Training [293/700]: mean_loss=0.026246465742588043
Online_Training [294/700]: mean_loss=0.03631762135773897
Online_Training [295/700]: mean_loss=0.027577614644542336
Online_Training [296/700]: mean_loss=0.04019779246300459
Online_Training [297/700]: mean_loss=0.01727184932678938
Online_Training [298/700]: mean_loss=0.040747912134975195
Online_Training [299/700]: mean_loss=0.03660085890442133
Online_Training [300/700]: mean_loss=0.049977424554526806
Online_Training [301/700]: mean_loss=0.01546284114010632
Online_Training [302/700]: mean_loss=0.02562572853639722
Online_Training [303/700]: mean_loss=0.017271259799599648
Online_Training [304/700]: mean_loss=0.02099499781616032
Online_Training [305/700]: mean_loss=0.07245142059400678
Online_Training [306/700]: mean_loss=0.05438154935836792
Online_Training [307/700]: mean_loss=0.05684475367888808
Online_Training [308/700]: mean_loss=0.03129904647357762
Online_Training [309/700]: mean_loss=0.012795325834304094
Online_Training [310/700]: mean_loss=0.029499745229259133
Online_Training [311/700]: mean_loss=0.012388031114824116
Online_Training [312/700]: mean_loss=0.04884802969172597
Online_Training [313/700]: mean_loss=0.023924683453515172
Online_Training [314/700]: mean_loss=0.019302257569506764
Online_Training [315/700]: mean_loss=0.01595218083821237
Online_Training [316/700]: mean_loss=0.02121591498143971
Online_Training [317/700]: mean_loss=0.007717450323980302
Online_Training [318/700]: mean_loss=0.04273668210953474
Online_Training [319/700]: mean_loss=0.03207736718468368
Online_Training [320/700]: mean_loss=0.014816449722275138
Online_Training [321/700]: mean_loss=0.016097248066216707
Online_Training [322/700]: mean_loss=0.036391927395015955
Online_Training [323/700]: mean_loss=0.022349694510921836
Online_Training [324/700]: mean_loss=0.01423711609095335
Online_Training [325/700]: mean_loss=0.023647147696465254
Online_Training [326/700]: mean_loss=0.03502917010337114
Online_Training [327/700]: mean_loss=0.02430507610552013
Online_Training [328/700]: mean_loss=0.04447866277769208
Online_Training [329/700]: mean_loss=0.015029632486402988
Online_Training [330/700]: mean_loss=0.02332171332091093
Online_Training [331/700]: mean_loss=0.017479971167631447
Online_Training [332/700]: mean_loss=0.02327464334666729
Online_Training [333/700]: mean_loss=0.012347112875431776
Online_Training [334/700]: mean_loss=0.012480360339395702
Online_Training [335/700]: mean_loss=0.06700817123055458
Online_Training [336/700]: mean_loss=0.07464610319584608
Online_Training [337/700]: mean_loss=0.13470737170428038
Online_Training [338/700]: mean_loss=0.05871853232383728
Online_Training [339/700]: mean_loss=0.016614609747193754
Online_Training [340/700]: mean_loss=0.009583840786945075
Online_Training [341/700]: mean_loss=0.07511333143338561
Online_Training [342/700]: mean_loss=0.05331916734576225
Online_Training [343/700]: mean_loss=0.012633783277124166
Online_Training [344/700]: mean_loss=0.02288345480337739
Online_Training [345/700]: mean_loss=0.03675003442913294
Online_Training [346/700]: mean_loss=0.0236975506413728
Online_Training [347/700]: mean_loss=0.13663168251514435
Online_Training [348/700]: mean_loss=0.02480093133635819
Online_Training [349/700]: mean_loss=0.029028648510575294
Online_Training [350/700]: mean_loss=0.01688095333520323
Online_Training [351/700]: mean_loss=0.01203659805469215
Online_Training [352/700]: mean_loss=0.01285139610990882
Online_Training [353/700]: mean_loss=0.06143242213875055
Online_Training [354/700]: mean_loss=0.020378573099151254
Online_Training [355/700]: mean_loss=0.016292953048832715
Online_Training [356/700]: mean_loss=0.014660585671663284
Online_Training [357/700]: mean_loss=0.07053609192371368
Online_Training [358/700]: mean_loss=0.06418062001466751
Online_Training [359/700]: mean_loss=0.07694810815155506
Online_Training [360/700]: mean_loss=0.02229561610147357
Online_Training [361/700]: mean_loss=0.025021031964570284
Online_Training [362/700]: mean_loss=0.0577361136674881
Online_Training [363/700]: mean_loss=0.023090977454558015
Online_Training [364/700]: mean_loss=0.007185899070464075
Online_Training [365/700]: mean_loss=0.027982695028185844
Online_Training [366/700]: mean_loss=0.010747750871814787
Online_Training [367/700]: mean_loss=0.02577730268239975
Online_Training [368/700]: mean_loss=0.026637022383511066
Online_Training [369/700]: mean_loss=0.02892626216635108
Online_Training [370/700]: mean_loss=0.03014914272353053
Online_Training [371/700]: mean_loss=0.011355007882229984
Online_Training [372/700]: mean_loss=0.03289708914235234
Online_Training [373/700]: mean_loss=0.016503723920322955
Online_Training [374/700]: mean_loss=0.0120177052449435
Online_Training [375/700]: mean_loss=0.019954164512455463
Online_Training [376/700]: mean_loss=0.009951237821951509
Online_Training [377/700]: mean_loss=0.01887290528975427
Online_Training [378/700]: mean_loss=0.018965411465615034
Online_Training [379/700]: mean_loss=0.035345963668078184
Online_Training [380/700]: mean_loss=0.011667795479297638
Online_Training [381/700]: mean_loss=0.010552102816291153
Online_Training [382/700]: mean_loss=0.009360959811601788
Online_Training [383/700]: mean_loss=0.008381894207559526
Online_Training [384/700]: mean_loss=0.10768657270818949
Online_Training [385/700]: mean_loss=0.009818052290938795
Online_Training [386/700]: mean_loss=0.023609866853803396
Online_Training [387/700]: mean_loss=0.018519027857109904
Online_Training [388/700]: mean_loss=0.016537444083951414
Online_Training [389/700]: mean_loss=0.009403530973941088
Online_Training [390/700]: mean_loss=0.039263280341401696
Online_Training [391/700]: mean_loss=0.00515093351714313
Online_Training [392/700]: mean_loss=0.03122106264345348
Online_Training [393/700]: mean_loss=0.02516255504451692
Online_Training [394/700]: mean_loss=0.02483365754596889
Online_Training [395/700]: mean_loss=0.007606941449921578
Online_Training [396/700]: mean_loss=0.028994633816182613
Online_Training [397/700]: mean_loss=0.014554468914866447
Online_Training [398/700]: mean_loss=0.023215731140226126
Online_Training [399/700]: mean_loss=0.03106860746629536
Online_Training [400/700]: mean_loss=0.023726053070276976
Online_Training [401/700]: mean_loss=0.0360876286868006
Online_Training [402/700]: mean_loss=0.011091876542195678
Online_Training [403/700]: mean_loss=0.022722740890458226
Online_Training [404/700]: mean_loss=0.0378344445489347
Online_Training [405/700]: mean_loss=0.05507941823452711
Online_Training [406/700]: mean_loss=0.017544682836160064
Online_Training [407/700]: mean_loss=0.038346679182723165
Online_Training [408/700]: mean_loss=0.011923464946448803
Online_Training [409/700]: mean_loss=0.008489832689519972
Online_Training [410/700]: mean_loss=0.029198176693171263
Online_Training [411/700]: mean_loss=0.02111497870646417
Online_Training [412/700]: mean_loss=0.10579388402402401
Online_Training [413/700]: mean_loss=0.045074683614075184
Online_Training [414/700]: mean_loss=0.04740737425163388
Online_Training [415/700]: mean_loss=0.02101093204692006
Online_Training [416/700]: mean_loss=0.020642194198444486
Online_Training [417/700]: mean_loss=0.06285843532532454
Online_Training [418/700]: mean_loss=0.014462979044765234
Online_Training [419/700]: mean_loss=0.011973514221608639
Online_Training [420/700]: mean_loss=0.06054412666708231
Online_Training [421/700]: mean_loss=0.031641378765925765
Online_Training [422/700]: mean_loss=0.03009209642186761
Online_Training [423/700]: mean_loss=0.033789274748414755
Online_Training [424/700]: mean_loss=0.05193519126623869
Online_Training [425/700]: mean_loss=0.0277046172413975
Online_Training [426/700]: mean_loss=0.009499899111688137
Online_Training [427/700]: mean_loss=0.01785596110858023
Online_Training [428/700]: mean_loss=0.031708215828984976
Online_Training [429/700]: mean_loss=0.013625162071548402
Online_Training [430/700]: mean_loss=0.00934147322550416
Online_Training [431/700]: mean_loss=0.01225316314958036
Online_Training [432/700]: mean_loss=0.07494712807238102
Online_Training [433/700]: mean_loss=0.012900812085717916
Online_Training [434/700]: mean_loss=0.020520861027762294
Online_Training [435/700]: mean_loss=0.008734760573133826
Online_Training [436/700]: mean_loss=0.04364407202228904
Online_Training [437/700]: mean_loss=0.011760269408114254
Online_Training [438/700]: mean_loss=0.2030528523027897
Online_Training [439/700]: mean_loss=0.12133618630468845
Online_Training [440/700]: mean_loss=0.07829123269766569
Online_Training [441/700]: mean_loss=0.07499755965545774
Online_Training [442/700]: mean_loss=0.027936089085415006
Online_Training [443/700]: mean_loss=0.01213073602411896
Online_Training [444/700]: mean_loss=0.0335976320784539
Online_Training [445/700]: mean_loss=0.02181168575771153
Online_Training [446/700]: mean_loss=0.0327366185374558
Online_Training [447/700]: mean_loss=0.011690670857205987
Online_Training [448/700]: mean_loss=0.017848049523308873
Online_Training [449/700]: mean_loss=0.009246611210983247
Online_Training [450/700]: mean_loss=0.02529224520549178
Online_Training [451/700]: mean_loss=0.05058699939399958
Online_Training [452/700]: mean_loss=0.027059712912887335
Online_Training [453/700]: mean_loss=0.062081833835691214
Online_Training [454/700]: mean_loss=0.03831317322328687
Online_Training [455/700]: mean_loss=0.0456217173486948
Online_Training [456/700]: mean_loss=0.009002520935609937
Online_Training [457/700]: mean_loss=0.019942550570704043
Online_Training [458/700]: mean_loss=0.036013114266097546
Online_Training [459/700]: mean_loss=0.01616682473104447
Online_Training [460/700]: mean_loss=0.019125516759231687
Online_Training [461/700]: mean_loss=0.03234030865132809
Online_Training [462/700]: mean_loss=0.0374903897754848
Online_Training [463/700]: mean_loss=0.02217871625907719
Online_Training [464/700]: mean_loss=0.01664917846210301
Online_Training [465/700]: mean_loss=0.04846078949049115
Online_Training [466/700]: mean_loss=0.030413141008466482
Online_Training [467/700]: mean_loss=0.047423192765563726
Online_Training [468/700]: mean_loss=0.02105854987166822
Online_Training [469/700]: mean_loss=0.031458368292078376
Online_Training [470/700]: mean_loss=0.04447888024151325
Online_Training [471/700]: mean_loss=0.02514494745992124
Online_Training [472/700]: mean_loss=0.024642247008159757
Online_Training [473/700]: mean_loss=0.00666300707962364
Online_Training [474/700]: mean_loss=0.012684753048233688
Online_Training [475/700]: mean_loss=0.020160431740805507
Online_Training [476/700]: mean_loss=0.19448567368090153
Online_Training [477/700]: mean_loss=0.13962260819971561
Online_Training [478/700]: mean_loss=0.03659726865589619
Online_Training [479/700]: mean_loss=0.014443458174355328
Online_Training [480/700]: mean_loss=0.01175880676601082
Online_Training [481/700]: mean_loss=0.026996260974556208
Online_Training [482/700]: mean_loss=0.020828045904636383
Online_Training [483/700]: mean_loss=0.01551105605904013
Online_Training [484/700]: mean_loss=0.023842673748731613
Online_Training [485/700]: mean_loss=0.014483449864201248
Online_Training [486/700]: mean_loss=0.011537321843206882
Online_Training [487/700]: mean_loss=0.03116731229238212
Online_Training [488/700]: mean_loss=0.017319113248959184
Online_Training [489/700]: mean_loss=0.013150056940503418
Online_Training [490/700]: mean_loss=0.022913227090612054
Online_Training [491/700]: mean_loss=0.03220930625684559
Online_Training [492/700]: mean_loss=0.01599105237983167
Online_Training [493/700]: mean_loss=0.01724960480351001
Online_Training [494/700]: mean_loss=0.05452403984963894
Online_Training [495/700]: mean_loss=0.008175432682037354
Online_Training [496/700]: mean_loss=0.040195442736148834
Online_Training [497/700]: mean_loss=0.025876335916109383
Online_Training [498/700]: mean_loss=0.036386376013979316
Online_Training [499/700]: mean_loss=0.018677634419873357
Online_Training [500/700]: mean_loss=0.00937154854182154
Online_Training [501/700]: mean_loss=0.015361380064859986
Online_Training [502/700]: mean_loss=0.035253350622951984
Online_Training [503/700]: mean_loss=0.018305262783542275
Online_Training [504/700]: mean_loss=0.03232256602495909
Online_Training [505/700]: mean_loss=0.014715926838107407
Online_Training [506/700]: mean_loss=0.09619833528995514
Online_Training [507/700]: mean_loss=0.14664588123559952
Online_Training [508/700]: mean_loss=0.042773634660989046
Online_Training [509/700]: mean_loss=0.01603033288847655
Online_Training [510/700]: mean_loss=0.059390564914792776
Online_Training [511/700]: mean_loss=0.03345344332046807
Online_Training [512/700]: mean_loss=0.014175771619193256
Online_Training [513/700]: mean_loss=0.03989960066974163
Online_Training [514/700]: mean_loss=0.032585544511675835
Online_Training [515/700]: mean_loss=0.044150346890091896
Online_Training [516/700]: mean_loss=0.01310454832855612
Online_Training [517/700]: mean_loss=0.022123761009424925
Online_Training [518/700]: mean_loss=0.023989320266991854
Online_Training [519/700]: mean_loss=0.009011606511194259
Online_Training [520/700]: mean_loss=0.023888094117864966
Online_Training [521/700]: mean_loss=0.03237008536234498
Online_Training [522/700]: mean_loss=0.011395626584999263
Online_Training [523/700]: mean_loss=0.019473767839372158
Online_Training [524/700]: mean_loss=0.07773361634463072
Online_Training [525/700]: mean_loss=0.025048252195119858
Online_Training [526/700]: mean_loss=0.014699430554173887
Online_Training [527/700]: mean_loss=0.016766142915003
Online_Training [528/700]: mean_loss=0.03775727259926498
Online_Training [529/700]: mean_loss=0.02468828042037785
Online_Training [530/700]: mean_loss=0.0191751376260072
Online_Training [531/700]: mean_loss=0.048050899524241686
Online_Training [532/700]: mean_loss=0.0316256913356483
Online_Training [533/700]: mean_loss=0.016260909382253885
Online_Training [534/700]: mean_loss=0.04127848241478205
Online_Training [535/700]: mean_loss=0.023284959373995662
Online_Training [536/700]: mean_loss=0.1162203149870038
Online_Training [537/700]: mean_loss=0.0439093466848135
Online_Training [538/700]: mean_loss=0.034204073483124375
Online_Training [539/700]: mean_loss=0.007473588746506721
Online_Training [540/700]: mean_loss=0.027082805056124926
Online_Training [541/700]: mean_loss=0.10900805797427893
Online_Training [542/700]: mean_loss=0.006578666274435818
Online_Training [543/700]: mean_loss=0.02971614943817258
Online_Training [544/700]: mean_loss=0.0146219483576715
Online_Training [545/700]: mean_loss=0.06358135584741831
Online_Training [546/700]: mean_loss=0.009549350594170392
Online_Training [547/700]: mean_loss=0.010532692365814
Online_Training [548/700]: mean_loss=0.012862464878708124
Online_Training [549/700]: mean_loss=0.010096884449012578
Online_Training [550/700]: mean_loss=0.06877139583230019
Online_Training [551/700]: mean_loss=0.03963898494839668
Online_Training [552/700]: mean_loss=0.04242535214871168
Online_Training [553/700]: mean_loss=0.04188078152947128
Online_Training [554/700]: mean_loss=0.012848024838604033
Online_Training [555/700]: mean_loss=0.024038599338382483
Online_Training [556/700]: mean_loss=0.019936295924708247
Online_Training [557/700]: mean_loss=0.023627636372111738
Online_Training [558/700]: mean_loss=0.015104815713129938
Online_Training [559/700]: mean_loss=0.004586183466017246
Online_Training [560/700]: mean_loss=0.010329052223823965
Online_Training [561/700]: mean_loss=0.01835613278672099
Online_Training [562/700]: mean_loss=0.0352839813567698
Online_Training [563/700]: mean_loss=0.02145674964413047
Online_Training [564/700]: mean_loss=0.01417236216366291
Online_Training [565/700]: mean_loss=0.03461244236677885
Online_Training [566/700]: mean_loss=0.01826671720482409
Online_Training [567/700]: mean_loss=0.018988025840371847
Online_Training [568/700]: mean_loss=0.020331091480329633
Online_Training [569/700]: mean_loss=0.02268069563433528
Online_Training [570/700]: mean_loss=0.009015578194521368
Online_Training [571/700]: mean_loss=0.03292608610354364
Online_Training [572/700]: mean_loss=0.018989148316904902
Online_Training [573/700]: mean_loss=0.026021675439551473
Online_Training [574/700]: mean_loss=0.05976941576227546
Online_Training [575/700]: mean_loss=0.05568826058879495
Online_Training [576/700]: mean_loss=0.009596085757948458
Online_Training [577/700]: mean_loss=0.018634035484865308
Online_Training [578/700]: mean_loss=0.007392958563286811
Online_Training [579/700]: mean_loss=0.014554494060575962
Online_Training [580/700]: mean_loss=0.0260907169431448
Online_Training [581/700]: mean_loss=0.024097556713968515
Online_Training [582/700]: mean_loss=0.04034786601550877
Online_Training [583/700]: mean_loss=0.006228334852494299
Online_Training [584/700]: mean_loss=0.036472463980317116
Online_Training [585/700]: mean_loss=0.022400998044759035
Online_Training [586/700]: mean_loss=0.08954887930303812
Online_Training [587/700]: mean_loss=0.031178173841908574
Online_Training [588/700]: mean_loss=0.03358501591719687
Online_Training [589/700]: mean_loss=0.029902590438723564
Online_Training [590/700]: mean_loss=0.022530958987772465
Online_Training [591/700]: mean_loss=0.014410866773687303
Online_Training [592/700]: mean_loss=0.021261005429551005
Online_Training [593/700]: mean_loss=0.03695067577064037
Online_Training [594/700]: mean_loss=0.047005138359963894
Online_Training [595/700]: mean_loss=0.027965042972937226
Online_Training [596/700]: mean_loss=0.016807818319648504
Online_Training [597/700]: mean_loss=0.009856296121142805
Online_Training [598/700]: mean_loss=0.021087113302201033
Online_Training [599/700]: mean_loss=0.01596065319608897
Online_Training [600/700]: mean_loss=0.010459482902660966
Online_Training [601/700]: mean_loss=0.032540404703468084
Online_Training [602/700]: mean_loss=0.01143608579877764
Online_Training [603/700]: mean_loss=0.006196844624355435
Online_Training [604/700]: mean_loss=0.02945003961212933
Online_Training [605/700]: mean_loss=0.017148045008070767
Online_Training [606/700]: mean_loss=0.0051060947007499635
Online_Training [607/700]: mean_loss=0.007880094985011965
Online_Training [608/700]: mean_loss=0.016085723880678415
Online_Training [609/700]: mean_loss=0.010855250409804285
Online_Training [610/700]: mean_loss=0.017575069679878652
Online_Training [611/700]: mean_loss=0.008484560356009752
Online_Training [612/700]: mean_loss=0.12032345309853554
Online_Training [613/700]: mean_loss=0.040651585441082716
Online_Training [614/700]: mean_loss=0.01153386547230184
Online_Training [615/700]: mean_loss=0.015320132952183485
Online_Training [616/700]: mean_loss=0.03252160712145269
Online_Training [617/700]: mean_loss=0.00789349665865302
Online_Training [618/700]: mean_loss=0.02269767504185438
Online_Training [619/700]: mean_loss=0.013605086482129991
Online_Training [620/700]: mean_loss=0.06666127359494567
Online_Training [621/700]: mean_loss=0.011217301362194121
Online_Training [622/700]: mean_loss=0.060301839374005795
Online_Training [623/700]: mean_loss=0.047477026004344225
Online_Training [624/700]: mean_loss=0.01729261118452996
Online_Training [625/700]: mean_loss=0.014005900244228542
Online_Training [626/700]: mean_loss=0.04106930596753955
Online_Training [627/700]: mean_loss=0.027470189845189452
Online_Training [628/700]: mean_loss=0.009093178494367748
Online_Training [629/700]: mean_loss=0.06761982245370746
Online_Training [630/700]: mean_loss=0.04689392540603876
Online_Training [631/700]: mean_loss=0.013909986009821296
Online_Training [632/700]: mean_loss=0.022370847640559077
Online_Training [633/700]: mean_loss=0.012686233269050717
Online_Training [634/700]: mean_loss=0.02761985268443823
Online_Training [635/700]: mean_loss=0.03051562560722232
Online_Training [636/700]: mean_loss=0.014054110448341817
Online_Training [637/700]: mean_loss=0.014868031488731503
Online_Training [638/700]: mean_loss=0.0368997841142118
Online_Training [639/700]: mean_loss=0.013463543495163321
Online_Training [640/700]: mean_loss=0.01618151750881225
Online_Training [641/700]: mean_loss=0.028234647819772363
Online_Training [642/700]: mean_loss=0.01598985306918621
Online_Training [643/700]: mean_loss=0.009830811235588044
Online_Training [644/700]: mean_loss=0.041262208949774504
Online_Training [645/700]: mean_loss=0.01362392061855644
Online_Training [646/700]: mean_loss=0.07208002172410488
Online_Training [647/700]: mean_loss=0.0074868290685117245
Online_Training [648/700]: mean_loss=0.013441261486150324
Online_Training [649/700]: mean_loss=0.010728799970820546
Online_Training [650/700]: mean_loss=0.014473451534286141
Online_Training [651/700]: mean_loss=0.010305439354851842
Online_Training [652/700]: mean_loss=0.01224325445946306
Online_Training [653/700]: mean_loss=0.10311383102089167
Online_Training [654/700]: mean_loss=0.019947350956499577
Online_Training [655/700]: mean_loss=0.016976648825220764
Online_Training [656/700]: mean_loss=0.018152473377995193
Online_Training [657/700]: mean_loss=0.01423978095408529
Online_Training [658/700]: mean_loss=0.018147120252251625
Online_Training [659/700]: mean_loss=0.018674746388569474
Online_Training [660/700]: mean_loss=0.012099045095965266
Online_Training [661/700]: mean_loss=0.045178795233368874
Online_Training [662/700]: mean_loss=0.021183184813708067
Online_Training [663/700]: mean_loss=0.019767480436712503
Online_Training [664/700]: mean_loss=0.012128454050980508
Online_Training [665/700]: mean_loss=0.03559305868111551
Online_Training [666/700]: mean_loss=0.01462773175444454
Online_Training [667/700]: mean_loss=0.0045386959973257035
Online_Training [668/700]: mean_loss=0.026653035078197718
Online_Training [669/700]: mean_loss=0.015273023629561067
Online_Training [670/700]: mean_loss=0.014733774703927338
Online_Training [671/700]: mean_loss=0.010057651321403682
Online_Training [672/700]: mean_loss=0.024811972863972187
Online_Training [673/700]: mean_loss=0.0158771745627746
Online_Training [674/700]: mean_loss=0.01631090440787375
Online_Training [675/700]: mean_loss=0.015554726240225136
Online_Training [676/700]: mean_loss=0.03489264426752925
Online_Training [677/700]: mean_loss=0.0489468052983284
Online_Training [678/700]: mean_loss=0.022025841986760497
Online_Training [679/700]: mean_loss=0.01209220162127167
Online_Training [680/700]: mean_loss=0.03876388445496559
Online_Training [681/700]: mean_loss=0.026383638149127364
Online_Training [682/700]: mean_loss=0.01105791435111314
Online_Training [683/700]: mean_loss=0.01080299325985834
Online_Training [684/700]: mean_loss=0.014334333536680788
Online_Training [685/700]: mean_loss=0.029547574929893017
Online_Training [686/700]: mean_loss=0.016303496551699936
Online_Training [687/700]: mean_loss=0.008287007338367403
Online_Training [688/700]: mean_loss=0.08121577790006995
Online_Training [689/700]: mean_loss=0.008955673081800342
Online_Training [690/700]: mean_loss=0.00977732241153717
Online_Training [691/700]: mean_loss=0.03237150004133582
Online_Training [692/700]: mean_loss=0.026723627001047134
Online_Training [693/700]: mean_loss=0.023418991127982736
Online_Training [694/700]: mean_loss=0.03259240719489753
Online_Training [695/700]: mean_loss=0.020868882886134088
Online_Training [696/700]: mean_loss=0.0332835391163826
Online_Training [697/700]: mean_loss=0.015883749816566706
Online_Training [698/700]: mean_loss=0.016131784243043512
Online_Training [699/700]: mean_loss=0.1869086939841509
Online_Training [700/700]: mean_loss=0.006959053745958954
Q_Learning [1/300]: mean_loss=0.19637731835246086
Q_Learning [2/300]: mean_loss=0.2699493505060673
Q_Learning [3/300]: mean_loss=0.2145647592842579
Q_Learning [4/300]: mean_loss=0.08330627158284187
Q_Learning [5/300]: mean_loss=0.2569534257054329
Q_Learning [6/300]: mean_loss=0.1289422083646059
Q_Learning [7/300]: mean_loss=0.16154845990240574
Q_Learning [8/300]: mean_loss=0.07893185317516327
Q_Learning [9/300]: mean_loss=0.2580884099006653
Q_Learning [10/300]: mean_loss=0.15357394330203533
Q_Learning [11/300]: mean_loss=0.10589547920972109
Q_Learning [12/300]: mean_loss=0.0727920401841402
Q_Learning [13/300]: mean_loss=0.11263484042137861
Q_Learning [14/300]: mean_loss=0.08183771185576916
Q_Learning [15/300]: mean_loss=0.03943064156919718
Q_Learning [16/300]: mean_loss=0.16444841772317886
Q_Learning [17/300]: mean_loss=0.13699156418442726
Q_Learning [18/300]: mean_loss=0.08146517165005207
Q_Learning [19/300]: mean_loss=0.028125223238021135
Q_Learning [20/300]: mean_loss=0.18240386806428432
Q_Learning [21/300]: mean_loss=0.13462532870471478
Q_Learning [22/300]: mean_loss=0.051720247603952885
Q_Learning [23/300]: mean_loss=0.022866394370794296
Q_Learning [24/300]: mean_loss=0.08748394809663296
Q_Learning [25/300]: mean_loss=0.045334643218666315
Q_Learning [26/300]: mean_loss=0.06586662633344531
Q_Learning [27/300]: mean_loss=0.09924027137458324
Q_Learning [28/300]: mean_loss=0.0431422614492476
Q_Learning [29/300]: mean_loss=0.04677288932725787
Q_Learning [30/300]: mean_loss=0.03130364674143493
Q_Learning [31/300]: mean_loss=0.026241437764838338
Q_Learning [32/300]: mean_loss=0.04278846876695752
Q_Learning [33/300]: mean_loss=0.023135778261348605
Q_Learning [34/300]: mean_loss=0.17769860662519932
Q_Learning [35/300]: mean_loss=0.06255025835707784
Q_Learning [36/300]: mean_loss=0.08590720873326063
Q_Learning [37/300]: mean_loss=0.052582832518965006
Q_Learning [38/300]: mean_loss=0.03763118525967002
Q_Learning [39/300]: mean_loss=0.11854861211031675
Q_Learning [40/300]: mean_loss=0.03391275042667985
Q_Learning [41/300]: mean_loss=0.02892331825569272
Q_Learning [42/300]: mean_loss=0.05590505665168166
Q_Learning [43/300]: mean_loss=0.12195468600839376
Q_Learning [44/300]: mean_loss=0.1437425184994936
Q_Learning [45/300]: mean_loss=0.08555234409868717
Q_Learning [46/300]: mean_loss=0.04737699776887894
Q_Learning [47/300]: mean_loss=0.08965051174163818
Q_Learning [48/300]: mean_loss=0.07074866350740194
Q_Learning [49/300]: mean_loss=0.0925081530585885
Q_Learning [50/300]: mean_loss=0.11014985013753176
Q_Learning [51/300]: mean_loss=0.028136915527284145
Q_Learning [52/300]: mean_loss=0.16163325868546963
Q_Learning [53/300]: mean_loss=0.021423124242573977
Q_Learning [54/300]: mean_loss=0.07830823119729757
Q_Learning [55/300]: mean_loss=0.043068003840744495
Q_Learning [56/300]: mean_loss=0.04736929200589657
Q_Learning [57/300]: mean_loss=0.09089074935764074
Q_Learning [58/300]: mean_loss=0.3046474978327751
Q_Learning [59/300]: mean_loss=0.08471610210835934
Q_Learning [60/300]: mean_loss=0.062392531894147396
Q_Learning [61/300]: mean_loss=0.03585687093436718
Q_Learning [62/300]: mean_loss=0.10714845918118954
Q_Learning [63/300]: mean_loss=0.05726163741201162
Q_Learning [64/300]: mean_loss=0.004637587000615895
Q_Learning [65/300]: mean_loss=0.06314303074032068
Q_Learning [66/300]: mean_loss=0.05088371457532048
Q_Learning [67/300]: mean_loss=0.06743950536474586
Q_Learning [68/300]: mean_loss=0.04895559512078762
Q_Learning [69/300]: mean_loss=0.08477944694459438
Q_Learning [70/300]: mean_loss=0.03594518546015024
Q_Learning [71/300]: mean_loss=0.07510503195226192
Q_Learning [72/300]: mean_loss=0.08281084522604942
Q_Learning [73/300]: mean_loss=0.04259959189221263
Q_Learning [74/300]: mean_loss=0.04336202424019575
Q_Learning [75/300]: mean_loss=0.029507195111364126
Q_Learning [76/300]: mean_loss=0.01947228447534144
Q_Learning [77/300]: mean_loss=0.03303929418325424
Q_Learning [78/300]: mean_loss=0.02840756974183023
Q_Learning [79/300]: mean_loss=0.045158205553889275
Q_Learning [80/300]: mean_loss=0.03979223733767867
Q_Learning [81/300]: mean_loss=0.019318463979288936
Q_Learning [82/300]: mean_loss=0.030520083382725716
Q_Learning [83/300]: mean_loss=0.042000272776931524
Q_Learning [84/300]: mean_loss=0.03423169394955039
Q_Learning [85/300]: mean_loss=0.023633339907974005
Q_Learning [86/300]: mean_loss=0.04119643312878907
Q_Learning [87/300]: mean_loss=0.01946978410705924
Q_Learning [88/300]: mean_loss=0.02512935665436089
Q_Learning [89/300]: mean_loss=0.042589399963617325
Q_Learning [90/300]: mean_loss=0.019315415062010288
Q_Learning [91/300]: mean_loss=0.034305202309042215
Q_Learning [92/300]: mean_loss=0.042007384821772575
Q_Learning [93/300]: mean_loss=0.03347895457409322
Q_Learning [94/300]: mean_loss=0.050144309643656015
Q_Learning [95/300]: mean_loss=0.04459991119801998
Q_Learning [96/300]: mean_loss=0.020068536279723048
Q_Learning [97/300]: mean_loss=0.05342924455180764
Q_Learning [98/300]: mean_loss=0.05181527556851506
Q_Learning [99/300]: mean_loss=0.02864817576482892
Q_Learning [100/300]: mean_loss=0.048314348328858614
Q_Learning [101/300]: mean_loss=0.016865286277607083
Q_Learning [102/300]: mean_loss=0.05880406638607383
Q_Learning [103/300]: mean_loss=0.04737826995551586
Q_Learning [104/300]: mean_loss=0.04826284013688564
Q_Learning [105/300]: mean_loss=0.04104418633505702
Q_Learning [106/300]: mean_loss=0.017629222013056278
Q_Learning [107/300]: mean_loss=0.019033252727240324
Q_Learning [108/300]: mean_loss=0.03389528696425259
Q_Learning [109/300]: mean_loss=0.030488200951367617
Q_Learning [110/300]: mean_loss=0.026343755889683962
Q_Learning [111/300]: mean_loss=0.028843654319643974
Q_Learning [112/300]: mean_loss=0.15874350257217884
Q_Learning [113/300]: mean_loss=0.021967160515487194
Q_Learning [114/300]: mean_loss=0.050346712581813335
Q_Learning [115/300]: mean_loss=0.05019567767158151
Q_Learning [116/300]: mean_loss=0.02352374978363514
Q_Learning [117/300]: mean_loss=0.06255228025838733
Q_Learning [118/300]: mean_loss=0.05802553938701749
Q_Learning [119/300]: mean_loss=0.131448139436543
Q_Learning [120/300]: mean_loss=0.06277351453900337
Q_Learning [121/300]: mean_loss=0.07878390606492758
Q_Learning [122/300]: mean_loss=0.07925731968134642
Q_Learning [123/300]: mean_loss=0.03697453858330846
Q_Learning [124/300]: mean_loss=0.015985274454578757
Q_Learning [125/300]: mean_loss=0.08489829627797008
Q_Learning [126/300]: mean_loss=0.04650972969830036
Q_Learning [127/300]: mean_loss=0.07906730473041534
Q_Learning [128/300]: mean_loss=0.030846114037558436
Q_Learning [129/300]: mean_loss=0.037904208060353994
Q_Learning [130/300]: mean_loss=0.019279753789305687
Q_Learning [131/300]: mean_loss=0.026303403545171022
Q_Learning [132/300]: mean_loss=0.017519108252599835
Q_Learning [133/300]: mean_loss=0.029992627911269665
Q_Learning [134/300]: mean_loss=0.02500919043086469
Q_Learning [135/300]: mean_loss=0.12253465224057436
Q_Learning [136/300]: mean_loss=0.02873656526207924
Q_Learning [137/300]: mean_loss=0.020220893435180187
Q_Learning [138/300]: mean_loss=0.012060593930073082
Q_Learning [139/300]: mean_loss=0.021537807770073414
Q_Learning [140/300]: mean_loss=0.03421309683471918
Q_Learning [141/300]: mean_loss=0.04935442050918937
Q_Learning [142/300]: mean_loss=0.01405357662588358
Q_Learning [143/300]: mean_loss=0.021646668901667
Q_Learning [144/300]: mean_loss=0.0141534119611606
Q_Learning [145/300]: mean_loss=0.06807319214567542
Q_Learning [146/300]: mean_loss=0.02279384504072368
Q_Learning [147/300]: mean_loss=0.01732111640740186
Q_Learning [148/300]: mean_loss=0.04897794546559453
Q_Learning [149/300]: mean_loss=0.09782886411994696
Q_Learning [150/300]: mean_loss=0.11940385308116674
Q_Learning [151/300]: mean_loss=0.028342564124614
Q_Learning [152/300]: mean_loss=0.01914484752342105
Q_Learning [153/300]: mean_loss=0.08846861775964499
Q_Learning [154/300]: mean_loss=0.02737193275243044
Q_Learning [155/300]: mean_loss=0.02203479059971869
Q_Learning [156/300]: mean_loss=0.023410890949890018
Q_Learning [157/300]: mean_loss=0.20540617406368256
Q_Learning [158/300]: mean_loss=0.007792291697114706
Q_Learning [159/300]: mean_loss=0.016908492194488645
Q_Learning [160/300]: mean_loss=0.04341276176273823
Q_Learning [161/300]: mean_loss=0.033063813811168075
Q_Learning [162/300]: mean_loss=0.01918139518238604
Q_Learning [163/300]: mean_loss=0.06280066538602114
Q_Learning [164/300]: mean_loss=0.013123814249411225
Q_Learning [165/300]: mean_loss=0.016250023967586458
Q_Learning [166/300]: mean_loss=0.029155804309993982
Q_Learning [167/300]: mean_loss=0.0473174056969583
Q_Learning [168/300]: mean_loss=0.04003885807469487
Q_Learning [169/300]: mean_loss=0.057365118991583586
Q_Learning [170/300]: mean_loss=0.1777661181986332
Q_Learning [171/300]: mean_loss=0.01801813708152622
Q_Learning [172/300]: mean_loss=0.016325465170666575
Q_Learning [173/300]: mean_loss=0.04553544847294688
Q_Learning [174/300]: mean_loss=0.014230761211365461
Q_Learning [175/300]: mean_loss=0.012270877719856799
Q_Learning [176/300]: mean_loss=0.007031151209957898
Q_Learning [177/300]: mean_loss=0.03306120540946722
Q_Learning [178/300]: mean_loss=0.04098415421321988
Q_Learning [179/300]: mean_loss=0.024989142082631588
Q_Learning [180/300]: mean_loss=0.03683599457144737
Q_Learning [181/300]: mean_loss=0.03867707261815667
Q_Learning [182/300]: mean_loss=0.034052268136292696
Q_Learning [183/300]: mean_loss=0.014097102335654199
Q_Learning [184/300]: mean_loss=0.010311255580745637
Q_Learning [185/300]: mean_loss=0.05653475224971771
Q_Learning [186/300]: mean_loss=0.03822652134113014
Q_Learning [187/300]: mean_loss=0.028193895239382982
Q_Learning [188/300]: mean_loss=0.028808724135160446
Q_Learning [189/300]: mean_loss=0.0553131029009819
Q_Learning [190/300]: mean_loss=0.026701857801526785
Q_Learning [191/300]: mean_loss=0.15872428007423878
Q_Learning [192/300]: mean_loss=0.02150938007980585
Q_Learning [193/300]: mean_loss=0.02500377013348043
Q_Learning [194/300]: mean_loss=0.02908629458397627
Q_Learning [195/300]: mean_loss=0.0274860099889338
Q_Learning [196/300]: mean_loss=0.01655495713930577
Q_Learning [197/300]: mean_loss=0.05298516480252147
Q_Learning [198/300]: mean_loss=0.01752975000999868
Q_Learning [199/300]: mean_loss=0.09919807221740484
Q_Learning [200/300]: mean_loss=0.015843442757613957
Q_Learning [201/300]: mean_loss=0.03460595291107893
Q_Learning [202/300]: mean_loss=0.036467937752604485
Q_Learning [203/300]: mean_loss=0.010958660393953323
Q_Learning [204/300]: mean_loss=0.018108565593138337
Q_Learning [205/300]: mean_loss=0.08213700354099274
Q_Learning [206/300]: mean_loss=0.02240092004649341
Q_Learning [207/300]: mean_loss=0.05329684913158417
Q_Learning [208/300]: mean_loss=0.046084731351584196
Q_Learning [209/300]: mean_loss=0.052188627421855927
Q_Learning [210/300]: mean_loss=0.03092258726246655
Q_Learning [211/300]: mean_loss=0.027820400660857558
Q_Learning [212/300]: mean_loss=0.11065225396305323
Q_Learning [213/300]: mean_loss=0.06841309741139412
Q_Learning [214/300]: mean_loss=0.029018904315307736
Q_Learning [215/300]: mean_loss=0.029413010692223907
Q_Learning [216/300]: mean_loss=0.07201827690005302
Q_Learning [217/300]: mean_loss=0.013539490522816777
Q_Learning [218/300]: mean_loss=0.008903816575184464
Q_Learning [219/300]: mean_loss=0.058332884684205055
Q_Learning [220/300]: mean_loss=0.012052460573613644
Q_Learning [221/300]: mean_loss=0.028291559545323253
Q_Learning [222/300]: mean_loss=0.03705972246825695
Q_Learning [223/300]: mean_loss=0.03124092286452651
Q_Learning [224/300]: mean_loss=0.008560518152080476
Q_Learning [225/300]: mean_loss=0.03756700409576297
Q_Learning [226/300]: mean_loss=0.033283289754763246
Q_Learning [227/300]: mean_loss=0.01668014330789447
Q_Learning [228/300]: mean_loss=0.03447105106897652
Q_Learning [229/300]: mean_loss=0.053355562034994364
Q_Learning [230/300]: mean_loss=0.01499369100201875
Q_Learning [231/300]: mean_loss=0.02690528496168554
Q_Learning [232/300]: mean_loss=0.021352380979806185
Q_Learning [233/300]: mean_loss=0.032087473664432764
Q_Learning [234/300]: mean_loss=0.039819310419261456
Q_Learning [235/300]: mean_loss=0.11792989633977413
Q_Learning [236/300]: mean_loss=0.05639387387782335
Q_Learning [237/300]: mean_loss=0.026008832966908813
Q_Learning [238/300]: mean_loss=0.09834196418523788
Q_Learning [239/300]: mean_loss=0.28236932680010796
Q_Learning [240/300]: mean_loss=0.035338937072083354
Q_Learning [241/300]: mean_loss=0.03557759802788496
Q_Learning [242/300]: mean_loss=0.01870391343254596
Q_Learning [243/300]: mean_loss=0.030912701273337007
Q_Learning [244/300]: mean_loss=0.042115761898458004
Q_Learning [245/300]: mean_loss=0.05931058619171381
Q_Learning [246/300]: mean_loss=0.028309035813435912
Q_Learning [247/300]: mean_loss=0.013234651298262179
Q_Learning [248/300]: mean_loss=0.09314091969281435
Q_Learning [249/300]: mean_loss=0.06638568826019764
Q_Learning [250/300]: mean_loss=0.014723949832841754
Q_Learning [251/300]: mean_loss=0.018724367022514343
Q_Learning [252/300]: mean_loss=0.01920052245259285
Q_Learning [253/300]: mean_loss=0.010881394846364856
Q_Learning [254/300]: mean_loss=0.018632502062246203
Q_Learning [255/300]: mean_loss=0.03775801695883274
Q_Learning [256/300]: mean_loss=0.017939676414243877
Q_Learning [257/300]: mean_loss=0.029125418746843934
Q_Learning [258/300]: mean_loss=0.012857683119364083
Q_Learning [259/300]: mean_loss=0.011518453829921782
Q_Learning [260/300]: mean_loss=0.023239349015057087
Q_Learning [261/300]: mean_loss=0.026513903634622693
Q_Learning [262/300]: mean_loss=0.030821703374385834
Q_Learning [263/300]: mean_loss=0.018977331928908825
Q_Learning [264/300]: mean_loss=0.04249506676569581
Q_Learning [265/300]: mean_loss=0.01932250475510955
Q_Learning [266/300]: mean_loss=0.014272636268287897
Q_Learning [267/300]: mean_loss=0.028330863919109106
Q_Learning [268/300]: mean_loss=0.011009433190338314
Q_Learning [269/300]: mean_loss=0.02977058244869113
Q_Learning [270/300]: mean_loss=0.023580395616590977
Q_Learning [271/300]: mean_loss=0.024115961510688066
Q_Learning [272/300]: mean_loss=0.006211479834746569
Q_Learning [273/300]: mean_loss=0.018833063542842865
Q_Learning [274/300]: mean_loss=0.0346274240873754
Q_Learning [275/300]: mean_loss=0.011114316526800394
Q_Learning [276/300]: mean_loss=0.019377184798941016
Q_Learning [277/300]: mean_loss=0.09111125208437443
Q_Learning [278/300]: mean_loss=0.023634599056094885
Q_Learning [279/300]: mean_loss=0.02547208685427904
Q_Learning [280/300]: mean_loss=0.030141781782731414
Q_Learning [281/300]: mean_loss=0.035787437576800585
Q_Learning [282/300]: mean_loss=0.03315382613800466
Q_Learning [283/300]: mean_loss=0.022709951736032963
Q_Learning [284/300]: mean_loss=0.026858556549996138
Q_Learning [285/300]: mean_loss=0.03217620635405183
Q_Learning [286/300]: mean_loss=0.017034572432748973
Q_Learning [287/300]: mean_loss=0.014830963453277946
Q_Learning [288/300]: mean_loss=0.01558406453114003
Q_Learning [289/300]: mean_loss=0.033756852615624666
Q_Learning [290/300]: mean_loss=0.008091774419881403
Q_Learning [291/300]: mean_loss=0.011942930519580841
Q_Learning [292/300]: mean_loss=0.008159792050719261
Q_Learning [293/300]: mean_loss=0.026246465742588043
Q_Learning [294/300]: mean_loss=0.03631762135773897
Q_Learning [295/300]: mean_loss=0.027577614644542336
Q_Learning [296/300]: mean_loss=0.04019779246300459
Q_Learning [297/300]: mean_loss=0.01727184932678938
Q_Learning [298/300]: mean_loss=0.040747912134975195
Q_Learning [299/300]: mean_loss=0.03660085890442133
Q_Learning [300/300]: mean_loss=0.049977424554526806
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 1.7769818 -1.3631088]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 1, 1, 0, 3, 1, 1, 1, 2, 4, 0, 0, 1, 0, 1, 3, 1, 0, 0, 1, 1, 1, 0, 1, 2, 0, 2, 2, 0, 2, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 0, 5, 1, 1, 6, 1, 0, 0, 0, 1, 1, 1, 1, 0, 2, 2, 6, 2, 0, 3, 2, 4, 1, 6, 2, 0, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 4, 0, 4, 3, 0, 2, 1, 4, 1, 3, 4, 6, 0, 1, 1, 0, 1, 1, 4, 0, 0, 0, 1, 4, 0, 1, 1, 1, 1, 4, 0, 2, 2, 4, 4, 1, 7, 3, 4, 1, 3, 1, 1, 0, 2, 1, 2, 4, 0, 2, 0, 0, 1, 4, 1, 4, 4, 1, 0, 1, 1, 1, 4, 4, 0, 0, 1, 0, 0, 4, 0, 1, 0, 1, 0, 1, 4, 0, 4, 1, 0, 4, 1, 4, 1, 0, 1, 4, 6, 0, 1, 0, 1, 4, 2, 1, 3, 1, 4, 2, 1, 0, 1, 4, 1, 1, 0, 3, 4, 4, 4, 4, 1, 7, 3, 0, 0, 2, 0, 0, 2, 1, 4, 1, 0, 0, 1, 1, 4, 0, 1, 1, 0, 4, 1, 1, 8, 9, 1, 2, 1, 4, 1, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 4, 1, 1, 4, 2, 0, 3, 2, 1, 1, 1, 2, 1, 1, 4, 1, 1, 0, 0, 1, 4, 10, 0, 0, 1, 2, 4, 0, 2, 4, 0, 0, 1, 4, 7, 5, 1, 2, 0, 0, 1, 1, 4, 1, 7]
Centroids: [[-1.6803607, 0.5943539], [-0.91453433, -0.07179159], [1.340211, -1.0137904]]
Centroids: [[1.3578744, -0.81632525], [-0.91794074, 0.030620588], [-2.0185163, -0.038707707], [1.3083906, -2.1996171], [-1.689492, 0.9478694], [-1.9720457, -2.083783], [0.8732422, 1.2170957], [-0.63280284, 2.2611775], [-3.9004138, -0.8408666], [2.613442, -3.613154], [0.20855789, -5.0016274]]
Contingency Matrix: 
[[ 0 30 28  0 41  1  0  2  1  0  0]
 [ 0 79 11  0  4  1  3  2  0  0  0]
 [81  1  0 11  0  0  2  0  0  1  1]]
[[0, 30, 28, 0, 41, 1, 0, 2, 1, 0, 0], [0, 79, 11, 0, 4, 1, 3, 2, 0, 0, 0], [81, 1, 0, 11, 0, 0, 2, 0, 0, 1, 1]]
[[0, 30, 28, 0, 41, 1, 0, 2, 1, 0, 0], [0, 79, 11, 0, 4, 1, 3, 2, 0, 0, 0], [81, 1, 0, 11, 0, 0, 2, 0, 0, 1, 1]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
[[-1, 30, 28, 0, 41, 1, 0, 2, 1, 0, 0], [-1, 79, 11, 0, 4, 1, 3, 2, 0, 0, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, 28, 0, 41, 1, 0, 2, 1, 0, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {2: 0, 1: 1, 0: 4}
New Contingency Matrix: 
[[41 30  0 28  0  1  0  2  1  0  0]
 [ 4 79  0 11  0  1  3  2  0  0  0]
 [ 0  1 81  0 11  0  2  0  0  1  1]]
New Clustered Label Sequence: [4, 1, 0, 2, 3, 5, 6, 7, 8, 9, 10]
Diagonal_Elements: [41, 79, 81], Sum: 201
All_Elements: [41, 30, 0, 28, 0, 1, 0, 2, 1, 0, 0, 4, 79, 0, 11, 0, 1, 3, 2, 0, 0, 0, 0, 1, 81, 0, 11, 0, 2, 0, 0, 1, 1], Sum: 300
Accuracy: 0.67
