Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_9_opt
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_9_opt/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt/2023_04_24-14_52_25
Punishment_Coefficient: 0.9
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002479AB83518>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.2680307626724243
Online_Training [2/700]: mean_loss=0.25465891882777214
Online_Training [3/700]: mean_loss=0.2422297392040491
Online_Training [4/700]: mean_loss=0.10754455719143152
Online_Training [5/700]: mean_loss=0.25868625566363335
Online_Training [6/700]: mean_loss=0.16085092723369598
Online_Training [7/700]: mean_loss=0.16076222620904446
Online_Training [8/700]: mean_loss=0.07296316791325808
Online_Training [9/700]: mean_loss=0.25229062139987946
Online_Training [10/700]: mean_loss=0.14542743377387524
Online_Training [11/700]: mean_loss=0.122611740604043
Online_Training [12/700]: mean_loss=0.10505146440118551
Online_Training [13/700]: mean_loss=0.0987406987696886
Online_Training [14/700]: mean_loss=0.07333918754011393
Online_Training [15/700]: mean_loss=0.0906401053071022
Online_Training [16/700]: mean_loss=0.11639816127717495
Online_Training [17/700]: mean_loss=0.11274830345064402
Online_Training [18/700]: mean_loss=0.058020723052322865
Online_Training [19/700]: mean_loss=0.03560175094753504
Online_Training [20/700]: mean_loss=0.12865754682570696
Online_Training [21/700]: mean_loss=0.12805750593543053
Online_Training [22/700]: mean_loss=0.02144345035776496
Online_Training [23/700]: mean_loss=0.02138084569014609
Online_Training [24/700]: mean_loss=0.0629290184006095
Online_Training [25/700]: mean_loss=0.04436864657327533
Online_Training [26/700]: mean_loss=0.04681672202423215
Online_Training [27/700]: mean_loss=0.08624537475407124
Online_Training [28/700]: mean_loss=0.03522784914821386
Online_Training [29/700]: mean_loss=0.049261524342000484
Online_Training [30/700]: mean_loss=0.0310643941629678
Online_Training [31/700]: mean_loss=0.02447384991683066
Online_Training [32/700]: mean_loss=0.04204034246504307
Online_Training [33/700]: mean_loss=0.018036322318948805
Online_Training [34/700]: mean_loss=0.1125931041315198
Online_Training [35/700]: mean_loss=0.0472306776791811
Online_Training [36/700]: mean_loss=0.08147466648370028
Online_Training [37/700]: mean_loss=0.0629102811217308
Online_Training [38/700]: mean_loss=0.04150622338056564
Online_Training [39/700]: mean_loss=0.09247614536434412
Online_Training [40/700]: mean_loss=0.03010694496333599
Online_Training [41/700]: mean_loss=0.02245845808647573
Online_Training [42/700]: mean_loss=0.06089143827557564
Online_Training [43/700]: mean_loss=0.09734613541513681
Online_Training [44/700]: mean_loss=0.10262214299291372
Online_Training [45/700]: mean_loss=0.05890219332650304
Online_Training [46/700]: mean_loss=0.03025724529288709
Online_Training [47/700]: mean_loss=0.05866739014163613
Online_Training [48/700]: mean_loss=0.06985591445118189
Online_Training [49/700]: mean_loss=0.047547530848532915
Online_Training [50/700]: mean_loss=0.05052348645403981
Online_Training [51/700]: mean_loss=0.02083408343605697
Online_Training [52/700]: mean_loss=0.09235191438347101
Online_Training [53/700]: mean_loss=0.022717774379998446
Online_Training [54/700]: mean_loss=0.043837862089276314
Online_Training [55/700]: mean_loss=0.024006936233490705
Online_Training [56/700]: mean_loss=0.0371803087182343
Online_Training [57/700]: mean_loss=0.07525462098419666
Online_Training [58/700]: mean_loss=0.12061112374067307
Online_Training [59/700]: mean_loss=0.08427925268188119
Online_Training [60/700]: mean_loss=0.04343182686716318
Online_Training [61/700]: mean_loss=0.022712470032274723
Online_Training [62/700]: mean_loss=0.08002462005242705
Online_Training [63/700]: mean_loss=0.06018701987341046
Online_Training [64/700]: mean_loss=0.011709181882906705
Online_Training [65/700]: mean_loss=0.06209834851324558
Online_Training [66/700]: mean_loss=0.053116822615265846
Online_Training [67/700]: mean_loss=0.06604903005063534
Online_Training [68/700]: mean_loss=0.020695088431239128
Online_Training [69/700]: mean_loss=0.03139358037151396
Online_Training [70/700]: mean_loss=0.03743955725803971
Online_Training [71/700]: mean_loss=0.07260258123278618
Online_Training [72/700]: mean_loss=0.07675706781446934
Online_Training [73/700]: mean_loss=0.037015979178249836
Online_Training [74/700]: mean_loss=0.040695080533623695
Online_Training [75/700]: mean_loss=0.02302637929096818
Online_Training [76/700]: mean_loss=0.01658242044504732
Online_Training [77/700]: mean_loss=0.03298658458516002
Online_Training [78/700]: mean_loss=0.02524955221451819
Online_Training [79/700]: mean_loss=0.029926338931545615
Online_Training [80/700]: mean_loss=0.027562128147110343
Online_Training [81/700]: mean_loss=0.00783394678728655
Online_Training [82/700]: mean_loss=0.02365341386757791
Online_Training [83/700]: mean_loss=0.03980579413473606
Online_Training [84/700]: mean_loss=0.024390411097556353
Online_Training [85/700]: mean_loss=0.020437124418094754
Online_Training [86/700]: mean_loss=0.03144488367252052
Online_Training [87/700]: mean_loss=0.008564772200770676
Online_Training [88/700]: mean_loss=0.03252142807468772
Online_Training [89/700]: mean_loss=0.03606135491281748
Online_Training [90/700]: mean_loss=0.016008557053282857
Online_Training [91/700]: mean_loss=0.035267509054392576
Online_Training [92/700]: mean_loss=0.04630487132817507
Online_Training [93/700]: mean_loss=0.021523204632103443
Online_Training [94/700]: mean_loss=0.041857856791466475
Online_Training [95/700]: mean_loss=0.036172982305288315
Online_Training [96/700]: mean_loss=0.017022684682160616
Online_Training [97/700]: mean_loss=0.04680051375180483
Online_Training [98/700]: mean_loss=0.03168773744255304
Online_Training [99/700]: mean_loss=0.01713908731471747
Online_Training [100/700]: mean_loss=0.05961667047813535
Online_Training [101/700]: mean_loss=0.013807420036755502
Online_Training [102/700]: mean_loss=0.047700274270027876
Online_Training [103/700]: mean_loss=0.03245962015353143
Online_Training [104/700]: mean_loss=0.05761469481512904
Online_Training [105/700]: mean_loss=0.02433509170077741
Online_Training [106/700]: mean_loss=0.007214054581709206
Online_Training [107/700]: mean_loss=0.01567429944407195
Online_Training [108/700]: mean_loss=0.021074541611596942
Online_Training [109/700]: mean_loss=0.02494891150854528
Online_Training [110/700]: mean_loss=0.02774383220821619
Online_Training [111/700]: mean_loss=0.020284370984882116
Online_Training [112/700]: mean_loss=0.07055891212075949
Online_Training [113/700]: mean_loss=0.013373888796195388
Online_Training [114/700]: mean_loss=0.03208415117114782
Online_Training [115/700]: mean_loss=0.037047065794467926
Online_Training [116/700]: mean_loss=0.023747905855998397
Online_Training [117/700]: mean_loss=0.05329431314021349
Online_Training [118/700]: mean_loss=0.03556748665869236
Online_Training [119/700]: mean_loss=0.09560940228402615
Online_Training [120/700]: mean_loss=0.06229535769671202
Online_Training [121/700]: mean_loss=0.0691006425768137
Online_Training [122/700]: mean_loss=0.058441026136279106
Online_Training [123/700]: mean_loss=0.046516754664480686
Online_Training [124/700]: mean_loss=0.011764157214201987
Online_Training [125/700]: mean_loss=0.06039560725912452
Online_Training [126/700]: mean_loss=0.023976342985406518
Online_Training [127/700]: mean_loss=0.0628259857185185
Online_Training [128/700]: mean_loss=0.018575280904769897
Online_Training [129/700]: mean_loss=0.013606470543891191
Online_Training [130/700]: mean_loss=0.01906874030828476
Online_Training [131/700]: mean_loss=0.01868572412058711
Online_Training [132/700]: mean_loss=0.02270642784424126
Online_Training [133/700]: mean_loss=0.02903491328470409
Online_Training [134/700]: mean_loss=0.008186855993699282
Online_Training [135/700]: mean_loss=0.06741630751639605
Online_Training [136/700]: mean_loss=0.019213117426261306
Online_Training [137/700]: mean_loss=0.02456865762360394
Online_Training [138/700]: mean_loss=0.014062870643101633
Online_Training [139/700]: mean_loss=0.02093987329863012
Online_Training [140/700]: mean_loss=0.00810366333462298
Online_Training [141/700]: mean_loss=0.021843241062015295
Online_Training [142/700]: mean_loss=0.010896473773755133
Online_Training [143/700]: mean_loss=0.022314721019938588
Online_Training [144/700]: mean_loss=0.008419898513238877
Online_Training [145/700]: mean_loss=0.05376276466995478
Online_Training [146/700]: mean_loss=0.02019390440545976
Online_Training [147/700]: mean_loss=0.01670331065542996
Online_Training [148/700]: mean_loss=0.04714498948305845
Online_Training [149/700]: mean_loss=0.04966562241315842
Online_Training [150/700]: mean_loss=0.08495844155550003
Online_Training [151/700]: mean_loss=0.029611733742058277
Online_Training [152/700]: mean_loss=0.01823128736577928
Online_Training [153/700]: mean_loss=0.02233169972896576
Online_Training [154/700]: mean_loss=0.027931658318266273
Online_Training [155/700]: mean_loss=0.013570254435762763
Online_Training [156/700]: mean_loss=0.02522838651202619
Online_Training [157/700]: mean_loss=0.16451266966760159
Online_Training [158/700]: mean_loss=0.010798033501487225
Online_Training [159/700]: mean_loss=0.0216672969982028
Online_Training [160/700]: mean_loss=0.03855819581076503
Online_Training [161/700]: mean_loss=0.024409585632383823
Online_Training [162/700]: mean_loss=0.01619198708795011
Online_Training [163/700]: mean_loss=0.028784779831767082
Online_Training [164/700]: mean_loss=0.013821059605106711
Online_Training [165/700]: mean_loss=0.014429793343879282
Online_Training [166/700]: mean_loss=0.022847147192806005
Online_Training [167/700]: mean_loss=0.030703387456014752
Online_Training [168/700]: mean_loss=0.04817593237385154
Online_Training [169/700]: mean_loss=0.045583979692310095
Online_Training [170/700]: mean_loss=0.17369131743907928
Online_Training [171/700]: mean_loss=0.016032155486755073
Online_Training [172/700]: mean_loss=0.024721197551116347
Online_Training [173/700]: mean_loss=0.03957257233560085
Online_Training [174/700]: mean_loss=0.019699543016031384
Online_Training [175/700]: mean_loss=0.01385657419450581
Online_Training [176/700]: mean_loss=0.00821346661541611
Online_Training [177/700]: mean_loss=0.020871229702606797
Online_Training [178/700]: mean_loss=0.020008855499327183
Online_Training [179/700]: mean_loss=0.0242280054371804
Online_Training [180/700]: mean_loss=0.028235696954652667
Online_Training [181/700]: mean_loss=0.028098956448957324
Online_Training [182/700]: mean_loss=0.0118573943618685
Online_Training [183/700]: mean_loss=0.015533503028564155
Online_Training [184/700]: mean_loss=0.010147167602553964
Online_Training [185/700]: mean_loss=0.044108144007623196
Online_Training [186/700]: mean_loss=0.037744543282315135
Online_Training [187/700]: mean_loss=0.015259299194440246
Online_Training [188/700]: mean_loss=0.02676120586693287
Online_Training [189/700]: mean_loss=0.0454289298504591
Online_Training [190/700]: mean_loss=0.016683471389114857
Online_Training [191/700]: mean_loss=0.15967351756989956
Online_Training [192/700]: mean_loss=0.02377952612005174
Online_Training [193/700]: mean_loss=0.024261708138510585
Online_Training [194/700]: mean_loss=0.017313749063760042
Online_Training [195/700]: mean_loss=0.022402031114324927
Online_Training [196/700]: mean_loss=0.010662190965376794
Online_Training [197/700]: mean_loss=0.03570818714797497
Online_Training [198/700]: mean_loss=0.016670207609422505
Online_Training [199/700]: mean_loss=0.09713387675583363
Online_Training [200/700]: mean_loss=0.022268512519076467
Online_Training [201/700]: mean_loss=0.022894622292369604
Online_Training [202/700]: mean_loss=0.02621357887983322
Online_Training [203/700]: mean_loss=0.004370045528048649
Online_Training [204/700]: mean_loss=0.017361640348099172
Online_Training [205/700]: mean_loss=0.06299826595932245
Online_Training [206/700]: mean_loss=0.009996668784879148
Online_Training [207/700]: mean_loss=0.04473619535565376
Online_Training [208/700]: mean_loss=0.03509086603298783
Online_Training [209/700]: mean_loss=0.05786542221903801
Online_Training [210/700]: mean_loss=0.025521254865452647
Online_Training [211/700]: mean_loss=0.009552070638164878
Online_Training [212/700]: mean_loss=0.1148031186312437
Online_Training [213/700]: mean_loss=0.07755832467228174
Online_Training [214/700]: mean_loss=0.02996809221804142
Online_Training [215/700]: mean_loss=0.019281333778053522
Online_Training [216/700]: mean_loss=0.047402418218553066
Online_Training [217/700]: mean_loss=0.015835230937227607
Online_Training [218/700]: mean_loss=0.007493797980714589
Online_Training [219/700]: mean_loss=0.04639095766469836
Online_Training [220/700]: mean_loss=0.010285487165674567
Online_Training [221/700]: mean_loss=0.029501041863113642
Online_Training [222/700]: mean_loss=0.01709021464921534
Online_Training [223/700]: mean_loss=0.027594563318416476
Online_Training [224/700]: mean_loss=0.008367093047127128
Online_Training [225/700]: mean_loss=0.019676292082294822
Online_Training [226/700]: mean_loss=0.016696261591278017
Online_Training [227/700]: mean_loss=0.00883939175400883
Online_Training [228/700]: mean_loss=0.03821833012625575
Online_Training [229/700]: mean_loss=0.04269241355359554
Online_Training [230/700]: mean_loss=0.013153966865502298
Online_Training [231/700]: mean_loss=0.030107308644801378
Online_Training [232/700]: mean_loss=0.013315174030140042
Online_Training [233/700]: mean_loss=0.02355118840932846
Online_Training [234/700]: mean_loss=0.020569917804095894
Online_Training [235/700]: mean_loss=0.06869309954345226
Online_Training [236/700]: mean_loss=0.047020452097058296
Online_Training [237/700]: mean_loss=0.018578761024400592
Online_Training [238/700]: mean_loss=0.0921240970492363
Online_Training [239/700]: mean_loss=0.2783725205808878
Online_Training [240/700]: mean_loss=0.06907670106738806
Online_Training [241/700]: mean_loss=0.039480842649936676
Online_Training [242/700]: mean_loss=0.0372870652936399
Online_Training [243/700]: mean_loss=0.03300666343420744
Online_Training [244/700]: mean_loss=0.04050882672891021
Online_Training [245/700]: mean_loss=0.05038610706105828
Online_Training [246/700]: mean_loss=0.02510850504040718
Online_Training [247/700]: mean_loss=0.02070062083657831
Online_Training [248/700]: mean_loss=0.05411567585542798
Online_Training [249/700]: mean_loss=0.05287210503593087
Online_Training [250/700]: mean_loss=0.01410149596631527
Online_Training [251/700]: mean_loss=0.019449007464572787
Online_Training [252/700]: mean_loss=0.014104808564297855
Online_Training [253/700]: mean_loss=0.0079431893536821
Online_Training [254/700]: mean_loss=0.020097604021430016
Online_Training [255/700]: mean_loss=0.04552658135071397
Online_Training [256/700]: mean_loss=0.0199826747411862
Online_Training [257/700]: mean_loss=0.02545223035849631
Online_Training [258/700]: mean_loss=0.010448934743180871
Online_Training [259/700]: mean_loss=0.01063920243177563
Online_Training [260/700]: mean_loss=0.016976890619844198
Online_Training [261/700]: mean_loss=0.02388317440636456
Online_Training [262/700]: mean_loss=0.026585086714476347
Online_Training [263/700]: mean_loss=0.016365386196412146
Online_Training [264/700]: mean_loss=0.044007503893226385
Online_Training [265/700]: mean_loss=0.01594249054323882
Online_Training [266/700]: mean_loss=0.01011755398940295
Online_Training [267/700]: mean_loss=0.014292052364908159
Online_Training [268/700]: mean_loss=0.007246025023050606
Online_Training [269/700]: mean_loss=0.03005503467284143
Online_Training [270/700]: mean_loss=0.015004590386524796
Online_Training [271/700]: mean_loss=0.017867897870019078
Online_Training [272/700]: mean_loss=0.007541793049313128
Online_Training [273/700]: mean_loss=0.011464202078059316
Online_Training [274/700]: mean_loss=0.021699523786082864
Online_Training [275/700]: mean_loss=0.009969133185222745
Online_Training [276/700]: mean_loss=0.013643345097079873
Online_Training [277/700]: mean_loss=0.07526080403476954
Online_Training [278/700]: mean_loss=0.021576937288045883
Online_Training [279/700]: mean_loss=0.02363621979020536
Online_Training [280/700]: mean_loss=0.033760696183890104
Online_Training [281/700]: mean_loss=0.03387511218897998
Online_Training [282/700]: mean_loss=0.026965411612764
Online_Training [283/700]: mean_loss=0.019886894850060344
Online_Training [284/700]: mean_loss=0.02343784272670746
Online_Training [285/700]: mean_loss=0.026547996094450355
Online_Training [286/700]: mean_loss=0.006463760044425726
Online_Training [287/700]: mean_loss=0.013416723813861609
Online_Training [288/700]: mean_loss=0.014566495781764388
Online_Training [289/700]: mean_loss=0.03156088478863239
Online_Training [290/700]: mean_loss=0.00828864041250199
Online_Training [291/700]: mean_loss=0.014663187903352082
Online_Training [292/700]: mean_loss=0.006517152534797788
Online_Training [293/700]: mean_loss=0.0188731097150594
Online_Training [294/700]: mean_loss=0.026819435879588127
Online_Training [295/700]: mean_loss=0.03518998599611223
Online_Training [296/700]: mean_loss=0.028888732194900513
Online_Training [297/700]: mean_loss=0.017272471450269222
Online_Training [298/700]: mean_loss=0.029552266001701355
Online_Training [299/700]: mean_loss=0.02878534561023116
Online_Training [300/700]: mean_loss=0.04603148391470313
Online_Training [301/700]: mean_loss=0.016599242808297276
Online_Training [302/700]: mean_loss=0.029180932324379683
Online_Training [303/700]: mean_loss=0.01632609439548105
Online_Training [304/700]: mean_loss=0.018618476926349103
Online_Training [305/700]: mean_loss=0.06742563750594854
Online_Training [306/700]: mean_loss=0.052922436967492104
Online_Training [307/700]: mean_loss=0.0769428014755249
Online_Training [308/700]: mean_loss=0.020186961628496647
Online_Training [309/700]: mean_loss=0.008428759989328682
Online_Training [310/700]: mean_loss=0.021704323356971145
Online_Training [311/700]: mean_loss=0.015459731221199036
Online_Training [312/700]: mean_loss=0.054463156033307314
Online_Training [313/700]: mean_loss=0.017008557682856917
Online_Training [314/700]: mean_loss=0.01358175789937377
Online_Training [315/700]: mean_loss=0.011492489371448755
Online_Training [316/700]: mean_loss=0.015066837659105659
Online_Training [317/700]: mean_loss=0.006656819197814912
Online_Training [318/700]: mean_loss=0.02736517833545804
Online_Training [319/700]: mean_loss=0.026206542737782
Online_Training [320/700]: mean_loss=0.022030784748494625
Online_Training [321/700]: mean_loss=0.01598802558146417
Online_Training [322/700]: mean_loss=0.0315568910446018
Online_Training [323/700]: mean_loss=0.022676266497001052
Online_Training [324/700]: mean_loss=0.013009186135604978
Online_Training [325/700]: mean_loss=0.025156376184895635
Online_Training [326/700]: mean_loss=0.029063445515930653
Online_Training [327/700]: mean_loss=0.021428029285743833
Online_Training [328/700]: mean_loss=0.037016686517745256
Online_Training [329/700]: mean_loss=0.014936776366084814
Online_Training [330/700]: mean_loss=0.026594278868287802
Online_Training [331/700]: mean_loss=0.02144358167424798
Online_Training [332/700]: mean_loss=0.015399771393276751
Online_Training [333/700]: mean_loss=0.008708474109880626
Online_Training [334/700]: mean_loss=0.010176981741096824
Online_Training [335/700]: mean_loss=0.05981820356100798
Online_Training [336/700]: mean_loss=0.06537628592923284
Online_Training [337/700]: mean_loss=0.1227007694542408
Online_Training [338/700]: mean_loss=0.04203393589705229
Online_Training [339/700]: mean_loss=0.030360236880369484
Online_Training [340/700]: mean_loss=0.011787039111368358
Online_Training [341/700]: mean_loss=0.050768869929015636
Online_Training [342/700]: mean_loss=0.07028182642534375
Online_Training [343/700]: mean_loss=0.021956892451271415
Online_Training [344/700]: mean_loss=0.019343998050317168
Online_Training [345/700]: mean_loss=0.0380939831957221
Online_Training [346/700]: mean_loss=0.012435688404366374
Online_Training [347/700]: mean_loss=0.12904216721653938
Online_Training [348/700]: mean_loss=0.026908524800091982
Online_Training [349/700]: mean_loss=0.02614912181161344
Online_Training [350/700]: mean_loss=0.017169759492389858
Online_Training [351/700]: mean_loss=0.009144005947746336
Online_Training [352/700]: mean_loss=0.009562612685840577
Online_Training [353/700]: mean_loss=0.046914088539779186
Online_Training [354/700]: mean_loss=0.009486042312346399
Online_Training [355/700]: mean_loss=0.012454394833184779
Online_Training [356/700]: mean_loss=0.022352007683366537
Online_Training [357/700]: mean_loss=0.08228655252605677
Online_Training [358/700]: mean_loss=0.07112433202564716
Online_Training [359/700]: mean_loss=0.08521667588502169
Online_Training [360/700]: mean_loss=0.027788066770881414
Online_Training [361/700]: mean_loss=0.025161237455904484
Online_Training [362/700]: mean_loss=0.053770049940794706
Online_Training [363/700]: mean_loss=0.020142055582255125
Online_Training [364/700]: mean_loss=0.009821929270401597
Online_Training [365/700]: mean_loss=0.018374660867266357
Online_Training [366/700]: mean_loss=0.01960046961903572
Online_Training [367/700]: mean_loss=0.030432099709287286
Online_Training [368/700]: mean_loss=0.025704000610858202
Online_Training [369/700]: mean_loss=0.027949638664722443
Online_Training [370/700]: mean_loss=0.038583141285926104
Online_Training [371/700]: mean_loss=0.009866731590591371
Online_Training [372/700]: mean_loss=0.0272348637226969
Online_Training [373/700]: mean_loss=0.022591719403862953
Online_Training [374/700]: mean_loss=0.01575355080422014
Online_Training [375/700]: mean_loss=0.019462748430669308
Online_Training [376/700]: mean_loss=0.009011598594952375
Online_Training [377/700]: mean_loss=0.018272467888891697
Online_Training [378/700]: mean_loss=0.02362753450870514
Online_Training [379/700]: mean_loss=0.03308588592335582
Online_Training [380/700]: mean_loss=0.011283190222457051
Online_Training [381/700]: mean_loss=0.015716044115833938
Online_Training [382/700]: mean_loss=0.008861300768330693
Online_Training [383/700]: mean_loss=0.007838631048798561
Online_Training [384/700]: mean_loss=0.17070165276527405
Online_Training [385/700]: mean_loss=0.009412277722731233
Online_Training [386/700]: mean_loss=0.02255104831419885
Online_Training [387/700]: mean_loss=0.018783538369461894
Online_Training [388/700]: mean_loss=0.010321842390112579
Online_Training [389/700]: mean_loss=0.010417497134767473
Online_Training [390/700]: mean_loss=0.03999643726274371
Online_Training [391/700]: mean_loss=0.008375753473956138
Online_Training [392/700]: mean_loss=0.01878431555815041
Online_Training [393/700]: mean_loss=0.02082901168614626
Online_Training [394/700]: mean_loss=0.023523399606347084
Online_Training [395/700]: mean_loss=0.007167000148911029
Online_Training [396/700]: mean_loss=0.024530218681320548
Online_Training [397/700]: mean_loss=0.016991917975246906
Online_Training [398/700]: mean_loss=0.029825071105733514
Online_Training [399/700]: mean_loss=0.02826530486345291
Online_Training [400/700]: mean_loss=0.030785757349804044
Online_Training [401/700]: mean_loss=0.029867764795199037
Online_Training [402/700]: mean_loss=0.010798441711813211
Online_Training [403/700]: mean_loss=0.018408611067570746
Online_Training [404/700]: mean_loss=0.04327699774876237
Online_Training [405/700]: mean_loss=0.0669206134043634
Online_Training [406/700]: mean_loss=0.010969092370942235
Online_Training [407/700]: mean_loss=0.037363963201642036
Online_Training [408/700]: mean_loss=0.012806044891476631
Online_Training [409/700]: mean_loss=0.006602214241866022
Online_Training [410/700]: mean_loss=0.024500587722286582
Online_Training [411/700]: mean_loss=0.014782152487896383
Online_Training [412/700]: mean_loss=0.10195720102638006
Online_Training [413/700]: mean_loss=0.02589862304739654
Online_Training [414/700]: mean_loss=0.023998720105737448
Online_Training [415/700]: mean_loss=0.02261510887183249
Online_Training [416/700]: mean_loss=0.015138765797019005
Online_Training [417/700]: mean_loss=0.05912507278844714
Online_Training [418/700]: mean_loss=0.00864875316619873
Online_Training [419/700]: mean_loss=0.008654665783978999
Online_Training [420/700]: mean_loss=0.05297576915472746
Online_Training [421/700]: mean_loss=0.03253541002050042
Online_Training [422/700]: mean_loss=0.022351375548169017
Online_Training [423/700]: mean_loss=0.03537146653980017
Online_Training [424/700]: mean_loss=0.05891470052301884
Online_Training [425/700]: mean_loss=0.024880105862393975
Online_Training [426/700]: mean_loss=0.007965477532707155
Online_Training [427/700]: mean_loss=0.019085515988990664
Online_Training [428/700]: mean_loss=0.02604461251758039
Online_Training [429/700]: mean_loss=0.012245672987774014
Online_Training [430/700]: mean_loss=0.010250937542878091
Online_Training [431/700]: mean_loss=0.014166526030749083
Online_Training [432/700]: mean_loss=0.08120794873684645
Online_Training [433/700]: mean_loss=0.01977935153990984
Online_Training [434/700]: mean_loss=0.02032330015208572
Online_Training [435/700]: mean_loss=0.01777067524380982
Online_Training [436/700]: mean_loss=0.05775015940889716
Online_Training [437/700]: mean_loss=0.014993328135460615
Online_Training [438/700]: mean_loss=0.14143768046051264
Online_Training [439/700]: mean_loss=0.07021334022283554
Online_Training [440/700]: mean_loss=0.06382418237626553
Online_Training [441/700]: mean_loss=0.06635713018476963
Online_Training [442/700]: mean_loss=0.013058469747193158
Online_Training [443/700]: mean_loss=0.015897423028945923
Online_Training [444/700]: mean_loss=0.02552169794216752
Online_Training [445/700]: mean_loss=0.022135019302368164
Online_Training [446/700]: mean_loss=0.0366677432321012
Online_Training [447/700]: mean_loss=0.012149773770943284
Online_Training [448/700]: mean_loss=0.016607166035100818
Online_Training [449/700]: mean_loss=0.01592576422262937
Online_Training [450/700]: mean_loss=0.015389373642392457
Online_Training [451/700]: mean_loss=0.04053591750562191
Online_Training [452/700]: mean_loss=0.03718021837994456
Online_Training [453/700]: mean_loss=0.0630787773989141
Online_Training [454/700]: mean_loss=0.034129714127629995
Online_Training [455/700]: mean_loss=0.045311895199120045
Online_Training [456/700]: mean_loss=0.010424235253594816
Online_Training [457/700]: mean_loss=0.010317035659682006
Online_Training [458/700]: mean_loss=0.028425276512280107
Online_Training [459/700]: mean_loss=0.016612847102805972
Online_Training [460/700]: mean_loss=0.02287171338684857
Online_Training [461/700]: mean_loss=0.03836557129397988
Online_Training [462/700]: mean_loss=0.015620703343302011
Online_Training [463/700]: mean_loss=0.019448611419647932
Online_Training [464/700]: mean_loss=0.019390894332900643
Online_Training [465/700]: mean_loss=0.03615177795290947
Online_Training [466/700]: mean_loss=0.030484820948913693
Online_Training [467/700]: mean_loss=0.025626724120229483
Online_Training [468/700]: mean_loss=0.01642382948193699
Online_Training [469/700]: mean_loss=0.02429839503020048
Online_Training [470/700]: mean_loss=0.04640506953001022
Online_Training [471/700]: mean_loss=0.02004971611313522
Online_Training [472/700]: mean_loss=0.02476427494548261
Online_Training [473/700]: mean_loss=0.005911895364988595
Online_Training [474/700]: mean_loss=0.013322776649147272
Online_Training [475/700]: mean_loss=0.019122092984616756
Online_Training [476/700]: mean_loss=0.22118249721825123
Online_Training [477/700]: mean_loss=0.1089525856077671
Online_Training [478/700]: mean_loss=0.045711116399616
Online_Training [479/700]: mean_loss=0.00948831276036799
Online_Training [480/700]: mean_loss=0.01211332541424781
Online_Training [481/700]: mean_loss=0.026665155543014407
Online_Training [482/700]: mean_loss=0.02201570407487452
Online_Training [483/700]: mean_loss=0.014866888406686485
Online_Training [484/700]: mean_loss=0.02386803668923676
Online_Training [485/700]: mean_loss=0.011912887915968895
Online_Training [486/700]: mean_loss=0.017147793085314333
Online_Training [487/700]: mean_loss=0.0313191432505846
Online_Training [488/700]: mean_loss=0.01816191035322845
Online_Training [489/700]: mean_loss=0.015967503539286554
Online_Training [490/700]: mean_loss=0.025023694382980466
Online_Training [491/700]: mean_loss=0.0338191541377455
Online_Training [492/700]: mean_loss=0.018118266481906176
Online_Training [493/700]: mean_loss=0.024459844222292304
Online_Training [494/700]: mean_loss=0.04267967492341995
Online_Training [495/700]: mean_loss=0.01070176565553993
Online_Training [496/700]: mean_loss=0.031767692882567644
Online_Training [497/700]: mean_loss=0.01740599295590073
Online_Training [498/700]: mean_loss=0.018317318987101316
Online_Training [499/700]: mean_loss=0.015469879028387368
Online_Training [500/700]: mean_loss=0.010762009653262794
Online_Training [501/700]: mean_loss=0.013631417299620807
Online_Training [502/700]: mean_loss=0.03938278090208769
Online_Training [503/700]: mean_loss=0.015714864362962544
Online_Training [504/700]: mean_loss=0.023156995652243495
Online_Training [505/700]: mean_loss=0.014393228222616017
Online_Training [506/700]: mean_loss=0.11102166213095188
Online_Training [507/700]: mean_loss=0.12875542044639587
Online_Training [508/700]: mean_loss=0.030259970808401704
Online_Training [509/700]: mean_loss=0.015037076198495924
Online_Training [510/700]: mean_loss=0.019598995568230748
Online_Training [511/700]: mean_loss=0.01975157647393644
Online_Training [512/700]: mean_loss=0.01598676131106913
Online_Training [513/700]: mean_loss=0.02921188110485673
Online_Training [514/700]: mean_loss=0.02956045395694673
Online_Training [515/700]: mean_loss=0.027052482357248664
Online_Training [516/700]: mean_loss=0.018675234634429216
Online_Training [517/700]: mean_loss=0.023919232888147235
Online_Training [518/700]: mean_loss=0.028495660051703453
Online_Training [519/700]: mean_loss=0.008597084553912282
Online_Training [520/700]: mean_loss=0.025592179968953133
Online_Training [521/700]: mean_loss=0.032359179109334946
Online_Training [522/700]: mean_loss=0.009078022034373134
Online_Training [523/700]: mean_loss=0.02006617304868996
Online_Training [524/700]: mean_loss=0.07612238638103008
Online_Training [525/700]: mean_loss=0.023885942297056317
Online_Training [526/700]: mean_loss=0.01247331069316715
Online_Training [527/700]: mean_loss=0.01763228513300419
Online_Training [528/700]: mean_loss=0.024176612263545394
Online_Training [529/700]: mean_loss=0.02886372827924788
Online_Training [530/700]: mean_loss=0.01659177232068032
Online_Training [531/700]: mean_loss=0.0439565503038466
Online_Training [532/700]: mean_loss=0.02760343928821385
Online_Training [533/700]: mean_loss=0.023046984570100904
Online_Training [534/700]: mean_loss=0.01745943760033697
Online_Training [535/700]: mean_loss=0.023099388927221298
Online_Training [536/700]: mean_loss=0.10390456672757864
Online_Training [537/700]: mean_loss=0.03268440626561642
Online_Training [538/700]: mean_loss=0.012993849930353463
Online_Training [539/700]: mean_loss=0.006911286094691604
Online_Training [540/700]: mean_loss=0.01216709241271019
Online_Training [541/700]: mean_loss=0.11067575123161077
Online_Training [542/700]: mean_loss=0.009288266708608717
Online_Training [543/700]: mean_loss=0.02512304252013564
Online_Training [544/700]: mean_loss=0.014258151408284903
Online_Training [545/700]: mean_loss=0.0430465517565608
Online_Training [546/700]: mean_loss=0.011710527585819364
Online_Training [547/700]: mean_loss=0.01521839527413249
Online_Training [548/700]: mean_loss=0.014555457048118114
Online_Training [549/700]: mean_loss=0.010553015279583633
Online_Training [550/700]: mean_loss=0.04510491341352463
Online_Training [551/700]: mean_loss=0.026498307939618826
Online_Training [552/700]: mean_loss=0.03938007075339556
Online_Training [553/700]: mean_loss=0.04701761156320572
Online_Training [554/700]: mean_loss=0.010546599281951785
Online_Training [555/700]: mean_loss=0.024512748001143336
Online_Training [556/700]: mean_loss=0.01697667478583753
Online_Training [557/700]: mean_loss=0.018919446738436818
Online_Training [558/700]: mean_loss=0.007336355629377067
Online_Training [559/700]: mean_loss=0.003384396608453244
Online_Training [560/700]: mean_loss=0.01160251209512353
Online_Training [561/700]: mean_loss=0.021997089497745037
Online_Training [562/700]: mean_loss=0.03688660031184554
Online_Training [563/700]: mean_loss=0.015779975801706314
Online_Training [564/700]: mean_loss=0.014657480060122907
Online_Training [565/700]: mean_loss=0.024258935824036598
Online_Training [566/700]: mean_loss=0.01465787913184613
Online_Training [567/700]: mean_loss=0.017923269304446876
Online_Training [568/700]: mean_loss=0.024963081115856767
Online_Training [569/700]: mean_loss=0.02744529629126191
Online_Training [570/700]: mean_loss=0.009060992393642664
Online_Training [571/700]: mean_loss=0.025834974367171526
Online_Training [572/700]: mean_loss=0.019527334021404386
Online_Training [573/700]: mean_loss=0.024574756855145097
Online_Training [574/700]: mean_loss=0.057845468167215586
Online_Training [575/700]: mean_loss=0.06459678336977959
Online_Training [576/700]: mean_loss=0.012946507195010781
Online_Training [577/700]: mean_loss=0.015970019972883165
Online_Training [578/700]: mean_loss=0.008677580044604838
Online_Training [579/700]: mean_loss=0.016952752834185958
Online_Training [580/700]: mean_loss=0.022613497218117118
Online_Training [581/700]: mean_loss=0.024772746255621314
Online_Training [582/700]: mean_loss=0.019581621512770653
Online_Training [583/700]: mean_loss=0.007156725449021906
Online_Training [584/700]: mean_loss=0.01929900306276977
Online_Training [585/700]: mean_loss=0.01824454916641116
Online_Training [586/700]: mean_loss=0.09804389718919992
Online_Training [587/700]: mean_loss=0.02630383404903114
Online_Training [588/700]: mean_loss=0.012191048474051058
Online_Training [589/700]: mean_loss=0.02673182333819568
Online_Training [590/700]: mean_loss=0.016457523335702717
Online_Training [591/700]: mean_loss=0.020797646837309003
Online_Training [592/700]: mean_loss=0.015313074691221118
Online_Training [593/700]: mean_loss=0.03837317926809192
Online_Training [594/700]: mean_loss=0.028487497940659523
Online_Training [595/700]: mean_loss=0.024705421878024936
Online_Training [596/700]: mean_loss=0.011357757495716214
Online_Training [597/700]: mean_loss=0.008367552189156413
Online_Training [598/700]: mean_loss=0.018297537229955196
Online_Training [599/700]: mean_loss=0.016997708473354578
Online_Training [600/700]: mean_loss=0.011323250131681561
Online_Training [601/700]: mean_loss=0.032685007667168975
Online_Training [602/700]: mean_loss=0.009596881573088467
Online_Training [603/700]: mean_loss=0.005400785419624299
Online_Training [604/700]: mean_loss=0.015627798507921398
Online_Training [605/700]: mean_loss=0.014646757976152003
Online_Training [606/700]: mean_loss=0.004292627796530724
Online_Training [607/700]: mean_loss=0.010009068879298866
Online_Training [608/700]: mean_loss=0.014959002030082047
Online_Training [609/700]: mean_loss=0.014562324387952685
Online_Training [610/700]: mean_loss=0.01987189636565745
Online_Training [611/700]: mean_loss=0.011000310187228024
Online_Training [612/700]: mean_loss=0.1433436181396246
Online_Training [613/700]: mean_loss=0.061274920124560595
Online_Training [614/700]: mean_loss=0.01314030063804239
Online_Training [615/700]: mean_loss=0.00897619704483077
Online_Training [616/700]: mean_loss=0.024452162673696876
Online_Training [617/700]: mean_loss=0.005247082648565993
Online_Training [618/700]: mean_loss=0.02135559218004346
Online_Training [619/700]: mean_loss=0.013354219612665474
Online_Training [620/700]: mean_loss=0.09194825682789087
Online_Training [621/700]: mean_loss=0.007948282174766064
Online_Training [622/700]: mean_loss=0.07110628113150597
Online_Training [623/700]: mean_loss=0.05344259878620505
Online_Training [624/700]: mean_loss=0.015057960175909102
Online_Training [625/700]: mean_loss=0.012233634712174535
Online_Training [626/700]: mean_loss=0.03376713744364679
Online_Training [627/700]: mean_loss=0.013541502063162625
Online_Training [628/700]: mean_loss=0.0086799570126459
Online_Training [629/700]: mean_loss=0.040933909360319376
Online_Training [630/700]: mean_loss=0.043763190507888794
Online_Training [631/700]: mean_loss=0.016016436624340713
Online_Training [632/700]: mean_loss=0.026481683598831296
Online_Training [633/700]: mean_loss=0.01127850718330592
Online_Training [634/700]: mean_loss=0.0223778992658481
Online_Training [635/700]: mean_loss=0.016555620124563575
Online_Training [636/700]: mean_loss=0.014217250572983176
Online_Training [637/700]: mean_loss=0.020851325942203403
Online_Training [638/700]: mean_loss=0.03127243532799184
Online_Training [639/700]: mean_loss=0.02039351500570774
Online_Training [640/700]: mean_loss=0.008325971430167556
Online_Training [641/700]: mean_loss=0.008410234237089753
Online_Training [642/700]: mean_loss=0.017118782037869096
Online_Training [643/700]: mean_loss=0.017856696154922247
Online_Training [644/700]: mean_loss=0.04274805635213852
Online_Training [645/700]: mean_loss=0.013654452981427312
Online_Training [646/700]: mean_loss=0.0482733054086566
Online_Training [647/700]: mean_loss=0.008718265569768846
Online_Training [648/700]: mean_loss=0.014919494860805571
Online_Training [649/700]: mean_loss=0.013000417384319007
Online_Training [650/700]: mean_loss=0.014836667221970856
Online_Training [651/700]: mean_loss=0.009560684557072818
Online_Training [652/700]: mean_loss=0.005201385414693505
Online_Training [653/700]: mean_loss=0.07848719879984856
Online_Training [654/700]: mean_loss=0.0144201151560992
Online_Training [655/700]: mean_loss=0.017065280582755804
Online_Training [656/700]: mean_loss=0.020440964261069894
Online_Training [657/700]: mean_loss=0.007896453666035086
Online_Training [658/700]: mean_loss=0.02445707470178604
Online_Training [659/700]: mean_loss=0.020058355992659926
Online_Training [660/700]: mean_loss=0.015606050728820264
Online_Training [661/700]: mean_loss=0.050215688068419695
Online_Training [662/700]: mean_loss=0.03788250079378486
Online_Training [663/700]: mean_loss=0.02023203019052744
Online_Training [664/700]: mean_loss=0.01011332037160173
Online_Training [665/700]: mean_loss=0.032131393905729055
Online_Training [666/700]: mean_loss=0.007979743648320436
Online_Training [667/700]: mean_loss=0.007848191307857633
Online_Training [668/700]: mean_loss=0.013229578034952283
Online_Training [669/700]: mean_loss=0.008914075791835785
Online_Training [670/700]: mean_loss=0.013941765879280865
Online_Training [671/700]: mean_loss=0.010897529195062816
Online_Training [672/700]: mean_loss=0.014913097373209894
Online_Training [673/700]: mean_loss=0.011536928126588464
Online_Training [674/700]: mean_loss=0.014756569871678948
Online_Training [675/700]: mean_loss=0.013715287204831839
Online_Training [676/700]: mean_loss=0.028426081407815218
Online_Training [677/700]: mean_loss=0.048389696050435305
Online_Training [678/700]: mean_loss=0.020785824628546834
Online_Training [679/700]: mean_loss=0.013262197491712868
Online_Training [680/700]: mean_loss=0.031243809964507818
Online_Training [681/700]: mean_loss=0.02184412139467895
Online_Training [682/700]: mean_loss=0.012754447059705853
Online_Training [683/700]: mean_loss=0.006685819418635219
Online_Training [684/700]: mean_loss=0.020537712262012064
Online_Training [685/700]: mean_loss=0.033233542228117585
Online_Training [686/700]: mean_loss=0.012688873684965074
Online_Training [687/700]: mean_loss=0.011785308248363435
Online_Training [688/700]: mean_loss=0.04585207626223564
Online_Training [689/700]: mean_loss=0.014779888791963458
Online_Training [690/700]: mean_loss=0.009559539961628616
Online_Training [691/700]: mean_loss=0.011062099947594106
Online_Training [692/700]: mean_loss=0.025094748241826892
Online_Training [693/700]: mean_loss=0.012782611302100122
Online_Training [694/700]: mean_loss=0.029934390215203166
Online_Training [695/700]: mean_loss=0.01218857429921627
Online_Training [696/700]: mean_loss=0.029676560778170824
Online_Training [697/700]: mean_loss=0.007081828138325363
Online_Training [698/700]: mean_loss=0.006909533927682787
Online_Training [699/700]: mean_loss=0.11049178894609213
Online_Training [700/700]: mean_loss=0.010254369350150228
Q_Learning [1/300]: mean_loss=0.2680307626724243
Q_Learning [2/300]: mean_loss=0.25465891882777214
Q_Learning [3/300]: mean_loss=0.2422297392040491
Q_Learning [4/300]: mean_loss=0.10754455719143152
Q_Learning [5/300]: mean_loss=0.25868625566363335
Q_Learning [6/300]: mean_loss=0.16085092723369598
Q_Learning [7/300]: mean_loss=0.16076222620904446
Q_Learning [8/300]: mean_loss=0.07296316791325808
Q_Learning [9/300]: mean_loss=0.25229062139987946
Q_Learning [10/300]: mean_loss=0.14542743377387524
Q_Learning [11/300]: mean_loss=0.122611740604043
Q_Learning [12/300]: mean_loss=0.10505146440118551
Q_Learning [13/300]: mean_loss=0.0987406987696886
Q_Learning [14/300]: mean_loss=0.07333918754011393
Q_Learning [15/300]: mean_loss=0.0906401053071022
Q_Learning [16/300]: mean_loss=0.11639816127717495
Q_Learning [17/300]: mean_loss=0.11274830345064402
Q_Learning [18/300]: mean_loss=0.058020723052322865
Q_Learning [19/300]: mean_loss=0.03560175094753504
Q_Learning [20/300]: mean_loss=0.12865754682570696
Q_Learning [21/300]: mean_loss=0.12805750593543053
Q_Learning [22/300]: mean_loss=0.02144345035776496
Q_Learning [23/300]: mean_loss=0.02138084569014609
Q_Learning [24/300]: mean_loss=0.0629290184006095
Q_Learning [25/300]: mean_loss=0.04436864657327533
Q_Learning [26/300]: mean_loss=0.04681672202423215
Q_Learning [27/300]: mean_loss=0.08624537475407124
Q_Learning [28/300]: mean_loss=0.03522784914821386
Q_Learning [29/300]: mean_loss=0.049261524342000484
Q_Learning [30/300]: mean_loss=0.0310643941629678
Q_Learning [31/300]: mean_loss=0.02447384991683066
Q_Learning [32/300]: mean_loss=0.04204034246504307
Q_Learning [33/300]: mean_loss=0.018036322318948805
Q_Learning [34/300]: mean_loss=0.1125931041315198
Q_Learning [35/300]: mean_loss=0.0472306776791811
Q_Learning [36/300]: mean_loss=0.08147466648370028
Q_Learning [37/300]: mean_loss=0.0629102811217308
Q_Learning [38/300]: mean_loss=0.04150622338056564
Q_Learning [39/300]: mean_loss=0.09247614536434412
Q_Learning [40/300]: mean_loss=0.03010694496333599
Q_Learning [41/300]: mean_loss=0.02245845808647573
Q_Learning [42/300]: mean_loss=0.06089143827557564
Q_Learning [43/300]: mean_loss=0.09734613541513681
Q_Learning [44/300]: mean_loss=0.10262214299291372
Q_Learning [45/300]: mean_loss=0.05890219332650304
Q_Learning [46/300]: mean_loss=0.03025724529288709
Q_Learning [47/300]: mean_loss=0.05866739014163613
Q_Learning [48/300]: mean_loss=0.06985591445118189
Q_Learning [49/300]: mean_loss=0.047547530848532915
Q_Learning [50/300]: mean_loss=0.05052348645403981
Q_Learning [51/300]: mean_loss=0.02083408343605697
Q_Learning [52/300]: mean_loss=0.09235191438347101
Q_Learning [53/300]: mean_loss=0.022717774379998446
Q_Learning [54/300]: mean_loss=0.043837862089276314
Q_Learning [55/300]: mean_loss=0.024006936233490705
Q_Learning [56/300]: mean_loss=0.0371803087182343
Q_Learning [57/300]: mean_loss=0.07525462098419666
Q_Learning [58/300]: mean_loss=0.12061112374067307
Q_Learning [59/300]: mean_loss=0.08427925268188119
Q_Learning [60/300]: mean_loss=0.04343182686716318
Q_Learning [61/300]: mean_loss=0.022712470032274723
Q_Learning [62/300]: mean_loss=0.08002462005242705
Q_Learning [63/300]: mean_loss=0.06018701987341046
Q_Learning [64/300]: mean_loss=0.011709181882906705
Q_Learning [65/300]: mean_loss=0.06209834851324558
Q_Learning [66/300]: mean_loss=0.053116822615265846
Q_Learning [67/300]: mean_loss=0.06604903005063534
Q_Learning [68/300]: mean_loss=0.020695088431239128
Q_Learning [69/300]: mean_loss=0.03139358037151396
Q_Learning [70/300]: mean_loss=0.03743955725803971
Q_Learning [71/300]: mean_loss=0.07260258123278618
Q_Learning [72/300]: mean_loss=0.07675706781446934
Q_Learning [73/300]: mean_loss=0.037015979178249836
Q_Learning [74/300]: mean_loss=0.040695080533623695
Q_Learning [75/300]: mean_loss=0.02302637929096818
Q_Learning [76/300]: mean_loss=0.01658242044504732
Q_Learning [77/300]: mean_loss=0.03298658458516002
Q_Learning [78/300]: mean_loss=0.02524955221451819
Q_Learning [79/300]: mean_loss=0.029926338931545615
Q_Learning [80/300]: mean_loss=0.027562128147110343
Q_Learning [81/300]: mean_loss=0.00783394678728655
Q_Learning [82/300]: mean_loss=0.02365341386757791
Q_Learning [83/300]: mean_loss=0.03980579413473606
Q_Learning [84/300]: mean_loss=0.024390411097556353
Q_Learning [85/300]: mean_loss=0.020437124418094754
Q_Learning [86/300]: mean_loss=0.03144488367252052
Q_Learning [87/300]: mean_loss=0.008564772200770676
Q_Learning [88/300]: mean_loss=0.03252142807468772
Q_Learning [89/300]: mean_loss=0.03606135491281748
Q_Learning [90/300]: mean_loss=0.016008557053282857
Q_Learning [91/300]: mean_loss=0.035267509054392576
Q_Learning [92/300]: mean_loss=0.04630487132817507
Q_Learning [93/300]: mean_loss=0.021523204632103443
Q_Learning [94/300]: mean_loss=0.041857856791466475
Q_Learning [95/300]: mean_loss=0.036172982305288315
Q_Learning [96/300]: mean_loss=0.017022684682160616
Q_Learning [97/300]: mean_loss=0.04680051375180483
Q_Learning [98/300]: mean_loss=0.03168773744255304
Q_Learning [99/300]: mean_loss=0.01713908731471747
Q_Learning [100/300]: mean_loss=0.05961667047813535
Q_Learning [101/300]: mean_loss=0.013807420036755502
Q_Learning [102/300]: mean_loss=0.047700274270027876
Q_Learning [103/300]: mean_loss=0.03245962015353143
Q_Learning [104/300]: mean_loss=0.05761469481512904
Q_Learning [105/300]: mean_loss=0.02433509170077741
Q_Learning [106/300]: mean_loss=0.007214054581709206
Q_Learning [107/300]: mean_loss=0.01567429944407195
Q_Learning [108/300]: mean_loss=0.021074541611596942
Q_Learning [109/300]: mean_loss=0.02494891150854528
Q_Learning [110/300]: mean_loss=0.02774383220821619
Q_Learning [111/300]: mean_loss=0.020284370984882116
Q_Learning [112/300]: mean_loss=0.07055891212075949
Q_Learning [113/300]: mean_loss=0.013373888796195388
Q_Learning [114/300]: mean_loss=0.03208415117114782
Q_Learning [115/300]: mean_loss=0.037047065794467926
Q_Learning [116/300]: mean_loss=0.023747905855998397
Q_Learning [117/300]: mean_loss=0.05329431314021349
Q_Learning [118/300]: mean_loss=0.03556748665869236
Q_Learning [119/300]: mean_loss=0.09560940228402615
Q_Learning [120/300]: mean_loss=0.06229535769671202
Q_Learning [121/300]: mean_loss=0.0691006425768137
Q_Learning [122/300]: mean_loss=0.058441026136279106
Q_Learning [123/300]: mean_loss=0.046516754664480686
Q_Learning [124/300]: mean_loss=0.011764157214201987
Q_Learning [125/300]: mean_loss=0.06039560725912452
Q_Learning [126/300]: mean_loss=0.023976342985406518
Q_Learning [127/300]: mean_loss=0.0628259857185185
Q_Learning [128/300]: mean_loss=0.018575280904769897
Q_Learning [129/300]: mean_loss=0.013606470543891191
Q_Learning [130/300]: mean_loss=0.01906874030828476
Q_Learning [131/300]: mean_loss=0.01868572412058711
Q_Learning [132/300]: mean_loss=0.02270642784424126
Q_Learning [133/300]: mean_loss=0.02903491328470409
Q_Learning [134/300]: mean_loss=0.008186855993699282
Q_Learning [135/300]: mean_loss=0.06741630751639605
Q_Learning [136/300]: mean_loss=0.019213117426261306
Q_Learning [137/300]: mean_loss=0.02456865762360394
Q_Learning [138/300]: mean_loss=0.014062870643101633
Q_Learning [139/300]: mean_loss=0.02093987329863012
Q_Learning [140/300]: mean_loss=0.00810366333462298
Q_Learning [141/300]: mean_loss=0.021843241062015295
Q_Learning [142/300]: mean_loss=0.010896473773755133
Q_Learning [143/300]: mean_loss=0.022314721019938588
Q_Learning [144/300]: mean_loss=0.008419898513238877
Q_Learning [145/300]: mean_loss=0.05376276466995478
Q_Learning [146/300]: mean_loss=0.02019390440545976
Q_Learning [147/300]: mean_loss=0.01670331065542996
Q_Learning [148/300]: mean_loss=0.04714498948305845
Q_Learning [149/300]: mean_loss=0.04966562241315842
Q_Learning [150/300]: mean_loss=0.08495844155550003
Q_Learning [151/300]: mean_loss=0.029611733742058277
Q_Learning [152/300]: mean_loss=0.01823128736577928
Q_Learning [153/300]: mean_loss=0.02233169972896576
Q_Learning [154/300]: mean_loss=0.027931658318266273
Q_Learning [155/300]: mean_loss=0.013570254435762763
Q_Learning [156/300]: mean_loss=0.02522838651202619
Q_Learning [157/300]: mean_loss=0.16451266966760159
Q_Learning [158/300]: mean_loss=0.010798033501487225
Q_Learning [159/300]: mean_loss=0.0216672969982028
Q_Learning [160/300]: mean_loss=0.03855819581076503
Q_Learning [161/300]: mean_loss=0.024409585632383823
Q_Learning [162/300]: mean_loss=0.01619198708795011
Q_Learning [163/300]: mean_loss=0.028784779831767082
Q_Learning [164/300]: mean_loss=0.013821059605106711
Q_Learning [165/300]: mean_loss=0.014429793343879282
Q_Learning [166/300]: mean_loss=0.022847147192806005
Q_Learning [167/300]: mean_loss=0.030703387456014752
Q_Learning [168/300]: mean_loss=0.04817593237385154
Q_Learning [169/300]: mean_loss=0.045583979692310095
Q_Learning [170/300]: mean_loss=0.17369131743907928
Q_Learning [171/300]: mean_loss=0.016032155486755073
Q_Learning [172/300]: mean_loss=0.024721197551116347
Q_Learning [173/300]: mean_loss=0.03957257233560085
Q_Learning [174/300]: mean_loss=0.019699543016031384
Q_Learning [175/300]: mean_loss=0.01385657419450581
Q_Learning [176/300]: mean_loss=0.00821346661541611
Q_Learning [177/300]: mean_loss=0.020871229702606797
Q_Learning [178/300]: mean_loss=0.020008855499327183
Q_Learning [179/300]: mean_loss=0.0242280054371804
Q_Learning [180/300]: mean_loss=0.028235696954652667
Q_Learning [181/300]: mean_loss=0.028098956448957324
Q_Learning [182/300]: mean_loss=0.0118573943618685
Q_Learning [183/300]: mean_loss=0.015533503028564155
Q_Learning [184/300]: mean_loss=0.010147167602553964
Q_Learning [185/300]: mean_loss=0.044108144007623196
Q_Learning [186/300]: mean_loss=0.037744543282315135
Q_Learning [187/300]: mean_loss=0.015259299194440246
Q_Learning [188/300]: mean_loss=0.02676120586693287
Q_Learning [189/300]: mean_loss=0.0454289298504591
Q_Learning [190/300]: mean_loss=0.016683471389114857
Q_Learning [191/300]: mean_loss=0.15967351756989956
Q_Learning [192/300]: mean_loss=0.02377952612005174
Q_Learning [193/300]: mean_loss=0.024261708138510585
Q_Learning [194/300]: mean_loss=0.017313749063760042
Q_Learning [195/300]: mean_loss=0.022402031114324927
Q_Learning [196/300]: mean_loss=0.010662190965376794
Q_Learning [197/300]: mean_loss=0.03570818714797497
Q_Learning [198/300]: mean_loss=0.016670207609422505
Q_Learning [199/300]: mean_loss=0.09713387675583363
Q_Learning [200/300]: mean_loss=0.022268512519076467
Q_Learning [201/300]: mean_loss=0.022894622292369604
Q_Learning [202/300]: mean_loss=0.02621357887983322
Q_Learning [203/300]: mean_loss=0.004370045528048649
Q_Learning [204/300]: mean_loss=0.017361640348099172
Q_Learning [205/300]: mean_loss=0.06299826595932245
Q_Learning [206/300]: mean_loss=0.009996668784879148
Q_Learning [207/300]: mean_loss=0.04473619535565376
Q_Learning [208/300]: mean_loss=0.03509086603298783
Q_Learning [209/300]: mean_loss=0.05786542221903801
Q_Learning [210/300]: mean_loss=0.025521254865452647
Q_Learning [211/300]: mean_loss=0.009552070638164878
Q_Learning [212/300]: mean_loss=0.1148031186312437
Q_Learning [213/300]: mean_loss=0.07755832467228174
Q_Learning [214/300]: mean_loss=0.02996809221804142
Q_Learning [215/300]: mean_loss=0.019281333778053522
Q_Learning [216/300]: mean_loss=0.047402418218553066
Q_Learning [217/300]: mean_loss=0.015835230937227607
Q_Learning [218/300]: mean_loss=0.007493797980714589
Q_Learning [219/300]: mean_loss=0.04639095766469836
Q_Learning [220/300]: mean_loss=0.010285487165674567
Q_Learning [221/300]: mean_loss=0.029501041863113642
Q_Learning [222/300]: mean_loss=0.01709021464921534
Q_Learning [223/300]: mean_loss=0.027594563318416476
Q_Learning [224/300]: mean_loss=0.008367093047127128
Q_Learning [225/300]: mean_loss=0.019676292082294822
Q_Learning [226/300]: mean_loss=0.016696261591278017
Q_Learning [227/300]: mean_loss=0.00883939175400883
Q_Learning [228/300]: mean_loss=0.03821833012625575
Q_Learning [229/300]: mean_loss=0.04269241355359554
Q_Learning [230/300]: mean_loss=0.013153966865502298
Q_Learning [231/300]: mean_loss=0.030107308644801378
Q_Learning [232/300]: mean_loss=0.013315174030140042
Q_Learning [233/300]: mean_loss=0.02355118840932846
Q_Learning [234/300]: mean_loss=0.020569917804095894
Q_Learning [235/300]: mean_loss=0.06869309954345226
Q_Learning [236/300]: mean_loss=0.047020452097058296
Q_Learning [237/300]: mean_loss=0.018578761024400592
Q_Learning [238/300]: mean_loss=0.0921240970492363
Q_Learning [239/300]: mean_loss=0.2783725205808878
Q_Learning [240/300]: mean_loss=0.06907670106738806
Q_Learning [241/300]: mean_loss=0.039480842649936676
Q_Learning [242/300]: mean_loss=0.0372870652936399
Q_Learning [243/300]: mean_loss=0.03300666343420744
Q_Learning [244/300]: mean_loss=0.04050882672891021
Q_Learning [245/300]: mean_loss=0.05038610706105828
Q_Learning [246/300]: mean_loss=0.02510850504040718
Q_Learning [247/300]: mean_loss=0.02070062083657831
Q_Learning [248/300]: mean_loss=0.05411567585542798
Q_Learning [249/300]: mean_loss=0.05287210503593087
Q_Learning [250/300]: mean_loss=0.01410149596631527
Q_Learning [251/300]: mean_loss=0.019449007464572787
Q_Learning [252/300]: mean_loss=0.014104808564297855
Q_Learning [253/300]: mean_loss=0.0079431893536821
Q_Learning [254/300]: mean_loss=0.020097604021430016
Q_Learning [255/300]: mean_loss=0.04552658135071397
Q_Learning [256/300]: mean_loss=0.0199826747411862
Q_Learning [257/300]: mean_loss=0.02545223035849631
Q_Learning [258/300]: mean_loss=0.010448934743180871
Q_Learning [259/300]: mean_loss=0.01063920243177563
Q_Learning [260/300]: mean_loss=0.016976890619844198
Q_Learning [261/300]: mean_loss=0.02388317440636456
Q_Learning [262/300]: mean_loss=0.026585086714476347
Q_Learning [263/300]: mean_loss=0.016365386196412146
Q_Learning [264/300]: mean_loss=0.044007503893226385
Q_Learning [265/300]: mean_loss=0.01594249054323882
Q_Learning [266/300]: mean_loss=0.01011755398940295
Q_Learning [267/300]: mean_loss=0.014292052364908159
Q_Learning [268/300]: mean_loss=0.007246025023050606
Q_Learning [269/300]: mean_loss=0.03005503467284143
Q_Learning [270/300]: mean_loss=0.015004590386524796
Q_Learning [271/300]: mean_loss=0.017867897870019078
Q_Learning [272/300]: mean_loss=0.007541793049313128
Q_Learning [273/300]: mean_loss=0.011464202078059316
Q_Learning [274/300]: mean_loss=0.021699523786082864
Q_Learning [275/300]: mean_loss=0.009969133185222745
Q_Learning [276/300]: mean_loss=0.013643345097079873
Q_Learning [277/300]: mean_loss=0.07526080403476954
Q_Learning [278/300]: mean_loss=0.021576937288045883
Q_Learning [279/300]: mean_loss=0.02363621979020536
Q_Learning [280/300]: mean_loss=0.033760696183890104
Q_Learning [281/300]: mean_loss=0.03387511218897998
Q_Learning [282/300]: mean_loss=0.026965411612764
Q_Learning [283/300]: mean_loss=0.019886894850060344
Q_Learning [284/300]: mean_loss=0.02343784272670746
Q_Learning [285/300]: mean_loss=0.026547996094450355
Q_Learning [286/300]: mean_loss=0.006463760044425726
Q_Learning [287/300]: mean_loss=0.013416723813861609
Q_Learning [288/300]: mean_loss=0.014566495781764388
Q_Learning [289/300]: mean_loss=0.03156088478863239
Q_Learning [290/300]: mean_loss=0.00828864041250199
Q_Learning [291/300]: mean_loss=0.014663187903352082
Q_Learning [292/300]: mean_loss=0.006517152534797788
Q_Learning [293/300]: mean_loss=0.0188731097150594
Q_Learning [294/300]: mean_loss=0.026819435879588127
Q_Learning [295/300]: mean_loss=0.03518998599611223
Q_Learning [296/300]: mean_loss=0.028888732194900513
Q_Learning [297/300]: mean_loss=0.017272471450269222
Q_Learning [298/300]: mean_loss=0.029552266001701355
Q_Learning [299/300]: mean_loss=0.02878534561023116
Q_Learning [300/300]: mean_loss=0.04603148391470313
Number of Samples after Autoencoder testing: 300
First Spike after testing: [2.6888628  0.09077489]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 2, 1, 2, 2, 2, 0, 3, 3, 0, 2, 2, 2, 0, 0, 1, 2, 1, 2, 3, 0, 0, 1, 0, 2, 4, 1, 0, 0, 1, 1, 2, 4, 2, 2, 4, 3, 2, 0, 1, 1, 2, 4, 4, 2, 1, 2, 1, 1, 2, 4, 2, 2, 1, 0, 1, 4, 0, 4, 1, 1, 1, 2, 0, 1, 3, 0, 1, 0, 4, 1, 1, 1, 1, 3, 4, 3, 2, 2, 0, 3, 2, 4, 2, 1, 1, 1, 3, 0, 3, 3, 1, 1, 4, 1, 4, 4, 1, 1, 1, 1, 4, 1, 1, 4, 1, 2, 0, 1, 1, 1, 0, 4, 0, 2, 1, 4, 2, 1, 2, 2, 3, 4, 3, 3, 1, 3, 1, 1, 4, 1, 2, 0, 1, 2, 0, 3, 2, 1, 1, 4, 1, 4, 0, 1, 3, 1, 1, 3, 2, 0, 2, 2, 2, 1, 1, 0, 0, 2, 0, 4, 3, 4, 2, 0, 2, 0, 2, 1, 0, 1, 1, 0, 3, 2, 1, 2, 0, 2, 1, 2, 4, 2, 4, 2, 1, 3, 2, 4, 2, 3, 3, 2, 4, 2, 1, 1, 2, 0, 4, 1, 3, 3, 3, 2, 1, 4, 4, 4, 2, 4, 0, 1, 2, 1, 2, 4, 0, 1, 2, 1, 0, 2, 2, 4, 1, 2, 2, 5, 6, 2, 1, 2, 3, 2, 0, 1, 0, 0, 0, 4, 1, 0, 0, 0, 1, 2, 2, 1, 3, 0, 4, 2, 2, 1, 2, 3, 2, 2, 1, 2, 2, 4, 0, 2, 3, 6, 0, 0, 2, 1, 1, 4, 2, 2, 4, 4, 2, 1, 1, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1]
Centroids: [[-1.6401274, 1.6701819], [-0.5247694, 1.275608], [2.0580938, 0.2883436]]
Centroids: [[1.7418292, -0.10073636], [-1.5474827, 1.3184279], [-0.30524465, 1.3193274], [-1.844727, 2.2946985], [2.3812678, 0.643712], [-2.253323, 4.5503497], [4.6188793, 2.4754117]]
Contingency Matrix: 
[[ 0 69  6 27  0  1  0]
 [ 0 20 77  3  0  0  0]
 [53  0  1  0 41  0  2]]
[[0, 69, 6, 27, 0, 1, 0], [0, 20, 77, 3, 0, 0, 0], [53, 0, 1, 0, 41, 0, 2]]
[[0, 69, 6, 27, 0, 1, 0], [0, 20, 77, 3, 0, 0, 0], [53, 0, 1, 0, 41, 0, 2]]
[0, 1, 2, 3, 4, 5, 6]
[[0, 69, -1, 27, 0, 1, 0], [-1, -1, -1, -1, -1, -1, -1], [53, 0, -1, 0, 41, 0, 2]]
[[-1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1], [53, -1, -1, 0, 41, 0, 2]]
[[-1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 2, 0: 1, 2: 0}
New Contingency Matrix: 
[[69  6  0 27  0  1  0]
 [20 77  0  3  0  0  0]
 [ 0  1 53  0 41  0  2]]
New Clustered Label Sequence: [1, 2, 0, 3, 4, 5, 6]
Diagonal_Elements: [69, 77, 53], Sum: 199
All_Elements: [69, 6, 0, 27, 0, 1, 0, 20, 77, 0, 3, 0, 0, 0, 0, 1, 53, 0, 41, 0, 2], Sum: 300
Accuracy: 0.6633333333333333
