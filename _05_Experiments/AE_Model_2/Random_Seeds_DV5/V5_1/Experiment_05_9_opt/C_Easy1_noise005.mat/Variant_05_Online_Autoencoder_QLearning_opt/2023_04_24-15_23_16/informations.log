Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_9_opt
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_9_opt/C_Easy1_noise005.mat/Variant_05_Online_Autoencoder_QLearning_opt/2023_04_24-15_23_16
Punishment_Coefficient: 1.1
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002479B520E48>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.1565920189023018
Online_Training [2/700]: mean_loss=0.0786384092643857
Online_Training [3/700]: mean_loss=0.331835076212883
Online_Training [4/700]: mean_loss=0.3005834147334099
Online_Training [5/700]: mean_loss=0.3275088667869568
Online_Training [6/700]: mean_loss=0.14376506954431534
Online_Training [7/700]: mean_loss=0.06920340098440647
Online_Training [8/700]: mean_loss=0.29482392594218254
Online_Training [9/700]: mean_loss=0.06554545555263758
Online_Training [10/700]: mean_loss=0.05929398210719228
Online_Training [11/700]: mean_loss=0.04759691609069705
Online_Training [12/700]: mean_loss=0.04352825274690986
Online_Training [13/700]: mean_loss=0.02936302637681365
Online_Training [14/700]: mean_loss=0.17626593448221684
Online_Training [15/700]: mean_loss=0.21913000382483006
Online_Training [16/700]: mean_loss=0.15677768550813198
Online_Training [17/700]: mean_loss=0.17351542972028255
Online_Training [18/700]: mean_loss=0.18915496952831745
Online_Training [19/700]: mean_loss=0.1340494267642498
Online_Training [20/700]: mean_loss=0.12446073349565268
Online_Training [21/700]: mean_loss=0.18766183033585548
Online_Training [22/700]: mean_loss=0.1279498226940632
Online_Training [23/700]: mean_loss=0.12486302386969328
Online_Training [24/700]: mean_loss=0.06275429110974073
Online_Training [25/700]: mean_loss=0.08350830711424351
Online_Training [26/700]: mean_loss=0.0644748667255044
Online_Training [27/700]: mean_loss=0.05167661188170314
Online_Training [28/700]: mean_loss=0.04213088424876332
Online_Training [29/700]: mean_loss=0.08780997572466731
Online_Training [30/700]: mean_loss=0.040605037938803434
Online_Training [31/700]: mean_loss=0.1044324403628707
Online_Training [32/700]: mean_loss=0.02604496362619102
Online_Training [33/700]: mean_loss=0.01802590163424611
Online_Training [34/700]: mean_loss=0.0849336152896285
Online_Training [35/700]: mean_loss=0.011115288827568293
Online_Training [36/700]: mean_loss=0.1235961141064763
Online_Training [37/700]: mean_loss=0.0766229024156928
Online_Training [38/700]: mean_loss=0.06784604117274284
Online_Training [39/700]: mean_loss=0.0513423359952867
Online_Training [40/700]: mean_loss=0.03777085384353995
Online_Training [41/700]: mean_loss=0.02741804043762386
Online_Training [42/700]: mean_loss=0.04354847292415798
Online_Training [43/700]: mean_loss=0.034870177041739225
Online_Training [44/700]: mean_loss=0.015735067892819643
Online_Training [45/700]: mean_loss=0.04384447494521737
Online_Training [46/700]: mean_loss=0.022984380600973964
Online_Training [47/700]: mean_loss=0.10702725499868393
Online_Training [48/700]: mean_loss=0.09868839383125305
Online_Training [49/700]: mean_loss=0.019264501053839922
Online_Training [50/700]: mean_loss=0.024285286432132125
Online_Training [51/700]: mean_loss=0.014828101149760187
Online_Training [52/700]: mean_loss=0.005806473200209439
Online_Training [53/700]: mean_loss=0.05900705372914672
Online_Training [54/700]: mean_loss=0.17463586293160915
Online_Training [55/700]: mean_loss=0.039015812799334526
Online_Training [56/700]: mean_loss=0.0384607738815248
Online_Training [57/700]: mean_loss=0.026771653210744262
Online_Training [58/700]: mean_loss=0.013116645743139088
Online_Training [59/700]: mean_loss=0.11445382330566645
Online_Training [60/700]: mean_loss=0.019338682759553194
Online_Training [61/700]: mean_loss=0.01747745950706303
Online_Training [62/700]: mean_loss=0.014374319231137633
Online_Training [63/700]: mean_loss=0.008007411728613079
Online_Training [64/700]: mean_loss=0.003768040071008727
Online_Training [65/700]: mean_loss=0.012310225400142372
Online_Training [66/700]: mean_loss=0.005544878949876875
Online_Training [67/700]: mean_loss=0.0034609506838023663
Online_Training [68/700]: mean_loss=0.10916028544306755
Online_Training [69/700]: mean_loss=0.006814391177613288
Online_Training [70/700]: mean_loss=0.014450220623984933
Online_Training [71/700]: mean_loss=0.0038810917758382857
Online_Training [72/700]: mean_loss=0.0077118911431171
Online_Training [73/700]: mean_loss=0.008561873284634203
Online_Training [74/700]: mean_loss=0.0038549374148715287
Online_Training [75/700]: mean_loss=0.005798123369459063
Online_Training [76/700]: mean_loss=0.0034373333328403533
Online_Training [77/700]: mean_loss=0.0015690242289565504
Online_Training [78/700]: mean_loss=0.00665946863591671
Online_Training [79/700]: mean_loss=0.01951400050893426
Online_Training [80/700]: mean_loss=0.009719445020891726
Online_Training [81/700]: mean_loss=0.004438586940523237
Online_Training [82/700]: mean_loss=0.008990337490104139
Online_Training [83/700]: mean_loss=0.007691573933698237
Online_Training [84/700]: mean_loss=0.003791689465288073
Online_Training [85/700]: mean_loss=0.005069056001957506
Online_Training [86/700]: mean_loss=0.00990149297285825
Online_Training [87/700]: mean_loss=0.010685229382943362
Online_Training [88/700]: mean_loss=0.012222736258991063
Online_Training [89/700]: mean_loss=0.0033425627916585654
Online_Training [90/700]: mean_loss=0.006849478697404265
Online_Training [91/700]: mean_loss=0.0066949171596206725
Online_Training [92/700]: mean_loss=0.019280055072158575
Online_Training [93/700]: mean_loss=0.013397933566011488
Online_Training [94/700]: mean_loss=0.0054371056030504405
Online_Training [95/700]: mean_loss=0.004120721365325153
Online_Training [96/700]: mean_loss=0.006381196260917932
Online_Training [97/700]: mean_loss=0.007234310905914754
Online_Training [98/700]: mean_loss=0.003942094539524987
Online_Training [99/700]: mean_loss=0.00660466036060825
Online_Training [100/700]: mean_loss=0.0009967707592295483
Online_Training [101/700]: mean_loss=0.003269526467192918
Online_Training [102/700]: mean_loss=0.003369329875567928
Online_Training [103/700]: mean_loss=0.006640044797677547
Online_Training [104/700]: mean_loss=0.0032581526174908504
Online_Training [105/700]: mean_loss=0.02335775620304048
Online_Training [106/700]: mean_loss=0.020357740111649036
Online_Training [107/700]: mean_loss=0.0034224029950564727
Online_Training [108/700]: mean_loss=0.010888328426517546
Online_Training [109/700]: mean_loss=0.005025565798860043
Online_Training [110/700]: mean_loss=0.005059720220742747
Online_Training [111/700]: mean_loss=0.0038583105779252946
Online_Training [112/700]: mean_loss=0.004234812018694356
Online_Training [113/700]: mean_loss=0.00695105193881318
Online_Training [114/700]: mean_loss=0.0037958816392347217
Online_Training [115/700]: mean_loss=0.018238068441860378
Online_Training [116/700]: mean_loss=0.002967039807117544
Online_Training [117/700]: mean_loss=0.0037567772960755974
Online_Training [118/700]: mean_loss=0.0031578726484440267
Online_Training [119/700]: mean_loss=0.002278912957990542
Online_Training [120/700]: mean_loss=0.004552025347948074
Online_Training [121/700]: mean_loss=0.00419301787042059
Online_Training [122/700]: mean_loss=0.008095124911051244
Online_Training [123/700]: mean_loss=0.0005076788474980276
Online_Training [124/700]: mean_loss=0.005062399053713307
Online_Training [125/700]: mean_loss=0.0015817209496162832
Online_Training [126/700]: mean_loss=0.0017268973751924932
Online_Training [127/700]: mean_loss=0.005261285696178675
Online_Training [128/700]: mean_loss=0.008842607960104942
Online_Training [129/700]: mean_loss=0.003453991375863552
Online_Training [130/700]: mean_loss=0.004293295205570757
Online_Training [131/700]: mean_loss=0.0033893353247549385
Online_Training [132/700]: mean_loss=0.004107602682779543
Online_Training [133/700]: mean_loss=0.004162228957284242
Online_Training [134/700]: mean_loss=0.008293346560094506
Online_Training [135/700]: mean_loss=0.004267808981239796
Online_Training [136/700]: mean_loss=0.0022323418670566753
Online_Training [137/700]: mean_loss=0.004778885806445032
Online_Training [138/700]: mean_loss=0.005803054329589941
Online_Training [139/700]: mean_loss=0.004546971045783721
Online_Training [140/700]: mean_loss=0.0021741325326729566
Online_Training [141/700]: mean_loss=0.0027900476998183876
Online_Training [142/700]: mean_loss=0.006095307704526931
Online_Training [143/700]: mean_loss=0.07866374542936683
Online_Training [144/700]: mean_loss=0.030174885410815477
Online_Training [145/700]: mean_loss=0.06119981547817588
Online_Training [146/700]: mean_loss=0.14983987621963024
Online_Training [147/700]: mean_loss=0.014379100175574422
Online_Training [148/700]: mean_loss=0.008052606659475714
Online_Training [149/700]: mean_loss=0.007068289094604552
Online_Training [150/700]: mean_loss=0.09627648163586855
Online_Training [151/700]: mean_loss=0.26681130938231945
Online_Training [152/700]: mean_loss=0.009403751406352967
Online_Training [153/700]: mean_loss=0.010766609804704785
Online_Training [154/700]: mean_loss=0.007373235421255231
Online_Training [155/700]: mean_loss=0.03401956823654473
Online_Training [156/700]: mean_loss=0.014925258117727935
Online_Training [157/700]: mean_loss=0.007436769490595907
Online_Training [158/700]: mean_loss=0.022868364583700895
Online_Training [159/700]: mean_loss=0.010055506165372208
Online_Training [160/700]: mean_loss=0.016950428718701005
Online_Training [161/700]: mean_loss=0.01122443680651486
Online_Training [162/700]: mean_loss=0.052948211785405874
Online_Training [163/700]: mean_loss=0.10394721571356058
Online_Training [164/700]: mean_loss=0.017767406534403563
Online_Training [165/700]: mean_loss=0.00616253400221467
Online_Training [166/700]: mean_loss=0.019696077797561884
Online_Training [167/700]: mean_loss=0.005031585169490427
Online_Training [168/700]: mean_loss=0.006536299944855273
Online_Training [169/700]: mean_loss=0.0017592084186617285
Online_Training [170/700]: mean_loss=0.004361210740171373
Online_Training [171/700]: mean_loss=0.015210058772936463
Online_Training [172/700]: mean_loss=0.023976612370461226
Online_Training [173/700]: mean_loss=0.027839449467137456
Online_Training [174/700]: mean_loss=0.008986808825284243
Online_Training [175/700]: mean_loss=0.016839935909956694
Online_Training [176/700]: mean_loss=0.0012588792305905372
Online_Training [177/700]: mean_loss=0.004062082152813673
Online_Training [178/700]: mean_loss=0.0036165566416457295
Online_Training [179/700]: mean_loss=0.004396196804009378
Online_Training [180/700]: mean_loss=0.00687365944031626
Online_Training [181/700]: mean_loss=0.0037610703730024397
Online_Training [182/700]: mean_loss=0.002009409450693056
Online_Training [183/700]: mean_loss=0.005678675195667893
Online_Training [184/700]: mean_loss=0.003847882413538173
Online_Training [185/700]: mean_loss=0.0035572232154663652
Online_Training [186/700]: mean_loss=0.0024703187227714807
Online_Training [187/700]: mean_loss=0.002210838138125837
Online_Training [188/700]: mean_loss=0.08801655378192663
Online_Training [189/700]: mean_loss=0.0868142144754529
Online_Training [190/700]: mean_loss=0.015351986745372415
Online_Training [191/700]: mean_loss=0.05273747118189931
Online_Training [192/700]: mean_loss=0.015045101754367352
Online_Training [193/700]: mean_loss=0.014732791692949831
Online_Training [194/700]: mean_loss=0.025941528845578432
Online_Training [195/700]: mean_loss=0.007155218278057873
Online_Training [196/700]: mean_loss=0.013934735208749771
Online_Training [197/700]: mean_loss=0.0049983473581960425
Online_Training [198/700]: mean_loss=0.005162456422112882
Online_Training [199/700]: mean_loss=0.010650166077539325
Online_Training [200/700]: mean_loss=0.005909160419832915
Online_Training [201/700]: mean_loss=0.009840061888098717
Online_Training [202/700]: mean_loss=0.006838561675976962
Online_Training [203/700]: mean_loss=0.0020147563191130757
Online_Training [204/700]: mean_loss=0.005853805516380817
Online_Training [205/700]: mean_loss=0.0030265600653365254
Online_Training [206/700]: mean_loss=0.00786892231553793
Online_Training [207/700]: mean_loss=0.00631019999855198
Online_Training [208/700]: mean_loss=0.005782612483017147
Online_Training [209/700]: mean_loss=0.006699805497191846
Online_Training [210/700]: mean_loss=0.007274429779499769
Online_Training [211/700]: mean_loss=0.004621922736987472
Online_Training [212/700]: mean_loss=0.0032494522747583687
Online_Training [213/700]: mean_loss=0.004666180408094078
Online_Training [214/700]: mean_loss=0.0035296327841933817
Online_Training [215/700]: mean_loss=0.004535752144875005
Online_Training [216/700]: mean_loss=0.0013346472405828536
Online_Training [217/700]: mean_loss=0.004433357040397823
Online_Training [218/700]: mean_loss=0.0027046276663895696
Online_Training [219/700]: mean_loss=0.006868946482427418
Online_Training [220/700]: mean_loss=0.013791754667181522
Online_Training [221/700]: mean_loss=0.020393646671436727
Online_Training [222/700]: mean_loss=0.006168175634229556
Online_Training [223/700]: mean_loss=0.0004243788789608516
Online_Training [224/700]: mean_loss=0.004386649874504656
Online_Training [225/700]: mean_loss=0.0009666607293183915
Online_Training [226/700]: mean_loss=0.004132137735723518
Online_Training [227/700]: mean_loss=0.010553074069321156
Online_Training [228/700]: mean_loss=0.007150489487685263
Online_Training [229/700]: mean_loss=0.003734598692972213
Online_Training [230/700]: mean_loss=0.002801035821903497
Online_Training [231/700]: mean_loss=0.002742285461863503
Online_Training [232/700]: mean_loss=0.002651541493833065
Online_Training [233/700]: mean_loss=0.004426938481628895
Online_Training [234/700]: mean_loss=0.0053755848784931
Online_Training [235/700]: mean_loss=0.00572428124723956
Online_Training [236/700]: mean_loss=0.020900957577396184
Online_Training [237/700]: mean_loss=0.002660178142832592
Online_Training [238/700]: mean_loss=0.0036584479094017297
Online_Training [239/700]: mean_loss=0.0019028971873922274
Online_Training [240/700]: mean_loss=0.009084392455406487
Online_Training [241/700]: mean_loss=0.04288580408319831
Online_Training [242/700]: mean_loss=0.008794917492195964
Online_Training [243/700]: mean_loss=0.009326254890765995
Online_Training [244/700]: mean_loss=0.007244490261655301
Online_Training [245/700]: mean_loss=0.002298464940395206
Online_Training [246/700]: mean_loss=0.0037993150181137025
Online_Training [247/700]: mean_loss=0.00393602141411975
Online_Training [248/700]: mean_loss=0.018536231014877558
Online_Training [249/700]: mean_loss=0.010263428557664156
Online_Training [250/700]: mean_loss=0.003697429841849953
Online_Training [251/700]: mean_loss=0.012391699710860848
Online_Training [252/700]: mean_loss=0.0026148635952267796
Online_Training [253/700]: mean_loss=0.005876632349099964
Online_Training [254/700]: mean_loss=0.005729113836423494
Online_Training [255/700]: mean_loss=0.0037724093708675355
Online_Training [256/700]: mean_loss=0.07907587941735983
Online_Training [257/700]: mean_loss=0.08306860737502575
Online_Training [258/700]: mean_loss=0.009240857674740255
Online_Training [259/700]: mean_loss=0.002029762137681246
Online_Training [260/700]: mean_loss=0.003940368653275073
Online_Training [261/700]: mean_loss=0.033101308392360806
Online_Training [262/700]: mean_loss=0.009258216887246817
Online_Training [263/700]: mean_loss=0.009749255899805576
Online_Training [264/700]: mean_loss=0.009771453740540892
Online_Training [265/700]: mean_loss=0.004750192470964976
Online_Training [266/700]: mean_loss=0.0026953680207952857
Online_Training [267/700]: mean_loss=0.004026180831715465
Online_Training [268/700]: mean_loss=0.010764117236249149
Online_Training [269/700]: mean_loss=0.0068954339367337525
Online_Training [270/700]: mean_loss=0.003799561149207875
Online_Training [271/700]: mean_loss=0.00376474013319239
Online_Training [272/700]: mean_loss=0.002923834486864507
Online_Training [273/700]: mean_loss=0.00439902298967354
Online_Training [274/700]: mean_loss=0.003565927894669585
Online_Training [275/700]: mean_loss=0.19079104624688625
Online_Training [276/700]: mean_loss=0.05158043745905161
Online_Training [277/700]: mean_loss=0.012841151328757405
Online_Training [278/700]: mean_loss=0.012715948862023652
Online_Training [279/700]: mean_loss=0.0030621477344539016
Online_Training [280/700]: mean_loss=0.007980263326317072
Online_Training [281/700]: mean_loss=0.0036330771690700203
Online_Training [282/700]: mean_loss=0.01117898733355105
Online_Training [283/700]: mean_loss=0.009716203436255455
Online_Training [284/700]: mean_loss=0.008272458944702521
Online_Training [285/700]: mean_loss=0.014204464387148619
Online_Training [286/700]: mean_loss=0.009009354515001178
Online_Training [287/700]: mean_loss=0.009434115927433595
Online_Training [288/700]: mean_loss=0.004139963799389079
Online_Training [289/700]: mean_loss=0.004532910767011344
Online_Training [290/700]: mean_loss=0.0027973862597718835
Online_Training [291/700]: mean_loss=0.004869096621405333
Online_Training [292/700]: mean_loss=0.003553326620021835
Online_Training [293/700]: mean_loss=0.0047651902423240244
Online_Training [294/700]: mean_loss=0.0025405450433027
Online_Training [295/700]: mean_loss=0.002032143296673894
Online_Training [296/700]: mean_loss=0.17886519245803356
Online_Training [297/700]: mean_loss=0.08573807589709759
Online_Training [298/700]: mean_loss=0.011679678922519088
Online_Training [299/700]: mean_loss=0.014750661444850266
Online_Training [300/700]: mean_loss=0.006905282905790955
Online_Training [301/700]: mean_loss=0.010160984005779028
Online_Training [302/700]: mean_loss=0.006867607415188104
Online_Training [303/700]: mean_loss=0.0031699744577053934
Online_Training [304/700]: mean_loss=0.005452358804177493
Online_Training [305/700]: mean_loss=0.006747540086507797
Online_Training [306/700]: mean_loss=0.007230620831251144
Online_Training [307/700]: mean_loss=0.004606754286214709
Online_Training [308/700]: mean_loss=0.0021960492158541456
Online_Training [309/700]: mean_loss=0.003441435197601095
Online_Training [310/700]: mean_loss=0.0032877033518161625
Online_Training [311/700]: mean_loss=0.006769138795789331
Online_Training [312/700]: mean_loss=0.003825269843218848
Online_Training [313/700]: mean_loss=0.002842052810592577
Online_Training [314/700]: mean_loss=0.007788433227688074
Online_Training [315/700]: mean_loss=0.008816819288767874
Online_Training [316/700]: mean_loss=0.003775205957936123
Online_Training [317/700]: mean_loss=0.005607173952739686
Online_Training [318/700]: mean_loss=0.005796939192805439
Online_Training [319/700]: mean_loss=0.0036633687559515238
Online_Training [320/700]: mean_loss=0.0061112899566069245
Online_Training [321/700]: mean_loss=0.003481623949483037
Online_Training [322/700]: mean_loss=0.0013273708173073828
Online_Training [323/700]: mean_loss=0.11576246935874224
Online_Training [324/700]: mean_loss=0.09969587065279484
Online_Training [325/700]: mean_loss=0.0066164296003989875
Online_Training [326/700]: mean_loss=0.0021161310141906142
Online_Training [327/700]: mean_loss=0.017357638804242015
Online_Training [328/700]: mean_loss=0.011037194519303739
Online_Training [329/700]: mean_loss=0.003596950467908755
Online_Training [330/700]: mean_loss=0.01144777552690357
Online_Training [331/700]: mean_loss=0.0019464562938082963
Online_Training [332/700]: mean_loss=0.005515893630217761
Online_Training [333/700]: mean_loss=0.0060039160889573395
Online_Training [334/700]: mean_loss=0.010366888716816902
Online_Training [335/700]: mean_loss=0.010448529501445591
Online_Training [336/700]: mean_loss=0.004503027710597962
Online_Training [337/700]: mean_loss=0.00590422612731345
Online_Training [338/700]: mean_loss=0.005706239375285804
Online_Training [339/700]: mean_loss=0.004811390754184686
Online_Training [340/700]: mean_loss=0.0010484079539310187
Online_Training [341/700]: mean_loss=0.0018926753400592133
Online_Training [342/700]: mean_loss=0.007355538720730692
Online_Training [343/700]: mean_loss=0.011221049120649695
Online_Training [344/700]: mean_loss=0.0024773933982942253
Online_Training [345/700]: mean_loss=0.0024221208586823195
Online_Training [346/700]: mean_loss=0.006564584909938276
Online_Training [347/700]: mean_loss=0.009638150746468455
Online_Training [348/700]: mean_loss=0.005111404287163168
Online_Training [349/700]: mean_loss=0.0016737311234464869
Online_Training [350/700]: mean_loss=0.004268460761522874
Online_Training [351/700]: mean_loss=0.007067269471008331
Online_Training [352/700]: mean_loss=0.0048249223618768156
Online_Training [353/700]: mean_loss=0.004958771518431604
Online_Training [354/700]: mean_loss=0.0007354610606853385
Online_Training [355/700]: mean_loss=0.0017945114959729835
Online_Training [356/700]: mean_loss=0.0033467155881226063
Online_Training [357/700]: mean_loss=0.0022435801511164755
Online_Training [358/700]: mean_loss=0.003672533028293401
Online_Training [359/700]: mean_loss=0.009748522192239761
Online_Training [360/700]: mean_loss=0.0029977252997923642
Online_Training [361/700]: mean_loss=0.007838345714844763
Online_Training [362/700]: mean_loss=0.1778369639068842
Online_Training [363/700]: mean_loss=0.09035121835768223
Online_Training [364/700]: mean_loss=0.011934871203266084
Online_Training [365/700]: mean_loss=0.017252731136977673
Online_Training [366/700]: mean_loss=0.022220244398340583
Online_Training [367/700]: mean_loss=0.005231874238234013
Online_Training [368/700]: mean_loss=0.005019000789616257
Online_Training [369/700]: mean_loss=0.010877909953705966
Online_Training [370/700]: mean_loss=0.005743682268075645
Online_Training [371/700]: mean_loss=0.019872350967489183
Online_Training [372/700]: mean_loss=0.0037519496690947562
Online_Training [373/700]: mean_loss=0.005191783362533897
Online_Training [374/700]: mean_loss=0.0663818484172225
Online_Training [375/700]: mean_loss=0.012511023902334273
Online_Training [376/700]: mean_loss=0.0068624879932031035
Online_Training [377/700]: mean_loss=0.010919694439508021
Online_Training [378/700]: mean_loss=0.013456271728500724
Online_Training [379/700]: mean_loss=0.0059738425188697875
Online_Training [380/700]: mean_loss=0.003252199472626671
Online_Training [381/700]: mean_loss=0.00574439245974645
Online_Training [382/700]: mean_loss=0.0074697412783280015
Online_Training [383/700]: mean_loss=0.003841235098661855
Online_Training [384/700]: mean_loss=0.007144677685573697
Online_Training [385/700]: mean_loss=0.00404091490781866
Online_Training [386/700]: mean_loss=0.006544781208503991
Online_Training [387/700]: mean_loss=0.009666613186709583
Online_Training [388/700]: mean_loss=0.07692476455122232
Online_Training [389/700]: mean_loss=0.30727727711200714
Online_Training [390/700]: mean_loss=0.0789485014975071
Online_Training [391/700]: mean_loss=0.011646928498521447
Online_Training [392/700]: mean_loss=0.009955416433513165
Online_Training [393/700]: mean_loss=0.01021572423633188
Online_Training [394/700]: mean_loss=0.0024182163760997355
Online_Training [395/700]: mean_loss=0.006975494383368641
Online_Training [396/700]: mean_loss=0.013924194616265595
Online_Training [397/700]: mean_loss=0.010343013796955347
Online_Training [398/700]: mean_loss=0.006344499008264393
Online_Training [399/700]: mean_loss=0.012896122643724084
Online_Training [400/700]: mean_loss=0.0011711549668689258
Online_Training [401/700]: mean_loss=0.005318361334502697
Online_Training [402/700]: mean_loss=0.0026775317382998765
Online_Training [403/700]: mean_loss=0.0036902991705574095
Online_Training [404/700]: mean_loss=0.0032281103485729545
Online_Training [405/700]: mean_loss=0.005169283540453762
Online_Training [406/700]: mean_loss=0.004259004781488329
Online_Training [407/700]: mean_loss=0.0038917382480576634
Online_Training [408/700]: mean_loss=0.003611633088439703
Online_Training [409/700]: mean_loss=0.003378944151336327
Online_Training [410/700]: mean_loss=0.006391340750269592
Online_Training [411/700]: mean_loss=0.004210356331896037
Online_Training [412/700]: mean_loss=0.0032272273383568972
Online_Training [413/700]: mean_loss=0.0023560213448945433
Online_Training [414/700]: mean_loss=0.0054041758994571865
Online_Training [415/700]: mean_loss=0.005158442247193307
Online_Training [416/700]: mean_loss=0.008381585124880075
Online_Training [417/700]: mean_loss=0.0012662547451327555
Online_Training [418/700]: mean_loss=0.00409940694225952
Online_Training [419/700]: mean_loss=0.0036092279478907585
Online_Training [420/700]: mean_loss=0.002279916312545538
Online_Training [421/700]: mean_loss=0.013078916701488197
Online_Training [422/700]: mean_loss=0.0038225302996579558
Online_Training [423/700]: mean_loss=0.0034991796128451824
Online_Training [424/700]: mean_loss=0.004541293499642052
Online_Training [425/700]: mean_loss=0.007187191804405302
Online_Training [426/700]: mean_loss=0.07611068151891232
Online_Training [427/700]: mean_loss=0.09000971633940935
Online_Training [428/700]: mean_loss=0.009332095854915679
Online_Training [429/700]: mean_loss=0.009823813452385366
Online_Training [430/700]: mean_loss=0.009496355894953012
Online_Training [431/700]: mean_loss=0.03657211968675256
Online_Training [432/700]: mean_loss=0.031115211080759764
Online_Training [433/700]: mean_loss=0.01026571774855256
Online_Training [434/700]: mean_loss=0.009374467423185706
Online_Training [435/700]: mean_loss=0.00794305931776762
Online_Training [436/700]: mean_loss=0.006928139511728659
Online_Training [437/700]: mean_loss=0.00599676591809839
Online_Training [438/700]: mean_loss=0.0054312870488502085
Online_Training [439/700]: mean_loss=0.004714012204203755
Online_Training [440/700]: mean_loss=0.0056628850870765746
Online_Training [441/700]: mean_loss=0.003974356222897768
Online_Training [442/700]: mean_loss=0.00714424072066322
Online_Training [443/700]: mean_loss=0.06679869396612048
Online_Training [444/700]: mean_loss=0.003942721203202382
Online_Training [445/700]: mean_loss=0.003057337482459843
Online_Training [446/700]: mean_loss=0.011879741156008095
Online_Training [447/700]: mean_loss=0.009499461913947016
Online_Training [448/700]: mean_loss=0.017569694959092885
Online_Training [449/700]: mean_loss=0.004874529782682657
Online_Training [450/700]: mean_loss=0.005689291981980205
Online_Training [451/700]: mean_loss=0.01074215114931576
Online_Training [452/700]: mean_loss=0.012906775926239789
Online_Training [453/700]: mean_loss=0.00603388698073104
Online_Training [454/700]: mean_loss=0.0026725756470113993
Online_Training [455/700]: mean_loss=0.0062995339394547045
Online_Training [456/700]: mean_loss=0.010648131894413382
Online_Training [457/700]: mean_loss=0.0047985652345232666
Online_Training [458/700]: mean_loss=0.0012574008651426993
Online_Training [459/700]: mean_loss=0.0023655732366023585
Online_Training [460/700]: mean_loss=0.017481910181231797
Online_Training [461/700]: mean_loss=0.0076537245768122375
Online_Training [462/700]: mean_loss=0.0687983175739646
Online_Training [463/700]: mean_loss=0.07305847387760878
Online_Training [464/700]: mean_loss=0.010453380644321442
Online_Training [465/700]: mean_loss=0.011861146660521626
Online_Training [466/700]: mean_loss=0.005097422632388771
Online_Training [467/700]: mean_loss=0.002392058027908206
Online_Training [468/700]: mean_loss=0.0066902064136229455
Online_Training [469/700]: mean_loss=0.011165694100782275
Online_Training [470/700]: mean_loss=0.0061444659368135035
Online_Training [471/700]: mean_loss=0.007139304652810097
Online_Training [472/700]: mean_loss=0.002603422530228272
Online_Training [473/700]: mean_loss=0.003547175379935652
Online_Training [474/700]: mean_loss=0.002400115947239101
Online_Training [475/700]: mean_loss=0.0021883687586523592
Online_Training [476/700]: mean_loss=0.005065853940322995
Online_Training [477/700]: mean_loss=0.003062810836127028
Online_Training [478/700]: mean_loss=0.0037302457203622907
Online_Training [479/700]: mean_loss=0.0036050060589332134
Online_Training [480/700]: mean_loss=0.005157028266694397
Online_Training [481/700]: mean_loss=0.0075162387220188975
Online_Training [482/700]: mean_loss=0.012518525472842157
Online_Training [483/700]: mean_loss=0.008622718276455998
Online_Training [484/700]: mean_loss=0.006369018723489717
Online_Training [485/700]: mean_loss=0.003192044561728835
Online_Training [486/700]: mean_loss=0.005759460269473493
Online_Training [487/700]: mean_loss=0.008727196021936834
Online_Training [488/700]: mean_loss=0.005406221374869347
Online_Training [489/700]: mean_loss=0.012297525303438306
Online_Training [490/700]: mean_loss=0.006782834883779287
Online_Training [491/700]: mean_loss=0.0051101656863465905
Online_Training [492/700]: mean_loss=0.014292417123215273
Online_Training [493/700]: mean_loss=0.004666731983888894
Online_Training [494/700]: mean_loss=0.08830730617046356
Online_Training [495/700]: mean_loss=0.2025609128177166
Online_Training [496/700]: mean_loss=0.004866423347266391
Online_Training [497/700]: mean_loss=0.01116468443069607
Online_Training [498/700]: mean_loss=0.015788269694894552
Online_Training [499/700]: mean_loss=0.010417989105917513
Online_Training [500/700]: mean_loss=0.004355186450993642
Online_Training [501/700]: mean_loss=0.006578934378921986
Online_Training [502/700]: mean_loss=0.006439933378715068
Online_Training [503/700]: mean_loss=0.003439329215325415
Online_Training [504/700]: mean_loss=0.012376932776533067
Online_Training [505/700]: mean_loss=0.017977425130084157
Online_Training [506/700]: mean_loss=0.007969186000991613
Online_Training [507/700]: mean_loss=0.005845995503477752
Online_Training [508/700]: mean_loss=0.003152013261569664
Online_Training [509/700]: mean_loss=0.18670818582177162
Online_Training [510/700]: mean_loss=0.030183888506144285
Online_Training [511/700]: mean_loss=0.005414928251411766
Online_Training [512/700]: mean_loss=0.20825674384832382
Online_Training [513/700]: mean_loss=0.5461914055049419
Online_Training [514/700]: mean_loss=0.3907196447253227
Online_Training [515/700]: mean_loss=0.08273914037272334
Online_Training [516/700]: mean_loss=0.08370043151080608
Online_Training [517/700]: mean_loss=0.023835041793063283
Online_Training [518/700]: mean_loss=0.05974961631000042
Online_Training [519/700]: mean_loss=0.014259762363508344
Online_Training [520/700]: mean_loss=0.014849697006866336
Online_Training [521/700]: mean_loss=0.013242084998637438
Online_Training [522/700]: mean_loss=0.031760486075654626
Online_Training [523/700]: mean_loss=0.016914334730245173
Online_Training [524/700]: mean_loss=0.009329958586022258
Online_Training [525/700]: mean_loss=0.013797160470858216
Online_Training [526/700]: mean_loss=0.015100378077477217
Online_Training [527/700]: mean_loss=0.06797797931358218
Online_Training [528/700]: mean_loss=0.14714166056364775
Online_Training [529/700]: mean_loss=0.008838983427267522
Online_Training [530/700]: mean_loss=0.09161268081516027
Online_Training [531/700]: mean_loss=0.016440436826087534
Online_Training [532/700]: mean_loss=0.004318319115554914
Online_Training [533/700]: mean_loss=0.08447944931685925
Online_Training [534/700]: mean_loss=0.007121046248357743
Online_Training [535/700]: mean_loss=0.007843759376555681
Online_Training [536/700]: mean_loss=0.005734335049055517
Online_Training [537/700]: mean_loss=0.007972203544341028
Online_Training [538/700]: mean_loss=0.008845259028021246
Online_Training [539/700]: mean_loss=0.0049776844680309296
Online_Training [540/700]: mean_loss=0.008518180693499744
Online_Training [541/700]: mean_loss=0.0011519751569721848
Online_Training [542/700]: mean_loss=0.007094525150023401
Online_Training [543/700]: mean_loss=0.008342081506270915
Online_Training [544/700]: mean_loss=0.002248294709715992
Online_Training [545/700]: mean_loss=0.0023945210996316746
Online_Training [546/700]: mean_loss=0.014372865087352693
Online_Training [547/700]: mean_loss=0.005363420466892421
Online_Training [548/700]: mean_loss=0.004429726337548345
Online_Training [549/700]: mean_loss=0.005058325652498752
Online_Training [550/700]: mean_loss=0.0032765716896392405
Online_Training [551/700]: mean_loss=0.0022014201822457835
Online_Training [552/700]: mean_loss=0.08691221941262484
Online_Training [553/700]: mean_loss=0.006400558224413544
Online_Training [554/700]: mean_loss=0.0013622373662656173
Online_Training [555/700]: mean_loss=0.0016361968300770968
Online_Training [556/700]: mean_loss=0.008119142788928002
Online_Training [557/700]: mean_loss=0.004041964566567913
Online_Training [558/700]: mean_loss=0.008770518936216831
Online_Training [559/700]: mean_loss=0.0021018725965404883
Online_Training [560/700]: mean_loss=0.007468639581929892
Online_Training [561/700]: mean_loss=0.0057613143872004
Online_Training [562/700]: mean_loss=0.0046495727729052305
Online_Training [563/700]: mean_loss=0.003953908832045272
Online_Training [564/700]: mean_loss=0.004398093558847904
Online_Training [565/700]: mean_loss=0.005188085313420743
Online_Training [566/700]: mean_loss=0.005028530023992062
Online_Training [567/700]: mean_loss=0.008496866968926042
Online_Training [568/700]: mean_loss=0.0065335399704054
Online_Training [569/700]: mean_loss=0.004928718553856015
Online_Training [570/700]: mean_loss=0.010193494497798383
Online_Training [571/700]: mean_loss=0.07317389454692602
Online_Training [572/700]: mean_loss=0.08802846260368824
Online_Training [573/700]: mean_loss=0.003859707241645083
Online_Training [574/700]: mean_loss=0.003906925761839375
Online_Training [575/700]: mean_loss=0.008829417172819376
Online_Training [576/700]: mean_loss=0.00678189960308373
Online_Training [577/700]: mean_loss=0.0060674415435642
Online_Training [578/700]: mean_loss=0.0061709259753115475
Online_Training [579/700]: mean_loss=0.008307251788210124
Online_Training [580/700]: mean_loss=0.001691798519459553
Online_Training [581/700]: mean_loss=0.004333017859607935
Online_Training [582/700]: mean_loss=0.002967644832096994
Online_Training [583/700]: mean_loss=0.002304398105479777
Online_Training [584/700]: mean_loss=0.002497132998541929
Online_Training [585/700]: mean_loss=0.0067040229914709926
Online_Training [586/700]: mean_loss=0.0018603788776090369
Online_Training [587/700]: mean_loss=0.004399367957375944
Online_Training [588/700]: mean_loss=0.006758609029930085
Online_Training [589/700]: mean_loss=0.006282089743763208
Online_Training [590/700]: mean_loss=0.003839201934169978
Online_Training [591/700]: mean_loss=0.002088568653562106
Online_Training [592/700]: mean_loss=0.006491463340353221
Online_Training [593/700]: mean_loss=0.002951714472146705
Online_Training [594/700]: mean_loss=0.0018991132819792256
Online_Training [595/700]: mean_loss=0.00809124915394932
Online_Training [596/700]: mean_loss=0.0054837739444337785
Online_Training [597/700]: mean_loss=0.004479807044845074
Online_Training [598/700]: mean_loss=0.003415944054722786
Online_Training [599/700]: mean_loss=0.002810056641465053
Online_Training [600/700]: mean_loss=0.008454649243503809
Online_Training [601/700]: mean_loss=0.009628571686334908
Online_Training [602/700]: mean_loss=0.003404470655368641
Online_Training [603/700]: mean_loss=0.0019137752096867189
Online_Training [604/700]: mean_loss=0.005806541128549725
Online_Training [605/700]: mean_loss=0.007120776048395783
Online_Training [606/700]: mean_loss=0.0035665153991431
Online_Training [607/700]: mean_loss=0.002008433613809757
Online_Training [608/700]: mean_loss=0.00967951794154942
Online_Training [609/700]: mean_loss=0.0025207538274116814
Online_Training [610/700]: mean_loss=0.0017031348252203315
Online_Training [611/700]: mean_loss=0.07837049663066864
Online_Training [612/700]: mean_loss=0.020463879918679595
Online_Training [613/700]: mean_loss=0.015232839155942202
Online_Training [614/700]: mean_loss=0.005010919354390353
Online_Training [615/700]: mean_loss=0.010284114396199584
Online_Training [616/700]: mean_loss=0.0019346351182321087
Online_Training [617/700]: mean_loss=0.004340792598668486
Online_Training [618/700]: mean_loss=0.0008690827162354253
Online_Training [619/700]: mean_loss=0.00535433879122138
Online_Training [620/700]: mean_loss=0.0015731562161818147
Online_Training [621/700]: mean_loss=0.11136423610150814
Online_Training [622/700]: mean_loss=0.023928901879116893
Online_Training [623/700]: mean_loss=0.07104474864900112
Online_Training [624/700]: mean_loss=0.17995438538491726
Online_Training [625/700]: mean_loss=0.004923909204080701
Online_Training [626/700]: mean_loss=0.03389621223323047
Online_Training [627/700]: mean_loss=0.017980142030864954
Online_Training [628/700]: mean_loss=0.03150558634661138
Online_Training [629/700]: mean_loss=0.009535368997603655
Online_Training [630/700]: mean_loss=0.008668138470966369
Online_Training [631/700]: mean_loss=0.009048090199939907
Online_Training [632/700]: mean_loss=0.006642043124884367
Online_Training [633/700]: mean_loss=0.002934872347395867
Online_Training [634/700]: mean_loss=0.004415165254613385
Online_Training [635/700]: mean_loss=0.003188407514244318
Online_Training [636/700]: mean_loss=0.006156458577606827
Online_Training [637/700]: mean_loss=0.008596799336373806
Online_Training [638/700]: mean_loss=0.0020515169453574345
Online_Training [639/700]: mean_loss=0.00672525231493637
Online_Training [640/700]: mean_loss=0.0025229285965906456
Online_Training [641/700]: mean_loss=0.06213003117591143
Online_Training [642/700]: mean_loss=0.007113000261597335
Online_Training [643/700]: mean_loss=0.0017100834811571985
Online_Training [644/700]: mean_loss=0.0024071892839856446
Online_Training [645/700]: mean_loss=0.003687096672365442
Online_Training [646/700]: mean_loss=0.0021410279150586575
Online_Training [647/700]: mean_loss=0.06344321509823203
Online_Training [648/700]: mean_loss=0.0026758609747048467
Online_Training [649/700]: mean_loss=0.0041304322658106685
Online_Training [650/700]: mean_loss=0.007384528871625662
Online_Training [651/700]: mean_loss=0.012392116710543633
Online_Training [652/700]: mean_loss=0.002364312647841871
Online_Training [653/700]: mean_loss=0.008853198029100895
Online_Training [654/700]: mean_loss=0.003979881730629131
Online_Training [655/700]: mean_loss=0.0022912444546818733
Online_Training [656/700]: mean_loss=0.008040842483751476
Online_Training [657/700]: mean_loss=0.012388172093778849
Online_Training [658/700]: mean_loss=0.0030383820412680507
Online_Training [659/700]: mean_loss=0.005861377925612032
Online_Training [660/700]: mean_loss=0.012207794818095863
Online_Training [661/700]: mean_loss=0.0057802141818683594
Online_Training [662/700]: mean_loss=0.005673450825270265
Online_Training [663/700]: mean_loss=0.006060248415451497
Online_Training [664/700]: mean_loss=0.0068530992430169135
Online_Training [665/700]: mean_loss=0.006280328787397593
Online_Training [666/700]: mean_loss=0.005964488256722689
Online_Training [667/700]: mean_loss=0.008689953130669892
Online_Training [668/700]: mean_loss=0.0059923879452981055
Online_Training [669/700]: mean_loss=0.005082830612082034
Online_Training [670/700]: mean_loss=0.0011415337212383747
Online_Training [671/700]: mean_loss=0.004456921014934778
Online_Training [672/700]: mean_loss=0.004059024737216532
Online_Training [673/700]: mean_loss=0.0070579006569460034
Online_Training [674/700]: mean_loss=0.0029439380596159026
Online_Training [675/700]: mean_loss=0.0029143427964299917
Online_Training [676/700]: mean_loss=0.001632521118153818
Online_Training [677/700]: mean_loss=0.002089035275275819
Online_Training [678/700]: mean_loss=0.008771276450715959
Online_Training [679/700]: mean_loss=0.003764825698453933
Online_Training [680/700]: mean_loss=0.07826615264639258
Online_Training [681/700]: mean_loss=0.0013274048687890172
Online_Training [682/700]: mean_loss=0.008120675280224532
Online_Training [683/700]: mean_loss=0.004453121015103534
Online_Training [684/700]: mean_loss=0.00815989071270451
Online_Training [685/700]: mean_loss=0.009711726394016296
Online_Training [686/700]: mean_loss=0.013388766441494226
Online_Training [687/700]: mean_loss=0.0033044516312656924
Online_Training [688/700]: mean_loss=0.004859636479523033
Online_Training [689/700]: mean_loss=0.004697639204096049
Online_Training [690/700]: mean_loss=0.00319766384200193
Online_Training [691/700]: mean_loss=0.002701252175029367
Online_Training [692/700]: mean_loss=0.0018733190663624555
Online_Training [693/700]: mean_loss=0.001878944764030166
Online_Training [694/700]: mean_loss=0.0059216119116172194
Online_Training [695/700]: mean_loss=0.005669655802194029
Online_Training [696/700]: mean_loss=0.0016347644705092534
Online_Training [697/700]: mean_loss=0.005191700533032417
Online_Training [698/700]: mean_loss=0.0038103836122900248
Online_Training [699/700]: mean_loss=0.00177421496482566
Online_Training [700/700]: mean_loss=0.007852106471545994
Q_Learning [1/300]: mean_loss=0.1565920189023018
Q_Learning [2/300]: mean_loss=0.0786384092643857
Q_Learning [3/300]: mean_loss=0.331835076212883
Q_Learning [4/300]: mean_loss=0.3005834147334099
Q_Learning [5/300]: mean_loss=0.3275088667869568
Q_Learning [6/300]: mean_loss=0.14376506954431534
Q_Learning [7/300]: mean_loss=0.06920340098440647
Q_Learning [8/300]: mean_loss=0.29482392594218254
Q_Learning [9/300]: mean_loss=0.06554545555263758
Q_Learning [10/300]: mean_loss=0.05929398210719228
Q_Learning [11/300]: mean_loss=0.04759691609069705
Q_Learning [12/300]: mean_loss=0.04352825274690986
Q_Learning [13/300]: mean_loss=0.02936302637681365
Q_Learning [14/300]: mean_loss=0.17626593448221684
Q_Learning [15/300]: mean_loss=0.21913000382483006
Q_Learning [16/300]: mean_loss=0.15677768550813198
Q_Learning [17/300]: mean_loss=0.17351542972028255
Q_Learning [18/300]: mean_loss=0.18915496952831745
Q_Learning [19/300]: mean_loss=0.1340494267642498
Q_Learning [20/300]: mean_loss=0.12446073349565268
Q_Learning [21/300]: mean_loss=0.18766183033585548
Q_Learning [22/300]: mean_loss=0.1279498226940632
Q_Learning [23/300]: mean_loss=0.12486302386969328
Q_Learning [24/300]: mean_loss=0.06275429110974073
Q_Learning [25/300]: mean_loss=0.08350830711424351
Q_Learning [26/300]: mean_loss=0.0644748667255044
Q_Learning [27/300]: mean_loss=0.05167661188170314
Q_Learning [28/300]: mean_loss=0.04213088424876332
Q_Learning [29/300]: mean_loss=0.08780997572466731
Q_Learning [30/300]: mean_loss=0.040605037938803434
Q_Learning [31/300]: mean_loss=0.1044324403628707
Q_Learning [32/300]: mean_loss=0.02604496362619102
Q_Learning [33/300]: mean_loss=0.01802590163424611
Q_Learning [34/300]: mean_loss=0.0849336152896285
Q_Learning [35/300]: mean_loss=0.011115288827568293
Q_Learning [36/300]: mean_loss=0.1235961141064763
Q_Learning [37/300]: mean_loss=0.0766229024156928
Q_Learning [38/300]: mean_loss=0.06784604117274284
Q_Learning [39/300]: mean_loss=0.0513423359952867
Q_Learning [40/300]: mean_loss=0.03777085384353995
Q_Learning [41/300]: mean_loss=0.02741804043762386
Q_Learning [42/300]: mean_loss=0.04354847292415798
Q_Learning [43/300]: mean_loss=0.034870177041739225
Q_Learning [44/300]: mean_loss=0.015735067892819643
Q_Learning [45/300]: mean_loss=0.04384447494521737
Q_Learning [46/300]: mean_loss=0.022984380600973964
Q_Learning [47/300]: mean_loss=0.10702725499868393
Q_Learning [48/300]: mean_loss=0.09868839383125305
Q_Learning [49/300]: mean_loss=0.019264501053839922
Q_Learning [50/300]: mean_loss=0.024285286432132125
Q_Learning [51/300]: mean_loss=0.014828101149760187
Q_Learning [52/300]: mean_loss=0.005806473200209439
Q_Learning [53/300]: mean_loss=0.05900705372914672
Q_Learning [54/300]: mean_loss=0.17463586293160915
Q_Learning [55/300]: mean_loss=0.039015812799334526
Q_Learning [56/300]: mean_loss=0.0384607738815248
Q_Learning [57/300]: mean_loss=0.026771653210744262
Q_Learning [58/300]: mean_loss=0.013116645743139088
Q_Learning [59/300]: mean_loss=0.11445382330566645
Q_Learning [60/300]: mean_loss=0.019338682759553194
Q_Learning [61/300]: mean_loss=0.01747745950706303
Q_Learning [62/300]: mean_loss=0.014374319231137633
Q_Learning [63/300]: mean_loss=0.008007411728613079
Q_Learning [64/300]: mean_loss=0.003768040071008727
Q_Learning [65/300]: mean_loss=0.012310225400142372
Q_Learning [66/300]: mean_loss=0.005544878949876875
Q_Learning [67/300]: mean_loss=0.0034609506838023663
Q_Learning [68/300]: mean_loss=0.10916028544306755
Q_Learning [69/300]: mean_loss=0.006814391177613288
Q_Learning [70/300]: mean_loss=0.014450220623984933
Q_Learning [71/300]: mean_loss=0.0038810917758382857
Q_Learning [72/300]: mean_loss=0.0077118911431171
Q_Learning [73/300]: mean_loss=0.008561873284634203
Q_Learning [74/300]: mean_loss=0.0038549374148715287
Q_Learning [75/300]: mean_loss=0.005798123369459063
Q_Learning [76/300]: mean_loss=0.0034373333328403533
Q_Learning [77/300]: mean_loss=0.0015690242289565504
Q_Learning [78/300]: mean_loss=0.00665946863591671
Q_Learning [79/300]: mean_loss=0.01951400050893426
Q_Learning [80/300]: mean_loss=0.009719445020891726
Q_Learning [81/300]: mean_loss=0.004438586940523237
Q_Learning [82/300]: mean_loss=0.008990337490104139
Q_Learning [83/300]: mean_loss=0.007691573933698237
Q_Learning [84/300]: mean_loss=0.003791689465288073
Q_Learning [85/300]: mean_loss=0.005069056001957506
Q_Learning [86/300]: mean_loss=0.00990149297285825
Q_Learning [87/300]: mean_loss=0.010685229382943362
Q_Learning [88/300]: mean_loss=0.012222736258991063
Q_Learning [89/300]: mean_loss=0.0033425627916585654
Q_Learning [90/300]: mean_loss=0.006849478697404265
Q_Learning [91/300]: mean_loss=0.0066949171596206725
Q_Learning [92/300]: mean_loss=0.019280055072158575
Q_Learning [93/300]: mean_loss=0.013397933566011488
Q_Learning [94/300]: mean_loss=0.0054371056030504405
Q_Learning [95/300]: mean_loss=0.004120721365325153
Q_Learning [96/300]: mean_loss=0.006381196260917932
Q_Learning [97/300]: mean_loss=0.007234310905914754
Q_Learning [98/300]: mean_loss=0.003942094539524987
Q_Learning [99/300]: mean_loss=0.00660466036060825
Q_Learning [100/300]: mean_loss=0.0009967707592295483
Q_Learning [101/300]: mean_loss=0.003269526467192918
Q_Learning [102/300]: mean_loss=0.003369329875567928
Q_Learning [103/300]: mean_loss=0.006640044797677547
Q_Learning [104/300]: mean_loss=0.0032581526174908504
Q_Learning [105/300]: mean_loss=0.02335775620304048
Q_Learning [106/300]: mean_loss=0.020357740111649036
Q_Learning [107/300]: mean_loss=0.0034224029950564727
Q_Learning [108/300]: mean_loss=0.010888328426517546
Q_Learning [109/300]: mean_loss=0.005025565798860043
Q_Learning [110/300]: mean_loss=0.005059720220742747
Q_Learning [111/300]: mean_loss=0.0038583105779252946
Q_Learning [112/300]: mean_loss=0.004234812018694356
Q_Learning [113/300]: mean_loss=0.00695105193881318
Q_Learning [114/300]: mean_loss=0.0037958816392347217
Q_Learning [115/300]: mean_loss=0.018238068441860378
Q_Learning [116/300]: mean_loss=0.002967039807117544
Q_Learning [117/300]: mean_loss=0.0037567772960755974
Q_Learning [118/300]: mean_loss=0.0031578726484440267
Q_Learning [119/300]: mean_loss=0.002278912957990542
Q_Learning [120/300]: mean_loss=0.004552025347948074
Q_Learning [121/300]: mean_loss=0.00419301787042059
Q_Learning [122/300]: mean_loss=0.008095124911051244
Q_Learning [123/300]: mean_loss=0.0005076788474980276
Q_Learning [124/300]: mean_loss=0.005062399053713307
Q_Learning [125/300]: mean_loss=0.0015817209496162832
Q_Learning [126/300]: mean_loss=0.0017268973751924932
Q_Learning [127/300]: mean_loss=0.005261285696178675
Q_Learning [128/300]: mean_loss=0.008842607960104942
Q_Learning [129/300]: mean_loss=0.003453991375863552
Q_Learning [130/300]: mean_loss=0.004293295205570757
Q_Learning [131/300]: mean_loss=0.0033893353247549385
Q_Learning [132/300]: mean_loss=0.004107602682779543
Q_Learning [133/300]: mean_loss=0.004162228957284242
Q_Learning [134/300]: mean_loss=0.008293346560094506
Q_Learning [135/300]: mean_loss=0.004267808981239796
Q_Learning [136/300]: mean_loss=0.0022323418670566753
Q_Learning [137/300]: mean_loss=0.004778885806445032
Q_Learning [138/300]: mean_loss=0.005803054329589941
Q_Learning [139/300]: mean_loss=0.004546971045783721
Q_Learning [140/300]: mean_loss=0.0021741325326729566
Q_Learning [141/300]: mean_loss=0.0027900476998183876
Q_Learning [142/300]: mean_loss=0.006095307704526931
Q_Learning [143/300]: mean_loss=0.07866374542936683
Q_Learning [144/300]: mean_loss=0.030174885410815477
Q_Learning [145/300]: mean_loss=0.06119981547817588
Q_Learning [146/300]: mean_loss=0.14983987621963024
Q_Learning [147/300]: mean_loss=0.014379100175574422
Q_Learning [148/300]: mean_loss=0.008052606659475714
Q_Learning [149/300]: mean_loss=0.007068289094604552
Q_Learning [150/300]: mean_loss=0.09627648163586855
Q_Learning [151/300]: mean_loss=0.26681130938231945
Q_Learning [152/300]: mean_loss=0.009403751406352967
Q_Learning [153/300]: mean_loss=0.010766609804704785
Q_Learning [154/300]: mean_loss=0.007373235421255231
Q_Learning [155/300]: mean_loss=0.03401956823654473
Q_Learning [156/300]: mean_loss=0.014925258117727935
Q_Learning [157/300]: mean_loss=0.007436769490595907
Q_Learning [158/300]: mean_loss=0.022868364583700895
Q_Learning [159/300]: mean_loss=0.010055506165372208
Q_Learning [160/300]: mean_loss=0.016950428718701005
Q_Learning [161/300]: mean_loss=0.01122443680651486
Q_Learning [162/300]: mean_loss=0.052948211785405874
Q_Learning [163/300]: mean_loss=0.10394721571356058
Q_Learning [164/300]: mean_loss=0.017767406534403563
Q_Learning [165/300]: mean_loss=0.00616253400221467
Q_Learning [166/300]: mean_loss=0.019696077797561884
Q_Learning [167/300]: mean_loss=0.005031585169490427
Q_Learning [168/300]: mean_loss=0.006536299944855273
Q_Learning [169/300]: mean_loss=0.0017592084186617285
Q_Learning [170/300]: mean_loss=0.004361210740171373
Q_Learning [171/300]: mean_loss=0.015210058772936463
Q_Learning [172/300]: mean_loss=0.023976612370461226
Q_Learning [173/300]: mean_loss=0.027839449467137456
Q_Learning [174/300]: mean_loss=0.008986808825284243
Q_Learning [175/300]: mean_loss=0.016839935909956694
Q_Learning [176/300]: mean_loss=0.0012588792305905372
Q_Learning [177/300]: mean_loss=0.004062082152813673
Q_Learning [178/300]: mean_loss=0.0036165566416457295
Q_Learning [179/300]: mean_loss=0.004396196804009378
Q_Learning [180/300]: mean_loss=0.00687365944031626
Q_Learning [181/300]: mean_loss=0.0037610703730024397
Q_Learning [182/300]: mean_loss=0.002009409450693056
Q_Learning [183/300]: mean_loss=0.005678675195667893
Q_Learning [184/300]: mean_loss=0.003847882413538173
Q_Learning [185/300]: mean_loss=0.0035572232154663652
Q_Learning [186/300]: mean_loss=0.0024703187227714807
Q_Learning [187/300]: mean_loss=0.002210838138125837
Q_Learning [188/300]: mean_loss=0.08801655378192663
Q_Learning [189/300]: mean_loss=0.0868142144754529
Q_Learning [190/300]: mean_loss=0.015351986745372415
Q_Learning [191/300]: mean_loss=0.05273747118189931
Q_Learning [192/300]: mean_loss=0.015045101754367352
Q_Learning [193/300]: mean_loss=0.014732791692949831
Q_Learning [194/300]: mean_loss=0.025941528845578432
Q_Learning [195/300]: mean_loss=0.007155218278057873
Q_Learning [196/300]: mean_loss=0.013934735208749771
Q_Learning [197/300]: mean_loss=0.0049983473581960425
Q_Learning [198/300]: mean_loss=0.005162456422112882
Q_Learning [199/300]: mean_loss=0.010650166077539325
Q_Learning [200/300]: mean_loss=0.005909160419832915
Q_Learning [201/300]: mean_loss=0.009840061888098717
Q_Learning [202/300]: mean_loss=0.006838561675976962
Q_Learning [203/300]: mean_loss=0.0020147563191130757
Q_Learning [204/300]: mean_loss=0.005853805516380817
Q_Learning [205/300]: mean_loss=0.0030265600653365254
Q_Learning [206/300]: mean_loss=0.00786892231553793
Q_Learning [207/300]: mean_loss=0.00631019999855198
Q_Learning [208/300]: mean_loss=0.005782612483017147
Q_Learning [209/300]: mean_loss=0.006699805497191846
Q_Learning [210/300]: mean_loss=0.007274429779499769
Q_Learning [211/300]: mean_loss=0.004621922736987472
Q_Learning [212/300]: mean_loss=0.0032494522747583687
Q_Learning [213/300]: mean_loss=0.004666180408094078
Q_Learning [214/300]: mean_loss=0.0035296327841933817
Q_Learning [215/300]: mean_loss=0.004535752144875005
Q_Learning [216/300]: mean_loss=0.0013346472405828536
Q_Learning [217/300]: mean_loss=0.004433357040397823
Q_Learning [218/300]: mean_loss=0.0027046276663895696
Q_Learning [219/300]: mean_loss=0.006868946482427418
Q_Learning [220/300]: mean_loss=0.013791754667181522
Q_Learning [221/300]: mean_loss=0.020393646671436727
Q_Learning [222/300]: mean_loss=0.006168175634229556
Q_Learning [223/300]: mean_loss=0.0004243788789608516
Q_Learning [224/300]: mean_loss=0.004386649874504656
Q_Learning [225/300]: mean_loss=0.0009666607293183915
Q_Learning [226/300]: mean_loss=0.004132137735723518
Q_Learning [227/300]: mean_loss=0.010553074069321156
Q_Learning [228/300]: mean_loss=0.007150489487685263
Q_Learning [229/300]: mean_loss=0.003734598692972213
Q_Learning [230/300]: mean_loss=0.002801035821903497
Q_Learning [231/300]: mean_loss=0.002742285461863503
Q_Learning [232/300]: mean_loss=0.002651541493833065
Q_Learning [233/300]: mean_loss=0.004426938481628895
Q_Learning [234/300]: mean_loss=0.0053755848784931
Q_Learning [235/300]: mean_loss=0.00572428124723956
Q_Learning [236/300]: mean_loss=0.020900957577396184
Q_Learning [237/300]: mean_loss=0.002660178142832592
Q_Learning [238/300]: mean_loss=0.0036584479094017297
Q_Learning [239/300]: mean_loss=0.0019028971873922274
Q_Learning [240/300]: mean_loss=0.009084392455406487
Q_Learning [241/300]: mean_loss=0.04288580408319831
Q_Learning [242/300]: mean_loss=0.008794917492195964
Q_Learning [243/300]: mean_loss=0.009326254890765995
Q_Learning [244/300]: mean_loss=0.007244490261655301
Q_Learning [245/300]: mean_loss=0.002298464940395206
Q_Learning [246/300]: mean_loss=0.0037993150181137025
Q_Learning [247/300]: mean_loss=0.00393602141411975
Q_Learning [248/300]: mean_loss=0.018536231014877558
Q_Learning [249/300]: mean_loss=0.010263428557664156
Q_Learning [250/300]: mean_loss=0.003697429841849953
Q_Learning [251/300]: mean_loss=0.012391699710860848
Q_Learning [252/300]: mean_loss=0.0026148635952267796
Q_Learning [253/300]: mean_loss=0.005876632349099964
Q_Learning [254/300]: mean_loss=0.005729113836423494
Q_Learning [255/300]: mean_loss=0.0037724093708675355
Q_Learning [256/300]: mean_loss=0.07907587941735983
Q_Learning [257/300]: mean_loss=0.08306860737502575
Q_Learning [258/300]: mean_loss=0.009240857674740255
Q_Learning [259/300]: mean_loss=0.002029762137681246
Q_Learning [260/300]: mean_loss=0.003940368653275073
Q_Learning [261/300]: mean_loss=0.033101308392360806
Q_Learning [262/300]: mean_loss=0.009258216887246817
Q_Learning [263/300]: mean_loss=0.009749255899805576
Q_Learning [264/300]: mean_loss=0.009771453740540892
Q_Learning [265/300]: mean_loss=0.004750192470964976
Q_Learning [266/300]: mean_loss=0.0026953680207952857
Q_Learning [267/300]: mean_loss=0.004026180831715465
Q_Learning [268/300]: mean_loss=0.010764117236249149
Q_Learning [269/300]: mean_loss=0.0068954339367337525
Q_Learning [270/300]: mean_loss=0.003799561149207875
Q_Learning [271/300]: mean_loss=0.00376474013319239
Q_Learning [272/300]: mean_loss=0.002923834486864507
Q_Learning [273/300]: mean_loss=0.00439902298967354
Q_Learning [274/300]: mean_loss=0.003565927894669585
Q_Learning [275/300]: mean_loss=0.19079104624688625
Q_Learning [276/300]: mean_loss=0.05158043745905161
Q_Learning [277/300]: mean_loss=0.012841151328757405
Q_Learning [278/300]: mean_loss=0.012715948862023652
Q_Learning [279/300]: mean_loss=0.0030621477344539016
Q_Learning [280/300]: mean_loss=0.007980263326317072
Q_Learning [281/300]: mean_loss=0.0036330771690700203
Q_Learning [282/300]: mean_loss=0.01117898733355105
Q_Learning [283/300]: mean_loss=0.009716203436255455
Q_Learning [284/300]: mean_loss=0.008272458944702521
Q_Learning [285/300]: mean_loss=0.014204464387148619
Q_Learning [286/300]: mean_loss=0.009009354515001178
Q_Learning [287/300]: mean_loss=0.009434115927433595
Q_Learning [288/300]: mean_loss=0.004139963799389079
Q_Learning [289/300]: mean_loss=0.004532910767011344
Q_Learning [290/300]: mean_loss=0.0027973862597718835
Q_Learning [291/300]: mean_loss=0.004869096621405333
Q_Learning [292/300]: mean_loss=0.003553326620021835
Q_Learning [293/300]: mean_loss=0.0047651902423240244
Q_Learning [294/300]: mean_loss=0.0025405450433027
Q_Learning [295/300]: mean_loss=0.002032143296673894
Q_Learning [296/300]: mean_loss=0.17886519245803356
Q_Learning [297/300]: mean_loss=0.08573807589709759
Q_Learning [298/300]: mean_loss=0.011679678922519088
Q_Learning [299/300]: mean_loss=0.014750661444850266
Q_Learning [300/300]: mean_loss=0.006905282905790955
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 1.5911626 -0.9033914]
[1, 2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 0, 2, 1, 1, 1, 2, 0, 1, 2, 0, 0, 2, 0, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 1, 1, 1, 2, 2, 2, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 1, 2, 2, 0, 1, 2, 0, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 1, 2, 1, 2, 0, 2, 1, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 0, 2, 2, 2, 0, 1, 2, 0, 2, 1, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 1, 0, 1, 0, 1, 2, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 0, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 2, 2]
[0, 1, 2, 1, 1, 3, 3, 1, 0, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 1, 3, 3, 1, 3, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 3, 3, 3, 1, 3, 3, 1, 0, 0, 1, 1, 1, 0, 3, 1, 3, 1, 0, 0, 0, 1, 1, 1, 0, 2, 1, 1, 1, 3, 3, 3, 3, 3, 0, 1, 3, 3, 3, 0, 3, 0, 3, 1, 1, 0, 3, 1, 3, 3, 3, 0, 1, 3, 1, 0, 1, 1, 3, 0, 1, 3, 1, 3, 1, 0, 3, 3, 0, 3, 3, 3, 4, 5, 3, 3, 1, 3, 3, 1, 0, 0, 3, 0, 4, 4, 0, 0, 3, 3, 0, 1, 3, 3, 0, 3, 0, 1, 1, 3, 0, 3, 1, 3, 3, 0, 3, 3, 1, 1, 3, 3, 0, 1, 0, 1, 3, 1, 0, 1, 3, 1, 3, 1, 0, 3, 0, 3, 0, 0, 1, 3, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 3, 1, 1, 1, 3, 0, 1, 3, 1, 0, 0, 0, 3, 0, 1, 3, 1, 3, 1, 1, 1, 5, 3, 0, 0, 3, 1, 3, 0, 0, 3, 0, 0, 1, 1, 1, 1, 3, 1, 3, 3, 3, 1, 1, 1, 0, 1, 1, 1, 0, 3, 0, 3, 0, 1, 3, 1, 0, 0, 1, 2, 0, 1, 0, 3, 0, 1, 3, 3, 1, 0, 3, 1, 0, 0, 0, 3, 1, 3, 0, 0, 0, 3, 0, 1, 3, 1, 1, 1, 0, 3, 1, 1, 3, 1, 1, 3, 0, 3, 0, 0, 1, 1, 3, 6, 1, 0, 0, 1, 3, 1, 0, 1, 1, 3, 3, 0, 1, 3, 1, 1]
Centroids: [[-1.4485137, 0.7100992], [1.443888, -0.54638284], [1.0674042, 3.4934478]]
Centroids: [[1.4312844, -0.6118255], [1.0411931, 3.5053494], [-2.44454, -0.5287512], [-1.4085126, 0.6932912], [2.3347914, 2.9903755], [-1.2832985, 2.8937502], [3.7352667, 0.9313438]]
Contingency Matrix: 
[[  0   0   3  94   0   2   0]
 [ 86   0   0   1   1   0   1]
 [  0 110   0   0   2   0   0]]
[[0, 0, 3, 94, 0, 2, 0], [86, 0, 0, 1, 1, 0, 1], [0, 110, 0, 0, 2, 0, 0]]
[[0, 0, 3, 94, 0, 2, 0], [86, 0, 0, 1, 1, 0, 1], [0, 110, 0, 0, 2, 0, 0]]
[0, 1, 2, 3, 4, 5, 6]
[[0, -1, 3, 94, 0, 2, 0], [86, -1, 0, 1, 1, 0, 1], [-1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1], [86, -1, 0, -1, 1, 0, 1], [-1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {2: 1, 0: 3, 1: 0}
New Contingency Matrix: 
[[ 94   0   0   3   0   2   0]
 [  1  86   0   0   1   0   1]
 [  0   0 110   0   2   0   0]]
New Clustered Label Sequence: [3, 0, 1, 2, 4, 5, 6]
Diagonal_Elements: [94, 86, 110], Sum: 290
All_Elements: [94, 0, 0, 3, 0, 2, 0, 1, 86, 0, 0, 1, 0, 1, 0, 0, 110, 0, 2, 0, 0], Sum: 300
Accuracy: 0.9666666666666667
