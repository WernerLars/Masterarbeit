Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_4_opt
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_4_opt/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt/2023_04_23-11_33_18
Punishment_Coefficient: 0.9
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002425B5937B8>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.14675897359848022
Online_Training [2/700]: mean_loss=0.19658895768225193
Online_Training [3/700]: mean_loss=0.14613459818065166
Online_Training [4/700]: mean_loss=0.03712200187146664
Online_Training [5/700]: mean_loss=0.216490613296628
Online_Training [6/700]: mean_loss=0.05902352975681424
Online_Training [7/700]: mean_loss=0.09162152465432882
Online_Training [8/700]: mean_loss=0.06397021468728781
Online_Training [9/700]: mean_loss=0.14157610572874546
Online_Training [10/700]: mean_loss=0.13601074554026127
Online_Training [11/700]: mean_loss=0.05993156647309661
Online_Training [12/700]: mean_loss=0.06913080904632807
Online_Training [13/700]: mean_loss=0.076758973300457
Online_Training [14/700]: mean_loss=0.053707890678197145
Online_Training [15/700]: mean_loss=0.04487564694136381
Online_Training [16/700]: mean_loss=0.13696200214326382
Online_Training [17/700]: mean_loss=0.12335748597979546
Online_Training [18/700]: mean_loss=0.06623268825933337
Online_Training [19/700]: mean_loss=0.038011109456419945
Online_Training [20/700]: mean_loss=0.16790995374321938
Online_Training [21/700]: mean_loss=0.1365222381427884
Online_Training [22/700]: mean_loss=0.0457063764333725
Online_Training [23/700]: mean_loss=0.021893511060625315
Online_Training [24/700]: mean_loss=0.0814432566985488
Online_Training [25/700]: mean_loss=0.04671625839546323
Online_Training [26/700]: mean_loss=0.06426813546568155
Online_Training [27/700]: mean_loss=0.08248582389205694
Online_Training [28/700]: mean_loss=0.04343444714322686
Online_Training [29/700]: mean_loss=0.04021838586777449
Online_Training [30/700]: mean_loss=0.030106220161542296
Online_Training [31/700]: mean_loss=0.027862092945724726
Online_Training [32/700]: mean_loss=0.04761272296309471
Online_Training [33/700]: mean_loss=0.02474319306202233
Online_Training [34/700]: mean_loss=0.14042751863598824
Online_Training [35/700]: mean_loss=0.05341070331633091
Online_Training [36/700]: mean_loss=0.06930425949394703
Online_Training [37/700]: mean_loss=0.047493670135736465
Online_Training [38/700]: mean_loss=0.038889593444764614
Online_Training [39/700]: mean_loss=0.09128091763705015
Online_Training [40/700]: mean_loss=0.0312313970644027
Online_Training [41/700]: mean_loss=0.021305365720763803
Online_Training [42/700]: mean_loss=0.042615808080881834
Online_Training [43/700]: mean_loss=0.07981925085186958
Online_Training [44/700]: mean_loss=0.08988260757178068
Online_Training [45/700]: mean_loss=0.057210348546504974
Online_Training [46/700]: mean_loss=0.03342739422805607
Online_Training [47/700]: mean_loss=0.03950282512232661
Online_Training [48/700]: mean_loss=0.06323342118412256
Online_Training [49/700]: mean_loss=0.035320037277415395
Online_Training [50/700]: mean_loss=0.05269968044012785
Online_Training [51/700]: mean_loss=0.017778035486117005
Online_Training [52/700]: mean_loss=0.05344944866374135
Online_Training [53/700]: mean_loss=0.017040945822373033
Online_Training [54/700]: mean_loss=0.04682842083275318
Online_Training [55/700]: mean_loss=0.01935674494598061
Online_Training [56/700]: mean_loss=0.03696553921326995
Online_Training [57/700]: mean_loss=0.07706133043393493
Online_Training [58/700]: mean_loss=0.11165013071149588
Online_Training [59/700]: mean_loss=0.08304761443287134
Online_Training [60/700]: mean_loss=0.04906434891745448
Online_Training [61/700]: mean_loss=0.03058775537647307
Online_Training [62/700]: mean_loss=0.0974783655256033
Online_Training [63/700]: mean_loss=0.0417992495931685
Online_Training [64/700]: mean_loss=0.003791841969359666
Online_Training [65/700]: mean_loss=0.04057050868868828
Online_Training [66/700]: mean_loss=0.04166766442358494
Online_Training [67/700]: mean_loss=0.06004768284037709
Online_Training [68/700]: mean_loss=0.025414718547835946
Online_Training [69/700]: mean_loss=0.030483533861115575
Online_Training [70/700]: mean_loss=0.03695998573675752
Online_Training [71/700]: mean_loss=0.07541396003216505
Online_Training [72/700]: mean_loss=0.07275609858334064
Online_Training [73/700]: mean_loss=0.04091242095455527
Online_Training [74/700]: mean_loss=0.02676369179971516
Online_Training [75/700]: mean_loss=0.02344044065102935
Online_Training [76/700]: mean_loss=0.015327988076023757
Online_Training [77/700]: mean_loss=0.03402478713542223
Online_Training [78/700]: mean_loss=0.019605338806286454
Online_Training [79/700]: mean_loss=0.03434473555535078
Online_Training [80/700]: mean_loss=0.028160007670521736
Online_Training [81/700]: mean_loss=0.017891230527311563
Online_Training [82/700]: mean_loss=0.01788692967966199
Online_Training [83/700]: mean_loss=0.013555762940086424
Online_Training [84/700]: mean_loss=0.03007736918516457
Online_Training [85/700]: mean_loss=0.02307979459874332
Online_Training [86/700]: mean_loss=0.027017113519832492
Online_Training [87/700]: mean_loss=0.013360325479879975
Online_Training [88/700]: mean_loss=0.0185641577700153
Online_Training [89/700]: mean_loss=0.026577841490507126
Online_Training [90/700]: mean_loss=0.013998630223795772
Online_Training [91/700]: mean_loss=0.018656309926882386
Online_Training [92/700]: mean_loss=0.02661398146301508
Online_Training [93/700]: mean_loss=0.022887228289619088
Online_Training [94/700]: mean_loss=0.037339300848543644
Online_Training [95/700]: mean_loss=0.024818811798468232
Online_Training [96/700]: mean_loss=0.02292377082630992
Online_Training [97/700]: mean_loss=0.023162483470514417
Online_Training [98/700]: mean_loss=0.03700445406138897
Online_Training [99/700]: mean_loss=0.02059601922519505
Online_Training [100/700]: mean_loss=0.04643614776432514
Online_Training [101/700]: mean_loss=0.017634288175031543
Online_Training [102/700]: mean_loss=0.04133985470980406
Online_Training [103/700]: mean_loss=0.028701384318992496
Online_Training [104/700]: mean_loss=0.03566064964979887
Online_Training [105/700]: mean_loss=0.01700073666870594
Online_Training [106/700]: mean_loss=0.010894555249251425
Online_Training [107/700]: mean_loss=0.01144012063741684
Online_Training [108/700]: mean_loss=0.015946705592796206
Online_Training [109/700]: mean_loss=0.028769672382622957
Online_Training [110/700]: mean_loss=0.02179936459288001
Online_Training [111/700]: mean_loss=0.022187027148902416
Online_Training [112/700]: mean_loss=0.09871989022940397
Online_Training [113/700]: mean_loss=0.023458322742953897
Online_Training [114/700]: mean_loss=0.013246533344499767
Online_Training [115/700]: mean_loss=0.04975650925189257
Online_Training [116/700]: mean_loss=0.022394681116566062
Online_Training [117/700]: mean_loss=0.04132336284965277
Online_Training [118/700]: mean_loss=0.015212823986075819
Online_Training [119/700]: mean_loss=0.13276741467416286
Online_Training [120/700]: mean_loss=0.06410901295021176
Online_Training [121/700]: mean_loss=0.03414200316183269
Online_Training [122/700]: mean_loss=0.041675534565001726
Online_Training [123/700]: mean_loss=0.02315308665856719
Online_Training [124/700]: mean_loss=0.017218812950886786
Online_Training [125/700]: mean_loss=0.07766814343631268
Online_Training [126/700]: mean_loss=0.03655801713466644
Online_Training [127/700]: mean_loss=0.02348827407695353
Online_Training [128/700]: mean_loss=0.022565030958503485
Online_Training [129/700]: mean_loss=0.016956512350589037
Online_Training [130/700]: mean_loss=0.026295172050595284
Online_Training [131/700]: mean_loss=0.019397434312850237
Online_Training [132/700]: mean_loss=0.018805273459292948
Online_Training [133/700]: mean_loss=0.023146865190938115
Online_Training [134/700]: mean_loss=0.008808425976894796
Online_Training [135/700]: mean_loss=0.11171941179782152
Online_Training [136/700]: mean_loss=0.015137326437979937
Online_Training [137/700]: mean_loss=0.0191515606129542
Online_Training [138/700]: mean_loss=0.0136992676416412
Online_Training [139/700]: mean_loss=0.01773977989796549
Online_Training [140/700]: mean_loss=0.021540137007832527
Online_Training [141/700]: mean_loss=0.04166776267811656
Online_Training [142/700]: mean_loss=0.018673720420338213
Online_Training [143/700]: mean_loss=0.020637727808207273
Online_Training [144/700]: mean_loss=0.00869155244436115
Online_Training [145/700]: mean_loss=0.02289487957023084
Online_Training [146/700]: mean_loss=0.01962184952571988
Online_Training [147/700]: mean_loss=0.016813618130981922
Online_Training [148/700]: mean_loss=0.033902119379490614
Online_Training [149/700]: mean_loss=0.05069219134747982
Online_Training [150/700]: mean_loss=0.04597313888370991
Online_Training [151/700]: mean_loss=0.018553501344285905
Online_Training [152/700]: mean_loss=0.01611008809413761
Online_Training [153/700]: mean_loss=0.02119063283316791
Online_Training [154/700]: mean_loss=0.01665735791902989
Online_Training [155/700]: mean_loss=0.011243793182075024
Online_Training [156/700]: mean_loss=0.01770120277069509
Online_Training [157/700]: mean_loss=0.13536369800567627
Online_Training [158/700]: mean_loss=0.007342242985032499
Online_Training [159/700]: mean_loss=0.026797428959980607
Online_Training [160/700]: mean_loss=0.021943422267213464
Online_Training [161/700]: mean_loss=0.027821322437375784
Online_Training [162/700]: mean_loss=0.013307468849234283
Online_Training [163/700]: mean_loss=0.0511768632568419
Online_Training [164/700]: mean_loss=0.019255208782851696
Online_Training [165/700]: mean_loss=0.009373190288897604
Online_Training [166/700]: mean_loss=0.01821879216004163
Online_Training [167/700]: mean_loss=0.02985403616912663
Online_Training [168/700]: mean_loss=0.03733438206836581
Online_Training [169/700]: mean_loss=0.05194031307473779
Online_Training [170/700]: mean_loss=0.18136954307556152
Online_Training [171/700]: mean_loss=0.015052521950565279
Online_Training [172/700]: mean_loss=0.013353120419196784
Online_Training [173/700]: mean_loss=0.01990163209848106
Online_Training [174/700]: mean_loss=0.011716029839590192
Online_Training [175/700]: mean_loss=0.010368248331360519
Online_Training [176/700]: mean_loss=0.007987544988282025
Online_Training [177/700]: mean_loss=0.023861035238951445
Online_Training [178/700]: mean_loss=0.03379242168739438
Online_Training [179/700]: mean_loss=0.017693003173917532
Online_Training [180/700]: mean_loss=0.016047297045588493
Online_Training [181/700]: mean_loss=0.013692928943783045
Online_Training [182/700]: mean_loss=0.03204981214366853
Online_Training [183/700]: mean_loss=0.012465032748878002
Online_Training [184/700]: mean_loss=0.004572909616399556
Online_Training [185/700]: mean_loss=0.026729835430160165
Online_Training [186/700]: mean_loss=0.032124934485182166
Online_Training [187/700]: mean_loss=0.02481312328018248
Online_Training [188/700]: mean_loss=0.02380849700421095
Online_Training [189/700]: mean_loss=0.058676119428128004
Online_Training [190/700]: mean_loss=0.021094375988468528
Online_Training [191/700]: mean_loss=0.15423513017594814
Online_Training [192/700]: mean_loss=0.02588999830186367
Online_Training [193/700]: mean_loss=0.02537600789219141
Online_Training [194/700]: mean_loss=0.009613717149477452
Online_Training [195/700]: mean_loss=0.03207036969251931
Online_Training [196/700]: mean_loss=0.014693074976094067
Online_Training [197/700]: mean_loss=0.02088090986944735
Online_Training [198/700]: mean_loss=0.017393789486959577
Online_Training [199/700]: mean_loss=0.09386585932224989
Online_Training [200/700]: mean_loss=0.01861177757382393
Online_Training [201/700]: mean_loss=0.02846422465518117
Online_Training [202/700]: mean_loss=0.011958640301600099
Online_Training [203/700]: mean_loss=0.011513704084791243
Online_Training [204/700]: mean_loss=0.010447541018947959
Online_Training [205/700]: mean_loss=0.05865115998312831
Online_Training [206/700]: mean_loss=0.01173877774272114
Online_Training [207/700]: mean_loss=0.03835810301825404
Online_Training [208/700]: mean_loss=0.03635374456644058
Online_Training [209/700]: mean_loss=0.05312279751524329
Online_Training [210/700]: mean_loss=0.029477143893018365
Online_Training [211/700]: mean_loss=0.011587725253775716
Online_Training [212/700]: mean_loss=0.09816097747534513
Online_Training [213/700]: mean_loss=0.0400208979845047
Online_Training [214/700]: mean_loss=0.011156992753967643
Online_Training [215/700]: mean_loss=0.02898859791457653
Online_Training [216/700]: mean_loss=0.02611485938541591
Online_Training [217/700]: mean_loss=0.010208000196143985
Online_Training [218/700]: mean_loss=0.008572846127208322
Online_Training [219/700]: mean_loss=0.04289326537400484
Online_Training [220/700]: mean_loss=0.013788943644613028
Online_Training [221/700]: mean_loss=0.03233351814560592
Online_Training [222/700]: mean_loss=0.013461778522469103
Online_Training [223/700]: mean_loss=0.030326546635478735
Online_Training [224/700]: mean_loss=0.007364864402916282
Online_Training [225/700]: mean_loss=0.02362783905118704
Online_Training [226/700]: mean_loss=0.02330112108029425
Online_Training [227/700]: mean_loss=0.014535286813043058
Online_Training [228/700]: mean_loss=0.02734413743019104
Online_Training [229/700]: mean_loss=0.039064477663487196
Online_Training [230/700]: mean_loss=0.014048820012249053
Online_Training [231/700]: mean_loss=0.02228078688494861
Online_Training [232/700]: mean_loss=0.019640046637505293
Online_Training [233/700]: mean_loss=0.01212494506035
Online_Training [234/700]: mean_loss=0.02108108508400619
Online_Training [235/700]: mean_loss=0.09147996827960014
Online_Training [236/700]: mean_loss=0.052834514528512955
Online_Training [237/700]: mean_loss=0.031104091554880142
Online_Training [238/700]: mean_loss=0.10133790131658316
Online_Training [239/700]: mean_loss=0.11302953958511353
Online_Training [240/700]: mean_loss=0.03473837999626994
Online_Training [241/700]: mean_loss=0.04570145416073501
Online_Training [242/700]: mean_loss=0.04025966580957174
Online_Training [243/700]: mean_loss=0.0390964956022799
Online_Training [244/700]: mean_loss=0.017189334495924413
Online_Training [245/700]: mean_loss=0.032524987356737256
Online_Training [246/700]: mean_loss=0.017940433230251074
Online_Training [247/700]: mean_loss=0.00852318323450163
Online_Training [248/700]: mean_loss=0.07829906046390533
Online_Training [249/700]: mean_loss=0.011178698914591223
Online_Training [250/700]: mean_loss=0.01773475855588913
Online_Training [251/700]: mean_loss=0.011588040622882545
Online_Training [252/700]: mean_loss=0.014738979516550899
Online_Training [253/700]: mean_loss=0.015642395126633346
Online_Training [254/700]: mean_loss=0.017476713052019477
Online_Training [255/700]: mean_loss=0.03624006034806371
Online_Training [256/700]: mean_loss=0.019294412340968847
Online_Training [257/700]: mean_loss=0.013603627099655569
Online_Training [258/700]: mean_loss=0.025763287907466292
Online_Training [259/700]: mean_loss=0.011544198961928487
Online_Training [260/700]: mean_loss=0.006132053036708385
Online_Training [261/700]: mean_loss=0.022410430014133453
Online_Training [262/700]: mean_loss=0.026348914485424757
Online_Training [263/700]: mean_loss=0.01371781004127115
Online_Training [264/700]: mean_loss=0.017137105111032724
Online_Training [265/700]: mean_loss=0.017559533240273595
Online_Training [266/700]: mean_loss=0.01282766810618341
Online_Training [267/700]: mean_loss=0.012493492104113102
Online_Training [268/700]: mean_loss=0.004496888432186097
Online_Training [269/700]: mean_loss=0.015267503098584712
Online_Training [270/700]: mean_loss=0.017918715719133615
Online_Training [271/700]: mean_loss=0.0246631542686373
Online_Training [272/700]: mean_loss=0.014720951323397458
Online_Training [273/700]: mean_loss=0.007899804564658552
Online_Training [274/700]: mean_loss=0.012667536037042737
Online_Training [275/700]: mean_loss=0.012065946240909398
Online_Training [276/700]: mean_loss=0.01250472164247185
Online_Training [277/700]: mean_loss=0.016714030178263783
Online_Training [278/700]: mean_loss=0.019887266913428903
Online_Training [279/700]: mean_loss=0.01390955236274749
Online_Training [280/700]: mean_loss=0.019599043997004628
Online_Training [281/700]: mean_loss=0.02045599021948874
Online_Training [282/700]: mean_loss=0.028988106874749064
Online_Training [283/700]: mean_loss=0.02198891993612051
Online_Training [284/700]: mean_loss=0.013692009262740612
Online_Training [285/700]: mean_loss=0.018436550861224532
Online_Training [286/700]: mean_loss=0.013390933279879391
Online_Training [287/700]: mean_loss=0.018901597941294312
Online_Training [288/700]: mean_loss=0.01356249232776463
Online_Training [289/700]: mean_loss=0.03599607665091753
Online_Training [290/700]: mean_loss=0.006187983555719256
Online_Training [291/700]: mean_loss=0.011187441064976156
Online_Training [292/700]: mean_loss=0.007689570833463222
Online_Training [293/700]: mean_loss=0.013225927366875112
Online_Training [294/700]: mean_loss=0.015401029726490378
Online_Training [295/700]: mean_loss=0.03444680548273027
Online_Training [296/700]: mean_loss=0.035006217658519745
Online_Training [297/700]: mean_loss=0.019630863796919584
Online_Training [298/700]: mean_loss=0.015671541215851903
Online_Training [299/700]: mean_loss=0.016537356423214078
Online_Training [300/700]: mean_loss=0.037342369090765715
Online_Training [301/700]: mean_loss=0.014195769210346043
Online_Training [302/700]: mean_loss=0.017571524251252413
Online_Training [303/700]: mean_loss=0.019547070609405637
Online_Training [304/700]: mean_loss=0.007768237730488181
Online_Training [305/700]: mean_loss=0.05039316043257713
Online_Training [306/700]: mean_loss=0.0669840332120657
Online_Training [307/700]: mean_loss=0.06943845842033625
Online_Training [308/700]: mean_loss=0.02434362261556089
Online_Training [309/700]: mean_loss=0.009029616136103868
Online_Training [310/700]: mean_loss=0.009266772773116827
Online_Training [311/700]: mean_loss=0.012660910957492888
Online_Training [312/700]: mean_loss=0.05376986274495721
Online_Training [313/700]: mean_loss=0.015501422225497663
Online_Training [314/700]: mean_loss=0.009948938386514783
Online_Training [315/700]: mean_loss=0.009824915381614119
Online_Training [316/700]: mean_loss=0.017648798879235983
Online_Training [317/700]: mean_loss=0.00720067328074947
Online_Training [318/700]: mean_loss=0.01660839666146785
Online_Training [319/700]: mean_loss=0.020989595679566264
Online_Training [320/700]: mean_loss=0.010446164291352034
Online_Training [321/700]: mean_loss=0.02108973846770823
Online_Training [322/700]: mean_loss=0.029242777731269598
Online_Training [323/700]: mean_loss=0.01709301781374961
Online_Training [324/700]: mean_loss=0.02495885849930346
Online_Training [325/700]: mean_loss=0.02608232945203781
Online_Training [326/700]: mean_loss=0.014134267927147448
Online_Training [327/700]: mean_loss=0.024209619034081697
Online_Training [328/700]: mean_loss=0.019562561763450503
Online_Training [329/700]: mean_loss=0.012325061368755996
Online_Training [330/700]: mean_loss=0.03400770202279091
Online_Training [331/700]: mean_loss=0.017158095841296017
Online_Training [332/700]: mean_loss=0.02171421842649579
Online_Training [333/700]: mean_loss=0.008720375713892281
Online_Training [334/700]: mean_loss=0.00963364407652989
Online_Training [335/700]: mean_loss=0.063959791790694
Online_Training [336/700]: mean_loss=0.06317130569368601
Online_Training [337/700]: mean_loss=0.0681165368296206
Online_Training [338/700]: mean_loss=0.0344113321043551
Online_Training [339/700]: mean_loss=0.02412576845381409
Online_Training [340/700]: mean_loss=0.007893628149759024
Online_Training [341/700]: mean_loss=0.025442814687266946
Online_Training [342/700]: mean_loss=0.051095040049403906
Online_Training [343/700]: mean_loss=0.014351741061545908
Online_Training [344/700]: mean_loss=0.020869181724265218
Online_Training [345/700]: mean_loss=0.032814791426062584
Online_Training [346/700]: mean_loss=0.02106532920151949
Online_Training [347/700]: mean_loss=0.1323809875175357
Online_Training [348/700]: mean_loss=0.017113952315412462
Online_Training [349/700]: mean_loss=0.027376274345442653
Online_Training [350/700]: mean_loss=0.010127124260179698
Online_Training [351/700]: mean_loss=0.008794822555501014
Online_Training [352/700]: mean_loss=0.01092377316672355
Online_Training [353/700]: mean_loss=0.013259207713417709
Online_Training [354/700]: mean_loss=0.022010845597833395
Online_Training [355/700]: mean_loss=0.012830356834456325
Online_Training [356/700]: mean_loss=0.01665479503571987
Online_Training [357/700]: mean_loss=0.08288125973194838
Online_Training [358/700]: mean_loss=0.06663252506405115
Online_Training [359/700]: mean_loss=0.08761411719024181
Online_Training [360/700]: mean_loss=0.02808338846080005
Online_Training [361/700]: mean_loss=0.02372700092382729
Online_Training [362/700]: mean_loss=0.04987328825518489
Online_Training [363/700]: mean_loss=0.017051836824975908
Online_Training [364/700]: mean_loss=0.008596564992330968
Online_Training [365/700]: mean_loss=0.018360641435720026
Online_Training [366/700]: mean_loss=0.023845469346269965
Online_Training [367/700]: mean_loss=0.024384294636547565
Online_Training [368/700]: mean_loss=0.016766791930422187
Online_Training [369/700]: mean_loss=0.011355761089362204
Online_Training [370/700]: mean_loss=0.03694797493517399
Online_Training [371/700]: mean_loss=0.007488240720704198
Online_Training [372/700]: mean_loss=0.01965650194324553
Online_Training [373/700]: mean_loss=0.016791177913546562
Online_Training [374/700]: mean_loss=0.01544856559485197
Online_Training [375/700]: mean_loss=0.018828087486326694
Online_Training [376/700]: mean_loss=0.009334033937193453
Online_Training [377/700]: mean_loss=0.017584796296432614
Online_Training [378/700]: mean_loss=0.011988313868641853
Online_Training [379/700]: mean_loss=0.014568401616998017
Online_Training [380/700]: mean_loss=0.01117537496611476
Online_Training [381/700]: mean_loss=0.017440106021240354
Online_Training [382/700]: mean_loss=0.009922682773321867
Online_Training [383/700]: mean_loss=0.00838774349540472
Online_Training [384/700]: mean_loss=0.12674638535827398
Online_Training [385/700]: mean_loss=0.007295320392586291
Online_Training [386/700]: mean_loss=0.029890817822888494
Online_Training [387/700]: mean_loss=0.0225342467892915
Online_Training [388/700]: mean_loss=0.019918645964935422
Online_Training [389/700]: mean_loss=0.009800732019357383
Online_Training [390/700]: mean_loss=0.02688709693029523
Online_Training [391/700]: mean_loss=0.007250708353240043
Online_Training [392/700]: mean_loss=0.021136284107342362
Online_Training [393/700]: mean_loss=0.015730904648080468
Online_Training [394/700]: mean_loss=0.024123232113197446
Online_Training [395/700]: mean_loss=0.00782715535024181
Online_Training [396/700]: mean_loss=0.0199172489810735
Online_Training [397/700]: mean_loss=0.010298882727511227
Online_Training [398/700]: mean_loss=0.020298587158322334
Online_Training [399/700]: mean_loss=0.016875513712875545
Online_Training [400/700]: mean_loss=0.03434953512623906
Online_Training [401/700]: mean_loss=0.013901742757298052
Online_Training [402/700]: mean_loss=0.011932944529689848
Online_Training [403/700]: mean_loss=0.012389624142087996
Online_Training [404/700]: mean_loss=0.052366120740771294
Online_Training [405/700]: mean_loss=0.06955548468977213
Online_Training [406/700]: mean_loss=0.024227198911830783
Online_Training [407/700]: mean_loss=0.028504560934379697
Online_Training [408/700]: mean_loss=0.018271313048899174
Online_Training [409/700]: mean_loss=0.006068244460038841
Online_Training [410/700]: mean_loss=0.020317791495472193
Online_Training [411/700]: mean_loss=0.021044937893748283
Online_Training [412/700]: mean_loss=0.11523259244859219
Online_Training [413/700]: mean_loss=0.0364708723500371
Online_Training [414/700]: mean_loss=0.04176071682013571
Online_Training [415/700]: mean_loss=0.01988116092979908
Online_Training [416/700]: mean_loss=0.014847461483441293
Online_Training [417/700]: mean_loss=0.05577958934009075
Online_Training [418/700]: mean_loss=0.014987763250246644
Online_Training [419/700]: mean_loss=0.014354296261444688
Online_Training [420/700]: mean_loss=0.054468206129968166
Online_Training [421/700]: mean_loss=0.03503423440270126
Online_Training [422/700]: mean_loss=0.013948686886578798
Online_Training [423/700]: mean_loss=0.03562346938997507
Online_Training [424/700]: mean_loss=0.0509357089176774
Online_Training [425/700]: mean_loss=0.022901735734194517
Online_Training [426/700]: mean_loss=0.010364726767875254
Online_Training [427/700]: mean_loss=0.01738713530357927
Online_Training [428/700]: mean_loss=0.02577589708380401
Online_Training [429/700]: mean_loss=0.011044317157939076
Online_Training [430/700]: mean_loss=0.006881862645968795
Online_Training [431/700]: mean_loss=0.010486927931196988
Online_Training [432/700]: mean_loss=0.08257910702377558
Online_Training [433/700]: mean_loss=0.019511465216055512
Online_Training [434/700]: mean_loss=0.02491298597306013
Online_Training [435/700]: mean_loss=0.018134281039237976
Online_Training [436/700]: mean_loss=0.06527100643143058
Online_Training [437/700]: mean_loss=0.014129230403341353
Online_Training [438/700]: mean_loss=0.11301294807344675
Online_Training [439/700]: mean_loss=0.04482656926847994
Online_Training [440/700]: mean_loss=0.034127710619941354
Online_Training [441/700]: mean_loss=0.038109925109893084
Online_Training [442/700]: mean_loss=0.01091509498655796
Online_Training [443/700]: mean_loss=0.020455274265259504
Online_Training [444/700]: mean_loss=0.01979629963170737
Online_Training [445/700]: mean_loss=0.024185047717764974
Online_Training [446/700]: mean_loss=0.02432500128634274
Online_Training [447/700]: mean_loss=0.011762990499846637
Online_Training [448/700]: mean_loss=0.02120642689988017
Online_Training [449/700]: mean_loss=0.019055129145272076
Online_Training [450/700]: mean_loss=0.02608476998284459
Online_Training [451/700]: mean_loss=0.02441675984300673
Online_Training [452/700]: mean_loss=0.03957582823932171
Online_Training [453/700]: mean_loss=0.06507930858060718
Online_Training [454/700]: mean_loss=0.015389069449156523
Online_Training [455/700]: mean_loss=0.04895614646375179
Online_Training [456/700]: mean_loss=0.007768870156724006
Online_Training [457/700]: mean_loss=0.00751839141594246
Online_Training [458/700]: mean_loss=0.00727459677727893
Online_Training [459/700]: mean_loss=0.01137845148332417
Online_Training [460/700]: mean_loss=0.017602283624000847
Online_Training [461/700]: mean_loss=0.025925597175955772
Online_Training [462/700]: mean_loss=0.009243657812476158
Online_Training [463/700]: mean_loss=0.004679224395658821
Online_Training [464/700]: mean_loss=0.012091258307918906
Online_Training [465/700]: mean_loss=0.07703255582600832
Online_Training [466/700]: mean_loss=0.022421505767852068
Online_Training [467/700]: mean_loss=0.016741339000873268
Online_Training [468/700]: mean_loss=0.015775624779053032
Online_Training [469/700]: mean_loss=0.02535001002252102
Online_Training [470/700]: mean_loss=0.054606396704912186
Online_Training [471/700]: mean_loss=0.02439316618256271
Online_Training [472/700]: mean_loss=0.02620235295034945
Online_Training [473/700]: mean_loss=0.005920651543419808
Online_Training [474/700]: mean_loss=0.010961438063532114
Online_Training [475/700]: mean_loss=0.00995137426070869
Online_Training [476/700]: mean_loss=0.1982429064810276
Online_Training [477/700]: mean_loss=0.08441904094070196
Online_Training [478/700]: mean_loss=0.04286515899002552
Online_Training [479/700]: mean_loss=0.010962010128423572
Online_Training [480/700]: mean_loss=0.008752865018323064
Online_Training [481/700]: mean_loss=0.016970166354440153
Online_Training [482/700]: mean_loss=0.026189208962023258
Online_Training [483/700]: mean_loss=0.01864811428822577
Online_Training [484/700]: mean_loss=0.0145447967806831
Online_Training [485/700]: mean_loss=0.006918999599292874
Online_Training [486/700]: mean_loss=0.017103492049500346
Online_Training [487/700]: mean_loss=0.030416473280638456
Online_Training [488/700]: mean_loss=0.019046074710786343
Online_Training [489/700]: mean_loss=0.014179929159581661
Online_Training [490/700]: mean_loss=0.021560918539762497
Online_Training [491/700]: mean_loss=0.030895431758835912
Online_Training [492/700]: mean_loss=0.014538348885253072
Online_Training [493/700]: mean_loss=0.019702860503457487
Online_Training [494/700]: mean_loss=0.047131676226854324
Online_Training [495/700]: mean_loss=0.009231888107024133
Online_Training [496/700]: mean_loss=0.02620746986940503
Online_Training [497/700]: mean_loss=0.017225269693881273
Online_Training [498/700]: mean_loss=0.014149685157462955
Online_Training [499/700]: mean_loss=0.01729814149439335
Online_Training [500/700]: mean_loss=0.008333771489560604
Online_Training [501/700]: mean_loss=0.012100429157726467
Online_Training [502/700]: mean_loss=0.01341104693710804
Online_Training [503/700]: mean_loss=0.0162968672811985
Online_Training [504/700]: mean_loss=0.00798347918316722
Online_Training [505/700]: mean_loss=0.01507898245472461
Online_Training [506/700]: mean_loss=0.12113725487142801
Online_Training [507/700]: mean_loss=0.08725945372134447
Online_Training [508/700]: mean_loss=0.03168530738912523
Online_Training [509/700]: mean_loss=0.016384518356062472
Online_Training [510/700]: mean_loss=0.01889152266085148
Online_Training [511/700]: mean_loss=0.005791037518065423
Online_Training [512/700]: mean_loss=0.007667641097214073
Online_Training [513/700]: mean_loss=0.05867228750139475
Online_Training [514/700]: mean_loss=0.031233908608555794
Online_Training [515/700]: mean_loss=0.05147202732041478
Online_Training [516/700]: mean_loss=0.020131252007558942
Online_Training [517/700]: mean_loss=0.02805734775029123
Online_Training [518/700]: mean_loss=0.023684638552367687
Online_Training [519/700]: mean_loss=0.007192696153651923
Online_Training [520/700]: mean_loss=0.012061403947882354
Online_Training [521/700]: mean_loss=0.026078030234202743
Online_Training [522/700]: mean_loss=0.009053688205312937
Online_Training [523/700]: mean_loss=0.02109068213030696
Online_Training [524/700]: mean_loss=0.07772799767553806
Online_Training [525/700]: mean_loss=0.02546742046251893
Online_Training [526/700]: mean_loss=0.012209216831251979
Online_Training [527/700]: mean_loss=0.014225687133148313
Online_Training [528/700]: mean_loss=0.022376862820237875
Online_Training [529/700]: mean_loss=0.027354588033631444
Online_Training [530/700]: mean_loss=0.017289862618781626
Online_Training [531/700]: mean_loss=0.02051818580366671
Online_Training [532/700]: mean_loss=0.02565795765258372
Online_Training [533/700]: mean_loss=0.012950101518072188
Online_Training [534/700]: mean_loss=0.010359122301451862
Online_Training [535/700]: mean_loss=0.026002394501119852
Online_Training [536/700]: mean_loss=0.1063031442463398
Online_Training [537/700]: mean_loss=0.009562757448293269
Online_Training [538/700]: mean_loss=0.013145091128535569
Online_Training [539/700]: mean_loss=0.005771407100837678
Online_Training [540/700]: mean_loss=0.042400521226227283
Online_Training [541/700]: mean_loss=0.11931959073990583
Online_Training [542/700]: mean_loss=0.005615839967504144
Online_Training [543/700]: mean_loss=0.02852492011152208
Online_Training [544/700]: mean_loss=0.011307337088510394
Online_Training [545/700]: mean_loss=0.028012161143124104
Online_Training [546/700]: mean_loss=0.009621097357012331
Online_Training [547/700]: mean_loss=0.0236227682325989
Online_Training [548/700]: mean_loss=0.025094768265262246
Online_Training [549/700]: mean_loss=0.006355268589686602
Online_Training [550/700]: mean_loss=0.02178208902478218
Online_Training [551/700]: mean_loss=0.020240100333467126
Online_Training [552/700]: mean_loss=0.030172668863087893
Online_Training [553/700]: mean_loss=0.03369040973484516
Online_Training [554/700]: mean_loss=0.019635670352727175
Online_Training [555/700]: mean_loss=0.02528992504812777
Online_Training [556/700]: mean_loss=0.015648772125132382
Online_Training [557/700]: mean_loss=0.016161277424544096
Online_Training [558/700]: mean_loss=0.006912602577358484
Online_Training [559/700]: mean_loss=0.0038053803727962077
Online_Training [560/700]: mean_loss=0.006756115879397839
Online_Training [561/700]: mean_loss=0.017907700035721064
Online_Training [562/700]: mean_loss=0.036794102285057306
Online_Training [563/700]: mean_loss=0.03269081632606685
Online_Training [564/700]: mean_loss=0.013377447496168315
Online_Training [565/700]: mean_loss=0.020040884846821427
Online_Training [566/700]: mean_loss=0.019384267972782254
Online_Training [567/700]: mean_loss=0.02089787437580526
Online_Training [568/700]: mean_loss=0.018178190803155303
Online_Training [569/700]: mean_loss=0.02433600602671504
Online_Training [570/700]: mean_loss=0.01268476340919733
Online_Training [571/700]: mean_loss=0.020754855126142502
Online_Training [572/700]: mean_loss=0.019194721477106214
Online_Training [573/700]: mean_loss=0.023516342043876648
Online_Training [574/700]: mean_loss=0.05161801027134061
Online_Training [575/700]: mean_loss=0.055798045825213194
Online_Training [576/700]: mean_loss=0.00954625685699284
Online_Training [577/700]: mean_loss=0.01412353792693466
Online_Training [578/700]: mean_loss=0.007304641476366669
Online_Training [579/700]: mean_loss=0.015001270221546292
Online_Training [580/700]: mean_loss=0.032652301248162985
Online_Training [581/700]: mean_loss=0.016210376983508468
Online_Training [582/700]: mean_loss=0.01184569369070232
Online_Training [583/700]: mean_loss=0.00580940704094246
Online_Training [584/700]: mean_loss=0.010959970240946859
Online_Training [585/700]: mean_loss=0.021084794076159596
Online_Training [586/700]: mean_loss=0.10851636901497841
Online_Training [587/700]: mean_loss=0.022547172149643302
Online_Training [588/700]: mean_loss=0.009578749537467957
Online_Training [589/700]: mean_loss=0.026515683624893427
Online_Training [590/700]: mean_loss=0.02128297952003777
Online_Training [591/700]: mean_loss=0.012445562635548413
Online_Training [592/700]: mean_loss=0.012148987501859665
Online_Training [593/700]: mean_loss=0.04174883058294654
Online_Training [594/700]: mean_loss=0.015462101437151432
Online_Training [595/700]: mean_loss=0.03175701410509646
Online_Training [596/700]: mean_loss=0.014233104418963194
Online_Training [597/700]: mean_loss=0.009732381324283779
Online_Training [598/700]: mean_loss=0.015480564557947218
Online_Training [599/700]: mean_loss=0.01963602635078132
Online_Training [600/700]: mean_loss=0.014700774918310344
Online_Training [601/700]: mean_loss=0.032107856357470155
Online_Training [602/700]: mean_loss=0.008907845593057573
Online_Training [603/700]: mean_loss=0.008052071381825954
Online_Training [604/700]: mean_loss=0.027012606151401997
Online_Training [605/700]: mean_loss=0.009323341655544937
Online_Training [606/700]: mean_loss=0.006145300285425037
Online_Training [607/700]: mean_loss=0.010615780600346625
Online_Training [608/700]: mean_loss=0.014368673437274992
Online_Training [609/700]: mean_loss=0.012920034467242658
Online_Training [610/700]: mean_loss=0.019969599787145853
Online_Training [611/700]: mean_loss=0.0101079709129408
Online_Training [612/700]: mean_loss=0.1254301844164729
Online_Training [613/700]: mean_loss=0.051679265685379505
Online_Training [614/700]: mean_loss=0.00728113460354507
Online_Training [615/700]: mean_loss=0.011628712876699865
Online_Training [616/700]: mean_loss=0.019017926650121808
Online_Training [617/700]: mean_loss=0.003765784786082804
Online_Training [618/700]: mean_loss=0.020671233534812927
Online_Training [619/700]: mean_loss=0.01070690166670829
Online_Training [620/700]: mean_loss=0.06764950137585402
Online_Training [621/700]: mean_loss=0.007055224443320185
Online_Training [622/700]: mean_loss=0.04814803693443537
Online_Training [623/700]: mean_loss=0.03924541175365448
Online_Training [624/700]: mean_loss=0.012969182105734944
Online_Training [625/700]: mean_loss=0.01049899053759873
Online_Training [626/700]: mean_loss=0.012039167690090835
Online_Training [627/700]: mean_loss=0.009777663508430123
Online_Training [628/700]: mean_loss=0.009147880831733346
Online_Training [629/700]: mean_loss=0.020904992939904332
Online_Training [630/700]: mean_loss=0.04884406132623553
Online_Training [631/700]: mean_loss=0.01431752450298518
Online_Training [632/700]: mean_loss=0.026922485791146755
Online_Training [633/700]: mean_loss=0.013043082202784717
Online_Training [634/700]: mean_loss=0.012494383729062974
Online_Training [635/700]: mean_loss=0.014579293900169432
Online_Training [636/700]: mean_loss=0.006095097574871033
Online_Training [637/700]: mean_loss=0.009195842314511538
Online_Training [638/700]: mean_loss=0.024853394366800785
Online_Training [639/700]: mean_loss=0.017915504751726985
Online_Training [640/700]: mean_loss=0.008284040726721287
Online_Training [641/700]: mean_loss=0.02108917897567153
Online_Training [642/700]: mean_loss=0.01211751182563603
Online_Training [643/700]: mean_loss=0.006179024640005082
Online_Training [644/700]: mean_loss=0.01092530123423785
Online_Training [645/700]: mean_loss=0.014083453570492566
Online_Training [646/700]: mean_loss=0.03437751275487244
Online_Training [647/700]: mean_loss=0.00879633636213839
Online_Training [648/700]: mean_loss=0.011680887080729008
Online_Training [649/700]: mean_loss=0.009162851609289646
Online_Training [650/700]: mean_loss=0.014855877263471484
Online_Training [651/700]: mean_loss=0.007526398345362395
Online_Training [652/700]: mean_loss=0.009439294750336558
Online_Training [653/700]: mean_loss=0.10277007706463337
Online_Training [654/700]: mean_loss=0.01396860892418772
Online_Training [655/700]: mean_loss=0.023627995746210217
Online_Training [656/700]: mean_loss=0.019887740956619382
Online_Training [657/700]: mean_loss=0.02128725766669959
Online_Training [658/700]: mean_loss=0.010944208013825119
Online_Training [659/700]: mean_loss=0.01381655188743025
Online_Training [660/700]: mean_loss=0.01445756177417934
Online_Training [661/700]: mean_loss=0.0393505129031837
Online_Training [662/700]: mean_loss=0.05506156152114272
Online_Training [663/700]: mean_loss=0.019869314273819327
Online_Training [664/700]: mean_loss=0.0067608345416374505
Online_Training [665/700]: mean_loss=0.03522992483340204
Online_Training [666/700]: mean_loss=0.025033810641616583
Online_Training [667/700]: mean_loss=0.006655466044321656
Online_Training [668/700]: mean_loss=0.012013251311145723
Online_Training [669/700]: mean_loss=0.00942838506307453
Online_Training [670/700]: mean_loss=0.01264976675156504
Online_Training [671/700]: mean_loss=0.017276737140491605
Online_Training [672/700]: mean_loss=0.008146268897689879
Online_Training [673/700]: mean_loss=0.011694328277371824
Online_Training [674/700]: mean_loss=0.007380339258816093
Online_Training [675/700]: mean_loss=0.009931730106472969
Online_Training [676/700]: mean_loss=0.03229952580295503
Online_Training [677/700]: mean_loss=0.04289199272170663
Online_Training [678/700]: mean_loss=0.019954244140535593
Online_Training [679/700]: mean_loss=0.01761249639093876
Online_Training [680/700]: mean_loss=0.011565930675715208
Online_Training [681/700]: mean_loss=0.01890918775461614
Online_Training [682/700]: mean_loss=0.012309246929362416
Online_Training [683/700]: mean_loss=0.0061161486664786935
Online_Training [684/700]: mean_loss=0.007686674187425524
Online_Training [685/700]: mean_loss=0.02758235391229391
Online_Training [686/700]: mean_loss=0.011848623864352703
Online_Training [687/700]: mean_loss=0.01732583693228662
Online_Training [688/700]: mean_loss=0.056054385378956795
Online_Training [689/700]: mean_loss=0.012901277979835868
Online_Training [690/700]: mean_loss=0.007988439174368978
Online_Training [691/700]: mean_loss=0.012528079678304493
Online_Training [692/700]: mean_loss=0.028162868693470955
Online_Training [693/700]: mean_loss=0.014856178313493729
Online_Training [694/700]: mean_loss=0.03111786930821836
Online_Training [695/700]: mean_loss=0.01102411700412631
Online_Training [696/700]: mean_loss=0.02676194766536355
Online_Training [697/700]: mean_loss=0.004776465124450624
Online_Training [698/700]: mean_loss=0.007672363892197609
Online_Training [699/700]: mean_loss=0.07240801397711039
Online_Training [700/700]: mean_loss=0.006644410663284361
Q_Learning [1/300]: mean_loss=0.14675897359848022
Q_Learning [2/300]: mean_loss=0.19658895768225193
Q_Learning [3/300]: mean_loss=0.14613459818065166
Q_Learning [4/300]: mean_loss=0.03712200187146664
Q_Learning [5/300]: mean_loss=0.216490613296628
Q_Learning [6/300]: mean_loss=0.05902352975681424
Q_Learning [7/300]: mean_loss=0.09162152465432882
Q_Learning [8/300]: mean_loss=0.06397021468728781
Q_Learning [9/300]: mean_loss=0.14157610572874546
Q_Learning [10/300]: mean_loss=0.13601074554026127
Q_Learning [11/300]: mean_loss=0.05993156647309661
Q_Learning [12/300]: mean_loss=0.06913080904632807
Q_Learning [13/300]: mean_loss=0.076758973300457
Q_Learning [14/300]: mean_loss=0.053707890678197145
Q_Learning [15/300]: mean_loss=0.04487564694136381
Q_Learning [16/300]: mean_loss=0.13696200214326382
Q_Learning [17/300]: mean_loss=0.12335748597979546
Q_Learning [18/300]: mean_loss=0.06623268825933337
Q_Learning [19/300]: mean_loss=0.038011109456419945
Q_Learning [20/300]: mean_loss=0.16790995374321938
Q_Learning [21/300]: mean_loss=0.1365222381427884
Q_Learning [22/300]: mean_loss=0.0457063764333725
Q_Learning [23/300]: mean_loss=0.021893511060625315
Q_Learning [24/300]: mean_loss=0.0814432566985488
Q_Learning [25/300]: mean_loss=0.04671625839546323
Q_Learning [26/300]: mean_loss=0.06426813546568155
Q_Learning [27/300]: mean_loss=0.08248582389205694
Q_Learning [28/300]: mean_loss=0.04343444714322686
Q_Learning [29/300]: mean_loss=0.04021838586777449
Q_Learning [30/300]: mean_loss=0.030106220161542296
Q_Learning [31/300]: mean_loss=0.027862092945724726
Q_Learning [32/300]: mean_loss=0.04761272296309471
Q_Learning [33/300]: mean_loss=0.02474319306202233
Q_Learning [34/300]: mean_loss=0.14042751863598824
Q_Learning [35/300]: mean_loss=0.05341070331633091
Q_Learning [36/300]: mean_loss=0.06930425949394703
Q_Learning [37/300]: mean_loss=0.047493670135736465
Q_Learning [38/300]: mean_loss=0.038889593444764614
Q_Learning [39/300]: mean_loss=0.09128091763705015
Q_Learning [40/300]: mean_loss=0.0312313970644027
Q_Learning [41/300]: mean_loss=0.021305365720763803
Q_Learning [42/300]: mean_loss=0.042615808080881834
Q_Learning [43/300]: mean_loss=0.07981925085186958
Q_Learning [44/300]: mean_loss=0.08988260757178068
Q_Learning [45/300]: mean_loss=0.057210348546504974
Q_Learning [46/300]: mean_loss=0.03342739422805607
Q_Learning [47/300]: mean_loss=0.03950282512232661
Q_Learning [48/300]: mean_loss=0.06323342118412256
Q_Learning [49/300]: mean_loss=0.035320037277415395
Q_Learning [50/300]: mean_loss=0.05269968044012785
Q_Learning [51/300]: mean_loss=0.017778035486117005
Q_Learning [52/300]: mean_loss=0.05344944866374135
Q_Learning [53/300]: mean_loss=0.017040945822373033
Q_Learning [54/300]: mean_loss=0.04682842083275318
Q_Learning [55/300]: mean_loss=0.01935674494598061
Q_Learning [56/300]: mean_loss=0.03696553921326995
Q_Learning [57/300]: mean_loss=0.07706133043393493
Q_Learning [58/300]: mean_loss=0.11165013071149588
Q_Learning [59/300]: mean_loss=0.08304761443287134
Q_Learning [60/300]: mean_loss=0.04906434891745448
Q_Learning [61/300]: mean_loss=0.03058775537647307
Q_Learning [62/300]: mean_loss=0.0974783655256033
Q_Learning [63/300]: mean_loss=0.0417992495931685
Q_Learning [64/300]: mean_loss=0.003791841969359666
Q_Learning [65/300]: mean_loss=0.04057050868868828
Q_Learning [66/300]: mean_loss=0.04166766442358494
Q_Learning [67/300]: mean_loss=0.06004768284037709
Q_Learning [68/300]: mean_loss=0.025414718547835946
Q_Learning [69/300]: mean_loss=0.030483533861115575
Q_Learning [70/300]: mean_loss=0.03695998573675752
Q_Learning [71/300]: mean_loss=0.07541396003216505
Q_Learning [72/300]: mean_loss=0.07275609858334064
Q_Learning [73/300]: mean_loss=0.04091242095455527
Q_Learning [74/300]: mean_loss=0.02676369179971516
Q_Learning [75/300]: mean_loss=0.02344044065102935
Q_Learning [76/300]: mean_loss=0.015327988076023757
Q_Learning [77/300]: mean_loss=0.03402478713542223
Q_Learning [78/300]: mean_loss=0.019605338806286454
Q_Learning [79/300]: mean_loss=0.03434473555535078
Q_Learning [80/300]: mean_loss=0.028160007670521736
Q_Learning [81/300]: mean_loss=0.017891230527311563
Q_Learning [82/300]: mean_loss=0.01788692967966199
Q_Learning [83/300]: mean_loss=0.013555762940086424
Q_Learning [84/300]: mean_loss=0.03007736918516457
Q_Learning [85/300]: mean_loss=0.02307979459874332
Q_Learning [86/300]: mean_loss=0.027017113519832492
Q_Learning [87/300]: mean_loss=0.013360325479879975
Q_Learning [88/300]: mean_loss=0.0185641577700153
Q_Learning [89/300]: mean_loss=0.026577841490507126
Q_Learning [90/300]: mean_loss=0.013998630223795772
Q_Learning [91/300]: mean_loss=0.018656309926882386
Q_Learning [92/300]: mean_loss=0.02661398146301508
Q_Learning [93/300]: mean_loss=0.022887228289619088
Q_Learning [94/300]: mean_loss=0.037339300848543644
Q_Learning [95/300]: mean_loss=0.024818811798468232
Q_Learning [96/300]: mean_loss=0.02292377082630992
Q_Learning [97/300]: mean_loss=0.023162483470514417
Q_Learning [98/300]: mean_loss=0.03700445406138897
Q_Learning [99/300]: mean_loss=0.02059601922519505
Q_Learning [100/300]: mean_loss=0.04643614776432514
Q_Learning [101/300]: mean_loss=0.017634288175031543
Q_Learning [102/300]: mean_loss=0.04133985470980406
Q_Learning [103/300]: mean_loss=0.028701384318992496
Q_Learning [104/300]: mean_loss=0.03566064964979887
Q_Learning [105/300]: mean_loss=0.01700073666870594
Q_Learning [106/300]: mean_loss=0.010894555249251425
Q_Learning [107/300]: mean_loss=0.01144012063741684
Q_Learning [108/300]: mean_loss=0.015946705592796206
Q_Learning [109/300]: mean_loss=0.028769672382622957
Q_Learning [110/300]: mean_loss=0.02179936459288001
Q_Learning [111/300]: mean_loss=0.022187027148902416
Q_Learning [112/300]: mean_loss=0.09871989022940397
Q_Learning [113/300]: mean_loss=0.023458322742953897
Q_Learning [114/300]: mean_loss=0.013246533344499767
Q_Learning [115/300]: mean_loss=0.04975650925189257
Q_Learning [116/300]: mean_loss=0.022394681116566062
Q_Learning [117/300]: mean_loss=0.04132336284965277
Q_Learning [118/300]: mean_loss=0.015212823986075819
Q_Learning [119/300]: mean_loss=0.13276741467416286
Q_Learning [120/300]: mean_loss=0.06410901295021176
Q_Learning [121/300]: mean_loss=0.03414200316183269
Q_Learning [122/300]: mean_loss=0.041675534565001726
Q_Learning [123/300]: mean_loss=0.02315308665856719
Q_Learning [124/300]: mean_loss=0.017218812950886786
Q_Learning [125/300]: mean_loss=0.07766814343631268
Q_Learning [126/300]: mean_loss=0.03655801713466644
Q_Learning [127/300]: mean_loss=0.02348827407695353
Q_Learning [128/300]: mean_loss=0.022565030958503485
Q_Learning [129/300]: mean_loss=0.016956512350589037
Q_Learning [130/300]: mean_loss=0.026295172050595284
Q_Learning [131/300]: mean_loss=0.019397434312850237
Q_Learning [132/300]: mean_loss=0.018805273459292948
Q_Learning [133/300]: mean_loss=0.023146865190938115
Q_Learning [134/300]: mean_loss=0.008808425976894796
Q_Learning [135/300]: mean_loss=0.11171941179782152
Q_Learning [136/300]: mean_loss=0.015137326437979937
Q_Learning [137/300]: mean_loss=0.0191515606129542
Q_Learning [138/300]: mean_loss=0.0136992676416412
Q_Learning [139/300]: mean_loss=0.01773977989796549
Q_Learning [140/300]: mean_loss=0.021540137007832527
Q_Learning [141/300]: mean_loss=0.04166776267811656
Q_Learning [142/300]: mean_loss=0.018673720420338213
Q_Learning [143/300]: mean_loss=0.020637727808207273
Q_Learning [144/300]: mean_loss=0.00869155244436115
Q_Learning [145/300]: mean_loss=0.02289487957023084
Q_Learning [146/300]: mean_loss=0.01962184952571988
Q_Learning [147/300]: mean_loss=0.016813618130981922
Q_Learning [148/300]: mean_loss=0.033902119379490614
Q_Learning [149/300]: mean_loss=0.05069219134747982
Q_Learning [150/300]: mean_loss=0.04597313888370991
Q_Learning [151/300]: mean_loss=0.018553501344285905
Q_Learning [152/300]: mean_loss=0.01611008809413761
Q_Learning [153/300]: mean_loss=0.02119063283316791
Q_Learning [154/300]: mean_loss=0.01665735791902989
Q_Learning [155/300]: mean_loss=0.011243793182075024
Q_Learning [156/300]: mean_loss=0.01770120277069509
Q_Learning [157/300]: mean_loss=0.13536369800567627
Q_Learning [158/300]: mean_loss=0.007342242985032499
Q_Learning [159/300]: mean_loss=0.026797428959980607
Q_Learning [160/300]: mean_loss=0.021943422267213464
Q_Learning [161/300]: mean_loss=0.027821322437375784
Q_Learning [162/300]: mean_loss=0.013307468849234283
Q_Learning [163/300]: mean_loss=0.0511768632568419
Q_Learning [164/300]: mean_loss=0.019255208782851696
Q_Learning [165/300]: mean_loss=0.009373190288897604
Q_Learning [166/300]: mean_loss=0.01821879216004163
Q_Learning [167/300]: mean_loss=0.02985403616912663
Q_Learning [168/300]: mean_loss=0.03733438206836581
Q_Learning [169/300]: mean_loss=0.05194031307473779
Q_Learning [170/300]: mean_loss=0.18136954307556152
Q_Learning [171/300]: mean_loss=0.015052521950565279
Q_Learning [172/300]: mean_loss=0.013353120419196784
Q_Learning [173/300]: mean_loss=0.01990163209848106
Q_Learning [174/300]: mean_loss=0.011716029839590192
Q_Learning [175/300]: mean_loss=0.010368248331360519
Q_Learning [176/300]: mean_loss=0.007987544988282025
Q_Learning [177/300]: mean_loss=0.023861035238951445
Q_Learning [178/300]: mean_loss=0.03379242168739438
Q_Learning [179/300]: mean_loss=0.017693003173917532
Q_Learning [180/300]: mean_loss=0.016047297045588493
Q_Learning [181/300]: mean_loss=0.013692928943783045
Q_Learning [182/300]: mean_loss=0.03204981214366853
Q_Learning [183/300]: mean_loss=0.012465032748878002
Q_Learning [184/300]: mean_loss=0.004572909616399556
Q_Learning [185/300]: mean_loss=0.026729835430160165
Q_Learning [186/300]: mean_loss=0.032124934485182166
Q_Learning [187/300]: mean_loss=0.02481312328018248
Q_Learning [188/300]: mean_loss=0.02380849700421095
Q_Learning [189/300]: mean_loss=0.058676119428128004
Q_Learning [190/300]: mean_loss=0.021094375988468528
Q_Learning [191/300]: mean_loss=0.15423513017594814
Q_Learning [192/300]: mean_loss=0.02588999830186367
Q_Learning [193/300]: mean_loss=0.02537600789219141
Q_Learning [194/300]: mean_loss=0.009613717149477452
Q_Learning [195/300]: mean_loss=0.03207036969251931
Q_Learning [196/300]: mean_loss=0.014693074976094067
Q_Learning [197/300]: mean_loss=0.02088090986944735
Q_Learning [198/300]: mean_loss=0.017393789486959577
Q_Learning [199/300]: mean_loss=0.09386585932224989
Q_Learning [200/300]: mean_loss=0.01861177757382393
Q_Learning [201/300]: mean_loss=0.02846422465518117
Q_Learning [202/300]: mean_loss=0.011958640301600099
Q_Learning [203/300]: mean_loss=0.011513704084791243
Q_Learning [204/300]: mean_loss=0.010447541018947959
Q_Learning [205/300]: mean_loss=0.05865115998312831
Q_Learning [206/300]: mean_loss=0.01173877774272114
Q_Learning [207/300]: mean_loss=0.03835810301825404
Q_Learning [208/300]: mean_loss=0.03635374456644058
Q_Learning [209/300]: mean_loss=0.05312279751524329
Q_Learning [210/300]: mean_loss=0.029477143893018365
Q_Learning [211/300]: mean_loss=0.011587725253775716
Q_Learning [212/300]: mean_loss=0.09816097747534513
Q_Learning [213/300]: mean_loss=0.0400208979845047
Q_Learning [214/300]: mean_loss=0.011156992753967643
Q_Learning [215/300]: mean_loss=0.02898859791457653
Q_Learning [216/300]: mean_loss=0.02611485938541591
Q_Learning [217/300]: mean_loss=0.010208000196143985
Q_Learning [218/300]: mean_loss=0.008572846127208322
Q_Learning [219/300]: mean_loss=0.04289326537400484
Q_Learning [220/300]: mean_loss=0.013788943644613028
Q_Learning [221/300]: mean_loss=0.03233351814560592
Q_Learning [222/300]: mean_loss=0.013461778522469103
Q_Learning [223/300]: mean_loss=0.030326546635478735
Q_Learning [224/300]: mean_loss=0.007364864402916282
Q_Learning [225/300]: mean_loss=0.02362783905118704
Q_Learning [226/300]: mean_loss=0.02330112108029425
Q_Learning [227/300]: mean_loss=0.014535286813043058
Q_Learning [228/300]: mean_loss=0.02734413743019104
Q_Learning [229/300]: mean_loss=0.039064477663487196
Q_Learning [230/300]: mean_loss=0.014048820012249053
Q_Learning [231/300]: mean_loss=0.02228078688494861
Q_Learning [232/300]: mean_loss=0.019640046637505293
Q_Learning [233/300]: mean_loss=0.01212494506035
Q_Learning [234/300]: mean_loss=0.02108108508400619
Q_Learning [235/300]: mean_loss=0.09147996827960014
Q_Learning [236/300]: mean_loss=0.052834514528512955
Q_Learning [237/300]: mean_loss=0.031104091554880142
Q_Learning [238/300]: mean_loss=0.10133790131658316
Q_Learning [239/300]: mean_loss=0.11302953958511353
Q_Learning [240/300]: mean_loss=0.03473837999626994
Q_Learning [241/300]: mean_loss=0.04570145416073501
Q_Learning [242/300]: mean_loss=0.04025966580957174
Q_Learning [243/300]: mean_loss=0.0390964956022799
Q_Learning [244/300]: mean_loss=0.017189334495924413
Q_Learning [245/300]: mean_loss=0.032524987356737256
Q_Learning [246/300]: mean_loss=0.017940433230251074
Q_Learning [247/300]: mean_loss=0.00852318323450163
Q_Learning [248/300]: mean_loss=0.07829906046390533
Q_Learning [249/300]: mean_loss=0.011178698914591223
Q_Learning [250/300]: mean_loss=0.01773475855588913
Q_Learning [251/300]: mean_loss=0.011588040622882545
Q_Learning [252/300]: mean_loss=0.014738979516550899
Q_Learning [253/300]: mean_loss=0.015642395126633346
Q_Learning [254/300]: mean_loss=0.017476713052019477
Q_Learning [255/300]: mean_loss=0.03624006034806371
Q_Learning [256/300]: mean_loss=0.019294412340968847
Q_Learning [257/300]: mean_loss=0.013603627099655569
Q_Learning [258/300]: mean_loss=0.025763287907466292
Q_Learning [259/300]: mean_loss=0.011544198961928487
Q_Learning [260/300]: mean_loss=0.006132053036708385
Q_Learning [261/300]: mean_loss=0.022410430014133453
Q_Learning [262/300]: mean_loss=0.026348914485424757
Q_Learning [263/300]: mean_loss=0.01371781004127115
Q_Learning [264/300]: mean_loss=0.017137105111032724
Q_Learning [265/300]: mean_loss=0.017559533240273595
Q_Learning [266/300]: mean_loss=0.01282766810618341
Q_Learning [267/300]: mean_loss=0.012493492104113102
Q_Learning [268/300]: mean_loss=0.004496888432186097
Q_Learning [269/300]: mean_loss=0.015267503098584712
Q_Learning [270/300]: mean_loss=0.017918715719133615
Q_Learning [271/300]: mean_loss=0.0246631542686373
Q_Learning [272/300]: mean_loss=0.014720951323397458
Q_Learning [273/300]: mean_loss=0.007899804564658552
Q_Learning [274/300]: mean_loss=0.012667536037042737
Q_Learning [275/300]: mean_loss=0.012065946240909398
Q_Learning [276/300]: mean_loss=0.01250472164247185
Q_Learning [277/300]: mean_loss=0.016714030178263783
Q_Learning [278/300]: mean_loss=0.019887266913428903
Q_Learning [279/300]: mean_loss=0.01390955236274749
Q_Learning [280/300]: mean_loss=0.019599043997004628
Q_Learning [281/300]: mean_loss=0.02045599021948874
Q_Learning [282/300]: mean_loss=0.028988106874749064
Q_Learning [283/300]: mean_loss=0.02198891993612051
Q_Learning [284/300]: mean_loss=0.013692009262740612
Q_Learning [285/300]: mean_loss=0.018436550861224532
Q_Learning [286/300]: mean_loss=0.013390933279879391
Q_Learning [287/300]: mean_loss=0.018901597941294312
Q_Learning [288/300]: mean_loss=0.01356249232776463
Q_Learning [289/300]: mean_loss=0.03599607665091753
Q_Learning [290/300]: mean_loss=0.006187983555719256
Q_Learning [291/300]: mean_loss=0.011187441064976156
Q_Learning [292/300]: mean_loss=0.007689570833463222
Q_Learning [293/300]: mean_loss=0.013225927366875112
Q_Learning [294/300]: mean_loss=0.015401029726490378
Q_Learning [295/300]: mean_loss=0.03444680548273027
Q_Learning [296/300]: mean_loss=0.035006217658519745
Q_Learning [297/300]: mean_loss=0.019630863796919584
Q_Learning [298/300]: mean_loss=0.015671541215851903
Q_Learning [299/300]: mean_loss=0.016537356423214078
Q_Learning [300/300]: mean_loss=0.037342369090765715
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.2841406 -1.9231741]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 2, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1, 0, 2, 2, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 2, 0, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 2, 1, 0, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 0, 2, 2, 0, 1, 2, 1, 1, 0, 1, 0, 0, 1, 1, 2, 1, 1, 2, 0, 2, 2, 2, 1, 1, 0, 0, 2, 0, 0, 1, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1, 0, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1, 1, 2, 0, 2, 1, 1, 2, 0, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 1, 2, 0, 0, 1, 2, 1, 0, 2, 2, 0, 1, 2, 2, 1, 3, 2, 1, 2, 1, 2, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 2, 2, 2, 1, 1, 0, 0, 1, 2, 2, 2, 1, 1, 2, 1, 4, 2, 0, 0, 2, 1, 3, 0, 0, 2, 1, 1, 0, 1, 2, 0, 0, 2, 1, 1, 4, 2, 1, 0, 0, 2, 2, 1, 2, 1]
Centroids: [[0.73244846, 1.2609284], [-0.10746932, 0.3086636], [0.061952792, -2.0568964]]
Centroids: [[0.02493254, -2.0382223], [0.6474672, 1.1754887], [-0.28135327, 0.14650236], [1.9417977, -3.4168634], [1.6752892, -0.3125594]]
Contingency Matrix: 
[[ 0 96  5  0  2]
 [ 1 31 68  0  0]
 [93  0  2  2  0]]
[[0, 96, 5, 0, 2], [1, 31, 68, 0, 0], [93, 0, 2, 2, 0]]
[[0, 96, 5, 0, 2], [1, 31, 68, 0, 0], [93, 0, 2, 2, 0]]
[0, 1, 2, 3, 4]
[[-1, -1, -1, -1, -1], [1, -1, 68, 0, 0], [93, -1, 2, 2, 0]]
[[-1, -1, -1, -1, -1], [-1, -1, 68, 0, 0], [-1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1]]
Match_Labels: {0: 1, 2: 0, 1: 2}
New Contingency Matrix: 
[[96  5  0  0  2]
 [31 68  1  0  0]
 [ 0  2 93  2  0]]
New Clustered Label Sequence: [1, 2, 0, 3, 4]
Diagonal_Elements: [96, 68, 93], Sum: 257
All_Elements: [96, 5, 0, 0, 2, 31, 68, 1, 0, 0, 0, 2, 93, 2, 0], Sum: 300
Accuracy: 0.8566666666666667
