Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_4_opt
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_4_opt/C_Difficult2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt/2023_05_04-14_14_43
Punishment_Coefficient: 0.8
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001ECF0C72208>
Sampling rate: 24000.0
Raw: [-0.05565321 -0.04571496 -0.03115923 ...  0.1473638   0.13534729
  0.111692  ]
Times: [    418     529    1030 ... 1439028 1439080 1439623]
Cluster: [2 3 2 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3440
First aligned Spike Frame: [-0.17099344 -0.1945709  -0.20692804 -0.21224585 -0.21123273 -0.19839621
 -0.16928805 -0.13455314 -0.10755804 -0.09418858 -0.09168847 -0.09014646
 -0.07785681 -0.05220219 -0.010559    0.05141874  0.13325345  0.23429051
  0.3635645   0.52201137  0.68833941  0.84629252  0.96368446  0.9673675
  0.80566127  0.51814506  0.20703252 -0.04483802 -0.21878317 -0.33306068
 -0.39936966 -0.41844164 -0.40822894 -0.3999483  -0.40801198 -0.43204789
 -0.46902504 -0.51735316 -0.56113271 -0.57967205 -0.56696316 -0.53144438
 -0.47215401 -0.37953885 -0.25698053 -0.12693248 -0.00995817]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1185
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.15972063690423965
Online_Training [2/700]: mean_loss=0.09433443751186132
Online_Training [3/700]: mean_loss=0.13285456784069538
Online_Training [4/700]: mean_loss=0.10026354063302279
Online_Training [5/700]: mean_loss=0.09185411315411329
Online_Training [6/700]: mean_loss=0.22290288470685482
Online_Training [7/700]: mean_loss=0.07434763945639133
Online_Training [8/700]: mean_loss=0.10085209645330906
Online_Training [9/700]: mean_loss=0.09873568173497915
Online_Training [10/700]: mean_loss=0.0400161980651319
Online_Training [11/700]: mean_loss=0.08572061080485582
Online_Training [12/700]: mean_loss=0.11613005492836237
Online_Training [13/700]: mean_loss=0.09113208018243313
Online_Training [14/700]: mean_loss=0.08869270235300064
Online_Training [15/700]: mean_loss=0.08209567051380873
Online_Training [16/700]: mean_loss=0.040977459866553545
Online_Training [17/700]: mean_loss=0.030306538566946983
Online_Training [18/700]: mean_loss=0.14445390179753304
Online_Training [19/700]: mean_loss=0.0544160483404994
Online_Training [20/700]: mean_loss=0.04612449835985899
Online_Training [21/700]: mean_loss=0.2801572158932686
Online_Training [22/700]: mean_loss=0.1716491226106882
Online_Training [23/700]: mean_loss=0.041055680718272924
Online_Training [24/700]: mean_loss=0.14552408270537853
Online_Training [25/700]: mean_loss=0.05061471089720726
Online_Training [26/700]: mean_loss=0.10126836504787207
Online_Training [27/700]: mean_loss=0.12639330979436636
Online_Training [28/700]: mean_loss=0.04785348754376173
Online_Training [29/700]: mean_loss=0.07517668325453997
Online_Training [30/700]: mean_loss=0.06269885413348675
Online_Training [31/700]: mean_loss=0.07662018481642008
Online_Training [32/700]: mean_loss=0.05680139549076557
Online_Training [33/700]: mean_loss=0.0267972182482481
Online_Training [34/700]: mean_loss=0.1070047877728939
Online_Training [35/700]: mean_loss=0.049032704439014196
Online_Training [36/700]: mean_loss=0.02078630472533405
Online_Training [37/700]: mean_loss=0.07842295244336128
Online_Training [38/700]: mean_loss=0.05688070738688111
Online_Training [39/700]: mean_loss=0.06601811712607741
Online_Training [40/700]: mean_loss=0.025901383254677057
Online_Training [41/700]: mean_loss=0.1170099088922143
Online_Training [42/700]: mean_loss=0.06318167969584465
Online_Training [43/700]: mean_loss=0.058923044707626104
Online_Training [44/700]: mean_loss=0.08148965332657099
Online_Training [45/700]: mean_loss=0.01961405877955258
Online_Training [46/700]: mean_loss=0.03557583084329963
Online_Training [47/700]: mean_loss=0.15838280133903027
Online_Training [48/700]: mean_loss=0.0518218376673758
Online_Training [49/700]: mean_loss=0.048292077612131834
Online_Training [50/700]: mean_loss=0.03180404054000974
Online_Training [51/700]: mean_loss=0.04086465248838067
Online_Training [52/700]: mean_loss=0.0157367626670748
Online_Training [53/700]: mean_loss=0.0911876056343317
Online_Training [54/700]: mean_loss=0.036137477960437536
Online_Training [55/700]: mean_loss=0.030911308946087956
Online_Training [56/700]: mean_loss=0.012996765784919262
Online_Training [57/700]: mean_loss=0.032413151348009706
Online_Training [58/700]: mean_loss=0.053258891217410564
Online_Training [59/700]: mean_loss=0.12254289723932743
Online_Training [60/700]: mean_loss=0.0506689939647913
Online_Training [61/700]: mean_loss=0.03293388104066253
Online_Training [62/700]: mean_loss=0.077573386952281
Online_Training [63/700]: mean_loss=0.01511340809520334
Online_Training [64/700]: mean_loss=0.013313992414623499
Online_Training [65/700]: mean_loss=0.02122233295813203
Online_Training [66/700]: mean_loss=0.010682254564017057
Online_Training [67/700]: mean_loss=0.04089955426752567
Online_Training [68/700]: mean_loss=0.01539962668903172
Online_Training [69/700]: mean_loss=0.035802032332867384
Online_Training [70/700]: mean_loss=0.0392533028498292
Online_Training [71/700]: mean_loss=0.013302604435011744
Online_Training [72/700]: mean_loss=0.057742333970963955
Online_Training [73/700]: mean_loss=0.03924839850515127
Online_Training [74/700]: mean_loss=0.053358931094408035
Online_Training [75/700]: mean_loss=0.10025771521031857
Online_Training [76/700]: mean_loss=0.03150414302945137
Online_Training [77/700]: mean_loss=0.1666276790201664
Online_Training [78/700]: mean_loss=0.051291200798004866
Online_Training [79/700]: mean_loss=0.03782323747873306
Online_Training [80/700]: mean_loss=0.02193402498960495
Online_Training [81/700]: mean_loss=0.020749280462041497
Online_Training [82/700]: mean_loss=0.031192408874630928
Online_Training [83/700]: mean_loss=0.08893716987222433
Online_Training [84/700]: mean_loss=0.008553490333724767
Online_Training [85/700]: mean_loss=0.043153430335223675
Online_Training [86/700]: mean_loss=0.06451564840972424
Online_Training [87/700]: mean_loss=0.01397582609206438
Online_Training [88/700]: mean_loss=0.033666351810097694
Online_Training [89/700]: mean_loss=0.007952791347634047
Online_Training [90/700]: mean_loss=0.01543710648547858
Online_Training [91/700]: mean_loss=0.037096054293215275
Online_Training [92/700]: mean_loss=0.013608232722617686
Online_Training [93/700]: mean_loss=0.10416580270975828
Online_Training [94/700]: mean_loss=0.029664496425539255
Online_Training [95/700]: mean_loss=0.01866247714497149
Online_Training [96/700]: mean_loss=0.02370050991885364
Online_Training [97/700]: mean_loss=0.025727389147505164
Online_Training [98/700]: mean_loss=0.14056870806962252
Online_Training [99/700]: mean_loss=0.09186849184334278
Online_Training [100/700]: mean_loss=0.022302535362541676
Online_Training [101/700]: mean_loss=0.031469331588596106
Online_Training [102/700]: mean_loss=0.03888996597379446
Online_Training [103/700]: mean_loss=0.03727580211125314
Online_Training [104/700]: mean_loss=0.06854553334414959
Online_Training [105/700]: mean_loss=0.014992191223427653
Online_Training [106/700]: mean_loss=0.05152911553159356
Online_Training [107/700]: mean_loss=0.01605570875108242
Online_Training [108/700]: mean_loss=0.03836949123069644
Online_Training [109/700]: mean_loss=0.026308840373530984
Online_Training [110/700]: mean_loss=0.06652494706213474
Online_Training [111/700]: mean_loss=0.024982472881674767
Online_Training [112/700]: mean_loss=0.02415655297227204
Online_Training [113/700]: mean_loss=0.0519738495349884
Online_Training [114/700]: mean_loss=0.04301181901246309
Online_Training [115/700]: mean_loss=0.029920489992946386
Online_Training [116/700]: mean_loss=0.009565385989844799
Online_Training [117/700]: mean_loss=0.055216214153915644
Online_Training [118/700]: mean_loss=0.013397427857853472
Online_Training [119/700]: mean_loss=0.04335741885006428
Online_Training [120/700]: mean_loss=0.038349670358002186
Online_Training [121/700]: mean_loss=0.03446153341792524
Online_Training [122/700]: mean_loss=0.014869420556351542
Online_Training [123/700]: mean_loss=0.017457678681239486
Online_Training [124/700]: mean_loss=0.010616169543936849
Online_Training [125/700]: mean_loss=0.04051356576383114
Online_Training [126/700]: mean_loss=0.011838114936836064
Online_Training [127/700]: mean_loss=0.10741317830979824
Online_Training [128/700]: mean_loss=0.021477727219462395
Online_Training [129/700]: mean_loss=0.05582539178431034
Online_Training [130/700]: mean_loss=0.011571483104489744
Online_Training [131/700]: mean_loss=0.0367437144741416
Online_Training [132/700]: mean_loss=0.038929511327296495
Online_Training [133/700]: mean_loss=0.03979297075420618
Online_Training [134/700]: mean_loss=0.04093178175389767
Online_Training [135/700]: mean_loss=0.09634545166045427
Online_Training [136/700]: mean_loss=0.01883185561746359
Online_Training [137/700]: mean_loss=0.01525026501622051
Online_Training [138/700]: mean_loss=0.023989854147657752
Online_Training [139/700]: mean_loss=0.011331719812005758
Online_Training [140/700]: mean_loss=0.014119536965154111
Online_Training [141/700]: mean_loss=0.019276356091722846
Online_Training [142/700]: mean_loss=0.012719999998807907
Online_Training [143/700]: mean_loss=0.009159884182736278
Online_Training [144/700]: mean_loss=0.014269761391915381
Online_Training [145/700]: mean_loss=0.015373872127383947
Online_Training [146/700]: mean_loss=0.04020729614421725
Online_Training [147/700]: mean_loss=0.013803686131723225
Online_Training [148/700]: mean_loss=0.02099275798536837
Online_Training [149/700]: mean_loss=0.017569763236679137
Online_Training [150/700]: mean_loss=0.021405128529295325
Online_Training [151/700]: mean_loss=0.013423258438706398
Online_Training [152/700]: mean_loss=0.10513446293771267
Online_Training [153/700]: mean_loss=0.04858567612245679
Online_Training [154/700]: mean_loss=0.04887202149257064
Online_Training [155/700]: mean_loss=0.015062542399391532
Online_Training [156/700]: mean_loss=0.009077027789317071
Online_Training [157/700]: mean_loss=0.014305904624052346
Online_Training [158/700]: mean_loss=0.011096103116869926
Online_Training [159/700]: mean_loss=0.03709338931366801
Online_Training [160/700]: mean_loss=0.022157876286655664
Online_Training [161/700]: mean_loss=0.020806302782148123
Online_Training [162/700]: mean_loss=0.09578330907970667
Online_Training [163/700]: mean_loss=0.10302675701677799
Online_Training [164/700]: mean_loss=0.02010530687402934
Online_Training [165/700]: mean_loss=0.0357889027800411
Online_Training [166/700]: mean_loss=0.012660352978855371
Online_Training [167/700]: mean_loss=0.013037105556577444
Online_Training [168/700]: mean_loss=0.01627990126144141
Online_Training [169/700]: mean_loss=0.023218433372676373
Online_Training [170/700]: mean_loss=0.02995037310756743
Online_Training [171/700]: mean_loss=0.03675921028479934
Online_Training [172/700]: mean_loss=0.00864199543138966
Online_Training [173/700]: mean_loss=0.01728334347717464
Online_Training [174/700]: mean_loss=0.006241265218704939
Online_Training [175/700]: mean_loss=0.02818055939860642
Online_Training [176/700]: mean_loss=0.036428880179300904
Online_Training [177/700]: mean_loss=0.01793642481788993
Online_Training [178/700]: mean_loss=0.023963798535987735
Online_Training [179/700]: mean_loss=0.01503527327440679
Online_Training [180/700]: mean_loss=0.027846276992931962
Online_Training [181/700]: mean_loss=0.01770813437178731
Online_Training [182/700]: mean_loss=0.018451287178322673
Online_Training [183/700]: mean_loss=0.01934812287800014
Online_Training [184/700]: mean_loss=0.013054233742877841
Online_Training [185/700]: mean_loss=0.019183184718713164
Online_Training [186/700]: mean_loss=0.02146637812256813
Online_Training [187/700]: mean_loss=0.05206865631043911
Online_Training [188/700]: mean_loss=0.014243353623896837
Online_Training [189/700]: mean_loss=0.04511305736377835
Online_Training [190/700]: mean_loss=0.042029607109725475
Online_Training [191/700]: mean_loss=0.04058122308924794
Online_Training [192/700]: mean_loss=0.010575899039395154
Online_Training [193/700]: mean_loss=0.011605372070334852
Online_Training [194/700]: mean_loss=0.02474429947324097
Online_Training [195/700]: mean_loss=0.007094424101524055
Online_Training [196/700]: mean_loss=0.023415327072143555
Online_Training [197/700]: mean_loss=0.029581465991213918
Online_Training [198/700]: mean_loss=0.0077186753042042255
Online_Training [199/700]: mean_loss=0.02334762434475124
Online_Training [200/700]: mean_loss=0.04088471829891205
Online_Training [201/700]: mean_loss=0.0077587515115737915
Online_Training [202/700]: mean_loss=0.01676829729694873
Online_Training [203/700]: mean_loss=0.1594861038029194
Online_Training [204/700]: mean_loss=0.07148849684745073
Online_Training [205/700]: mean_loss=0.03414583206176758
Online_Training [206/700]: mean_loss=0.012407900299876928
Online_Training [207/700]: mean_loss=0.012288868427276611
Online_Training [208/700]: mean_loss=0.03090417291969061
Online_Training [209/700]: mean_loss=0.03660450782626867
Online_Training [210/700]: mean_loss=0.013679936644621193
Online_Training [211/700]: mean_loss=0.026478179963305593
Online_Training [212/700]: mean_loss=0.09595874231308699
Online_Training [213/700]: mean_loss=0.02499470254406333
Online_Training [214/700]: mean_loss=0.006855188985355198
Online_Training [215/700]: mean_loss=0.025092208059504628
Online_Training [216/700]: mean_loss=0.017851178185082972
Online_Training [217/700]: mean_loss=0.04803626937791705
Online_Training [218/700]: mean_loss=0.020233789924532175
Online_Training [219/700]: mean_loss=0.02205459284596145
Online_Training [220/700]: mean_loss=0.03163903462700546
Online_Training [221/700]: mean_loss=0.00995241291821003
Online_Training [222/700]: mean_loss=0.02277336409315467
Online_Training [223/700]: mean_loss=0.06743482407182455
Online_Training [224/700]: mean_loss=0.05003836937248707
Online_Training [225/700]: mean_loss=0.005557630502153188
Online_Training [226/700]: mean_loss=0.01930652977898717
Online_Training [227/700]: mean_loss=0.017247718875296414
Online_Training [228/700]: mean_loss=0.008806902100332081
Online_Training [229/700]: mean_loss=0.03766667051240802
Online_Training [230/700]: mean_loss=0.020827801432460546
Online_Training [231/700]: mean_loss=0.013171795522794127
Online_Training [232/700]: mean_loss=0.011915285722352564
Online_Training [233/700]: mean_loss=0.014689330360852182
Online_Training [234/700]: mean_loss=0.005566333187744021
Online_Training [235/700]: mean_loss=0.019716194830834866
Online_Training [236/700]: mean_loss=0.016408172086812556
Online_Training [237/700]: mean_loss=0.05232154997065663
Online_Training [238/700]: mean_loss=0.023293620673939586
Online_Training [239/700]: mean_loss=0.0180144514888525
Online_Training [240/700]: mean_loss=0.01193499518558383
Online_Training [241/700]: mean_loss=0.01770613552071154
Online_Training [242/700]: mean_loss=0.012053467915393412
Online_Training [243/700]: mean_loss=0.006248453864827752
Online_Training [244/700]: mean_loss=0.04267087206244469
Online_Training [245/700]: mean_loss=0.021829946199432015
Online_Training [246/700]: mean_loss=0.026439549634233117
Online_Training [247/700]: mean_loss=0.01707525458186865
Online_Training [248/700]: mean_loss=0.015790473204106092
Online_Training [249/700]: mean_loss=0.012371068238280714
Online_Training [250/700]: mean_loss=0.012995242956094444
Online_Training [251/700]: mean_loss=0.012389012263156474
Online_Training [252/700]: mean_loss=0.02637890772894025
Online_Training [253/700]: mean_loss=0.01645830029156059
Online_Training [254/700]: mean_loss=0.014443354215472937
Online_Training [255/700]: mean_loss=0.024445156566798687
Online_Training [256/700]: mean_loss=0.014689009985886514
Online_Training [257/700]: mean_loss=0.01959728356450796
Online_Training [258/700]: mean_loss=0.013759536435827613
Online_Training [259/700]: mean_loss=0.012098830775357783
Online_Training [260/700]: mean_loss=0.0524827647022903
Online_Training [261/700]: mean_loss=0.018866662867367268
Online_Training [262/700]: mean_loss=0.00857212784467265
Online_Training [263/700]: mean_loss=0.015723230433650315
Online_Training [264/700]: mean_loss=0.08945104945451021
Online_Training [265/700]: mean_loss=0.0319181801751256
Online_Training [266/700]: mean_loss=0.0404724539257586
Online_Training [267/700]: mean_loss=0.05330433789640665
Online_Training [268/700]: mean_loss=0.045861306600272655
Online_Training [269/700]: mean_loss=0.006912322831340134
Online_Training [270/700]: mean_loss=0.04932296322658658
Online_Training [271/700]: mean_loss=0.01619830832350999
Online_Training [272/700]: mean_loss=0.011365532758645713
Online_Training [273/700]: mean_loss=0.018235923489555717
Online_Training [274/700]: mean_loss=0.014869083184748888
Online_Training [275/700]: mean_loss=0.013471857644617558
Online_Training [276/700]: mean_loss=0.012521398137323558
Online_Training [277/700]: mean_loss=0.010022574453614652
Online_Training [278/700]: mean_loss=0.018367428332567215
Online_Training [279/700]: mean_loss=0.0108765242039226
Online_Training [280/700]: mean_loss=0.014194571296684444
Online_Training [281/700]: mean_loss=0.008390277449507266
Online_Training [282/700]: mean_loss=0.021647651912644506
Online_Training [283/700]: mean_loss=0.03196340752765536
Online_Training [284/700]: mean_loss=0.013308480381965637
Online_Training [285/700]: mean_loss=0.04152619373053312
Online_Training [286/700]: mean_loss=0.0428259763866663
Online_Training [287/700]: mean_loss=0.014683081419207156
Online_Training [288/700]: mean_loss=0.01636054227128625
Online_Training [289/700]: mean_loss=0.0040636817866470665
Online_Training [290/700]: mean_loss=0.008170992659870535
Online_Training [291/700]: mean_loss=0.008919737592805177
Online_Training [292/700]: mean_loss=0.005524741252884269
Online_Training [293/700]: mean_loss=0.017127230181358755
Online_Training [294/700]: mean_loss=0.009824593435041606
Online_Training [295/700]: mean_loss=0.017552394070662558
Online_Training [296/700]: mean_loss=0.00822850753320381
Online_Training [297/700]: mean_loss=0.05446858378127217
Online_Training [298/700]: mean_loss=0.020097942324355245
Online_Training [299/700]: mean_loss=0.01196296839043498
Online_Training [300/700]: mean_loss=0.025340566877275705
Online_Training [301/700]: mean_loss=0.009347699116915464
Online_Training [302/700]: mean_loss=0.009303143830038607
Online_Training [303/700]: mean_loss=0.010015353560447693
Online_Training [304/700]: mean_loss=0.012460203608497977
Online_Training [305/700]: mean_loss=0.012883617891930044
Online_Training [306/700]: mean_loss=0.022857871372252703
Online_Training [307/700]: mean_loss=0.032747446559369564
Online_Training [308/700]: mean_loss=0.008903201087377965
Online_Training [309/700]: mean_loss=0.033542189514264464
Online_Training [310/700]: mean_loss=0.016953412094153464
Online_Training [311/700]: mean_loss=0.02385595627129078
Online_Training [312/700]: mean_loss=0.04457077383995056
Online_Training [313/700]: mean_loss=0.03814917057752609
Online_Training [314/700]: mean_loss=0.022980024805292487
Online_Training [315/700]: mean_loss=0.013251198222860694
Online_Training [316/700]: mean_loss=0.013188604498282075
Online_Training [317/700]: mean_loss=0.018423591274768114
Online_Training [318/700]: mean_loss=0.029092132579535246
Online_Training [319/700]: mean_loss=0.044147159438580275
Online_Training [320/700]: mean_loss=0.0303312202449888
Online_Training [321/700]: mean_loss=0.01510442269500345
Online_Training [322/700]: mean_loss=0.01180942659266293
Online_Training [323/700]: mean_loss=0.016766868997365236
Online_Training [324/700]: mean_loss=0.026668564649298787
Online_Training [325/700]: mean_loss=0.008867067634128034
Online_Training [326/700]: mean_loss=0.018574426998384297
Online_Training [327/700]: mean_loss=0.024900380987673998
Online_Training [328/700]: mean_loss=0.02021723799407482
Online_Training [329/700]: mean_loss=0.021526232361793518
Online_Training [330/700]: mean_loss=0.004990190820535645
Online_Training [331/700]: mean_loss=0.018980965251103044
Online_Training [332/700]: mean_loss=0.026876249350607395
Online_Training [333/700]: mean_loss=0.02611821424216032
Online_Training [334/700]: mean_loss=0.023139973869547248
Online_Training [335/700]: mean_loss=0.025586845353245735
Online_Training [336/700]: mean_loss=0.009489969816058874
Online_Training [337/700]: mean_loss=0.01301440317183733
Online_Training [338/700]: mean_loss=0.011276296456344426
Online_Training [339/700]: mean_loss=0.008558897126931697
Online_Training [340/700]: mean_loss=0.026861031772568822
Online_Training [341/700]: mean_loss=0.007922489719931036
Online_Training [342/700]: mean_loss=0.019871181808412075
Online_Training [343/700]: mean_loss=0.03083078912459314
Online_Training [344/700]: mean_loss=0.024066626327112317
Online_Training [345/700]: mean_loss=0.0020878681680187583
Online_Training [346/700]: mean_loss=0.006597361294552684
Online_Training [347/700]: mean_loss=0.025956416269764304
Online_Training [348/700]: mean_loss=0.0085055839153938
Online_Training [349/700]: mean_loss=0.022173509234562516
Online_Training [350/700]: mean_loss=0.03173541254363954
Online_Training [351/700]: mean_loss=0.029537069844081998
Online_Training [352/700]: mean_loss=0.06602060329169035
Online_Training [353/700]: mean_loss=0.008780838397797197
Online_Training [354/700]: mean_loss=0.049338461831212044
Online_Training [355/700]: mean_loss=0.017577098798938096
Online_Training [356/700]: mean_loss=0.01618832559324801
Online_Training [357/700]: mean_loss=0.046043412294238806
Online_Training [358/700]: mean_loss=0.061269992496818304
Online_Training [359/700]: mean_loss=0.03741346951574087
Online_Training [360/700]: mean_loss=0.026004840387031436
Online_Training [361/700]: mean_loss=0.025582523550838232
Online_Training [362/700]: mean_loss=0.025582656962797046
Online_Training [363/700]: mean_loss=0.030825584661215544
Online_Training [364/700]: mean_loss=0.003165757021633908
Online_Training [365/700]: mean_loss=0.02237464743666351
Online_Training [366/700]: mean_loss=0.04958119476214051
Online_Training [367/700]: mean_loss=0.2148281093686819
Online_Training [368/700]: mean_loss=0.02330617606639862
Online_Training [369/700]: mean_loss=0.027594977291300893
Online_Training [370/700]: mean_loss=0.015399753348901868
Online_Training [371/700]: mean_loss=0.029602445429190993
Online_Training [372/700]: mean_loss=0.01908483891747892
Online_Training [373/700]: mean_loss=0.03408677224069834
Online_Training [374/700]: mean_loss=0.017504954244941473
Online_Training [375/700]: mean_loss=0.0157834718702361
Online_Training [376/700]: mean_loss=0.05037136981263757
Online_Training [377/700]: mean_loss=0.027745376341044903
Online_Training [378/700]: mean_loss=0.015030978713184595
Online_Training [379/700]: mean_loss=0.009400972980074584
Online_Training [380/700]: mean_loss=0.0212967733386904
Online_Training [381/700]: mean_loss=0.010022284463047981
Online_Training [382/700]: mean_loss=0.020415749866515398
Online_Training [383/700]: mean_loss=0.013624753570184112
Online_Training [384/700]: mean_loss=0.04184497334063053
Online_Training [385/700]: mean_loss=0.010035687475465238
Online_Training [386/700]: mean_loss=0.02006925386376679
Online_Training [387/700]: mean_loss=0.049696342553943396
Online_Training [388/700]: mean_loss=0.007658730843104422
Online_Training [389/700]: mean_loss=0.011764260940253735
Online_Training [390/700]: mean_loss=0.02483207476325333
Online_Training [391/700]: mean_loss=0.08602366410195827
Online_Training [392/700]: mean_loss=0.03624330926686525
Online_Training [393/700]: mean_loss=0.0343433883972466
Online_Training [394/700]: mean_loss=0.015414685243740678
Online_Training [395/700]: mean_loss=0.03718293411657214
Online_Training [396/700]: mean_loss=0.020380715373903513
Online_Training [397/700]: mean_loss=0.056930959690362215
Online_Training [398/700]: mean_loss=0.014096734579652548
Online_Training [399/700]: mean_loss=0.028457524022087455
Online_Training [400/700]: mean_loss=0.019269683165475726
Online_Training [401/700]: mean_loss=0.018914855550974607
Online_Training [402/700]: mean_loss=0.025948979193344712
Online_Training [403/700]: mean_loss=0.019386658910661936
Online_Training [404/700]: mean_loss=0.007964581018313766
Online_Training [405/700]: mean_loss=0.02342066471464932
Online_Training [406/700]: mean_loss=0.011155227781273425
Online_Training [407/700]: mean_loss=0.05182116338983178
Online_Training [408/700]: mean_loss=0.008723648614250124
Online_Training [409/700]: mean_loss=0.012783546466380358
Online_Training [410/700]: mean_loss=0.031345118302851915
Online_Training [411/700]: mean_loss=0.054059043526649475
Online_Training [412/700]: mean_loss=0.04270463762804866
Online_Training [413/700]: mean_loss=0.004141000332310796
Online_Training [414/700]: mean_loss=0.025970345130190253
Online_Training [415/700]: mean_loss=0.03594586346298456
Online_Training [416/700]: mean_loss=0.03457348910160363
Online_Training [417/700]: mean_loss=0.024786236230283976
Online_Training [418/700]: mean_loss=0.00878416164778173
Online_Training [419/700]: mean_loss=0.025685512460768223
Online_Training [420/700]: mean_loss=0.010086249210871756
Online_Training [421/700]: mean_loss=0.010091760545037687
Online_Training [422/700]: mean_loss=0.010906607960350811
Online_Training [423/700]: mean_loss=0.009903106838464737
Online_Training [424/700]: mean_loss=0.012590771540999413
Online_Training [425/700]: mean_loss=0.009089405124541372
Online_Training [426/700]: mean_loss=0.025863966438919306
Online_Training [427/700]: mean_loss=0.03208842873573303
Online_Training [428/700]: mean_loss=0.012279192451387644
Online_Training [429/700]: mean_loss=0.04634794779121876
Online_Training [430/700]: mean_loss=0.023409234825521708
Online_Training [431/700]: mean_loss=0.02007354935631156
Online_Training [432/700]: mean_loss=0.008117248478811234
Online_Training [433/700]: mean_loss=0.0046536895097233355
Online_Training [434/700]: mean_loss=0.017581973574124277
Online_Training [435/700]: mean_loss=0.009301198180764914
Online_Training [436/700]: mean_loss=0.018450830597430468
Online_Training [437/700]: mean_loss=0.0278875264339149
Online_Training [438/700]: mean_loss=0.03373350319452584
Online_Training [439/700]: mean_loss=0.014407729730010033
Online_Training [440/700]: mean_loss=0.0222666934132576
Online_Training [441/700]: mean_loss=0.01962047629058361
Online_Training [442/700]: mean_loss=0.018801897414959967
Online_Training [443/700]: mean_loss=0.06934626679867506
Online_Training [444/700]: mean_loss=0.044121510814875364
Online_Training [445/700]: mean_loss=0.020662488415837288
Online_Training [446/700]: mean_loss=0.015421435004100204
Online_Training [447/700]: mean_loss=0.12419042084366083
Online_Training [448/700]: mean_loss=0.12320414371788502
Online_Training [449/700]: mean_loss=0.03309615748003125
Online_Training [450/700]: mean_loss=0.03087323298677802
Online_Training [451/700]: mean_loss=0.01446709712035954
Online_Training [452/700]: mean_loss=0.012518499395810068
Online_Training [453/700]: mean_loss=0.024850089568644762
Online_Training [454/700]: mean_loss=0.01458839827682823
Online_Training [455/700]: mean_loss=0.025237497175112367
Online_Training [456/700]: mean_loss=0.019685893319547176
Online_Training [457/700]: mean_loss=0.018038448877632618
Online_Training [458/700]: mean_loss=0.02429416263476014
Online_Training [459/700]: mean_loss=0.02216768031939864
Online_Training [460/700]: mean_loss=0.014414574834518135
Online_Training [461/700]: mean_loss=0.0216711584944278
Online_Training [462/700]: mean_loss=0.017952325521036983
Online_Training [463/700]: mean_loss=0.005986278178170323
Online_Training [464/700]: mean_loss=0.04123194236308336
Online_Training [465/700]: mean_loss=0.012308157398365438
Online_Training [466/700]: mean_loss=0.01011554105207324
Online_Training [467/700]: mean_loss=0.012711925548501313
Online_Training [468/700]: mean_loss=0.036074740812182426
Online_Training [469/700]: mean_loss=0.01191433472558856
Online_Training [470/700]: mean_loss=0.007303492689970881
Online_Training [471/700]: mean_loss=0.01129562919959426
Online_Training [472/700]: mean_loss=0.00597538280999288
Online_Training [473/700]: mean_loss=0.005348387931007892
Online_Training [474/700]: mean_loss=0.014659463660791516
Online_Training [475/700]: mean_loss=0.017225668765604496
Online_Training [476/700]: mean_loss=0.026010005036368966
Online_Training [477/700]: mean_loss=0.02449917863123119
Online_Training [478/700]: mean_loss=0.022227508947253227
Online_Training [479/700]: mean_loss=0.006856684165541083
Online_Training [480/700]: mean_loss=0.04773238813504577
Online_Training [481/700]: mean_loss=0.010160953039303422
Online_Training [482/700]: mean_loss=0.02151999669149518
Online_Training [483/700]: mean_loss=0.013673683162778616
Online_Training [484/700]: mean_loss=0.010716554359532893
Online_Training [485/700]: mean_loss=0.016457476187497377
Online_Training [486/700]: mean_loss=0.02171495114453137
Online_Training [487/700]: mean_loss=0.010590442456305027
Online_Training [488/700]: mean_loss=0.03244111710228026
Online_Training [489/700]: mean_loss=0.016892889514565468
Online_Training [490/700]: mean_loss=0.009748074226081371
Online_Training [491/700]: mean_loss=0.024182389490306377
Online_Training [492/700]: mean_loss=0.017603615066036582
Online_Training [493/700]: mean_loss=0.058156919199973345
Online_Training [494/700]: mean_loss=0.12681400496512651
Online_Training [495/700]: mean_loss=0.03453249344602227
Online_Training [496/700]: mean_loss=0.006444251455832273
Online_Training [497/700]: mean_loss=0.01905555767007172
Online_Training [498/700]: mean_loss=0.010383879765868187
Online_Training [499/700]: mean_loss=0.02303833863697946
Online_Training [500/700]: mean_loss=0.14641781337559223
Online_Training [501/700]: mean_loss=0.07717250660061836
Online_Training [502/700]: mean_loss=0.027603268157690763
Online_Training [503/700]: mean_loss=0.020877066301181912
Online_Training [504/700]: mean_loss=0.03410385479219258
Online_Training [505/700]: mean_loss=0.01868393598124385
Online_Training [506/700]: mean_loss=0.015594829455949366
Online_Training [507/700]: mean_loss=0.1367047093808651
Online_Training [508/700]: mean_loss=0.11201898474246264
Online_Training [509/700]: mean_loss=0.015676468145102262
Online_Training [510/700]: mean_loss=0.15535993874073029
Online_Training [511/700]: mean_loss=0.03420068696141243
Online_Training [512/700]: mean_loss=0.029272987274453044
Online_Training [513/700]: mean_loss=0.026532195042818785
Online_Training [514/700]: mean_loss=0.030676935566589236
Online_Training [515/700]: mean_loss=0.009503275970928371
Online_Training [516/700]: mean_loss=0.01795412797946483
Online_Training [517/700]: mean_loss=0.01502044580411166
Online_Training [518/700]: mean_loss=0.045003756415098906
Online_Training [519/700]: mean_loss=0.024461418855935335
Online_Training [520/700]: mean_loss=0.02735907630994916
Online_Training [521/700]: mean_loss=0.011122790863737464
Online_Training [522/700]: mean_loss=0.008741031168028712
Online_Training [523/700]: mean_loss=0.03402740112505853
Online_Training [524/700]: mean_loss=0.01125685649458319
Online_Training [525/700]: mean_loss=0.021237002685666084
Online_Training [526/700]: mean_loss=0.00422252991120331
Online_Training [527/700]: mean_loss=0.017546117305755615
Online_Training [528/700]: mean_loss=0.031167992623522878
Online_Training [529/700]: mean_loss=0.03686949051916599
Online_Training [530/700]: mean_loss=0.01923300768248737
Online_Training [531/700]: mean_loss=0.07851219270378351
Online_Training [532/700]: mean_loss=0.07104038074612617
Online_Training [533/700]: mean_loss=0.029904773691669106
Online_Training [534/700]: mean_loss=0.0213013319298625
Online_Training [535/700]: mean_loss=0.016273936606012285
Online_Training [536/700]: mean_loss=0.014169816742651165
Online_Training [537/700]: mean_loss=0.017201242852024734
Online_Training [538/700]: mean_loss=0.02712196228094399
Online_Training [539/700]: mean_loss=0.007701620226725936
Online_Training [540/700]: mean_loss=0.05759118450805545
Online_Training [541/700]: mean_loss=0.03035568236373365
Online_Training [542/700]: mean_loss=0.05984806641936302
Online_Training [543/700]: mean_loss=0.02231585537083447
Online_Training [544/700]: mean_loss=0.029570162063464522
Online_Training [545/700]: mean_loss=0.03396860370412469
Online_Training [546/700]: mean_loss=0.01297623768914491
Online_Training [547/700]: mean_loss=0.017727051628753543
Online_Training [548/700]: mean_loss=0.02010097389575094
Online_Training [549/700]: mean_loss=0.00670617533614859
Online_Training [550/700]: mean_loss=0.00743161141872406
Online_Training [551/700]: mean_loss=0.008613698999397457
Online_Training [552/700]: mean_loss=0.025012988364323974
Online_Training [553/700]: mean_loss=0.023936134530231357
Online_Training [554/700]: mean_loss=0.037179138511419296
Online_Training [555/700]: mean_loss=0.011592527036555111
Online_Training [556/700]: mean_loss=0.011792599922046065
Online_Training [557/700]: mean_loss=0.0331371461506933
Online_Training [558/700]: mean_loss=0.005994278588332236
Online_Training [559/700]: mean_loss=0.008368314942345023
Online_Training [560/700]: mean_loss=0.013848120113834739
Online_Training [561/700]: mean_loss=0.012147604837082326
Online_Training [562/700]: mean_loss=0.00801328063244
Online_Training [563/700]: mean_loss=0.02395846857689321
Online_Training [564/700]: mean_loss=0.02070821658708155
Online_Training [565/700]: mean_loss=0.016768667730502784
Online_Training [566/700]: mean_loss=0.02536224527284503
Online_Training [567/700]: mean_loss=0.010287149692885578
Online_Training [568/700]: mean_loss=0.02202227641828358
Online_Training [569/700]: mean_loss=0.007823168765753508
Online_Training [570/700]: mean_loss=0.042447660118341446
Online_Training [571/700]: mean_loss=0.006421055120881647
Online_Training [572/700]: mean_loss=0.002706346655031666
Online_Training [573/700]: mean_loss=0.06054661003872752
Online_Training [574/700]: mean_loss=0.09532407764345407
Online_Training [575/700]: mean_loss=0.020128626376390457
Online_Training [576/700]: mean_loss=0.031456927536055446
Online_Training [577/700]: mean_loss=0.00292807724326849
Online_Training [578/700]: mean_loss=0.00981978652998805
Online_Training [579/700]: mean_loss=0.009876560070551932
Online_Training [580/700]: mean_loss=0.008101449580863118
Online_Training [581/700]: mean_loss=0.008370072755496949
Online_Training [582/700]: mean_loss=0.007256143959239125
Online_Training [583/700]: mean_loss=0.022678221808746457
Online_Training [584/700]: mean_loss=0.013787061208859086
Online_Training [585/700]: mean_loss=0.0250594865065068
Online_Training [586/700]: mean_loss=0.0075395138701424
Online_Training [587/700]: mean_loss=0.015341707854531705
Online_Training [588/700]: mean_loss=0.008401814207900316
Online_Training [589/700]: mean_loss=0.007724208408035338
Online_Training [590/700]: mean_loss=0.008661447209306061
Online_Training [591/700]: mean_loss=0.022549422224983573
Online_Training [592/700]: mean_loss=0.011042193393222988
Online_Training [593/700]: mean_loss=0.020168319111689925
Online_Training [594/700]: mean_loss=0.013048521825112402
Online_Training [595/700]: mean_loss=0.01308326458092779
Online_Training [596/700]: mean_loss=0.008680070284754038
Online_Training [597/700]: mean_loss=0.02292406396009028
Online_Training [598/700]: mean_loss=0.01933099515736103
Online_Training [599/700]: mean_loss=0.009822566411457956
Online_Training [600/700]: mean_loss=0.02076467568986118
Online_Training [601/700]: mean_loss=0.035319977439939976
Online_Training [602/700]: mean_loss=0.06017020205035806
Online_Training [603/700]: mean_loss=0.13879686128348112
Online_Training [604/700]: mean_loss=0.0242011493537575
Online_Training [605/700]: mean_loss=0.009997064480558038
Online_Training [606/700]: mean_loss=0.017574168276041746
Online_Training [607/700]: mean_loss=0.005518959718756378
Online_Training [608/700]: mean_loss=0.019288062816485763
Online_Training [609/700]: mean_loss=0.00990460254251957
Online_Training [610/700]: mean_loss=0.018420522334054112
Online_Training [611/700]: mean_loss=0.017475435975939035
Online_Training [612/700]: mean_loss=0.03188499924726784
Online_Training [613/700]: mean_loss=0.007467759307473898
Online_Training [614/700]: mean_loss=0.011166293057613075
Online_Training [615/700]: mean_loss=0.01871253177523613
Online_Training [616/700]: mean_loss=0.02005457249470055
Online_Training [617/700]: mean_loss=0.024570597568526864
Online_Training [618/700]: mean_loss=0.011932831606827676
Online_Training [619/700]: mean_loss=0.0073318182257935405
Online_Training [620/700]: mean_loss=0.006349403178319335
Online_Training [621/700]: mean_loss=0.013051470392383635
Online_Training [622/700]: mean_loss=0.02372181206010282
Online_Training [623/700]: mean_loss=0.00759360141819343
Online_Training [624/700]: mean_loss=0.03944602981209755
Online_Training [625/700]: mean_loss=0.014846022357232869
Online_Training [626/700]: mean_loss=0.019464044366031885
Online_Training [627/700]: mean_loss=0.022221252787858248
Online_Training [628/700]: mean_loss=0.013276788988150656
Online_Training [629/700]: mean_loss=0.014291974599473178
Online_Training [630/700]: mean_loss=0.011368776555173099
Online_Training [631/700]: mean_loss=0.0068998910137452185
Online_Training [632/700]: mean_loss=0.008908690884709358
Online_Training [633/700]: mean_loss=0.008097120502498
Online_Training [634/700]: mean_loss=0.02469132700935006
Online_Training [635/700]: mean_loss=0.0023557144741062075
Online_Training [636/700]: mean_loss=0.026177344378083944
Online_Training [637/700]: mean_loss=0.004879025917034596
Online_Training [638/700]: mean_loss=0.011730723199434578
Online_Training [639/700]: mean_loss=0.014562719617970288
Online_Training [640/700]: mean_loss=0.006868849392049015
Online_Training [641/700]: mean_loss=0.017052234732545912
Online_Training [642/700]: mean_loss=0.03311737021431327
Online_Training [643/700]: mean_loss=0.020629946840927005
Online_Training [644/700]: mean_loss=0.010484644211828709
Online_Training [645/700]: mean_loss=0.008574040490202606
Online_Training [646/700]: mean_loss=0.009117715351749212
Online_Training [647/700]: mean_loss=0.023254830623045564
Online_Training [648/700]: mean_loss=0.013481100322678685
Online_Training [649/700]: mean_loss=0.012791829649358988
Online_Training [650/700]: mean_loss=0.0712232505902648
Online_Training [651/700]: mean_loss=0.01531625387724489
Online_Training [652/700]: mean_loss=0.008366179827135056
Online_Training [653/700]: mean_loss=0.10401518549770117
Online_Training [654/700]: mean_loss=0.032472495222464204
Online_Training [655/700]: mean_loss=0.007322769961319864
Online_Training [656/700]: mean_loss=0.005954158958047628
Online_Training [657/700]: mean_loss=0.012405167799443007
Online_Training [658/700]: mean_loss=0.01307123398873955
Online_Training [659/700]: mean_loss=0.022157645085826516
Online_Training [660/700]: mean_loss=0.030360518023371696
Online_Training [661/700]: mean_loss=0.04851728118956089
Online_Training [662/700]: mean_loss=0.006924909830559045
Online_Training [663/700]: mean_loss=0.039645427372306585
Online_Training [664/700]: mean_loss=0.04269523732364178
Online_Training [665/700]: mean_loss=0.013680575066246092
Online_Training [666/700]: mean_loss=0.013237884035333991
Online_Training [667/700]: mean_loss=0.010876517742872238
Online_Training [668/700]: mean_loss=0.013516049482859671
Online_Training [669/700]: mean_loss=0.012607435579411685
Online_Training [670/700]: mean_loss=0.021470767445862293
Online_Training [671/700]: mean_loss=0.021945115877315402
Online_Training [672/700]: mean_loss=0.01082404691260308
Online_Training [673/700]: mean_loss=0.052450827322900295
Online_Training [674/700]: mean_loss=0.011578271980397403
Online_Training [675/700]: mean_loss=0.030824976973235607
Online_Training [676/700]: mean_loss=0.01193670544307679
Online_Training [677/700]: mean_loss=0.03606014093384147
Online_Training [678/700]: mean_loss=0.02012677351012826
Online_Training [679/700]: mean_loss=0.039008304476737976
Online_Training [680/700]: mean_loss=0.019389598397538066
Online_Training [681/700]: mean_loss=0.02660899772308767
Online_Training [682/700]: mean_loss=0.10037038195878267
Online_Training [683/700]: mean_loss=0.15103305876255035
Online_Training [684/700]: mean_loss=0.010684380424208939
Online_Training [685/700]: mean_loss=0.012256041867658496
Online_Training [686/700]: mean_loss=0.009658280876465142
Online_Training [687/700]: mean_loss=0.008415044168941677
Online_Training [688/700]: mean_loss=0.020599577575922012
Online_Training [689/700]: mean_loss=0.021119713899679482
Online_Training [690/700]: mean_loss=0.009116674773395061
Online_Training [691/700]: mean_loss=0.09244863037019968
Online_Training [692/700]: mean_loss=0.1870371550321579
Online_Training [693/700]: mean_loss=0.011567407986149192
Online_Training [694/700]: mean_loss=0.0325420256704092
Online_Training [695/700]: mean_loss=0.05852709384635091
Online_Training [696/700]: mean_loss=0.01877228869125247
Online_Training [697/700]: mean_loss=0.012876322609372437
Online_Training [698/700]: mean_loss=0.008728406217414886
Online_Training [699/700]: mean_loss=0.09816964901983738
Online_Training [700/700]: mean_loss=0.06647876789793372
Q_Learning [1/300]: mean_loss=0.15972063690423965
Q_Learning [2/300]: mean_loss=0.09433443751186132
Q_Learning [3/300]: mean_loss=0.13285456784069538
Q_Learning [4/300]: mean_loss=0.10026354063302279
Q_Learning [5/300]: mean_loss=0.09185411315411329
Q_Learning [6/300]: mean_loss=0.22290288470685482
Q_Learning [7/300]: mean_loss=0.07434763945639133
Q_Learning [8/300]: mean_loss=0.10085209645330906
Q_Learning [9/300]: mean_loss=0.09873568173497915
Q_Learning [10/300]: mean_loss=0.0400161980651319
Q_Learning [11/300]: mean_loss=0.08572061080485582
Q_Learning [12/300]: mean_loss=0.11613005492836237
Q_Learning [13/300]: mean_loss=0.09113208018243313
Q_Learning [14/300]: mean_loss=0.08869270235300064
Q_Learning [15/300]: mean_loss=0.08209567051380873
Q_Learning [16/300]: mean_loss=0.040977459866553545
Q_Learning [17/300]: mean_loss=0.030306538566946983
Q_Learning [18/300]: mean_loss=0.14445390179753304
Q_Learning [19/300]: mean_loss=0.0544160483404994
Q_Learning [20/300]: mean_loss=0.04612449835985899
Q_Learning [21/300]: mean_loss=0.2801572158932686
Q_Learning [22/300]: mean_loss=0.1716491226106882
Q_Learning [23/300]: mean_loss=0.041055680718272924
Q_Learning [24/300]: mean_loss=0.14552408270537853
Q_Learning [25/300]: mean_loss=0.05061471089720726
Q_Learning [26/300]: mean_loss=0.10126836504787207
Q_Learning [27/300]: mean_loss=0.12639330979436636
Q_Learning [28/300]: mean_loss=0.04785348754376173
Q_Learning [29/300]: mean_loss=0.07517668325453997
Q_Learning [30/300]: mean_loss=0.06269885413348675
Q_Learning [31/300]: mean_loss=0.07662018481642008
Q_Learning [32/300]: mean_loss=0.05680139549076557
Q_Learning [33/300]: mean_loss=0.0267972182482481
Q_Learning [34/300]: mean_loss=0.1070047877728939
Q_Learning [35/300]: mean_loss=0.049032704439014196
Q_Learning [36/300]: mean_loss=0.02078630472533405
Q_Learning [37/300]: mean_loss=0.07842295244336128
Q_Learning [38/300]: mean_loss=0.05688070738688111
Q_Learning [39/300]: mean_loss=0.06601811712607741
Q_Learning [40/300]: mean_loss=0.025901383254677057
Q_Learning [41/300]: mean_loss=0.1170099088922143
Q_Learning [42/300]: mean_loss=0.06318167969584465
Q_Learning [43/300]: mean_loss=0.058923044707626104
Q_Learning [44/300]: mean_loss=0.08148965332657099
Q_Learning [45/300]: mean_loss=0.01961405877955258
Q_Learning [46/300]: mean_loss=0.03557583084329963
Q_Learning [47/300]: mean_loss=0.15838280133903027
Q_Learning [48/300]: mean_loss=0.0518218376673758
Q_Learning [49/300]: mean_loss=0.048292077612131834
Q_Learning [50/300]: mean_loss=0.03180404054000974
Q_Learning [51/300]: mean_loss=0.04086465248838067
Q_Learning [52/300]: mean_loss=0.0157367626670748
Q_Learning [53/300]: mean_loss=0.0911876056343317
Q_Learning [54/300]: mean_loss=0.036137477960437536
Q_Learning [55/300]: mean_loss=0.030911308946087956
Q_Learning [56/300]: mean_loss=0.012996765784919262
Q_Learning [57/300]: mean_loss=0.032413151348009706
Q_Learning [58/300]: mean_loss=0.053258891217410564
Q_Learning [59/300]: mean_loss=0.12254289723932743
Q_Learning [60/300]: mean_loss=0.0506689939647913
Q_Learning [61/300]: mean_loss=0.03293388104066253
Q_Learning [62/300]: mean_loss=0.077573386952281
Q_Learning [63/300]: mean_loss=0.01511340809520334
Q_Learning [64/300]: mean_loss=0.013313992414623499
Q_Learning [65/300]: mean_loss=0.02122233295813203
Q_Learning [66/300]: mean_loss=0.010682254564017057
Q_Learning [67/300]: mean_loss=0.04089955426752567
Q_Learning [68/300]: mean_loss=0.01539962668903172
Q_Learning [69/300]: mean_loss=0.035802032332867384
Q_Learning [70/300]: mean_loss=0.0392533028498292
Q_Learning [71/300]: mean_loss=0.013302604435011744
Q_Learning [72/300]: mean_loss=0.057742333970963955
Q_Learning [73/300]: mean_loss=0.03924839850515127
Q_Learning [74/300]: mean_loss=0.053358931094408035
Q_Learning [75/300]: mean_loss=0.10025771521031857
Q_Learning [76/300]: mean_loss=0.03150414302945137
Q_Learning [77/300]: mean_loss=0.1666276790201664
Q_Learning [78/300]: mean_loss=0.051291200798004866
Q_Learning [79/300]: mean_loss=0.03782323747873306
Q_Learning [80/300]: mean_loss=0.02193402498960495
Q_Learning [81/300]: mean_loss=0.020749280462041497
Q_Learning [82/300]: mean_loss=0.031192408874630928
Q_Learning [83/300]: mean_loss=0.08893716987222433
Q_Learning [84/300]: mean_loss=0.008553490333724767
Q_Learning [85/300]: mean_loss=0.043153430335223675
Q_Learning [86/300]: mean_loss=0.06451564840972424
Q_Learning [87/300]: mean_loss=0.01397582609206438
Q_Learning [88/300]: mean_loss=0.033666351810097694
Q_Learning [89/300]: mean_loss=0.007952791347634047
Q_Learning [90/300]: mean_loss=0.01543710648547858
Q_Learning [91/300]: mean_loss=0.037096054293215275
Q_Learning [92/300]: mean_loss=0.013608232722617686
Q_Learning [93/300]: mean_loss=0.10416580270975828
Q_Learning [94/300]: mean_loss=0.029664496425539255
Q_Learning [95/300]: mean_loss=0.01866247714497149
Q_Learning [96/300]: mean_loss=0.02370050991885364
Q_Learning [97/300]: mean_loss=0.025727389147505164
Q_Learning [98/300]: mean_loss=0.14056870806962252
Q_Learning [99/300]: mean_loss=0.09186849184334278
Q_Learning [100/300]: mean_loss=0.022302535362541676
Q_Learning [101/300]: mean_loss=0.031469331588596106
Q_Learning [102/300]: mean_loss=0.03888996597379446
Q_Learning [103/300]: mean_loss=0.03727580211125314
Q_Learning [104/300]: mean_loss=0.06854553334414959
Q_Learning [105/300]: mean_loss=0.014992191223427653
Q_Learning [106/300]: mean_loss=0.05152911553159356
Q_Learning [107/300]: mean_loss=0.01605570875108242
Q_Learning [108/300]: mean_loss=0.03836949123069644
Q_Learning [109/300]: mean_loss=0.026308840373530984
Q_Learning [110/300]: mean_loss=0.06652494706213474
Q_Learning [111/300]: mean_loss=0.024982472881674767
Q_Learning [112/300]: mean_loss=0.02415655297227204
Q_Learning [113/300]: mean_loss=0.0519738495349884
Q_Learning [114/300]: mean_loss=0.04301181901246309
Q_Learning [115/300]: mean_loss=0.029920489992946386
Q_Learning [116/300]: mean_loss=0.009565385989844799
Q_Learning [117/300]: mean_loss=0.055216214153915644
Q_Learning [118/300]: mean_loss=0.013397427857853472
Q_Learning [119/300]: mean_loss=0.04335741885006428
Q_Learning [120/300]: mean_loss=0.038349670358002186
Q_Learning [121/300]: mean_loss=0.03446153341792524
Q_Learning [122/300]: mean_loss=0.014869420556351542
Q_Learning [123/300]: mean_loss=0.017457678681239486
Q_Learning [124/300]: mean_loss=0.010616169543936849
Q_Learning [125/300]: mean_loss=0.04051356576383114
Q_Learning [126/300]: mean_loss=0.011838114936836064
Q_Learning [127/300]: mean_loss=0.10741317830979824
Q_Learning [128/300]: mean_loss=0.021477727219462395
Q_Learning [129/300]: mean_loss=0.05582539178431034
Q_Learning [130/300]: mean_loss=0.011571483104489744
Q_Learning [131/300]: mean_loss=0.0367437144741416
Q_Learning [132/300]: mean_loss=0.038929511327296495
Q_Learning [133/300]: mean_loss=0.03979297075420618
Q_Learning [134/300]: mean_loss=0.04093178175389767
Q_Learning [135/300]: mean_loss=0.09634545166045427
Q_Learning [136/300]: mean_loss=0.01883185561746359
Q_Learning [137/300]: mean_loss=0.01525026501622051
Q_Learning [138/300]: mean_loss=0.023989854147657752
Q_Learning [139/300]: mean_loss=0.011331719812005758
Q_Learning [140/300]: mean_loss=0.014119536965154111
Q_Learning [141/300]: mean_loss=0.019276356091722846
Q_Learning [142/300]: mean_loss=0.012719999998807907
Q_Learning [143/300]: mean_loss=0.009159884182736278
Q_Learning [144/300]: mean_loss=0.014269761391915381
Q_Learning [145/300]: mean_loss=0.015373872127383947
Q_Learning [146/300]: mean_loss=0.04020729614421725
Q_Learning [147/300]: mean_loss=0.013803686131723225
Q_Learning [148/300]: mean_loss=0.02099275798536837
Q_Learning [149/300]: mean_loss=0.017569763236679137
Q_Learning [150/300]: mean_loss=0.021405128529295325
Q_Learning [151/300]: mean_loss=0.013423258438706398
Q_Learning [152/300]: mean_loss=0.10513446293771267
Q_Learning [153/300]: mean_loss=0.04858567612245679
Q_Learning [154/300]: mean_loss=0.04887202149257064
Q_Learning [155/300]: mean_loss=0.015062542399391532
Q_Learning [156/300]: mean_loss=0.009077027789317071
Q_Learning [157/300]: mean_loss=0.014305904624052346
Q_Learning [158/300]: mean_loss=0.011096103116869926
Q_Learning [159/300]: mean_loss=0.03709338931366801
Q_Learning [160/300]: mean_loss=0.022157876286655664
Q_Learning [161/300]: mean_loss=0.020806302782148123
Q_Learning [162/300]: mean_loss=0.09578330907970667
Q_Learning [163/300]: mean_loss=0.10302675701677799
Q_Learning [164/300]: mean_loss=0.02010530687402934
Q_Learning [165/300]: mean_loss=0.0357889027800411
Q_Learning [166/300]: mean_loss=0.012660352978855371
Q_Learning [167/300]: mean_loss=0.013037105556577444
Q_Learning [168/300]: mean_loss=0.01627990126144141
Q_Learning [169/300]: mean_loss=0.023218433372676373
Q_Learning [170/300]: mean_loss=0.02995037310756743
Q_Learning [171/300]: mean_loss=0.03675921028479934
Q_Learning [172/300]: mean_loss=0.00864199543138966
Q_Learning [173/300]: mean_loss=0.01728334347717464
Q_Learning [174/300]: mean_loss=0.006241265218704939
Q_Learning [175/300]: mean_loss=0.02818055939860642
Q_Learning [176/300]: mean_loss=0.036428880179300904
Q_Learning [177/300]: mean_loss=0.01793642481788993
Q_Learning [178/300]: mean_loss=0.023963798535987735
Q_Learning [179/300]: mean_loss=0.01503527327440679
Q_Learning [180/300]: mean_loss=0.027846276992931962
Q_Learning [181/300]: mean_loss=0.01770813437178731
Q_Learning [182/300]: mean_loss=0.018451287178322673
Q_Learning [183/300]: mean_loss=0.01934812287800014
Q_Learning [184/300]: mean_loss=0.013054233742877841
Q_Learning [185/300]: mean_loss=0.019183184718713164
Q_Learning [186/300]: mean_loss=0.02146637812256813
Q_Learning [187/300]: mean_loss=0.05206865631043911
Q_Learning [188/300]: mean_loss=0.014243353623896837
Q_Learning [189/300]: mean_loss=0.04511305736377835
Q_Learning [190/300]: mean_loss=0.042029607109725475
Q_Learning [191/300]: mean_loss=0.04058122308924794
Q_Learning [192/300]: mean_loss=0.010575899039395154
Q_Learning [193/300]: mean_loss=0.011605372070334852
Q_Learning [194/300]: mean_loss=0.02474429947324097
Q_Learning [195/300]: mean_loss=0.007094424101524055
Q_Learning [196/300]: mean_loss=0.023415327072143555
Q_Learning [197/300]: mean_loss=0.029581465991213918
Q_Learning [198/300]: mean_loss=0.0077186753042042255
Q_Learning [199/300]: mean_loss=0.02334762434475124
Q_Learning [200/300]: mean_loss=0.04088471829891205
Q_Learning [201/300]: mean_loss=0.0077587515115737915
Q_Learning [202/300]: mean_loss=0.01676829729694873
Q_Learning [203/300]: mean_loss=0.1594861038029194
Q_Learning [204/300]: mean_loss=0.07148849684745073
Q_Learning [205/300]: mean_loss=0.03414583206176758
Q_Learning [206/300]: mean_loss=0.012407900299876928
Q_Learning [207/300]: mean_loss=0.012288868427276611
Q_Learning [208/300]: mean_loss=0.03090417291969061
Q_Learning [209/300]: mean_loss=0.03660450782626867
Q_Learning [210/300]: mean_loss=0.013679936644621193
Q_Learning [211/300]: mean_loss=0.026478179963305593
Q_Learning [212/300]: mean_loss=0.09595874231308699
Q_Learning [213/300]: mean_loss=0.02499470254406333
Q_Learning [214/300]: mean_loss=0.006855188985355198
Q_Learning [215/300]: mean_loss=0.025092208059504628
Q_Learning [216/300]: mean_loss=0.017851178185082972
Q_Learning [217/300]: mean_loss=0.04803626937791705
Q_Learning [218/300]: mean_loss=0.020233789924532175
Q_Learning [219/300]: mean_loss=0.02205459284596145
Q_Learning [220/300]: mean_loss=0.03163903462700546
Q_Learning [221/300]: mean_loss=0.00995241291821003
Q_Learning [222/300]: mean_loss=0.02277336409315467
Q_Learning [223/300]: mean_loss=0.06743482407182455
Q_Learning [224/300]: mean_loss=0.05003836937248707
Q_Learning [225/300]: mean_loss=0.005557630502153188
Q_Learning [226/300]: mean_loss=0.01930652977898717
Q_Learning [227/300]: mean_loss=0.017247718875296414
Q_Learning [228/300]: mean_loss=0.008806902100332081
Q_Learning [229/300]: mean_loss=0.03766667051240802
Q_Learning [230/300]: mean_loss=0.020827801432460546
Q_Learning [231/300]: mean_loss=0.013171795522794127
Q_Learning [232/300]: mean_loss=0.011915285722352564
Q_Learning [233/300]: mean_loss=0.014689330360852182
Q_Learning [234/300]: mean_loss=0.005566333187744021
Q_Learning [235/300]: mean_loss=0.019716194830834866
Q_Learning [236/300]: mean_loss=0.016408172086812556
Q_Learning [237/300]: mean_loss=0.05232154997065663
Q_Learning [238/300]: mean_loss=0.023293620673939586
Q_Learning [239/300]: mean_loss=0.0180144514888525
Q_Learning [240/300]: mean_loss=0.01193499518558383
Q_Learning [241/300]: mean_loss=0.01770613552071154
Q_Learning [242/300]: mean_loss=0.012053467915393412
Q_Learning [243/300]: mean_loss=0.006248453864827752
Q_Learning [244/300]: mean_loss=0.04267087206244469
Q_Learning [245/300]: mean_loss=0.021829946199432015
Q_Learning [246/300]: mean_loss=0.026439549634233117
Q_Learning [247/300]: mean_loss=0.01707525458186865
Q_Learning [248/300]: mean_loss=0.015790473204106092
Q_Learning [249/300]: mean_loss=0.012371068238280714
Q_Learning [250/300]: mean_loss=0.012995242956094444
Q_Learning [251/300]: mean_loss=0.012389012263156474
Q_Learning [252/300]: mean_loss=0.02637890772894025
Q_Learning [253/300]: mean_loss=0.01645830029156059
Q_Learning [254/300]: mean_loss=0.014443354215472937
Q_Learning [255/300]: mean_loss=0.024445156566798687
Q_Learning [256/300]: mean_loss=0.014689009985886514
Q_Learning [257/300]: mean_loss=0.01959728356450796
Q_Learning [258/300]: mean_loss=0.013759536435827613
Q_Learning [259/300]: mean_loss=0.012098830775357783
Q_Learning [260/300]: mean_loss=0.0524827647022903
Q_Learning [261/300]: mean_loss=0.018866662867367268
Q_Learning [262/300]: mean_loss=0.00857212784467265
Q_Learning [263/300]: mean_loss=0.015723230433650315
Q_Learning [264/300]: mean_loss=0.08945104945451021
Q_Learning [265/300]: mean_loss=0.0319181801751256
Q_Learning [266/300]: mean_loss=0.0404724539257586
Q_Learning [267/300]: mean_loss=0.05330433789640665
Q_Learning [268/300]: mean_loss=0.045861306600272655
Q_Learning [269/300]: mean_loss=0.006912322831340134
Q_Learning [270/300]: mean_loss=0.04932296322658658
Q_Learning [271/300]: mean_loss=0.01619830832350999
Q_Learning [272/300]: mean_loss=0.011365532758645713
Q_Learning [273/300]: mean_loss=0.018235923489555717
Q_Learning [274/300]: mean_loss=0.014869083184748888
Q_Learning [275/300]: mean_loss=0.013471857644617558
Q_Learning [276/300]: mean_loss=0.012521398137323558
Q_Learning [277/300]: mean_loss=0.010022574453614652
Q_Learning [278/300]: mean_loss=0.018367428332567215
Q_Learning [279/300]: mean_loss=0.0108765242039226
Q_Learning [280/300]: mean_loss=0.014194571296684444
Q_Learning [281/300]: mean_loss=0.008390277449507266
Q_Learning [282/300]: mean_loss=0.021647651912644506
Q_Learning [283/300]: mean_loss=0.03196340752765536
Q_Learning [284/300]: mean_loss=0.013308480381965637
Q_Learning [285/300]: mean_loss=0.04152619373053312
Q_Learning [286/300]: mean_loss=0.0428259763866663
Q_Learning [287/300]: mean_loss=0.014683081419207156
Q_Learning [288/300]: mean_loss=0.01636054227128625
Q_Learning [289/300]: mean_loss=0.0040636817866470665
Q_Learning [290/300]: mean_loss=0.008170992659870535
Q_Learning [291/300]: mean_loss=0.008919737592805177
Q_Learning [292/300]: mean_loss=0.005524741252884269
Q_Learning [293/300]: mean_loss=0.017127230181358755
Q_Learning [294/300]: mean_loss=0.009824593435041606
Q_Learning [295/300]: mean_loss=0.017552394070662558
Q_Learning [296/300]: mean_loss=0.00822850753320381
Q_Learning [297/300]: mean_loss=0.05446858378127217
Q_Learning [298/300]: mean_loss=0.020097942324355245
Q_Learning [299/300]: mean_loss=0.01196296839043498
Q_Learning [300/300]: mean_loss=0.025340566877275705
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 0.2795913 -0.258581 ]
[2, 1, 0, 1, 0, 2, 1, 1, 1, 1, 2, 0, 1, 1, 0, 2, 1, 1, 0, 2, 2, 1, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 0, 0, 1, 0, 0, 2, 1, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 1, 0, 1, 1, 2, 1, 2, 1, 0, 1, 2, 1, 2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 1, 2, 2, 1, 1, 0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0, 2, 0, 2, 2, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 1, 0, 2, 2, 2, 1, 2, 2, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 2, 0, 1, 2, 2, 2, 1, 1, 0, 0, 0, 2, 2, 2, 2, 1, 0, 2, 1, 2, 1, 2, 0, 0, 0, 2, 1, 2, 2, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 2, 2, 2, 0, 0]
[0, 1, 2, 3, 2, 0, 1, 3, 3, 3, 0, 2, 1, 1, 2, 0, 1, 1, 2, 0, 0, 3, 1, 1, 1, 2, 3, 0, 0, 3, 0, 1, 0, 2, 3, 2, 2, 0, 1, 1, 0, 0, 0, 1, 2, 0, 1, 1, 1, 3, 1, 2, 1, 0, 0, 2, 2, 3, 1, 2, 1, 0, 1, 0, 0, 1, 1, 3, 2, 0, 1, 1, 2, 2, 2, 1, 2, 1, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 1, 3, 2, 3, 1, 3, 0, 0, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0, 2, 2, 3, 1, 0, 1, 0, 1, 2, 3, 0, 1, 2, 2, 2, 0, 3, 2, 0, 2, 0, 2, 0, 2, 0, 1, 0, 3, 0, 0, 3, 3, 2, 1, 2, 1, 2, 0, 2, 3, 1, 2, 2, 0, 2, 0, 2, 1, 2, 0, 0, 4, 5, 2, 2, 1, 2, 3, 4, 4, 2, 1, 3, 1, 2, 2, 0, 0, 1, 0, 0, 1, 2, 3, 3, 0, 2, 3, 2, 2, 1, 2, 2, 4, 2, 0, 0, 0, 1, 2, 0, 1, 1, 2, 1, 3, 2, 4, 2, 1, 0, 0, 0, 1, 1, 0, 0, 2, 4, 0, 0, 0, 3, 2, 0, 1, 2, 1, 0, 2, 2, 2, 0, 1, 0, 0, 1, 2, 0, 2, 6, 0, 6, 2, 0, 2, 2, 2, 1, 4, 0, 1, 2, 6, 1, 6, 2, 2, 2, 1, 6, 0, 0, 3, 0, 1, 4, 3, 0, 1, 0, 2, 7, 5, 2, 0, 2, 1, 1, 2, 6, 1, 0, 3, 4, 1, 0, 3, 1, 2, 0, 2, 2, 1, 6, 1, 2, 0, 0, 8, 6, 2]
Centroids: [[-0.028816199, -1.626215], [-1.0297288, 1.4379106], [-0.083407715, -0.35384202]]
Centroids: [[-0.038203273, -0.34900805], [-0.77470577, 1.5615352], [-0.21556985, -1.6777813], [-1.7539659, 1.3203181], [0.6312301, 0.3516474], [1.5566249, -2.1959538], [0.7142709, -1.2836857], [0.83576083, 2.2525542], [-1.1983896, -0.99721533]]
Contingency Matrix: 
[[ 9  0 76  0  1  2  8  0  0]
 [ 0 69  2 32  0  0  0  1  0]
 [79  0 12  0  8  0  0  0  1]]
[[9, 0, 76, 0, 1, 2, 8, 0, 0], [0, 69, 2, 32, 0, 0, 0, 1, 0], [79, 0, 12, 0, 8, 0, 0, 0, 1]]
[[9, 0, 76, 0, 1, 2, 8, 0, 0], [0, 69, 2, 32, 0, 0, 0, 1, 0], [79, 0, 12, 0, 8, 0, 0, 0, 1]]
[0, 1, 2, 3, 4, 5, 6, 7, 8]
[[-1, 0, 76, 0, 1, 2, 8, 0, 0], [-1, 69, 2, 32, 0, 0, 0, 1, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 69, -1, 32, 0, 0, 0, 1, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[76  0  9  0  1  2  8  0  0]
 [ 2 69  0 32  0  0  0  1  0]
 [12  0 79  0  8  0  0  0  1]]
New Clustered Label Sequence: [2, 1, 0, 3, 4, 5, 6, 7, 8]
Diagonal_Elements: [76, 69, 79], Sum: 224
All_Elements: [76, 0, 9, 0, 1, 2, 8, 0, 0, 2, 69, 0, 32, 0, 0, 0, 1, 0, 12, 0, 79, 0, 8, 0, 0, 0, 1], Sum: 300
Accuracy: 0.7466666666666667
