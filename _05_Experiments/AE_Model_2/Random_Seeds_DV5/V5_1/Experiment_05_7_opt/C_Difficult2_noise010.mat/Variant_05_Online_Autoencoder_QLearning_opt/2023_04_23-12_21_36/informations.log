Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_7_opt
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_1/Experiment_05_7_opt/C_Difficult2_noise010.mat/Variant_05_Online_Autoencoder_QLearning_opt/2023_04_23-12_21_36
Punishment_Coefficient: 0.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000018A4BD17F60>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.14379365928471088
Online_Training [2/700]: mean_loss=0.13652436062693596
Online_Training [3/700]: mean_loss=0.12723330687731504
Online_Training [4/700]: mean_loss=0.12407764792442322
Online_Training [5/700]: mean_loss=0.14681462198495865
Online_Training [6/700]: mean_loss=0.1590529978275299
Online_Training [7/700]: mean_loss=0.1967894695699215
Online_Training [8/700]: mean_loss=0.14532256312668324
Online_Training [9/700]: mean_loss=0.09729741793125868
Online_Training [10/700]: mean_loss=0.10919668059796095
Online_Training [11/700]: mean_loss=0.0397261343896389
Online_Training [12/700]: mean_loss=0.06249964749440551
Online_Training [13/700]: mean_loss=0.03246643650345504
Online_Training [14/700]: mean_loss=0.027471465291455388
Online_Training [15/700]: mean_loss=0.03590275626629591
Online_Training [16/700]: mean_loss=0.03257928928360343
Online_Training [17/700]: mean_loss=0.11208933684974909
Online_Training [18/700]: mean_loss=0.03910992434248328
Online_Training [19/700]: mean_loss=0.15663254261016846
Online_Training [20/700]: mean_loss=0.08278492465615273
Online_Training [21/700]: mean_loss=0.05713925790041685
Online_Training [22/700]: mean_loss=0.053254249040037394
Online_Training [23/700]: mean_loss=0.09144677314907312
Online_Training [24/700]: mean_loss=0.040933961514383554
Online_Training [25/700]: mean_loss=0.10102562606334686
Online_Training [26/700]: mean_loss=0.08547197002917528
Online_Training [27/700]: mean_loss=0.06946236081421375
Online_Training [28/700]: mean_loss=0.04319492122158408
Online_Training [29/700]: mean_loss=0.07279822789132595
Online_Training [30/700]: mean_loss=0.08007075265049934
Online_Training [31/700]: mean_loss=0.07651230599731207
Online_Training [32/700]: mean_loss=0.0823061028495431
Online_Training [33/700]: mean_loss=0.016691031865775585
Online_Training [34/700]: mean_loss=0.015379765070974827
Online_Training [35/700]: mean_loss=0.021647138288244605
Online_Training [36/700]: mean_loss=0.09695232287049294
Online_Training [37/700]: mean_loss=0.05565664358437061
Online_Training [38/700]: mean_loss=0.06956262234598398
Online_Training [39/700]: mean_loss=0.01605657651089132
Online_Training [40/700]: mean_loss=0.07021488808095455
Online_Training [41/700]: mean_loss=0.02280333056114614
Online_Training [42/700]: mean_loss=0.04838643362745643
Online_Training [43/700]: mean_loss=0.03583622258156538
Online_Training [44/700]: mean_loss=0.021857504034414887
Online_Training [45/700]: mean_loss=0.016779354540631175
Online_Training [46/700]: mean_loss=0.07972283009439707
Online_Training [47/700]: mean_loss=0.007389630540274084
Online_Training [48/700]: mean_loss=0.009365732898004353
Online_Training [49/700]: mean_loss=0.01003617828246206
Online_Training [50/700]: mean_loss=0.04538506967946887
Online_Training [51/700]: mean_loss=0.0625487701036036
Online_Training [52/700]: mean_loss=0.005535666074138135
Online_Training [53/700]: mean_loss=0.027137911412864923
Online_Training [54/700]: mean_loss=0.006661532039288431
Online_Training [55/700]: mean_loss=0.052565556950867176
Online_Training [56/700]: mean_loss=0.07069502677768469
Online_Training [57/700]: mean_loss=0.022084041265770793
Online_Training [58/700]: mean_loss=0.059025296941399574
Online_Training [59/700]: mean_loss=0.0483629796653986
Online_Training [60/700]: mean_loss=0.02441319520585239
Online_Training [61/700]: mean_loss=0.05435886653140187
Online_Training [62/700]: mean_loss=0.048868747893720865
Online_Training [63/700]: mean_loss=0.035465383203700185
Online_Training [64/700]: mean_loss=0.08984720427542925
Online_Training [65/700]: mean_loss=0.1485891081392765
Online_Training [66/700]: mean_loss=0.019828547723591328
Online_Training [67/700]: mean_loss=0.10768634267151356
Online_Training [68/700]: mean_loss=0.0946847116574645
Online_Training [69/700]: mean_loss=0.02171393297612667
Online_Training [70/700]: mean_loss=0.02236006036400795
Online_Training [71/700]: mean_loss=0.021936431992799044
Online_Training [72/700]: mean_loss=0.020922234747558832
Online_Training [73/700]: mean_loss=0.017372254049405456
Online_Training [74/700]: mean_loss=0.01636058557778597
Online_Training [75/700]: mean_loss=0.13570336159318686
Online_Training [76/700]: mean_loss=0.11785295885056257
Online_Training [77/700]: mean_loss=0.03779352456331253
Online_Training [78/700]: mean_loss=0.009803034423384815
Online_Training [79/700]: mean_loss=0.023020541993901134
Online_Training [80/700]: mean_loss=0.010023465496487916
Online_Training [81/700]: mean_loss=0.009153705090284348
Online_Training [82/700]: mean_loss=0.025613679783418775
Online_Training [83/700]: mean_loss=0.01692721585277468
Online_Training [84/700]: mean_loss=0.046464398968964815
Online_Training [85/700]: mean_loss=0.01191437419038266
Online_Training [86/700]: mean_loss=0.008889218792319298
Online_Training [87/700]: mean_loss=0.052331604063510895
Online_Training [88/700]: mean_loss=0.023599495412781835
Online_Training [89/700]: mean_loss=0.021168157923966646
Online_Training [90/700]: mean_loss=0.011682613519951701
Online_Training [91/700]: mean_loss=0.0047304725158028305
Online_Training [92/700]: mean_loss=0.005111530481372029
Online_Training [93/700]: mean_loss=0.01037893327884376
Online_Training [94/700]: mean_loss=0.008307152020279318
Online_Training [95/700]: mean_loss=0.07945015653967857
Online_Training [96/700]: mean_loss=0.036985857877880335
Online_Training [97/700]: mean_loss=0.008068460854701698
Online_Training [98/700]: mean_loss=0.029141988372430205
Online_Training [99/700]: mean_loss=0.01161493279505521
Online_Training [100/700]: mean_loss=0.024833623552694917
Online_Training [101/700]: mean_loss=0.01306504337117076
Online_Training [102/700]: mean_loss=0.007245465298183262
Online_Training [103/700]: mean_loss=0.023570689372718334
Online_Training [104/700]: mean_loss=0.03386117029003799
Online_Training [105/700]: mean_loss=0.03202241752296686
Online_Training [106/700]: mean_loss=0.015229763695970178
Online_Training [107/700]: mean_loss=0.019312503281980753
Online_Training [108/700]: mean_loss=0.013639129814691842
Online_Training [109/700]: mean_loss=0.010030929406639189
Online_Training [110/700]: mean_loss=0.015263483859598637
Online_Training [111/700]: mean_loss=0.021636291639879346
Online_Training [112/700]: mean_loss=0.008223032113164663
Online_Training [113/700]: mean_loss=0.013050094596110284
Online_Training [114/700]: mean_loss=0.008519579016137868
Online_Training [115/700]: mean_loss=0.0054563042358495295
Online_Training [116/700]: mean_loss=0.0032521322718821466
Online_Training [117/700]: mean_loss=0.012692154268734157
Online_Training [118/700]: mean_loss=0.04633365012705326
Online_Training [119/700]: mean_loss=0.01513080601580441
Online_Training [120/700]: mean_loss=0.014814761467278004
Online_Training [121/700]: mean_loss=0.016875337343662977
Online_Training [122/700]: mean_loss=0.005608197767287493
Online_Training [123/700]: mean_loss=0.030938980169594288
Online_Training [124/700]: mean_loss=0.013526120805181563
Online_Training [125/700]: mean_loss=0.004537733213510364
Online_Training [126/700]: mean_loss=0.017521535279229283
Online_Training [127/700]: mean_loss=0.024578670505434275
Online_Training [128/700]: mean_loss=0.012322465190663934
Online_Training [129/700]: mean_loss=0.00991405954118818
Online_Training [130/700]: mean_loss=0.01046060340013355
Online_Training [131/700]: mean_loss=0.014826022437773645
Online_Training [132/700]: mean_loss=0.015083264792338014
Online_Training [133/700]: mean_loss=0.09159777779132128
Online_Training [134/700]: mean_loss=0.036792869213968515
Online_Training [135/700]: mean_loss=0.04565774369984865
Online_Training [136/700]: mean_loss=0.04402771615423262
Online_Training [137/700]: mean_loss=0.03836723091080785
Online_Training [138/700]: mean_loss=0.031709643080830574
Online_Training [139/700]: mean_loss=0.014850887295324355
Online_Training [140/700]: mean_loss=0.018307599471881986
Online_Training [141/700]: mean_loss=0.015052640461362898
Online_Training [142/700]: mean_loss=0.006514061591587961
Online_Training [143/700]: mean_loss=0.006347091868519783
Online_Training [144/700]: mean_loss=0.024975929642096162
Online_Training [145/700]: mean_loss=0.0063817675109021366
Online_Training [146/700]: mean_loss=0.007763141125906259
Online_Training [147/700]: mean_loss=0.012801061384379864
Online_Training [148/700]: mean_loss=0.023741249460726976
Online_Training [149/700]: mean_loss=0.008476343704387546
Online_Training [150/700]: mean_loss=0.014316974906250834
Online_Training [151/700]: mean_loss=0.006623008521273732
Online_Training [152/700]: mean_loss=0.008512665168382227
Online_Training [153/700]: mean_loss=0.028459117282181978
Online_Training [154/700]: mean_loss=0.04581607738509774
Online_Training [155/700]: mean_loss=0.011090417741797864
Online_Training [156/700]: mean_loss=0.01608430768828839
Online_Training [157/700]: mean_loss=0.0037444408517330885
Online_Training [158/700]: mean_loss=0.011643082136288285
Online_Training [159/700]: mean_loss=0.0021782261173939332
Online_Training [160/700]: mean_loss=0.011825057561509311
Online_Training [161/700]: mean_loss=0.003267603402491659
Online_Training [162/700]: mean_loss=0.007522580737713724
Online_Training [163/700]: mean_loss=0.011693416512571275
Online_Training [164/700]: mean_loss=0.0058181905769743025
Online_Training [165/700]: mean_loss=0.020484235370531678
Online_Training [166/700]: mean_loss=0.17372538708150387
Online_Training [167/700]: mean_loss=0.1078797047957778
Online_Training [168/700]: mean_loss=0.0050307206402067095
Online_Training [169/700]: mean_loss=0.010948191746138036
Online_Training [170/700]: mean_loss=0.04980903444811702
Online_Training [171/700]: mean_loss=0.034957942785695195
Online_Training [172/700]: mean_loss=0.011302320170216262
Online_Training [173/700]: mean_loss=0.048754403833299875
Online_Training [174/700]: mean_loss=0.006087241636123508
Online_Training [175/700]: mean_loss=0.009303174738306552
Online_Training [176/700]: mean_loss=0.010885678930208087
Online_Training [177/700]: mean_loss=0.0149276900338009
Online_Training [178/700]: mean_loss=0.10239725653082132
Online_Training [179/700]: mean_loss=0.030652186833322048
Online_Training [180/700]: mean_loss=0.018949632067233324
Online_Training [181/700]: mean_loss=0.035371772246435285
Online_Training [182/700]: mean_loss=0.009561821701936424
Online_Training [183/700]: mean_loss=0.013583071646280587
Online_Training [184/700]: mean_loss=0.007888699183240533
Online_Training [185/700]: mean_loss=0.026353290304541588
Online_Training [186/700]: mean_loss=0.004764490004163235
Online_Training [187/700]: mean_loss=0.003687247517518699
Online_Training [188/700]: mean_loss=0.01165833615232259
Online_Training [189/700]: mean_loss=0.019833673955872655
Online_Training [190/700]: mean_loss=0.01314623944927007
Online_Training [191/700]: mean_loss=0.02497183089144528
Online_Training [192/700]: mean_loss=0.06346036726608872
Online_Training [193/700]: mean_loss=0.04945620079524815
Online_Training [194/700]: mean_loss=0.06619948241859674
Online_Training [195/700]: mean_loss=0.028708831639960408
Online_Training [196/700]: mean_loss=0.019139621523208916
Online_Training [197/700]: mean_loss=0.014120415202341974
Online_Training [198/700]: mean_loss=0.01201601733919233
Online_Training [199/700]: mean_loss=0.01806891756132245
Online_Training [200/700]: mean_loss=0.012512924615293741
Online_Training [201/700]: mean_loss=0.02365601761266589
Online_Training [202/700]: mean_loss=0.025735216215252876
Online_Training [203/700]: mean_loss=0.04877089988440275
Online_Training [204/700]: mean_loss=0.050741944927722216
Online_Training [205/700]: mean_loss=0.017095260205678642
Online_Training [206/700]: mean_loss=0.009991120547056198
Online_Training [207/700]: mean_loss=0.021831614430993795
Online_Training [208/700]: mean_loss=0.02041375101543963
Online_Training [209/700]: mean_loss=0.007952731451950967
Online_Training [210/700]: mean_loss=0.005622179945930839
Online_Training [211/700]: mean_loss=0.013104506768286228
Online_Training [212/700]: mean_loss=0.012390642194077373
Online_Training [213/700]: mean_loss=0.01390594441909343
Online_Training [214/700]: mean_loss=0.004150209133513272
Online_Training [215/700]: mean_loss=0.011035880190320313
Online_Training [216/700]: mean_loss=0.012231828062795103
Online_Training [217/700]: mean_loss=0.017491912352852523
Online_Training [218/700]: mean_loss=0.021626322995871305
Online_Training [219/700]: mean_loss=0.010725062573328614
Online_Training [220/700]: mean_loss=0.0117690289625898
Online_Training [221/700]: mean_loss=0.07585569936782122
Online_Training [222/700]: mean_loss=0.015667619765736163
Online_Training [223/700]: mean_loss=0.013753500999882817
Online_Training [224/700]: mean_loss=0.011974885826930404
Online_Training [225/700]: mean_loss=0.006198471877723932
Online_Training [226/700]: mean_loss=0.004183354438282549
Online_Training [227/700]: mean_loss=0.02054291986860335
Online_Training [228/700]: mean_loss=0.01800992025528103
Online_Training [229/700]: mean_loss=0.017595691024325788
Online_Training [230/700]: mean_loss=0.00739349948707968
Online_Training [231/700]: mean_loss=0.011675140238367021
Online_Training [232/700]: mean_loss=0.016630668425932527
Online_Training [233/700]: mean_loss=0.013745182077400386
Online_Training [234/700]: mean_loss=0.012045012088492513
Online_Training [235/700]: mean_loss=0.00875073007773608
Online_Training [236/700]: mean_loss=0.016654705395922065
Online_Training [237/700]: mean_loss=0.0073359140660613775
Online_Training [238/700]: mean_loss=0.016533123911358416
Online_Training [239/700]: mean_loss=0.007338158378843218
Online_Training [240/700]: mean_loss=0.009459972148761153
Online_Training [241/700]: mean_loss=0.0057578375563025475
Online_Training [242/700]: mean_loss=0.007156507985200733
Online_Training [243/700]: mean_loss=0.0035792318521998823
Online_Training [244/700]: mean_loss=0.007793637167196721
Online_Training [245/700]: mean_loss=0.008712013601325452
Online_Training [246/700]: mean_loss=0.0039091034559533
Online_Training [247/700]: mean_loss=0.016253704321570694
Online_Training [248/700]: mean_loss=0.06067942641675472
Online_Training [249/700]: mean_loss=0.14672261476516724
Online_Training [250/700]: mean_loss=0.01332824770361185
Online_Training [251/700]: mean_loss=0.013062705053016543
Online_Training [252/700]: mean_loss=0.0095143539365381
Online_Training [253/700]: mean_loss=0.008048784511629492
Online_Training [254/700]: mean_loss=0.016875352943316102
Online_Training [255/700]: mean_loss=0.014145380118861794
Online_Training [256/700]: mean_loss=0.0440020551905036
Online_Training [257/700]: mean_loss=0.056321293115615845
Online_Training [258/700]: mean_loss=0.03715155087411404
Online_Training [259/700]: mean_loss=0.013600171369034797
Online_Training [260/700]: mean_loss=0.011358629912137985
Online_Training [261/700]: mean_loss=0.026209319476038218
Online_Training [262/700]: mean_loss=0.014939573244191706
Online_Training [263/700]: mean_loss=0.01811274152714759
Online_Training [264/700]: mean_loss=0.006305936025455594
Online_Training [265/700]: mean_loss=0.025740576209500432
Online_Training [266/700]: mean_loss=0.024666914250701666
Online_Training [267/700]: mean_loss=0.0051482730195857584
Online_Training [268/700]: mean_loss=0.032529287273064256
Online_Training [269/700]: mean_loss=0.019711276283487678
Online_Training [270/700]: mean_loss=0.007238264486659318
Online_Training [271/700]: mean_loss=0.015965054160915315
Online_Training [272/700]: mean_loss=0.009384207311086357
Online_Training [273/700]: mean_loss=0.009910333435982466
Online_Training [274/700]: mean_loss=0.004270660661859438
Online_Training [275/700]: mean_loss=0.007111100945621729
Online_Training [276/700]: mean_loss=0.008985476742964238
Online_Training [277/700]: mean_loss=0.008181318989954889
Online_Training [278/700]: mean_loss=0.011031130678020418
Online_Training [279/700]: mean_loss=0.004571710771415383
Online_Training [280/700]: mean_loss=0.004538419452728704
Online_Training [281/700]: mean_loss=0.004581298329867423
Online_Training [282/700]: mean_loss=0.08650213479995728
Online_Training [283/700]: mean_loss=0.08435715176165104
Online_Training [284/700]: mean_loss=0.01878714421764016
Online_Training [285/700]: mean_loss=0.010545978671871126
Online_Training [286/700]: mean_loss=0.01759606332052499
Online_Training [287/700]: mean_loss=0.0063519926043227315
Online_Training [288/700]: mean_loss=0.00841231393860653
Online_Training [289/700]: mean_loss=0.02015977376140654
Online_Training [290/700]: mean_loss=0.005521234939806163
Online_Training [291/700]: mean_loss=0.007296161958947778
Online_Training [292/700]: mean_loss=0.008966027526184916
Online_Training [293/700]: mean_loss=0.010871815611608326
Online_Training [294/700]: mean_loss=0.009587412467226386
Online_Training [295/700]: mean_loss=0.2930445335805416
Online_Training [296/700]: mean_loss=0.08084265887737274
Online_Training [297/700]: mean_loss=0.04798048222437501
Online_Training [298/700]: mean_loss=0.022914958652108908
Online_Training [299/700]: mean_loss=0.014398211031220853
Online_Training [300/700]: mean_loss=0.039922831347212195
Online_Training [301/700]: mean_loss=0.01987071055918932
Online_Training [302/700]: mean_loss=0.013068439322523773
Online_Training [303/700]: mean_loss=0.027889140881597996
Online_Training [304/700]: mean_loss=0.05860431957989931
Online_Training [305/700]: mean_loss=0.03525302605703473
Online_Training [306/700]: mean_loss=0.009444124880246818
Online_Training [307/700]: mean_loss=0.012015585671178997
Online_Training [308/700]: mean_loss=0.009140853071585298
Online_Training [309/700]: mean_loss=0.015383446705527604
Online_Training [310/700]: mean_loss=0.06882878951728344
Online_Training [311/700]: mean_loss=0.18265160359442234
Online_Training [312/700]: mean_loss=0.08885352965444326
Online_Training [313/700]: mean_loss=0.008818601490929723
Online_Training [314/700]: mean_loss=0.01433062506839633
Online_Training [315/700]: mean_loss=0.005051139683928341
Online_Training [316/700]: mean_loss=0.0067416638485156
Online_Training [317/700]: mean_loss=0.014702033367939293
Online_Training [318/700]: mean_loss=0.014046947006136179
Online_Training [319/700]: mean_loss=0.02476288890466094
Online_Training [320/700]: mean_loss=0.0055456909467466176
Online_Training [321/700]: mean_loss=0.009975510067306459
Online_Training [322/700]: mean_loss=0.004109239729586989
Online_Training [323/700]: mean_loss=0.0012402339925756678
Online_Training [324/700]: mean_loss=0.00675666204188019
Online_Training [325/700]: mean_loss=0.00784445699537173
Online_Training [326/700]: mean_loss=0.006433976872358471
Online_Training [327/700]: mean_loss=0.01301011408213526
Online_Training [328/700]: mean_loss=0.02681459067389369
Online_Training [329/700]: mean_loss=0.004909297393169254
Online_Training [330/700]: mean_loss=0.006668356072623283
Online_Training [331/700]: mean_loss=0.012399865314364433
Online_Training [332/700]: mean_loss=0.023995768278837204
Online_Training [333/700]: mean_loss=0.010078487452119589
Online_Training [334/700]: mean_loss=0.014700501691550016
Online_Training [335/700]: mean_loss=0.01366353768389672
Online_Training [336/700]: mean_loss=0.029342787340283394
Online_Training [337/700]: mean_loss=0.0034341709106229246
Online_Training [338/700]: mean_loss=0.005709398363251239
Online_Training [339/700]: mean_loss=0.02608445705845952
Online_Training [340/700]: mean_loss=0.005251593538559973
Online_Training [341/700]: mean_loss=0.005872015259228647
Online_Training [342/700]: mean_loss=0.014380079344846308
Online_Training [343/700]: mean_loss=0.008023217669688165
Online_Training [344/700]: mean_loss=0.005995137442369014
Online_Training [345/700]: mean_loss=0.006259185844101012
Online_Training [346/700]: mean_loss=0.013324948726221919
Online_Training [347/700]: mean_loss=0.00713835988426581
Online_Training [348/700]: mean_loss=0.013293017400428653
Online_Training [349/700]: mean_loss=0.009748681797645986
Online_Training [350/700]: mean_loss=0.01634665089659393
Online_Training [351/700]: mean_loss=0.08751113433390856
Online_Training [352/700]: mean_loss=0.034012037329375744
Online_Training [353/700]: mean_loss=0.05583129217848182
Online_Training [354/700]: mean_loss=0.046149262227118015
Online_Training [355/700]: mean_loss=0.11723633483052254
Online_Training [356/700]: mean_loss=0.08162644132971764
Online_Training [357/700]: mean_loss=0.010467183194123209
Online_Training [358/700]: mean_loss=0.007888113672379404
Online_Training [359/700]: mean_loss=0.02485190494917333
Online_Training [360/700]: mean_loss=0.012470064568333328
Online_Training [361/700]: mean_loss=0.010248622042126954
Online_Training [362/700]: mean_loss=0.004833958693780005
Online_Training [363/700]: mean_loss=0.023152183508500457
Online_Training [364/700]: mean_loss=0.020705634262412786
Online_Training [365/700]: mean_loss=0.014871373190544546
Online_Training [366/700]: mean_loss=0.004702603502664715
Online_Training [367/700]: mean_loss=0.003705493756569922
Online_Training [368/700]: mean_loss=0.014266551355831325
Online_Training [369/700]: mean_loss=0.004957156605087221
Online_Training [370/700]: mean_loss=0.031979536172002554
Online_Training [371/700]: mean_loss=0.043555077631026506
Online_Training [372/700]: mean_loss=0.0220594834536314
Online_Training [373/700]: mean_loss=0.060286945197731256
Online_Training [374/700]: mean_loss=0.10010965447872877
Online_Training [375/700]: mean_loss=0.013079932541586459
Online_Training [376/700]: mean_loss=0.009948718128725886
Online_Training [377/700]: mean_loss=0.01223257218953222
Online_Training [378/700]: mean_loss=0.011493183905258775
Online_Training [379/700]: mean_loss=0.07298027910292149
Online_Training [380/700]: mean_loss=0.052231482695788145
Online_Training [381/700]: mean_loss=0.006364612432662398
Online_Training [382/700]: mean_loss=0.01864693488460034
Online_Training [383/700]: mean_loss=0.0074393010581843555
Online_Training [384/700]: mean_loss=0.015741565264761448
Online_Training [385/700]: mean_loss=0.012348395655862987
Online_Training [386/700]: mean_loss=0.010833681095391512
Online_Training [387/700]: mean_loss=0.011615957831963897
Online_Training [388/700]: mean_loss=0.02096595522016287
Online_Training [389/700]: mean_loss=0.0038042384840082377
Online_Training [390/700]: mean_loss=0.007842135149985552
Online_Training [391/700]: mean_loss=0.010090427938848734
Online_Training [392/700]: mean_loss=0.0016393739497289062
Online_Training [393/700]: mean_loss=0.02631271118298173
Online_Training [394/700]: mean_loss=0.005483396642375737
Online_Training [395/700]: mean_loss=0.00679445854621008
Online_Training [396/700]: mean_loss=0.004671798407798633
Online_Training [397/700]: mean_loss=0.010186345898546278
Online_Training [398/700]: mean_loss=0.01699200179427862
Online_Training [399/700]: mean_loss=0.007729000877588987
Online_Training [400/700]: mean_loss=0.011167202610522509
Online_Training [401/700]: mean_loss=0.011511657270602882
Online_Training [402/700]: mean_loss=0.008169818844180554
Online_Training [403/700]: mean_loss=0.004132479021791369
Online_Training [404/700]: mean_loss=0.006011014396790415
Online_Training [405/700]: mean_loss=0.009532208321616054
Online_Training [406/700]: mean_loss=0.007464628084562719
Online_Training [407/700]: mean_loss=0.06872871797531843
Online_Training [408/700]: mean_loss=0.08589806128293276
Online_Training [409/700]: mean_loss=0.01635694783180952
Online_Training [410/700]: mean_loss=0.014127500355243683
Online_Training [411/700]: mean_loss=0.017700905678793788
Online_Training [412/700]: mean_loss=0.07970891799777746
Online_Training [413/700]: mean_loss=0.1385695170611143
Online_Training [414/700]: mean_loss=0.027164567727595568
Online_Training [415/700]: mean_loss=0.010658216662704945
Online_Training [416/700]: mean_loss=0.028259596787393093
Online_Training [417/700]: mean_loss=0.014854345005005598
Online_Training [418/700]: mean_loss=0.016125964233651757
Online_Training [419/700]: mean_loss=0.022842269390821457
Online_Training [420/700]: mean_loss=0.013529063086025417
Online_Training [421/700]: mean_loss=0.014249670901335776
Online_Training [422/700]: mean_loss=0.00974253739695996
Online_Training [423/700]: mean_loss=0.0019835567800328135
Online_Training [424/700]: mean_loss=0.006936097517609596
Online_Training [425/700]: mean_loss=0.008244060561992228
Online_Training [426/700]: mean_loss=0.010145715088583529
Online_Training [427/700]: mean_loss=0.006316944025456905
Online_Training [428/700]: mean_loss=0.01606341591104865
Online_Training [429/700]: mean_loss=0.017191059421747923
Online_Training [430/700]: mean_loss=0.015632214955985546
Online_Training [431/700]: mean_loss=0.01766408304683864
Online_Training [432/700]: mean_loss=0.01568950363434851
Online_Training [433/700]: mean_loss=0.007539374753832817
Online_Training [434/700]: mean_loss=0.0023554773651994765
Online_Training [435/700]: mean_loss=0.003838608361547813
Online_Training [436/700]: mean_loss=0.010276437446009368
Online_Training [437/700]: mean_loss=0.008420680009294301
Online_Training [438/700]: mean_loss=0.02450730581767857
Online_Training [439/700]: mean_loss=0.01620211824774742
Online_Training [440/700]: mean_loss=0.015310992021113634
Online_Training [441/700]: mean_loss=0.008352406322956085
Online_Training [442/700]: mean_loss=0.002901069790823385
Online_Training [443/700]: mean_loss=0.00824098166776821
Online_Training [444/700]: mean_loss=0.01011639868374914
Online_Training [445/700]: mean_loss=0.004728973202873021
Online_Training [446/700]: mean_loss=0.005919280578382313
Online_Training [447/700]: mean_loss=0.006861117668449879
Online_Training [448/700]: mean_loss=0.004497092217206955
Online_Training [449/700]: mean_loss=0.007861002581194043
Online_Training [450/700]: mean_loss=0.015449136029928923
Online_Training [451/700]: mean_loss=0.005439422093331814
Online_Training [452/700]: mean_loss=0.003388655575690791
Online_Training [453/700]: mean_loss=0.0036382737453095615
Online_Training [454/700]: mean_loss=0.006538450194057077
Online_Training [455/700]: mean_loss=0.013763611088506877
Online_Training [456/700]: mean_loss=0.007591631438117474
Online_Training [457/700]: mean_loss=0.051376736257225275
Online_Training [458/700]: mean_loss=0.02912494563497603
Online_Training [459/700]: mean_loss=0.01650410029105842
Online_Training [460/700]: mean_loss=0.018226108280941844
Online_Training [461/700]: mean_loss=0.010679843137040734
Online_Training [462/700]: mean_loss=0.006569137214682996
Online_Training [463/700]: mean_loss=0.007442465401254594
Online_Training [464/700]: mean_loss=0.00814573693787679
Online_Training [465/700]: mean_loss=0.0032609595509711653
Online_Training [466/700]: mean_loss=0.009446627111174166
Online_Training [467/700]: mean_loss=0.013910658890381455
Online_Training [468/700]: mean_loss=0.012574563617818058
Online_Training [469/700]: mean_loss=0.003936396795324981
Online_Training [470/700]: mean_loss=0.01499520312063396
Online_Training [471/700]: mean_loss=0.011419772868975997
Online_Training [472/700]: mean_loss=0.009395261527970433
Online_Training [473/700]: mean_loss=0.017452913569286466
Online_Training [474/700]: mean_loss=0.005013103771489114
Online_Training [475/700]: mean_loss=0.00749355903826654
Online_Training [476/700]: mean_loss=0.010208998806774616
Online_Training [477/700]: mean_loss=0.005148154392372817
Online_Training [478/700]: mean_loss=0.006943206186406314
Online_Training [479/700]: mean_loss=0.013592339120805264
Online_Training [480/700]: mean_loss=0.004130556102609262
Online_Training [481/700]: mean_loss=0.008446661988273263
Online_Training [482/700]: mean_loss=0.004868265299592167
Online_Training [483/700]: mean_loss=0.0059424861101433635
Online_Training [484/700]: mean_loss=0.009731702040880919
Online_Training [485/700]: mean_loss=0.02392063825391233
Online_Training [486/700]: mean_loss=0.013341800775378942
Online_Training [487/700]: mean_loss=0.00726993492571637
Online_Training [488/700]: mean_loss=0.07670581061393023
Online_Training [489/700]: mean_loss=0.10632536932826042
Online_Training [490/700]: mean_loss=0.040793921099975705
Online_Training [491/700]: mean_loss=0.015049557550810277
Online_Training [492/700]: mean_loss=0.010337132029235363
Online_Training [493/700]: mean_loss=0.08065438363701105
Online_Training [494/700]: mean_loss=0.034345654072239995
Online_Training [495/700]: mean_loss=0.007278660195879638
Online_Training [496/700]: mean_loss=0.014740208513103426
Online_Training [497/700]: mean_loss=0.013711386825889349
Online_Training [498/700]: mean_loss=0.0063745343359187245
Online_Training [499/700]: mean_loss=0.013130940380506217
Online_Training [500/700]: mean_loss=0.007980064139701426
Online_Training [501/700]: mean_loss=0.00833042582962662
Online_Training [502/700]: mean_loss=0.006399642094038427
Online_Training [503/700]: mean_loss=0.014282530872151256
Online_Training [504/700]: mean_loss=0.009514176868833601
Online_Training [505/700]: mean_loss=0.010509791551157832
Online_Training [506/700]: mean_loss=0.009889515698887408
Online_Training [507/700]: mean_loss=0.004851905629038811
Online_Training [508/700]: mean_loss=0.007094809436239302
Online_Training [509/700]: mean_loss=0.013544912333600223
Online_Training [510/700]: mean_loss=0.0024731834419071674
Online_Training [511/700]: mean_loss=0.02250018948689103
Online_Training [512/700]: mean_loss=0.007588922686409205
Online_Training [513/700]: mean_loss=0.009385363780893385
Online_Training [514/700]: mean_loss=0.015264346031472087
Online_Training [515/700]: mean_loss=0.00927050324389711
Online_Training [516/700]: mean_loss=0.012036483036354184
Online_Training [517/700]: mean_loss=0.011411406099796295
Online_Training [518/700]: mean_loss=0.010715878335759044
Online_Training [519/700]: mean_loss=0.008737674623262137
Online_Training [520/700]: mean_loss=0.004199303104542196
Online_Training [521/700]: mean_loss=0.014984074397943914
Online_Training [522/700]: mean_loss=0.006048215203918517
Online_Training [523/700]: mean_loss=0.004479267634451389
Online_Training [524/700]: mean_loss=0.011477615335024893
Online_Training [525/700]: mean_loss=0.006063019798602909
Online_Training [526/700]: mean_loss=0.006808216916397214
Online_Training [527/700]: mean_loss=0.006390359078068286
Online_Training [528/700]: mean_loss=0.006075912620872259
Online_Training [529/700]: mean_loss=0.004651292052585632
Online_Training [530/700]: mean_loss=0.00701724347891286
Online_Training [531/700]: mean_loss=0.01006847235839814
Online_Training [532/700]: mean_loss=0.006265264004468918
Online_Training [533/700]: mean_loss=0.003580208169296384
Online_Training [534/700]: mean_loss=0.022396805230528116
Online_Training [535/700]: mean_loss=0.0307467938400805
Online_Training [536/700]: mean_loss=0.024325093952938914
Online_Training [537/700]: mean_loss=0.013227078597992659
Online_Training [538/700]: mean_loss=0.007011685869656503
Online_Training [539/700]: mean_loss=0.0085231316043064
Online_Training [540/700]: mean_loss=0.005854010465554893
Online_Training [541/700]: mean_loss=0.006098122627008706
Online_Training [542/700]: mean_loss=0.018637197208590806
Online_Training [543/700]: mean_loss=0.01414228673093021
Online_Training [544/700]: mean_loss=0.0074384151375852525
Online_Training [545/700]: mean_loss=0.01228065462782979
Online_Training [546/700]: mean_loss=0.0038294792466331273
Online_Training [547/700]: mean_loss=0.00770019250921905
Online_Training [548/700]: mean_loss=0.005614978610537946
Online_Training [549/700]: mean_loss=0.0069862824166193604
Online_Training [550/700]: mean_loss=0.02411020128056407
Online_Training [551/700]: mean_loss=0.004599925654474646
Online_Training [552/700]: mean_loss=0.018620835384353995
Online_Training [553/700]: mean_loss=0.008212790184188634
Online_Training [554/700]: mean_loss=0.012479673023335636
Online_Training [555/700]: mean_loss=0.006751803099177778
Online_Training [556/700]: mean_loss=0.008403464336879551
Online_Training [557/700]: mean_loss=0.005429891054518521
Online_Training [558/700]: mean_loss=0.0055064104963094
Online_Training [559/700]: mean_loss=0.004248296638252214
Online_Training [560/700]: mean_loss=0.006171678425744176
Online_Training [561/700]: mean_loss=0.007668631093110889
Online_Training [562/700]: mean_loss=0.011368493433110416
Online_Training [563/700]: mean_loss=0.011349924257956445
Online_Training [564/700]: mean_loss=0.0023141168931033462
Online_Training [565/700]: mean_loss=0.010278969071805477
Online_Training [566/700]: mean_loss=0.01340701908338815
Online_Training [567/700]: mean_loss=0.07024256838485599
Online_Training [568/700]: mean_loss=0.024675645167008042
Online_Training [569/700]: mean_loss=0.00936635909602046
Online_Training [570/700]: mean_loss=0.01876311213709414
Online_Training [571/700]: mean_loss=0.0071536769974045455
Online_Training [572/700]: mean_loss=0.009855790180154145
Online_Training [573/700]: mean_loss=0.005140375578776002
Online_Training [574/700]: mean_loss=0.014261611853726208
Online_Training [575/700]: mean_loss=0.014432935509830713
Online_Training [576/700]: mean_loss=0.01256120193284005
Online_Training [577/700]: mean_loss=0.0016689831099938601
Online_Training [578/700]: mean_loss=0.004389242210891098
Online_Training [579/700]: mean_loss=0.0020715033897431567
Online_Training [580/700]: mean_loss=0.008895822567865252
Online_Training [581/700]: mean_loss=0.004304961708839983
Online_Training [582/700]: mean_loss=0.013823794666677713
Online_Training [583/700]: mean_loss=0.009174969745799899
Online_Training [584/700]: mean_loss=0.012015927932225168
Online_Training [585/700]: mean_loss=0.021195679204538465
Online_Training [586/700]: mean_loss=0.011003458523191512
Online_Training [587/700]: mean_loss=0.012136125122196972
Online_Training [588/700]: mean_loss=0.005014161637518555
Online_Training [589/700]: mean_loss=0.010212482651695609
Online_Training [590/700]: mean_loss=0.009548320434987545
Online_Training [591/700]: mean_loss=0.006527437304612249
Online_Training [592/700]: mean_loss=0.011941757751628757
Online_Training [593/700]: mean_loss=0.007161238288972527
Online_Training [594/700]: mean_loss=0.008644812332931906
Online_Training [595/700]: mean_loss=0.005544470564927906
Online_Training [596/700]: mean_loss=0.009550995484460145
Online_Training [597/700]: mean_loss=0.02380225108936429
Online_Training [598/700]: mean_loss=0.010288904653862119
Online_Training [599/700]: mean_loss=0.03203869494609535
Online_Training [600/700]: mean_loss=0.005066166282631457
Online_Training [601/700]: mean_loss=0.013862128253094852
Online_Training [602/700]: mean_loss=0.008556729881092906
Online_Training [603/700]: mean_loss=0.005968755052890629
Online_Training [604/700]: mean_loss=0.014007994206622243
Online_Training [605/700]: mean_loss=0.0042970832146238536
Online_Training [606/700]: mean_loss=0.009115762659348547
Online_Training [607/700]: mean_loss=0.01657413865905255
Online_Training [608/700]: mean_loss=0.004742524062748998
Online_Training [609/700]: mean_loss=0.011879184748977423
Online_Training [610/700]: mean_loss=0.0030311924347188324
Online_Training [611/700]: mean_loss=0.008055525133386254
Online_Training [612/700]: mean_loss=0.017982036340981722
Online_Training [613/700]: mean_loss=0.009915551054291427
Online_Training [614/700]: mean_loss=0.005963193427305669
Online_Training [615/700]: mean_loss=0.00406083109555766
Online_Training [616/700]: mean_loss=0.0032924116239883006
Online_Training [617/700]: mean_loss=0.007781270542182028
Online_Training [618/700]: mean_loss=0.022259572288021445
Online_Training [619/700]: mean_loss=0.008937721257098019
Online_Training [620/700]: mean_loss=0.0023089750320650637
Online_Training [621/700]: mean_loss=0.005605344544164836
Online_Training [622/700]: mean_loss=0.024705505929887295
Online_Training [623/700]: mean_loss=0.040108202025294304
Online_Training [624/700]: mean_loss=0.009290498215705156
Online_Training [625/700]: mean_loss=0.014229798689484596
Online_Training [626/700]: mean_loss=0.0069547833991236985
Online_Training [627/700]: mean_loss=0.008096968987956643
Online_Training [628/700]: mean_loss=0.009017207368742675
Online_Training [629/700]: mean_loss=0.006223618402145803
Online_Training [630/700]: mean_loss=0.01097481488250196
Online_Training [631/700]: mean_loss=0.01641986658796668
Online_Training [632/700]: mean_loss=0.010210225242190063
Online_Training [633/700]: mean_loss=0.01092197629623115
Online_Training [634/700]: mean_loss=0.012614643317647278
Online_Training [635/700]: mean_loss=0.005629575869534165
Online_Training [636/700]: mean_loss=0.0110076506389305
Online_Training [637/700]: mean_loss=0.011632531764917076
Online_Training [638/700]: mean_loss=0.016127959941513836
Online_Training [639/700]: mean_loss=0.010232160333544016
Online_Training [640/700]: mean_loss=0.005535316769964993
Online_Training [641/700]: mean_loss=0.011009573354385793
Online_Training [642/700]: mean_loss=0.009123695781454444
Online_Training [643/700]: mean_loss=0.014165945467539132
Online_Training [644/700]: mean_loss=0.008587388205341995
Online_Training [645/700]: mean_loss=0.00521220889640972
Online_Training [646/700]: mean_loss=0.008209015359170735
Online_Training [647/700]: mean_loss=0.0129935541190207
Online_Training [648/700]: mean_loss=0.00919438258279115
Online_Training [649/700]: mean_loss=0.0065352426609024405
Online_Training [650/700]: mean_loss=0.007297303876839578
Online_Training [651/700]: mean_loss=0.004776700807269663
Online_Training [652/700]: mean_loss=0.005903009499888867
Online_Training [653/700]: mean_loss=0.014412745600566268
Online_Training [654/700]: mean_loss=0.0038342124898917973
Online_Training [655/700]: mean_loss=0.008727967273443937
Online_Training [656/700]: mean_loss=0.006403776700608432
Online_Training [657/700]: mean_loss=0.009724661125801504
Online_Training [658/700]: mean_loss=0.019233083818107843
Online_Training [659/700]: mean_loss=0.02137699769809842
Online_Training [660/700]: mean_loss=0.01112513942644
Online_Training [661/700]: mean_loss=0.09410533681511879
Online_Training [662/700]: mean_loss=0.023036848986521363
Online_Training [663/700]: mean_loss=0.006700100959278643
Online_Training [664/700]: mean_loss=0.004861824854742736
Online_Training [665/700]: mean_loss=0.013200344401411712
Online_Training [666/700]: mean_loss=0.0051419041701592505
Online_Training [667/700]: mean_loss=0.006888095464091748
Online_Training [668/700]: mean_loss=0.0038610546325799078
Online_Training [669/700]: mean_loss=0.01570798724424094
Online_Training [670/700]: mean_loss=0.022339534712955356
Online_Training [671/700]: mean_loss=0.007055975263938308
Online_Training [672/700]: mean_loss=0.011979620903730392
Online_Training [673/700]: mean_loss=0.06070703873410821
Online_Training [674/700]: mean_loss=0.05257028853520751
Online_Training [675/700]: mean_loss=0.002923542575445026
Online_Training [676/700]: mean_loss=0.009846201748587191
Online_Training [677/700]: mean_loss=0.012185916304588318
Online_Training [678/700]: mean_loss=0.005737140018027276
Online_Training [679/700]: mean_loss=0.009626095998100936
Online_Training [680/700]: mean_loss=0.004007503041066229
Online_Training [681/700]: mean_loss=0.015970837441273034
Online_Training [682/700]: mean_loss=0.0062881443882361054
Online_Training [683/700]: mean_loss=0.00920146267162636
Online_Training [684/700]: mean_loss=0.013965530903078616
Online_Training [685/700]: mean_loss=0.004804585943929851
Online_Training [686/700]: mean_loss=0.01100846752524376
Online_Training [687/700]: mean_loss=0.010988266905769706
Online_Training [688/700]: mean_loss=0.0212326489854604
Online_Training [689/700]: mean_loss=0.004149609536398202
Online_Training [690/700]: mean_loss=0.019440562115050852
Online_Training [691/700]: mean_loss=0.0033282841613981873
Online_Training [692/700]: mean_loss=0.0061331301112659276
Online_Training [693/700]: mean_loss=0.005157297127880156
Online_Training [694/700]: mean_loss=0.005407845426816493
Online_Training [695/700]: mean_loss=0.003033936256542802
Online_Training [696/700]: mean_loss=0.009855426149442792
Online_Training [697/700]: mean_loss=0.005927320220507681
Online_Training [698/700]: mean_loss=0.007027625397313386
Online_Training [699/700]: mean_loss=0.012044435599818826
Online_Training [700/700]: mean_loss=0.015930513152852654
Q_Learning [1/300]: mean_loss=0.14379365928471088
Q_Learning [2/300]: mean_loss=0.13652436062693596
Q_Learning [3/300]: mean_loss=0.12723330687731504
Q_Learning [4/300]: mean_loss=0.12407764792442322
Q_Learning [5/300]: mean_loss=0.14681462198495865
Q_Learning [6/300]: mean_loss=0.1590529978275299
Q_Learning [7/300]: mean_loss=0.1967894695699215
Q_Learning [8/300]: mean_loss=0.14532256312668324
Q_Learning [9/300]: mean_loss=0.09729741793125868
Q_Learning [10/300]: mean_loss=0.10919668059796095
Q_Learning [11/300]: mean_loss=0.0397261343896389
Q_Learning [12/300]: mean_loss=0.06249964749440551
Q_Learning [13/300]: mean_loss=0.03246643650345504
Q_Learning [14/300]: mean_loss=0.027471465291455388
Q_Learning [15/300]: mean_loss=0.03590275626629591
Q_Learning [16/300]: mean_loss=0.03257928928360343
Q_Learning [17/300]: mean_loss=0.11208933684974909
Q_Learning [18/300]: mean_loss=0.03910992434248328
Q_Learning [19/300]: mean_loss=0.15663254261016846
Q_Learning [20/300]: mean_loss=0.08278492465615273
Q_Learning [21/300]: mean_loss=0.05713925790041685
Q_Learning [22/300]: mean_loss=0.053254249040037394
Q_Learning [23/300]: mean_loss=0.09144677314907312
Q_Learning [24/300]: mean_loss=0.040933961514383554
Q_Learning [25/300]: mean_loss=0.10102562606334686
Q_Learning [26/300]: mean_loss=0.08547197002917528
Q_Learning [27/300]: mean_loss=0.06946236081421375
Q_Learning [28/300]: mean_loss=0.04319492122158408
Q_Learning [29/300]: mean_loss=0.07279822789132595
Q_Learning [30/300]: mean_loss=0.08007075265049934
Q_Learning [31/300]: mean_loss=0.07651230599731207
Q_Learning [32/300]: mean_loss=0.0823061028495431
Q_Learning [33/300]: mean_loss=0.016691031865775585
Q_Learning [34/300]: mean_loss=0.015379765070974827
Q_Learning [35/300]: mean_loss=0.021647138288244605
Q_Learning [36/300]: mean_loss=0.09695232287049294
Q_Learning [37/300]: mean_loss=0.05565664358437061
Q_Learning [38/300]: mean_loss=0.06956262234598398
Q_Learning [39/300]: mean_loss=0.01605657651089132
Q_Learning [40/300]: mean_loss=0.07021488808095455
Q_Learning [41/300]: mean_loss=0.02280333056114614
Q_Learning [42/300]: mean_loss=0.04838643362745643
Q_Learning [43/300]: mean_loss=0.03583622258156538
Q_Learning [44/300]: mean_loss=0.021857504034414887
Q_Learning [45/300]: mean_loss=0.016779354540631175
Q_Learning [46/300]: mean_loss=0.07972283009439707
Q_Learning [47/300]: mean_loss=0.007389630540274084
Q_Learning [48/300]: mean_loss=0.009365732898004353
Q_Learning [49/300]: mean_loss=0.01003617828246206
Q_Learning [50/300]: mean_loss=0.04538506967946887
Q_Learning [51/300]: mean_loss=0.0625487701036036
Q_Learning [52/300]: mean_loss=0.005535666074138135
Q_Learning [53/300]: mean_loss=0.027137911412864923
Q_Learning [54/300]: mean_loss=0.006661532039288431
Q_Learning [55/300]: mean_loss=0.052565556950867176
Q_Learning [56/300]: mean_loss=0.07069502677768469
Q_Learning [57/300]: mean_loss=0.022084041265770793
Q_Learning [58/300]: mean_loss=0.059025296941399574
Q_Learning [59/300]: mean_loss=0.0483629796653986
Q_Learning [60/300]: mean_loss=0.02441319520585239
Q_Learning [61/300]: mean_loss=0.05435886653140187
Q_Learning [62/300]: mean_loss=0.048868747893720865
Q_Learning [63/300]: mean_loss=0.035465383203700185
Q_Learning [64/300]: mean_loss=0.08984720427542925
Q_Learning [65/300]: mean_loss=0.1485891081392765
Q_Learning [66/300]: mean_loss=0.019828547723591328
Q_Learning [67/300]: mean_loss=0.10768634267151356
Q_Learning [68/300]: mean_loss=0.0946847116574645
Q_Learning [69/300]: mean_loss=0.02171393297612667
Q_Learning [70/300]: mean_loss=0.02236006036400795
Q_Learning [71/300]: mean_loss=0.021936431992799044
Q_Learning [72/300]: mean_loss=0.020922234747558832
Q_Learning [73/300]: mean_loss=0.017372254049405456
Q_Learning [74/300]: mean_loss=0.01636058557778597
Q_Learning [75/300]: mean_loss=0.13570336159318686
Q_Learning [76/300]: mean_loss=0.11785295885056257
Q_Learning [77/300]: mean_loss=0.03779352456331253
Q_Learning [78/300]: mean_loss=0.009803034423384815
Q_Learning [79/300]: mean_loss=0.023020541993901134
Q_Learning [80/300]: mean_loss=0.010023465496487916
Q_Learning [81/300]: mean_loss=0.009153705090284348
Q_Learning [82/300]: mean_loss=0.025613679783418775
Q_Learning [83/300]: mean_loss=0.01692721585277468
Q_Learning [84/300]: mean_loss=0.046464398968964815
Q_Learning [85/300]: mean_loss=0.01191437419038266
Q_Learning [86/300]: mean_loss=0.008889218792319298
Q_Learning [87/300]: mean_loss=0.052331604063510895
Q_Learning [88/300]: mean_loss=0.023599495412781835
Q_Learning [89/300]: mean_loss=0.021168157923966646
Q_Learning [90/300]: mean_loss=0.011682613519951701
Q_Learning [91/300]: mean_loss=0.0047304725158028305
Q_Learning [92/300]: mean_loss=0.005111530481372029
Q_Learning [93/300]: mean_loss=0.01037893327884376
Q_Learning [94/300]: mean_loss=0.008307152020279318
Q_Learning [95/300]: mean_loss=0.07945015653967857
Q_Learning [96/300]: mean_loss=0.036985857877880335
Q_Learning [97/300]: mean_loss=0.008068460854701698
Q_Learning [98/300]: mean_loss=0.029141988372430205
Q_Learning [99/300]: mean_loss=0.01161493279505521
Q_Learning [100/300]: mean_loss=0.024833623552694917
Q_Learning [101/300]: mean_loss=0.01306504337117076
Q_Learning [102/300]: mean_loss=0.007245465298183262
Q_Learning [103/300]: mean_loss=0.023570689372718334
Q_Learning [104/300]: mean_loss=0.03386117029003799
Q_Learning [105/300]: mean_loss=0.03202241752296686
Q_Learning [106/300]: mean_loss=0.015229763695970178
Q_Learning [107/300]: mean_loss=0.019312503281980753
Q_Learning [108/300]: mean_loss=0.013639129814691842
Q_Learning [109/300]: mean_loss=0.010030929406639189
Q_Learning [110/300]: mean_loss=0.015263483859598637
Q_Learning [111/300]: mean_loss=0.021636291639879346
Q_Learning [112/300]: mean_loss=0.008223032113164663
Q_Learning [113/300]: mean_loss=0.013050094596110284
Q_Learning [114/300]: mean_loss=0.008519579016137868
Q_Learning [115/300]: mean_loss=0.0054563042358495295
Q_Learning [116/300]: mean_loss=0.0032521322718821466
Q_Learning [117/300]: mean_loss=0.012692154268734157
Q_Learning [118/300]: mean_loss=0.04633365012705326
Q_Learning [119/300]: mean_loss=0.01513080601580441
Q_Learning [120/300]: mean_loss=0.014814761467278004
Q_Learning [121/300]: mean_loss=0.016875337343662977
Q_Learning [122/300]: mean_loss=0.005608197767287493
Q_Learning [123/300]: mean_loss=0.030938980169594288
Q_Learning [124/300]: mean_loss=0.013526120805181563
Q_Learning [125/300]: mean_loss=0.004537733213510364
Q_Learning [126/300]: mean_loss=0.017521535279229283
Q_Learning [127/300]: mean_loss=0.024578670505434275
Q_Learning [128/300]: mean_loss=0.012322465190663934
Q_Learning [129/300]: mean_loss=0.00991405954118818
Q_Learning [130/300]: mean_loss=0.01046060340013355
Q_Learning [131/300]: mean_loss=0.014826022437773645
Q_Learning [132/300]: mean_loss=0.015083264792338014
Q_Learning [133/300]: mean_loss=0.09159777779132128
Q_Learning [134/300]: mean_loss=0.036792869213968515
Q_Learning [135/300]: mean_loss=0.04565774369984865
Q_Learning [136/300]: mean_loss=0.04402771615423262
Q_Learning [137/300]: mean_loss=0.03836723091080785
Q_Learning [138/300]: mean_loss=0.031709643080830574
Q_Learning [139/300]: mean_loss=0.014850887295324355
Q_Learning [140/300]: mean_loss=0.018307599471881986
Q_Learning [141/300]: mean_loss=0.015052640461362898
Q_Learning [142/300]: mean_loss=0.006514061591587961
Q_Learning [143/300]: mean_loss=0.006347091868519783
Q_Learning [144/300]: mean_loss=0.024975929642096162
Q_Learning [145/300]: mean_loss=0.0063817675109021366
Q_Learning [146/300]: mean_loss=0.007763141125906259
Q_Learning [147/300]: mean_loss=0.012801061384379864
Q_Learning [148/300]: mean_loss=0.023741249460726976
Q_Learning [149/300]: mean_loss=0.008476343704387546
Q_Learning [150/300]: mean_loss=0.014316974906250834
Q_Learning [151/300]: mean_loss=0.006623008521273732
Q_Learning [152/300]: mean_loss=0.008512665168382227
Q_Learning [153/300]: mean_loss=0.028459117282181978
Q_Learning [154/300]: mean_loss=0.04581607738509774
Q_Learning [155/300]: mean_loss=0.011090417741797864
Q_Learning [156/300]: mean_loss=0.01608430768828839
Q_Learning [157/300]: mean_loss=0.0037444408517330885
Q_Learning [158/300]: mean_loss=0.011643082136288285
Q_Learning [159/300]: mean_loss=0.0021782261173939332
Q_Learning [160/300]: mean_loss=0.011825057561509311
Q_Learning [161/300]: mean_loss=0.003267603402491659
Q_Learning [162/300]: mean_loss=0.007522580737713724
Q_Learning [163/300]: mean_loss=0.011693416512571275
Q_Learning [164/300]: mean_loss=0.0058181905769743025
Q_Learning [165/300]: mean_loss=0.020484235370531678
Q_Learning [166/300]: mean_loss=0.17372538708150387
Q_Learning [167/300]: mean_loss=0.1078797047957778
Q_Learning [168/300]: mean_loss=0.0050307206402067095
Q_Learning [169/300]: mean_loss=0.010948191746138036
Q_Learning [170/300]: mean_loss=0.04980903444811702
Q_Learning [171/300]: mean_loss=0.034957942785695195
Q_Learning [172/300]: mean_loss=0.011302320170216262
Q_Learning [173/300]: mean_loss=0.048754403833299875
Q_Learning [174/300]: mean_loss=0.006087241636123508
Q_Learning [175/300]: mean_loss=0.009303174738306552
Q_Learning [176/300]: mean_loss=0.010885678930208087
Q_Learning [177/300]: mean_loss=0.0149276900338009
Q_Learning [178/300]: mean_loss=0.10239725653082132
Q_Learning [179/300]: mean_loss=0.030652186833322048
Q_Learning [180/300]: mean_loss=0.018949632067233324
Q_Learning [181/300]: mean_loss=0.035371772246435285
Q_Learning [182/300]: mean_loss=0.009561821701936424
Q_Learning [183/300]: mean_loss=0.013583071646280587
Q_Learning [184/300]: mean_loss=0.007888699183240533
Q_Learning [185/300]: mean_loss=0.026353290304541588
Q_Learning [186/300]: mean_loss=0.004764490004163235
Q_Learning [187/300]: mean_loss=0.003687247517518699
Q_Learning [188/300]: mean_loss=0.01165833615232259
Q_Learning [189/300]: mean_loss=0.019833673955872655
Q_Learning [190/300]: mean_loss=0.01314623944927007
Q_Learning [191/300]: mean_loss=0.02497183089144528
Q_Learning [192/300]: mean_loss=0.06346036726608872
Q_Learning [193/300]: mean_loss=0.04945620079524815
Q_Learning [194/300]: mean_loss=0.06619948241859674
Q_Learning [195/300]: mean_loss=0.028708831639960408
Q_Learning [196/300]: mean_loss=0.019139621523208916
Q_Learning [197/300]: mean_loss=0.014120415202341974
Q_Learning [198/300]: mean_loss=0.01201601733919233
Q_Learning [199/300]: mean_loss=0.01806891756132245
Q_Learning [200/300]: mean_loss=0.012512924615293741
Q_Learning [201/300]: mean_loss=0.02365601761266589
Q_Learning [202/300]: mean_loss=0.025735216215252876
Q_Learning [203/300]: mean_loss=0.04877089988440275
Q_Learning [204/300]: mean_loss=0.050741944927722216
Q_Learning [205/300]: mean_loss=0.017095260205678642
Q_Learning [206/300]: mean_loss=0.009991120547056198
Q_Learning [207/300]: mean_loss=0.021831614430993795
Q_Learning [208/300]: mean_loss=0.02041375101543963
Q_Learning [209/300]: mean_loss=0.007952731451950967
Q_Learning [210/300]: mean_loss=0.005622179945930839
Q_Learning [211/300]: mean_loss=0.013104506768286228
Q_Learning [212/300]: mean_loss=0.012390642194077373
Q_Learning [213/300]: mean_loss=0.01390594441909343
Q_Learning [214/300]: mean_loss=0.004150209133513272
Q_Learning [215/300]: mean_loss=0.011035880190320313
Q_Learning [216/300]: mean_loss=0.012231828062795103
Q_Learning [217/300]: mean_loss=0.017491912352852523
Q_Learning [218/300]: mean_loss=0.021626322995871305
Q_Learning [219/300]: mean_loss=0.010725062573328614
Q_Learning [220/300]: mean_loss=0.0117690289625898
Q_Learning [221/300]: mean_loss=0.07585569936782122
Q_Learning [222/300]: mean_loss=0.015667619765736163
Q_Learning [223/300]: mean_loss=0.013753500999882817
Q_Learning [224/300]: mean_loss=0.011974885826930404
Q_Learning [225/300]: mean_loss=0.006198471877723932
Q_Learning [226/300]: mean_loss=0.004183354438282549
Q_Learning [227/300]: mean_loss=0.02054291986860335
Q_Learning [228/300]: mean_loss=0.01800992025528103
Q_Learning [229/300]: mean_loss=0.017595691024325788
Q_Learning [230/300]: mean_loss=0.00739349948707968
Q_Learning [231/300]: mean_loss=0.011675140238367021
Q_Learning [232/300]: mean_loss=0.016630668425932527
Q_Learning [233/300]: mean_loss=0.013745182077400386
Q_Learning [234/300]: mean_loss=0.012045012088492513
Q_Learning [235/300]: mean_loss=0.00875073007773608
Q_Learning [236/300]: mean_loss=0.016654705395922065
Q_Learning [237/300]: mean_loss=0.0073359140660613775
Q_Learning [238/300]: mean_loss=0.016533123911358416
Q_Learning [239/300]: mean_loss=0.007338158378843218
Q_Learning [240/300]: mean_loss=0.009459972148761153
Q_Learning [241/300]: mean_loss=0.0057578375563025475
Q_Learning [242/300]: mean_loss=0.007156507985200733
Q_Learning [243/300]: mean_loss=0.0035792318521998823
Q_Learning [244/300]: mean_loss=0.007793637167196721
Q_Learning [245/300]: mean_loss=0.008712013601325452
Q_Learning [246/300]: mean_loss=0.0039091034559533
Q_Learning [247/300]: mean_loss=0.016253704321570694
Q_Learning [248/300]: mean_loss=0.06067942641675472
Q_Learning [249/300]: mean_loss=0.14672261476516724
Q_Learning [250/300]: mean_loss=0.01332824770361185
Q_Learning [251/300]: mean_loss=0.013062705053016543
Q_Learning [252/300]: mean_loss=0.0095143539365381
Q_Learning [253/300]: mean_loss=0.008048784511629492
Q_Learning [254/300]: mean_loss=0.016875352943316102
Q_Learning [255/300]: mean_loss=0.014145380118861794
Q_Learning [256/300]: mean_loss=0.0440020551905036
Q_Learning [257/300]: mean_loss=0.056321293115615845
Q_Learning [258/300]: mean_loss=0.03715155087411404
Q_Learning [259/300]: mean_loss=0.013600171369034797
Q_Learning [260/300]: mean_loss=0.011358629912137985
Q_Learning [261/300]: mean_loss=0.026209319476038218
Q_Learning [262/300]: mean_loss=0.014939573244191706
Q_Learning [263/300]: mean_loss=0.01811274152714759
Q_Learning [264/300]: mean_loss=0.006305936025455594
Q_Learning [265/300]: mean_loss=0.025740576209500432
Q_Learning [266/300]: mean_loss=0.024666914250701666
Q_Learning [267/300]: mean_loss=0.0051482730195857584
Q_Learning [268/300]: mean_loss=0.032529287273064256
Q_Learning [269/300]: mean_loss=0.019711276283487678
Q_Learning [270/300]: mean_loss=0.007238264486659318
Q_Learning [271/300]: mean_loss=0.015965054160915315
Q_Learning [272/300]: mean_loss=0.009384207311086357
Q_Learning [273/300]: mean_loss=0.009910333435982466
Q_Learning [274/300]: mean_loss=0.004270660661859438
Q_Learning [275/300]: mean_loss=0.007111100945621729
Q_Learning [276/300]: mean_loss=0.008985476742964238
Q_Learning [277/300]: mean_loss=0.008181318989954889
Q_Learning [278/300]: mean_loss=0.011031130678020418
Q_Learning [279/300]: mean_loss=0.004571710771415383
Q_Learning [280/300]: mean_loss=0.004538419452728704
Q_Learning [281/300]: mean_loss=0.004581298329867423
Q_Learning [282/300]: mean_loss=0.08650213479995728
Q_Learning [283/300]: mean_loss=0.08435715176165104
Q_Learning [284/300]: mean_loss=0.01878714421764016
Q_Learning [285/300]: mean_loss=0.010545978671871126
Q_Learning [286/300]: mean_loss=0.01759606332052499
Q_Learning [287/300]: mean_loss=0.0063519926043227315
Q_Learning [288/300]: mean_loss=0.00841231393860653
Q_Learning [289/300]: mean_loss=0.02015977376140654
Q_Learning [290/300]: mean_loss=0.005521234939806163
Q_Learning [291/300]: mean_loss=0.007296161958947778
Q_Learning [292/300]: mean_loss=0.008966027526184916
Q_Learning [293/300]: mean_loss=0.010871815611608326
Q_Learning [294/300]: mean_loss=0.009587412467226386
Q_Learning [295/300]: mean_loss=0.2930445335805416
Q_Learning [296/300]: mean_loss=0.08084265887737274
Q_Learning [297/300]: mean_loss=0.04798048222437501
Q_Learning [298/300]: mean_loss=0.022914958652108908
Q_Learning [299/300]: mean_loss=0.014398211031220853
Q_Learning [300/300]: mean_loss=0.039922831347212195
Number of Samples after Autoencoder testing: 300
First Spike after testing: [0.49645737 1.0929445 ]
[2, 1, 2, 1, 0, 0, 2, 1, 0, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 1, 1, 2, 0, 0, 2, 2, 2, 1, 1, 0, 2, 1, 1, 2, 1, 0, 2, 2, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 2, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 2, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 2, 1, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 1, 0, 2, 1, 0, 2, 2, 2, 2, 0, 2, 1, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2, 0, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 0, 0, 2, 2, 1, 1, 2, 2, 2, 0, 1, 0, 1, 2, 0, 1, 0, 1, 1, 0, 2, 2, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 1, 2, 2, 2, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 2, 0, 2, 1, 1, 1, 0, 2, 1, 2, 0, 1, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 2, 0, 2, 0, 2, 0, 1]
[0, 1, 0, 2, 0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 3, 2, 3, 1, 0, 3, 1, 2, 3, 0, 2, 2, 3, 3, 3, 3, 1, 1, 2, 3, 1, 3, 0, 0, 2, 3, 0, 0, 3, 2, 3, 2, 3, 0, 1, 0, 2, 2, 2, 2, 2, 3, 1, 3, 0, 3, 2, 4, 3, 3, 2, 1, 0, 3, 0, 3, 1, 1, 3, 2, 2, 3, 0, 0, 2, 0, 3, 1, 4, 3, 3, 2, 2, 0, 4, 4, 3, 0, 1, 0, 0, 1, 3, 4, 4, 4, 3, 3, 0, 2, 0, 2, 0, 3, 3, 4, 4, 3, 3, 3, 4, 3, 3, 1, 3, 1, 0, 3, 3, 1, 4, 3, 0, 2, 0, 4, 0, 4, 3, 4, 2, 1, 4, 4, 3, 1, 4, 1, 4, 4, 4, 1, 4, 2, 1, 0, 3, 3, 4, 4, 5, 2, 0, 4, 4, 0, 1, 3, 2, 4, 3, 1, 4, 2, 2, 3, 0, 0, 2, 4, 4, 2, 3, 3, 1, 1, 2, 2, 0, 3, 4, 4, 2, 1, 2, 1, 2, 3, 3, 3, 4, 3, 4, 1, 4, 4, 4, 4, 4, 2, 3, 3, 3, 4, 2, 3, 4, 3, 3, 1, 1, 2, 2, 2, 3, 4, 3, 3, 3, 3, 3, 3, 1, 1, 2, 3, 0, 4, 0, 4, 2, 4, 2, 3, 0, 1, 4, 3, 6, 6, 3, 4, 0, 3, 3, 1, 4, 7, 8, 4, 3, 4, 0, 4, 0, 1]
Centroids: [[1.0990187, 0.12981074], [-1.0683377, 0.47248456], [0.40152434, 0.7105043]]
Centroids: [[0.6630464, 0.5292469], [-1.277904, 0.7267772], [-0.9364672, 0.24643509], [1.1479872, 0.019821797], [0.2620662, 0.83046323], [-0.10924487, -0.49351934], [1.398659, 1.150149], [-2.2366946, 1.4536998], [1.0377582, -1.1838858]]
Contingency Matrix: 
[[27  0  0 73  2  0  1  0  0]
 [ 0 45 56  0  2  1  1  1  0]
 [42  0  0  2 46  0  0  0  1]]
[[27, 0, 0, 73, 2, 0, 1, 0, 0], [0, 45, 56, 0, 2, 1, 1, 1, 0], [42, 0, 0, 2, 46, 0, 0, 0, 1]]
[[27, 0, 0, 73, 2, 0, 1, 0, 0], [0, 45, 56, 0, 2, 1, 1, 1, 0], [42, 0, 0, 2, 46, 0, 0, 0, 1]]
[0, 1, 2, 3, 4, 5, 6, 7, 8]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 45, 56, -1, 2, 1, 1, 1, 0], [42, 0, 0, -1, 46, 0, 0, 0, 1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1], [42, 0, -1, -1, 46, 0, 0, 0, 1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 3, 1: 2, 2: 4}
New Contingency Matrix: 
[[73  0  2 27  0  0  1  0  0]
 [ 0 56  2  0 45  1  1  1  0]
 [ 2  0 46 42  0  0  0  0  1]]
New Clustered Label Sequence: [3, 2, 4, 0, 1, 5, 6, 7, 8]
Diagonal_Elements: [73, 56, 46], Sum: 175
All_Elements: [73, 0, 2, 27, 0, 0, 1, 0, 0, 0, 56, 2, 0, 45, 1, 1, 1, 0, 2, 0, 46, 42, 0, 0, 0, 0, 1], Sum: 300
Accuracy: 0.5833333333333334
