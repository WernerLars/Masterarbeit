Seed: 4
Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_4_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_4_opt_temp/C_Difficult1_noise010.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_04_23-12_28_27
Normalisation: False
Template Matching: True
Optimising Autoencoder: True
Update Factor: 1
Noisy Batches: False
Noisy Factor: 0.1
Epochs: 8
Batch Size: 1
maximal Spikes for Autoencoder Training : 700
maximal Spikes for Training: 1000
Input Size: 47
Chosen Model: Convolutional Autoencoder
ConvolutionalAutoencoder(
  (encoder): Sequential(
    (0): Conv1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Conv1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=37, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): ConvTranspose1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=12, out_features=47, bias=True)
  )
)
MSELoss()
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0
)
---Q Learning Parameters---
Normalisation: False
Punishment Coefficient: 0.5
Alpha: 0.8
Epsilon: 0.01
Gamma: 0.97
Initial Episode Number: 0
Episode Number Coefficient: 1.4
Number of Random Features: 20
Planning Number: 20
Max Random Features: 60
New Episode Number: 72
New Episode Number: 143
New Episode Number: 215
New Episode Number: 286
New Episode Number: 358
New Episode Number: 429
New Episode Number: 500
New Episode Number: 572
New Episode Number: 643
New Episode Number: 715
New Episode Number: 786
New Episode Number: 858
New Episode Number: 929
New Episode Number: 1000
New Episode Number: 1072
               0      1     2     3      4   ...     11    12    13    14    15
new_cluster -7.48 -10.12 -8.82 -7.66 -11.78  ...  -9.42 -6.75 -7.20 -9.36 -8.33
c1          -7.50 -10.04 -9.10 -7.30 -11.60  ...  -9.59 -6.65 -6.97 -9.06 -7.76
c2          -7.51  -9.86 -9.06 -6.99 -11.57  ...  -9.73 -6.79 -7.15 -8.75 -7.76
c3          -7.47 -10.09 -9.30 -7.43 -11.53  ...  -9.79 -6.89 -7.07 -8.85 -7.98
c4          -7.54  -9.36 -9.03 -7.10 -11.04  ...  -9.31 -6.98 -7.03 -9.18 -7.72
c5          -7.40  -9.93 -8.58 -7.27 -11.23  ...  -9.71 -6.78 -7.09 -8.85 -8.27
c6          -7.18 -10.17 -8.90 -7.22 -11.54  ...  -9.21 -6.48 -7.04 -8.82 -8.96
c7          -7.30  -9.58 -8.94 -7.22 -11.03  ...  -9.90 -6.41 -7.29 -8.80 -8.28
c8          -7.55 -10.28 -8.88 -7.47 -11.64  ... -10.34 -6.90 -7.17 -9.13 -7.76
c9          -6.87  -9.24 -8.99 -7.10 -11.26  ...  -9.92 -6.88 -7.27 -8.91 -7.66
c10         -7.52 -10.42 -8.77 -7.31 -11.10  ...  -9.68 -6.90 -7.17 -9.17 -8.07
c11         -7.52 -10.38 -9.04 -7.11 -12.25  ...  -9.55 -6.88 -7.28 -9.18 -7.71
c12         -7.39 -10.19 -9.19 -7.19 -10.96  ...  -9.49 -6.91 -7.24 -9.00 -7.91
c13         -7.38 -10.06 -9.20 -7.20 -11.44  ...  -9.29 -6.64 -7.17 -9.26  0.00
c14         -7.23 -10.58 -9.36 -6.87 -11.46  ...  -9.68 -6.46 -7.11 -9.16 -8.14
c15         -7.48  -9.93 -9.45 -7.34 -11.99  ...  -9.92 -6.83 -7.15 -8.97 -8.34

[16 rows x 16 columns]
\begin{tabular}{lrrrrrrrrrrrrrrrr}
\toprule
{} &    0  &     1  &    2  &    3  &     4  &    5  &     6  &    7  &     8  &     9  &     10 &     11 &    12 &    13 &    14 &    15 \\
\midrule
new\_cluster & -7.48 & -10.12 & -8.82 & -7.66 & -11.78 & -7.58 & -22.17 & -7.38 &  -9.90 & -15.40 & -27.40 &  -9.42 & -6.75 & -7.20 & -9.36 & -8.33 \\
c1          & -7.50 & -10.04 & -9.10 & -7.30 & -11.60 & -7.98 & -22.25 & -7.48 &  -9.91 & -16.15 & -28.69 &  -9.59 & -6.65 & -6.97 & -9.06 & -7.76 \\
c2          & -7.51 &  -9.86 & -9.06 & -6.99 & -11.57 & -7.57 & -22.23 & -7.37 &  -9.69 & -15.72 & -25.79 &  -9.73 & -6.79 & -7.15 & -8.75 & -7.76 \\
c3          & -7.47 & -10.09 & -9.30 & -7.43 & -11.53 & -7.41 & -22.21 & -7.62 &  -9.90 & -15.92 & -28.29 &  -9.79 & -6.89 & -7.07 & -8.85 & -7.98 \\
c4          & -7.54 &  -9.36 & -9.03 & -7.10 & -11.04 & -7.35 & -22.02 & -7.23 &  -9.87 & -15.55 & -27.74 &  -9.31 & -6.98 & -7.03 & -9.18 & -7.72 \\
c5          & -7.40 &  -9.93 & -8.58 & -7.27 & -11.23 & -7.81 & -22.25 & -7.27 &  -9.88 & -14.87 & -28.58 &  -9.71 & -6.78 & -7.09 & -8.85 & -8.27 \\
c6          & -7.18 & -10.17 & -8.90 & -7.22 & -11.54 & -7.92 & -22.02 & -7.43 &  -9.72 & -15.91 & -29.02 &  -9.21 & -6.48 & -7.04 & -8.82 & -8.96 \\
c7          & -7.30 &  -9.58 & -8.94 & -7.22 & -11.03 & -7.84 & -22.00 & -7.79 &  -9.94 & -16.33 & -28.53 &  -9.90 & -6.41 & -7.29 & -8.80 & -8.28 \\
c8          & -7.55 & -10.28 & -8.88 & -7.47 & -11.64 & -7.66 & -22.24 & -7.48 &  -9.88 & -16.12 & -27.41 & -10.34 & -6.90 & -7.17 & -9.13 & -7.76 \\
c9          & -6.87 &  -9.24 & -8.99 & -7.10 & -11.26 & -7.59 & -22.21 & -7.48 & -10.05 & -15.87 & -26.90 &  -9.92 & -6.88 & -7.27 & -8.91 & -7.66 \\
c10         & -7.52 & -10.42 & -8.77 & -7.31 & -11.10 & -7.16 & -22.11 & -7.47 &  -9.76 & -16.47 & -27.92 &  -9.68 & -6.90 & -7.17 & -9.17 & -8.07 \\
c11         & -7.52 & -10.38 & -9.04 & -7.11 & -12.25 & -7.49 & -22.04 & -7.62 & -10.10 & -15.75 & -27.44 &  -9.55 & -6.88 & -7.28 & -9.18 & -7.71 \\
c12         & -7.39 & -10.19 & -9.19 & -7.19 & -10.96 & -7.80 & -22.24 & -7.27 & -10.00 & -16.27 & -27.17 &  -9.49 & -6.91 & -7.24 & -9.00 & -7.91 \\
c13         & -7.38 & -10.06 & -9.20 & -7.20 & -11.44 & -7.51 & -22.25 & -7.53 &  -9.89 & -16.37 & -27.65 &  -9.29 & -6.64 & -7.17 & -9.26 &  0.00 \\
c14         & -7.23 & -10.58 & -9.36 & -6.87 & -11.46 & -7.77 & -22.23 & -7.24 &  -9.86 & -16.18 & -27.14 &  -9.68 & -6.46 & -7.11 & -9.16 & -8.14 \\
c15         & -7.48 &  -9.93 & -9.45 & -7.34 & -11.99 & -7.97 & -22.24 & -7.34 &  -9.46 & -16.75 & -29.09 &  -9.92 & -6.83 & -7.15 & -8.97 & -8.34 \\
\bottomrule
\end{tabular}

                              0            1   ...            14            15
new_cluster  [-1.0, new_cluster]  [-3.98, c1]  ...  [-3.17, c14]  [-1.75, c15]
c1           [-1.0, new_cluster]  [-3.74, c1]  ...  [-2.83, c14]  [-1.34, c15]
c2           [-1.0, new_cluster]  [-3.47, c1]  ...  [-2.48, c14]  [-1.34, c15]
c3           [-1.0, new_cluster]  [-3.79, c1]  ...   [-2.8, c14]  [-1.42, c15]
c4           [-1.0, new_cluster]  [-3.26, c1]  ...  [-2.92, c14]   [-1.3, c15]
c5           [-1.0, new_cluster]  [-3.82, c1]  ...  [-2.62, c14]  [-1.68, c15]
c6           [-1.0, new_cluster]  [-3.86, c1]  ...  [-2.56, c14]  [-2.38, c15]
c7           [-1.0, new_cluster]  [-3.49, c1]  ...  [-2.54, c14]  [-1.68, c15]
c8           [-1.0, new_cluster]  [-3.86, c1]  ...  [-2.86, c14]  [-1.36, c15]
c9           [-1.0, new_cluster]  [-3.14, c1]  ...  [-2.64, c14]  [-1.25, c15]
c10          [-1.0, new_cluster]  [-4.03, c1]  ...  [-2.91, c14]  [-1.53, c15]
c11          [-1.0, new_cluster]  [-4.09, c1]  ...  [-2.92, c14]  [-1.12, c15]
c12          [-1.0, new_cluster]  [-3.77, c1]  ...  [-2.73, c14]  [-1.49, c15]
c13          [-1.0, new_cluster]  [-3.92, c1]  ...  [-2.99, c14]         [0, ]
c14          [-1.0, new_cluster]  [-4.26, c1]  ...   [-2.9, c14]  [-1.58, c15]
c15          [-1.0, new_cluster]  [-3.56, c1]  ...  [-2.71, c14]  [-1.77, c15]

[16 rows x 16 columns]
\begin{tabular}{lllllllllllllllll}
\toprule
{} &                   0  &           1  &           2  &           3  &           4  &           5  &            6  &           7  &           8  &            9  &             10 &            11 &            12 &            13 &            14 &            15 \\
\midrule
new\_cluster &  [-1.0, new\_cluster] &  [-3.98, c1] &  [-2.52, c2] &  [-1.13, c3] &  [-5.08, c4] &  [-1.42, c5] &  [-15.97, c6] &  [-1.16, c7] &  [-3.41, c8] &   [-8.98, c9] &  [-20.96, c10] &  [-2.98, c11] &  [-0.16, c12] &   [-7.2, c13] &  [-3.17, c14] &  [-1.75, c15] \\
c1          &  [-1.0, new\_cluster] &  [-3.74, c1] &  [-2.79, c2] &  [-0.81, c3] &  [-4.83, c4] &  [-1.45, c5] &  [-15.97, c6] &  [-1.22, c7] &  [-3.43, c8] &    [-9.6, c9] &  [-22.24, c10] &  [-3.17, c11] &  [-0.11, c12] &  [-6.97, c13] &  [-2.83, c14] &  [-1.34, c15] \\
c2          &  [-1.0, new\_cluster] &  [-3.47, c1] &  [-2.79, c2] &  [-0.84, c3] &  [-5.17, c4] &  [-1.24, c5] &  [-15.97, c6] &  [-1.15, c7] &   [-3.2, c8] &   [-9.36, c9] &   [-19.4, c10] &   [-3.3, c11] &  [-0.16, c12] &  [-7.15, c13] &  [-2.48, c14] &  [-1.34, c15] \\
c3          &  [-1.0, new\_cluster] &  [-3.79, c1] &  [-2.78, c2] &  [-1.06, c3] &  [-5.11, c4] &  [-1.37, c5] &  [-15.97, c6] &   [-1.4, c7] &  [-3.42, c8] &   [-9.53, c9] &   [-21.6, c10] &  [-3.37, c11] &  [-0.22, c12] &  [-7.07, c13] &   [-2.8, c14] &  [-1.42, c15] \\
c4          &  [-1.0, new\_cluster] &  [-3.26, c1] &  [-2.73, c2] &  [-0.95, c3] &  [-4.34, c4] &  [-1.21, c5] &  [-15.97, c6] &  [-1.01, c7] &  [-3.39, c8] &   [-9.16, c9] &  [-21.07, c10] &  [-2.87, c11] &  [-0.39, c12] &  [-7.03, c13] &  [-2.92, c14] &   [-1.3, c15] \\
c5          &  [-1.0, new\_cluster] &  [-3.82, c1] &  [-2.46, c2] &  [-0.78, c3] &  [-4.82, c4] &  [-1.48, c5] &  [-15.97, c6] &  [-1.05, c7] &   [-3.4, c8] &   [-8.63, c9] &  [-22.13, c10] &  [-3.28, c11] &  [-0.09, c12] &  [-7.09, c13] &  [-2.62, c14] &  [-1.68, c15] \\
c6          &  [-1.0, new\_cluster] &  [-3.86, c1] &  [-2.38, c2] &  [-0.84, c3] &  [-5.13, c4] &  [-1.49, c5] &  [-15.97, c6] &  [-1.21, c7] &  [-3.07, c8] &   [-9.52, c9] &  [-22.57, c10] &  [-2.84, c11] &  [-0.08, c12] &  [-7.04, c13] &  [-2.56, c14] &  [-2.38, c15] \\
c7          &  [-1.0, new\_cluster] &  [-3.49, c1] &  [-2.78, c2] &  [-0.69, c3] &  [-4.58, c4] &  [-1.41, c5] &  [-15.97, c6] &  [-1.39, c7] &  [-3.45, c8] &   [-9.71, c9] &  [-22.24, c10] &  [-3.58, c11] &  [-0.25, c12] &  [-7.29, c13] &  [-2.54, c14] &  [-1.68, c15] \\
c8          &  [-1.0, new\_cluster] &  [-3.86, c1] &  [-2.56, c2] &   [-0.9, c3] &  [-4.94, c4] &  [-1.31, c5] &  [-15.97, c6] &  [-1.26, c7] &   [-3.4, c8] &   [-9.88, c9] &  [-20.74, c10] &  [-3.76, c11] &  [-0.26, c12] &  [-7.17, c13] &  [-2.86, c14] &  [-1.36, c15] \\
c9          &  [-1.0, new\_cluster] &  [-3.14, c1] &  [-2.75, c2] &  [-0.94, c3] &  [-4.51, c4] &  [-1.16, c5] &  [-15.97, c6] &  [-1.26, c7] &  [-3.56, c8] &   [-9.51, c9] &  [-20.76, c10] &  [-3.49, c11] &  [-0.19, c12] &  [-7.27, c13] &  [-2.64, c14] &  [-1.25, c15] \\
c10         &  [-1.0, new\_cluster] &  [-4.03, c1] &  [-2.47, c2] &  [-0.82, c3] &  [-4.67, c4] &  [-1.19, c5] &  [-15.97, c6] &  [-1.25, c7] &  [-3.29, c8] &  [-10.04, c9] &  [-21.28, c10] &  [-3.31, c11] &  [-0.25, c12] &  [-7.17, c13] &  [-2.91, c14] &  [-1.53, c15] \\
c11         &  [-1.0, new\_cluster] &  [-4.09, c1] &  [-2.77, c2] &  [-0.87, c3] &  [-5.54, c4] &  [-1.43, c5] &  [-15.97, c6] &   [-1.4, c7] &  [-3.45, c8] &    [-9.2, c9] &  [-21.28, c10] &  [-3.12, c11] &  [-0.19, c12] &  [-7.28, c13] &  [-2.92, c14] &  [-1.12, c15] \\
c12         &  [-1.0, new\_cluster] &  [-3.77, c1] &  [-2.88, c2] &  [-1.01, c3] &  [-4.53, c4] &  [-1.28, c5] &  [-15.97, c6] &  [-1.05, c7] &  [-3.54, c8] &   [-9.88, c9] &  [-20.53, c10] &  [-3.16, c11] &  [-0.21, c12] &  [-7.24, c13] &  [-2.73, c14] &  [-1.49, c15] \\
c13         &  [-1.0, new\_cluster] &  [-3.92, c1] &  [-2.68, c2] &  [-0.82, c3] &  [-4.68, c4] &  [-1.46, c5] &  [-15.97, c6] &  [-1.28, c7] &  [-3.41, c8] &   [-9.79, c9] &  [-21.41, c10] &  [-2.92, c11] &  [-0.17, c12] &  [-7.17, c13] &  [-2.99, c14] &         [0, ] \\
c14         &  [-1.0, new\_cluster] &  [-4.26, c1] &  [-3.07, c2] &  [-0.65, c3] &  [-4.94, c4] &  [-1.41, c5] &  [-15.97, c6] &  [-1.02, c7] &  [-3.38, c8] &   [-9.76, c9] &  [-20.85, c10] &  [-3.24, c11] &  [-0.17, c12] &  [-7.11, c13] &   [-2.9, c14] &  [-1.58, c15] \\
c15         &  [-1.0, new\_cluster] &  [-3.56, c1] &  [-2.95, c2] &  [-0.78, c3] &  [-5.28, c4] &  [-1.45, c5] &  [-15.97, c6] &  [-1.12, c7] &  [-2.98, c8] &  [-10.33, c9] &  [-22.47, c10] &  [-3.49, c11] &  [-0.14, c12] &  [-7.15, c13] &  [-2.71, c14] &  [-1.77, c15] \\
\bottomrule
\end{tabular}

