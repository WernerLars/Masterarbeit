Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_8_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_8_opt_temp/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_05_04-13_18_26
Punishment_Coefficient: 1.0
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001AFBE0371D0>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.24413112737238407
Online_Training [2/700]: mean_loss=0.2772955894470215
Online_Training [3/700]: mean_loss=0.22114034928381443
Online_Training [4/700]: mean_loss=0.10577248875051737
Online_Training [5/700]: mean_loss=0.2827841006219387
Online_Training [6/700]: mean_loss=0.13258128054440022
Online_Training [7/700]: mean_loss=0.13703787699341774
Online_Training [8/700]: mean_loss=0.0884051276370883
Online_Training [9/700]: mean_loss=0.23298868536949158
Online_Training [10/700]: mean_loss=0.153999799862504
Online_Training [11/700]: mean_loss=0.12026408035308123
Online_Training [12/700]: mean_loss=0.07977339439094067
Online_Training [13/700]: mean_loss=0.11566466186195612
Online_Training [14/700]: mean_loss=0.10214656218886375
Online_Training [15/700]: mean_loss=0.1054230323061347
Online_Training [16/700]: mean_loss=0.12235996127128601
Online_Training [17/700]: mean_loss=0.16496446542441845
Online_Training [18/700]: mean_loss=0.12254256755113602
Online_Training [19/700]: mean_loss=0.046046263072639704
Online_Training [20/700]: mean_loss=0.13514318130910397
Online_Training [21/700]: mean_loss=0.14011738449335098
Online_Training [22/700]: mean_loss=0.04548654844984412
Online_Training [23/700]: mean_loss=0.02449247078038752
Online_Training [24/700]: mean_loss=0.06332899676635861
Online_Training [25/700]: mean_loss=0.04545756662264466
Online_Training [26/700]: mean_loss=0.05515293497592211
Online_Training [27/700]: mean_loss=0.06731242360547185
Online_Training [28/700]: mean_loss=0.03435796522535384
Online_Training [29/700]: mean_loss=0.04128111666068435
Online_Training [30/700]: mean_loss=0.028687735786661506
Online_Training [31/700]: mean_loss=0.030867326771840453
Online_Training [32/700]: mean_loss=0.050702751614153385
Online_Training [33/700]: mean_loss=0.021834010258316994
Online_Training [34/700]: mean_loss=0.12269900739192963
Online_Training [35/700]: mean_loss=0.053182941395789385
Online_Training [36/700]: mean_loss=0.069038275629282
Online_Training [37/700]: mean_loss=0.05736395390704274
Online_Training [38/700]: mean_loss=0.03810146078467369
Online_Training [39/700]: mean_loss=0.061791830230504274
Online_Training [40/700]: mean_loss=0.034327647648751736
Online_Training [41/700]: mean_loss=0.02319260872900486
Online_Training [42/700]: mean_loss=0.04788239020854235
Online_Training [43/700]: mean_loss=0.055844270158559084
Online_Training [44/700]: mean_loss=0.06600149627774954
Online_Training [45/700]: mean_loss=0.04915142245590687
Online_Training [46/700]: mean_loss=0.03619031747803092
Online_Training [47/700]: mean_loss=0.036076946184039116
Online_Training [48/700]: mean_loss=0.06966482289135456
Online_Training [49/700]: mean_loss=0.022961061215028167
Online_Training [50/700]: mean_loss=0.03107618633657694
Online_Training [51/700]: mean_loss=0.020941775292158127
Online_Training [52/700]: mean_loss=0.05401980550959706
Online_Training [53/700]: mean_loss=0.021498048678040504
Online_Training [54/700]: mean_loss=0.04740456026047468
Online_Training [55/700]: mean_loss=0.018063719384372234
Online_Training [56/700]: mean_loss=0.03770320490002632
Online_Training [57/700]: mean_loss=0.06915901089087129
Online_Training [58/700]: mean_loss=0.1233651414513588
Online_Training [59/700]: mean_loss=0.0672997091896832
Online_Training [60/700]: mean_loss=0.03712531900964677
Online_Training [61/700]: mean_loss=0.0400057821534574
Online_Training [62/700]: mean_loss=0.0779455117881298
Online_Training [63/700]: mean_loss=0.05053732916712761
Online_Training [64/700]: mean_loss=0.004917771671898663
Online_Training [65/700]: mean_loss=0.05357790598645806
Online_Training [66/700]: mean_loss=0.043100371956825256
Online_Training [67/700]: mean_loss=0.06496301665902138
Online_Training [68/700]: mean_loss=0.017891935887746513
Online_Training [69/700]: mean_loss=0.03827215591445565
Online_Training [70/700]: mean_loss=0.033448874950408936
Online_Training [71/700]: mean_loss=0.07485144026577473
Online_Training [72/700]: mean_loss=0.07492300495505333
Online_Training [73/700]: mean_loss=0.03547738562338054
Online_Training [74/700]: mean_loss=0.03290445962920785
Online_Training [75/700]: mean_loss=0.03138701943680644
Online_Training [76/700]: mean_loss=0.02231965330429375
Online_Training [77/700]: mean_loss=0.04817508114501834
Online_Training [78/700]: mean_loss=0.01727866579312831
Online_Training [79/700]: mean_loss=0.04694038117304444
Online_Training [80/700]: mean_loss=0.026265019085258245
Online_Training [81/700]: mean_loss=0.019588773604482412
Online_Training [82/700]: mean_loss=0.022564272163435817
Online_Training [83/700]: mean_loss=0.031848506070673466
Online_Training [84/700]: mean_loss=0.024607961997389793
Online_Training [85/700]: mean_loss=0.022842629812657833
Online_Training [86/700]: mean_loss=0.038854387588799
Online_Training [87/700]: mean_loss=0.010829139151610434
Online_Training [88/700]: mean_loss=0.022555639035999775
Online_Training [89/700]: mean_loss=0.03949208720587194
Online_Training [90/700]: mean_loss=0.023035782389342785
Online_Training [91/700]: mean_loss=0.022637537214905024
Online_Training [92/700]: mean_loss=0.023362636100500822
Online_Training [93/700]: mean_loss=0.02239035931415856
Online_Training [94/700]: mean_loss=0.029910711105912924
Online_Training [95/700]: mean_loss=0.02356560924090445
Online_Training [96/700]: mean_loss=0.02316677407361567
Online_Training [97/700]: mean_loss=0.02665039640851319
Online_Training [98/700]: mean_loss=0.03454118291847408
Online_Training [99/700]: mean_loss=0.024181468412280083
Online_Training [100/700]: mean_loss=0.05194626888260245
Online_Training [101/700]: mean_loss=0.020815833238884807
Online_Training [102/700]: mean_loss=0.0462511507794261
Online_Training [103/700]: mean_loss=0.028078692965209484
Online_Training [104/700]: mean_loss=0.03168414207175374
Online_Training [105/700]: mean_loss=0.02005027956329286
Online_Training [106/700]: mean_loss=0.008068739669397473
Online_Training [107/700]: mean_loss=0.014463129802607
Online_Training [108/700]: mean_loss=0.01504128985106945
Online_Training [109/700]: mean_loss=0.020835581002756953
Online_Training [110/700]: mean_loss=0.03150923550128937
Online_Training [111/700]: mean_loss=0.018849006737582386
Online_Training [112/700]: mean_loss=0.06856228271499276
Online_Training [113/700]: mean_loss=0.024361508199945092
Online_Training [114/700]: mean_loss=0.03063217573799193
Online_Training [115/700]: mean_loss=0.04993663728237152
Online_Training [116/700]: mean_loss=0.02123050345107913
Online_Training [117/700]: mean_loss=0.05467019323259592
Online_Training [118/700]: mean_loss=0.01950738742016256
Online_Training [119/700]: mean_loss=0.12083378713577986
Online_Training [120/700]: mean_loss=0.05225085001438856
Online_Training [121/700]: mean_loss=0.05399464350193739
Online_Training [122/700]: mean_loss=0.03599739307537675
Online_Training [123/700]: mean_loss=0.02757772197946906
Online_Training [124/700]: mean_loss=0.01695375971030444
Online_Training [125/700]: mean_loss=0.09937726706266403
Online_Training [126/700]: mean_loss=0.06893690768629313
Online_Training [127/700]: mean_loss=0.04249994270503521
Online_Training [128/700]: mean_loss=0.026583224069327116
Online_Training [129/700]: mean_loss=0.013337463140487671
Online_Training [130/700]: mean_loss=0.021557397907599807
Online_Training [131/700]: mean_loss=0.01761086843907833
Online_Training [132/700]: mean_loss=0.017471206607297063
Online_Training [133/700]: mean_loss=0.02498633787035942
Online_Training [134/700]: mean_loss=0.007527195673901588
Online_Training [135/700]: mean_loss=0.1170857585966587
Online_Training [136/700]: mean_loss=0.022647934267297387
Online_Training [137/700]: mean_loss=0.01776587450876832
Online_Training [138/700]: mean_loss=0.01196706434711814
Online_Training [139/700]: mean_loss=0.019453872926533222
Online_Training [140/700]: mean_loss=0.020612101070582867
Online_Training [141/700]: mean_loss=0.04699762584641576
Online_Training [142/700]: mean_loss=0.01525599998421967
Online_Training [143/700]: mean_loss=0.019988938234746456
Online_Training [144/700]: mean_loss=0.006707577500492334
Online_Training [145/700]: mean_loss=0.028444084338843822
Online_Training [146/700]: mean_loss=0.01986353797838092
Online_Training [147/700]: mean_loss=0.016061117639765143
Online_Training [148/700]: mean_loss=0.027731422567740083
Online_Training [149/700]: mean_loss=0.039271782618016005
Online_Training [150/700]: mean_loss=0.09938539005815983
Online_Training [151/700]: mean_loss=0.020335801411420107
Online_Training [152/700]: mean_loss=0.016919379588216543
Online_Training [153/700]: mean_loss=0.035778466844931245
Online_Training [154/700]: mean_loss=0.02302233106456697
Online_Training [155/700]: mean_loss=0.01044745510444045
Online_Training [156/700]: mean_loss=0.022263640072196722
Online_Training [157/700]: mean_loss=0.15400883927941322
Online_Training [158/700]: mean_loss=0.004843952367082238
Online_Training [159/700]: mean_loss=0.023637083126232028
Online_Training [160/700]: mean_loss=0.02909296378493309
Online_Training [161/700]: mean_loss=0.0372887016274035
Online_Training [162/700]: mean_loss=0.01629278901964426
Online_Training [163/700]: mean_loss=0.06183765269815922
Online_Training [164/700]: mean_loss=0.017456025583669543
Online_Training [165/700]: mean_loss=0.009880183264613152
Online_Training [166/700]: mean_loss=0.018142722081393003
Online_Training [167/700]: mean_loss=0.027591202640905976
Online_Training [168/700]: mean_loss=0.028365794103592634
Online_Training [169/700]: mean_loss=0.05074443528428674
Online_Training [170/700]: mean_loss=0.1680087111890316
Online_Training [171/700]: mean_loss=0.021602501859888434
Online_Training [172/700]: mean_loss=0.018722006119787693
Online_Training [173/700]: mean_loss=0.03153745480813086
Online_Training [174/700]: mean_loss=0.015780059271492064
Online_Training [175/700]: mean_loss=0.010609596036374569
Online_Training [176/700]: mean_loss=0.007506680442020297
Online_Training [177/700]: mean_loss=0.024637257447466254
Online_Training [178/700]: mean_loss=0.03238619910553098
Online_Training [179/700]: mean_loss=0.02642656397074461
Online_Training [180/700]: mean_loss=0.01309081760700792
Online_Training [181/700]: mean_loss=0.01195523061323911
Online_Training [182/700]: mean_loss=0.03569153742864728
Online_Training [183/700]: mean_loss=0.013405211386270821
Online_Training [184/700]: mean_loss=0.00548345351126045
Online_Training [185/700]: mean_loss=0.04370070481672883
Online_Training [186/700]: mean_loss=0.03912041080184281
Online_Training [187/700]: mean_loss=0.021038147620856762
Online_Training [188/700]: mean_loss=0.02088300627656281
Online_Training [189/700]: mean_loss=0.0548688224516809
Online_Training [190/700]: mean_loss=0.015121633769012988
Online_Training [191/700]: mean_loss=0.12729591317474842
Online_Training [192/700]: mean_loss=0.029495877912268043
Online_Training [193/700]: mean_loss=0.01792672835290432
Online_Training [194/700]: mean_loss=0.005830590729601681
Online_Training [195/700]: mean_loss=0.02977540949359536
Online_Training [196/700]: mean_loss=0.01702875818591565
Online_Training [197/700]: mean_loss=0.022509743459522724
Online_Training [198/700]: mean_loss=0.022556551732122898
Online_Training [199/700]: mean_loss=0.0949925035238266
Online_Training [200/700]: mean_loss=0.024814492790028453
Online_Training [201/700]: mean_loss=0.023475305642932653
Online_Training [202/700]: mean_loss=0.009910874185152352
Online_Training [203/700]: mean_loss=0.013335764640942216
Online_Training [204/700]: mean_loss=0.012428867281414568
Online_Training [205/700]: mean_loss=0.0620799227617681
Online_Training [206/700]: mean_loss=0.006909376359544694
Online_Training [207/700]: mean_loss=0.05153112579137087
Online_Training [208/700]: mean_loss=0.034207784570753574
Online_Training [209/700]: mean_loss=0.052961861714720726
Online_Training [210/700]: mean_loss=0.03628103993833065
Online_Training [211/700]: mean_loss=0.012267879443243146
Online_Training [212/700]: mean_loss=0.09224327094852924
Online_Training [213/700]: mean_loss=0.039079359732568264
Online_Training [214/700]: mean_loss=0.010468614054843783
Online_Training [215/700]: mean_loss=0.03285656915977597
Online_Training [216/700]: mean_loss=0.03635612782090902
Online_Training [217/700]: mean_loss=0.012030990328639746
Online_Training [218/700]: mean_loss=0.006853782921098173
Online_Training [219/700]: mean_loss=0.06109960051253438
Online_Training [220/700]: mean_loss=0.013816709397360682
Online_Training [221/700]: mean_loss=0.0332294306717813
Online_Training [222/700]: mean_loss=0.009656833834014833
Online_Training [223/700]: mean_loss=0.028503997018560767
Online_Training [224/700]: mean_loss=0.008860578411258757
Online_Training [225/700]: mean_loss=0.030758809531107545
Online_Training [226/700]: mean_loss=0.030604574596509337
Online_Training [227/700]: mean_loss=0.018489315640181303
Online_Training [228/700]: mean_loss=0.02271493594162166
Online_Training [229/700]: mean_loss=0.03341347980313003
Online_Training [230/700]: mean_loss=0.01914155064150691
Online_Training [231/700]: mean_loss=0.01950505143031478
Online_Training [232/700]: mean_loss=0.021225603763014078
Online_Training [233/700]: mean_loss=0.012424019514583051
Online_Training [234/700]: mean_loss=0.028351969085633755
Online_Training [235/700]: mean_loss=0.11430756747722626
Online_Training [236/700]: mean_loss=0.061055609956383705
Online_Training [237/700]: mean_loss=0.027116654440760612
Online_Training [238/700]: mean_loss=0.1072841165587306
Online_Training [239/700]: mean_loss=0.05602098582312465
Online_Training [240/700]: mean_loss=0.040058541810140014
Online_Training [241/700]: mean_loss=0.04397848108783364
Online_Training [242/700]: mean_loss=0.026945512043312192
Online_Training [243/700]: mean_loss=0.03784323390573263
Online_Training [244/700]: mean_loss=0.014504773076623678
Online_Training [245/700]: mean_loss=0.026794651290401816
Online_Training [246/700]: mean_loss=0.015153854852542281
Online_Training [247/700]: mean_loss=0.011060243472456932
Online_Training [248/700]: mean_loss=0.07900145836174488
Online_Training [249/700]: mean_loss=0.018368500284850597
Online_Training [250/700]: mean_loss=0.015289728762581944
Online_Training [251/700]: mean_loss=0.012792078196071088
Online_Training [252/700]: mean_loss=0.021584663772955537
Online_Training [253/700]: mean_loss=0.01773107796907425
Online_Training [254/700]: mean_loss=0.017037650453858078
Online_Training [255/700]: mean_loss=0.029098600149154663
Online_Training [256/700]: mean_loss=0.016710223746486008
Online_Training [257/700]: mean_loss=0.013169298646971583
Online_Training [258/700]: mean_loss=0.021540775196626782
Online_Training [259/700]: mean_loss=0.010665765614248812
Online_Training [260/700]: mean_loss=0.0078058065846562386
Online_Training [261/700]: mean_loss=0.023127907421439886
Online_Training [262/700]: mean_loss=0.026390123181045055
Online_Training [263/700]: mean_loss=0.010501295211724937
Online_Training [264/700]: mean_loss=0.01922184438444674
Online_Training [265/700]: mean_loss=0.013634879840537906
Online_Training [266/700]: mean_loss=0.01039847545325756
Online_Training [267/700]: mean_loss=0.018652942962944508
Online_Training [268/700]: mean_loss=0.0063399175414815545
Online_Training [269/700]: mean_loss=0.014771913643926382
Online_Training [270/700]: mean_loss=0.01361364359036088
Online_Training [271/700]: mean_loss=0.02300719218328595
Online_Training [272/700]: mean_loss=0.009096637484617531
Online_Training [273/700]: mean_loss=0.010928795556537807
Online_Training [274/700]: mean_loss=0.008559343463275582
Online_Training [275/700]: mean_loss=0.014768633875064552
Online_Training [276/700]: mean_loss=0.01176802208647132
Online_Training [277/700]: mean_loss=0.018015850335359573
Online_Training [278/700]: mean_loss=0.021858637453988194
Online_Training [279/700]: mean_loss=0.013682135730050504
Online_Training [280/700]: mean_loss=0.019462780095636845
Online_Training [281/700]: mean_loss=0.021344889188185334
Online_Training [282/700]: mean_loss=0.030666680075228214
Online_Training [283/700]: mean_loss=0.019578656647354364
Online_Training [284/700]: mean_loss=0.009016110503580421
Online_Training [285/700]: mean_loss=0.016164098517037928
Online_Training [286/700]: mean_loss=0.019905894761905074
Online_Training [287/700]: mean_loss=0.01683874847367406
Online_Training [288/700]: mean_loss=0.015223742579109967
Online_Training [289/700]: mean_loss=0.04260517377406359
Online_Training [290/700]: mean_loss=0.0065239896648563445
Online_Training [291/700]: mean_loss=0.011063111713156104
Online_Training [292/700]: mean_loss=0.007373624364845455
Online_Training [293/700]: mean_loss=0.010007708915509284
Online_Training [294/700]: mean_loss=0.012591567356139421
Online_Training [295/700]: mean_loss=0.03365642437711358
Online_Training [296/700]: mean_loss=0.033108466072008014
Online_Training [297/700]: mean_loss=0.019202591152861714
Online_Training [298/700]: mean_loss=0.009935463895089924
Online_Training [299/700]: mean_loss=0.012632588972337544
Online_Training [300/700]: mean_loss=0.04430959094315767
Online_Training [301/700]: mean_loss=0.011637176270596683
Online_Training [302/700]: mean_loss=0.01333470270037651
Online_Training [303/700]: mean_loss=0.021987709449604154
Online_Training [304/700]: mean_loss=0.010266973404213786
Online_Training [305/700]: mean_loss=0.055907406844198704
Online_Training [306/700]: mean_loss=0.06287117581814528
Online_Training [307/700]: mean_loss=0.07245235703885555
Online_Training [308/700]: mean_loss=0.021475013811141253
Online_Training [309/700]: mean_loss=0.009324421407654881
Online_Training [310/700]: mean_loss=0.006368860485963523
Online_Training [311/700]: mean_loss=0.013881628401577473
Online_Training [312/700]: mean_loss=0.05020194314420223
Online_Training [313/700]: mean_loss=0.01448600401636213
Online_Training [314/700]: mean_loss=0.013874960015527904
Online_Training [315/700]: mean_loss=0.009871389367617667
Online_Training [316/700]: mean_loss=0.015966743347235024
Online_Training [317/700]: mean_loss=0.008059311483521014
Online_Training [318/700]: mean_loss=0.02428176114335656
Online_Training [319/700]: mean_loss=0.020240090088918805
Online_Training [320/700]: mean_loss=0.009712278086226434
Online_Training [321/700]: mean_loss=0.022670825943350792
Online_Training [322/700]: mean_loss=0.03327367780730128
Online_Training [323/700]: mean_loss=0.020408579846844077
Online_Training [324/700]: mean_loss=0.026871216483414173
Online_Training [325/700]: mean_loss=0.03081811754964292
Online_Training [326/700]: mean_loss=0.017772517981939018
Online_Training [327/700]: mean_loss=0.02346900408156216
Online_Training [328/700]: mean_loss=0.019170679850503802
Online_Training [329/700]: mean_loss=0.009495338192209601
Online_Training [330/700]: mean_loss=0.025197248440235853
Online_Training [331/700]: mean_loss=0.018073240644298494
Online_Training [332/700]: mean_loss=0.024603277444839478
Online_Training [333/700]: mean_loss=0.009482700261287391
Online_Training [334/700]: mean_loss=0.011423153104260564
Online_Training [335/700]: mean_loss=0.06427926430478692
Online_Training [336/700]: mean_loss=0.06427116552367806
Online_Training [337/700]: mean_loss=0.0949298394843936
Online_Training [338/700]: mean_loss=0.022257301723584533
Online_Training [339/700]: mean_loss=0.00885158171877265
Online_Training [340/700]: mean_loss=0.009525657864287496
Online_Training [341/700]: mean_loss=0.03128471621312201
Online_Training [342/700]: mean_loss=0.04540686774998903
Online_Training [343/700]: mean_loss=0.013322527636773884
Online_Training [344/700]: mean_loss=0.020280065247789025
Online_Training [345/700]: mean_loss=0.0332239659037441
Online_Training [346/700]: mean_loss=0.023616311140358448
Online_Training [347/700]: mean_loss=0.13022002298384905
Online_Training [348/700]: mean_loss=0.023556683212518692
Online_Training [349/700]: mean_loss=0.027910832781344652
Online_Training [350/700]: mean_loss=0.01139404356945306
Online_Training [351/700]: mean_loss=0.011719105648808181
Online_Training [352/700]: mean_loss=0.015380174852907658
Online_Training [353/700]: mean_loss=0.01899452123325318
Online_Training [354/700]: mean_loss=0.02482815575785935
Online_Training [355/700]: mean_loss=0.01362444506958127
Online_Training [356/700]: mean_loss=0.013963450561277568
Online_Training [357/700]: mean_loss=0.08842976205050945
Online_Training [358/700]: mean_loss=0.06758986692875624
Online_Training [359/700]: mean_loss=0.08731637056916952
Online_Training [360/700]: mean_loss=0.027508916100487113
Online_Training [361/700]: mean_loss=0.026344428537413478
Online_Training [362/700]: mean_loss=0.05189121328294277
Online_Training [363/700]: mean_loss=0.016523231752216816
Online_Training [364/700]: mean_loss=0.009817544836550951
Online_Training [365/700]: mean_loss=0.01940219453535974
Online_Training [366/700]: mean_loss=0.03358344663865864
Online_Training [367/700]: mean_loss=0.020300948759540915
Online_Training [368/700]: mean_loss=0.01697560551110655
Online_Training [369/700]: mean_loss=0.012478262651711702
Online_Training [370/700]: mean_loss=0.03613587515428662
Online_Training [371/700]: mean_loss=0.008068057242780924
Online_Training [372/700]: mean_loss=0.020458216778934002
Online_Training [373/700]: mean_loss=0.01890155323781073
Online_Training [374/700]: mean_loss=0.015100644901394844
Online_Training [375/700]: mean_loss=0.018195911776274443
Online_Training [376/700]: mean_loss=0.010278467903845012
Online_Training [377/700]: mean_loss=0.016796482959762216
Online_Training [378/700]: mean_loss=0.011764068389311433
Online_Training [379/700]: mean_loss=0.018079017288982868
Online_Training [380/700]: mean_loss=0.012833943590521812
Online_Training [381/700]: mean_loss=0.020341786788776517
Online_Training [382/700]: mean_loss=0.008533407119102776
Online_Training [383/700]: mean_loss=0.008094601100310683
Online_Training [384/700]: mean_loss=0.11262884177267551
Online_Training [385/700]: mean_loss=0.008065342728514224
Online_Training [386/700]: mean_loss=0.02240931778214872
Online_Training [387/700]: mean_loss=0.01934344181790948
Online_Training [388/700]: mean_loss=0.018459461629390717
Online_Training [389/700]: mean_loss=0.008335063001140952
Online_Training [390/700]: mean_loss=0.02589319460093975
Online_Training [391/700]: mean_loss=0.00704765651607886
Online_Training [392/700]: mean_loss=0.021321447333320975
Online_Training [393/700]: mean_loss=0.014161586295813322
Online_Training [394/700]: mean_loss=0.022178472951054573
Online_Training [395/700]: mean_loss=0.011116323294118047
Online_Training [396/700]: mean_loss=0.019945460837334394
Online_Training [397/700]: mean_loss=0.012041522189974785
Online_Training [398/700]: mean_loss=0.018481381237506866
Online_Training [399/700]: mean_loss=0.015572202973999083
Online_Training [400/700]: mean_loss=0.02642361563630402
Online_Training [401/700]: mean_loss=0.021837931592017412
Online_Training [402/700]: mean_loss=0.015120353200472891
Online_Training [403/700]: mean_loss=0.01416002691257745
Online_Training [404/700]: mean_loss=0.0679680802859366
Online_Training [405/700]: mean_loss=0.06315790209919214
Online_Training [406/700]: mean_loss=0.0199108284432441
Online_Training [407/700]: mean_loss=0.026390776736661792
Online_Training [408/700]: mean_loss=0.01745853410102427
Online_Training [409/700]: mean_loss=0.005567969812545925
Online_Training [410/700]: mean_loss=0.021096108946949244
Online_Training [411/700]: mean_loss=0.020008710213005543
Online_Training [412/700]: mean_loss=0.11146500054746866
Online_Training [413/700]: mean_loss=0.04358087573200464
Online_Training [414/700]: mean_loss=0.04268898535519838
Online_Training [415/700]: mean_loss=0.021134990267455578
Online_Training [416/700]: mean_loss=0.016085541108623147
Online_Training [417/700]: mean_loss=0.050267938524484634
Online_Training [418/700]: mean_loss=0.015931795118376613
Online_Training [419/700]: mean_loss=0.008559299050830305
Online_Training [420/700]: mean_loss=0.05364275258034468
Online_Training [421/700]: mean_loss=0.032050113659352064
Online_Training [422/700]: mean_loss=0.01830631890334189
Online_Training [423/700]: mean_loss=0.032635504845529795
Online_Training [424/700]: mean_loss=0.04988510720431805
Online_Training [425/700]: mean_loss=0.024724404327571392
Online_Training [426/700]: mean_loss=0.008239737420808524
Online_Training [427/700]: mean_loss=0.016709206509403884
Online_Training [428/700]: mean_loss=0.02465965528972447
Online_Training [429/700]: mean_loss=0.011863803723827004
Online_Training [430/700]: mean_loss=0.006167389277834445
Online_Training [431/700]: mean_loss=0.011385187157429755
Online_Training [432/700]: mean_loss=0.06558376690372825
Online_Training [433/700]: mean_loss=0.014181868289597332
Online_Training [434/700]: mean_loss=0.020598746836185455
Online_Training [435/700]: mean_loss=0.010641096509061754
Online_Training [436/700]: mean_loss=0.04805801622569561
Online_Training [437/700]: mean_loss=0.009508376359008253
Online_Training [438/700]: mean_loss=0.16495499946177006
Online_Training [439/700]: mean_loss=0.1019172202795744
Online_Training [440/700]: mean_loss=0.03301026998087764
Online_Training [441/700]: mean_loss=0.05415855860337615
Online_Training [442/700]: mean_loss=0.0044159587123431265
Online_Training [443/700]: mean_loss=0.014166506007313728
Online_Training [444/700]: mean_loss=0.026879710145294666
Online_Training [445/700]: mean_loss=0.030578250298276544
Online_Training [446/700]: mean_loss=0.018097049556672573
Online_Training [447/700]: mean_loss=0.011243580840528011
Online_Training [448/700]: mean_loss=0.025941801955923438
Online_Training [449/700]: mean_loss=0.021793732419610023
Online_Training [450/700]: mean_loss=0.030739236855879426
Online_Training [451/700]: mean_loss=0.02385499281808734
Online_Training [452/700]: mean_loss=0.03646288113668561
Online_Training [453/700]: mean_loss=0.06640087766572833
Online_Training [454/700]: mean_loss=0.01672741142101586
Online_Training [455/700]: mean_loss=0.04217617306858301
Online_Training [456/700]: mean_loss=0.0080869275261648
Online_Training [457/700]: mean_loss=0.007229196839034557
Online_Training [458/700]: mean_loss=0.009401705872733146
Online_Training [459/700]: mean_loss=0.009484158945269883
Online_Training [460/700]: mean_loss=0.01871895871590823
Online_Training [461/700]: mean_loss=0.028087800601497293
Online_Training [462/700]: mean_loss=0.01695987570565194
Online_Training [463/700]: mean_loss=0.005021589109674096
Online_Training [464/700]: mean_loss=0.01130217022728175
Online_Training [465/700]: mean_loss=0.07878296356648207
Online_Training [466/700]: mean_loss=0.020756199257448316
Online_Training [467/700]: mean_loss=0.014102020650170743
Online_Training [468/700]: mean_loss=0.01552039454691112
Online_Training [469/700]: mean_loss=0.01679005892947316
Online_Training [470/700]: mean_loss=0.06048471573740244
Online_Training [471/700]: mean_loss=0.03189596813172102
Online_Training [472/700]: mean_loss=0.0307543957605958
Online_Training [473/700]: mean_loss=0.005156196479219943
Online_Training [474/700]: mean_loss=0.013180294656194746
Online_Training [475/700]: mean_loss=0.011668942752294242
Online_Training [476/700]: mean_loss=0.1985970251262188
Online_Training [477/700]: mean_loss=0.10832267068326473
Online_Training [478/700]: mean_loss=0.04587031342089176
Online_Training [479/700]: mean_loss=0.012932730955071747
Online_Training [480/700]: mean_loss=0.00925056089181453
Online_Training [481/700]: mean_loss=0.0184423258760944
Online_Training [482/700]: mean_loss=0.028024158673360944
Online_Training [483/700]: mean_loss=0.01730065408628434
Online_Training [484/700]: mean_loss=0.013589287642389536
Online_Training [485/700]: mean_loss=0.01062657032161951
Online_Training [486/700]: mean_loss=0.01555794186424464
Online_Training [487/700]: mean_loss=0.0370340240187943
Online_Training [488/700]: mean_loss=0.018582095159217715
Online_Training [489/700]: mean_loss=0.015483377035707235
Online_Training [490/700]: mean_loss=0.019785758573561907
Online_Training [491/700]: mean_loss=0.03510736022144556
Online_Training [492/700]: mean_loss=0.011784742819145322
Online_Training [493/700]: mean_loss=0.021990397479385138
Online_Training [494/700]: mean_loss=0.06481668865308166
Online_Training [495/700]: mean_loss=0.008589044387917966
Online_Training [496/700]: mean_loss=0.025707878172397614
Online_Training [497/700]: mean_loss=0.015583014115691185
Online_Training [498/700]: mean_loss=0.014273488079197705
Online_Training [499/700]: mean_loss=0.025850742822512984
Online_Training [500/700]: mean_loss=0.008689424954354763
Online_Training [501/700]: mean_loss=0.011849518399685621
Online_Training [502/700]: mean_loss=0.020614083390682936
Online_Training [503/700]: mean_loss=0.01424848975148052
Online_Training [504/700]: mean_loss=0.009982191724702716
Online_Training [505/700]: mean_loss=0.012935689301230013
Online_Training [506/700]: mean_loss=0.11915633827447891
Online_Training [507/700]: mean_loss=0.12635441310703754
Online_Training [508/700]: mean_loss=0.029201914789155126
Online_Training [509/700]: mean_loss=0.016257255105301738
Online_Training [510/700]: mean_loss=0.03629332548007369
Online_Training [511/700]: mean_loss=0.0051271552219986916
Online_Training [512/700]: mean_loss=0.008214617962948978
Online_Training [513/700]: mean_loss=0.053988376865163445
Online_Training [514/700]: mean_loss=0.02785561280325055
Online_Training [515/700]: mean_loss=0.045794212725013494
Online_Training [516/700]: mean_loss=0.03057706286199391
Online_Training [517/700]: mean_loss=0.03154127183370292
Online_Training [518/700]: mean_loss=0.021808780962601304
Online_Training [519/700]: mean_loss=0.010934291989542544
Online_Training [520/700]: mean_loss=0.011548050562851131
Online_Training [521/700]: mean_loss=0.028538771672174335
Online_Training [522/700]: mean_loss=0.0076892494689673185
Online_Training [523/700]: mean_loss=0.01959649403579533
Online_Training [524/700]: mean_loss=0.07900515384972095
Online_Training [525/700]: mean_loss=0.023421954596415162
Online_Training [526/700]: mean_loss=0.011236390331760049
Online_Training [527/700]: mean_loss=0.018630475038662553
Online_Training [528/700]: mean_loss=0.024850265821442008
Online_Training [529/700]: mean_loss=0.03342747897841036
Online_Training [530/700]: mean_loss=0.018335731350816786
Online_Training [531/700]: mean_loss=0.014727770700119436
Online_Training [532/700]: mean_loss=0.02937710378319025
Online_Training [533/700]: mean_loss=0.017149940598756075
Online_Training [534/700]: mean_loss=0.013698565308004618
Online_Training [535/700]: mean_loss=0.029405303532257676
Online_Training [536/700]: mean_loss=0.10808390378952026
Online_Training [537/700]: mean_loss=0.00926115142647177
Online_Training [538/700]: mean_loss=0.019821635796688497
Online_Training [539/700]: mean_loss=0.00786566361784935
Online_Training [540/700]: mean_loss=0.04098163219168782
Online_Training [541/700]: mean_loss=0.11476536467671394
Online_Training [542/700]: mean_loss=0.0070951717789284885
Online_Training [543/700]: mean_loss=0.02805169438943267
Online_Training [544/700]: mean_loss=0.010614639846608043
Online_Training [545/700]: mean_loss=0.021749125327914953
Online_Training [546/700]: mean_loss=0.008515366585925221
Online_Training [547/700]: mean_loss=0.025531171821057796
Online_Training [548/700]: mean_loss=0.02303268387913704
Online_Training [549/700]: mean_loss=0.006424556777346879
Online_Training [550/700]: mean_loss=0.013129279483109713
Online_Training [551/700]: mean_loss=0.01811708661261946
Online_Training [552/700]: mean_loss=0.03280465607531369
Online_Training [553/700]: mean_loss=0.039846852887421846
Online_Training [554/700]: mean_loss=0.02669841726310551
Online_Training [555/700]: mean_loss=0.026483342982828617
Online_Training [556/700]: mean_loss=0.01632968382909894
Online_Training [557/700]: mean_loss=0.014743051491677761
Online_Training [558/700]: mean_loss=0.006634005520027131
Online_Training [559/700]: mean_loss=0.002503851254004985
Online_Training [560/700]: mean_loss=0.008895306382328272
Online_Training [561/700]: mean_loss=0.017476908629760146
Online_Training [562/700]: mean_loss=0.033972318982705474
Online_Training [563/700]: mean_loss=0.03938863566145301
Online_Training [564/700]: mean_loss=0.011801807559095323
Online_Training [565/700]: mean_loss=0.0253411412704736
Online_Training [566/700]: mean_loss=0.016037617693655193
Online_Training [567/700]: mean_loss=0.030259818537160754
Online_Training [568/700]: mean_loss=0.018020790768787265
Online_Training [569/700]: mean_loss=0.025055521400645375
Online_Training [570/700]: mean_loss=0.012834847788326442
Online_Training [571/700]: mean_loss=0.02903527393937111
Online_Training [572/700]: mean_loss=0.016620993264950812
Online_Training [573/700]: mean_loss=0.024062674958258867
Online_Training [574/700]: mean_loss=0.04821086535230279
Online_Training [575/700]: mean_loss=0.054868748877197504
Online_Training [576/700]: mean_loss=0.011516177793964744
Online_Training [577/700]: mean_loss=0.017655563890002668
Online_Training [578/700]: mean_loss=0.008514470013324171
Online_Training [579/700]: mean_loss=0.0159261601511389
Online_Training [580/700]: mean_loss=0.03410833002999425
Online_Training [581/700]: mean_loss=0.011969908722676337
Online_Training [582/700]: mean_loss=0.005564624210819602
Online_Training [583/700]: mean_loss=0.004593905905494466
Online_Training [584/700]: mean_loss=0.014332859311252832
Online_Training [585/700]: mean_loss=0.024940520292147994
Online_Training [586/700]: mean_loss=0.10628082230687141
Online_Training [587/700]: mean_loss=0.021508023142814636
Online_Training [588/700]: mean_loss=0.007804877357557416
Online_Training [589/700]: mean_loss=0.02469677315093577
Online_Training [590/700]: mean_loss=0.027368181152269244
Online_Training [591/700]: mean_loss=0.012248782208189368
Online_Training [592/700]: mean_loss=0.014177646371535957
Online_Training [593/700]: mean_loss=0.05080090509727597
Online_Training [594/700]: mean_loss=0.011019871919415891
Online_Training [595/700]: mean_loss=0.03226785338483751
Online_Training [596/700]: mean_loss=0.012139329803176224
Online_Training [597/700]: mean_loss=0.008129836292937398
Online_Training [598/700]: mean_loss=0.014343483955599368
Online_Training [599/700]: mean_loss=0.021445899736136198
Online_Training [600/700]: mean_loss=0.013672995148226619
Online_Training [601/700]: mean_loss=0.034798381850123405
Online_Training [602/700]: mean_loss=0.008213788794819266
Online_Training [603/700]: mean_loss=0.0073972478858195245
Online_Training [604/700]: mean_loss=0.03316468163393438
Online_Training [605/700]: mean_loss=0.009451089252252132
Online_Training [606/700]: mean_loss=0.009257268568035215
Online_Training [607/700]: mean_loss=0.012211129884235561
Online_Training [608/700]: mean_loss=0.011315211304463446
Online_Training [609/700]: mean_loss=0.014820889104157686
Online_Training [610/700]: mean_loss=0.017836965736933053
Online_Training [611/700]: mean_loss=0.010561872273683548
Online_Training [612/700]: mean_loss=0.13921836018562317
Online_Training [613/700]: mean_loss=0.06237001437693834
Online_Training [614/700]: mean_loss=0.011010425514541566
Online_Training [615/700]: mean_loss=0.011381549877114594
Online_Training [616/700]: mean_loss=0.020016896072775126
Online_Training [617/700]: mean_loss=0.006568174809217453
Online_Training [618/700]: mean_loss=0.02323301206342876
Online_Training [619/700]: mean_loss=0.01258608524221927
Online_Training [620/700]: mean_loss=0.059543751645833254
Online_Training [621/700]: mean_loss=0.008440148434601724
Online_Training [622/700]: mean_loss=0.04476646101102233
Online_Training [623/700]: mean_loss=0.029740332858636975
Online_Training [624/700]: mean_loss=0.01476632198318839
Online_Training [625/700]: mean_loss=0.010117983794771135
Online_Training [626/700]: mean_loss=0.008259743975941092
Online_Training [627/700]: mean_loss=0.009507601207587868
Online_Training [628/700]: mean_loss=0.011277084704488516
Online_Training [629/700]: mean_loss=0.01825953449588269
Online_Training [630/700]: mean_loss=0.04588484903797507
Online_Training [631/700]: mean_loss=0.016676966566592455
Online_Training [632/700]: mean_loss=0.029120536986738443
Online_Training [633/700]: mean_loss=0.015371193061582744
Online_Training [634/700]: mean_loss=0.01420317788142711
Online_Training [635/700]: mean_loss=0.01961543643847108
Online_Training [636/700]: mean_loss=0.0077139115310274065
Online_Training [637/700]: mean_loss=0.01047279522754252
Online_Training [638/700]: mean_loss=0.019465687801130116
Online_Training [639/700]: mean_loss=0.018120281165465713
Online_Training [640/700]: mean_loss=0.007553163915872574
Online_Training [641/700]: mean_loss=0.021421837038360536
Online_Training [642/700]: mean_loss=0.01250589347910136
Online_Training [643/700]: mean_loss=0.006790350598748773
Online_Training [644/700]: mean_loss=0.010341375542338938
Online_Training [645/700]: mean_loss=0.018955538049340248
Online_Training [646/700]: mean_loss=0.02526564779691398
Online_Training [647/700]: mean_loss=0.009833068936131895
Online_Training [648/700]: mean_loss=0.012574921129271388
Online_Training [649/700]: mean_loss=0.011275403085164726
Online_Training [650/700]: mean_loss=0.01521488861180842
Online_Training [651/700]: mean_loss=0.009148133802227676
Online_Training [652/700]: mean_loss=0.010700757498852909
Online_Training [653/700]: mean_loss=0.10030999314039946
Online_Training [654/700]: mean_loss=0.019278899999335408
Online_Training [655/700]: mean_loss=0.028056932846084237
Online_Training [656/700]: mean_loss=0.01871734904125333
Online_Training [657/700]: mean_loss=0.025950847193598747
Online_Training [658/700]: mean_loss=0.012272369116544724
Online_Training [659/700]: mean_loss=0.01493247237522155
Online_Training [660/700]: mean_loss=0.01274194906000048
Online_Training [661/700]: mean_loss=0.044701903127133846
Online_Training [662/700]: mean_loss=0.05213575949892402
Online_Training [663/700]: mean_loss=0.022827490232884884
Online_Training [664/700]: mean_loss=0.005654260283336043
Online_Training [665/700]: mean_loss=0.0363467235583812
Online_Training [666/700]: mean_loss=0.027352961944416165
Online_Training [667/700]: mean_loss=0.009317001677118242
Online_Training [668/700]: mean_loss=0.011141379363834858
Online_Training [669/700]: mean_loss=0.007986519893165678
Online_Training [670/700]: mean_loss=0.010538002010434866
Online_Training [671/700]: mean_loss=0.018712288001552224
Online_Training [672/700]: mean_loss=0.017647355678491294
Online_Training [673/700]: mean_loss=0.012680138112045825
Online_Training [674/700]: mean_loss=0.016480933292768896
Online_Training [675/700]: mean_loss=0.015606836299411952
Online_Training [676/700]: mean_loss=0.035032445564866066
Online_Training [677/700]: mean_loss=0.0484857140108943
Online_Training [678/700]: mean_loss=0.02273582061752677
Online_Training [679/700]: mean_loss=0.022637462010607123
Online_Training [680/700]: mean_loss=0.010258367285132408
Online_Training [681/700]: mean_loss=0.021515356842428446
Online_Training [682/700]: mean_loss=0.012746708351187408
Online_Training [683/700]: mean_loss=0.007557478093076497
Online_Training [684/700]: mean_loss=0.008296038722619414
Online_Training [685/700]: mean_loss=0.025442034704610705
Online_Training [686/700]: mean_loss=0.009550860500894487
Online_Training [687/700]: mean_loss=0.021335842553526163
Online_Training [688/700]: mean_loss=0.05081983329728246
Online_Training [689/700]: mean_loss=0.01779659278690815
Online_Training [690/700]: mean_loss=0.005479406740050763
Online_Training [691/700]: mean_loss=0.013936549075879157
Online_Training [692/700]: mean_loss=0.027797620045021176
Online_Training [693/700]: mean_loss=0.015900227590464056
Online_Training [694/700]: mean_loss=0.035547370091080666
Online_Training [695/700]: mean_loss=0.011975919711403549
Online_Training [696/700]: mean_loss=0.026356165762990713
Online_Training [697/700]: mean_loss=0.004214920161757618
Online_Training [698/700]: mean_loss=0.0076963676256127656
Online_Training [699/700]: mean_loss=0.04939700057730079
Online_Training [700/700]: mean_loss=0.01241111767012626
Q_Learning [1/300]: mean_loss=0.24413112737238407
Q_Learning [2/300]: mean_loss=0.2772955894470215
Q_Learning [3/300]: mean_loss=0.22114034928381443
Q_Learning [4/300]: mean_loss=0.10577248875051737
Q_Learning [5/300]: mean_loss=0.2827841006219387
Q_Learning [6/300]: mean_loss=0.13258128054440022
Q_Learning [7/300]: mean_loss=0.13703787699341774
Q_Learning [8/300]: mean_loss=0.0884051276370883
Q_Learning [9/300]: mean_loss=0.23298868536949158
Q_Learning [10/300]: mean_loss=0.153999799862504
Q_Learning [11/300]: mean_loss=0.12026408035308123
Q_Learning [12/300]: mean_loss=0.07977339439094067
Q_Learning [13/300]: mean_loss=0.11566466186195612
Q_Learning [14/300]: mean_loss=0.10214656218886375
Q_Learning [15/300]: mean_loss=0.1054230323061347
Q_Learning [16/300]: mean_loss=0.12235996127128601
Q_Learning [17/300]: mean_loss=0.16496446542441845
Q_Learning [18/300]: mean_loss=0.12254256755113602
Q_Learning [19/300]: mean_loss=0.046046263072639704
Q_Learning [20/300]: mean_loss=0.13514318130910397
Q_Learning [21/300]: mean_loss=0.14011738449335098
Q_Learning [22/300]: mean_loss=0.04548654844984412
Q_Learning [23/300]: mean_loss=0.02449247078038752
Q_Learning [24/300]: mean_loss=0.06332899676635861
Q_Learning [25/300]: mean_loss=0.04545756662264466
Q_Learning [26/300]: mean_loss=0.05515293497592211
Q_Learning [27/300]: mean_loss=0.06731242360547185
Q_Learning [28/300]: mean_loss=0.03435796522535384
Q_Learning [29/300]: mean_loss=0.04128111666068435
Q_Learning [30/300]: mean_loss=0.028687735786661506
Q_Learning [31/300]: mean_loss=0.030867326771840453
Q_Learning [32/300]: mean_loss=0.050702751614153385
Q_Learning [33/300]: mean_loss=0.021834010258316994
Q_Learning [34/300]: mean_loss=0.12269900739192963
Q_Learning [35/300]: mean_loss=0.053182941395789385
Q_Learning [36/300]: mean_loss=0.069038275629282
Q_Learning [37/300]: mean_loss=0.05736395390704274
Q_Learning [38/300]: mean_loss=0.03810146078467369
Q_Learning [39/300]: mean_loss=0.061791830230504274
Q_Learning [40/300]: mean_loss=0.034327647648751736
Q_Learning [41/300]: mean_loss=0.02319260872900486
Q_Learning [42/300]: mean_loss=0.04788239020854235
Q_Learning [43/300]: mean_loss=0.055844270158559084
Q_Learning [44/300]: mean_loss=0.06600149627774954
Q_Learning [45/300]: mean_loss=0.04915142245590687
Q_Learning [46/300]: mean_loss=0.03619031747803092
Q_Learning [47/300]: mean_loss=0.036076946184039116
Q_Learning [48/300]: mean_loss=0.06966482289135456
Q_Learning [49/300]: mean_loss=0.022961061215028167
Q_Learning [50/300]: mean_loss=0.03107618633657694
Q_Learning [51/300]: mean_loss=0.020941775292158127
Q_Learning [52/300]: mean_loss=0.05401980550959706
Q_Learning [53/300]: mean_loss=0.021498048678040504
Q_Learning [54/300]: mean_loss=0.04740456026047468
Q_Learning [55/300]: mean_loss=0.018063719384372234
Q_Learning [56/300]: mean_loss=0.03770320490002632
Q_Learning [57/300]: mean_loss=0.06915901089087129
Q_Learning [58/300]: mean_loss=0.1233651414513588
Q_Learning [59/300]: mean_loss=0.0672997091896832
Q_Learning [60/300]: mean_loss=0.03712531900964677
Q_Learning [61/300]: mean_loss=0.0400057821534574
Q_Learning [62/300]: mean_loss=0.0779455117881298
Q_Learning [63/300]: mean_loss=0.05053732916712761
Q_Learning [64/300]: mean_loss=0.004917771671898663
Q_Learning [65/300]: mean_loss=0.05357790598645806
Q_Learning [66/300]: mean_loss=0.043100371956825256
Q_Learning [67/300]: mean_loss=0.06496301665902138
Q_Learning [68/300]: mean_loss=0.017891935887746513
Q_Learning [69/300]: mean_loss=0.03827215591445565
Q_Learning [70/300]: mean_loss=0.033448874950408936
Q_Learning [71/300]: mean_loss=0.07485144026577473
Q_Learning [72/300]: mean_loss=0.07492300495505333
Q_Learning [73/300]: mean_loss=0.03547738562338054
Q_Learning [74/300]: mean_loss=0.03290445962920785
Q_Learning [75/300]: mean_loss=0.03138701943680644
Q_Learning [76/300]: mean_loss=0.02231965330429375
Q_Learning [77/300]: mean_loss=0.04817508114501834
Q_Learning [78/300]: mean_loss=0.01727866579312831
Q_Learning [79/300]: mean_loss=0.04694038117304444
Q_Learning [80/300]: mean_loss=0.026265019085258245
Q_Learning [81/300]: mean_loss=0.019588773604482412
Q_Learning [82/300]: mean_loss=0.022564272163435817
Q_Learning [83/300]: mean_loss=0.031848506070673466
Q_Learning [84/300]: mean_loss=0.024607961997389793
Q_Learning [85/300]: mean_loss=0.022842629812657833
Q_Learning [86/300]: mean_loss=0.038854387588799
Q_Learning [87/300]: mean_loss=0.010829139151610434
Q_Learning [88/300]: mean_loss=0.022555639035999775
Q_Learning [89/300]: mean_loss=0.03949208720587194
Q_Learning [90/300]: mean_loss=0.023035782389342785
Q_Learning [91/300]: mean_loss=0.022637537214905024
Q_Learning [92/300]: mean_loss=0.023362636100500822
Q_Learning [93/300]: mean_loss=0.02239035931415856
Q_Learning [94/300]: mean_loss=0.029910711105912924
Q_Learning [95/300]: mean_loss=0.02356560924090445
Q_Learning [96/300]: mean_loss=0.02316677407361567
Q_Learning [97/300]: mean_loss=0.02665039640851319
Q_Learning [98/300]: mean_loss=0.03454118291847408
Q_Learning [99/300]: mean_loss=0.024181468412280083
Q_Learning [100/300]: mean_loss=0.05194626888260245
Q_Learning [101/300]: mean_loss=0.020815833238884807
Q_Learning [102/300]: mean_loss=0.0462511507794261
Q_Learning [103/300]: mean_loss=0.028078692965209484
Q_Learning [104/300]: mean_loss=0.03168414207175374
Q_Learning [105/300]: mean_loss=0.02005027956329286
Q_Learning [106/300]: mean_loss=0.008068739669397473
Q_Learning [107/300]: mean_loss=0.014463129802607
Q_Learning [108/300]: mean_loss=0.01504128985106945
Q_Learning [109/300]: mean_loss=0.020835581002756953
Q_Learning [110/300]: mean_loss=0.03150923550128937
Q_Learning [111/300]: mean_loss=0.018849006737582386
Q_Learning [112/300]: mean_loss=0.06856228271499276
Q_Learning [113/300]: mean_loss=0.024361508199945092
Q_Learning [114/300]: mean_loss=0.03063217573799193
Q_Learning [115/300]: mean_loss=0.04993663728237152
Q_Learning [116/300]: mean_loss=0.02123050345107913
Q_Learning [117/300]: mean_loss=0.05467019323259592
Q_Learning [118/300]: mean_loss=0.01950738742016256
Q_Learning [119/300]: mean_loss=0.12083378713577986
Q_Learning [120/300]: mean_loss=0.05225085001438856
Q_Learning [121/300]: mean_loss=0.05399464350193739
Q_Learning [122/300]: mean_loss=0.03599739307537675
Q_Learning [123/300]: mean_loss=0.02757772197946906
Q_Learning [124/300]: mean_loss=0.01695375971030444
Q_Learning [125/300]: mean_loss=0.09937726706266403
Q_Learning [126/300]: mean_loss=0.06893690768629313
Q_Learning [127/300]: mean_loss=0.04249994270503521
Q_Learning [128/300]: mean_loss=0.026583224069327116
Q_Learning [129/300]: mean_loss=0.013337463140487671
Q_Learning [130/300]: mean_loss=0.021557397907599807
Q_Learning [131/300]: mean_loss=0.01761086843907833
Q_Learning [132/300]: mean_loss=0.017471206607297063
Q_Learning [133/300]: mean_loss=0.02498633787035942
Q_Learning [134/300]: mean_loss=0.007527195673901588
Q_Learning [135/300]: mean_loss=0.1170857585966587
Q_Learning [136/300]: mean_loss=0.022647934267297387
Q_Learning [137/300]: mean_loss=0.01776587450876832
Q_Learning [138/300]: mean_loss=0.01196706434711814
Q_Learning [139/300]: mean_loss=0.019453872926533222
Q_Learning [140/300]: mean_loss=0.020612101070582867
Q_Learning [141/300]: mean_loss=0.04699762584641576
Q_Learning [142/300]: mean_loss=0.01525599998421967
Q_Learning [143/300]: mean_loss=0.019988938234746456
Q_Learning [144/300]: mean_loss=0.006707577500492334
Q_Learning [145/300]: mean_loss=0.028444084338843822
Q_Learning [146/300]: mean_loss=0.01986353797838092
Q_Learning [147/300]: mean_loss=0.016061117639765143
Q_Learning [148/300]: mean_loss=0.027731422567740083
Q_Learning [149/300]: mean_loss=0.039271782618016005
Q_Learning [150/300]: mean_loss=0.09938539005815983
Q_Learning [151/300]: mean_loss=0.020335801411420107
Q_Learning [152/300]: mean_loss=0.016919379588216543
Q_Learning [153/300]: mean_loss=0.035778466844931245
Q_Learning [154/300]: mean_loss=0.02302233106456697
Q_Learning [155/300]: mean_loss=0.01044745510444045
Q_Learning [156/300]: mean_loss=0.022263640072196722
Q_Learning [157/300]: mean_loss=0.15400883927941322
Q_Learning [158/300]: mean_loss=0.004843952367082238
Q_Learning [159/300]: mean_loss=0.023637083126232028
Q_Learning [160/300]: mean_loss=0.02909296378493309
Q_Learning [161/300]: mean_loss=0.0372887016274035
Q_Learning [162/300]: mean_loss=0.01629278901964426
Q_Learning [163/300]: mean_loss=0.06183765269815922
Q_Learning [164/300]: mean_loss=0.017456025583669543
Q_Learning [165/300]: mean_loss=0.009880183264613152
Q_Learning [166/300]: mean_loss=0.018142722081393003
Q_Learning [167/300]: mean_loss=0.027591202640905976
Q_Learning [168/300]: mean_loss=0.028365794103592634
Q_Learning [169/300]: mean_loss=0.05074443528428674
Q_Learning [170/300]: mean_loss=0.1680087111890316
Q_Learning [171/300]: mean_loss=0.021602501859888434
Q_Learning [172/300]: mean_loss=0.018722006119787693
Q_Learning [173/300]: mean_loss=0.03153745480813086
Q_Learning [174/300]: mean_loss=0.015780059271492064
Q_Learning [175/300]: mean_loss=0.010609596036374569
Q_Learning [176/300]: mean_loss=0.007506680442020297
Q_Learning [177/300]: mean_loss=0.024637257447466254
Q_Learning [178/300]: mean_loss=0.03238619910553098
Q_Learning [179/300]: mean_loss=0.02642656397074461
Q_Learning [180/300]: mean_loss=0.01309081760700792
Q_Learning [181/300]: mean_loss=0.01195523061323911
Q_Learning [182/300]: mean_loss=0.03569153742864728
Q_Learning [183/300]: mean_loss=0.013405211386270821
Q_Learning [184/300]: mean_loss=0.00548345351126045
Q_Learning [185/300]: mean_loss=0.04370070481672883
Q_Learning [186/300]: mean_loss=0.03912041080184281
Q_Learning [187/300]: mean_loss=0.021038147620856762
Q_Learning [188/300]: mean_loss=0.02088300627656281
Q_Learning [189/300]: mean_loss=0.0548688224516809
Q_Learning [190/300]: mean_loss=0.015121633769012988
Q_Learning [191/300]: mean_loss=0.12729591317474842
Q_Learning [192/300]: mean_loss=0.029495877912268043
Q_Learning [193/300]: mean_loss=0.01792672835290432
Q_Learning [194/300]: mean_loss=0.005830590729601681
Q_Learning [195/300]: mean_loss=0.02977540949359536
Q_Learning [196/300]: mean_loss=0.01702875818591565
Q_Learning [197/300]: mean_loss=0.022509743459522724
Q_Learning [198/300]: mean_loss=0.022556551732122898
Q_Learning [199/300]: mean_loss=0.0949925035238266
Q_Learning [200/300]: mean_loss=0.024814492790028453
Q_Learning [201/300]: mean_loss=0.023475305642932653
Q_Learning [202/300]: mean_loss=0.009910874185152352
Q_Learning [203/300]: mean_loss=0.013335764640942216
Q_Learning [204/300]: mean_loss=0.012428867281414568
Q_Learning [205/300]: mean_loss=0.0620799227617681
Q_Learning [206/300]: mean_loss=0.006909376359544694
Q_Learning [207/300]: mean_loss=0.05153112579137087
Q_Learning [208/300]: mean_loss=0.034207784570753574
Q_Learning [209/300]: mean_loss=0.052961861714720726
Q_Learning [210/300]: mean_loss=0.03628103993833065
Q_Learning [211/300]: mean_loss=0.012267879443243146
Q_Learning [212/300]: mean_loss=0.09224327094852924
Q_Learning [213/300]: mean_loss=0.039079359732568264
Q_Learning [214/300]: mean_loss=0.010468614054843783
Q_Learning [215/300]: mean_loss=0.03285656915977597
Q_Learning [216/300]: mean_loss=0.03635612782090902
Q_Learning [217/300]: mean_loss=0.012030990328639746
Q_Learning [218/300]: mean_loss=0.006853782921098173
Q_Learning [219/300]: mean_loss=0.06109960051253438
Q_Learning [220/300]: mean_loss=0.013816709397360682
Q_Learning [221/300]: mean_loss=0.0332294306717813
Q_Learning [222/300]: mean_loss=0.009656833834014833
Q_Learning [223/300]: mean_loss=0.028503997018560767
Q_Learning [224/300]: mean_loss=0.008860578411258757
Q_Learning [225/300]: mean_loss=0.030758809531107545
Q_Learning [226/300]: mean_loss=0.030604574596509337
Q_Learning [227/300]: mean_loss=0.018489315640181303
Q_Learning [228/300]: mean_loss=0.02271493594162166
Q_Learning [229/300]: mean_loss=0.03341347980313003
Q_Learning [230/300]: mean_loss=0.01914155064150691
Q_Learning [231/300]: mean_loss=0.01950505143031478
Q_Learning [232/300]: mean_loss=0.021225603763014078
Q_Learning [233/300]: mean_loss=0.012424019514583051
Q_Learning [234/300]: mean_loss=0.028351969085633755
Q_Learning [235/300]: mean_loss=0.11430756747722626
Q_Learning [236/300]: mean_loss=0.061055609956383705
Q_Learning [237/300]: mean_loss=0.027116654440760612
Q_Learning [238/300]: mean_loss=0.1072841165587306
Q_Learning [239/300]: mean_loss=0.05602098582312465
Q_Learning [240/300]: mean_loss=0.040058541810140014
Q_Learning [241/300]: mean_loss=0.04397848108783364
Q_Learning [242/300]: mean_loss=0.026945512043312192
Q_Learning [243/300]: mean_loss=0.03784323390573263
Q_Learning [244/300]: mean_loss=0.014504773076623678
Q_Learning [245/300]: mean_loss=0.026794651290401816
Q_Learning [246/300]: mean_loss=0.015153854852542281
Q_Learning [247/300]: mean_loss=0.011060243472456932
Q_Learning [248/300]: mean_loss=0.07900145836174488
Q_Learning [249/300]: mean_loss=0.018368500284850597
Q_Learning [250/300]: mean_loss=0.015289728762581944
Q_Learning [251/300]: mean_loss=0.012792078196071088
Q_Learning [252/300]: mean_loss=0.021584663772955537
Q_Learning [253/300]: mean_loss=0.01773107796907425
Q_Learning [254/300]: mean_loss=0.017037650453858078
Q_Learning [255/300]: mean_loss=0.029098600149154663
Q_Learning [256/300]: mean_loss=0.016710223746486008
Q_Learning [257/300]: mean_loss=0.013169298646971583
Q_Learning [258/300]: mean_loss=0.021540775196626782
Q_Learning [259/300]: mean_loss=0.010665765614248812
Q_Learning [260/300]: mean_loss=0.0078058065846562386
Q_Learning [261/300]: mean_loss=0.023127907421439886
Q_Learning [262/300]: mean_loss=0.026390123181045055
Q_Learning [263/300]: mean_loss=0.010501295211724937
Q_Learning [264/300]: mean_loss=0.01922184438444674
Q_Learning [265/300]: mean_loss=0.013634879840537906
Q_Learning [266/300]: mean_loss=0.01039847545325756
Q_Learning [267/300]: mean_loss=0.018652942962944508
Q_Learning [268/300]: mean_loss=0.0063399175414815545
Q_Learning [269/300]: mean_loss=0.014771913643926382
Q_Learning [270/300]: mean_loss=0.01361364359036088
Q_Learning [271/300]: mean_loss=0.02300719218328595
Q_Learning [272/300]: mean_loss=0.009096637484617531
Q_Learning [273/300]: mean_loss=0.010928795556537807
Q_Learning [274/300]: mean_loss=0.008559343463275582
Q_Learning [275/300]: mean_loss=0.014768633875064552
Q_Learning [276/300]: mean_loss=0.01176802208647132
Q_Learning [277/300]: mean_loss=0.018015850335359573
Q_Learning [278/300]: mean_loss=0.021858637453988194
Q_Learning [279/300]: mean_loss=0.013682135730050504
Q_Learning [280/300]: mean_loss=0.019462780095636845
Q_Learning [281/300]: mean_loss=0.021344889188185334
Q_Learning [282/300]: mean_loss=0.030666680075228214
Q_Learning [283/300]: mean_loss=0.019578656647354364
Q_Learning [284/300]: mean_loss=0.009016110503580421
Q_Learning [285/300]: mean_loss=0.016164098517037928
Q_Learning [286/300]: mean_loss=0.019905894761905074
Q_Learning [287/300]: mean_loss=0.01683874847367406
Q_Learning [288/300]: mean_loss=0.015223742579109967
Q_Learning [289/300]: mean_loss=0.04260517377406359
Q_Learning [290/300]: mean_loss=0.0065239896648563445
Q_Learning [291/300]: mean_loss=0.011063111713156104
Q_Learning [292/300]: mean_loss=0.007373624364845455
Q_Learning [293/300]: mean_loss=0.010007708915509284
Q_Learning [294/300]: mean_loss=0.012591567356139421
Q_Learning [295/300]: mean_loss=0.03365642437711358
Q_Learning [296/300]: mean_loss=0.033108466072008014
Q_Learning [297/300]: mean_loss=0.019202591152861714
Q_Learning [298/300]: mean_loss=0.009935463895089924
Q_Learning [299/300]: mean_loss=0.012632588972337544
Q_Learning [300/300]: mean_loss=0.04430959094315767
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.970141   1.2890278]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 1, 1, 1, 0, 0, 2, 1, 1, 1, 2, 0, 0, 1, 0, 1, 0, 2, 0, 0, 1, 2, 1, 0, 1, 2, 0, 2, 1, 0, 2, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 2, 0, 0, 0, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 1, 2, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 2, 1, 2, 0, 2, 2, 1, 2, 0, 2, 0, 0, 2, 1, 2, 1, 0, 2, 1, 0, 2, 1, 0, 1, 2, 1, 0, 0, 0, 1, 2, 0, 1, 2, 1, 1, 2, 0, 2, 2, 1, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 2, 2, 0, 0, 1, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 0, 2, 1, 0, 2, 1, 2, 0, 0, 1, 1, 1, 0, 1, 0, 1, 2, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 1, 1, 0, 1, 1, 1, 2, 3, 1, 2, 1, 2, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 2, 2, 0, 3, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 0, 1, 2, 3, 0, 0, 1, 2, 2, 0, 2, 1, 0, 0, 1, 1, 2, 2, 1, 2, 0, 0, 2, 1, 2, 1, 2]
Centroids: [[0.8742054, -1.285756], [0.84746724, -0.1023625], [-0.99653697, 1.2789674]]
Centroids: [[-0.9551242, 1.2885511], [0.95434517, -0.14546263], [0.7506658, -1.3620241], [-2.2941334, 0.9786799]]
Contingency Matrix: 
[[ 0 21 82  0]
 [ 0 89 11  0]
 [94  0  0  3]]
[[0, 21, 82, 0], [0, 89, 11, 0], [94, 0, 0, 3]]
[[0, 21, 82, 0], [0, 89, 11, 0], [94, 0, 0, 3]]
[0, 1, 2, 3]
[[-1, 21, 82, 0], [-1, 89, 11, 0], [-1, -1, -1, -1]]
[[-1, -1, 82, 0], [-1, -1, -1, -1], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {2: 0, 1: 1, 0: 2}
New Contingency Matrix: 
[[82 21  0  0]
 [11 89  0  0]
 [ 0  0 94  3]]
New Clustered Label Sequence: [2, 1, 0, 3]
Diagonal_Elements: [82, 89, 94], Sum: 265
All_Elements: [82, 21, 0, 0, 11, 89, 0, 0, 0, 0, 94, 3], Sum: 300
Accuracy: 0.8833333333333333
