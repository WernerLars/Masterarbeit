Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_6_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_6_opt_temp/C_Easy1_noise005.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_05_04-17_15_42
Punishment_Coefficient: 1.1
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000025AA6557CF8>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.11907435767352581
Online_Training [2/700]: mean_loss=0.096489735879004
Online_Training [3/700]: mean_loss=0.35334111750125885
Online_Training [4/700]: mean_loss=0.30047332495450974
Online_Training [5/700]: mean_loss=0.28207484260201454
Online_Training [6/700]: mean_loss=0.12328332103788853
Online_Training [7/700]: mean_loss=0.11486530769616365
Online_Training [8/700]: mean_loss=0.21942880004644394
Online_Training [9/700]: mean_loss=0.10820742230862379
Online_Training [10/700]: mean_loss=0.08591767959296703
Online_Training [11/700]: mean_loss=0.06684542633593082
Online_Training [12/700]: mean_loss=0.06033724918961525
Online_Training [13/700]: mean_loss=0.044128662906587124
Online_Training [14/700]: mean_loss=0.1363319493830204
Online_Training [15/700]: mean_loss=0.2226413320749998
Online_Training [16/700]: mean_loss=0.12981677800416946
Online_Training [17/700]: mean_loss=0.13697027787566185
Online_Training [18/700]: mean_loss=0.1842855978757143
Online_Training [19/700]: mean_loss=0.12088365573436022
Online_Training [20/700]: mean_loss=0.10561706498265266
Online_Training [21/700]: mean_loss=0.16685502603650093
Online_Training [22/700]: mean_loss=0.1279439451172948
Online_Training [23/700]: mean_loss=0.10521352756768465
Online_Training [24/700]: mean_loss=0.05690024746581912
Online_Training [25/700]: mean_loss=0.11339136958122253
Online_Training [26/700]: mean_loss=0.07685326598584652
Online_Training [27/700]: mean_loss=0.06509234104305506
Online_Training [28/700]: mean_loss=0.05509530706331134
Online_Training [29/700]: mean_loss=0.09618321806192398
Online_Training [30/700]: mean_loss=0.03424065373837948
Online_Training [31/700]: mean_loss=0.14025763608515263
Online_Training [32/700]: mean_loss=0.015757657820358872
Online_Training [33/700]: mean_loss=0.016791223781183362
Online_Training [34/700]: mean_loss=0.10775793343782425
Online_Training [35/700]: mean_loss=0.006714613438816741
Online_Training [36/700]: mean_loss=0.12573078647255898
Online_Training [37/700]: mean_loss=0.09241601172834635
Online_Training [38/700]: mean_loss=0.06747271586209536
Online_Training [39/700]: mean_loss=0.06365377875044942
Online_Training [40/700]: mean_loss=0.0470883478410542
Online_Training [41/700]: mean_loss=0.045545962173491716
Online_Training [42/700]: mean_loss=0.03264947677962482
Online_Training [43/700]: mean_loss=0.04205933632329106
Online_Training [44/700]: mean_loss=0.015885688131675124
Online_Training [45/700]: mean_loss=0.05098234489560127
Online_Training [46/700]: mean_loss=0.052591000217944384
Online_Training [47/700]: mean_loss=0.126219448633492
Online_Training [48/700]: mean_loss=0.16843233816325665
Online_Training [49/700]: mean_loss=0.025476956856437027
Online_Training [50/700]: mean_loss=0.04043641500174999
Online_Training [51/700]: mean_loss=0.03367356793023646
Online_Training [52/700]: mean_loss=0.012802397483028471
Online_Training [53/700]: mean_loss=0.07010180503129959
Online_Training [54/700]: mean_loss=0.26993197202682495
Online_Training [55/700]: mean_loss=0.0627828985452652
Online_Training [56/700]: mean_loss=0.028895366471260786
Online_Training [57/700]: mean_loss=0.026805379427969456
Online_Training [58/700]: mean_loss=0.009170298522803932
Online_Training [59/700]: mean_loss=0.09118765592575073
Online_Training [60/700]: mean_loss=0.019457767251878977
Online_Training [61/700]: mean_loss=0.021494514541700482
Online_Training [62/700]: mean_loss=0.016792879439890385
Online_Training [63/700]: mean_loss=0.0035407413088250905
Online_Training [64/700]: mean_loss=0.0021314647747203708
Online_Training [65/700]: mean_loss=0.010638227802701294
Online_Training [66/700]: mean_loss=0.0036018971004523337
Online_Training [67/700]: mean_loss=0.0023515516077168286
Online_Training [68/700]: mean_loss=0.12330261524766684
Online_Training [69/700]: mean_loss=0.011198483523912728
Online_Training [70/700]: mean_loss=0.005259612284135073
Online_Training [71/700]: mean_loss=0.0025280468398705125
Online_Training [72/700]: mean_loss=0.0066958736861124635
Online_Training [73/700]: mean_loss=0.009165100025711581
Online_Training [74/700]: mean_loss=0.0027159764867974445
Online_Training [75/700]: mean_loss=0.005898779782000929
Online_Training [76/700]: mean_loss=0.01325533026829362
Online_Training [77/700]: mean_loss=0.006122373772086576
Online_Training [78/700]: mean_loss=0.005300536286085844
Online_Training [79/700]: mean_loss=0.030185913434252143
Online_Training [80/700]: mean_loss=0.009736989624798298
Online_Training [81/700]: mean_loss=0.004367534798802808
Online_Training [82/700]: mean_loss=0.021927172783762217
Online_Training [83/700]: mean_loss=0.021034260746091604
Online_Training [84/700]: mean_loss=0.0033003719872795045
Online_Training [85/700]: mean_loss=0.01240143203176558
Online_Training [86/700]: mean_loss=0.013103593955747783
Online_Training [87/700]: mean_loss=0.005682838964276016
Online_Training [88/700]: mean_loss=0.012128140311688185
Online_Training [89/700]: mean_loss=0.0041900857468135655
Online_Training [90/700]: mean_loss=0.01253398205153644
Online_Training [91/700]: mean_loss=0.01364521577488631
Online_Training [92/700]: mean_loss=0.007661714742425829
Online_Training [93/700]: mean_loss=0.0030524608737323433
Online_Training [94/700]: mean_loss=0.012296607717871666
Online_Training [95/700]: mean_loss=0.00200116602354683
Online_Training [96/700]: mean_loss=0.0058323044795542955
Online_Training [97/700]: mean_loss=0.009350422653369606
Online_Training [98/700]: mean_loss=0.0037241219251882285
Online_Training [99/700]: mean_loss=0.0050901976064778864
Online_Training [100/700]: mean_loss=0.0012780706529156305
Online_Training [101/700]: mean_loss=0.0024448945478070527
Online_Training [102/700]: mean_loss=0.012858632835559547
Online_Training [103/700]: mean_loss=0.0062419152818620205
Online_Training [104/700]: mean_loss=0.0021255285246297717
Online_Training [105/700]: mean_loss=0.033212955109775066
Online_Training [106/700]: mean_loss=0.029644136782735586
Online_Training [107/700]: mean_loss=0.003358359361300245
Online_Training [108/700]: mean_loss=0.012552600121125579
Online_Training [109/700]: mean_loss=0.002860632142983377
Online_Training [110/700]: mean_loss=0.004028377530630678
Online_Training [111/700]: mean_loss=0.003243611950892955
Online_Training [112/700]: mean_loss=0.004159851639997214
Online_Training [113/700]: mean_loss=0.007353855122346431
Online_Training [114/700]: mean_loss=0.00495009683072567
Online_Training [115/700]: mean_loss=0.01606957777403295
Online_Training [116/700]: mean_loss=0.002742985525401309
Online_Training [117/700]: mean_loss=0.002847010619007051
Online_Training [118/700]: mean_loss=0.0024051837681327015
Online_Training [119/700]: mean_loss=0.002923849126091227
Online_Training [120/700]: mean_loss=0.009755973413120955
Online_Training [121/700]: mean_loss=0.007526024826802313
Online_Training [122/700]: mean_loss=0.011602931073866785
Online_Training [123/700]: mean_loss=0.0009794625875656493
Online_Training [124/700]: mean_loss=0.006836476037278771
Online_Training [125/700]: mean_loss=0.003943992065615021
Online_Training [126/700]: mean_loss=0.0020847583218710497
Online_Training [127/700]: mean_loss=0.004610624979250133
Online_Training [128/700]: mean_loss=0.00838379783090204
Online_Training [129/700]: mean_loss=0.007759953150525689
Online_Training [130/700]: mean_loss=0.00410347554134205
Online_Training [131/700]: mean_loss=0.004471273074159399
Online_Training [132/700]: mean_loss=0.0074388218054082245
Online_Training [133/700]: mean_loss=0.0038418622280005366
Online_Training [134/700]: mean_loss=0.012933705875184387
Online_Training [135/700]: mean_loss=0.0036727193801198155
Online_Training [136/700]: mean_loss=0.003850340872304514
Online_Training [137/700]: mean_loss=0.004671593720559031
Online_Training [138/700]: mean_loss=0.0021076643461128697
Online_Training [139/700]: mean_loss=0.0016838606679812074
Online_Training [140/700]: mean_loss=0.003890478517860174
Online_Training [141/700]: mean_loss=0.0020331104315118864
Online_Training [142/700]: mean_loss=0.004576081468258053
Online_Training [143/700]: mean_loss=0.023745222948491573
Online_Training [144/700]: mean_loss=0.0072642753075342625
Online_Training [145/700]: mean_loss=0.06846780981868505
Online_Training [146/700]: mean_loss=0.12874070182442665
Online_Training [147/700]: mean_loss=0.017641610116697848
Online_Training [148/700]: mean_loss=0.014198816032148898
Online_Training [149/700]: mean_loss=0.012942297500558197
Online_Training [150/700]: mean_loss=0.1074962173588574
Online_Training [151/700]: mean_loss=0.2759343720972538
Online_Training [152/700]: mean_loss=0.014018320594914258
Online_Training [153/700]: mean_loss=0.01427203242201358
Online_Training [154/700]: mean_loss=0.007690112164709717
Online_Training [155/700]: mean_loss=0.039645338198170066
Online_Training [156/700]: mean_loss=0.01636414579115808
Online_Training [157/700]: mean_loss=0.004041780135594308
Online_Training [158/700]: mean_loss=0.017817572806961834
Online_Training [159/700]: mean_loss=0.008145551779307425
Online_Training [160/700]: mean_loss=0.012777102529071271
Online_Training [161/700]: mean_loss=0.0035130779433529824
Online_Training [162/700]: mean_loss=0.05054446030408144
Online_Training [163/700]: mean_loss=0.10944303125143051
Online_Training [164/700]: mean_loss=0.012183943530544639
Online_Training [165/700]: mean_loss=0.006050022901035845
Online_Training [166/700]: mean_loss=0.014237382332794368
Online_Training [167/700]: mean_loss=0.004364367923699319
Online_Training [168/700]: mean_loss=0.007092938350979239
Online_Training [169/700]: mean_loss=0.002272580415592529
Online_Training [170/700]: mean_loss=0.0051870731404051185
Online_Training [171/700]: mean_loss=0.016718993661925197
Online_Training [172/700]: mean_loss=0.03675292991101742
Online_Training [173/700]: mean_loss=0.03177202888764441
Online_Training [174/700]: mean_loss=0.020846464671194553
Online_Training [175/700]: mean_loss=0.016741009894758463
Online_Training [176/700]: mean_loss=0.0031355287064798176
Online_Training [177/700]: mean_loss=0.005367075587855652
Online_Training [178/700]: mean_loss=0.004144071834161878
Online_Training [179/700]: mean_loss=0.005097358371131122
Online_Training [180/700]: mean_loss=0.005871022527571768
Online_Training [181/700]: mean_loss=0.007024090911727399
Online_Training [182/700]: mean_loss=0.001370817728457041
Online_Training [183/700]: mean_loss=0.005866806139238179
Online_Training [184/700]: mean_loss=0.0038330518000293523
Online_Training [185/700]: mean_loss=0.0030404285062104464
Online_Training [186/700]: mean_loss=0.0034602170635480434
Online_Training [187/700]: mean_loss=0.0017611881776247174
Online_Training [188/700]: mean_loss=0.08436852879822254
Online_Training [189/700]: mean_loss=0.08807533234357834
Online_Training [190/700]: mean_loss=0.018798787146806717
Online_Training [191/700]: mean_loss=0.016086929943412542
Online_Training [192/700]: mean_loss=0.005691940488759428
Online_Training [193/700]: mean_loss=0.009177978499792516
Online_Training [194/700]: mean_loss=0.012430790346115828
Online_Training [195/700]: mean_loss=0.005460737447720021
Online_Training [196/700]: mean_loss=0.005123404727783054
Online_Training [197/700]: mean_loss=0.0038119356613606215
Online_Training [198/700]: mean_loss=0.008015444909688085
Online_Training [199/700]: mean_loss=0.011687038582749665
Online_Training [200/700]: mean_loss=0.006599697400815785
Online_Training [201/700]: mean_loss=0.011371188680641353
Online_Training [202/700]: mean_loss=0.005046908278018236
Online_Training [203/700]: mean_loss=0.0014231177483452484
Online_Training [204/700]: mean_loss=0.006541434035170823
Online_Training [205/700]: mean_loss=0.0038400958001147956
Online_Training [206/700]: mean_loss=0.006823850388173014
Online_Training [207/700]: mean_loss=0.006383277475833893
Online_Training [208/700]: mean_loss=0.004059658269397914
Online_Training [209/700]: mean_loss=0.006763885670807213
Online_Training [210/700]: mean_loss=0.009350141044706106
Online_Training [211/700]: mean_loss=0.004523185372818261
Online_Training [212/700]: mean_loss=0.003231796290492639
Online_Training [213/700]: mean_loss=0.005279806267935783
Online_Training [214/700]: mean_loss=0.004409104352816939
Online_Training [215/700]: mean_loss=0.007120527210645378
Online_Training [216/700]: mean_loss=0.0012281378731131554
Online_Training [217/700]: mean_loss=0.004142155317822471
Online_Training [218/700]: mean_loss=0.003304155805381015
Online_Training [219/700]: mean_loss=0.007074187626130879
Online_Training [220/700]: mean_loss=0.008874333172570914
Online_Training [221/700]: mean_loss=0.0073544225306250155
Online_Training [222/700]: mean_loss=0.0024919758434407413
Online_Training [223/700]: mean_loss=0.00073977201100206
Online_Training [224/700]: mean_loss=0.004088401678018272
Online_Training [225/700]: mean_loss=0.0010443356150062755
Online_Training [226/700]: mean_loss=0.0008447150030406192
Online_Training [227/700]: mean_loss=0.009338585659861565
Online_Training [228/700]: mean_loss=0.006887835101224482
Online_Training [229/700]: mean_loss=0.004365614004200324
Online_Training [230/700]: mean_loss=0.003236906515667215
Online_Training [231/700]: mean_loss=0.002275479811942205
Online_Training [232/700]: mean_loss=0.003544746054103598
Online_Training [233/700]: mean_loss=0.004722857265733182
Online_Training [234/700]: mean_loss=0.005084672477096319
Online_Training [235/700]: mean_loss=0.006224404147360474
Online_Training [236/700]: mean_loss=0.010972794203553349
Online_Training [237/700]: mean_loss=0.002840810368070379
Online_Training [238/700]: mean_loss=0.00424495933111757
Online_Training [239/700]: mean_loss=0.0016463996580569074
Online_Training [240/700]: mean_loss=0.006297383981291205
Online_Training [241/700]: mean_loss=0.01093600643798709
Online_Training [242/700]: mean_loss=0.00499390866025351
Online_Training [243/700]: mean_loss=0.007148625503759831
Online_Training [244/700]: mean_loss=0.00500363003811799
Online_Training [245/700]: mean_loss=0.003316778689622879
Online_Training [246/700]: mean_loss=0.0048864711716305465
Online_Training [247/700]: mean_loss=0.005035832116845995
Online_Training [248/700]: mean_loss=0.018968239659443498
Online_Training [249/700]: mean_loss=0.014132340671494603
Online_Training [250/700]: mean_loss=0.0056468281836714596
Online_Training [251/700]: mean_loss=0.015014370554126799
Online_Training [252/700]: mean_loss=0.008022640249691904
Online_Training [253/700]: mean_loss=0.0017526388546684757
Online_Training [254/700]: mean_loss=0.0018682772933971137
Online_Training [255/700]: mean_loss=0.0024295045586768538
Online_Training [256/700]: mean_loss=0.07982838619500399
Online_Training [257/700]: mean_loss=0.09070150274783373
Online_Training [258/700]: mean_loss=0.011758969107177109
Online_Training [259/700]: mean_loss=0.0042212389525957406
Online_Training [260/700]: mean_loss=0.003833798080449924
Online_Training [261/700]: mean_loss=0.02045788208488375
Online_Training [262/700]: mean_loss=0.02767984929960221
Online_Training [263/700]: mean_loss=0.029665934445802122
Online_Training [264/700]: mean_loss=0.009111550287343562
Online_Training [265/700]: mean_loss=0.022455886792158708
Online_Training [266/700]: mean_loss=0.007582823163829744
Online_Training [267/700]: mean_loss=0.027548975951503962
Online_Training [268/700]: mean_loss=0.008824848686344922
Online_Training [269/700]: mean_loss=0.009358464158140123
Online_Training [270/700]: mean_loss=0.022952807717956603
Online_Training [271/700]: mean_loss=0.02646957989782095
Online_Training [272/700]: mean_loss=0.0067039161222055554
Online_Training [273/700]: mean_loss=0.00443027721485123
Online_Training [274/700]: mean_loss=0.0390249754418619
Online_Training [275/700]: mean_loss=0.20301641710102558
Online_Training [276/700]: mean_loss=0.06106451619416475
Online_Training [277/700]: mean_loss=0.011457737651653588
Online_Training [278/700]: mean_loss=0.014914359198883176
Online_Training [279/700]: mean_loss=0.00383464532205835
Online_Training [280/700]: mean_loss=0.009296578471548855
Online_Training [281/700]: mean_loss=0.004825969925150275
Online_Training [282/700]: mean_loss=0.019830335048027337
Online_Training [283/700]: mean_loss=0.013190601486712694
Online_Training [284/700]: mean_loss=0.009641437151003629
Online_Training [285/700]: mean_loss=0.012586377677507699
Online_Training [286/700]: mean_loss=0.008676918514538556
Online_Training [287/700]: mean_loss=0.0040736277878750116
Online_Training [288/700]: mean_loss=0.0025878686719806865
Online_Training [289/700]: mean_loss=0.004723862803075463
Online_Training [290/700]: mean_loss=0.002552719379309565
Online_Training [291/700]: mean_loss=0.004749484302010387
Online_Training [292/700]: mean_loss=0.0018916812696261331
Online_Training [293/700]: mean_loss=0.003961229958804324
Online_Training [294/700]: mean_loss=0.0031781205616425723
Online_Training [295/700]: mean_loss=0.0018802369595505297
Online_Training [296/700]: mean_loss=0.18324270471930504
Online_Training [297/700]: mean_loss=0.07644595485180616
Online_Training [298/700]: mean_loss=0.012347111129201949
Online_Training [299/700]: mean_loss=0.014170448645018041
Online_Training [300/700]: mean_loss=0.00772542116465047
Online_Training [301/700]: mean_loss=0.009595124167390168
Online_Training [302/700]: mean_loss=0.007911778811831027
Online_Training [303/700]: mean_loss=0.003049794409889728
Online_Training [304/700]: mean_loss=0.003210263152141124
Online_Training [305/700]: mean_loss=0.006141118239611387
Online_Training [306/700]: mean_loss=0.009291898284573108
Online_Training [307/700]: mean_loss=0.0042409289162606
Online_Training [308/700]: mean_loss=0.0019039076287299395
Online_Training [309/700]: mean_loss=0.002492592917406
Online_Training [310/700]: mean_loss=0.00325831412919797
Online_Training [311/700]: mean_loss=0.00690564833348617
Online_Training [312/700]: mean_loss=0.003224323911126703
Online_Training [313/700]: mean_loss=0.0035354862338863313
Online_Training [314/700]: mean_loss=0.009079955168999732
Online_Training [315/700]: mean_loss=0.006992565584369004
Online_Training [316/700]: mean_loss=0.004462472512386739
Online_Training [317/700]: mean_loss=0.005237459728959948
Online_Training [318/700]: mean_loss=0.006104680927819572
Online_Training [319/700]: mean_loss=0.003762144915526733
Online_Training [320/700]: mean_loss=0.005697893386241049
Online_Training [321/700]: mean_loss=0.002641896571731195
Online_Training [322/700]: mean_loss=0.001228172957780771
Online_Training [323/700]: mean_loss=0.11396604590117931
Online_Training [324/700]: mean_loss=0.1003778874874115
Online_Training [325/700]: mean_loss=0.006138020951766521
Online_Training [326/700]: mean_loss=0.0019399953162064776
Online_Training [327/700]: mean_loss=0.03325512842275202
Online_Training [328/700]: mean_loss=0.011955282068811357
Online_Training [329/700]: mean_loss=0.0034871005918830633
Online_Training [330/700]: mean_loss=0.013843260356225073
Online_Training [331/700]: mean_loss=0.0033864733413793147
Online_Training [332/700]: mean_loss=0.005254019401036203
Online_Training [333/700]: mean_loss=0.003973859013058245
Online_Training [334/700]: mean_loss=0.010227566002868116
Online_Training [335/700]: mean_loss=0.01128740212880075
Online_Training [336/700]: mean_loss=0.005585690552834421
Online_Training [337/700]: mean_loss=0.002954712850623764
Online_Training [338/700]: mean_loss=0.0062610486056655645
Online_Training [339/700]: mean_loss=0.002784871496260166
Online_Training [340/700]: mean_loss=0.0011958200921071693
Online_Training [341/700]: mean_loss=0.0027336811181157827
Online_Training [342/700]: mean_loss=0.007975952932611108
Online_Training [343/700]: mean_loss=0.011672454420477152
Online_Training [344/700]: mean_loss=0.003347164165461436
Online_Training [345/700]: mean_loss=0.002895133919082582
Online_Training [346/700]: mean_loss=0.0066609635832719505
Online_Training [347/700]: mean_loss=0.007115809014067054
Online_Training [348/700]: mean_loss=0.00392401876160875
Online_Training [349/700]: mean_loss=0.0015120974130695686
Online_Training [350/700]: mean_loss=0.004490324878133833
Online_Training [351/700]: mean_loss=0.007239232654683292
Online_Training [352/700]: mean_loss=0.004826595832128078
Online_Training [353/700]: mean_loss=0.0052397180697880685
Online_Training [354/700]: mean_loss=0.0007978217945492361
Online_Training [355/700]: mean_loss=0.0016291193605866283
Online_Training [356/700]: mean_loss=0.0031980008352547884
Online_Training [357/700]: mean_loss=0.0020015071786474437
Online_Training [358/700]: mean_loss=0.0035627149627543986
Online_Training [359/700]: mean_loss=0.009895620285533369
Online_Training [360/700]: mean_loss=0.0021152587578399107
Online_Training [361/700]: mean_loss=0.007733183156233281
Online_Training [362/700]: mean_loss=0.14708227664232254
Online_Training [363/700]: mean_loss=0.08614445198327303
Online_Training [364/700]: mean_loss=0.011910358560271561
Online_Training [365/700]: mean_loss=0.012797444593161345
Online_Training [366/700]: mean_loss=0.03260262403637171
Online_Training [367/700]: mean_loss=0.00404047456686385
Online_Training [368/700]: mean_loss=0.004739859665278345
Online_Training [369/700]: mean_loss=0.016211177338846028
Online_Training [370/700]: mean_loss=0.007143093564081937
Online_Training [371/700]: mean_loss=0.022851215093396604
Online_Training [372/700]: mean_loss=0.004235120344674215
Online_Training [373/700]: mean_loss=0.010758552409242839
Online_Training [374/700]: mean_loss=0.06500878790393472
Online_Training [375/700]: mean_loss=0.013403486576862633
Online_Training [376/700]: mean_loss=0.007548071560449898
Online_Training [377/700]: mean_loss=0.012843788368627429
Online_Training [378/700]: mean_loss=0.01078994560521096
Online_Training [379/700]: mean_loss=0.005626813799608499
Online_Training [380/700]: mean_loss=0.005120792775414884
Online_Training [381/700]: mean_loss=0.005851329711731523
Online_Training [382/700]: mean_loss=0.006034129182808101
Online_Training [383/700]: mean_loss=0.005281542660668492
Online_Training [384/700]: mean_loss=0.005988244374748319
Online_Training [385/700]: mean_loss=0.00464149346225895
Online_Training [386/700]: mean_loss=0.009270562091842294
Online_Training [387/700]: mean_loss=0.009822284104302526
Online_Training [388/700]: mean_loss=0.07525600865483284
Online_Training [389/700]: mean_loss=0.29109851084649563
Online_Training [390/700]: mean_loss=0.07885718625038862
Online_Training [391/700]: mean_loss=0.01374591386411339
Online_Training [392/700]: mean_loss=0.016897672438062727
Online_Training [393/700]: mean_loss=0.010473284171894193
Online_Training [394/700]: mean_loss=0.003412833553738892
Online_Training [395/700]: mean_loss=0.009940071147866547
Online_Training [396/700]: mean_loss=0.025693365605548024
Online_Training [397/700]: mean_loss=0.016675441758707166
Online_Training [398/700]: mean_loss=0.009025023260619491
Online_Training [399/700]: mean_loss=0.015446687350049615
Online_Training [400/700]: mean_loss=0.002632128569530323
Online_Training [401/700]: mean_loss=0.004668666748329997
Online_Training [402/700]: mean_loss=0.003540518315276131
Online_Training [403/700]: mean_loss=0.0056866672821342945
Online_Training [404/700]: mean_loss=0.004135681665502489
Online_Training [405/700]: mean_loss=0.004813352308701724
Online_Training [406/700]: mean_loss=0.004165142250712961
Online_Training [407/700]: mean_loss=0.003539795841788873
Online_Training [408/700]: mean_loss=0.005975235137157142
Online_Training [409/700]: mean_loss=0.003282842633780092
Online_Training [410/700]: mean_loss=0.006710598710924387
Online_Training [411/700]: mean_loss=0.004837565997149795
Online_Training [412/700]: mean_loss=0.007389999693259597
Online_Training [413/700]: mean_loss=0.002791715698549524
Online_Training [414/700]: mean_loss=0.005436794250272214
Online_Training [415/700]: mean_loss=0.009743402188178152
Online_Training [416/700]: mean_loss=0.009879499790258706
Online_Training [417/700]: mean_loss=0.004616135818650946
Online_Training [418/700]: mean_loss=0.005083504453068599
Online_Training [419/700]: mean_loss=0.003476353216683492
Online_Training [420/700]: mean_loss=0.001903591473819688
Online_Training [421/700]: mean_loss=0.013170619029551744
Online_Training [422/700]: mean_loss=0.004891750781098381
Online_Training [423/700]: mean_loss=0.003440076718106866
Online_Training [424/700]: mean_loss=0.0015903848761809058
Online_Training [425/700]: mean_loss=0.006110378715675324
Online_Training [426/700]: mean_loss=0.07080514403060079
Online_Training [427/700]: mean_loss=0.08939473051577806
Online_Training [428/700]: mean_loss=0.00402522282092832
Online_Training [429/700]: mean_loss=0.007545456639491022
Online_Training [430/700]: mean_loss=0.011754277162253857
Online_Training [431/700]: mean_loss=0.031512136571109295
Online_Training [432/700]: mean_loss=0.028563867090269923
Online_Training [433/700]: mean_loss=0.008320092281792313
Online_Training [434/700]: mean_loss=0.01250002346932888
Online_Training [435/700]: mean_loss=0.008596390136517584
Online_Training [436/700]: mean_loss=0.004024942230898887
Online_Training [437/700]: mean_loss=0.00623060017824173
Online_Training [438/700]: mean_loss=0.005288640619255602
Online_Training [439/700]: mean_loss=0.003236473858123645
Online_Training [440/700]: mean_loss=0.0044575430219992995
Online_Training [441/700]: mean_loss=0.0031379307038150728
Online_Training [442/700]: mean_loss=0.005172804929316044
Online_Training [443/700]: mean_loss=0.06592083536088467
Online_Training [444/700]: mean_loss=0.0029414732998702675
Online_Training [445/700]: mean_loss=0.0036595182900782675
Online_Training [446/700]: mean_loss=0.00767654663650319
Online_Training [447/700]: mean_loss=0.006559906236361712
Online_Training [448/700]: mean_loss=0.012153892719652504
Online_Training [449/700]: mean_loss=0.004995038034394383
Online_Training [450/700]: mean_loss=0.00496581377228722
Online_Training [451/700]: mean_loss=0.010983096450218
Online_Training [452/700]: mean_loss=0.010958049213513732
Online_Training [453/700]: mean_loss=0.006646953464951366
Online_Training [454/700]: mean_loss=0.0021095404226798564
Online_Training [455/700]: mean_loss=0.007894400623627007
Online_Training [456/700]: mean_loss=0.015077603980898857
Online_Training [457/700]: mean_loss=0.005731524841394275
Online_Training [458/700]: mean_loss=0.0011821833468275145
Online_Training [459/700]: mean_loss=0.0023110566107789055
Online_Training [460/700]: mean_loss=0.02282740897499025
Online_Training [461/700]: mean_loss=0.007489468727726489
Online_Training [462/700]: mean_loss=0.07242763973772526
Online_Training [463/700]: mean_loss=0.07207918353378773
Online_Training [464/700]: mean_loss=0.012429471360519528
Online_Training [465/700]: mean_loss=0.012876823777332902
Online_Training [466/700]: mean_loss=0.004510604339884594
Online_Training [467/700]: mean_loss=0.0036592180258594453
Online_Training [468/700]: mean_loss=0.007182144559919834
Online_Training [469/700]: mean_loss=0.010384315508417785
Online_Training [470/700]: mean_loss=0.008024186652619392
Online_Training [471/700]: mean_loss=0.006199531489983201
Online_Training [472/700]: mean_loss=0.002653086994541809
Online_Training [473/700]: mean_loss=0.006443168123951182
Online_Training [474/700]: mean_loss=0.0023249173536896706
Online_Training [475/700]: mean_loss=0.0020946851873304695
Online_Training [476/700]: mean_loss=0.007708727120188996
Online_Training [477/700]: mean_loss=0.0037828054337296635
Online_Training [478/700]: mean_loss=0.006775537971407175
Online_Training [479/700]: mean_loss=0.003966308053350076
Online_Training [480/700]: mean_loss=0.0060093996580690145
Online_Training [481/700]: mean_loss=0.008101427869405597
Online_Training [482/700]: mean_loss=0.011399466777220368
Online_Training [483/700]: mean_loss=0.00859294511610642
Online_Training [484/700]: mean_loss=0.0043372989384806715
Online_Training [485/700]: mean_loss=0.0033947752381209284
Online_Training [486/700]: mean_loss=0.008034985337872058
Online_Training [487/700]: mean_loss=0.008373631222639233
Online_Training [488/700]: mean_loss=0.005449963617138565
Online_Training [489/700]: mean_loss=0.006555205502081662
Online_Training [490/700]: mean_loss=0.0033975114638451487
Online_Training [491/700]: mean_loss=0.005304450402036309
Online_Training [492/700]: mean_loss=0.008091970172245055
Online_Training [493/700]: mean_loss=0.005728740303311497
Online_Training [494/700]: mean_loss=0.08471072465181351
Online_Training [495/700]: mean_loss=0.19409577175974846
Online_Training [496/700]: mean_loss=0.006198149581905454
Online_Training [497/700]: mean_loss=0.017048429348506033
Online_Training [498/700]: mean_loss=0.02106443326920271
Online_Training [499/700]: mean_loss=0.01211731880903244
Online_Training [500/700]: mean_loss=0.009070948348380625
Online_Training [501/700]: mean_loss=0.006182289100252092
Online_Training [502/700]: mean_loss=0.006627690163441002
Online_Training [503/700]: mean_loss=0.0033333334722556174
Online_Training [504/700]: mean_loss=0.013182178139686584
Online_Training [505/700]: mean_loss=0.019316588528454304
Online_Training [506/700]: mean_loss=0.00823120679706335
Online_Training [507/700]: mean_loss=0.006186865561176091
Online_Training [508/700]: mean_loss=0.002700658544199541
Online_Training [509/700]: mean_loss=0.18398503586649895
Online_Training [510/700]: mean_loss=0.026235526660457253
Online_Training [511/700]: mean_loss=0.01267080643447116
Online_Training [512/700]: mean_loss=0.20936597138643265
Online_Training [513/700]: mean_loss=0.4724454991519451
Online_Training [514/700]: mean_loss=0.3612243980169296
Online_Training [515/700]: mean_loss=0.18828676361590624
Online_Training [516/700]: mean_loss=0.07964748051017523
Online_Training [517/700]: mean_loss=0.013979227747768164
Online_Training [518/700]: mean_loss=0.16741607710719109
Online_Training [519/700]: mean_loss=0.012155028991401196
Online_Training [520/700]: mean_loss=0.05687951389700174
Online_Training [521/700]: mean_loss=0.014162885257974267
Online_Training [522/700]: mean_loss=0.031316585605964065
Online_Training [523/700]: mean_loss=0.014401096850633621
Online_Training [524/700]: mean_loss=0.008238633105065674
Online_Training [525/700]: mean_loss=0.008945700246840715
Online_Training [526/700]: mean_loss=0.013122135540470481
Online_Training [527/700]: mean_loss=0.07707100454717875
Online_Training [528/700]: mean_loss=0.13461077213287354
Online_Training [529/700]: mean_loss=0.010985273402184248
Online_Training [530/700]: mean_loss=0.10499459691345692
Online_Training [531/700]: mean_loss=0.015540339751169086
Online_Training [532/700]: mean_loss=0.0036603602347895503
Online_Training [533/700]: mean_loss=0.06550830882042646
Online_Training [534/700]: mean_loss=0.008353208308108151
Online_Training [535/700]: mean_loss=0.0029823335935361683
Online_Training [536/700]: mean_loss=0.004467032267712057
Online_Training [537/700]: mean_loss=0.008123663428705186
Online_Training [538/700]: mean_loss=0.008805485966149718
Online_Training [539/700]: mean_loss=0.005445621674880385
Online_Training [540/700]: mean_loss=0.007669717655517161
Online_Training [541/700]: mean_loss=0.0009817060781642795
Online_Training [542/700]: mean_loss=0.007209771312773228
Online_Training [543/700]: mean_loss=0.008671905379742384
Online_Training [544/700]: mean_loss=0.001499613543273881
Online_Training [545/700]: mean_loss=0.0013207056326791644
Online_Training [546/700]: mean_loss=0.014211558387614787
Online_Training [547/700]: mean_loss=0.004839142959099263
Online_Training [548/700]: mean_loss=0.00522381899645552
Online_Training [549/700]: mean_loss=0.004374968004412949
Online_Training [550/700]: mean_loss=0.0028483744827099144
Online_Training [551/700]: mean_loss=0.0029139026592019945
Online_Training [552/700]: mean_loss=0.08151410520076752
Online_Training [553/700]: mean_loss=0.007284097082447261
Online_Training [554/700]: mean_loss=0.0012615269515663385
Online_Training [555/700]: mean_loss=0.0014679799933219329
Online_Training [556/700]: mean_loss=0.0052828488405793905
Online_Training [557/700]: mean_loss=0.004037368664285168
Online_Training [558/700]: mean_loss=0.008536412031389773
Online_Training [559/700]: mean_loss=0.001618448892259039
Online_Training [560/700]: mean_loss=0.008095669792965055
Online_Training [561/700]: mean_loss=0.0046168525295797735
Online_Training [562/700]: mean_loss=0.00411832841928117
Online_Training [563/700]: mean_loss=0.004104341409401968
Online_Training [564/700]: mean_loss=0.004123727936530486
Online_Training [565/700]: mean_loss=0.004428988031577319
Online_Training [566/700]: mean_loss=0.004289119562599808
Online_Training [567/700]: mean_loss=0.006798298622015864
Online_Training [568/700]: mean_loss=0.007127012941055
Online_Training [569/700]: mean_loss=0.00477807637071237
Online_Training [570/700]: mean_loss=0.012370644486509264
Online_Training [571/700]: mean_loss=0.07205633446574211
Online_Training [572/700]: mean_loss=0.08305403403937817
Online_Training [573/700]: mean_loss=0.003447978087933734
Online_Training [574/700]: mean_loss=0.0049432716332376
Online_Training [575/700]: mean_loss=0.008314928621985018
Online_Training [576/700]: mean_loss=0.0056943101226352155
Online_Training [577/700]: mean_loss=0.008005063864402473
Online_Training [578/700]: mean_loss=0.0031937741732690483
Online_Training [579/700]: mean_loss=0.008817254682071507
Online_Training [580/700]: mean_loss=0.0013440355032798834
Online_Training [581/700]: mean_loss=0.004693044174928218
Online_Training [582/700]: mean_loss=0.0033237689349334687
Online_Training [583/700]: mean_loss=0.002554133185185492
Online_Training [584/700]: mean_loss=0.002208304242230952
Online_Training [585/700]: mean_loss=0.005454222671687603
Online_Training [586/700]: mean_loss=0.0021549083321588114
Online_Training [587/700]: mean_loss=0.0049785159062594175
Online_Training [588/700]: mean_loss=0.005502787884324789
Online_Training [589/700]: mean_loss=0.006951341114472598
Online_Training [590/700]: mean_loss=0.00396946509135887
Online_Training [591/700]: mean_loss=0.0016281718999380246
Online_Training [592/700]: mean_loss=0.006437911419197917
Online_Training [593/700]: mean_loss=0.00275325815891847
Online_Training [594/700]: mean_loss=0.001503816107288003
Online_Training [595/700]: mean_loss=0.00883517088368535
Online_Training [596/700]: mean_loss=0.00491882354253903
Online_Training [597/700]: mean_loss=0.004606861504726112
Online_Training [598/700]: mean_loss=0.0031351057114079595
Online_Training [599/700]: mean_loss=0.002417019597487524
Online_Training [600/700]: mean_loss=0.005774775054305792
Online_Training [601/700]: mean_loss=0.009911787346936762
Online_Training [602/700]: mean_loss=0.002291725526447408
Online_Training [603/700]: mean_loss=0.0023383146908599883
Online_Training [604/700]: mean_loss=0.005908163439016789
Online_Training [605/700]: mean_loss=0.006244910240639001
Online_Training [606/700]: mean_loss=0.002621307474328205
Online_Training [607/700]: mean_loss=0.003235097974538803
Online_Training [608/700]: mean_loss=0.009279253310523927
Online_Training [609/700]: mean_loss=0.0018770246533676982
Online_Training [610/700]: mean_loss=0.0012931700330227613
Online_Training [611/700]: mean_loss=0.0784485088661313
Online_Training [612/700]: mean_loss=0.019975607050582767
Online_Training [613/700]: mean_loss=0.013715528533793986
Online_Training [614/700]: mean_loss=0.005757036036811769
Online_Training [615/700]: mean_loss=0.010235367342829704
Online_Training [616/700]: mean_loss=0.0019132871530018747
Online_Training [617/700]: mean_loss=0.004178896982921287
Online_Training [618/700]: mean_loss=0.0011063661149819382
Online_Training [619/700]: mean_loss=0.004797720001079142
Online_Training [620/700]: mean_loss=0.0016425527428509668
Online_Training [621/700]: mean_loss=0.1130345044657588
Online_Training [622/700]: mean_loss=0.019264881499111652
Online_Training [623/700]: mean_loss=0.0745711731724441
Online_Training [624/700]: mean_loss=0.16191051993519068
Online_Training [625/700]: mean_loss=0.008279941393993795
Online_Training [626/700]: mean_loss=0.03233368881046772
Online_Training [627/700]: mean_loss=0.014292444102466106
Online_Training [628/700]: mean_loss=0.020619759685359895
Online_Training [629/700]: mean_loss=0.006237121240701526
Online_Training [630/700]: mean_loss=0.005365146673284471
Online_Training [631/700]: mean_loss=0.010041434899903834
Online_Training [632/700]: mean_loss=0.005668371799401939
Online_Training [633/700]: mean_loss=0.002325744499103166
Online_Training [634/700]: mean_loss=0.004842695750994608
Online_Training [635/700]: mean_loss=0.004589745833072811
Online_Training [636/700]: mean_loss=0.01090221299091354
Online_Training [637/700]: mean_loss=0.008763261255808175
Online_Training [638/700]: mean_loss=0.0016812943358672783
Online_Training [639/700]: mean_loss=0.004903722496237606
Online_Training [640/700]: mean_loss=0.007496763457311317
Online_Training [641/700]: mean_loss=0.06788035575300455
Online_Training [642/700]: mean_loss=0.006053927063476294
Online_Training [643/700]: mean_loss=0.0023021531524136662
Online_Training [644/700]: mean_loss=0.0033419046667404473
Online_Training [645/700]: mean_loss=0.01445390417939052
Online_Training [646/700]: mean_loss=0.004199224727926776
Online_Training [647/700]: mean_loss=0.05818527564406395
Online_Training [648/700]: mean_loss=0.0022995443432591856
Online_Training [649/700]: mean_loss=0.005233670643065125
Online_Training [650/700]: mean_loss=0.005102732626255602
Online_Training [651/700]: mean_loss=0.01123584748711437
Online_Training [652/700]: mean_loss=0.0014630955265602097
Online_Training [653/700]: mean_loss=0.006778634968213737
Online_Training [654/700]: mean_loss=0.007563662715256214
Online_Training [655/700]: mean_loss=0.00209742717561312
Online_Training [656/700]: mean_loss=0.007630204374436289
Online_Training [657/700]: mean_loss=0.011112742009572685
Online_Training [658/700]: mean_loss=0.005832682451000437
Online_Training [659/700]: mean_loss=0.006223646050784737
Online_Training [660/700]: mean_loss=0.012669964227825403
Online_Training [661/700]: mean_loss=0.013082854333333671
Online_Training [662/700]: mean_loss=0.005047937796916813
Online_Training [663/700]: mean_loss=0.007269851921591908
Online_Training [664/700]: mean_loss=0.013473161699948832
Online_Training [665/700]: mean_loss=0.006299061526078731
Online_Training [666/700]: mean_loss=0.007941824791487306
Online_Training [667/700]: mean_loss=0.00920371909160167
Online_Training [668/700]: mean_loss=0.007910587009973824
Online_Training [669/700]: mean_loss=0.0060799928032793105
Online_Training [670/700]: mean_loss=0.0015382722194772214
Online_Training [671/700]: mean_loss=0.005549027118831873
Online_Training [672/700]: mean_loss=0.00391591977677308
Online_Training [673/700]: mean_loss=0.016255018766969442
Online_Training [674/700]: mean_loss=0.007223970955237746
Online_Training [675/700]: mean_loss=0.0044738629658240825
Online_Training [676/700]: mean_loss=0.0007639321629540063
Online_Training [677/700]: mean_loss=0.0022579127398785204
Online_Training [678/700]: mean_loss=0.0096057957271114
Online_Training [679/700]: mean_loss=0.004757833783514798
Online_Training [680/700]: mean_loss=0.08444149699062109
Online_Training [681/700]: mean_loss=0.003530959860654548
Online_Training [682/700]: mean_loss=0.011696488392772153
Online_Training [683/700]: mean_loss=0.001997246567043476
Online_Training [684/700]: mean_loss=0.011978544935118407
Online_Training [685/700]: mean_loss=0.008195270202122629
Online_Training [686/700]: mean_loss=0.013930787914432585
Online_Training [687/700]: mean_loss=0.0034575057070469484
Online_Training [688/700]: mean_loss=0.006059039442334324
Online_Training [689/700]: mean_loss=0.003853271249681711
Online_Training [690/700]: mean_loss=0.0027640293701551855
Online_Training [691/700]: mean_loss=0.002424296093522571
Online_Training [692/700]: mean_loss=0.0019370681693544611
Online_Training [693/700]: mean_loss=0.0021604845096589997
Online_Training [694/700]: mean_loss=0.008377690915949643
Online_Training [695/700]: mean_loss=0.006465812388341874
Online_Training [696/700]: mean_loss=0.002576632919954136
Online_Training [697/700]: mean_loss=0.00485503306845203
Online_Training [698/700]: mean_loss=0.00411787981283851
Online_Training [699/700]: mean_loss=0.0030830118048470467
Online_Training [700/700]: mean_loss=0.006080779945477843
Q_Learning [1/300]: mean_loss=0.11907435767352581
Q_Learning [2/300]: mean_loss=0.096489735879004
Q_Learning [3/300]: mean_loss=0.35334111750125885
Q_Learning [4/300]: mean_loss=0.30047332495450974
Q_Learning [5/300]: mean_loss=0.28207484260201454
Q_Learning [6/300]: mean_loss=0.12328332103788853
Q_Learning [7/300]: mean_loss=0.11486530769616365
Q_Learning [8/300]: mean_loss=0.21942880004644394
Q_Learning [9/300]: mean_loss=0.10820742230862379
Q_Learning [10/300]: mean_loss=0.08591767959296703
Q_Learning [11/300]: mean_loss=0.06684542633593082
Q_Learning [12/300]: mean_loss=0.06033724918961525
Q_Learning [13/300]: mean_loss=0.044128662906587124
Q_Learning [14/300]: mean_loss=0.1363319493830204
Q_Learning [15/300]: mean_loss=0.2226413320749998
Q_Learning [16/300]: mean_loss=0.12981677800416946
Q_Learning [17/300]: mean_loss=0.13697027787566185
Q_Learning [18/300]: mean_loss=0.1842855978757143
Q_Learning [19/300]: mean_loss=0.12088365573436022
Q_Learning [20/300]: mean_loss=0.10561706498265266
Q_Learning [21/300]: mean_loss=0.16685502603650093
Q_Learning [22/300]: mean_loss=0.1279439451172948
Q_Learning [23/300]: mean_loss=0.10521352756768465
Q_Learning [24/300]: mean_loss=0.05690024746581912
Q_Learning [25/300]: mean_loss=0.11339136958122253
Q_Learning [26/300]: mean_loss=0.07685326598584652
Q_Learning [27/300]: mean_loss=0.06509234104305506
Q_Learning [28/300]: mean_loss=0.05509530706331134
Q_Learning [29/300]: mean_loss=0.09618321806192398
Q_Learning [30/300]: mean_loss=0.03424065373837948
Q_Learning [31/300]: mean_loss=0.14025763608515263
Q_Learning [32/300]: mean_loss=0.015757657820358872
Q_Learning [33/300]: mean_loss=0.016791223781183362
Q_Learning [34/300]: mean_loss=0.10775793343782425
Q_Learning [35/300]: mean_loss=0.006714613438816741
Q_Learning [36/300]: mean_loss=0.12573078647255898
Q_Learning [37/300]: mean_loss=0.09241601172834635
Q_Learning [38/300]: mean_loss=0.06747271586209536
Q_Learning [39/300]: mean_loss=0.06365377875044942
Q_Learning [40/300]: mean_loss=0.0470883478410542
Q_Learning [41/300]: mean_loss=0.045545962173491716
Q_Learning [42/300]: mean_loss=0.03264947677962482
Q_Learning [43/300]: mean_loss=0.04205933632329106
Q_Learning [44/300]: mean_loss=0.015885688131675124
Q_Learning [45/300]: mean_loss=0.05098234489560127
Q_Learning [46/300]: mean_loss=0.052591000217944384
Q_Learning [47/300]: mean_loss=0.126219448633492
Q_Learning [48/300]: mean_loss=0.16843233816325665
Q_Learning [49/300]: mean_loss=0.025476956856437027
Q_Learning [50/300]: mean_loss=0.04043641500174999
Q_Learning [51/300]: mean_loss=0.03367356793023646
Q_Learning [52/300]: mean_loss=0.012802397483028471
Q_Learning [53/300]: mean_loss=0.07010180503129959
Q_Learning [54/300]: mean_loss=0.26993197202682495
Q_Learning [55/300]: mean_loss=0.0627828985452652
Q_Learning [56/300]: mean_loss=0.028895366471260786
Q_Learning [57/300]: mean_loss=0.026805379427969456
Q_Learning [58/300]: mean_loss=0.009170298522803932
Q_Learning [59/300]: mean_loss=0.09118765592575073
Q_Learning [60/300]: mean_loss=0.019457767251878977
Q_Learning [61/300]: mean_loss=0.021494514541700482
Q_Learning [62/300]: mean_loss=0.016792879439890385
Q_Learning [63/300]: mean_loss=0.0035407413088250905
Q_Learning [64/300]: mean_loss=0.0021314647747203708
Q_Learning [65/300]: mean_loss=0.010638227802701294
Q_Learning [66/300]: mean_loss=0.0036018971004523337
Q_Learning [67/300]: mean_loss=0.0023515516077168286
Q_Learning [68/300]: mean_loss=0.12330261524766684
Q_Learning [69/300]: mean_loss=0.011198483523912728
Q_Learning [70/300]: mean_loss=0.005259612284135073
Q_Learning [71/300]: mean_loss=0.0025280468398705125
Q_Learning [72/300]: mean_loss=0.0066958736861124635
Q_Learning [73/300]: mean_loss=0.009165100025711581
Q_Learning [74/300]: mean_loss=0.0027159764867974445
Q_Learning [75/300]: mean_loss=0.005898779782000929
Q_Learning [76/300]: mean_loss=0.01325533026829362
Q_Learning [77/300]: mean_loss=0.006122373772086576
Q_Learning [78/300]: mean_loss=0.005300536286085844
Q_Learning [79/300]: mean_loss=0.030185913434252143
Q_Learning [80/300]: mean_loss=0.009736989624798298
Q_Learning [81/300]: mean_loss=0.004367534798802808
Q_Learning [82/300]: mean_loss=0.021927172783762217
Q_Learning [83/300]: mean_loss=0.021034260746091604
Q_Learning [84/300]: mean_loss=0.0033003719872795045
Q_Learning [85/300]: mean_loss=0.01240143203176558
Q_Learning [86/300]: mean_loss=0.013103593955747783
Q_Learning [87/300]: mean_loss=0.005682838964276016
Q_Learning [88/300]: mean_loss=0.012128140311688185
Q_Learning [89/300]: mean_loss=0.0041900857468135655
Q_Learning [90/300]: mean_loss=0.01253398205153644
Q_Learning [91/300]: mean_loss=0.01364521577488631
Q_Learning [92/300]: mean_loss=0.007661714742425829
Q_Learning [93/300]: mean_loss=0.0030524608737323433
Q_Learning [94/300]: mean_loss=0.012296607717871666
Q_Learning [95/300]: mean_loss=0.00200116602354683
Q_Learning [96/300]: mean_loss=0.0058323044795542955
Q_Learning [97/300]: mean_loss=0.009350422653369606
Q_Learning [98/300]: mean_loss=0.0037241219251882285
Q_Learning [99/300]: mean_loss=0.0050901976064778864
Q_Learning [100/300]: mean_loss=0.0012780706529156305
Q_Learning [101/300]: mean_loss=0.0024448945478070527
Q_Learning [102/300]: mean_loss=0.012858632835559547
Q_Learning [103/300]: mean_loss=0.0062419152818620205
Q_Learning [104/300]: mean_loss=0.0021255285246297717
Q_Learning [105/300]: mean_loss=0.033212955109775066
Q_Learning [106/300]: mean_loss=0.029644136782735586
Q_Learning [107/300]: mean_loss=0.003358359361300245
Q_Learning [108/300]: mean_loss=0.012552600121125579
Q_Learning [109/300]: mean_loss=0.002860632142983377
Q_Learning [110/300]: mean_loss=0.004028377530630678
Q_Learning [111/300]: mean_loss=0.003243611950892955
Q_Learning [112/300]: mean_loss=0.004159851639997214
Q_Learning [113/300]: mean_loss=0.007353855122346431
Q_Learning [114/300]: mean_loss=0.00495009683072567
Q_Learning [115/300]: mean_loss=0.01606957777403295
Q_Learning [116/300]: mean_loss=0.002742985525401309
Q_Learning [117/300]: mean_loss=0.002847010619007051
Q_Learning [118/300]: mean_loss=0.0024051837681327015
Q_Learning [119/300]: mean_loss=0.002923849126091227
Q_Learning [120/300]: mean_loss=0.009755973413120955
Q_Learning [121/300]: mean_loss=0.007526024826802313
Q_Learning [122/300]: mean_loss=0.011602931073866785
Q_Learning [123/300]: mean_loss=0.0009794625875656493
Q_Learning [124/300]: mean_loss=0.006836476037278771
Q_Learning [125/300]: mean_loss=0.003943992065615021
Q_Learning [126/300]: mean_loss=0.0020847583218710497
Q_Learning [127/300]: mean_loss=0.004610624979250133
Q_Learning [128/300]: mean_loss=0.00838379783090204
Q_Learning [129/300]: mean_loss=0.007759953150525689
Q_Learning [130/300]: mean_loss=0.00410347554134205
Q_Learning [131/300]: mean_loss=0.004471273074159399
Q_Learning [132/300]: mean_loss=0.0074388218054082245
Q_Learning [133/300]: mean_loss=0.0038418622280005366
Q_Learning [134/300]: mean_loss=0.012933705875184387
Q_Learning [135/300]: mean_loss=0.0036727193801198155
Q_Learning [136/300]: mean_loss=0.003850340872304514
Q_Learning [137/300]: mean_loss=0.004671593720559031
Q_Learning [138/300]: mean_loss=0.0021076643461128697
Q_Learning [139/300]: mean_loss=0.0016838606679812074
Q_Learning [140/300]: mean_loss=0.003890478517860174
Q_Learning [141/300]: mean_loss=0.0020331104315118864
Q_Learning [142/300]: mean_loss=0.004576081468258053
Q_Learning [143/300]: mean_loss=0.023745222948491573
Q_Learning [144/300]: mean_loss=0.0072642753075342625
Q_Learning [145/300]: mean_loss=0.06846780981868505
Q_Learning [146/300]: mean_loss=0.12874070182442665
Q_Learning [147/300]: mean_loss=0.017641610116697848
Q_Learning [148/300]: mean_loss=0.014198816032148898
Q_Learning [149/300]: mean_loss=0.012942297500558197
Q_Learning [150/300]: mean_loss=0.1074962173588574
Q_Learning [151/300]: mean_loss=0.2759343720972538
Q_Learning [152/300]: mean_loss=0.014018320594914258
Q_Learning [153/300]: mean_loss=0.01427203242201358
Q_Learning [154/300]: mean_loss=0.007690112164709717
Q_Learning [155/300]: mean_loss=0.039645338198170066
Q_Learning [156/300]: mean_loss=0.01636414579115808
Q_Learning [157/300]: mean_loss=0.004041780135594308
Q_Learning [158/300]: mean_loss=0.017817572806961834
Q_Learning [159/300]: mean_loss=0.008145551779307425
Q_Learning [160/300]: mean_loss=0.012777102529071271
Q_Learning [161/300]: mean_loss=0.0035130779433529824
Q_Learning [162/300]: mean_loss=0.05054446030408144
Q_Learning [163/300]: mean_loss=0.10944303125143051
Q_Learning [164/300]: mean_loss=0.012183943530544639
Q_Learning [165/300]: mean_loss=0.006050022901035845
Q_Learning [166/300]: mean_loss=0.014237382332794368
Q_Learning [167/300]: mean_loss=0.004364367923699319
Q_Learning [168/300]: mean_loss=0.007092938350979239
Q_Learning [169/300]: mean_loss=0.002272580415592529
Q_Learning [170/300]: mean_loss=0.0051870731404051185
Q_Learning [171/300]: mean_loss=0.016718993661925197
Q_Learning [172/300]: mean_loss=0.03675292991101742
Q_Learning [173/300]: mean_loss=0.03177202888764441
Q_Learning [174/300]: mean_loss=0.020846464671194553
Q_Learning [175/300]: mean_loss=0.016741009894758463
Q_Learning [176/300]: mean_loss=0.0031355287064798176
Q_Learning [177/300]: mean_loss=0.005367075587855652
Q_Learning [178/300]: mean_loss=0.004144071834161878
Q_Learning [179/300]: mean_loss=0.005097358371131122
Q_Learning [180/300]: mean_loss=0.005871022527571768
Q_Learning [181/300]: mean_loss=0.007024090911727399
Q_Learning [182/300]: mean_loss=0.001370817728457041
Q_Learning [183/300]: mean_loss=0.005866806139238179
Q_Learning [184/300]: mean_loss=0.0038330518000293523
Q_Learning [185/300]: mean_loss=0.0030404285062104464
Q_Learning [186/300]: mean_loss=0.0034602170635480434
Q_Learning [187/300]: mean_loss=0.0017611881776247174
Q_Learning [188/300]: mean_loss=0.08436852879822254
Q_Learning [189/300]: mean_loss=0.08807533234357834
Q_Learning [190/300]: mean_loss=0.018798787146806717
Q_Learning [191/300]: mean_loss=0.016086929943412542
Q_Learning [192/300]: mean_loss=0.005691940488759428
Q_Learning [193/300]: mean_loss=0.009177978499792516
Q_Learning [194/300]: mean_loss=0.012430790346115828
Q_Learning [195/300]: mean_loss=0.005460737447720021
Q_Learning [196/300]: mean_loss=0.005123404727783054
Q_Learning [197/300]: mean_loss=0.0038119356613606215
Q_Learning [198/300]: mean_loss=0.008015444909688085
Q_Learning [199/300]: mean_loss=0.011687038582749665
Q_Learning [200/300]: mean_loss=0.006599697400815785
Q_Learning [201/300]: mean_loss=0.011371188680641353
Q_Learning [202/300]: mean_loss=0.005046908278018236
Q_Learning [203/300]: mean_loss=0.0014231177483452484
Q_Learning [204/300]: mean_loss=0.006541434035170823
Q_Learning [205/300]: mean_loss=0.0038400958001147956
Q_Learning [206/300]: mean_loss=0.006823850388173014
Q_Learning [207/300]: mean_loss=0.006383277475833893
Q_Learning [208/300]: mean_loss=0.004059658269397914
Q_Learning [209/300]: mean_loss=0.006763885670807213
Q_Learning [210/300]: mean_loss=0.009350141044706106
Q_Learning [211/300]: mean_loss=0.004523185372818261
Q_Learning [212/300]: mean_loss=0.003231796290492639
Q_Learning [213/300]: mean_loss=0.005279806267935783
Q_Learning [214/300]: mean_loss=0.004409104352816939
Q_Learning [215/300]: mean_loss=0.007120527210645378
Q_Learning [216/300]: mean_loss=0.0012281378731131554
Q_Learning [217/300]: mean_loss=0.004142155317822471
Q_Learning [218/300]: mean_loss=0.003304155805381015
Q_Learning [219/300]: mean_loss=0.007074187626130879
Q_Learning [220/300]: mean_loss=0.008874333172570914
Q_Learning [221/300]: mean_loss=0.0073544225306250155
Q_Learning [222/300]: mean_loss=0.0024919758434407413
Q_Learning [223/300]: mean_loss=0.00073977201100206
Q_Learning [224/300]: mean_loss=0.004088401678018272
Q_Learning [225/300]: mean_loss=0.0010443356150062755
Q_Learning [226/300]: mean_loss=0.0008447150030406192
Q_Learning [227/300]: mean_loss=0.009338585659861565
Q_Learning [228/300]: mean_loss=0.006887835101224482
Q_Learning [229/300]: mean_loss=0.004365614004200324
Q_Learning [230/300]: mean_loss=0.003236906515667215
Q_Learning [231/300]: mean_loss=0.002275479811942205
Q_Learning [232/300]: mean_loss=0.003544746054103598
Q_Learning [233/300]: mean_loss=0.004722857265733182
Q_Learning [234/300]: mean_loss=0.005084672477096319
Q_Learning [235/300]: mean_loss=0.006224404147360474
Q_Learning [236/300]: mean_loss=0.010972794203553349
Q_Learning [237/300]: mean_loss=0.002840810368070379
Q_Learning [238/300]: mean_loss=0.00424495933111757
Q_Learning [239/300]: mean_loss=0.0016463996580569074
Q_Learning [240/300]: mean_loss=0.006297383981291205
Q_Learning [241/300]: mean_loss=0.01093600643798709
Q_Learning [242/300]: mean_loss=0.00499390866025351
Q_Learning [243/300]: mean_loss=0.007148625503759831
Q_Learning [244/300]: mean_loss=0.00500363003811799
Q_Learning [245/300]: mean_loss=0.003316778689622879
Q_Learning [246/300]: mean_loss=0.0048864711716305465
Q_Learning [247/300]: mean_loss=0.005035832116845995
Q_Learning [248/300]: mean_loss=0.018968239659443498
Q_Learning [249/300]: mean_loss=0.014132340671494603
Q_Learning [250/300]: mean_loss=0.0056468281836714596
Q_Learning [251/300]: mean_loss=0.015014370554126799
Q_Learning [252/300]: mean_loss=0.008022640249691904
Q_Learning [253/300]: mean_loss=0.0017526388546684757
Q_Learning [254/300]: mean_loss=0.0018682772933971137
Q_Learning [255/300]: mean_loss=0.0024295045586768538
Q_Learning [256/300]: mean_loss=0.07982838619500399
Q_Learning [257/300]: mean_loss=0.09070150274783373
Q_Learning [258/300]: mean_loss=0.011758969107177109
Q_Learning [259/300]: mean_loss=0.0042212389525957406
Q_Learning [260/300]: mean_loss=0.003833798080449924
Q_Learning [261/300]: mean_loss=0.02045788208488375
Q_Learning [262/300]: mean_loss=0.02767984929960221
Q_Learning [263/300]: mean_loss=0.029665934445802122
Q_Learning [264/300]: mean_loss=0.009111550287343562
Q_Learning [265/300]: mean_loss=0.022455886792158708
Q_Learning [266/300]: mean_loss=0.007582823163829744
Q_Learning [267/300]: mean_loss=0.027548975951503962
Q_Learning [268/300]: mean_loss=0.008824848686344922
Q_Learning [269/300]: mean_loss=0.009358464158140123
Q_Learning [270/300]: mean_loss=0.022952807717956603
Q_Learning [271/300]: mean_loss=0.02646957989782095
Q_Learning [272/300]: mean_loss=0.0067039161222055554
Q_Learning [273/300]: mean_loss=0.00443027721485123
Q_Learning [274/300]: mean_loss=0.0390249754418619
Q_Learning [275/300]: mean_loss=0.20301641710102558
Q_Learning [276/300]: mean_loss=0.06106451619416475
Q_Learning [277/300]: mean_loss=0.011457737651653588
Q_Learning [278/300]: mean_loss=0.014914359198883176
Q_Learning [279/300]: mean_loss=0.00383464532205835
Q_Learning [280/300]: mean_loss=0.009296578471548855
Q_Learning [281/300]: mean_loss=0.004825969925150275
Q_Learning [282/300]: mean_loss=0.019830335048027337
Q_Learning [283/300]: mean_loss=0.013190601486712694
Q_Learning [284/300]: mean_loss=0.009641437151003629
Q_Learning [285/300]: mean_loss=0.012586377677507699
Q_Learning [286/300]: mean_loss=0.008676918514538556
Q_Learning [287/300]: mean_loss=0.0040736277878750116
Q_Learning [288/300]: mean_loss=0.0025878686719806865
Q_Learning [289/300]: mean_loss=0.004723862803075463
Q_Learning [290/300]: mean_loss=0.002552719379309565
Q_Learning [291/300]: mean_loss=0.004749484302010387
Q_Learning [292/300]: mean_loss=0.0018916812696261331
Q_Learning [293/300]: mean_loss=0.003961229958804324
Q_Learning [294/300]: mean_loss=0.0031781205616425723
Q_Learning [295/300]: mean_loss=0.0018802369595505297
Q_Learning [296/300]: mean_loss=0.18324270471930504
Q_Learning [297/300]: mean_loss=0.07644595485180616
Q_Learning [298/300]: mean_loss=0.012347111129201949
Q_Learning [299/300]: mean_loss=0.014170448645018041
Q_Learning [300/300]: mean_loss=0.00772542116465047
Number of Samples after Autoencoder testing: 300
First Spike after testing: [0.9066505 1.4960588]
[1, 2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 0, 2, 1, 1, 1, 2, 0, 1, 2, 0, 0, 2, 0, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 1, 1, 1, 2, 2, 2, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 1, 2, 2, 0, 1, 2, 0, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 1, 2, 1, 2, 0, 2, 1, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 0, 2, 2, 2, 0, 1, 2, 0, 2, 1, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 1, 0, 1, 0, 1, 2, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 0, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 2, 2]
[0, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 2, 1, 0, 0, 0, 1, 2, 0, 1, 2, 2, 1, 2, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 1, 1, 1, 0, 2, 1, 2, 1, 0, 0, 0, 1, 1, 1, 0, 2, 1, 1, 1, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 1, 1, 0, 2, 1, 2, 2, 2, 0, 1, 2, 1, 0, 1, 1, 2, 0, 1, 2, 1, 2, 1, 0, 2, 2, 0, 2, 2, 2, 1, 3, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 1, 2, 0, 2, 1, 2, 2, 0, 2, 2, 1, 3, 2, 2, 0, 3, 0, 1, 2, 3, 0, 3, 2, 3, 2, 3, 0, 2, 0, 2, 0, 0, 3, 2, 0, 3, 0, 3, 0, 3, 3, 3, 3, 0, 0, 0, 3, 2, 3, 3, 3, 2, 0, 3, 2, 3, 0, 0, 0, 2, 0, 3, 2, 3, 2, 3, 3, 3, 2, 2, 0, 0, 2, 1, 2, 0, 0, 2, 0, 0, 3, 3, 3, 3, 2, 3, 2, 2, 2, 1, 3, 3, 0, 3, 3, 3, 0, 2, 0, 2, 0, 3, 2, 3, 0, 0, 3, 2, 0, 3, 0, 2, 0, 3, 2, 2, 3, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 0, 0, 2, 0, 3, 2, 3, 3, 3, 0, 2, 3, 3, 2, 3, 3, 2, 0, 2, 0, 0, 3, 3, 2, 4, 3, 0, 0, 3, 2, 3, 0, 3, 3, 2, 2, 0, 3, 2, 3, 3]
Centroids: [[-0.48250255, -1.3649493], [0.73671, 1.6678119], [-3.8851337, 0.89774334]]
Centroids: [[0.8126578, 1.6477145], [-3.9302692, 1.5524328], [-0.45022777, -1.3755124], [-3.8493588, 0.30427122], [-0.7184055, 3.2139235]]
Contingency Matrix: 
[[ 1  0 97  1  0]
 [86  1  1  0  1]
 [ 0 53  0 59  0]]
[[1, 0, 97, 1, 0], [86, 1, 1, 0, 1], [0, 53, 0, 59, 0]]
[[1, 0, 97, 1, 0], [86, 1, 1, 0, 1], [0, 53, 0, 59, 0]]
[0, 1, 2, 3, 4]
[[-1, -1, -1, -1, -1], [86, 1, -1, 0, 1], [0, 53, -1, 59, 0]]
[[-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, 53, -1, 59, 0]]
[[-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1]]
Match_Labels: {0: 2, 1: 0, 2: 3}
New Contingency Matrix: 
[[97  1  1  0  0]
 [ 1 86  0  1  1]
 [ 0  0 59 53  0]]
New Clustered Label Sequence: [2, 0, 3, 1, 4]
Diagonal_Elements: [97, 86, 59], Sum: 242
All_Elements: [97, 1, 1, 0, 0, 1, 86, 0, 1, 1, 0, 0, 59, 53, 0], Sum: 300
Accuracy: 0.8066666666666666
