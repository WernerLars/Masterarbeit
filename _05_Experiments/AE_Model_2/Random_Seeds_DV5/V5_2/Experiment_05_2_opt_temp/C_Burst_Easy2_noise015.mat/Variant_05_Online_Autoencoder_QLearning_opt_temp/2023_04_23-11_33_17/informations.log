Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_2_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_2_opt_temp/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_04_23-11_33_17
Punishment_Coefficient: 0.9
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FFF38B3630>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.16264784336090088
Online_Training [2/700]: mean_loss=0.20413810946047306
Online_Training [3/700]: mean_loss=0.17004199884831905
Online_Training [4/700]: mean_loss=0.0608846303075552
Online_Training [5/700]: mean_loss=0.24612360075116158
Online_Training [6/700]: mean_loss=0.09035573992878199
Online_Training [7/700]: mean_loss=0.09589536115527153
Online_Training [8/700]: mean_loss=0.07429037615656853
Online_Training [9/700]: mean_loss=0.16000030003488064
Online_Training [10/700]: mean_loss=0.1419121939688921
Online_Training [11/700]: mean_loss=0.06636008620262146
Online_Training [12/700]: mean_loss=0.07420600112527609
Online_Training [13/700]: mean_loss=0.09389601647853851
Online_Training [14/700]: mean_loss=0.05419966345652938
Online_Training [15/700]: mean_loss=0.05974000692367554
Online_Training [16/700]: mean_loss=0.10270926728844643
Online_Training [17/700]: mean_loss=0.08370819129049778
Online_Training [18/700]: mean_loss=0.048952892888337374
Online_Training [19/700]: mean_loss=0.021962576545774937
Online_Training [20/700]: mean_loss=0.07540295738726854
Online_Training [21/700]: mean_loss=0.13476995564997196
Online_Training [22/700]: mean_loss=0.013088079867884517
Online_Training [23/700]: mean_loss=0.021275010891258717
Online_Training [24/700]: mean_loss=0.029920936562120914
Online_Training [25/700]: mean_loss=0.042122588492929935
Online_Training [26/700]: mean_loss=0.04845794849097729
Online_Training [27/700]: mean_loss=0.05526145175099373
Online_Training [28/700]: mean_loss=0.029589318437501788
Online_Training [29/700]: mean_loss=0.04143963381648064
Online_Training [30/700]: mean_loss=0.029061235720291734
Online_Training [31/700]: mean_loss=0.025775477988645434
Online_Training [32/700]: mean_loss=0.04448508098721504
Online_Training [33/700]: mean_loss=0.025718863122165203
Online_Training [34/700]: mean_loss=0.08219917677342892
Online_Training [35/700]: mean_loss=0.05376569228246808
Online_Training [36/700]: mean_loss=0.055147222708910704
Online_Training [37/700]: mean_loss=0.04635129636153579
Online_Training [38/700]: mean_loss=0.038076940923929214
Online_Training [39/700]: mean_loss=0.0412609726190567
Online_Training [40/700]: mean_loss=0.03048115107230842
Online_Training [41/700]: mean_loss=0.027208066079765558
Online_Training [42/700]: mean_loss=0.0558471092954278
Online_Training [43/700]: mean_loss=0.04851712239906192
Online_Training [44/700]: mean_loss=0.051969405729323626
Online_Training [45/700]: mean_loss=0.051492493599653244
Online_Training [46/700]: mean_loss=0.031047218712046742
Online_Training [47/700]: mean_loss=0.032226790208369493
Online_Training [48/700]: mean_loss=0.06755777727812529
Online_Training [49/700]: mean_loss=0.012013637693598866
Online_Training [50/700]: mean_loss=0.027006467571482062
Online_Training [51/700]: mean_loss=0.016545020160265267
Online_Training [52/700]: mean_loss=0.053549572825431824
Online_Training [53/700]: mean_loss=0.019697218667715788
Online_Training [54/700]: mean_loss=0.04545081267133355
Online_Training [55/700]: mean_loss=0.017374754417687654
Online_Training [56/700]: mean_loss=0.03887828951701522
Online_Training [57/700]: mean_loss=0.09160014986991882
Online_Training [58/700]: mean_loss=0.10703600849956274
Online_Training [59/700]: mean_loss=0.08104812493547797
Online_Training [60/700]: mean_loss=0.04152008472010493
Online_Training [61/700]: mean_loss=0.03755480796098709
Online_Training [62/700]: mean_loss=0.08207547944039106
Online_Training [63/700]: mean_loss=0.048702419735491276
Online_Training [64/700]: mean_loss=0.004204079858027399
Online_Training [65/700]: mean_loss=0.05774143524467945
Online_Training [66/700]: mean_loss=0.04099880252033472
Online_Training [67/700]: mean_loss=0.07151070050895214
Online_Training [68/700]: mean_loss=0.02138611674308777
Online_Training [69/700]: mean_loss=0.03216519928537309
Online_Training [70/700]: mean_loss=0.0392188117839396
Online_Training [71/700]: mean_loss=0.07084459345787764
Online_Training [72/700]: mean_loss=0.0773323941975832
Online_Training [73/700]: mean_loss=0.040844233240932226
Online_Training [74/700]: mean_loss=0.03910905309021473
Online_Training [75/700]: mean_loss=0.024849759647622705
Online_Training [76/700]: mean_loss=0.01653158839326352
Online_Training [77/700]: mean_loss=0.04333962732926011
Online_Training [78/700]: mean_loss=0.019161483505740762
Online_Training [79/700]: mean_loss=0.04400681611150503
Online_Training [80/700]: mean_loss=0.03732166951522231
Online_Training [81/700]: mean_loss=0.017978958087041974
Online_Training [82/700]: mean_loss=0.031173120019957423
Online_Training [83/700]: mean_loss=0.02877896325662732
Online_Training [84/700]: mean_loss=0.03308206098154187
Online_Training [85/700]: mean_loss=0.02662280132062733
Online_Training [86/700]: mean_loss=0.0313180279918015
Online_Training [87/700]: mean_loss=0.01960895722731948
Online_Training [88/700]: mean_loss=0.02703342866152525
Online_Training [89/700]: mean_loss=0.043244974222034216
Online_Training [90/700]: mean_loss=0.017688302090391517
Online_Training [91/700]: mean_loss=0.033062195871025324
Online_Training [92/700]: mean_loss=0.03641455341130495
Online_Training [93/700]: mean_loss=0.024588311556726694
Online_Training [94/700]: mean_loss=0.039199996273964643
Online_Training [95/700]: mean_loss=0.03216742258518934
Online_Training [96/700]: mean_loss=0.022409539436921477
Online_Training [97/700]: mean_loss=0.04623768338933587
Online_Training [98/700]: mean_loss=0.04693102743476629
Online_Training [99/700]: mean_loss=0.023302112938836217
Online_Training [100/700]: mean_loss=0.04156118491664529
Online_Training [101/700]: mean_loss=0.01760395138990134
Online_Training [102/700]: mean_loss=0.05966134276241064
Online_Training [103/700]: mean_loss=0.040789314080029726
Online_Training [104/700]: mean_loss=0.04010317847132683
Online_Training [105/700]: mean_loss=0.03807738143950701
Online_Training [106/700]: mean_loss=0.01781845581717789
Online_Training [107/700]: mean_loss=0.017907104222103953
Online_Training [108/700]: mean_loss=0.03155229822732508
Online_Training [109/700]: mean_loss=0.029890415025874972
Online_Training [110/700]: mean_loss=0.025555561063811183
Online_Training [111/700]: mean_loss=0.029925005976110697
Online_Training [112/700]: mean_loss=0.165525134652853
Online_Training [113/700]: mean_loss=0.021863429341465235
Online_Training [114/700]: mean_loss=0.0385970096103847
Online_Training [115/700]: mean_loss=0.036524626426398754
Online_Training [116/700]: mean_loss=0.021473679691553116
Online_Training [117/700]: mean_loss=0.053830234333872795
Online_Training [118/700]: mean_loss=0.04833467956632376
Online_Training [119/700]: mean_loss=0.13998190686106682
Online_Training [120/700]: mean_loss=0.06509446445852518
Online_Training [121/700]: mean_loss=0.05787305487319827
Online_Training [122/700]: mean_loss=0.06785923615098
Online_Training [123/700]: mean_loss=0.02766381879337132
Online_Training [124/700]: mean_loss=0.010363029781728983
Online_Training [125/700]: mean_loss=0.05748675903305411
Online_Training [126/700]: mean_loss=0.04586863378062844
Online_Training [127/700]: mean_loss=0.05554356751963496
Online_Training [128/700]: mean_loss=0.030517212580889463
Online_Training [129/700]: mean_loss=0.036144344601780176
Online_Training [130/700]: mean_loss=0.024241985753178596
Online_Training [131/700]: mean_loss=0.024957029381766915
Online_Training [132/700]: mean_loss=0.01876693218946457
Online_Training [133/700]: mean_loss=0.02499404503032565
Online_Training [134/700]: mean_loss=0.021829168079420924
Online_Training [135/700]: mean_loss=0.11812127660959959
Online_Training [136/700]: mean_loss=0.02115835971198976
Online_Training [137/700]: mean_loss=0.02249322389252484
Online_Training [138/700]: mean_loss=0.014445576118305326
Online_Training [139/700]: mean_loss=0.01899545476771891
Online_Training [140/700]: mean_loss=0.03467492526397109
Online_Training [141/700]: mean_loss=0.028087185928598046
Online_Training [142/700]: mean_loss=0.016365113318897784
Online_Training [143/700]: mean_loss=0.021082533756271005
Online_Training [144/700]: mean_loss=0.013260210282169282
Online_Training [145/700]: mean_loss=0.04474802454933524
Online_Training [146/700]: mean_loss=0.019584009889513254
Online_Training [147/700]: mean_loss=0.0164118530228734
Online_Training [148/700]: mean_loss=0.040236583445221186
Online_Training [149/700]: mean_loss=0.0931989885866642
Online_Training [150/700]: mean_loss=0.056710471864789724
Online_Training [151/700]: mean_loss=0.026741107692942023
Online_Training [152/700]: mean_loss=0.017363689374178648
Online_Training [153/700]: mean_loss=0.02099625999107957
Online_Training [154/700]: mean_loss=0.020841113291680813
Online_Training [155/700]: mean_loss=0.009479178988840431
Online_Training [156/700]: mean_loss=0.018980656284838915
Online_Training [157/700]: mean_loss=0.13296423386782408
Online_Training [158/700]: mean_loss=0.0048085153684951365
Online_Training [159/700]: mean_loss=0.020402560010552406
Online_Training [160/700]: mean_loss=0.02219256479293108
Online_Training [161/700]: mean_loss=0.027959371684119105
Online_Training [162/700]: mean_loss=0.016089355223812163
Online_Training [163/700]: mean_loss=0.0584358568303287
Online_Training [164/700]: mean_loss=0.016290170955471694
Online_Training [165/700]: mean_loss=0.008020593435503542
Online_Training [166/700]: mean_loss=0.014533175039105117
Online_Training [167/700]: mean_loss=0.04110714700073004
Online_Training [168/700]: mean_loss=0.035193323623389006
Online_Training [169/700]: mean_loss=0.059484603349119425
Online_Training [170/700]: mean_loss=0.17427130788564682
Online_Training [171/700]: mean_loss=0.015168211073614657
Online_Training [172/700]: mean_loss=0.01310192490927875
Online_Training [173/700]: mean_loss=0.023101210594177246
Online_Training [174/700]: mean_loss=0.012918855529278517
Online_Training [175/700]: mean_loss=0.012113635428249836
Online_Training [176/700]: mean_loss=0.0070496267871931195
Online_Training [177/700]: mean_loss=0.03412280301563442
Online_Training [178/700]: mean_loss=0.0412867134436965
Online_Training [179/700]: mean_loss=0.0159321321407333
Online_Training [180/700]: mean_loss=0.024105531629174948
Online_Training [181/700]: mean_loss=0.02881419425830245
Online_Training [182/700]: mean_loss=0.03358948137611151
Online_Training [183/700]: mean_loss=0.010976869729347527
Online_Training [184/700]: mean_loss=0.005309066269546747
Online_Training [185/700]: mean_loss=0.03512396407313645
Online_Training [186/700]: mean_loss=0.03420307161286473
Online_Training [187/700]: mean_loss=0.03438466042280197
Online_Training [188/700]: mean_loss=0.02425728947855532
Online_Training [189/700]: mean_loss=0.056927456986159086
Online_Training [190/700]: mean_loss=0.028967262944206595
Online_Training [191/700]: mean_loss=0.15233591571450233
Online_Training [192/700]: mean_loss=0.023775042966008186
Online_Training [193/700]: mean_loss=0.02179206325672567
Online_Training [194/700]: mean_loss=0.017301160492934287
Online_Training [195/700]: mean_loss=0.024028092389926314
Online_Training [196/700]: mean_loss=0.011684472439810634
Online_Training [197/700]: mean_loss=0.03956278646364808
Online_Training [198/700]: mean_loss=0.017303486703895032
Online_Training [199/700]: mean_loss=0.09040744323283434
Online_Training [200/700]: mean_loss=0.020182506181299686
Online_Training [201/700]: mean_loss=0.039040328934788704
Online_Training [202/700]: mean_loss=0.01577087980695069
Online_Training [203/700]: mean_loss=0.011702144285663962
Online_Training [204/700]: mean_loss=0.011837046244181693
Online_Training [205/700]: mean_loss=0.06656076852232218
Online_Training [206/700]: mean_loss=0.01965326303616166
Online_Training [207/700]: mean_loss=0.043457296676933765
Online_Training [208/700]: mean_loss=0.0408046287484467
Online_Training [209/700]: mean_loss=0.051674663089215755
Online_Training [210/700]: mean_loss=0.030365135986357927
Online_Training [211/700]: mean_loss=0.02027169638313353
Online_Training [212/700]: mean_loss=0.0907408082857728
Online_Training [213/700]: mean_loss=0.043582063633948565
Online_Training [214/700]: mean_loss=0.019908152520656586
Online_Training [215/700]: mean_loss=0.03716073790565133
Online_Training [216/700]: mean_loss=0.030512933852151036
Online_Training [217/700]: mean_loss=0.01231464243028313
Online_Training [218/700]: mean_loss=0.010554231004789472
Online_Training [219/700]: mean_loss=0.04966907715424895
Online_Training [220/700]: mean_loss=0.01363180042244494
Online_Training [221/700]: mean_loss=0.03221927653066814
Online_Training [222/700]: mean_loss=0.022274567745625973
Online_Training [223/700]: mean_loss=0.03358868882060051
Online_Training [224/700]: mean_loss=0.006879171472974122
Online_Training [225/700]: mean_loss=0.03028836427256465
Online_Training [226/700]: mean_loss=0.028264266904443502
Online_Training [227/700]: mean_loss=0.01595969556365162
Online_Training [228/700]: mean_loss=0.020960816415026784
Online_Training [229/700]: mean_loss=0.04706269036978483
Online_Training [230/700]: mean_loss=0.021544559043832123
Online_Training [231/700]: mean_loss=0.021937250858172774
Online_Training [232/700]: mean_loss=0.027389124734327197
Online_Training [233/700]: mean_loss=0.023409303976222873
Online_Training [234/700]: mean_loss=0.042784767691046
Online_Training [235/700]: mean_loss=0.09165351092815399
Online_Training [236/700]: mean_loss=0.0596064287237823
Online_Training [237/700]: mean_loss=0.023285001516342163
Online_Training [238/700]: mean_loss=0.12236526980996132
Online_Training [239/700]: mean_loss=0.09583489689975977
Online_Training [240/700]: mean_loss=0.0372550159227103
Online_Training [241/700]: mean_loss=0.03767068684101105
Online_Training [242/700]: mean_loss=0.03419741825200617
Online_Training [243/700]: mean_loss=0.04000841546803713
Online_Training [244/700]: mean_loss=0.031483662547543645
Online_Training [245/700]: mean_loss=0.043468646705150604
Online_Training [246/700]: mean_loss=0.03082311269827187
Online_Training [247/700]: mean_loss=0.00946056202519685
Online_Training [248/700]: mean_loss=0.08156743738800287
Online_Training [249/700]: mean_loss=0.012787573272362351
Online_Training [250/700]: mean_loss=0.022067548474296927
Online_Training [251/700]: mean_loss=0.01582118426449597
Online_Training [252/700]: mean_loss=0.017706864047795534
Online_Training [253/700]: mean_loss=0.02179363975301385
Online_Training [254/700]: mean_loss=0.017705417005345225
Online_Training [255/700]: mean_loss=0.027363060042262077
Online_Training [256/700]: mean_loss=0.016452645184472203
Online_Training [257/700]: mean_loss=0.01999451476149261
Online_Training [258/700]: mean_loss=0.0168085367185995
Online_Training [259/700]: mean_loss=0.010441789985634387
Online_Training [260/700]: mean_loss=0.014089062809944153
Online_Training [261/700]: mean_loss=0.025156727991998196
Online_Training [262/700]: mean_loss=0.03201637719757855
Online_Training [263/700]: mean_loss=0.012413591612130404
Online_Training [264/700]: mean_loss=0.019454489229246974
Online_Training [265/700]: mean_loss=0.02045625331811607
Online_Training [266/700]: mean_loss=0.013859994243830442
Online_Training [267/700]: mean_loss=0.015519849257543683
Online_Training [268/700]: mean_loss=0.006354037788696587
Online_Training [269/700]: mean_loss=0.017146480968222022
Online_Training [270/700]: mean_loss=0.008341250708326697
Online_Training [271/700]: mean_loss=0.029340607346966863
Online_Training [272/700]: mean_loss=0.008557057939469814
Online_Training [273/700]: mean_loss=0.007848658133298159
Online_Training [274/700]: mean_loss=0.014048679848201573
Online_Training [275/700]: mean_loss=0.018065276322886348
Online_Training [276/700]: mean_loss=0.02025689696893096
Online_Training [277/700]: mean_loss=0.022380473790690303
Online_Training [278/700]: mean_loss=0.01907814247533679
Online_Training [279/700]: mean_loss=0.016398931271396577
Online_Training [280/700]: mean_loss=0.019016623264178634
Online_Training [281/700]: mean_loss=0.019073877949267626
Online_Training [282/700]: mean_loss=0.03275123075582087
Online_Training [283/700]: mean_loss=0.023672743001952767
Online_Training [284/700]: mean_loss=0.00752368284156546
Online_Training [285/700]: mean_loss=0.016328662633895874
Online_Training [286/700]: mean_loss=0.0272171120159328
Online_Training [287/700]: mean_loss=0.022890057414770126
Online_Training [288/700]: mean_loss=0.013163993484340608
Online_Training [289/700]: mean_loss=0.04451613454148173
Online_Training [290/700]: mean_loss=0.007204239198472351
Online_Training [291/700]: mean_loss=0.011885092360898852
Online_Training [292/700]: mean_loss=0.0071600236697122455
Online_Training [293/700]: mean_loss=0.00931320188101381
Online_Training [294/700]: mean_loss=0.01344876375515014
Online_Training [295/700]: mean_loss=0.033343179151415825
Online_Training [296/700]: mean_loss=0.04415525682270527
Online_Training [297/700]: mean_loss=0.022939840564504266
Online_Training [298/700]: mean_loss=0.009988082107156515
Online_Training [299/700]: mean_loss=0.01968615734949708
Online_Training [300/700]: mean_loss=0.032313917530700564
Online_Training [301/700]: mean_loss=0.01420879561919719
Online_Training [302/700]: mean_loss=0.016642313916236162
Online_Training [303/700]: mean_loss=0.02345374971628189
Online_Training [304/700]: mean_loss=0.014525549369864166
Online_Training [305/700]: mean_loss=0.05398438544943929
Online_Training [306/700]: mean_loss=0.07039672508835793
Online_Training [307/700]: mean_loss=0.07028475403785706
Online_Training [308/700]: mean_loss=0.028537192149087787
Online_Training [309/700]: mean_loss=0.012496205512434244
Online_Training [310/700]: mean_loss=0.008388526446651667
Online_Training [311/700]: mean_loss=0.013356636161915958
Online_Training [312/700]: mean_loss=0.054332499857991934
Online_Training [313/700]: mean_loss=0.019275732804089785
Online_Training [314/700]: mean_loss=0.012147083296440542
Online_Training [315/700]: mean_loss=0.006409960857126862
Online_Training [316/700]: mean_loss=0.02161800442263484
Online_Training [317/700]: mean_loss=0.00649545737542212
Online_Training [318/700]: mean_loss=0.018163860077038407
Online_Training [319/700]: mean_loss=0.0329060482326895
Online_Training [320/700]: mean_loss=0.009462355461437255
Online_Training [321/700]: mean_loss=0.022050513420253992
Online_Training [322/700]: mean_loss=0.03159200795926154
Online_Training [323/700]: mean_loss=0.019326414680108428
Online_Training [324/700]: mean_loss=0.0281142161693424
Online_Training [325/700]: mean_loss=0.03141063451766968
Online_Training [326/700]: mean_loss=0.01579701795708388
Online_Training [327/700]: mean_loss=0.020060615381225944
Online_Training [328/700]: mean_loss=0.01896935934200883
Online_Training [329/700]: mean_loss=0.013580204569734633
Online_Training [330/700]: mean_loss=0.024304996244609356
Online_Training [331/700]: mean_loss=0.02296967268921435
Online_Training [332/700]: mean_loss=0.024492312455549836
Online_Training [333/700]: mean_loss=0.015938572585582733
Online_Training [334/700]: mean_loss=0.005405236384831369
Online_Training [335/700]: mean_loss=0.06486591277644038
Online_Training [336/700]: mean_loss=0.06252041179686785
Online_Training [337/700]: mean_loss=0.08030128385871649
Online_Training [338/700]: mean_loss=0.027039355132728815
Online_Training [339/700]: mean_loss=0.010829539853148162
Online_Training [340/700]: mean_loss=0.009036480449140072
Online_Training [341/700]: mean_loss=0.01920487522147596
Online_Training [342/700]: mean_loss=0.05369543796405196
Online_Training [343/700]: mean_loss=0.009166365605778992
Online_Training [344/700]: mean_loss=0.02017637388780713
Online_Training [345/700]: mean_loss=0.034549007657915354
Online_Training [346/700]: mean_loss=0.02510150778107345
Online_Training [347/700]: mean_loss=0.13170044217258692
Online_Training [348/700]: mean_loss=0.022877495735883713
Online_Training [349/700]: mean_loss=0.023242827272042632
Online_Training [350/700]: mean_loss=0.011213636142201722
Online_Training [351/700]: mean_loss=0.014084846363402903
Online_Training [352/700]: mean_loss=0.018741412670351565
Online_Training [353/700]: mean_loss=0.015733505715616047
Online_Training [354/700]: mean_loss=0.027733396738767624
Online_Training [355/700]: mean_loss=0.01878279121592641
Online_Training [356/700]: mean_loss=0.015047715394757688
Online_Training [357/700]: mean_loss=0.091774164699018
Online_Training [358/700]: mean_loss=0.07231096737086773
Online_Training [359/700]: mean_loss=0.09156879782676697
Online_Training [360/700]: mean_loss=0.024979241658002138
Online_Training [361/700]: mean_loss=0.022994033759459853
Online_Training [362/700]: mean_loss=0.04353735921904445
Online_Training [363/700]: mean_loss=0.014043696806766093
Online_Training [364/700]: mean_loss=0.010292702354490757
Online_Training [365/700]: mean_loss=0.015987989958375692
Online_Training [366/700]: mean_loss=0.03619428817182779
Online_Training [367/700]: mean_loss=0.02317095547914505
Online_Training [368/700]: mean_loss=0.014429444097913802
Online_Training [369/700]: mean_loss=0.012621409259736538
Online_Training [370/700]: mean_loss=0.036139648873358965
Online_Training [371/700]: mean_loss=0.008411768823862076
Online_Training [372/700]: mean_loss=0.02223545522429049
Online_Training [373/700]: mean_loss=0.019241162110120058
Online_Training [374/700]: mean_loss=0.01531835226342082
Online_Training [375/700]: mean_loss=0.019536374369636178
Online_Training [376/700]: mean_loss=0.007148034987039864
Online_Training [377/700]: mean_loss=0.01699959416873753
Online_Training [378/700]: mean_loss=0.01142100605648011
Online_Training [379/700]: mean_loss=0.015271107316948473
Online_Training [380/700]: mean_loss=0.013353679794818163
Online_Training [381/700]: mean_loss=0.01880097482353449
Online_Training [382/700]: mean_loss=0.009654997382313013
Online_Training [383/700]: mean_loss=0.007559499004855752
Online_Training [384/700]: mean_loss=0.11277423612773418
Online_Training [385/700]: mean_loss=0.008414888754487038
Online_Training [386/700]: mean_loss=0.027753588743507862
Online_Training [387/700]: mean_loss=0.018106802366673946
Online_Training [388/700]: mean_loss=0.025709886336699128
Online_Training [389/700]: mean_loss=0.010590070276521146
Online_Training [390/700]: mean_loss=0.024790934985503554
Online_Training [391/700]: mean_loss=0.008980071055702865
Online_Training [392/700]: mean_loss=0.021245617885142565
Online_Training [393/700]: mean_loss=0.01772133819758892
Online_Training [394/700]: mean_loss=0.02619286417029798
Online_Training [395/700]: mean_loss=0.011172326165251434
Online_Training [396/700]: mean_loss=0.01969692064449191
Online_Training [397/700]: mean_loss=0.01034793711733073
Online_Training [398/700]: mean_loss=0.018364039482548833
Online_Training [399/700]: mean_loss=0.016766571323387325
Online_Training [400/700]: mean_loss=0.027312912046909332
Online_Training [401/700]: mean_loss=0.01691214123275131
Online_Training [402/700]: mean_loss=0.013269232586026192
Online_Training [403/700]: mean_loss=0.021592357428744435
Online_Training [404/700]: mean_loss=0.07384569337591529
Online_Training [405/700]: mean_loss=0.06395661877468228
Online_Training [406/700]: mean_loss=0.03939582221210003
Online_Training [407/700]: mean_loss=0.029064869275316596
Online_Training [408/700]: mean_loss=0.02350780926644802
Online_Training [409/700]: mean_loss=0.008216221060138196
Online_Training [410/700]: mean_loss=0.019330871291458607
Online_Training [411/700]: mean_loss=0.024303805781528354
Online_Training [412/700]: mean_loss=0.109921520575881
Online_Training [413/700]: mean_loss=0.04836426069959998
Online_Training [414/700]: mean_loss=0.03707512887194753
Online_Training [415/700]: mean_loss=0.01850501843728125
Online_Training [416/700]: mean_loss=0.017413683235645294
Online_Training [417/700]: mean_loss=0.05537713412195444
Online_Training [418/700]: mean_loss=0.01861822954379022
Online_Training [419/700]: mean_loss=0.008950867457315326
Online_Training [420/700]: mean_loss=0.05444942507892847
Online_Training [421/700]: mean_loss=0.0366840660572052
Online_Training [422/700]: mean_loss=0.016829317319206893
Online_Training [423/700]: mean_loss=0.03423808887600899
Online_Training [424/700]: mean_loss=0.04494000552222133
Online_Training [425/700]: mean_loss=0.02218599570915103
Online_Training [426/700]: mean_loss=0.01082623761612922
Online_Training [427/700]: mean_loss=0.016588390222750604
Online_Training [428/700]: mean_loss=0.02892534644342959
Online_Training [429/700]: mean_loss=0.013913032365962863
Online_Training [430/700]: mean_loss=0.007473475125152618
Online_Training [431/700]: mean_loss=0.010081395041197538
Online_Training [432/700]: mean_loss=0.08083520829677582
Online_Training [433/700]: mean_loss=0.015286996262148023
Online_Training [434/700]: mean_loss=0.016130842152051628
Online_Training [435/700]: mean_loss=0.010670142830349505
Online_Training [436/700]: mean_loss=0.05361006082966924
Online_Training [437/700]: mean_loss=0.011847783694975078
Online_Training [438/700]: mean_loss=0.11424336582422256
Online_Training [439/700]: mean_loss=0.0630410211160779
Online_Training [440/700]: mean_loss=0.040527773555368185
Online_Training [441/700]: mean_loss=0.033358021173626184
Online_Training [442/700]: mean_loss=0.007396958244498819
Online_Training [443/700]: mean_loss=0.017754973843693733
Online_Training [444/700]: mean_loss=0.010785158374346793
Online_Training [445/700]: mean_loss=0.01946091279387474
Online_Training [446/700]: mean_loss=0.027353882556781173
Online_Training [447/700]: mean_loss=0.012466631713323295
Online_Training [448/700]: mean_loss=0.026236985810101032
Online_Training [449/700]: mean_loss=0.022696034982800484
Online_Training [450/700]: mean_loss=0.03225702093914151
Online_Training [451/700]: mean_loss=0.02460379875265062
Online_Training [452/700]: mean_loss=0.044020713306963444
Online_Training [453/700]: mean_loss=0.0659452029503882
Online_Training [454/700]: mean_loss=0.017411172622814775
Online_Training [455/700]: mean_loss=0.05262111220508814
Online_Training [456/700]: mean_loss=0.009740507754031569
Online_Training [457/700]: mean_loss=0.00531528249848634
Online_Training [458/700]: mean_loss=0.009997152956202626
Online_Training [459/700]: mean_loss=0.009666936239227653
Online_Training [460/700]: mean_loss=0.012718077399767935
Online_Training [461/700]: mean_loss=0.026830179151147604
Online_Training [462/700]: mean_loss=0.007808643626049161
Online_Training [463/700]: mean_loss=0.006442973157390952
Online_Training [464/700]: mean_loss=0.012075267732143402
Online_Training [465/700]: mean_loss=0.07376798428595066
Online_Training [466/700]: mean_loss=0.02255899249576032
Online_Training [467/700]: mean_loss=0.014695112477056682
Online_Training [468/700]: mean_loss=0.016721472376957536
Online_Training [469/700]: mean_loss=0.018000656738877296
Online_Training [470/700]: mean_loss=0.05493873078376055
Online_Training [471/700]: mean_loss=0.020097287837415934
Online_Training [472/700]: mean_loss=0.02742028934881091
Online_Training [473/700]: mean_loss=0.006924424495082349
Online_Training [474/700]: mean_loss=0.011908131651580334
Online_Training [475/700]: mean_loss=0.008996295277029276
Online_Training [476/700]: mean_loss=0.20506217144429684
Online_Training [477/700]: mean_loss=0.09477147832512856
Online_Training [478/700]: mean_loss=0.051290273666381836
Online_Training [479/700]: mean_loss=0.013424393837340176
Online_Training [480/700]: mean_loss=0.008883148431777954
Online_Training [481/700]: mean_loss=0.014009799691848457
Online_Training [482/700]: mean_loss=0.03259695018641651
Online_Training [483/700]: mean_loss=0.017794822342693806
Online_Training [484/700]: mean_loss=0.01497142855077982
Online_Training [485/700]: mean_loss=0.0075919037335552275
Online_Training [486/700]: mean_loss=0.018144161673262715
Online_Training [487/700]: mean_loss=0.03562432620674372
Online_Training [488/700]: mean_loss=0.023156662238761783
Online_Training [489/700]: mean_loss=0.017521407920867205
Online_Training [490/700]: mean_loss=0.016835158225148916
Online_Training [491/700]: mean_loss=0.03624280262738466
Online_Training [492/700]: mean_loss=0.019394055008888245
Online_Training [493/700]: mean_loss=0.016983199398964643
Online_Training [494/700]: mean_loss=0.06457891315221786
Online_Training [495/700]: mean_loss=0.014176844619214535
Online_Training [496/700]: mean_loss=0.025438360637053847
Online_Training [497/700]: mean_loss=0.015696572954766452
Online_Training [498/700]: mean_loss=0.013010667986236513
Online_Training [499/700]: mean_loss=0.01748976856470108
Online_Training [500/700]: mean_loss=0.008516218513250351
Online_Training [501/700]: mean_loss=0.015668438165448606
Online_Training [502/700]: mean_loss=0.011865150416269898
Online_Training [503/700]: mean_loss=0.013893108116462827
Online_Training [504/700]: mean_loss=0.005719959503039718
Online_Training [505/700]: mean_loss=0.016387016512453556
Online_Training [506/700]: mean_loss=0.12278157472610474
Online_Training [507/700]: mean_loss=0.11697424482554197
Online_Training [508/700]: mean_loss=0.028964693192392588
Online_Training [509/700]: mean_loss=0.019197272369638085
Online_Training [510/700]: mean_loss=0.030779575230553746
Online_Training [511/700]: mean_loss=0.004344150045653805
Online_Training [512/700]: mean_loss=0.012520893476903439
Online_Training [513/700]: mean_loss=0.036706503946334124
Online_Training [514/700]: mean_loss=0.025053582387045026
Online_Training [515/700]: mean_loss=0.04053819319233298
Online_Training [516/700]: mean_loss=0.02433297550305724
Online_Training [517/700]: mean_loss=0.023683064384385943
Online_Training [518/700]: mean_loss=0.024212410440668464
Online_Training [519/700]: mean_loss=0.0077085631201043725
Online_Training [520/700]: mean_loss=0.01160127145703882
Online_Training [521/700]: mean_loss=0.03133150120265782
Online_Training [522/700]: mean_loss=0.01069315942004323
Online_Training [523/700]: mean_loss=0.020630353596061468
Online_Training [524/700]: mean_loss=0.08073739521205425
Online_Training [525/700]: mean_loss=0.023558814311400056
Online_Training [526/700]: mean_loss=0.012381967389956117
Online_Training [527/700]: mean_loss=0.01710841292515397
Online_Training [528/700]: mean_loss=0.025525293312966824
Online_Training [529/700]: mean_loss=0.02770191547460854
Online_Training [530/700]: mean_loss=0.01778454356826842
Online_Training [531/700]: mean_loss=0.013752431841567159
Online_Training [532/700]: mean_loss=0.029512322740629315
Online_Training [533/700]: mean_loss=0.018082839902490377
Online_Training [534/700]: mean_loss=0.015121459146030247
Online_Training [535/700]: mean_loss=0.02443153806962073
Online_Training [536/700]: mean_loss=0.10704094357788563
Online_Training [537/700]: mean_loss=0.010259981849230826
Online_Training [538/700]: mean_loss=0.011573142604902387
Online_Training [539/700]: mean_loss=0.007441050431225449
Online_Training [540/700]: mean_loss=0.03328772145323455
Online_Training [541/700]: mean_loss=0.12220966536551714
Online_Training [542/700]: mean_loss=0.011898860218934715
Online_Training [543/700]: mean_loss=0.02128310175612569
Online_Training [544/700]: mean_loss=0.012625412899069488
Online_Training [545/700]: mean_loss=0.02755495859310031
Online_Training [546/700]: mean_loss=0.00931550026871264
Online_Training [547/700]: mean_loss=0.027922455221414566
Online_Training [548/700]: mean_loss=0.025113033363595605
Online_Training [549/700]: mean_loss=0.0059995505143888295
Online_Training [550/700]: mean_loss=0.017076135613024235
Online_Training [551/700]: mean_loss=0.015767788514494896
Online_Training [552/700]: mean_loss=0.02796563133597374
Online_Training [553/700]: mean_loss=0.038997262716293335
Online_Training [554/700]: mean_loss=0.03081376221962273
Online_Training [555/700]: mean_loss=0.025110680842772126
Online_Training [556/700]: mean_loss=0.020306460559368134
Online_Training [557/700]: mean_loss=0.014874035958200693
Online_Training [558/700]: mean_loss=0.006204282108228654
Online_Training [559/700]: mean_loss=0.002438307972624898
Online_Training [560/700]: mean_loss=0.00758963922271505
Online_Training [561/700]: mean_loss=0.020489331101998687
Online_Training [562/700]: mean_loss=0.036854084115475416
Online_Training [563/700]: mean_loss=0.04173581022769213
Online_Training [564/700]: mean_loss=0.011846872046589851
Online_Training [565/700]: mean_loss=0.02018253644928336
Online_Training [566/700]: mean_loss=0.017762009985744953
Online_Training [567/700]: mean_loss=0.03223755955696106
Online_Training [568/700]: mean_loss=0.017880149884149432
Online_Training [569/700]: mean_loss=0.026160466484725475
Online_Training [570/700]: mean_loss=0.01527807500679046
Online_Training [571/700]: mean_loss=0.021982363890856504
Online_Training [572/700]: mean_loss=0.018961181631311774
Online_Training [573/700]: mean_loss=0.02209515287540853
Online_Training [574/700]: mean_loss=0.04553177813068032
Online_Training [575/700]: mean_loss=0.056389481760561466
Online_Training [576/700]: mean_loss=0.011171755264513195
Online_Training [577/700]: mean_loss=0.017010247334837914
Online_Training [578/700]: mean_loss=0.0073979885200969875
Online_Training [579/700]: mean_loss=0.015093302121385932
Online_Training [580/700]: mean_loss=0.03720701765269041
Online_Training [581/700]: mean_loss=0.011488323216326535
Online_Training [582/700]: mean_loss=0.007347820443101227
Online_Training [583/700]: mean_loss=0.003913187974831089
Online_Training [584/700]: mean_loss=0.01548820489551872
Online_Training [585/700]: mean_loss=0.026642065029591322
Online_Training [586/700]: mean_loss=0.11004454549401999
Online_Training [587/700]: mean_loss=0.023264115676283836
Online_Training [588/700]: mean_loss=0.007413209415972233
Online_Training [589/700]: mean_loss=0.02278001280501485
Online_Training [590/700]: mean_loss=0.023527953773736954
Online_Training [591/700]: mean_loss=0.01464490219950676
Online_Training [592/700]: mean_loss=0.014464488020166755
Online_Training [593/700]: mean_loss=0.04847017116844654
Online_Training [594/700]: mean_loss=0.009297446114942431
Online_Training [595/700]: mean_loss=0.02834041486494243
Online_Training [596/700]: mean_loss=0.012496648239903152
Online_Training [597/700]: mean_loss=0.008559502311982214
Online_Training [598/700]: mean_loss=0.013392445398494601
Online_Training [599/700]: mean_loss=0.016428641276434064
Online_Training [600/700]: mean_loss=0.01456105220131576
Online_Training [601/700]: mean_loss=0.034013547003269196
Online_Training [602/700]: mean_loss=0.009131497819907963
Online_Training [603/700]: mean_loss=0.007717317435890436
Online_Training [604/700]: mean_loss=0.031889186007902026
Online_Training [605/700]: mean_loss=0.010401421925053
Online_Training [606/700]: mean_loss=0.009278970654122531
Online_Training [607/700]: mean_loss=0.012152691488154233
Online_Training [608/700]: mean_loss=0.01035079883877188
Online_Training [609/700]: mean_loss=0.014014918357133865
Online_Training [610/700]: mean_loss=0.020809473702684045
Online_Training [611/700]: mean_loss=0.011502327281050384
Online_Training [612/700]: mean_loss=0.14011509343981743
Online_Training [613/700]: mean_loss=0.06566000822931528
Online_Training [614/700]: mean_loss=0.009916504845023155
Online_Training [615/700]: mean_loss=0.012130083632655442
Online_Training [616/700]: mean_loss=0.019087310880422592
Online_Training [617/700]: mean_loss=0.005090558552183211
Online_Training [618/700]: mean_loss=0.021319348132237792
Online_Training [619/700]: mean_loss=0.010737975011579692
Online_Training [620/700]: mean_loss=0.0613159635104239
Online_Training [621/700]: mean_loss=0.009993109735660255
Online_Training [622/700]: mean_loss=0.047621960286051035
Online_Training [623/700]: mean_loss=0.03332403744570911
Online_Training [624/700]: mean_loss=0.014459610916674137
Online_Training [625/700]: mean_loss=0.01158766692969948
Online_Training [626/700]: mean_loss=0.012462022830732167
Online_Training [627/700]: mean_loss=0.010200251010246575
Online_Training [628/700]: mean_loss=0.011612163507379591
Online_Training [629/700]: mean_loss=0.016218466218560934
Online_Training [630/700]: mean_loss=0.04370177024975419
Online_Training [631/700]: mean_loss=0.017550013959407806
Online_Training [632/700]: mean_loss=0.028589459136128426
Online_Training [633/700]: mean_loss=0.009607637242879719
Online_Training [634/700]: mean_loss=0.011429282370954752
Online_Training [635/700]: mean_loss=0.013772557955235243
Online_Training [636/700]: mean_loss=0.009671324514783919
Online_Training [637/700]: mean_loss=0.012811883701942861
Online_Training [638/700]: mean_loss=0.01756146177649498
Online_Training [639/700]: mean_loss=0.01852826541289687
Online_Training [640/700]: mean_loss=0.00837983819656074
Online_Training [641/700]: mean_loss=0.017040378996171057
Online_Training [642/700]: mean_loss=0.015036320895887911
Online_Training [643/700]: mean_loss=0.006979288766160607
Online_Training [644/700]: mean_loss=0.00736391736427322
Online_Training [645/700]: mean_loss=0.016914646257646382
Online_Training [646/700]: mean_loss=0.028895649127662182
Online_Training [647/700]: mean_loss=0.010712507297284901
Online_Training [648/700]: mean_loss=0.012348322430625558
Online_Training [649/700]: mean_loss=0.010443416191264987
Online_Training [650/700]: mean_loss=0.015456015127710998
Online_Training [651/700]: mean_loss=0.008200401731301099
Online_Training [652/700]: mean_loss=0.008154445444233716
Online_Training [653/700]: mean_loss=0.10829391237348318
Online_Training [654/700]: mean_loss=0.016974109108559787
Online_Training [655/700]: mean_loss=0.0131527486955747
Online_Training [656/700]: mean_loss=0.015313708921894431
Online_Training [657/700]: mean_loss=0.013304344494827092
Online_Training [658/700]: mean_loss=0.011165722622536123
Online_Training [659/700]: mean_loss=0.016045094467699528
Online_Training [660/700]: mean_loss=0.01613674033433199
Online_Training [661/700]: mean_loss=0.037069955840706825
Online_Training [662/700]: mean_loss=0.045270544942468405
Online_Training [663/700]: mean_loss=0.017150223371572793
Online_Training [664/700]: mean_loss=0.007161997782532126
Online_Training [665/700]: mean_loss=0.04370319377630949
Online_Training [666/700]: mean_loss=0.033438865561038256
Online_Training [667/700]: mean_loss=0.004810020385775715
Online_Training [668/700]: mean_loss=0.00788020429899916
Online_Training [669/700]: mean_loss=0.00800094794249162
Online_Training [670/700]: mean_loss=0.010927150724455714
Online_Training [671/700]: mean_loss=0.018107923911884427
Online_Training [672/700]: mean_loss=0.012233216082677245
Online_Training [673/700]: mean_loss=0.010331843513995409
Online_Training [674/700]: mean_loss=0.009084178775083274
Online_Training [675/700]: mean_loss=0.010194937349297106
Online_Training [676/700]: mean_loss=0.03679915750399232
Online_Training [677/700]: mean_loss=0.04889616835862398
Online_Training [678/700]: mean_loss=0.021158938063308597
Online_Training [679/700]: mean_loss=0.02238937164656818
Online_Training [680/700]: mean_loss=0.008105200191494077
Online_Training [681/700]: mean_loss=0.018193196039646864
Online_Training [682/700]: mean_loss=0.012965165777131915
Online_Training [683/700]: mean_loss=0.007445490104146302
Online_Training [684/700]: mean_loss=0.008912931836675853
Online_Training [685/700]: mean_loss=0.025499725248664618
Online_Training [686/700]: mean_loss=0.01068686181679368
Online_Training [687/700]: mean_loss=0.021895362762734294
Online_Training [688/700]: mean_loss=0.053213960491120815
Online_Training [689/700]: mean_loss=0.01861821487545967
Online_Training [690/700]: mean_loss=0.008218807517550886
Online_Training [691/700]: mean_loss=0.009486863447818905
Online_Training [692/700]: mean_loss=0.026577906450256705
Online_Training [693/700]: mean_loss=0.01484026899561286
Online_Training [694/700]: mean_loss=0.03205226315185428
Online_Training [695/700]: mean_loss=0.012675260310061276
Online_Training [696/700]: mean_loss=0.029441422782838345
Online_Training [697/700]: mean_loss=0.003698078391607851
Online_Training [698/700]: mean_loss=0.007981088710948825
Online_Training [699/700]: mean_loss=0.07127223908901215
Online_Training [700/700]: mean_loss=0.009202882647514343
Q_Learning [1/300]: mean_loss=0.16264784336090088
Q_Learning [2/300]: mean_loss=0.20413810946047306
Q_Learning [3/300]: mean_loss=0.17004199884831905
Q_Learning [4/300]: mean_loss=0.0608846303075552
Q_Learning [5/300]: mean_loss=0.24612360075116158
Q_Learning [6/300]: mean_loss=0.09035573992878199
Q_Learning [7/300]: mean_loss=0.09589536115527153
Q_Learning [8/300]: mean_loss=0.07429037615656853
Q_Learning [9/300]: mean_loss=0.16000030003488064
Q_Learning [10/300]: mean_loss=0.1419121939688921
Q_Learning [11/300]: mean_loss=0.06636008620262146
Q_Learning [12/300]: mean_loss=0.07420600112527609
Q_Learning [13/300]: mean_loss=0.09389601647853851
Q_Learning [14/300]: mean_loss=0.05419966345652938
Q_Learning [15/300]: mean_loss=0.05974000692367554
Q_Learning [16/300]: mean_loss=0.10270926728844643
Q_Learning [17/300]: mean_loss=0.08370819129049778
Q_Learning [18/300]: mean_loss=0.048952892888337374
Q_Learning [19/300]: mean_loss=0.021962576545774937
Q_Learning [20/300]: mean_loss=0.07540295738726854
Q_Learning [21/300]: mean_loss=0.13476995564997196
Q_Learning [22/300]: mean_loss=0.013088079867884517
Q_Learning [23/300]: mean_loss=0.021275010891258717
Q_Learning [24/300]: mean_loss=0.029920936562120914
Q_Learning [25/300]: mean_loss=0.042122588492929935
Q_Learning [26/300]: mean_loss=0.04845794849097729
Q_Learning [27/300]: mean_loss=0.05526145175099373
Q_Learning [28/300]: mean_loss=0.029589318437501788
Q_Learning [29/300]: mean_loss=0.04143963381648064
Q_Learning [30/300]: mean_loss=0.029061235720291734
Q_Learning [31/300]: mean_loss=0.025775477988645434
Q_Learning [32/300]: mean_loss=0.04448508098721504
Q_Learning [33/300]: mean_loss=0.025718863122165203
Q_Learning [34/300]: mean_loss=0.08219917677342892
Q_Learning [35/300]: mean_loss=0.05376569228246808
Q_Learning [36/300]: mean_loss=0.055147222708910704
Q_Learning [37/300]: mean_loss=0.04635129636153579
Q_Learning [38/300]: mean_loss=0.038076940923929214
Q_Learning [39/300]: mean_loss=0.0412609726190567
Q_Learning [40/300]: mean_loss=0.03048115107230842
Q_Learning [41/300]: mean_loss=0.027208066079765558
Q_Learning [42/300]: mean_loss=0.0558471092954278
Q_Learning [43/300]: mean_loss=0.04851712239906192
Q_Learning [44/300]: mean_loss=0.051969405729323626
Q_Learning [45/300]: mean_loss=0.051492493599653244
Q_Learning [46/300]: mean_loss=0.031047218712046742
Q_Learning [47/300]: mean_loss=0.032226790208369493
Q_Learning [48/300]: mean_loss=0.06755777727812529
Q_Learning [49/300]: mean_loss=0.012013637693598866
Q_Learning [50/300]: mean_loss=0.027006467571482062
Q_Learning [51/300]: mean_loss=0.016545020160265267
Q_Learning [52/300]: mean_loss=0.053549572825431824
Q_Learning [53/300]: mean_loss=0.019697218667715788
Q_Learning [54/300]: mean_loss=0.04545081267133355
Q_Learning [55/300]: mean_loss=0.017374754417687654
Q_Learning [56/300]: mean_loss=0.03887828951701522
Q_Learning [57/300]: mean_loss=0.09160014986991882
Q_Learning [58/300]: mean_loss=0.10703600849956274
Q_Learning [59/300]: mean_loss=0.08104812493547797
Q_Learning [60/300]: mean_loss=0.04152008472010493
Q_Learning [61/300]: mean_loss=0.03755480796098709
Q_Learning [62/300]: mean_loss=0.08207547944039106
Q_Learning [63/300]: mean_loss=0.048702419735491276
Q_Learning [64/300]: mean_loss=0.004204079858027399
Q_Learning [65/300]: mean_loss=0.05774143524467945
Q_Learning [66/300]: mean_loss=0.04099880252033472
Q_Learning [67/300]: mean_loss=0.07151070050895214
Q_Learning [68/300]: mean_loss=0.02138611674308777
Q_Learning [69/300]: mean_loss=0.03216519928537309
Q_Learning [70/300]: mean_loss=0.0392188117839396
Q_Learning [71/300]: mean_loss=0.07084459345787764
Q_Learning [72/300]: mean_loss=0.0773323941975832
Q_Learning [73/300]: mean_loss=0.040844233240932226
Q_Learning [74/300]: mean_loss=0.03910905309021473
Q_Learning [75/300]: mean_loss=0.024849759647622705
Q_Learning [76/300]: mean_loss=0.01653158839326352
Q_Learning [77/300]: mean_loss=0.04333962732926011
Q_Learning [78/300]: mean_loss=0.019161483505740762
Q_Learning [79/300]: mean_loss=0.04400681611150503
Q_Learning [80/300]: mean_loss=0.03732166951522231
Q_Learning [81/300]: mean_loss=0.017978958087041974
Q_Learning [82/300]: mean_loss=0.031173120019957423
Q_Learning [83/300]: mean_loss=0.02877896325662732
Q_Learning [84/300]: mean_loss=0.03308206098154187
Q_Learning [85/300]: mean_loss=0.02662280132062733
Q_Learning [86/300]: mean_loss=0.0313180279918015
Q_Learning [87/300]: mean_loss=0.01960895722731948
Q_Learning [88/300]: mean_loss=0.02703342866152525
Q_Learning [89/300]: mean_loss=0.043244974222034216
Q_Learning [90/300]: mean_loss=0.017688302090391517
Q_Learning [91/300]: mean_loss=0.033062195871025324
Q_Learning [92/300]: mean_loss=0.03641455341130495
Q_Learning [93/300]: mean_loss=0.024588311556726694
Q_Learning [94/300]: mean_loss=0.039199996273964643
Q_Learning [95/300]: mean_loss=0.03216742258518934
Q_Learning [96/300]: mean_loss=0.022409539436921477
Q_Learning [97/300]: mean_loss=0.04623768338933587
Q_Learning [98/300]: mean_loss=0.04693102743476629
Q_Learning [99/300]: mean_loss=0.023302112938836217
Q_Learning [100/300]: mean_loss=0.04156118491664529
Q_Learning [101/300]: mean_loss=0.01760395138990134
Q_Learning [102/300]: mean_loss=0.05966134276241064
Q_Learning [103/300]: mean_loss=0.040789314080029726
Q_Learning [104/300]: mean_loss=0.04010317847132683
Q_Learning [105/300]: mean_loss=0.03807738143950701
Q_Learning [106/300]: mean_loss=0.01781845581717789
Q_Learning [107/300]: mean_loss=0.017907104222103953
Q_Learning [108/300]: mean_loss=0.03155229822732508
Q_Learning [109/300]: mean_loss=0.029890415025874972
Q_Learning [110/300]: mean_loss=0.025555561063811183
Q_Learning [111/300]: mean_loss=0.029925005976110697
Q_Learning [112/300]: mean_loss=0.165525134652853
Q_Learning [113/300]: mean_loss=0.021863429341465235
Q_Learning [114/300]: mean_loss=0.0385970096103847
Q_Learning [115/300]: mean_loss=0.036524626426398754
Q_Learning [116/300]: mean_loss=0.021473679691553116
Q_Learning [117/300]: mean_loss=0.053830234333872795
Q_Learning [118/300]: mean_loss=0.04833467956632376
Q_Learning [119/300]: mean_loss=0.13998190686106682
Q_Learning [120/300]: mean_loss=0.06509446445852518
Q_Learning [121/300]: mean_loss=0.05787305487319827
Q_Learning [122/300]: mean_loss=0.06785923615098
Q_Learning [123/300]: mean_loss=0.02766381879337132
Q_Learning [124/300]: mean_loss=0.010363029781728983
Q_Learning [125/300]: mean_loss=0.05748675903305411
Q_Learning [126/300]: mean_loss=0.04586863378062844
Q_Learning [127/300]: mean_loss=0.05554356751963496
Q_Learning [128/300]: mean_loss=0.030517212580889463
Q_Learning [129/300]: mean_loss=0.036144344601780176
Q_Learning [130/300]: mean_loss=0.024241985753178596
Q_Learning [131/300]: mean_loss=0.024957029381766915
Q_Learning [132/300]: mean_loss=0.01876693218946457
Q_Learning [133/300]: mean_loss=0.02499404503032565
Q_Learning [134/300]: mean_loss=0.021829168079420924
Q_Learning [135/300]: mean_loss=0.11812127660959959
Q_Learning [136/300]: mean_loss=0.02115835971198976
Q_Learning [137/300]: mean_loss=0.02249322389252484
Q_Learning [138/300]: mean_loss=0.014445576118305326
Q_Learning [139/300]: mean_loss=0.01899545476771891
Q_Learning [140/300]: mean_loss=0.03467492526397109
Q_Learning [141/300]: mean_loss=0.028087185928598046
Q_Learning [142/300]: mean_loss=0.016365113318897784
Q_Learning [143/300]: mean_loss=0.021082533756271005
Q_Learning [144/300]: mean_loss=0.013260210282169282
Q_Learning [145/300]: mean_loss=0.04474802454933524
Q_Learning [146/300]: mean_loss=0.019584009889513254
Q_Learning [147/300]: mean_loss=0.0164118530228734
Q_Learning [148/300]: mean_loss=0.040236583445221186
Q_Learning [149/300]: mean_loss=0.0931989885866642
Q_Learning [150/300]: mean_loss=0.056710471864789724
Q_Learning [151/300]: mean_loss=0.026741107692942023
Q_Learning [152/300]: mean_loss=0.017363689374178648
Q_Learning [153/300]: mean_loss=0.02099625999107957
Q_Learning [154/300]: mean_loss=0.020841113291680813
Q_Learning [155/300]: mean_loss=0.009479178988840431
Q_Learning [156/300]: mean_loss=0.018980656284838915
Q_Learning [157/300]: mean_loss=0.13296423386782408
Q_Learning [158/300]: mean_loss=0.0048085153684951365
Q_Learning [159/300]: mean_loss=0.020402560010552406
Q_Learning [160/300]: mean_loss=0.02219256479293108
Q_Learning [161/300]: mean_loss=0.027959371684119105
Q_Learning [162/300]: mean_loss=0.016089355223812163
Q_Learning [163/300]: mean_loss=0.0584358568303287
Q_Learning [164/300]: mean_loss=0.016290170955471694
Q_Learning [165/300]: mean_loss=0.008020593435503542
Q_Learning [166/300]: mean_loss=0.014533175039105117
Q_Learning [167/300]: mean_loss=0.04110714700073004
Q_Learning [168/300]: mean_loss=0.035193323623389006
Q_Learning [169/300]: mean_loss=0.059484603349119425
Q_Learning [170/300]: mean_loss=0.17427130788564682
Q_Learning [171/300]: mean_loss=0.015168211073614657
Q_Learning [172/300]: mean_loss=0.01310192490927875
Q_Learning [173/300]: mean_loss=0.023101210594177246
Q_Learning [174/300]: mean_loss=0.012918855529278517
Q_Learning [175/300]: mean_loss=0.012113635428249836
Q_Learning [176/300]: mean_loss=0.0070496267871931195
Q_Learning [177/300]: mean_loss=0.03412280301563442
Q_Learning [178/300]: mean_loss=0.0412867134436965
Q_Learning [179/300]: mean_loss=0.0159321321407333
Q_Learning [180/300]: mean_loss=0.024105531629174948
Q_Learning [181/300]: mean_loss=0.02881419425830245
Q_Learning [182/300]: mean_loss=0.03358948137611151
Q_Learning [183/300]: mean_loss=0.010976869729347527
Q_Learning [184/300]: mean_loss=0.005309066269546747
Q_Learning [185/300]: mean_loss=0.03512396407313645
Q_Learning [186/300]: mean_loss=0.03420307161286473
Q_Learning [187/300]: mean_loss=0.03438466042280197
Q_Learning [188/300]: mean_loss=0.02425728947855532
Q_Learning [189/300]: mean_loss=0.056927456986159086
Q_Learning [190/300]: mean_loss=0.028967262944206595
Q_Learning [191/300]: mean_loss=0.15233591571450233
Q_Learning [192/300]: mean_loss=0.023775042966008186
Q_Learning [193/300]: mean_loss=0.02179206325672567
Q_Learning [194/300]: mean_loss=0.017301160492934287
Q_Learning [195/300]: mean_loss=0.024028092389926314
Q_Learning [196/300]: mean_loss=0.011684472439810634
Q_Learning [197/300]: mean_loss=0.03956278646364808
Q_Learning [198/300]: mean_loss=0.017303486703895032
Q_Learning [199/300]: mean_loss=0.09040744323283434
Q_Learning [200/300]: mean_loss=0.020182506181299686
Q_Learning [201/300]: mean_loss=0.039040328934788704
Q_Learning [202/300]: mean_loss=0.01577087980695069
Q_Learning [203/300]: mean_loss=0.011702144285663962
Q_Learning [204/300]: mean_loss=0.011837046244181693
Q_Learning [205/300]: mean_loss=0.06656076852232218
Q_Learning [206/300]: mean_loss=0.01965326303616166
Q_Learning [207/300]: mean_loss=0.043457296676933765
Q_Learning [208/300]: mean_loss=0.0408046287484467
Q_Learning [209/300]: mean_loss=0.051674663089215755
Q_Learning [210/300]: mean_loss=0.030365135986357927
Q_Learning [211/300]: mean_loss=0.02027169638313353
Q_Learning [212/300]: mean_loss=0.0907408082857728
Q_Learning [213/300]: mean_loss=0.043582063633948565
Q_Learning [214/300]: mean_loss=0.019908152520656586
Q_Learning [215/300]: mean_loss=0.03716073790565133
Q_Learning [216/300]: mean_loss=0.030512933852151036
Q_Learning [217/300]: mean_loss=0.01231464243028313
Q_Learning [218/300]: mean_loss=0.010554231004789472
Q_Learning [219/300]: mean_loss=0.04966907715424895
Q_Learning [220/300]: mean_loss=0.01363180042244494
Q_Learning [221/300]: mean_loss=0.03221927653066814
Q_Learning [222/300]: mean_loss=0.022274567745625973
Q_Learning [223/300]: mean_loss=0.03358868882060051
Q_Learning [224/300]: mean_loss=0.006879171472974122
Q_Learning [225/300]: mean_loss=0.03028836427256465
Q_Learning [226/300]: mean_loss=0.028264266904443502
Q_Learning [227/300]: mean_loss=0.01595969556365162
Q_Learning [228/300]: mean_loss=0.020960816415026784
Q_Learning [229/300]: mean_loss=0.04706269036978483
Q_Learning [230/300]: mean_loss=0.021544559043832123
Q_Learning [231/300]: mean_loss=0.021937250858172774
Q_Learning [232/300]: mean_loss=0.027389124734327197
Q_Learning [233/300]: mean_loss=0.023409303976222873
Q_Learning [234/300]: mean_loss=0.042784767691046
Q_Learning [235/300]: mean_loss=0.09165351092815399
Q_Learning [236/300]: mean_loss=0.0596064287237823
Q_Learning [237/300]: mean_loss=0.023285001516342163
Q_Learning [238/300]: mean_loss=0.12236526980996132
Q_Learning [239/300]: mean_loss=0.09583489689975977
Q_Learning [240/300]: mean_loss=0.0372550159227103
Q_Learning [241/300]: mean_loss=0.03767068684101105
Q_Learning [242/300]: mean_loss=0.03419741825200617
Q_Learning [243/300]: mean_loss=0.04000841546803713
Q_Learning [244/300]: mean_loss=0.031483662547543645
Q_Learning [245/300]: mean_loss=0.043468646705150604
Q_Learning [246/300]: mean_loss=0.03082311269827187
Q_Learning [247/300]: mean_loss=0.00946056202519685
Q_Learning [248/300]: mean_loss=0.08156743738800287
Q_Learning [249/300]: mean_loss=0.012787573272362351
Q_Learning [250/300]: mean_loss=0.022067548474296927
Q_Learning [251/300]: mean_loss=0.01582118426449597
Q_Learning [252/300]: mean_loss=0.017706864047795534
Q_Learning [253/300]: mean_loss=0.02179363975301385
Q_Learning [254/300]: mean_loss=0.017705417005345225
Q_Learning [255/300]: mean_loss=0.027363060042262077
Q_Learning [256/300]: mean_loss=0.016452645184472203
Q_Learning [257/300]: mean_loss=0.01999451476149261
Q_Learning [258/300]: mean_loss=0.0168085367185995
Q_Learning [259/300]: mean_loss=0.010441789985634387
Q_Learning [260/300]: mean_loss=0.014089062809944153
Q_Learning [261/300]: mean_loss=0.025156727991998196
Q_Learning [262/300]: mean_loss=0.03201637719757855
Q_Learning [263/300]: mean_loss=0.012413591612130404
Q_Learning [264/300]: mean_loss=0.019454489229246974
Q_Learning [265/300]: mean_loss=0.02045625331811607
Q_Learning [266/300]: mean_loss=0.013859994243830442
Q_Learning [267/300]: mean_loss=0.015519849257543683
Q_Learning [268/300]: mean_loss=0.006354037788696587
Q_Learning [269/300]: mean_loss=0.017146480968222022
Q_Learning [270/300]: mean_loss=0.008341250708326697
Q_Learning [271/300]: mean_loss=0.029340607346966863
Q_Learning [272/300]: mean_loss=0.008557057939469814
Q_Learning [273/300]: mean_loss=0.007848658133298159
Q_Learning [274/300]: mean_loss=0.014048679848201573
Q_Learning [275/300]: mean_loss=0.018065276322886348
Q_Learning [276/300]: mean_loss=0.02025689696893096
Q_Learning [277/300]: mean_loss=0.022380473790690303
Q_Learning [278/300]: mean_loss=0.01907814247533679
Q_Learning [279/300]: mean_loss=0.016398931271396577
Q_Learning [280/300]: mean_loss=0.019016623264178634
Q_Learning [281/300]: mean_loss=0.019073877949267626
Q_Learning [282/300]: mean_loss=0.03275123075582087
Q_Learning [283/300]: mean_loss=0.023672743001952767
Q_Learning [284/300]: mean_loss=0.00752368284156546
Q_Learning [285/300]: mean_loss=0.016328662633895874
Q_Learning [286/300]: mean_loss=0.0272171120159328
Q_Learning [287/300]: mean_loss=0.022890057414770126
Q_Learning [288/300]: mean_loss=0.013163993484340608
Q_Learning [289/300]: mean_loss=0.04451613454148173
Q_Learning [290/300]: mean_loss=0.007204239198472351
Q_Learning [291/300]: mean_loss=0.011885092360898852
Q_Learning [292/300]: mean_loss=0.0071600236697122455
Q_Learning [293/300]: mean_loss=0.00931320188101381
Q_Learning [294/300]: mean_loss=0.01344876375515014
Q_Learning [295/300]: mean_loss=0.033343179151415825
Q_Learning [296/300]: mean_loss=0.04415525682270527
Q_Learning [297/300]: mean_loss=0.022939840564504266
Q_Learning [298/300]: mean_loss=0.009988082107156515
Q_Learning [299/300]: mean_loss=0.01968615734949708
Q_Learning [300/300]: mean_loss=0.032313917530700564
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 0.6382729 -1.0559762]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 1, 1, 0, 0, 3, 2, 1, 1, 2, 2, 0, 0, 1, 0, 1, 3, 2, 0, 0, 1, 2, 1, 0, 1, 2, 3, 2, 1, 0, 2, 1, 1, 0, 3, 1, 2, 1, 2, 1, 1, 3, 0, 1, 2, 0, 2, 0, 0, 3, 2, 2, 1, 1, 0, 2, 2, 0, 2, 0, 3, 2, 2, 2, 1, 2, 0, 2, 2, 1, 0, 2, 1, 0, 1, 1, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 3, 3, 2, 2, 2, 1, 3, 2, 1, 0, 2, 1, 0, 2, 1, 2, 0, 3, 0, 1, 2, 3, 1, 2, 1, 1, 2, 3, 2, 2, 2, 4, 2, 1, 3, 2, 1, 3, 1, 1, 0, 2, 1, 2, 2, 3, 2, 3, 0, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 2, 2, 0, 0, 1, 0, 3, 2, 3, 1, 0, 1, 0, 1, 2, 0, 2, 1, 3, 2, 1, 2, 0, 0, 1, 2, 1, 3, 1, 3, 1, 2, 2, 1, 3, 1, 2, 2, 1, 3, 1, 2, 2, 1, 0, 3, 2, 2, 4, 4, 1, 2, 3, 3, 3, 2, 3, 0, 1, 1, 2, 1, 3, 0, 2, 1, 2, 0, 1, 1, 3, 2, 1, 1, 4, 5, 1, 2, 1, 2, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 2, 2, 0, 3, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 0, 1, 2, 3, 0, 0, 1, 2, 2, 0, 2, 1, 0, 0, 1, 2, 2, 2, 1, 2, 0, 0, 1, 1, 2, 1, 2]
Centroids: [[-1.2962602, 1.0095118], [-1.1103352, -0.20099668], [1.0343169, -1.0967324]]
Centroids: [[0.5826221, -1.1550865], [-1.2037657, -0.26800153], [-1.2137569, 1.0251713], [1.7576593, -0.9716686], [-1.4409025, 2.4555264], [3.8017924, -0.40722698]]
Contingency Matrix: 
[[ 0 15 85  0  3  0]
 [ 2 83 14  0  1  0]
 [63  0  0 33  0  1]]
[[0, 15, 85, 0, 3, 0], [2, 83, 14, 0, 1, 0], [63, 0, 0, 33, 0, 1]]
[[0, 15, 85, 0, 3, 0], [2, 83, 14, 0, 1, 0], [63, 0, 0, 33, 0, 1]]
[0, 1, 2, 3, 4, 5]
[[-1, -1, -1, -1, -1, -1], [2, 83, -1, 0, 1, 0], [63, 0, -1, 33, 0, 1]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [63, -1, -1, 33, 0, 1]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 2, 1: 1, 2: 0}
New Contingency Matrix: 
[[85 15  0  0  3  0]
 [14 83  2  0  1  0]
 [ 0  0 63 33  0  1]]
New Clustered Label Sequence: [2, 1, 0, 3, 4, 5]
Diagonal_Elements: [85, 83, 63], Sum: 231
All_Elements: [85, 15, 0, 0, 3, 0, 14, 83, 2, 0, 1, 0, 0, 0, 63, 33, 0, 1], Sum: 300
Accuracy: 0.77
