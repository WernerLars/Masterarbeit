Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_1_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_2/Experiment_05_1_opt_temp/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_05_04-13_18_25
Punishment_Coefficient: 1.0
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000267BA0E7588>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.20289978198707104
Online_Training [2/700]: mean_loss=0.2343860510736704
Online_Training [3/700]: mean_loss=0.1887986045330763
Online_Training [4/700]: mean_loss=0.08767408318817616
Online_Training [5/700]: mean_loss=0.2867974787950516
Online_Training [6/700]: mean_loss=0.09930925816297531
Online_Training [7/700]: mean_loss=0.1253615990281105
Online_Training [8/700]: mean_loss=0.09804243315011263
Online_Training [9/700]: mean_loss=0.2015311513096094
Online_Training [10/700]: mean_loss=0.1556899156421423
Online_Training [11/700]: mean_loss=0.10435397271066904
Online_Training [12/700]: mean_loss=0.08603474963456392
Online_Training [13/700]: mean_loss=0.11063926480710506
Online_Training [14/700]: mean_loss=0.0767221124842763
Online_Training [15/700]: mean_loss=0.08214706648141146
Online_Training [16/700]: mean_loss=0.14106674306094646
Online_Training [17/700]: mean_loss=0.14528338983654976
Online_Training [18/700]: mean_loss=0.08335058763623238
Online_Training [19/700]: mean_loss=0.03328718896955252
Online_Training [20/700]: mean_loss=0.18070121482014656
Online_Training [21/700]: mean_loss=0.1269052717834711
Online_Training [22/700]: mean_loss=0.055027950555086136
Online_Training [23/700]: mean_loss=0.02678764541633427
Online_Training [24/700]: mean_loss=0.1034324737265706
Online_Training [25/700]: mean_loss=0.043375723995268345
Online_Training [26/700]: mean_loss=0.051283631939440966
Online_Training [27/700]: mean_loss=0.10374834667891264
Online_Training [28/700]: mean_loss=0.04942118376493454
Online_Training [29/700]: mean_loss=0.0475303758867085
Online_Training [30/700]: mean_loss=0.032496586907655
Online_Training [31/700]: mean_loss=0.028675551060587168
Online_Training [32/700]: mean_loss=0.0407429994083941
Online_Training [33/700]: mean_loss=0.021785105811432004
Online_Training [34/700]: mean_loss=0.15441140159964561
Online_Training [35/700]: mean_loss=0.05085064982995391
Online_Training [36/700]: mean_loss=0.08723342325538397
Online_Training [37/700]: mean_loss=0.05826224107295275
Online_Training [38/700]: mean_loss=0.036984095349907875
Online_Training [39/700]: mean_loss=0.13022209703922272
Online_Training [40/700]: mean_loss=0.03305424749851227
Online_Training [41/700]: mean_loss=0.025106780230998993
Online_Training [42/700]: mean_loss=0.05110158445313573
Online_Training [43/700]: mean_loss=0.1238044248893857
Online_Training [44/700]: mean_loss=0.140014773234725
Online_Training [45/700]: mean_loss=0.07618582621216774
Online_Training [46/700]: mean_loss=0.03867698786780238
Online_Training [47/700]: mean_loss=0.08130376134067774
Online_Training [48/700]: mean_loss=0.0691313510760665
Online_Training [49/700]: mean_loss=0.0799879739060998
Online_Training [50/700]: mean_loss=0.08902482315897942
Online_Training [51/700]: mean_loss=0.026794853154569864
Online_Training [52/700]: mean_loss=0.12991630751639605
Online_Training [53/700]: mean_loss=0.02017418947070837
Online_Training [54/700]: mean_loss=0.05549170123413205
Online_Training [55/700]: mean_loss=0.027849938720464706
Online_Training [56/700]: mean_loss=0.034272815100848675
Online_Training [57/700]: mean_loss=0.07352377893403172
Online_Training [58/700]: mean_loss=0.17734269425272942
Online_Training [59/700]: mean_loss=0.07658398803323507
Online_Training [60/700]: mean_loss=0.048362609930336475
Online_Training [61/700]: mean_loss=0.022089247591793537
Online_Training [62/700]: mean_loss=0.0872308649122715
Online_Training [63/700]: mean_loss=0.06225581327453256
Online_Training [64/700]: mean_loss=0.007305219856789336
Online_Training [65/700]: mean_loss=0.06736573250964284
Online_Training [66/700]: mean_loss=0.04113472905009985
Online_Training [67/700]: mean_loss=0.06343947350978851
Online_Training [68/700]: mean_loss=0.023809265112504363
Online_Training [69/700]: mean_loss=0.05376687739044428
Online_Training [70/700]: mean_loss=0.03678895020857453
Online_Training [71/700]: mean_loss=0.07650919072329998
Online_Training [72/700]: mean_loss=0.07487366255372763
Online_Training [73/700]: mean_loss=0.03678721166215837
Online_Training [74/700]: mean_loss=0.03818777436390519
Online_Training [75/700]: mean_loss=0.027975939447060227
Online_Training [76/700]: mean_loss=0.015856350190006196
Online_Training [77/700]: mean_loss=0.03294488089159131
Online_Training [78/700]: mean_loss=0.020010209176689386
Online_Training [79/700]: mean_loss=0.029775191331282258
Online_Training [80/700]: mean_loss=0.030857541598379612
Online_Training [81/700]: mean_loss=0.0181997986510396
Online_Training [82/700]: mean_loss=0.02651878632605076
Online_Training [83/700]: mean_loss=0.03446955839172006
Online_Training [84/700]: mean_loss=0.02475613891147077
Online_Training [85/700]: mean_loss=0.02712519676424563
Online_Training [86/700]: mean_loss=0.03429840668104589
Online_Training [87/700]: mean_loss=0.015559598919935524
Online_Training [88/700]: mean_loss=0.029257234884425998
Online_Training [89/700]: mean_loss=0.03892990294843912
Online_Training [90/700]: mean_loss=0.019268746254965663
Online_Training [91/700]: mean_loss=0.03132719243876636
Online_Training [92/700]: mean_loss=0.041606365237385035
Online_Training [93/700]: mean_loss=0.02674734010361135
Online_Training [94/700]: mean_loss=0.04025872191414237
Online_Training [95/700]: mean_loss=0.02804922009818256
Online_Training [96/700]: mean_loss=0.023245053831487894
Online_Training [97/700]: mean_loss=0.03614495322108269
Online_Training [98/700]: mean_loss=0.03585643763653934
Online_Training [99/700]: mean_loss=0.021842034766450524
Online_Training [100/700]: mean_loss=0.05819181818515062
Online_Training [101/700]: mean_loss=0.019370584283024073
Online_Training [102/700]: mean_loss=0.04970021732151508
Online_Training [103/700]: mean_loss=0.03695958526805043
Online_Training [104/700]: mean_loss=0.04603849397972226
Online_Training [105/700]: mean_loss=0.025763463927432895
Online_Training [106/700]: mean_loss=0.009326420025900006
Online_Training [107/700]: mean_loss=0.014372067176736891
Online_Training [108/700]: mean_loss=0.02520275069400668
Online_Training [109/700]: mean_loss=0.03132646717131138
Online_Training [110/700]: mean_loss=0.026803604559972882
Online_Training [111/700]: mean_loss=0.02392309485003352
Online_Training [112/700]: mean_loss=0.11313317622989416
Online_Training [113/700]: mean_loss=0.02089466224424541
Online_Training [114/700]: mean_loss=0.026198492851108313
Online_Training [115/700]: mean_loss=0.06165340030565858
Online_Training [116/700]: mean_loss=0.026029232190921903
Online_Training [117/700]: mean_loss=0.06554346205666661
Online_Training [118/700]: mean_loss=0.03342693950980902
Online_Training [119/700]: mean_loss=0.12159259337931871
Online_Training [120/700]: mean_loss=0.05083838989958167
Online_Training [121/700]: mean_loss=0.062335746828466654
Online_Training [122/700]: mean_loss=0.05015270225703716
Online_Training [123/700]: mean_loss=0.028320091543719172
Online_Training [124/700]: mean_loss=0.014565384481102228
Online_Training [125/700]: mean_loss=0.07106494344770908
Online_Training [126/700]: mean_loss=0.04022997338324785
Online_Training [127/700]: mean_loss=0.048644174821674824
Online_Training [128/700]: mean_loss=0.021286631003022194
Online_Training [129/700]: mean_loss=0.021074495278298855
Online_Training [130/700]: mean_loss=0.01842899527400732
Online_Training [131/700]: mean_loss=0.02494999673217535
Online_Training [132/700]: mean_loss=0.020055043743923306
Online_Training [133/700]: mean_loss=0.02423166297376156
Online_Training [134/700]: mean_loss=0.011155703337863088
Online_Training [135/700]: mean_loss=0.09619181603193283
Online_Training [136/700]: mean_loss=0.021364468848332763
Online_Training [137/700]: mean_loss=0.029986407607793808
Online_Training [138/700]: mean_loss=0.012422829400748014
Online_Training [139/700]: mean_loss=0.016661708592437208
Online_Training [140/700]: mean_loss=0.024122218368574977
Online_Training [141/700]: mean_loss=0.03627358516678214
Online_Training [142/700]: mean_loss=0.018194148316979408
Online_Training [143/700]: mean_loss=0.0199679983779788
Online_Training [144/700]: mean_loss=0.01098023820668459
Online_Training [145/700]: mean_loss=0.04223222704604268
Online_Training [146/700]: mean_loss=0.022522118990309536
Online_Training [147/700]: mean_loss=0.017492357175797224
Online_Training [148/700]: mean_loss=0.038012620992958546
Online_Training [149/700]: mean_loss=0.04753552610054612
Online_Training [150/700]: mean_loss=0.06610407121479511
Online_Training [151/700]: mean_loss=0.029686996014788747
Online_Training [152/700]: mean_loss=0.020858098287135363
Online_Training [153/700]: mean_loss=0.037919528782367706
Online_Training [154/700]: mean_loss=0.02268840535543859
Online_Training [155/700]: mean_loss=0.012705498258583248
Online_Training [156/700]: mean_loss=0.02379490714520216
Online_Training [157/700]: mean_loss=0.1418062625452876
Online_Training [158/700]: mean_loss=0.013447016128338873
Online_Training [159/700]: mean_loss=0.02382910391315818
Online_Training [160/700]: mean_loss=0.035324014024809
Online_Training [161/700]: mean_loss=0.034885779954493046
Online_Training [162/700]: mean_loss=0.01459827576763928
Online_Training [163/700]: mean_loss=0.049223759677261114
Online_Training [164/700]: mean_loss=0.018527917563915253
Online_Training [165/700]: mean_loss=0.0084955490892753
Online_Training [166/700]: mean_loss=0.024047640152275562
Online_Training [167/700]: mean_loss=0.02804610342718661
Online_Training [168/700]: mean_loss=0.029655908001586795
Online_Training [169/700]: mean_loss=0.052160569466650486
Online_Training [170/700]: mean_loss=0.16843408532440662
Online_Training [171/700]: mean_loss=0.013344705454073846
Online_Training [172/700]: mean_loss=0.016843290766701102
Online_Training [173/700]: mean_loss=0.022918239003047347
Online_Training [174/700]: mean_loss=0.013109652092680335
Online_Training [175/700]: mean_loss=0.011286754510365427
Online_Training [176/700]: mean_loss=0.0064472961239516735
Online_Training [177/700]: mean_loss=0.024160676635801792
Online_Training [178/700]: mean_loss=0.033192279282957315
Online_Training [179/700]: mean_loss=0.027240863535553217
Online_Training [180/700]: mean_loss=0.017277618288062513
Online_Training [181/700]: mean_loss=0.018082289258018136
Online_Training [182/700]: mean_loss=0.030169940320774913
Online_Training [183/700]: mean_loss=0.013456282555125654
Online_Training [184/700]: mean_loss=0.004494228691328317
Online_Training [185/700]: mean_loss=0.02920872112736106
Online_Training [186/700]: mean_loss=0.03480723546817899
Online_Training [187/700]: mean_loss=0.022260761121287942
Online_Training [188/700]: mean_loss=0.022017809562385082
Online_Training [189/700]: mean_loss=0.061847036238759756
Online_Training [190/700]: mean_loss=0.01669675367884338
Online_Training [191/700]: mean_loss=0.13120813947170973
Online_Training [192/700]: mean_loss=0.024205104215070605
Online_Training [193/700]: mean_loss=0.018650580430403352
Online_Training [194/700]: mean_loss=0.0067844256409443915
Online_Training [195/700]: mean_loss=0.031701748026534915
Online_Training [196/700]: mean_loss=0.014142322354018688
Online_Training [197/700]: mean_loss=0.028713850071653724
Online_Training [198/700]: mean_loss=0.016908990684896708
Online_Training [199/700]: mean_loss=0.09544094931334257
Online_Training [200/700]: mean_loss=0.02153215976431966
Online_Training [201/700]: mean_loss=0.02474498492665589
Online_Training [202/700]: mean_loss=0.01615876262076199
Online_Training [203/700]: mean_loss=0.009554024203680456
Online_Training [204/700]: mean_loss=0.011170772835612297
Online_Training [205/700]: mean_loss=0.059713393449783325
Online_Training [206/700]: mean_loss=0.01269367418717593
Online_Training [207/700]: mean_loss=0.05342452693730593
Online_Training [208/700]: mean_loss=0.035674838814884424
Online_Training [209/700]: mean_loss=0.056765332352370024
Online_Training [210/700]: mean_loss=0.023445915896445513
Online_Training [211/700]: mean_loss=0.010571773746050894
Online_Training [212/700]: mean_loss=0.09137034602463245
Online_Training [213/700]: mean_loss=0.03959790291264653
Online_Training [214/700]: mean_loss=0.01168387127108872
Online_Training [215/700]: mean_loss=0.02861838578246534
Online_Training [216/700]: mean_loss=0.032508915988728404
Online_Training [217/700]: mean_loss=0.011225227732211351
Online_Training [218/700]: mean_loss=0.007338320778217167
Online_Training [219/700]: mean_loss=0.05681216670200229
Online_Training [220/700]: mean_loss=0.01340474933385849
Online_Training [221/700]: mean_loss=0.033530586399137974
Online_Training [222/700]: mean_loss=0.012256549904122949
Online_Training [223/700]: mean_loss=0.027298841159790754
Online_Training [224/700]: mean_loss=0.00725813617464155
Online_Training [225/700]: mean_loss=0.028700978960841894
Online_Training [226/700]: mean_loss=0.031028276542201638
Online_Training [227/700]: mean_loss=0.01625208556652069
Online_Training [228/700]: mean_loss=0.021070544607937336
Online_Training [229/700]: mean_loss=0.036840508691966534
Online_Training [230/700]: mean_loss=0.01373518817126751
Online_Training [231/700]: mean_loss=0.0192628160584718
Online_Training [232/700]: mean_loss=0.01473708648700267
Online_Training [233/700]: mean_loss=0.011288632755167782
Online_Training [234/700]: mean_loss=0.021163932979106903
Online_Training [235/700]: mean_loss=0.07926929462701082
Online_Training [236/700]: mean_loss=0.05348865268751979
Online_Training [237/700]: mean_loss=0.027577412314713
Online_Training [238/700]: mean_loss=0.08410351723432541
Online_Training [239/700]: mean_loss=0.06755707412958145
Online_Training [240/700]: mean_loss=0.04162068502046168
Online_Training [241/700]: mean_loss=0.037916508968919516
Online_Training [242/700]: mean_loss=0.03721734252758324
Online_Training [243/700]: mean_loss=0.03981593856588006
Online_Training [244/700]: mean_loss=0.01601488550659269
Online_Training [245/700]: mean_loss=0.02773287449963391
Online_Training [246/700]: mean_loss=0.013640580582432449
Online_Training [247/700]: mean_loss=0.011842629173770547
Online_Training [248/700]: mean_loss=0.07515668030828238
Online_Training [249/700]: mean_loss=0.011236776714213192
Online_Training [250/700]: mean_loss=0.018607172882184386
Online_Training [251/700]: mean_loss=0.013714086497202516
Online_Training [252/700]: mean_loss=0.022697342559695244
Online_Training [253/700]: mean_loss=0.01151083956938237
Online_Training [254/700]: mean_loss=0.021223146468400955
Online_Training [255/700]: mean_loss=0.03959177155047655
Online_Training [256/700]: mean_loss=0.02082297287415713
Online_Training [257/700]: mean_loss=0.017482547089457512
Online_Training [258/700]: mean_loss=0.02393901185132563
Online_Training [259/700]: mean_loss=0.009607150917872787
Online_Training [260/700]: mean_loss=0.011512973345816135
Online_Training [261/700]: mean_loss=0.024882966419681907
Online_Training [262/700]: mean_loss=0.024430579505860806
Online_Training [263/700]: mean_loss=0.011604306753724813
Online_Training [264/700]: mean_loss=0.02276259264908731
Online_Training [265/700]: mean_loss=0.013457422377541661
Online_Training [266/700]: mean_loss=0.012528117164038122
Online_Training [267/700]: mean_loss=0.016313579748384655
Online_Training [268/700]: mean_loss=0.005848518863786012
Online_Training [269/700]: mean_loss=0.019785170443356037
Online_Training [270/700]: mean_loss=0.014561849413439631
Online_Training [271/700]: mean_loss=0.023030088050290942
Online_Training [272/700]: mean_loss=0.011428847443312407
Online_Training [273/700]: mean_loss=0.013588512083515525
Online_Training [274/700]: mean_loss=0.006513487838674337
Online_Training [275/700]: mean_loss=0.014201173791661859
Online_Training [276/700]: mean_loss=0.010800518211908638
Online_Training [277/700]: mean_loss=0.0266466720495373
Online_Training [278/700]: mean_loss=0.026848586974665523
Online_Training [279/700]: mean_loss=0.013831149321049452
Online_Training [280/700]: mean_loss=0.024405907606706023
Online_Training [281/700]: mean_loss=0.02700559888035059
Online_Training [282/700]: mean_loss=0.03243282367475331
Online_Training [283/700]: mean_loss=0.026517734164372087
Online_Training [284/700]: mean_loss=0.01617067342158407
Online_Training [285/700]: mean_loss=0.02087015425786376
Online_Training [286/700]: mean_loss=0.0142162695992738
Online_Training [287/700]: mean_loss=0.019742883276194334
Online_Training [288/700]: mean_loss=0.015134457964450121
Online_Training [289/700]: mean_loss=0.03528604609891772
Online_Training [290/700]: mean_loss=0.008699605357833207
Online_Training [291/700]: mean_loss=0.010439540725201368
Online_Training [292/700]: mean_loss=0.00756797578651458
Online_Training [293/700]: mean_loss=0.01217447908129543
Online_Training [294/700]: mean_loss=0.01263829239178449
Online_Training [295/700]: mean_loss=0.03578045847825706
Online_Training [296/700]: mean_loss=0.03509032493457198
Online_Training [297/700]: mean_loss=0.020641335751861334
Online_Training [298/700]: mean_loss=0.01736549730412662
Online_Training [299/700]: mean_loss=0.013163090101443231
Online_Training [300/700]: mean_loss=0.04114024480804801
Online_Training [301/700]: mean_loss=0.012983968365006149
Online_Training [302/700]: mean_loss=0.019471610197797418
Online_Training [303/700]: mean_loss=0.017272063763812184
Online_Training [304/700]: mean_loss=0.011921456549316645
Online_Training [305/700]: mean_loss=0.050831008702516556
Online_Training [306/700]: mean_loss=0.060880523175001144
Online_Training [307/700]: mean_loss=0.06464523496106267
Online_Training [308/700]: mean_loss=0.0223463571164757
Online_Training [309/700]: mean_loss=0.011992471758276224
Online_Training [310/700]: mean_loss=0.007473254052456468
Online_Training [311/700]: mean_loss=0.013313072733581066
Online_Training [312/700]: mean_loss=0.05327356467023492
Online_Training [313/700]: mean_loss=0.015688294428400695
Online_Training [314/700]: mean_loss=0.010138302808627486
Online_Training [315/700]: mean_loss=0.007177119608968496
Online_Training [316/700]: mean_loss=0.014927330776117742
Online_Training [317/700]: mean_loss=0.008161001140251756
Online_Training [318/700]: mean_loss=0.01482961606234312
Online_Training [319/700]: mean_loss=0.019506620476022363
Online_Training [320/700]: mean_loss=0.013420402887277305
Online_Training [321/700]: mean_loss=0.02111785300076008
Online_Training [322/700]: mean_loss=0.03466998087242246
Online_Training [323/700]: mean_loss=0.023004350252449512
Online_Training [324/700]: mean_loss=0.029729421017691493
Online_Training [325/700]: mean_loss=0.030278785387054086
Online_Training [326/700]: mean_loss=0.013686185702681541
Online_Training [327/700]: mean_loss=0.023114588344469666
Online_Training [328/700]: mean_loss=0.024088774109259248
Online_Training [329/700]: mean_loss=0.010183436330407858
Online_Training [330/700]: mean_loss=0.027189667569473386
Online_Training [331/700]: mean_loss=0.0193988619139418
Online_Training [332/700]: mean_loss=0.0203578588552773
Online_Training [333/700]: mean_loss=0.011160094873048365
Online_Training [334/700]: mean_loss=0.00878826528787613
Online_Training [335/700]: mean_loss=0.06470909062772989
Online_Training [336/700]: mean_loss=0.05147838266566396
Online_Training [337/700]: mean_loss=0.06715878285467625
Online_Training [338/700]: mean_loss=0.025773207424208522
Online_Training [339/700]: mean_loss=0.012426186818629503
Online_Training [340/700]: mean_loss=0.007904389523901045
Online_Training [341/700]: mean_loss=0.022765701171010733
Online_Training [342/700]: mean_loss=0.0426777652464807
Online_Training [343/700]: mean_loss=0.012615372776053846
Online_Training [344/700]: mean_loss=0.020075177075341344
Online_Training [345/700]: mean_loss=0.025343033950775862
Online_Training [346/700]: mean_loss=0.017232749611139297
Online_Training [347/700]: mean_loss=0.12978612072765827
Online_Training [348/700]: mean_loss=0.015449167927727103
Online_Training [349/700]: mean_loss=0.029504489619284868
Online_Training [350/700]: mean_loss=0.014141806401312351
Online_Training [351/700]: mean_loss=0.010132431169040501
Online_Training [352/700]: mean_loss=0.009428117424249649
Online_Training [353/700]: mean_loss=0.01349261892028153
Online_Training [354/700]: mean_loss=0.012958269682712853
Online_Training [355/700]: mean_loss=0.010113288415595889
Online_Training [356/700]: mean_loss=0.01427865563891828
Online_Training [357/700]: mean_loss=0.07717348914593458
Online_Training [358/700]: mean_loss=0.06516783498227596
Online_Training [359/700]: mean_loss=0.09296832513064146
Online_Training [360/700]: mean_loss=0.02678916370496154
Online_Training [361/700]: mean_loss=0.025285582523792982
Online_Training [362/700]: mean_loss=0.055500040762126446
Online_Training [363/700]: mean_loss=0.017303514061495662
Online_Training [364/700]: mean_loss=0.011485137278214097
Online_Training [365/700]: mean_loss=0.01649131055455655
Online_Training [366/700]: mean_loss=0.01936401450075209
Online_Training [367/700]: mean_loss=0.019189733313396573
Online_Training [368/700]: mean_loss=0.01641380274668336
Online_Training [369/700]: mean_loss=0.01466976385563612
Online_Training [370/700]: mean_loss=0.037747019436210394
Online_Training [371/700]: mean_loss=0.006631853699218482
Online_Training [372/700]: mean_loss=0.02357717091217637
Online_Training [373/700]: mean_loss=0.019264024449512362
Online_Training [374/700]: mean_loss=0.0153911606175825
Online_Training [375/700]: mean_loss=0.0190945144277066
Online_Training [376/700]: mean_loss=0.009651232976466417
Online_Training [377/700]: mean_loss=0.018962721107527614
Online_Training [378/700]: mean_loss=0.017002184875309467
Online_Training [379/700]: mean_loss=0.025496302638202906
Online_Training [380/700]: mean_loss=0.011188316391780972
Online_Training [381/700]: mean_loss=0.017378862714394927
Online_Training [382/700]: mean_loss=0.008701349375769496
Online_Training [383/700]: mean_loss=0.008043228590395302
Online_Training [384/700]: mean_loss=0.13834448996931314
Online_Training [385/700]: mean_loss=0.00658295868197456
Online_Training [386/700]: mean_loss=0.027513654436916113
Online_Training [387/700]: mean_loss=0.020100781694054604
Online_Training [388/700]: mean_loss=0.020631333347409964
Online_Training [389/700]: mean_loss=0.007077515707351267
Online_Training [390/700]: mean_loss=0.03077576612122357
Online_Training [391/700]: mean_loss=0.009170489094685763
Online_Training [392/700]: mean_loss=0.022447442868724465
Online_Training [393/700]: mean_loss=0.015443525626324117
Online_Training [394/700]: mean_loss=0.024266141233965755
Online_Training [395/700]: mean_loss=0.008458145428448915
Online_Training [396/700]: mean_loss=0.02078367955982685
Online_Training [397/700]: mean_loss=0.009970533312298357
Online_Training [398/700]: mean_loss=0.021901228232309222
Online_Training [399/700]: mean_loss=0.023196225287392735
Online_Training [400/700]: mean_loss=0.030418818583711982
Online_Training [401/700]: mean_loss=0.010399095946922898
Online_Training [402/700]: mean_loss=0.011973929824307561
Online_Training [403/700]: mean_loss=0.008494254667311907
Online_Training [404/700]: mean_loss=0.0511520360596478
Online_Training [405/700]: mean_loss=0.06981641845777631
Online_Training [406/700]: mean_loss=0.017194529878906906
Online_Training [407/700]: mean_loss=0.02669157600030303
Online_Training [408/700]: mean_loss=0.015886975801549852
Online_Training [409/700]: mean_loss=0.007107896206434816
Online_Training [410/700]: mean_loss=0.02267710887826979
Online_Training [411/700]: mean_loss=0.020783898886293173
Online_Training [412/700]: mean_loss=0.101833819411695
Online_Training [413/700]: mean_loss=0.024433349492028356
Online_Training [414/700]: mean_loss=0.022700949106365442
Online_Training [415/700]: mean_loss=0.024165757233276963
Online_Training [416/700]: mean_loss=0.017729916609823704
Online_Training [417/700]: mean_loss=0.055592992808669806
Online_Training [418/700]: mean_loss=0.012109850766137242
Online_Training [419/700]: mean_loss=0.010333082173019648
Online_Training [420/700]: mean_loss=0.0499207591637969
Online_Training [421/700]: mean_loss=0.030079204821959138
Online_Training [422/700]: mean_loss=0.015863025677390397
Online_Training [423/700]: mean_loss=0.029681343119591475
Online_Training [424/700]: mean_loss=0.05345017137005925
Online_Training [425/700]: mean_loss=0.025418754434213042
Online_Training [426/700]: mean_loss=0.011454605613835156
Online_Training [427/700]: mean_loss=0.017866272013634443
Online_Training [428/700]: mean_loss=0.024061688454821706
Online_Training [429/700]: mean_loss=0.01179334381595254
Online_Training [430/700]: mean_loss=0.008128165500238538
Online_Training [431/700]: mean_loss=0.011446151649579406
Online_Training [432/700]: mean_loss=0.11258712504059076
Online_Training [433/700]: mean_loss=0.02628482854925096
Online_Training [434/700]: mean_loss=0.04508342663757503
Online_Training [435/700]: mean_loss=0.030266699381172657
Online_Training [436/700]: mean_loss=0.0862129395827651
Online_Training [437/700]: mean_loss=0.012398271006532013
Online_Training [438/700]: mean_loss=0.10379423946142197
Online_Training [439/700]: mean_loss=0.052582730539143085
Online_Training [440/700]: mean_loss=0.037306059151887894
Online_Training [441/700]: mean_loss=0.03063902910798788
Online_Training [442/700]: mean_loss=0.007818829908501357
Online_Training [443/700]: mean_loss=0.017049329355359077
Online_Training [444/700]: mean_loss=0.029050125973299146
Online_Training [445/700]: mean_loss=0.024644687306135893
Online_Training [446/700]: mean_loss=0.02866321406327188
Online_Training [447/700]: mean_loss=0.010003376752138138
Online_Training [448/700]: mean_loss=0.021687223576009274
Online_Training [449/700]: mean_loss=0.020495325326919556
Online_Training [450/700]: mean_loss=0.029734300915151834
Online_Training [451/700]: mean_loss=0.0198714560829103
Online_Training [452/700]: mean_loss=0.04070481425151229
Online_Training [453/700]: mean_loss=0.06363952811807394
Online_Training [454/700]: mean_loss=0.020651525352150202
Online_Training [455/700]: mean_loss=0.05539212189614773
Online_Training [456/700]: mean_loss=0.009543285705149174
Online_Training [457/700]: mean_loss=0.007617339084390551
Online_Training [458/700]: mean_loss=0.009960840339772403
Online_Training [459/700]: mean_loss=0.011373003711923957
Online_Training [460/700]: mean_loss=0.02106154477223754
Online_Training [461/700]: mean_loss=0.02349193161353469
Online_Training [462/700]: mean_loss=0.012827204423956573
Online_Training [463/700]: mean_loss=0.007677188375964761
Online_Training [464/700]: mean_loss=0.016909203259274364
Online_Training [465/700]: mean_loss=0.05414700275287032
Online_Training [466/700]: mean_loss=0.019493478117510676
Online_Training [467/700]: mean_loss=0.014054879429750144
Online_Training [468/700]: mean_loss=0.016545675578527153
Online_Training [469/700]: mean_loss=0.0327463299036026
Online_Training [470/700]: mean_loss=0.06225186912342906
Online_Training [471/700]: mean_loss=0.023735563037917018
Online_Training [472/700]: mean_loss=0.03133557690307498
Online_Training [473/700]: mean_loss=0.005946354183834046
Online_Training [474/700]: mean_loss=0.011826033587567508
Online_Training [475/700]: mean_loss=0.009895718074403703
Online_Training [476/700]: mean_loss=0.16954425908625126
Online_Training [477/700]: mean_loss=0.07993089500814676
Online_Training [478/700]: mean_loss=0.03305796813219786
Online_Training [479/700]: mean_loss=0.012563986354507506
Online_Training [480/700]: mean_loss=0.010640504071488976
Online_Training [481/700]: mean_loss=0.016720482613891363
Online_Training [482/700]: mean_loss=0.02180474973283708
Online_Training [483/700]: mean_loss=0.016313179163262248
Online_Training [484/700]: mean_loss=0.016062618233263493
Online_Training [485/700]: mean_loss=0.00812379689887166
Online_Training [486/700]: mean_loss=0.016023339005187154
Online_Training [487/700]: mean_loss=0.03326484840363264
Online_Training [488/700]: mean_loss=0.018408677307888865
Online_Training [489/700]: mean_loss=0.015161313931457698
Online_Training [490/700]: mean_loss=0.021976850228384137
Online_Training [491/700]: mean_loss=0.03631700249388814
Online_Training [492/700]: mean_loss=0.015412970446050167
Online_Training [493/700]: mean_loss=0.017642531194724143
Online_Training [494/700]: mean_loss=0.04768137680366635
Online_Training [495/700]: mean_loss=0.011235140555072576
Online_Training [496/700]: mean_loss=0.03126179147511721
Online_Training [497/700]: mean_loss=0.017343565239571035
Online_Training [498/700]: mean_loss=0.015607078559696674
Online_Training [499/700]: mean_loss=0.01805116841569543
Online_Training [500/700]: mean_loss=0.009337431751191616
Online_Training [501/700]: mean_loss=0.014317687368020415
Online_Training [502/700]: mean_loss=0.022302159573882818
Online_Training [503/700]: mean_loss=0.014718008693307638
Online_Training [504/700]: mean_loss=0.011149706551805139
Online_Training [505/700]: mean_loss=0.014448783011175692
Online_Training [506/700]: mean_loss=0.0915075708180666
Online_Training [507/700]: mean_loss=0.06454529520124197
Online_Training [508/700]: mean_loss=0.034653546288609505
Online_Training [509/700]: mean_loss=0.014549478539265692
Online_Training [510/700]: mean_loss=0.02561410842463374
Online_Training [511/700]: mean_loss=0.003931000072043389
Online_Training [512/700]: mean_loss=0.008153886534273624
Online_Training [513/700]: mean_loss=0.03602595208212733
Online_Training [514/700]: mean_loss=0.020941460272297263
Online_Training [515/700]: mean_loss=0.02962336945347488
Online_Training [516/700]: mean_loss=0.0175192563328892
Online_Training [517/700]: mean_loss=0.03012183215469122
Online_Training [518/700]: mean_loss=0.019771111896261573
Online_Training [519/700]: mean_loss=0.009390932274982333
Online_Training [520/700]: mean_loss=0.014722015359438956
Online_Training [521/700]: mean_loss=0.032981414813548326
Online_Training [522/700]: mean_loss=0.010824501630850136
Online_Training [523/700]: mean_loss=0.022650996688753366
Online_Training [524/700]: mean_loss=0.0744456434622407
Online_Training [525/700]: mean_loss=0.022347673773765564
Online_Training [526/700]: mean_loss=0.014784592320211232
Online_Training [527/700]: mean_loss=0.01675205398350954
Online_Training [528/700]: mean_loss=0.020772084593772888
Online_Training [529/700]: mean_loss=0.02521729632280767
Online_Training [530/700]: mean_loss=0.017276474740356207
Online_Training [531/700]: mean_loss=0.0235289609991014
Online_Training [532/700]: mean_loss=0.027393797179684043
Online_Training [533/700]: mean_loss=0.009934458881616592
Online_Training [534/700]: mean_loss=0.012204877915792167
Online_Training [535/700]: mean_loss=0.02610996668227017
Online_Training [536/700]: mean_loss=0.10361254401504993
Online_Training [537/700]: mean_loss=0.013468061806634068
Online_Training [538/700]: mean_loss=0.0168200716143474
Online_Training [539/700]: mean_loss=0.011208082898519933
Online_Training [540/700]: mean_loss=0.031917241867631674
Online_Training [541/700]: mean_loss=0.1085160942748189
Online_Training [542/700]: mean_loss=0.019963201484642923
Online_Training [543/700]: mean_loss=0.030328811379149556
Online_Training [544/700]: mean_loss=0.016307341633364558
Online_Training [545/700]: mean_loss=0.025308406678959727
Online_Training [546/700]: mean_loss=0.009768339223228395
Online_Training [547/700]: mean_loss=0.014117428101599216
Online_Training [548/700]: mean_loss=0.029271234525367618
Online_Training [549/700]: mean_loss=0.009052934707142413
Online_Training [550/700]: mean_loss=0.028615797637030482
Online_Training [551/700]: mean_loss=0.022677314234897494
Online_Training [552/700]: mean_loss=0.02783075114712119
Online_Training [553/700]: mean_loss=0.0441558244638145
Online_Training [554/700]: mean_loss=0.019198966911062598
Online_Training [555/700]: mean_loss=0.030248337658122182
Online_Training [556/700]: mean_loss=0.01873824605718255
Online_Training [557/700]: mean_loss=0.015638331416994333
Online_Training [558/700]: mean_loss=0.0062810140661895275
Online_Training [559/700]: mean_loss=0.011447837168816477
Online_Training [560/700]: mean_loss=0.009851389797404408
Online_Training [561/700]: mean_loss=0.019845033064484596
Online_Training [562/700]: mean_loss=0.034633989445865154
Online_Training [563/700]: mean_loss=0.03574897488579154
Online_Training [564/700]: mean_loss=0.011626492138020694
Online_Training [565/700]: mean_loss=0.0208509573712945
Online_Training [566/700]: mean_loss=0.016890574363060296
Online_Training [567/700]: mean_loss=0.028501532739028335
Online_Training [568/700]: mean_loss=0.01920926640741527
Online_Training [569/700]: mean_loss=0.025035300524905324
Online_Training [570/700]: mean_loss=0.01022121065761894
Online_Training [571/700]: mean_loss=0.02013653260655701
Online_Training [572/700]: mean_loss=0.016480486025102437
Online_Training [573/700]: mean_loss=0.030122342752292752
Online_Training [574/700]: mean_loss=0.05443206150084734
Online_Training [575/700]: mean_loss=0.056476259138435125
Online_Training [576/700]: mean_loss=0.010867128265090287
Online_Training [577/700]: mean_loss=0.017622244311496615
Online_Training [578/700]: mean_loss=0.008354777353815734
Online_Training [579/700]: mean_loss=0.021298893494531512
Online_Training [580/700]: mean_loss=0.03134479187428951
Online_Training [581/700]: mean_loss=0.020810290705412626
Online_Training [582/700]: mean_loss=0.009349833650048822
Online_Training [583/700]: mean_loss=0.008241330040618777
Online_Training [584/700]: mean_loss=0.012685128254815936
Online_Training [585/700]: mean_loss=0.02645773347467184
Online_Training [586/700]: mean_loss=0.10244423989206553
Online_Training [587/700]: mean_loss=0.02495153760537505
Online_Training [588/700]: mean_loss=0.008090721152257174
Online_Training [589/700]: mean_loss=0.02744351699948311
Online_Training [590/700]: mean_loss=0.025995832169428468
Online_Training [591/700]: mean_loss=0.015726545825600624
Online_Training [592/700]: mean_loss=0.015204589115455747
Online_Training [593/700]: mean_loss=0.038292286451905966
Online_Training [594/700]: mean_loss=0.020250648260116577
Online_Training [595/700]: mean_loss=0.032280709594488144
Online_Training [596/700]: mean_loss=0.009685229742899537
Online_Training [597/700]: mean_loss=0.008659806160721928
Online_Training [598/700]: mean_loss=0.01645118638407439
Online_Training [599/700]: mean_loss=0.023251956328749657
Online_Training [600/700]: mean_loss=0.012771210982464254
Online_Training [601/700]: mean_loss=0.036400921642780304
Online_Training [602/700]: mean_loss=0.008045361028052866
Online_Training [603/700]: mean_loss=0.008561226655729115
Online_Training [604/700]: mean_loss=0.02519671944901347
Online_Training [605/700]: mean_loss=0.00997881917282939
Online_Training [606/700]: mean_loss=0.0040198033675551414
Online_Training [607/700]: mean_loss=0.009328437969088554
Online_Training [608/700]: mean_loss=0.012269726023077965
Online_Training [609/700]: mean_loss=0.013241710606962442
Online_Training [610/700]: mean_loss=0.01951241446658969
Online_Training [611/700]: mean_loss=0.009571581613272429
Online_Training [612/700]: mean_loss=0.11806098092347383
Online_Training [613/700]: mean_loss=0.05480937613174319
Online_Training [614/700]: mean_loss=0.010195328621193767
Online_Training [615/700]: mean_loss=0.010231084772385657
Online_Training [616/700]: mean_loss=0.021996906027197838
Online_Training [617/700]: mean_loss=0.004052461823448539
Online_Training [618/700]: mean_loss=0.020604355726391077
Online_Training [619/700]: mean_loss=0.014564930577762425
Online_Training [620/700]: mean_loss=0.08169279061257839
Online_Training [621/700]: mean_loss=0.00745844526682049
Online_Training [622/700]: mean_loss=0.051763932686299086
Online_Training [623/700]: mean_loss=0.03942938707768917
Online_Training [624/700]: mean_loss=0.01628899446222931
Online_Training [625/700]: mean_loss=0.01346044207457453
Online_Training [626/700]: mean_loss=0.010153524694032967
Online_Training [627/700]: mean_loss=0.008819908020086586
Online_Training [628/700]: mean_loss=0.009900603792630136
Online_Training [629/700]: mean_loss=0.02825651573948562
Online_Training [630/700]: mean_loss=0.04067932581529021
Online_Training [631/700]: mean_loss=0.011794403195381165
Online_Training [632/700]: mean_loss=0.020307609345763922
Online_Training [633/700]: mean_loss=0.009670927771367133
Online_Training [634/700]: mean_loss=0.02379094110801816
Online_Training [635/700]: mean_loss=0.022976707783527672
Online_Training [636/700]: mean_loss=0.008363373694010079
Online_Training [637/700]: mean_loss=0.011249751201830804
Online_Training [638/700]: mean_loss=0.026548629626631737
Online_Training [639/700]: mean_loss=0.02047964744269848
Online_Training [640/700]: mean_loss=0.006300793669652194
Online_Training [641/700]: mean_loss=0.02271835831925273
Online_Training [642/700]: mean_loss=0.011925166356377304
Online_Training [643/700]: mean_loss=0.009181237546727061
Online_Training [644/700]: mean_loss=0.01228873257059604
Online_Training [645/700]: mean_loss=0.016466765431687236
Online_Training [646/700]: mean_loss=0.040190115105360746
Online_Training [647/700]: mean_loss=0.00964288308750838
Online_Training [648/700]: mean_loss=0.015373617177829146
Online_Training [649/700]: mean_loss=0.00871936755720526
Online_Training [650/700]: mean_loss=0.015402177581563592
Online_Training [651/700]: mean_loss=0.008160202647559345
Online_Training [652/700]: mean_loss=0.006883367022965103
Online_Training [653/700]: mean_loss=0.10642050579190254
Online_Training [654/700]: mean_loss=0.01767691143322736
Online_Training [655/700]: mean_loss=0.01851726626046002
Online_Training [656/700]: mean_loss=0.024263849947601557
Online_Training [657/700]: mean_loss=0.019281333312392235
Online_Training [658/700]: mean_loss=0.0161284226924181
Online_Training [659/700]: mean_loss=0.012732588686048985
Online_Training [660/700]: mean_loss=0.014338328619487584
Online_Training [661/700]: mean_loss=0.04044304555281997
Online_Training [662/700]: mean_loss=0.0429798592813313
Online_Training [663/700]: mean_loss=0.023176800226792693
Online_Training [664/700]: mean_loss=0.005818690755404532
Online_Training [665/700]: mean_loss=0.037000028882175684
Online_Training [666/700]: mean_loss=0.02311829151585698
Online_Training [667/700]: mean_loss=0.006090271868743002
Online_Training [668/700]: mean_loss=0.009122583316639066
Online_Training [669/700]: mean_loss=0.009055707894731313
Online_Training [670/700]: mean_loss=0.013260065694339573
Online_Training [671/700]: mean_loss=0.01826488832011819
Online_Training [672/700]: mean_loss=0.012424713582731783
Online_Training [673/700]: mean_loss=0.011466347612440586
Online_Training [674/700]: mean_loss=0.013916647876612842
Online_Training [675/700]: mean_loss=0.01489143946673721
Online_Training [676/700]: mean_loss=0.030462903901934624
Online_Training [677/700]: mean_loss=0.04734386736527085
Online_Training [678/700]: mean_loss=0.02175169438123703
Online_Training [679/700]: mean_loss=0.017919886391609907
Online_Training [680/700]: mean_loss=0.017516840482130647
Online_Training [681/700]: mean_loss=0.02275605476461351
Online_Training [682/700]: mean_loss=0.013389143394306302
Online_Training [683/700]: mean_loss=0.007880185672547668
Online_Training [684/700]: mean_loss=0.004571933764964342
Online_Training [685/700]: mean_loss=0.02638570684939623
Online_Training [686/700]: mean_loss=0.011580683523789048
Online_Training [687/700]: mean_loss=0.013627611100673676
Online_Training [688/700]: mean_loss=0.05397349875420332
Online_Training [689/700]: mean_loss=0.01068675285205245
Online_Training [690/700]: mean_loss=0.005823018203955144
Online_Training [691/700]: mean_loss=0.012669305549934506
Online_Training [692/700]: mean_loss=0.021242299349978566
Online_Training [693/700]: mean_loss=0.010379409999586642
Online_Training [694/700]: mean_loss=0.034200394526124
Online_Training [695/700]: mean_loss=0.010644779889844358
Online_Training [696/700]: mean_loss=0.0332547971047461
Online_Training [697/700]: mean_loss=0.003473527845926583
Online_Training [698/700]: mean_loss=0.007509354734793305
Online_Training [699/700]: mean_loss=0.051417406648397446
Online_Training [700/700]: mean_loss=0.006331688025966287
Q_Learning [1/300]: mean_loss=0.20289978198707104
Q_Learning [2/300]: mean_loss=0.2343860510736704
Q_Learning [3/300]: mean_loss=0.1887986045330763
Q_Learning [4/300]: mean_loss=0.08767408318817616
Q_Learning [5/300]: mean_loss=0.2867974787950516
Q_Learning [6/300]: mean_loss=0.09930925816297531
Q_Learning [7/300]: mean_loss=0.1253615990281105
Q_Learning [8/300]: mean_loss=0.09804243315011263
Q_Learning [9/300]: mean_loss=0.2015311513096094
Q_Learning [10/300]: mean_loss=0.1556899156421423
Q_Learning [11/300]: mean_loss=0.10435397271066904
Q_Learning [12/300]: mean_loss=0.08603474963456392
Q_Learning [13/300]: mean_loss=0.11063926480710506
Q_Learning [14/300]: mean_loss=0.0767221124842763
Q_Learning [15/300]: mean_loss=0.08214706648141146
Q_Learning [16/300]: mean_loss=0.14106674306094646
Q_Learning [17/300]: mean_loss=0.14528338983654976
Q_Learning [18/300]: mean_loss=0.08335058763623238
Q_Learning [19/300]: mean_loss=0.03328718896955252
Q_Learning [20/300]: mean_loss=0.18070121482014656
Q_Learning [21/300]: mean_loss=0.1269052717834711
Q_Learning [22/300]: mean_loss=0.055027950555086136
Q_Learning [23/300]: mean_loss=0.02678764541633427
Q_Learning [24/300]: mean_loss=0.1034324737265706
Q_Learning [25/300]: mean_loss=0.043375723995268345
Q_Learning [26/300]: mean_loss=0.051283631939440966
Q_Learning [27/300]: mean_loss=0.10374834667891264
Q_Learning [28/300]: mean_loss=0.04942118376493454
Q_Learning [29/300]: mean_loss=0.0475303758867085
Q_Learning [30/300]: mean_loss=0.032496586907655
Q_Learning [31/300]: mean_loss=0.028675551060587168
Q_Learning [32/300]: mean_loss=0.0407429994083941
Q_Learning [33/300]: mean_loss=0.021785105811432004
Q_Learning [34/300]: mean_loss=0.15441140159964561
Q_Learning [35/300]: mean_loss=0.05085064982995391
Q_Learning [36/300]: mean_loss=0.08723342325538397
Q_Learning [37/300]: mean_loss=0.05826224107295275
Q_Learning [38/300]: mean_loss=0.036984095349907875
Q_Learning [39/300]: mean_loss=0.13022209703922272
Q_Learning [40/300]: mean_loss=0.03305424749851227
Q_Learning [41/300]: mean_loss=0.025106780230998993
Q_Learning [42/300]: mean_loss=0.05110158445313573
Q_Learning [43/300]: mean_loss=0.1238044248893857
Q_Learning [44/300]: mean_loss=0.140014773234725
Q_Learning [45/300]: mean_loss=0.07618582621216774
Q_Learning [46/300]: mean_loss=0.03867698786780238
Q_Learning [47/300]: mean_loss=0.08130376134067774
Q_Learning [48/300]: mean_loss=0.0691313510760665
Q_Learning [49/300]: mean_loss=0.0799879739060998
Q_Learning [50/300]: mean_loss=0.08902482315897942
Q_Learning [51/300]: mean_loss=0.026794853154569864
Q_Learning [52/300]: mean_loss=0.12991630751639605
Q_Learning [53/300]: mean_loss=0.02017418947070837
Q_Learning [54/300]: mean_loss=0.05549170123413205
Q_Learning [55/300]: mean_loss=0.027849938720464706
Q_Learning [56/300]: mean_loss=0.034272815100848675
Q_Learning [57/300]: mean_loss=0.07352377893403172
Q_Learning [58/300]: mean_loss=0.17734269425272942
Q_Learning [59/300]: mean_loss=0.07658398803323507
Q_Learning [60/300]: mean_loss=0.048362609930336475
Q_Learning [61/300]: mean_loss=0.022089247591793537
Q_Learning [62/300]: mean_loss=0.0872308649122715
Q_Learning [63/300]: mean_loss=0.06225581327453256
Q_Learning [64/300]: mean_loss=0.007305219856789336
Q_Learning [65/300]: mean_loss=0.06736573250964284
Q_Learning [66/300]: mean_loss=0.04113472905009985
Q_Learning [67/300]: mean_loss=0.06343947350978851
Q_Learning [68/300]: mean_loss=0.023809265112504363
Q_Learning [69/300]: mean_loss=0.05376687739044428
Q_Learning [70/300]: mean_loss=0.03678895020857453
Q_Learning [71/300]: mean_loss=0.07650919072329998
Q_Learning [72/300]: mean_loss=0.07487366255372763
Q_Learning [73/300]: mean_loss=0.03678721166215837
Q_Learning [74/300]: mean_loss=0.03818777436390519
Q_Learning [75/300]: mean_loss=0.027975939447060227
Q_Learning [76/300]: mean_loss=0.015856350190006196
Q_Learning [77/300]: mean_loss=0.03294488089159131
Q_Learning [78/300]: mean_loss=0.020010209176689386
Q_Learning [79/300]: mean_loss=0.029775191331282258
Q_Learning [80/300]: mean_loss=0.030857541598379612
Q_Learning [81/300]: mean_loss=0.0181997986510396
Q_Learning [82/300]: mean_loss=0.02651878632605076
Q_Learning [83/300]: mean_loss=0.03446955839172006
Q_Learning [84/300]: mean_loss=0.02475613891147077
Q_Learning [85/300]: mean_loss=0.02712519676424563
Q_Learning [86/300]: mean_loss=0.03429840668104589
Q_Learning [87/300]: mean_loss=0.015559598919935524
Q_Learning [88/300]: mean_loss=0.029257234884425998
Q_Learning [89/300]: mean_loss=0.03892990294843912
Q_Learning [90/300]: mean_loss=0.019268746254965663
Q_Learning [91/300]: mean_loss=0.03132719243876636
Q_Learning [92/300]: mean_loss=0.041606365237385035
Q_Learning [93/300]: mean_loss=0.02674734010361135
Q_Learning [94/300]: mean_loss=0.04025872191414237
Q_Learning [95/300]: mean_loss=0.02804922009818256
Q_Learning [96/300]: mean_loss=0.023245053831487894
Q_Learning [97/300]: mean_loss=0.03614495322108269
Q_Learning [98/300]: mean_loss=0.03585643763653934
Q_Learning [99/300]: mean_loss=0.021842034766450524
Q_Learning [100/300]: mean_loss=0.05819181818515062
Q_Learning [101/300]: mean_loss=0.019370584283024073
Q_Learning [102/300]: mean_loss=0.04970021732151508
Q_Learning [103/300]: mean_loss=0.03695958526805043
Q_Learning [104/300]: mean_loss=0.04603849397972226
Q_Learning [105/300]: mean_loss=0.025763463927432895
Q_Learning [106/300]: mean_loss=0.009326420025900006
Q_Learning [107/300]: mean_loss=0.014372067176736891
Q_Learning [108/300]: mean_loss=0.02520275069400668
Q_Learning [109/300]: mean_loss=0.03132646717131138
Q_Learning [110/300]: mean_loss=0.026803604559972882
Q_Learning [111/300]: mean_loss=0.02392309485003352
Q_Learning [112/300]: mean_loss=0.11313317622989416
Q_Learning [113/300]: mean_loss=0.02089466224424541
Q_Learning [114/300]: mean_loss=0.026198492851108313
Q_Learning [115/300]: mean_loss=0.06165340030565858
Q_Learning [116/300]: mean_loss=0.026029232190921903
Q_Learning [117/300]: mean_loss=0.06554346205666661
Q_Learning [118/300]: mean_loss=0.03342693950980902
Q_Learning [119/300]: mean_loss=0.12159259337931871
Q_Learning [120/300]: mean_loss=0.05083838989958167
Q_Learning [121/300]: mean_loss=0.062335746828466654
Q_Learning [122/300]: mean_loss=0.05015270225703716
Q_Learning [123/300]: mean_loss=0.028320091543719172
Q_Learning [124/300]: mean_loss=0.014565384481102228
Q_Learning [125/300]: mean_loss=0.07106494344770908
Q_Learning [126/300]: mean_loss=0.04022997338324785
Q_Learning [127/300]: mean_loss=0.048644174821674824
Q_Learning [128/300]: mean_loss=0.021286631003022194
Q_Learning [129/300]: mean_loss=0.021074495278298855
Q_Learning [130/300]: mean_loss=0.01842899527400732
Q_Learning [131/300]: mean_loss=0.02494999673217535
Q_Learning [132/300]: mean_loss=0.020055043743923306
Q_Learning [133/300]: mean_loss=0.02423166297376156
Q_Learning [134/300]: mean_loss=0.011155703337863088
Q_Learning [135/300]: mean_loss=0.09619181603193283
Q_Learning [136/300]: mean_loss=0.021364468848332763
Q_Learning [137/300]: mean_loss=0.029986407607793808
Q_Learning [138/300]: mean_loss=0.012422829400748014
Q_Learning [139/300]: mean_loss=0.016661708592437208
Q_Learning [140/300]: mean_loss=0.024122218368574977
Q_Learning [141/300]: mean_loss=0.03627358516678214
Q_Learning [142/300]: mean_loss=0.018194148316979408
Q_Learning [143/300]: mean_loss=0.0199679983779788
Q_Learning [144/300]: mean_loss=0.01098023820668459
Q_Learning [145/300]: mean_loss=0.04223222704604268
Q_Learning [146/300]: mean_loss=0.022522118990309536
Q_Learning [147/300]: mean_loss=0.017492357175797224
Q_Learning [148/300]: mean_loss=0.038012620992958546
Q_Learning [149/300]: mean_loss=0.04753552610054612
Q_Learning [150/300]: mean_loss=0.06610407121479511
Q_Learning [151/300]: mean_loss=0.029686996014788747
Q_Learning [152/300]: mean_loss=0.020858098287135363
Q_Learning [153/300]: mean_loss=0.037919528782367706
Q_Learning [154/300]: mean_loss=0.02268840535543859
Q_Learning [155/300]: mean_loss=0.012705498258583248
Q_Learning [156/300]: mean_loss=0.02379490714520216
Q_Learning [157/300]: mean_loss=0.1418062625452876
Q_Learning [158/300]: mean_loss=0.013447016128338873
Q_Learning [159/300]: mean_loss=0.02382910391315818
Q_Learning [160/300]: mean_loss=0.035324014024809
Q_Learning [161/300]: mean_loss=0.034885779954493046
Q_Learning [162/300]: mean_loss=0.01459827576763928
Q_Learning [163/300]: mean_loss=0.049223759677261114
Q_Learning [164/300]: mean_loss=0.018527917563915253
Q_Learning [165/300]: mean_loss=0.0084955490892753
Q_Learning [166/300]: mean_loss=0.024047640152275562
Q_Learning [167/300]: mean_loss=0.02804610342718661
Q_Learning [168/300]: mean_loss=0.029655908001586795
Q_Learning [169/300]: mean_loss=0.052160569466650486
Q_Learning [170/300]: mean_loss=0.16843408532440662
Q_Learning [171/300]: mean_loss=0.013344705454073846
Q_Learning [172/300]: mean_loss=0.016843290766701102
Q_Learning [173/300]: mean_loss=0.022918239003047347
Q_Learning [174/300]: mean_loss=0.013109652092680335
Q_Learning [175/300]: mean_loss=0.011286754510365427
Q_Learning [176/300]: mean_loss=0.0064472961239516735
Q_Learning [177/300]: mean_loss=0.024160676635801792
Q_Learning [178/300]: mean_loss=0.033192279282957315
Q_Learning [179/300]: mean_loss=0.027240863535553217
Q_Learning [180/300]: mean_loss=0.017277618288062513
Q_Learning [181/300]: mean_loss=0.018082289258018136
Q_Learning [182/300]: mean_loss=0.030169940320774913
Q_Learning [183/300]: mean_loss=0.013456282555125654
Q_Learning [184/300]: mean_loss=0.004494228691328317
Q_Learning [185/300]: mean_loss=0.02920872112736106
Q_Learning [186/300]: mean_loss=0.03480723546817899
Q_Learning [187/300]: mean_loss=0.022260761121287942
Q_Learning [188/300]: mean_loss=0.022017809562385082
Q_Learning [189/300]: mean_loss=0.061847036238759756
Q_Learning [190/300]: mean_loss=0.01669675367884338
Q_Learning [191/300]: mean_loss=0.13120813947170973
Q_Learning [192/300]: mean_loss=0.024205104215070605
Q_Learning [193/300]: mean_loss=0.018650580430403352
Q_Learning [194/300]: mean_loss=0.0067844256409443915
Q_Learning [195/300]: mean_loss=0.031701748026534915
Q_Learning [196/300]: mean_loss=0.014142322354018688
Q_Learning [197/300]: mean_loss=0.028713850071653724
Q_Learning [198/300]: mean_loss=0.016908990684896708
Q_Learning [199/300]: mean_loss=0.09544094931334257
Q_Learning [200/300]: mean_loss=0.02153215976431966
Q_Learning [201/300]: mean_loss=0.02474498492665589
Q_Learning [202/300]: mean_loss=0.01615876262076199
Q_Learning [203/300]: mean_loss=0.009554024203680456
Q_Learning [204/300]: mean_loss=0.011170772835612297
Q_Learning [205/300]: mean_loss=0.059713393449783325
Q_Learning [206/300]: mean_loss=0.01269367418717593
Q_Learning [207/300]: mean_loss=0.05342452693730593
Q_Learning [208/300]: mean_loss=0.035674838814884424
Q_Learning [209/300]: mean_loss=0.056765332352370024
Q_Learning [210/300]: mean_loss=0.023445915896445513
Q_Learning [211/300]: mean_loss=0.010571773746050894
Q_Learning [212/300]: mean_loss=0.09137034602463245
Q_Learning [213/300]: mean_loss=0.03959790291264653
Q_Learning [214/300]: mean_loss=0.01168387127108872
Q_Learning [215/300]: mean_loss=0.02861838578246534
Q_Learning [216/300]: mean_loss=0.032508915988728404
Q_Learning [217/300]: mean_loss=0.011225227732211351
Q_Learning [218/300]: mean_loss=0.007338320778217167
Q_Learning [219/300]: mean_loss=0.05681216670200229
Q_Learning [220/300]: mean_loss=0.01340474933385849
Q_Learning [221/300]: mean_loss=0.033530586399137974
Q_Learning [222/300]: mean_loss=0.012256549904122949
Q_Learning [223/300]: mean_loss=0.027298841159790754
Q_Learning [224/300]: mean_loss=0.00725813617464155
Q_Learning [225/300]: mean_loss=0.028700978960841894
Q_Learning [226/300]: mean_loss=0.031028276542201638
Q_Learning [227/300]: mean_loss=0.01625208556652069
Q_Learning [228/300]: mean_loss=0.021070544607937336
Q_Learning [229/300]: mean_loss=0.036840508691966534
Q_Learning [230/300]: mean_loss=0.01373518817126751
Q_Learning [231/300]: mean_loss=0.0192628160584718
Q_Learning [232/300]: mean_loss=0.01473708648700267
Q_Learning [233/300]: mean_loss=0.011288632755167782
Q_Learning [234/300]: mean_loss=0.021163932979106903
Q_Learning [235/300]: mean_loss=0.07926929462701082
Q_Learning [236/300]: mean_loss=0.05348865268751979
Q_Learning [237/300]: mean_loss=0.027577412314713
Q_Learning [238/300]: mean_loss=0.08410351723432541
Q_Learning [239/300]: mean_loss=0.06755707412958145
Q_Learning [240/300]: mean_loss=0.04162068502046168
Q_Learning [241/300]: mean_loss=0.037916508968919516
Q_Learning [242/300]: mean_loss=0.03721734252758324
Q_Learning [243/300]: mean_loss=0.03981593856588006
Q_Learning [244/300]: mean_loss=0.01601488550659269
Q_Learning [245/300]: mean_loss=0.02773287449963391
Q_Learning [246/300]: mean_loss=0.013640580582432449
Q_Learning [247/300]: mean_loss=0.011842629173770547
Q_Learning [248/300]: mean_loss=0.07515668030828238
Q_Learning [249/300]: mean_loss=0.011236776714213192
Q_Learning [250/300]: mean_loss=0.018607172882184386
Q_Learning [251/300]: mean_loss=0.013714086497202516
Q_Learning [252/300]: mean_loss=0.022697342559695244
Q_Learning [253/300]: mean_loss=0.01151083956938237
Q_Learning [254/300]: mean_loss=0.021223146468400955
Q_Learning [255/300]: mean_loss=0.03959177155047655
Q_Learning [256/300]: mean_loss=0.02082297287415713
Q_Learning [257/300]: mean_loss=0.017482547089457512
Q_Learning [258/300]: mean_loss=0.02393901185132563
Q_Learning [259/300]: mean_loss=0.009607150917872787
Q_Learning [260/300]: mean_loss=0.011512973345816135
Q_Learning [261/300]: mean_loss=0.024882966419681907
Q_Learning [262/300]: mean_loss=0.024430579505860806
Q_Learning [263/300]: mean_loss=0.011604306753724813
Q_Learning [264/300]: mean_loss=0.02276259264908731
Q_Learning [265/300]: mean_loss=0.013457422377541661
Q_Learning [266/300]: mean_loss=0.012528117164038122
Q_Learning [267/300]: mean_loss=0.016313579748384655
Q_Learning [268/300]: mean_loss=0.005848518863786012
Q_Learning [269/300]: mean_loss=0.019785170443356037
Q_Learning [270/300]: mean_loss=0.014561849413439631
Q_Learning [271/300]: mean_loss=0.023030088050290942
Q_Learning [272/300]: mean_loss=0.011428847443312407
Q_Learning [273/300]: mean_loss=0.013588512083515525
Q_Learning [274/300]: mean_loss=0.006513487838674337
Q_Learning [275/300]: mean_loss=0.014201173791661859
Q_Learning [276/300]: mean_loss=0.010800518211908638
Q_Learning [277/300]: mean_loss=0.0266466720495373
Q_Learning [278/300]: mean_loss=0.026848586974665523
Q_Learning [279/300]: mean_loss=0.013831149321049452
Q_Learning [280/300]: mean_loss=0.024405907606706023
Q_Learning [281/300]: mean_loss=0.02700559888035059
Q_Learning [282/300]: mean_loss=0.03243282367475331
Q_Learning [283/300]: mean_loss=0.026517734164372087
Q_Learning [284/300]: mean_loss=0.01617067342158407
Q_Learning [285/300]: mean_loss=0.02087015425786376
Q_Learning [286/300]: mean_loss=0.0142162695992738
Q_Learning [287/300]: mean_loss=0.019742883276194334
Q_Learning [288/300]: mean_loss=0.015134457964450121
Q_Learning [289/300]: mean_loss=0.03528604609891772
Q_Learning [290/300]: mean_loss=0.008699605357833207
Q_Learning [291/300]: mean_loss=0.010439540725201368
Q_Learning [292/300]: mean_loss=0.00756797578651458
Q_Learning [293/300]: mean_loss=0.01217447908129543
Q_Learning [294/300]: mean_loss=0.01263829239178449
Q_Learning [295/300]: mean_loss=0.03578045847825706
Q_Learning [296/300]: mean_loss=0.03509032493457198
Q_Learning [297/300]: mean_loss=0.020641335751861334
Q_Learning [298/300]: mean_loss=0.01736549730412662
Q_Learning [299/300]: mean_loss=0.013163090101443231
Q_Learning [300/300]: mean_loss=0.04114024480804801
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.44556692 -2.1399257 ]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 2, 2, 0, 1, 1, 0, 0, 3, 2, 1, 1, 1, 2, 0, 0, 1, 0, 1, 3, 1, 0, 0, 4, 2, 1, 0, 1, 2, 3, 2, 1, 0, 2, 2, 1, 0, 3, 1, 2, 2, 2, 1, 2, 3, 0, 1, 2, 4, 2, 0, 0, 3, 2, 2, 1, 1, 3, 2, 2, 0, 2, 0, 3, 2, 2, 2, 5, 2, 0, 2, 2, 1, 0, 2, 1, 3, 1, 1, 2, 2, 2, 3, 2, 2, 1, 2, 3, 2, 3, 3, 2, 2, 2, 1, 3, 2, 5, 3, 1, 1, 0, 1, 2, 2, 0, 3, 0, 1, 2, 3, 1, 2, 1, 4, 2, 3, 2, 2, 2, 6, 2, 5, 3, 2, 4, 3, 2, 1, 0, 2, 1, 2, 2, 3, 2, 3, 0, 2, 2, 1, 2, 2, 1, 3, 1, 1, 1, 2, 2, 0, 0, 1, 0, 3, 2, 3, 1, 0, 1, 0, 1, 2, 7, 2, 1, 0, 6, 2, 2, 4, 0, 1, 2, 4, 3, 1, 3, 1, 2, 6, 1, 3, 1, 2, 6, 1, 3, 4, 6, 2, 1, 0, 3, 2, 6, 6, 6, 1, 1, 3, 3, 0, 2, 3, 0, 2, 1, 6, 1, 3, 0, 2, 2, 6, 0, 1, 4, 0, 2, 4, 1, 8, 9, 1, 2, 1, 6, 1, 0, 6, 0, 3, 7, 0, 2, 4, 0, 0, 2, 1, 1, 6, 6, 0, 9, 2, 1, 2, 1, 6, 2, 1, 6, 10, 2, 0, 0, 1, 11, 9, 0, 0, 1, 6, 6, 3, 8, 2, 0, 9, 1, 6, 12, 13, 1, 6, 7, 0, 6, 2, 8, 1, 11]
Centroids: [[-2.0705385, 1.9382318], [-0.6957425, 0.7458322], [-0.7330681, -2.7364874]]
Centroids: [[-0.3176127, -2.400342], [-0.5054504, 0.71868885], [-1.8159405, 1.6451867], [-1.397825, -2.990314], [0.13627973, -0.38061562], [2.0317602, 1.8033468], [-2.9878414, 2.6346185], [0.9123315, -2.8588505], [-5.3236103, 2.9776165], [-2.1984336, -4.864024], [-3.6051526, -1.0836949], [-3.360846, 4.5199966], [-1.1118296, 4.47684], [-6.075148, -0.8663633]]
Contingency Matrix: 
[[ 0 11 66  0  0  0 19  0  3  0  1  2  0  1]
 [ 2 67 18  0  7  3  2  0  0  0  0  0  1  0]
 [51  0  0 36  3  0  0  3  0  4  0  0  0  0]]
[[0, 11, 66, 0, 0, 0, 19, 0, 3, 0, 1, 2, 0, 1], [2, 67, 18, 0, 7, 3, 2, 0, 0, 0, 0, 0, 1, 0], [51, 0, 0, 36, 3, 0, 0, 3, 0, 4, 0, 0, 0, 0]]
[[0, 11, 66, 0, 0, 0, 19, 0, 3, 0, 1, 2, 0, 1], [2, 67, 18, 0, 7, 3, 2, 0, 0, 0, 0, 0, 1, 0], [51, 0, 0, 36, 3, 0, 0, 3, 0, 4, 0, 0, 0, 0]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
[[0, -1, 66, 0, 0, 0, 19, 0, 3, 0, 1, 2, 0, 1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [51, -1, 0, 36, 3, 0, 0, 3, 0, 4, 0, 0, 0, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [51, -1, -1, 36, 3, 0, 0, 3, 0, 4, 0, 0, 0, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 1, 0: 2, 2: 0}
New Contingency Matrix: 
[[66 11  0  0  0  0 19  0  3  0  1  2  0  1]
 [18 67  2  0  7  3  2  0  0  0  0  0  1  0]
 [ 0  0 51 36  3  0  0  3  0  4  0  0  0  0]]
New Clustered Label Sequence: [2, 1, 0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Diagonal_Elements: [66, 67, 51], Sum: 184
All_Elements: [66, 11, 0, 0, 0, 0, 19, 0, 3, 0, 1, 2, 0, 1, 18, 67, 2, 0, 7, 3, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 51, 36, 3, 0, 0, 3, 0, 4, 0, 0, 0, 0], Sum: 300
Accuracy: 0.6133333333333333
