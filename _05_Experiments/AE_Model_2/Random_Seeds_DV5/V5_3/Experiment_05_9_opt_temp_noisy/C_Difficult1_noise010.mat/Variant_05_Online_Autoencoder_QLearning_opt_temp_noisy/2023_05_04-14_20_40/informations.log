Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_9_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_9_opt_temp_noisy/C_Difficult1_noise010.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_05_04-14_20_40
Punishment_Coefficient: 0.6
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001974186E4E0>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.1360450591892004
Online_Training [2/700]: mean_loss=0.18152598291635513
Online_Training [3/700]: mean_loss=0.1315509518608451
Online_Training [4/700]: mean_loss=0.07164035830646753
Online_Training [5/700]: mean_loss=0.09070831630378962
Online_Training [6/700]: mean_loss=0.05259845033288002
Online_Training [7/700]: mean_loss=0.05828543612733483
Online_Training [8/700]: mean_loss=0.0966942235827446
Online_Training [9/700]: mean_loss=0.053070586174726486
Online_Training [10/700]: mean_loss=0.03772999066859484
Online_Training [11/700]: mean_loss=0.0182993687922135
Online_Training [12/700]: mean_loss=0.025542360497638583
Online_Training [13/700]: mean_loss=0.048995491582900286
Online_Training [14/700]: mean_loss=0.03308009332977235
Online_Training [15/700]: mean_loss=0.012992322095669806
Online_Training [16/700]: mean_loss=0.03128959471359849
Online_Training [17/700]: mean_loss=0.029417560901492834
Online_Training [18/700]: mean_loss=0.035115032689645886
Online_Training [19/700]: mean_loss=0.10863082576543093
Online_Training [20/700]: mean_loss=0.040958392433822155
Online_Training [21/700]: mean_loss=0.01877583283931017
Online_Training [22/700]: mean_loss=0.04038807190954685
Online_Training [23/700]: mean_loss=0.024123028852045536
Online_Training [24/700]: mean_loss=0.011036808253265917
Online_Training [25/700]: mean_loss=0.03626334248110652
Online_Training [26/700]: mean_loss=0.040442229714244604
Online_Training [27/700]: mean_loss=0.07121334411203861
Online_Training [28/700]: mean_loss=0.03571231523528695
Online_Training [29/700]: mean_loss=0.014921432244591415
Online_Training [30/700]: mean_loss=0.020992502802982926
Online_Training [31/700]: mean_loss=0.01396052015479654
Online_Training [32/700]: mean_loss=0.04988735634833574
Online_Training [33/700]: mean_loss=0.027481930796056986
Online_Training [34/700]: mean_loss=0.017519345972687006
Online_Training [35/700]: mean_loss=0.028368420200422406
Online_Training [36/700]: mean_loss=0.03635923704132438
Online_Training [37/700]: mean_loss=0.006130990048404783
Online_Training [38/700]: mean_loss=0.019731502514332533
Online_Training [39/700]: mean_loss=0.02095375512726605
Online_Training [40/700]: mean_loss=0.009366198093630373
Online_Training [41/700]: mean_loss=0.03791818767786026
Online_Training [42/700]: mean_loss=0.05938509292900562
Online_Training [43/700]: mean_loss=0.038326041772961617
Online_Training [44/700]: mean_loss=0.00765244773356244
Online_Training [45/700]: mean_loss=0.01892873481847346
Online_Training [46/700]: mean_loss=0.008828879799693823
Online_Training [47/700]: mean_loss=0.02579806512221694
Online_Training [48/700]: mean_loss=0.03308062697760761
Online_Training [49/700]: mean_loss=0.015482599148526788
Online_Training [50/700]: mean_loss=0.005203932349104434
Online_Training [51/700]: mean_loss=0.0114255117950961
Online_Training [52/700]: mean_loss=0.02188924653455615
Online_Training [53/700]: mean_loss=0.03431047173216939
Online_Training [54/700]: mean_loss=0.016587561927735806
Online_Training [55/700]: mean_loss=0.020434871315956116
Online_Training [56/700]: mean_loss=0.016424249741248786
Online_Training [57/700]: mean_loss=0.010520399315282702
Online_Training [58/700]: mean_loss=0.02158665074966848
Online_Training [59/700]: mean_loss=0.12346841674298048
Online_Training [60/700]: mean_loss=0.03134755394421518
Online_Training [61/700]: mean_loss=0.06747220596298575
Online_Training [62/700]: mean_loss=0.007155777653679252
Online_Training [63/700]: mean_loss=0.015227245865389705
Online_Training [64/700]: mean_loss=0.016415471443906426
Online_Training [65/700]: mean_loss=0.0274122201371938
Online_Training [66/700]: mean_loss=0.05828431760892272
Online_Training [67/700]: mean_loss=0.012894292012788355
Online_Training [68/700]: mean_loss=0.03497633361257613
Online_Training [69/700]: mean_loss=0.020198850193992257
Online_Training [70/700]: mean_loss=0.011853931355290115
Online_Training [71/700]: mean_loss=0.012412031064741313
Online_Training [72/700]: mean_loss=0.028636085335165262
Online_Training [73/700]: mean_loss=0.017113738460466266
Online_Training [74/700]: mean_loss=0.024609923595562577
Online_Training [75/700]: mean_loss=0.018443294567987323
Online_Training [76/700]: mean_loss=0.020999553380534053
Online_Training [77/700]: mean_loss=0.04970131441950798
Online_Training [78/700]: mean_loss=0.006575083883944899
Online_Training [79/700]: mean_loss=0.00493897870182991
Online_Training [80/700]: mean_loss=0.013337070005945861
Online_Training [81/700]: mean_loss=0.022213941905647516
Online_Training [82/700]: mean_loss=0.04369970317929983
Online_Training [83/700]: mean_loss=0.006191195861902088
Online_Training [84/700]: mean_loss=0.018393065314739943
Online_Training [85/700]: mean_loss=0.02009801147505641
Online_Training [86/700]: mean_loss=0.07633525040000677
Online_Training [87/700]: mean_loss=0.04795391671359539
Online_Training [88/700]: mean_loss=0.018256393494084477
Online_Training [89/700]: mean_loss=0.01765244291163981
Online_Training [90/700]: mean_loss=0.037667508237063885
Online_Training [91/700]: mean_loss=0.01325967360753566
Online_Training [92/700]: mean_loss=0.005967109638731927
Online_Training [93/700]: mean_loss=0.018952491460368037
Online_Training [94/700]: mean_loss=0.022031273925676942
Online_Training [95/700]: mean_loss=0.01359883660916239
Online_Training [96/700]: mean_loss=0.011248809867538512
Online_Training [97/700]: mean_loss=0.017610154347494245
Online_Training [98/700]: mean_loss=0.008403539599385113
Online_Training [99/700]: mean_loss=0.010864099022001028
Online_Training [100/700]: mean_loss=0.006746741244569421
Online_Training [101/700]: mean_loss=0.014562364551238716
Online_Training [102/700]: mean_loss=0.00863192556425929
Online_Training [103/700]: mean_loss=0.02463115775026381
Online_Training [104/700]: mean_loss=0.007886173960287124
Online_Training [105/700]: mean_loss=0.007196822494734079
Online_Training [106/700]: mean_loss=0.013197455205954611
Online_Training [107/700]: mean_loss=0.030175782274454832
Online_Training [108/700]: mean_loss=0.008389732625801116
Online_Training [109/700]: mean_loss=0.01223880099132657
Online_Training [110/700]: mean_loss=0.0174190157558769
Online_Training [111/700]: mean_loss=0.006447003106586635
Online_Training [112/700]: mean_loss=0.009831171832047403
Online_Training [113/700]: mean_loss=0.019321303814649582
Online_Training [114/700]: mean_loss=0.010963536216877401
Online_Training [115/700]: mean_loss=0.01268661837093532
Online_Training [116/700]: mean_loss=0.010925907641649246
Online_Training [117/700]: mean_loss=0.006148975226096809
Online_Training [118/700]: mean_loss=0.006189144041854888
Online_Training [119/700]: mean_loss=0.009510295116342604
Online_Training [120/700]: mean_loss=0.011137984343804419
Online_Training [121/700]: mean_loss=0.0343119646422565
Online_Training [122/700]: mean_loss=0.023603624431416392
Online_Training [123/700]: mean_loss=0.013901371043175459
Online_Training [124/700]: mean_loss=0.005072382860817015
Online_Training [125/700]: mean_loss=0.02082975674420595
Online_Training [126/700]: mean_loss=0.019976859912276268
Online_Training [127/700]: mean_loss=0.008126027591060847
Online_Training [128/700]: mean_loss=0.08805488795042038
Online_Training [129/700]: mean_loss=0.0803478630259633
Online_Training [130/700]: mean_loss=0.016507938504219055
Online_Training [131/700]: mean_loss=0.017259768676012754
Online_Training [132/700]: mean_loss=0.03494942467659712
Online_Training [133/700]: mean_loss=0.017670999746769667
Online_Training [134/700]: mean_loss=0.0066160595160909
Online_Training [135/700]: mean_loss=0.007946826168335974
Online_Training [136/700]: mean_loss=0.0025197871727868915
Online_Training [137/700]: mean_loss=0.007339833420701325
Online_Training [138/700]: mean_loss=0.012008512858301401
Online_Training [139/700]: mean_loss=0.009506782342214137
Online_Training [140/700]: mean_loss=0.12882347125560045
Online_Training [141/700]: mean_loss=0.03717625583522022
Online_Training [142/700]: mean_loss=0.029995251912623644
Online_Training [143/700]: mean_loss=0.007411941536702216
Online_Training [144/700]: mean_loss=0.0049385480233468115
Online_Training [145/700]: mean_loss=0.028705716831609607
Online_Training [146/700]: mean_loss=0.01436989358626306
Online_Training [147/700]: mean_loss=0.0369593040086329
Online_Training [148/700]: mean_loss=0.01583286130335182
Online_Training [149/700]: mean_loss=0.012998650199733675
Online_Training [150/700]: mean_loss=0.023801248520612717
Online_Training [151/700]: mean_loss=0.019154156791046262
Online_Training [152/700]: mean_loss=0.007455940765794367
Online_Training [153/700]: mean_loss=0.008468018437270075
Online_Training [154/700]: mean_loss=0.002582322311354801
Online_Training [155/700]: mean_loss=0.012878686422482133
Online_Training [156/700]: mean_loss=0.01096641004551202
Online_Training [157/700]: mean_loss=0.014928917633369565
Online_Training [158/700]: mean_loss=0.013776211184449494
Online_Training [159/700]: mean_loss=0.012607372365891933
Online_Training [160/700]: mean_loss=0.010743888560682535
Online_Training [161/700]: mean_loss=0.009792444063350558
Online_Training [162/700]: mean_loss=0.010395627119578421
Online_Training [163/700]: mean_loss=0.011866382556036115
Online_Training [164/700]: mean_loss=0.005049320287071168
Online_Training [165/700]: mean_loss=0.01453624595887959
Online_Training [166/700]: mean_loss=0.015890739858150482
Online_Training [167/700]: mean_loss=0.009290143148973584
Online_Training [168/700]: mean_loss=0.004852659360039979
Online_Training [169/700]: mean_loss=0.011137173394672573
Online_Training [170/700]: mean_loss=0.012674257159233093
Online_Training [171/700]: mean_loss=0.04365141876041889
Online_Training [172/700]: mean_loss=0.009142524562776089
Online_Training [173/700]: mean_loss=0.005080422852188349
Online_Training [174/700]: mean_loss=0.0040493515552952886
Online_Training [175/700]: mean_loss=0.0190938045270741
Online_Training [176/700]: mean_loss=0.005993695987854153
Online_Training [177/700]: mean_loss=0.021915937075391412
Online_Training [178/700]: mean_loss=0.010435645468533039
Online_Training [179/700]: mean_loss=0.08259310107678175
Online_Training [180/700]: mean_loss=0.06662485422566533
Online_Training [181/700]: mean_loss=0.03000323660671711
Online_Training [182/700]: mean_loss=0.010120939230546355
Online_Training [183/700]: mean_loss=0.010701397550292313
Online_Training [184/700]: mean_loss=0.014449354843236506
Online_Training [185/700]: mean_loss=0.012429281254298985
Online_Training [186/700]: mean_loss=0.01841136463917792
Online_Training [187/700]: mean_loss=0.010210636188276112
Online_Training [188/700]: mean_loss=0.009634526679292321
Online_Training [189/700]: mean_loss=0.017753577092662454
Online_Training [190/700]: mean_loss=0.011831002484541386
Online_Training [191/700]: mean_loss=0.008389129885472357
Online_Training [192/700]: mean_loss=0.01192683749832213
Online_Training [193/700]: mean_loss=0.007675967121031135
Online_Training [194/700]: mean_loss=0.019843069603666663
Online_Training [195/700]: mean_loss=0.007238298479933292
Online_Training [196/700]: mean_loss=0.008560329675674438
Online_Training [197/700]: mean_loss=0.005625941616017371
Online_Training [198/700]: mean_loss=0.008971079951152205
Online_Training [199/700]: mean_loss=0.004317281011026353
Online_Training [200/700]: mean_loss=0.01018640911206603
Online_Training [201/700]: mean_loss=0.005344688310287893
Online_Training [202/700]: mean_loss=0.10765337012708187
Online_Training [203/700]: mean_loss=0.03040660941042006
Online_Training [204/700]: mean_loss=0.01743215578608215
Online_Training [205/700]: mean_loss=0.014658330823294818
Online_Training [206/700]: mean_loss=0.012553318054415286
Online_Training [207/700]: mean_loss=0.008322697831317782
Online_Training [208/700]: mean_loss=0.013212045188993216
Online_Training [209/700]: mean_loss=0.007494116551242769
Online_Training [210/700]: mean_loss=0.009890642599202693
Online_Training [211/700]: mean_loss=0.013302643434144557
Online_Training [212/700]: mean_loss=0.008031625184230506
Online_Training [213/700]: mean_loss=0.010649951174855232
Online_Training [214/700]: mean_loss=0.006833667634055018
Online_Training [215/700]: mean_loss=0.030249689240008593
Online_Training [216/700]: mean_loss=0.014256461523473263
Online_Training [217/700]: mean_loss=0.009448297438211739
Online_Training [218/700]: mean_loss=0.006697244942188263
Online_Training [219/700]: mean_loss=0.010936555685475469
Online_Training [220/700]: mean_loss=0.013280396698974073
Online_Training [221/700]: mean_loss=0.00889321806607768
Online_Training [222/700]: mean_loss=0.009360293159261346
Online_Training [223/700]: mean_loss=0.016120691667310894
Online_Training [224/700]: mean_loss=0.005252530158031732
Online_Training [225/700]: mean_loss=0.004382336686830968
Online_Training [226/700]: mean_loss=0.022496451623737812
Online_Training [227/700]: mean_loss=0.007896608440205455
Online_Training [228/700]: mean_loss=0.004380233964184299
Online_Training [229/700]: mean_loss=0.014124363660812378
Online_Training [230/700]: mean_loss=0.00825716252438724
Online_Training [231/700]: mean_loss=0.02422262425534427
Online_Training [232/700]: mean_loss=0.009843086008913815
Online_Training [233/700]: mean_loss=0.006228042300790548
Online_Training [234/700]: mean_loss=0.05593910114839673
Online_Training [235/700]: mean_loss=0.10665027517825365
Online_Training [236/700]: mean_loss=0.010692193754948676
Online_Training [237/700]: mean_loss=0.041676695458590984
Online_Training [238/700]: mean_loss=0.012425752356648445
Online_Training [239/700]: mean_loss=0.006259050685912371
Online_Training [240/700]: mean_loss=0.01141499332152307
Online_Training [241/700]: mean_loss=0.011138388654217124
Online_Training [242/700]: mean_loss=0.011756492778658867
Online_Training [243/700]: mean_loss=0.017753183841705322
Online_Training [244/700]: mean_loss=0.015032113995403051
Online_Training [245/700]: mean_loss=0.012647105264477432
Online_Training [246/700]: mean_loss=0.017229510005563498
Online_Training [247/700]: mean_loss=0.016664240742102265
Online_Training [248/700]: mean_loss=0.016820867429487407
Online_Training [249/700]: mean_loss=0.034614323638379574
Online_Training [250/700]: mean_loss=0.006119874655269086
Online_Training [251/700]: mean_loss=0.004951912385877222
Online_Training [252/700]: mean_loss=0.022924453020095825
Online_Training [253/700]: mean_loss=0.008612706093117595
Online_Training [254/700]: mean_loss=0.003907578749931417
Online_Training [255/700]: mean_loss=0.006132206821348518
Online_Training [256/700]: mean_loss=0.015546450740657747
Online_Training [257/700]: mean_loss=0.007053508597891778
Online_Training [258/700]: mean_loss=0.0093311796663329
Online_Training [259/700]: mean_loss=0.003769472474232316
Online_Training [260/700]: mean_loss=0.0032535712234675884
Online_Training [261/700]: mean_loss=0.00882600957993418
Online_Training [262/700]: mean_loss=0.004970659560058266
Online_Training [263/700]: mean_loss=0.0070696823531761765
Online_Training [264/700]: mean_loss=0.005174250574782491
Online_Training [265/700]: mean_loss=0.09805793222039938
Online_Training [266/700]: mean_loss=0.09862726088613272
Online_Training [267/700]: mean_loss=0.010146582964807749
Online_Training [268/700]: mean_loss=0.016874815803021193
Online_Training [269/700]: mean_loss=0.013827802380546927
Online_Training [270/700]: mean_loss=0.10687212739139795
Online_Training [271/700]: mean_loss=0.021223275223746896
Online_Training [272/700]: mean_loss=0.013373378198593855
Online_Training [273/700]: mean_loss=0.01679375022649765
Online_Training [274/700]: mean_loss=0.006344145105686039
Online_Training [275/700]: mean_loss=0.01824900833889842
Online_Training [276/700]: mean_loss=0.015048926696181297
Online_Training [277/700]: mean_loss=0.009152623009867966
Online_Training [278/700]: mean_loss=0.008618959225714207
Online_Training [279/700]: mean_loss=0.009659316507168114
Online_Training [280/700]: mean_loss=0.009791206801310182
Online_Training [281/700]: mean_loss=0.006569749384652823
Online_Training [282/700]: mean_loss=0.015172471641562879
Online_Training [283/700]: mean_loss=0.018018159898929298
Online_Training [284/700]: mean_loss=0.009364414378069341
Online_Training [285/700]: mean_loss=0.02310073748230934
Online_Training [286/700]: mean_loss=0.004151668777922168
Online_Training [287/700]: mean_loss=0.0046493198606185615
Online_Training [288/700]: mean_loss=0.016760939150117338
Online_Training [289/700]: mean_loss=0.00605433463351801
Online_Training [290/700]: mean_loss=0.003928220452507958
Online_Training [291/700]: mean_loss=0.014248012215830386
Online_Training [292/700]: mean_loss=0.010260667651891708
Online_Training [293/700]: mean_loss=0.0956411948427558
Online_Training [294/700]: mean_loss=0.023970493581146002
Online_Training [295/700]: mean_loss=0.010574051761068404
Online_Training [296/700]: mean_loss=0.015174631611444056
Online_Training [297/700]: mean_loss=0.014280621544457972
Online_Training [298/700]: mean_loss=0.007071814383380115
Online_Training [299/700]: mean_loss=0.018243317725136876
Online_Training [300/700]: mean_loss=0.00948328583035618
Online_Training [301/700]: mean_loss=0.009451122488826513
Online_Training [302/700]: mean_loss=0.004542943264823407
Online_Training [303/700]: mean_loss=0.01149644167162478
Online_Training [304/700]: mean_loss=0.004276807536371052
Online_Training [305/700]: mean_loss=0.019433862064033747
Online_Training [306/700]: mean_loss=0.014465756015852094
Online_Training [307/700]: mean_loss=0.019392254063859582
Online_Training [308/700]: mean_loss=0.0037810079229529947
Online_Training [309/700]: mean_loss=0.009176322142593563
Online_Training [310/700]: mean_loss=0.016067643300630152
Online_Training [311/700]: mean_loss=0.012086041970178485
Online_Training [312/700]: mean_loss=0.14845499210059643
Online_Training [313/700]: mean_loss=0.0828497800976038
Online_Training [314/700]: mean_loss=0.01601705781649798
Online_Training [315/700]: mean_loss=0.008660725317895412
Online_Training [316/700]: mean_loss=0.01559865172021091
Online_Training [317/700]: mean_loss=0.036225966177880764
Online_Training [318/700]: mean_loss=0.01128759584389627
Online_Training [319/700]: mean_loss=0.018143085995689034
Online_Training [320/700]: mean_loss=0.006137463147751987
Online_Training [321/700]: mean_loss=0.005933043081313372
Online_Training [322/700]: mean_loss=0.015203120419755578
Online_Training [323/700]: mean_loss=0.010849142214283347
Online_Training [324/700]: mean_loss=0.013018443947657943
Online_Training [325/700]: mean_loss=0.068895707372576
Online_Training [326/700]: mean_loss=0.03677262249402702
Online_Training [327/700]: mean_loss=0.015436173416674137
Online_Training [328/700]: mean_loss=0.025412130169570446
Online_Training [329/700]: mean_loss=0.08753329142928123
Online_Training [330/700]: mean_loss=0.11794501822441816
Online_Training [331/700]: mean_loss=0.0282081994228065
Online_Training [332/700]: mean_loss=0.011326002422720194
Online_Training [333/700]: mean_loss=0.02384421380702406
Online_Training [334/700]: mean_loss=0.005482692562509328
Online_Training [335/700]: mean_loss=0.02088140556588769
Online_Training [336/700]: mean_loss=0.007233438896946609
Online_Training [337/700]: mean_loss=0.006799442053306848
Online_Training [338/700]: mean_loss=0.01091849384829402
Online_Training [339/700]: mean_loss=0.016266971360892057
Online_Training [340/700]: mean_loss=0.014639970613643527
Online_Training [341/700]: mean_loss=0.014531391905620694
Online_Training [342/700]: mean_loss=0.016659917891956866
Online_Training [343/700]: mean_loss=0.0181680282112211
Online_Training [344/700]: mean_loss=0.013525141985155642
Online_Training [345/700]: mean_loss=0.008782455814071
Online_Training [346/700]: mean_loss=0.006377986923325807
Online_Training [347/700]: mean_loss=0.013123094802722335
Online_Training [348/700]: mean_loss=0.0019073955481871963
Online_Training [349/700]: mean_loss=0.006351746211294085
Online_Training [350/700]: mean_loss=0.09439285565167665
Online_Training [351/700]: mean_loss=0.028354919282719493
Online_Training [352/700]: mean_loss=0.015773702529259026
Online_Training [353/700]: mean_loss=0.021012423327192664
Online_Training [354/700]: mean_loss=0.00664778717327863
Online_Training [355/700]: mean_loss=0.01644527248572558
Online_Training [356/700]: mean_loss=0.006964419619180262
Online_Training [357/700]: mean_loss=0.020648000296205282
Online_Training [358/700]: mean_loss=0.007204832276329398
Online_Training [359/700]: mean_loss=0.006258863199036568
Online_Training [360/700]: mean_loss=0.005542166705708951
Online_Training [361/700]: mean_loss=0.0108204479329288
Online_Training [362/700]: mean_loss=0.10967131145298481
Online_Training [363/700]: mean_loss=0.11350678000599146
Online_Training [364/700]: mean_loss=0.0252140611410141
Online_Training [365/700]: mean_loss=0.015543040353804827
Online_Training [366/700]: mean_loss=0.011320976889692247
Online_Training [367/700]: mean_loss=0.018323246389627457
Online_Training [368/700]: mean_loss=0.017618115060031414
Online_Training [369/700]: mean_loss=0.006410771864466369
Online_Training [370/700]: mean_loss=0.0037710229807998985
Online_Training [371/700]: mean_loss=0.017469073878601193
Online_Training [372/700]: mean_loss=0.009577512508258224
Online_Training [373/700]: mean_loss=0.011732481885701418
Online_Training [374/700]: mean_loss=0.007833270239643753
Online_Training [375/700]: mean_loss=0.005127922282554209
Online_Training [376/700]: mean_loss=0.0034766512108035386
Online_Training [377/700]: mean_loss=0.007139187888242304
Online_Training [378/700]: mean_loss=0.006255209387745708
Online_Training [379/700]: mean_loss=0.1109901936724782
Online_Training [380/700]: mean_loss=0.035345705691725016
Online_Training [381/700]: mean_loss=0.012407837784849107
Online_Training [382/700]: mean_loss=0.01421010761987418
Online_Training [383/700]: mean_loss=0.09012868907302618
Online_Training [384/700]: mean_loss=0.03925383766181767
Online_Training [385/700]: mean_loss=0.03898116201162338
Online_Training [386/700]: mean_loss=0.026924921199679375
Online_Training [387/700]: mean_loss=0.011260153609327972
Online_Training [388/700]: mean_loss=0.02693465701304376
Online_Training [389/700]: mean_loss=0.008196175331249833
Online_Training [390/700]: mean_loss=0.09014292061328888
Online_Training [391/700]: mean_loss=0.01635277341119945
Online_Training [392/700]: mean_loss=0.00820732326246798
Online_Training [393/700]: mean_loss=0.00901785190217197
Online_Training [394/700]: mean_loss=0.00837605056585744
Online_Training [395/700]: mean_loss=0.008488576917443424
Online_Training [396/700]: mean_loss=0.01532566745299846
Online_Training [397/700]: mean_loss=0.002785043412586674
Online_Training [398/700]: mean_loss=0.01648273365572095
Online_Training [399/700]: mean_loss=0.012818570015951991
Online_Training [400/700]: mean_loss=0.014909934252500534
Online_Training [401/700]: mean_loss=0.006200475501827896
Online_Training [402/700]: mean_loss=0.010148103581741452
Online_Training [403/700]: mean_loss=0.010188285261392593
Online_Training [404/700]: mean_loss=0.0028217728540766984
Online_Training [405/700]: mean_loss=0.011397399939596653
Online_Training [406/700]: mean_loss=0.009080005576834083
Online_Training [407/700]: mean_loss=0.010147939203307033
Online_Training [408/700]: mean_loss=0.008221752534154803
Online_Training [409/700]: mean_loss=0.010022138012573123
Online_Training [410/700]: mean_loss=0.007036464405246079
Online_Training [411/700]: mean_loss=0.00696202862309292
Online_Training [412/700]: mean_loss=0.0065680836560204625
Online_Training [413/700]: mean_loss=0.006083353131543845
Online_Training [414/700]: mean_loss=0.01165502704679966
Online_Training [415/700]: mean_loss=0.007896911352872849
Online_Training [416/700]: mean_loss=0.008273045590613037
Online_Training [417/700]: mean_loss=0.012738756719045341
Online_Training [418/700]: mean_loss=0.005609306797850877
Online_Training [419/700]: mean_loss=0.008006125572137535
Online_Training [420/700]: mean_loss=0.01047096075490117
Online_Training [421/700]: mean_loss=0.008862841757945716
Online_Training [422/700]: mean_loss=0.017740302719175816
Online_Training [423/700]: mean_loss=0.005421098787337542
Online_Training [424/700]: mean_loss=0.0026322150661144406
Online_Training [425/700]: mean_loss=0.0020178435515845194
Online_Training [426/700]: mean_loss=0.013183116563595831
Online_Training [427/700]: mean_loss=0.010606216383166611
Online_Training [428/700]: mean_loss=0.0029604187584482133
Online_Training [429/700]: mean_loss=0.008585794712416828
Online_Training [430/700]: mean_loss=0.015293122734874487
Online_Training [431/700]: mean_loss=0.008557734196074307
Online_Training [432/700]: mean_loss=0.010385163244791329
Online_Training [433/700]: mean_loss=0.009874651557765901
Online_Training [434/700]: mean_loss=0.010180352604947984
Online_Training [435/700]: mean_loss=0.011167363380081952
Online_Training [436/700]: mean_loss=0.006126892869360745
Online_Training [437/700]: mean_loss=0.009639495052397251
Online_Training [438/700]: mean_loss=0.0026466584822628647
Online_Training [439/700]: mean_loss=0.009856299380771816
Online_Training [440/700]: mean_loss=0.027660186169669032
Online_Training [441/700]: mean_loss=0.016761209117248654
Online_Training [442/700]: mean_loss=0.006824128213338554
Online_Training [443/700]: mean_loss=0.07234708592295647
Online_Training [444/700]: mean_loss=0.08608850743621588
Online_Training [445/700]: mean_loss=0.010807754821144044
Online_Training [446/700]: mean_loss=0.009994649444706738
Online_Training [447/700]: mean_loss=0.007328103412874043
Online_Training [448/700]: mean_loss=0.007200828054919839
Online_Training [449/700]: mean_loss=0.026752385310828686
Online_Training [450/700]: mean_loss=0.009166388539597392
Online_Training [451/700]: mean_loss=0.005707074305973947
Online_Training [452/700]: mean_loss=0.03679524967446923
Online_Training [453/700]: mean_loss=0.006677942932583392
Online_Training [454/700]: mean_loss=0.005639257840812206
Online_Training [455/700]: mean_loss=0.012921392801217735
Online_Training [456/700]: mean_loss=0.0051126061589457095
Online_Training [457/700]: mean_loss=0.008607832249253988
Online_Training [458/700]: mean_loss=0.010164951207116246
Online_Training [459/700]: mean_loss=0.003326447738800198
Online_Training [460/700]: mean_loss=0.0031070943223312497
Online_Training [461/700]: mean_loss=0.00925230048596859
Online_Training [462/700]: mean_loss=0.007158427964895964
Online_Training [463/700]: mean_loss=0.013936694944277406
Online_Training [464/700]: mean_loss=0.021007834002375603
Online_Training [465/700]: mean_loss=0.002804031508276239
Online_Training [466/700]: mean_loss=0.007752695644740015
Online_Training [467/700]: mean_loss=0.005718764616176486
Online_Training [468/700]: mean_loss=0.007816525059752166
Online_Training [469/700]: mean_loss=0.005940812407061458
Online_Training [470/700]: mean_loss=0.02087684441357851
Online_Training [471/700]: mean_loss=0.0025111337599810213
Online_Training [472/700]: mean_loss=0.021707503590732813
Online_Training [473/700]: mean_loss=0.01355996762868017
Online_Training [474/700]: mean_loss=0.0088531116489321
Online_Training [475/700]: mean_loss=0.0028842347965110093
Online_Training [476/700]: mean_loss=0.007318745949305594
Online_Training [477/700]: mean_loss=0.022611609427258372
Online_Training [478/700]: mean_loss=0.002803340583341196
Online_Training [479/700]: mean_loss=0.008529738988727331
Online_Training [480/700]: mean_loss=0.004258754779584706
Online_Training [481/700]: mean_loss=0.009042513091117144
Online_Training [482/700]: mean_loss=0.00600240589119494
Online_Training [483/700]: mean_loss=0.01007101486902684
Online_Training [484/700]: mean_loss=0.011806946247816086
Online_Training [485/700]: mean_loss=0.01565957861021161
Online_Training [486/700]: mean_loss=0.0026995013759005815
Online_Training [487/700]: mean_loss=0.008609983429778367
Online_Training [488/700]: mean_loss=0.025247588055208325
Online_Training [489/700]: mean_loss=0.005395430896896869
Online_Training [490/700]: mean_loss=0.057022444903850555
Online_Training [491/700]: mean_loss=0.12303819786757231
Online_Training [492/700]: mean_loss=0.009050122229382396
Online_Training [493/700]: mean_loss=0.008988182060420513
Online_Training [494/700]: mean_loss=0.009489923482760787
Online_Training [495/700]: mean_loss=0.006547337106894702
Online_Training [496/700]: mean_loss=0.0054546709870919585
Online_Training [497/700]: mean_loss=0.013764730771072209
Online_Training [498/700]: mean_loss=0.007949134742375463
Online_Training [499/700]: mean_loss=0.01597605098504573
Online_Training [500/700]: mean_loss=0.009421910857781768
Online_Training [501/700]: mean_loss=0.013349759276024997
Online_Training [502/700]: mean_loss=0.017044462612830102
Online_Training [503/700]: mean_loss=0.006853013823274523
Online_Training [504/700]: mean_loss=0.006061956926714629
Online_Training [505/700]: mean_loss=0.0024159610911738127
Online_Training [506/700]: mean_loss=0.006805530458223075
Online_Training [507/700]: mean_loss=0.009226471069268882
Online_Training [508/700]: mean_loss=0.059590060729533434
Online_Training [509/700]: mean_loss=0.061547540593892336
Online_Training [510/700]: mean_loss=0.01518665300682187
Online_Training [511/700]: mean_loss=0.00824741757242009
Online_Training [512/700]: mean_loss=0.014993208460509777
Online_Training [513/700]: mean_loss=0.013135217595845461
Online_Training [514/700]: mean_loss=0.005889364634640515
Online_Training [515/700]: mean_loss=0.007954411499667913
Online_Training [516/700]: mean_loss=0.015140272444114089
Online_Training [517/700]: mean_loss=0.0037870872765779495
Online_Training [518/700]: mean_loss=0.0065511109423823655
Online_Training [519/700]: mean_loss=0.013690839288756251
Online_Training [520/700]: mean_loss=0.014968639006838202
Online_Training [521/700]: mean_loss=0.006496868678368628
Online_Training [522/700]: mean_loss=0.017121200799010694
Online_Training [523/700]: mean_loss=0.008132163318805397
Online_Training [524/700]: mean_loss=0.0025202235265169293
Online_Training [525/700]: mean_loss=0.012089127558283508
Online_Training [526/700]: mean_loss=0.014686874113976955
Online_Training [527/700]: mean_loss=0.008114522381220013
Online_Training [528/700]: mean_loss=0.0048611153033562005
Online_Training [529/700]: mean_loss=0.004149559506913647
Online_Training [530/700]: mean_loss=0.010376783437095582
Online_Training [531/700]: mean_loss=0.005732452671509236
Online_Training [532/700]: mean_loss=0.009753930615261197
Online_Training [533/700]: mean_loss=0.006371029536239803
Online_Training [534/700]: mean_loss=0.00291679851943627
Online_Training [535/700]: mean_loss=0.010977687779814005
Online_Training [536/700]: mean_loss=0.006173451081849635
Online_Training [537/700]: mean_loss=0.01171808794606477
Online_Training [538/700]: mean_loss=0.010139248333871365
Online_Training [539/700]: mean_loss=0.006131302332505584
Online_Training [540/700]: mean_loss=0.008016050502192229
Online_Training [541/700]: mean_loss=0.010365561698563397
Online_Training [542/700]: mean_loss=0.008268290781415999
Online_Training [543/700]: mean_loss=0.022204458713531494
Online_Training [544/700]: mean_loss=0.012519446783699095
Online_Training [545/700]: mean_loss=0.05762987723574042
Online_Training [546/700]: mean_loss=0.06118701212108135
Online_Training [547/700]: mean_loss=0.0071775036049075425
Online_Training [548/700]: mean_loss=0.14381319843232632
Online_Training [549/700]: mean_loss=0.08466779999434948
Online_Training [550/700]: mean_loss=0.022940447786822915
Online_Training [551/700]: mean_loss=0.019281074637547135
Online_Training [552/700]: mean_loss=0.007841393060516566
Online_Training [553/700]: mean_loss=0.019134837668389082
Online_Training [554/700]: mean_loss=0.010292505146935582
Online_Training [555/700]: mean_loss=0.008826397242955863
Online_Training [556/700]: mean_loss=0.027023132890462875
Online_Training [557/700]: mean_loss=0.007873348775319755
Online_Training [558/700]: mean_loss=0.011333806440234184
Online_Training [559/700]: mean_loss=0.003298539260867983
Online_Training [560/700]: mean_loss=0.009969350532628596
Online_Training [561/700]: mean_loss=0.005791281058918685
Online_Training [562/700]: mean_loss=0.008159121964126825
Online_Training [563/700]: mean_loss=0.008518668124452233
Online_Training [564/700]: mean_loss=0.010802261298522353
Online_Training [565/700]: mean_loss=0.017127858009189367
Online_Training [566/700]: mean_loss=0.007504226581659168
Online_Training [567/700]: mean_loss=0.017034756252542138
Online_Training [568/700]: mean_loss=0.00582220742944628
Online_Training [569/700]: mean_loss=0.009980338043533266
Online_Training [570/700]: mean_loss=0.010662505053915083
Online_Training [571/700]: mean_loss=0.01480700762476772
Online_Training [572/700]: mean_loss=0.008491108426824212
Online_Training [573/700]: mean_loss=0.00791047018719837
Online_Training [574/700]: mean_loss=0.0069624161696992815
Online_Training [575/700]: mean_loss=0.006747283157892525
Online_Training [576/700]: mean_loss=0.003194614313542843
Online_Training [577/700]: mean_loss=0.009765783790498972
Online_Training [578/700]: mean_loss=0.00806722411653027
Online_Training [579/700]: mean_loss=0.009215754922479391
Online_Training [580/700]: mean_loss=0.003534104587743059
Online_Training [581/700]: mean_loss=0.00930671626701951
Online_Training [582/700]: mean_loss=0.006784004624933004
Online_Training [583/700]: mean_loss=0.005644318705890328
Online_Training [584/700]: mean_loss=0.004663437488488853
Online_Training [585/700]: mean_loss=0.08056346606463194
Online_Training [586/700]: mean_loss=0.003020269999979064
Online_Training [587/700]: mean_loss=0.007112108403816819
Online_Training [588/700]: mean_loss=0.005799330770969391
Online_Training [589/700]: mean_loss=0.004365309694549069
Online_Training [590/700]: mean_loss=0.014802142279222608
Online_Training [591/700]: mean_loss=0.00612458644900471
Online_Training [592/700]: mean_loss=0.0022372238454408944
Online_Training [593/700]: mean_loss=0.0027266177639830858
Online_Training [594/700]: mean_loss=0.00835185986943543
Online_Training [595/700]: mean_loss=0.020253814524039626
Online_Training [596/700]: mean_loss=0.002450276690069586
Online_Training [597/700]: mean_loss=0.009571514907293022
Online_Training [598/700]: mean_loss=0.005978382017929107
Online_Training [599/700]: mean_loss=0.008422189683187753
Online_Training [600/700]: mean_loss=0.015292796539142728
Online_Training [601/700]: mean_loss=0.005200971267186105
Online_Training [602/700]: mean_loss=0.005715493171010166
Online_Training [603/700]: mean_loss=0.010235829395242035
Online_Training [604/700]: mean_loss=0.08667443972080946
Online_Training [605/700]: mean_loss=0.02754318155348301
Online_Training [606/700]: mean_loss=0.027082904940471053
Online_Training [607/700]: mean_loss=0.01533028669655323
Online_Training [608/700]: mean_loss=0.00849864084739238
Online_Training [609/700]: mean_loss=0.015423718141391873
Online_Training [610/700]: mean_loss=0.010152018629014492
Online_Training [611/700]: mean_loss=0.0052696564816869795
Online_Training [612/700]: mean_loss=0.012899887631647289
Online_Training [613/700]: mean_loss=0.007328819716349244
Online_Training [614/700]: mean_loss=0.024792242562398314
Online_Training [615/700]: mean_loss=0.008174055721610785
Online_Training [616/700]: mean_loss=0.008537720947060734
Online_Training [617/700]: mean_loss=0.00655666075181216
Online_Training [618/700]: mean_loss=0.011561048217117786
Online_Training [619/700]: mean_loss=0.008039611915592104
Online_Training [620/700]: mean_loss=0.010118709411472082
Online_Training [621/700]: mean_loss=0.006301934830844402
Online_Training [622/700]: mean_loss=0.00836891814833507
Online_Training [623/700]: mean_loss=0.008163495338521898
Online_Training [624/700]: mean_loss=0.00992466532625258
Online_Training [625/700]: mean_loss=0.010747444350272417
Online_Training [626/700]: mean_loss=0.007594016031362116
Online_Training [627/700]: mean_loss=0.11123404651880264
Online_Training [628/700]: mean_loss=0.029593805084004998
Online_Training [629/700]: mean_loss=0.0050169339519925416
Online_Training [630/700]: mean_loss=0.009316945332102478
Online_Training [631/700]: mean_loss=0.013714806758798659
Online_Training [632/700]: mean_loss=0.01005529158283025
Online_Training [633/700]: mean_loss=0.005797851481474936
Online_Training [634/700]: mean_loss=0.01142274506855756
Online_Training [635/700]: mean_loss=0.006669707770925015
Online_Training [636/700]: mean_loss=0.02114697196520865
Online_Training [637/700]: mean_loss=0.00790815445361659
Online_Training [638/700]: mean_loss=0.018076757434755564
Online_Training [639/700]: mean_loss=0.010132061142940074
Online_Training [640/700]: mean_loss=0.01348791120108217
Online_Training [641/700]: mean_loss=0.015330393332988024
Online_Training [642/700]: mean_loss=0.01027992635499686
Online_Training [643/700]: mean_loss=0.0054037501104176044
Online_Training [644/700]: mean_loss=0.010346023133024573
Online_Training [645/700]: mean_loss=0.004589128016959876
Online_Training [646/700]: mean_loss=0.004908907925710082
Online_Training [647/700]: mean_loss=0.0037056590081192553
Online_Training [648/700]: mean_loss=0.005194682918954641
Online_Training [649/700]: mean_loss=0.005064917029812932
Online_Training [650/700]: mean_loss=0.008696488803252578
Online_Training [651/700]: mean_loss=0.004309160256525502
Online_Training [652/700]: mean_loss=0.016529306420125067
Online_Training [653/700]: mean_loss=0.0057976190582849085
Online_Training [654/700]: mean_loss=0.0027880080742761493
Online_Training [655/700]: mean_loss=0.004135267867241055
Online_Training [656/700]: mean_loss=0.006218654511030763
Online_Training [657/700]: mean_loss=0.02600341523066163
Online_Training [658/700]: mean_loss=0.012000988470390439
Online_Training [659/700]: mean_loss=0.009870471083559096
Online_Training [660/700]: mean_loss=0.01717769494280219
Online_Training [661/700]: mean_loss=0.007845337386243045
Online_Training [662/700]: mean_loss=0.007766831666231155
Online_Training [663/700]: mean_loss=0.008673599746543914
Online_Training [664/700]: mean_loss=0.011787481023930013
Online_Training [665/700]: mean_loss=0.006397083343472332
Online_Training [666/700]: mean_loss=0.01805781270377338
Online_Training [667/700]: mean_loss=0.0035347638186067343
Online_Training [668/700]: mean_loss=0.008908431394957006
Online_Training [669/700]: mean_loss=0.006091797724366188
Online_Training [670/700]: mean_loss=0.009598051896318793
Online_Training [671/700]: mean_loss=0.005686701973900199
Online_Training [672/700]: mean_loss=0.010995233315043151
Online_Training [673/700]: mean_loss=0.0023567770840600133
Online_Training [674/700]: mean_loss=0.01658337633125484
Online_Training [675/700]: mean_loss=0.005912369000725448
Online_Training [676/700]: mean_loss=0.01016676495783031
Online_Training [677/700]: mean_loss=0.05768671631813049
Online_Training [678/700]: mean_loss=0.02044749748893082
Online_Training [679/700]: mean_loss=0.004013397934613749
Online_Training [680/700]: mean_loss=0.008219668350648135
Online_Training [681/700]: mean_loss=0.006555998581461608
Online_Training [682/700]: mean_loss=0.005649759143125266
Online_Training [683/700]: mean_loss=0.00599049509037286
Online_Training [684/700]: mean_loss=0.004479655064642429
Online_Training [685/700]: mean_loss=0.016728424350731075
Online_Training [686/700]: mean_loss=0.006842101633083075
Online_Training [687/700]: mean_loss=0.016893766820430756
Online_Training [688/700]: mean_loss=0.004072123294463381
Online_Training [689/700]: mean_loss=0.013851787196472287
Online_Training [690/700]: mean_loss=0.006371887458954006
Online_Training [691/700]: mean_loss=0.0234400846529752
Online_Training [692/700]: mean_loss=0.0030499962449539453
Online_Training [693/700]: mean_loss=0.008384488115552813
Online_Training [694/700]: mean_loss=0.009392963722348213
Online_Training [695/700]: mean_loss=0.016399805899709463
Online_Training [696/700]: mean_loss=0.10849774815142155
Online_Training [697/700]: mean_loss=0.0942657757550478
Online_Training [698/700]: mean_loss=0.01047954079695046
Online_Training [699/700]: mean_loss=0.008149243600200862
Online_Training [700/700]: mean_loss=0.004995495721232146
Q_Learning [1/300]: mean_loss=0.1360450591892004
Q_Learning [2/300]: mean_loss=0.18152598291635513
Q_Learning [3/300]: mean_loss=0.1315509518608451
Q_Learning [4/300]: mean_loss=0.07164035830646753
Q_Learning [5/300]: mean_loss=0.09070831630378962
Q_Learning [6/300]: mean_loss=0.05259845033288002
Q_Learning [7/300]: mean_loss=0.05828543612733483
Q_Learning [8/300]: mean_loss=0.0966942235827446
Q_Learning [9/300]: mean_loss=0.053070586174726486
Q_Learning [10/300]: mean_loss=0.03772999066859484
Q_Learning [11/300]: mean_loss=0.0182993687922135
Q_Learning [12/300]: mean_loss=0.025542360497638583
Q_Learning [13/300]: mean_loss=0.048995491582900286
Q_Learning [14/300]: mean_loss=0.03308009332977235
Q_Learning [15/300]: mean_loss=0.012992322095669806
Q_Learning [16/300]: mean_loss=0.03128959471359849
Q_Learning [17/300]: mean_loss=0.029417560901492834
Q_Learning [18/300]: mean_loss=0.035115032689645886
Q_Learning [19/300]: mean_loss=0.10863082576543093
Q_Learning [20/300]: mean_loss=0.040958392433822155
Q_Learning [21/300]: mean_loss=0.01877583283931017
Q_Learning [22/300]: mean_loss=0.04038807190954685
Q_Learning [23/300]: mean_loss=0.024123028852045536
Q_Learning [24/300]: mean_loss=0.011036808253265917
Q_Learning [25/300]: mean_loss=0.03626334248110652
Q_Learning [26/300]: mean_loss=0.040442229714244604
Q_Learning [27/300]: mean_loss=0.07121334411203861
Q_Learning [28/300]: mean_loss=0.03571231523528695
Q_Learning [29/300]: mean_loss=0.014921432244591415
Q_Learning [30/300]: mean_loss=0.020992502802982926
Q_Learning [31/300]: mean_loss=0.01396052015479654
Q_Learning [32/300]: mean_loss=0.04988735634833574
Q_Learning [33/300]: mean_loss=0.027481930796056986
Q_Learning [34/300]: mean_loss=0.017519345972687006
Q_Learning [35/300]: mean_loss=0.028368420200422406
Q_Learning [36/300]: mean_loss=0.03635923704132438
Q_Learning [37/300]: mean_loss=0.006130990048404783
Q_Learning [38/300]: mean_loss=0.019731502514332533
Q_Learning [39/300]: mean_loss=0.02095375512726605
Q_Learning [40/300]: mean_loss=0.009366198093630373
Q_Learning [41/300]: mean_loss=0.03791818767786026
Q_Learning [42/300]: mean_loss=0.05938509292900562
Q_Learning [43/300]: mean_loss=0.038326041772961617
Q_Learning [44/300]: mean_loss=0.00765244773356244
Q_Learning [45/300]: mean_loss=0.01892873481847346
Q_Learning [46/300]: mean_loss=0.008828879799693823
Q_Learning [47/300]: mean_loss=0.02579806512221694
Q_Learning [48/300]: mean_loss=0.03308062697760761
Q_Learning [49/300]: mean_loss=0.015482599148526788
Q_Learning [50/300]: mean_loss=0.005203932349104434
Q_Learning [51/300]: mean_loss=0.0114255117950961
Q_Learning [52/300]: mean_loss=0.02188924653455615
Q_Learning [53/300]: mean_loss=0.03431047173216939
Q_Learning [54/300]: mean_loss=0.016587561927735806
Q_Learning [55/300]: mean_loss=0.020434871315956116
Q_Learning [56/300]: mean_loss=0.016424249741248786
Q_Learning [57/300]: mean_loss=0.010520399315282702
Q_Learning [58/300]: mean_loss=0.02158665074966848
Q_Learning [59/300]: mean_loss=0.12346841674298048
Q_Learning [60/300]: mean_loss=0.03134755394421518
Q_Learning [61/300]: mean_loss=0.06747220596298575
Q_Learning [62/300]: mean_loss=0.007155777653679252
Q_Learning [63/300]: mean_loss=0.015227245865389705
Q_Learning [64/300]: mean_loss=0.016415471443906426
Q_Learning [65/300]: mean_loss=0.0274122201371938
Q_Learning [66/300]: mean_loss=0.05828431760892272
Q_Learning [67/300]: mean_loss=0.012894292012788355
Q_Learning [68/300]: mean_loss=0.03497633361257613
Q_Learning [69/300]: mean_loss=0.020198850193992257
Q_Learning [70/300]: mean_loss=0.011853931355290115
Q_Learning [71/300]: mean_loss=0.012412031064741313
Q_Learning [72/300]: mean_loss=0.028636085335165262
Q_Learning [73/300]: mean_loss=0.017113738460466266
Q_Learning [74/300]: mean_loss=0.024609923595562577
Q_Learning [75/300]: mean_loss=0.018443294567987323
Q_Learning [76/300]: mean_loss=0.020999553380534053
Q_Learning [77/300]: mean_loss=0.04970131441950798
Q_Learning [78/300]: mean_loss=0.006575083883944899
Q_Learning [79/300]: mean_loss=0.00493897870182991
Q_Learning [80/300]: mean_loss=0.013337070005945861
Q_Learning [81/300]: mean_loss=0.022213941905647516
Q_Learning [82/300]: mean_loss=0.04369970317929983
Q_Learning [83/300]: mean_loss=0.006191195861902088
Q_Learning [84/300]: mean_loss=0.018393065314739943
Q_Learning [85/300]: mean_loss=0.02009801147505641
Q_Learning [86/300]: mean_loss=0.07633525040000677
Q_Learning [87/300]: mean_loss=0.04795391671359539
Q_Learning [88/300]: mean_loss=0.018256393494084477
Q_Learning [89/300]: mean_loss=0.01765244291163981
Q_Learning [90/300]: mean_loss=0.037667508237063885
Q_Learning [91/300]: mean_loss=0.01325967360753566
Q_Learning [92/300]: mean_loss=0.005967109638731927
Q_Learning [93/300]: mean_loss=0.018952491460368037
Q_Learning [94/300]: mean_loss=0.022031273925676942
Q_Learning [95/300]: mean_loss=0.01359883660916239
Q_Learning [96/300]: mean_loss=0.011248809867538512
Q_Learning [97/300]: mean_loss=0.017610154347494245
Q_Learning [98/300]: mean_loss=0.008403539599385113
Q_Learning [99/300]: mean_loss=0.010864099022001028
Q_Learning [100/300]: mean_loss=0.006746741244569421
Q_Learning [101/300]: mean_loss=0.014562364551238716
Q_Learning [102/300]: mean_loss=0.00863192556425929
Q_Learning [103/300]: mean_loss=0.02463115775026381
Q_Learning [104/300]: mean_loss=0.007886173960287124
Q_Learning [105/300]: mean_loss=0.007196822494734079
Q_Learning [106/300]: mean_loss=0.013197455205954611
Q_Learning [107/300]: mean_loss=0.030175782274454832
Q_Learning [108/300]: mean_loss=0.008389732625801116
Q_Learning [109/300]: mean_loss=0.01223880099132657
Q_Learning [110/300]: mean_loss=0.0174190157558769
Q_Learning [111/300]: mean_loss=0.006447003106586635
Q_Learning [112/300]: mean_loss=0.009831171832047403
Q_Learning [113/300]: mean_loss=0.019321303814649582
Q_Learning [114/300]: mean_loss=0.010963536216877401
Q_Learning [115/300]: mean_loss=0.01268661837093532
Q_Learning [116/300]: mean_loss=0.010925907641649246
Q_Learning [117/300]: mean_loss=0.006148975226096809
Q_Learning [118/300]: mean_loss=0.006189144041854888
Q_Learning [119/300]: mean_loss=0.009510295116342604
Q_Learning [120/300]: mean_loss=0.011137984343804419
Q_Learning [121/300]: mean_loss=0.0343119646422565
Q_Learning [122/300]: mean_loss=0.023603624431416392
Q_Learning [123/300]: mean_loss=0.013901371043175459
Q_Learning [124/300]: mean_loss=0.005072382860817015
Q_Learning [125/300]: mean_loss=0.02082975674420595
Q_Learning [126/300]: mean_loss=0.019976859912276268
Q_Learning [127/300]: mean_loss=0.008126027591060847
Q_Learning [128/300]: mean_loss=0.08805488795042038
Q_Learning [129/300]: mean_loss=0.0803478630259633
Q_Learning [130/300]: mean_loss=0.016507938504219055
Q_Learning [131/300]: mean_loss=0.017259768676012754
Q_Learning [132/300]: mean_loss=0.03494942467659712
Q_Learning [133/300]: mean_loss=0.017670999746769667
Q_Learning [134/300]: mean_loss=0.0066160595160909
Q_Learning [135/300]: mean_loss=0.007946826168335974
Q_Learning [136/300]: mean_loss=0.0025197871727868915
Q_Learning [137/300]: mean_loss=0.007339833420701325
Q_Learning [138/300]: mean_loss=0.012008512858301401
Q_Learning [139/300]: mean_loss=0.009506782342214137
Q_Learning [140/300]: mean_loss=0.12882347125560045
Q_Learning [141/300]: mean_loss=0.03717625583522022
Q_Learning [142/300]: mean_loss=0.029995251912623644
Q_Learning [143/300]: mean_loss=0.007411941536702216
Q_Learning [144/300]: mean_loss=0.0049385480233468115
Q_Learning [145/300]: mean_loss=0.028705716831609607
Q_Learning [146/300]: mean_loss=0.01436989358626306
Q_Learning [147/300]: mean_loss=0.0369593040086329
Q_Learning [148/300]: mean_loss=0.01583286130335182
Q_Learning [149/300]: mean_loss=0.012998650199733675
Q_Learning [150/300]: mean_loss=0.023801248520612717
Q_Learning [151/300]: mean_loss=0.019154156791046262
Q_Learning [152/300]: mean_loss=0.007455940765794367
Q_Learning [153/300]: mean_loss=0.008468018437270075
Q_Learning [154/300]: mean_loss=0.002582322311354801
Q_Learning [155/300]: mean_loss=0.012878686422482133
Q_Learning [156/300]: mean_loss=0.01096641004551202
Q_Learning [157/300]: mean_loss=0.014928917633369565
Q_Learning [158/300]: mean_loss=0.013776211184449494
Q_Learning [159/300]: mean_loss=0.012607372365891933
Q_Learning [160/300]: mean_loss=0.010743888560682535
Q_Learning [161/300]: mean_loss=0.009792444063350558
Q_Learning [162/300]: mean_loss=0.010395627119578421
Q_Learning [163/300]: mean_loss=0.011866382556036115
Q_Learning [164/300]: mean_loss=0.005049320287071168
Q_Learning [165/300]: mean_loss=0.01453624595887959
Q_Learning [166/300]: mean_loss=0.015890739858150482
Q_Learning [167/300]: mean_loss=0.009290143148973584
Q_Learning [168/300]: mean_loss=0.004852659360039979
Q_Learning [169/300]: mean_loss=0.011137173394672573
Q_Learning [170/300]: mean_loss=0.012674257159233093
Q_Learning [171/300]: mean_loss=0.04365141876041889
Q_Learning [172/300]: mean_loss=0.009142524562776089
Q_Learning [173/300]: mean_loss=0.005080422852188349
Q_Learning [174/300]: mean_loss=0.0040493515552952886
Q_Learning [175/300]: mean_loss=0.0190938045270741
Q_Learning [176/300]: mean_loss=0.005993695987854153
Q_Learning [177/300]: mean_loss=0.021915937075391412
Q_Learning [178/300]: mean_loss=0.010435645468533039
Q_Learning [179/300]: mean_loss=0.08259310107678175
Q_Learning [180/300]: mean_loss=0.06662485422566533
Q_Learning [181/300]: mean_loss=0.03000323660671711
Q_Learning [182/300]: mean_loss=0.010120939230546355
Q_Learning [183/300]: mean_loss=0.010701397550292313
Q_Learning [184/300]: mean_loss=0.014449354843236506
Q_Learning [185/300]: mean_loss=0.012429281254298985
Q_Learning [186/300]: mean_loss=0.01841136463917792
Q_Learning [187/300]: mean_loss=0.010210636188276112
Q_Learning [188/300]: mean_loss=0.009634526679292321
Q_Learning [189/300]: mean_loss=0.017753577092662454
Q_Learning [190/300]: mean_loss=0.011831002484541386
Q_Learning [191/300]: mean_loss=0.008389129885472357
Q_Learning [192/300]: mean_loss=0.01192683749832213
Q_Learning [193/300]: mean_loss=0.007675967121031135
Q_Learning [194/300]: mean_loss=0.019843069603666663
Q_Learning [195/300]: mean_loss=0.007238298479933292
Q_Learning [196/300]: mean_loss=0.008560329675674438
Q_Learning [197/300]: mean_loss=0.005625941616017371
Q_Learning [198/300]: mean_loss=0.008971079951152205
Q_Learning [199/300]: mean_loss=0.004317281011026353
Q_Learning [200/300]: mean_loss=0.01018640911206603
Q_Learning [201/300]: mean_loss=0.005344688310287893
Q_Learning [202/300]: mean_loss=0.10765337012708187
Q_Learning [203/300]: mean_loss=0.03040660941042006
Q_Learning [204/300]: mean_loss=0.01743215578608215
Q_Learning [205/300]: mean_loss=0.014658330823294818
Q_Learning [206/300]: mean_loss=0.012553318054415286
Q_Learning [207/300]: mean_loss=0.008322697831317782
Q_Learning [208/300]: mean_loss=0.013212045188993216
Q_Learning [209/300]: mean_loss=0.007494116551242769
Q_Learning [210/300]: mean_loss=0.009890642599202693
Q_Learning [211/300]: mean_loss=0.013302643434144557
Q_Learning [212/300]: mean_loss=0.008031625184230506
Q_Learning [213/300]: mean_loss=0.010649951174855232
Q_Learning [214/300]: mean_loss=0.006833667634055018
Q_Learning [215/300]: mean_loss=0.030249689240008593
Q_Learning [216/300]: mean_loss=0.014256461523473263
Q_Learning [217/300]: mean_loss=0.009448297438211739
Q_Learning [218/300]: mean_loss=0.006697244942188263
Q_Learning [219/300]: mean_loss=0.010936555685475469
Q_Learning [220/300]: mean_loss=0.013280396698974073
Q_Learning [221/300]: mean_loss=0.00889321806607768
Q_Learning [222/300]: mean_loss=0.009360293159261346
Q_Learning [223/300]: mean_loss=0.016120691667310894
Q_Learning [224/300]: mean_loss=0.005252530158031732
Q_Learning [225/300]: mean_loss=0.004382336686830968
Q_Learning [226/300]: mean_loss=0.022496451623737812
Q_Learning [227/300]: mean_loss=0.007896608440205455
Q_Learning [228/300]: mean_loss=0.004380233964184299
Q_Learning [229/300]: mean_loss=0.014124363660812378
Q_Learning [230/300]: mean_loss=0.00825716252438724
Q_Learning [231/300]: mean_loss=0.02422262425534427
Q_Learning [232/300]: mean_loss=0.009843086008913815
Q_Learning [233/300]: mean_loss=0.006228042300790548
Q_Learning [234/300]: mean_loss=0.05593910114839673
Q_Learning [235/300]: mean_loss=0.10665027517825365
Q_Learning [236/300]: mean_loss=0.010692193754948676
Q_Learning [237/300]: mean_loss=0.041676695458590984
Q_Learning [238/300]: mean_loss=0.012425752356648445
Q_Learning [239/300]: mean_loss=0.006259050685912371
Q_Learning [240/300]: mean_loss=0.01141499332152307
Q_Learning [241/300]: mean_loss=0.011138388654217124
Q_Learning [242/300]: mean_loss=0.011756492778658867
Q_Learning [243/300]: mean_loss=0.017753183841705322
Q_Learning [244/300]: mean_loss=0.015032113995403051
Q_Learning [245/300]: mean_loss=0.012647105264477432
Q_Learning [246/300]: mean_loss=0.017229510005563498
Q_Learning [247/300]: mean_loss=0.016664240742102265
Q_Learning [248/300]: mean_loss=0.016820867429487407
Q_Learning [249/300]: mean_loss=0.034614323638379574
Q_Learning [250/300]: mean_loss=0.006119874655269086
Q_Learning [251/300]: mean_loss=0.004951912385877222
Q_Learning [252/300]: mean_loss=0.022924453020095825
Q_Learning [253/300]: mean_loss=0.008612706093117595
Q_Learning [254/300]: mean_loss=0.003907578749931417
Q_Learning [255/300]: mean_loss=0.006132206821348518
Q_Learning [256/300]: mean_loss=0.015546450740657747
Q_Learning [257/300]: mean_loss=0.007053508597891778
Q_Learning [258/300]: mean_loss=0.0093311796663329
Q_Learning [259/300]: mean_loss=0.003769472474232316
Q_Learning [260/300]: mean_loss=0.0032535712234675884
Q_Learning [261/300]: mean_loss=0.00882600957993418
Q_Learning [262/300]: mean_loss=0.004970659560058266
Q_Learning [263/300]: mean_loss=0.0070696823531761765
Q_Learning [264/300]: mean_loss=0.005174250574782491
Q_Learning [265/300]: mean_loss=0.09805793222039938
Q_Learning [266/300]: mean_loss=0.09862726088613272
Q_Learning [267/300]: mean_loss=0.010146582964807749
Q_Learning [268/300]: mean_loss=0.016874815803021193
Q_Learning [269/300]: mean_loss=0.013827802380546927
Q_Learning [270/300]: mean_loss=0.10687212739139795
Q_Learning [271/300]: mean_loss=0.021223275223746896
Q_Learning [272/300]: mean_loss=0.013373378198593855
Q_Learning [273/300]: mean_loss=0.01679375022649765
Q_Learning [274/300]: mean_loss=0.006344145105686039
Q_Learning [275/300]: mean_loss=0.01824900833889842
Q_Learning [276/300]: mean_loss=0.015048926696181297
Q_Learning [277/300]: mean_loss=0.009152623009867966
Q_Learning [278/300]: mean_loss=0.008618959225714207
Q_Learning [279/300]: mean_loss=0.009659316507168114
Q_Learning [280/300]: mean_loss=0.009791206801310182
Q_Learning [281/300]: mean_loss=0.006569749384652823
Q_Learning [282/300]: mean_loss=0.015172471641562879
Q_Learning [283/300]: mean_loss=0.018018159898929298
Q_Learning [284/300]: mean_loss=0.009364414378069341
Q_Learning [285/300]: mean_loss=0.02310073748230934
Q_Learning [286/300]: mean_loss=0.004151668777922168
Q_Learning [287/300]: mean_loss=0.0046493198606185615
Q_Learning [288/300]: mean_loss=0.016760939150117338
Q_Learning [289/300]: mean_loss=0.00605433463351801
Q_Learning [290/300]: mean_loss=0.003928220452507958
Q_Learning [291/300]: mean_loss=0.014248012215830386
Q_Learning [292/300]: mean_loss=0.010260667651891708
Q_Learning [293/300]: mean_loss=0.0956411948427558
Q_Learning [294/300]: mean_loss=0.023970493581146002
Q_Learning [295/300]: mean_loss=0.010574051761068404
Q_Learning [296/300]: mean_loss=0.015174631611444056
Q_Learning [297/300]: mean_loss=0.014280621544457972
Q_Learning [298/300]: mean_loss=0.007071814383380115
Q_Learning [299/300]: mean_loss=0.018243317725136876
Q_Learning [300/300]: mean_loss=0.00948328583035618
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.6711391   0.21107489]
[0, 2, 1, 0, 2, 1, 1, 2, 2, 0, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 1, 0, 0, 1, 0, 2, 2, 0, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 1, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0, 2, 2, 2, 0, 1, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 2, 0, 0, 2, 2, 2, 1, 1, 2, 1, 0, 2, 0, 1, 1, 1, 1, 2, 0, 2, 1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 2, 2, 2, 2, 1, 2, 0, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 2, 2, 2, 1, 2, 0, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 0, 0, 2, 2, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 2, 0, 2, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 0]
[0, 1, 0, 2, 1, 0, 0, 1, 1, 2, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 1, 1, 1, 2, 1, 1, 0, 0, 0, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 3, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1, 1, 1, 4, 0, 0, 1, 1, 2, 0, 0, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 1, 3, 0, 1, 2, 2, 1, 1, 1, 0, 0, 1, 2, 2, 1, 2, 3, 0, 1, 0, 3, 2, 1, 0, 0, 2, 2, 0, 2, 2, 2, 3, 5, 2, 3, 0, 0, 0, 0, 2, 2, 3, 1, 1, 1, 1, 1, 1, 0, 3, 2, 1, 4, 1, 2, 1, 0, 0, 1, 2, 4, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 6, 6, 0, 2, 1, 1, 1, 1, 1, 2, 3, 1, 2, 0, 1, 0, 2, 1, 3, 7, 1, 4, 0, 1, 0, 1, 7, 1, 2, 6, 2, 0, 2, 2, 1, 2, 1, 2, 2, 0, 0, 2, 3, 2, 0, 5, 7, 2, 2, 2, 0, 2, 4, 2, 8, 7, 2, 1, 8, 1, 2, 4, 4, 1, 2, 1, 8, 0, 0, 1, 2, 4, 0, 8, 2, 1, 0, 2, 2, 3, 2, 1, 2, 1, 1, 2, 2, 0, 0, 7, 2, 7, 0, 2, 3, 0, 0, 4, 0, 4, 2, 1, 2, 1, 2, 1, 0, 7, 1, 3, 2, 0, 2, 1, 6, 6, 2, 2, 2, 2, 8]
Centroids: [[-0.8749785, 0.17768091], [-0.005763975, 0.9916157], [-1.1902822, 1.4791359]]
Centroids: [[0.035896476, 0.9137982], [-1.147828, 1.4145947], [-0.9123272, 0.11378415], [-0.04251049, 1.6691648], [0.6790682, 0.40577215], [1.9006386, 3.5273433], [-1.0904692, 2.5376801], [-2.2209697, 1.5413369], [-0.30551958, -0.50308245]]
Contingency Matrix: 
[[ 4  8 76  0  0  0  2  0  5]
 [68 11  7 11 10  1  1  0  0]
 [ 3 75  5  3  0  1  2  7  0]]
[[4, 8, 76, 0, 0, 0, 2, 0, 5], [68, 11, 7, 11, 10, 1, 1, 0, 0], [3, 75, 5, 3, 0, 1, 2, 7, 0]]
[[4, 8, 76, 0, 0, 0, 2, 0, 5], [68, 11, 7, 11, 10, 1, 1, 0, 0], [3, 75, 5, 3, 0, 1, 2, 7, 0]]
[0, 1, 2, 3, 4, 5, 6, 7, 8]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [68, 11, -1, 11, 10, 1, 1, 0, 0], [3, 75, -1, 3, 0, 1, 2, 7, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [68, -1, -1, 11, 10, 1, 1, 0, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 2, 2: 1, 1: 0}
New Contingency Matrix: 
[[76  4  8  0  0  0  2  0  5]
 [ 7 68 11 11 10  1  1  0  0]
 [ 5  3 75  3  0  1  2  7  0]]
New Clustered Label Sequence: [2, 0, 1, 3, 4, 5, 6, 7, 8]
Diagonal_Elements: [76, 68, 75], Sum: 219
All_Elements: [76, 4, 8, 0, 0, 0, 2, 0, 5, 7, 68, 11, 11, 10, 1, 1, 0, 0, 5, 3, 75, 3, 0, 1, 2, 7, 0], Sum: 300
Accuracy: 0.73
