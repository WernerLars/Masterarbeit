Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_9_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise020.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_9_opt_temp_noisy/C_Difficult2_noise020.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-14_22_15
Punishment_Coefficient: 1.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017D017B2CC0>
Sampling rate: 24000.0
Raw: [-0.05920843 -0.02398302  0.01513494 ...  0.2971695   0.32984394
  0.35872829]
Times: [    337    1080    1305 ... 1438651 1438787 1439662]
Cluster: [2 1 1 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3493
First aligned Spike Frame: [ 0.50880334  0.56984686  0.60721022  0.60769692  0.58122704  0.55003969
  0.51479324  0.46436685  0.40848987  0.36206071  0.31750134  0.26828304
  0.23270096  0.2305818   0.25904633  0.30599383  0.36680145  0.45670025
  0.60261795  0.8012213   1.02149976  1.23478943  1.38977263  1.39868415
  1.211664    0.88028336  0.50425138  0.15449729 -0.12937778 -0.32272009
 -0.40685817 -0.38921932 -0.31829776 -0.24412685 -0.18860857 -0.1442941
 -0.0976923  -0.0504865  -0.01384986  0.00955437  0.03047694  0.05600466
  0.07308225  0.06101434  0.01148826 -0.0607151  -0.13636803]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1195
Cluster 2, Occurrences: 1147
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.37041374668478966
Online_Training [2/700]: mean_loss=0.14701982773840427
Online_Training [3/700]: mean_loss=0.23655742779374123
Online_Training [4/700]: mean_loss=0.13740210607647896
Online_Training [5/700]: mean_loss=0.18680274300277233
Online_Training [6/700]: mean_loss=0.11873102560639381
Online_Training [7/700]: mean_loss=0.0882771648466587
Online_Training [8/700]: mean_loss=0.12249359302222729
Online_Training [9/700]: mean_loss=0.1315347608178854
Online_Training [10/700]: mean_loss=0.09002522379159927
Online_Training [11/700]: mean_loss=0.13681597169488668
Online_Training [12/700]: mean_loss=0.09716070350259542
Online_Training [13/700]: mean_loss=0.038587227929383516
Online_Training [14/700]: mean_loss=0.13945105113089085
Online_Training [15/700]: mean_loss=0.055312913842499256
Online_Training [16/700]: mean_loss=0.05968768894672394
Online_Training [17/700]: mean_loss=0.027791400672867894
Online_Training [18/700]: mean_loss=0.0878488328307867
Online_Training [19/700]: mean_loss=0.03167422069236636
Online_Training [20/700]: mean_loss=0.023521044058725238
Online_Training [21/700]: mean_loss=0.025595201877877116
Online_Training [22/700]: mean_loss=0.05650171497836709
Online_Training [23/700]: mean_loss=0.4153177998960018
Online_Training [24/700]: mean_loss=0.14672502130270004
Online_Training [25/700]: mean_loss=0.03596802894026041
Online_Training [26/700]: mean_loss=0.12077843211591244
Online_Training [27/700]: mean_loss=0.08909592311829329
Online_Training [28/700]: mean_loss=0.15983080491423607
Online_Training [29/700]: mean_loss=0.07773512974381447
Online_Training [30/700]: mean_loss=0.08616785984486341
Online_Training [31/700]: mean_loss=0.1657737549394369
Online_Training [32/700]: mean_loss=0.10091410018503666
Online_Training [33/700]: mean_loss=0.07771144341677427
Online_Training [34/700]: mean_loss=0.46132805570960045
Online_Training [35/700]: mean_loss=0.25020928494632244
Online_Training [36/700]: mean_loss=0.10468360874801874
Online_Training [37/700]: mean_loss=0.07258762698620558
Online_Training [38/700]: mean_loss=0.11361780110746622
Online_Training [39/700]: mean_loss=0.07616629265248775
Online_Training [40/700]: mean_loss=0.12812631390988827
Online_Training [41/700]: mean_loss=0.12039064802229404
Online_Training [42/700]: mean_loss=0.07669110782444477
Online_Training [43/700]: mean_loss=0.10046321712434292
Online_Training [44/700]: mean_loss=0.23530584387481213
Online_Training [45/700]: mean_loss=0.08687528781592846
Online_Training [46/700]: mean_loss=0.05208242451772094
Online_Training [47/700]: mean_loss=0.07235487084835768
Online_Training [48/700]: mean_loss=0.09665247052907944
Online_Training [49/700]: mean_loss=0.04636055137962103
Online_Training [50/700]: mean_loss=0.05201401887461543
Online_Training [51/700]: mean_loss=0.05037973215803504
Online_Training [52/700]: mean_loss=0.04604370705783367
Online_Training [53/700]: mean_loss=0.047720547299832106
Online_Training [54/700]: mean_loss=0.10050298366695642
Online_Training [55/700]: mean_loss=0.07236435264348984
Online_Training [56/700]: mean_loss=0.044201248325407505
Online_Training [57/700]: mean_loss=0.036109503358602524
Online_Training [58/700]: mean_loss=0.0451065287925303
Online_Training [59/700]: mean_loss=0.04745828686282039
Online_Training [60/700]: mean_loss=0.026027873158454895
Online_Training [61/700]: mean_loss=0.032095004338771105
Online_Training [62/700]: mean_loss=0.019528003060258925
Online_Training [63/700]: mean_loss=0.030908192740753293
Online_Training [64/700]: mean_loss=0.017180209630168974
Online_Training [65/700]: mean_loss=0.33153940364718437
Online_Training [66/700]: mean_loss=0.14533177763223648
Online_Training [67/700]: mean_loss=0.07708119787275791
Online_Training [68/700]: mean_loss=0.03825882077217102
Online_Training [69/700]: mean_loss=0.06794014479964972
Online_Training [70/700]: mean_loss=0.06012225104495883
Online_Training [71/700]: mean_loss=0.037440011743456125
Online_Training [72/700]: mean_loss=0.07038639206439257
Online_Training [73/700]: mean_loss=0.05803449498489499
Online_Training [74/700]: mean_loss=0.046683572232723236
Online_Training [75/700]: mean_loss=0.023510875180363655
Online_Training [76/700]: mean_loss=0.02670711139217019
Online_Training [77/700]: mean_loss=0.027076089289039373
Online_Training [78/700]: mean_loss=0.04202205082401633
Online_Training [79/700]: mean_loss=0.04012154554948211
Online_Training [80/700]: mean_loss=0.04182752734050155
Online_Training [81/700]: mean_loss=0.06674373522400856
Online_Training [82/700]: mean_loss=0.05755410250276327
Online_Training [83/700]: mean_loss=0.03131308080628514
Online_Training [84/700]: mean_loss=0.03347590658813715
Online_Training [85/700]: mean_loss=0.05085113737732172
Online_Training [86/700]: mean_loss=0.051850307267159224
Online_Training [87/700]: mean_loss=0.042882722336798906
Online_Training [88/700]: mean_loss=0.029518016381189227
Online_Training [89/700]: mean_loss=0.025812336476519704
Online_Training [90/700]: mean_loss=0.03413970395922661
Online_Training [91/700]: mean_loss=0.025616351747885346
Online_Training [92/700]: mean_loss=0.047302066814154387
Online_Training [93/700]: mean_loss=0.039011156652122736
Online_Training [94/700]: mean_loss=0.05194780416786671
Online_Training [95/700]: mean_loss=0.0157510171411559
Online_Training [96/700]: mean_loss=0.04510186426341534
Online_Training [97/700]: mean_loss=0.11024831421673298
Online_Training [98/700]: mean_loss=0.02010547393001616
Online_Training [99/700]: mean_loss=0.025534897344186902
Online_Training [100/700]: mean_loss=0.05709824524819851
Online_Training [101/700]: mean_loss=0.046618981985375285
Online_Training [102/700]: mean_loss=0.07277471758425236
Online_Training [103/700]: mean_loss=0.0583755555562675
Online_Training [104/700]: mean_loss=0.027609516633674502
Online_Training [105/700]: mean_loss=0.018390757264569402
Online_Training [106/700]: mean_loss=0.0297237578779459
Online_Training [107/700]: mean_loss=0.03454855806194246
Online_Training [108/700]: mean_loss=0.027762381825596094
Online_Training [109/700]: mean_loss=0.02500155079178512
Online_Training [110/700]: mean_loss=0.03176052961498499
Online_Training [111/700]: mean_loss=0.03484894195571542
Online_Training [112/700]: mean_loss=0.02544570667669177
Online_Training [113/700]: mean_loss=0.032133571803569794
Online_Training [114/700]: mean_loss=0.05636910954490304
Online_Training [115/700]: mean_loss=0.11889050342142582
Online_Training [116/700]: mean_loss=0.13937134481966496
Online_Training [117/700]: mean_loss=0.04618277261033654
Online_Training [118/700]: mean_loss=0.052077331114560366
Online_Training [119/700]: mean_loss=0.021767521742731333
Online_Training [120/700]: mean_loss=0.034979759249836206
Online_Training [121/700]: mean_loss=0.058966392651200294
Online_Training [122/700]: mean_loss=0.024623433127999306
Online_Training [123/700]: mean_loss=0.1637945268303156
Online_Training [124/700]: mean_loss=0.03673743223771453
Online_Training [125/700]: mean_loss=0.015012998133897781
Online_Training [126/700]: mean_loss=0.008298822969663888
Online_Training [127/700]: mean_loss=0.02239955822005868
Online_Training [128/700]: mean_loss=0.024634123779833317
Online_Training [129/700]: mean_loss=0.06849689781665802
Online_Training [130/700]: mean_loss=0.01987042697146535
Online_Training [131/700]: mean_loss=0.07907330803573132
Online_Training [132/700]: mean_loss=0.02989312121644616
Online_Training [133/700]: mean_loss=0.056934076361358166
Online_Training [134/700]: mean_loss=0.0436448659747839
Online_Training [135/700]: mean_loss=0.025990313617512584
Online_Training [136/700]: mean_loss=0.051038654055446386
Online_Training [137/700]: mean_loss=0.0802721343934536
Online_Training [138/700]: mean_loss=0.05426269490271807
Online_Training [139/700]: mean_loss=0.03614852949976921
Online_Training [140/700]: mean_loss=0.011476462241262197
Online_Training [141/700]: mean_loss=0.021572529338300228
Online_Training [142/700]: mean_loss=0.006542679620906711
Online_Training [143/700]: mean_loss=0.020986550953239202
Online_Training [144/700]: mean_loss=0.044013191014528275
Online_Training [145/700]: mean_loss=0.01689661806449294
Online_Training [146/700]: mean_loss=0.025163111509755254
Online_Training [147/700]: mean_loss=0.014910498051904142
Online_Training [148/700]: mean_loss=0.05545955058187246
Online_Training [149/700]: mean_loss=0.006263157702051103
Online_Training [150/700]: mean_loss=0.029742911225184798
Online_Training [151/700]: mean_loss=0.018784666899591684
Online_Training [152/700]: mean_loss=0.030049180379137397
Online_Training [153/700]: mean_loss=0.07364764157682657
Online_Training [154/700]: mean_loss=0.02584926411509514
Online_Training [155/700]: mean_loss=0.041755244601517916
Online_Training [156/700]: mean_loss=0.031068714568391442
Online_Training [157/700]: mean_loss=0.020672571612522006
Online_Training [158/700]: mean_loss=0.09724843688309193
Online_Training [159/700]: mean_loss=0.011186689487658441
Online_Training [160/700]: mean_loss=0.020127069670706987
Online_Training [161/700]: mean_loss=0.02039201301522553
Online_Training [162/700]: mean_loss=0.03456486063078046
Online_Training [163/700]: mean_loss=0.013527313712984324
Online_Training [164/700]: mean_loss=0.016438808641396463
Online_Training [165/700]: mean_loss=0.035023758420720696
Online_Training [166/700]: mean_loss=0.012987606693059206
Online_Training [167/700]: mean_loss=0.05290492344647646
Online_Training [168/700]: mean_loss=0.04806722281500697
Online_Training [169/700]: mean_loss=0.040975218173116446
Online_Training [170/700]: mean_loss=0.034893924137577415
Online_Training [171/700]: mean_loss=0.06757381977513433
Online_Training [172/700]: mean_loss=0.027230543782934546
Online_Training [173/700]: mean_loss=0.031163758132606745
Online_Training [174/700]: mean_loss=0.013409168692305684
Online_Training [175/700]: mean_loss=0.039455979596823454
Online_Training [176/700]: mean_loss=0.011689526145346463
Online_Training [177/700]: mean_loss=0.11426954437047243
Online_Training [178/700]: mean_loss=0.0636355197057128
Online_Training [179/700]: mean_loss=0.06881939759477973
Online_Training [180/700]: mean_loss=0.032108048209920526
Online_Training [181/700]: mean_loss=0.05122114950791001
Online_Training [182/700]: mean_loss=0.042765033431351185
Online_Training [183/700]: mean_loss=0.061587704345583916
Online_Training [184/700]: mean_loss=0.016005686251446605
Online_Training [185/700]: mean_loss=0.03608632739633322
Online_Training [186/700]: mean_loss=0.013016484561376274
Online_Training [187/700]: mean_loss=0.02425665920600295
Online_Training [188/700]: mean_loss=0.06076964735984802
Online_Training [189/700]: mean_loss=0.03933060262352228
Online_Training [190/700]: mean_loss=0.02371556032449007
Online_Training [191/700]: mean_loss=0.08328642416745424
Online_Training [192/700]: mean_loss=0.05081939371302724
Online_Training [193/700]: mean_loss=0.027328307973220944
Online_Training [194/700]: mean_loss=0.030765314120799303
Online_Training [195/700]: mean_loss=0.0334312142804265
Online_Training [196/700]: mean_loss=0.026973056374117732
Online_Training [197/700]: mean_loss=0.07109950250014663
Online_Training [198/700]: mean_loss=0.017159812385216355
Online_Training [199/700]: mean_loss=0.04644598066806793
Online_Training [200/700]: mean_loss=0.01068811397999525
Online_Training [201/700]: mean_loss=0.040093967225402594
Online_Training [202/700]: mean_loss=0.028384211473166943
Online_Training [203/700]: mean_loss=0.022792496718466282
Online_Training [204/700]: mean_loss=0.07251467602327466
Online_Training [205/700]: mean_loss=0.037855681497603655
Online_Training [206/700]: mean_loss=0.04419994726777077
Online_Training [207/700]: mean_loss=0.011312285903841257
Online_Training [208/700]: mean_loss=0.028679010923951864
Online_Training [209/700]: mean_loss=0.025800277944654226
Online_Training [210/700]: mean_loss=0.059571792371571064
Online_Training [211/700]: mean_loss=0.04568183235824108
Online_Training [212/700]: mean_loss=0.02695962111465633
Online_Training [213/700]: mean_loss=0.042096787597984076
Online_Training [214/700]: mean_loss=0.04929459607228637
Online_Training [215/700]: mean_loss=0.069766731467098
Online_Training [216/700]: mean_loss=0.029627235140651464
Online_Training [217/700]: mean_loss=0.025410574860870838
Online_Training [218/700]: mean_loss=0.046422623097896576
Online_Training [219/700]: mean_loss=0.03535693930462003
Online_Training [220/700]: mean_loss=0.02030614926479757
Online_Training [221/700]: mean_loss=0.03472729539498687
Online_Training [222/700]: mean_loss=0.036280710250139236
Online_Training [223/700]: mean_loss=0.010670353658497334
Online_Training [224/700]: mean_loss=0.10967137757688761
Online_Training [225/700]: mean_loss=0.04486361285671592
Online_Training [226/700]: mean_loss=0.04692808911204338
Online_Training [227/700]: mean_loss=0.02762935310602188
Online_Training [228/700]: mean_loss=0.039980793837457895
Online_Training [229/700]: mean_loss=0.018812982132658362
Online_Training [230/700]: mean_loss=0.04294376727193594
Online_Training [231/700]: mean_loss=0.024937338894233108
Online_Training [232/700]: mean_loss=0.051748158410191536
Online_Training [233/700]: mean_loss=0.022652078652754426
Online_Training [234/700]: mean_loss=0.032217676751315594
Online_Training [235/700]: mean_loss=0.04896284593269229
Online_Training [236/700]: mean_loss=0.0477138627320528
Online_Training [237/700]: mean_loss=0.013905205763876438
Online_Training [238/700]: mean_loss=0.0642669158987701
Online_Training [239/700]: mean_loss=0.04084035009145737
Online_Training [240/700]: mean_loss=0.041268976870924234
Online_Training [241/700]: mean_loss=0.037292731925845146
Online_Training [242/700]: mean_loss=0.015072016278281808
Online_Training [243/700]: mean_loss=0.013527410803362727
Online_Training [244/700]: mean_loss=0.009491116681601852
Online_Training [245/700]: mean_loss=0.005604937730822712
Online_Training [246/700]: mean_loss=0.048496522940695286
Online_Training [247/700]: mean_loss=0.07240203022956848
Online_Training [248/700]: mean_loss=0.03975760703906417
Online_Training [249/700]: mean_loss=0.10492624528706074
Online_Training [250/700]: mean_loss=0.046094395220279694
Online_Training [251/700]: mean_loss=0.048986952286213636
Online_Training [252/700]: mean_loss=0.008017353946343064
Online_Training [253/700]: mean_loss=0.021774656837806106
Online_Training [254/700]: mean_loss=0.129318387247622
Online_Training [255/700]: mean_loss=0.009344478719867766
Online_Training [256/700]: mean_loss=0.016455214703455567
Online_Training [257/700]: mean_loss=0.03365249978378415
Online_Training [258/700]: mean_loss=0.0352684804238379
Online_Training [259/700]: mean_loss=0.05809772992506623
Online_Training [260/700]: mean_loss=0.029291485901921988
Online_Training [261/700]: mean_loss=0.03029021085239947
Online_Training [262/700]: mean_loss=0.014416951918974519
Online_Training [263/700]: mean_loss=0.02073887293227017
Online_Training [264/700]: mean_loss=0.010092875687405467
Online_Training [265/700]: mean_loss=0.05529306922107935
Online_Training [266/700]: mean_loss=0.04268463794142008
Online_Training [267/700]: mean_loss=0.035624036099761724
Online_Training [268/700]: mean_loss=0.031395073514431715
Online_Training [269/700]: mean_loss=0.04036555765196681
Online_Training [270/700]: mean_loss=0.07212575152516365
Online_Training [271/700]: mean_loss=0.10243301559239626
Online_Training [272/700]: mean_loss=0.08199685905128717
Online_Training [273/700]: mean_loss=0.057908028829842806
Online_Training [274/700]: mean_loss=0.05304357968270779
Online_Training [275/700]: mean_loss=0.09781533479690552
Online_Training [276/700]: mean_loss=0.03023706329986453
Online_Training [277/700]: mean_loss=0.027220115065574646
Online_Training [278/700]: mean_loss=0.017801281763240695
Online_Training [279/700]: mean_loss=0.027822701493278146
Online_Training [280/700]: mean_loss=0.0585482120513916
Online_Training [281/700]: mean_loss=0.03541976120322943
Online_Training [282/700]: mean_loss=0.027076163794845343
Online_Training [283/700]: mean_loss=0.021364394342526793
Online_Training [284/700]: mean_loss=0.06151098757982254
Online_Training [285/700]: mean_loss=0.02939732209779322
Online_Training [286/700]: mean_loss=0.07159370742738247
Online_Training [287/700]: mean_loss=0.013655846589244902
Online_Training [288/700]: mean_loss=0.041307900566607714
Online_Training [289/700]: mean_loss=0.032233057310804725
Online_Training [290/700]: mean_loss=0.017802999587729573
Online_Training [291/700]: mean_loss=0.05783020192757249
Online_Training [292/700]: mean_loss=0.017511454061605036
Online_Training [293/700]: mean_loss=0.021678135031834245
Online_Training [294/700]: mean_loss=0.013991811661981046
Online_Training [295/700]: mean_loss=0.05729975551366806
Online_Training [296/700]: mean_loss=0.05826112348586321
Online_Training [297/700]: mean_loss=0.034367410000413656
Online_Training [298/700]: mean_loss=0.05449562333524227
Online_Training [299/700]: mean_loss=0.04844055650755763
Online_Training [300/700]: mean_loss=0.02049112436361611
Online_Training [301/700]: mean_loss=0.014472723589278758
Online_Training [302/700]: mean_loss=0.012617965461686254
Online_Training [303/700]: mean_loss=0.009849404101260006
Online_Training [304/700]: mean_loss=0.013189854915253818
Online_Training [305/700]: mean_loss=0.06492187408730388
Online_Training [306/700]: mean_loss=0.031179050216451287
Online_Training [307/700]: mean_loss=0.027393227443099022
Online_Training [308/700]: mean_loss=0.05534380814060569
Online_Training [309/700]: mean_loss=0.015753041487187147
Online_Training [310/700]: mean_loss=0.047343910206109285
Online_Training [311/700]: mean_loss=0.03662831545807421
Online_Training [312/700]: mean_loss=0.012364816735498607
Online_Training [313/700]: mean_loss=0.014569653081707656
Online_Training [314/700]: mean_loss=0.011345195351168513
Online_Training [315/700]: mean_loss=0.047910176217556
Online_Training [316/700]: mean_loss=0.03301863605156541
Online_Training [317/700]: mean_loss=0.035110579803586006
Online_Training [318/700]: mean_loss=0.019685659557580948
Online_Training [319/700]: mean_loss=0.018943564733490348
Online_Training [320/700]: mean_loss=0.014798928867094219
Online_Training [321/700]: mean_loss=0.06522073363885283
Online_Training [322/700]: mean_loss=0.020597040187567472
Online_Training [323/700]: mean_loss=0.03211068292148411
Online_Training [324/700]: mean_loss=0.11126002296805382
Online_Training [325/700]: mean_loss=0.11734924279153347
Online_Training [326/700]: mean_loss=0.04581355978734791
Online_Training [327/700]: mean_loss=0.019341914216056466
Online_Training [328/700]: mean_loss=0.037248735781759024
Online_Training [329/700]: mean_loss=0.03722877101972699
Online_Training [330/700]: mean_loss=0.017958138370886445
Online_Training [331/700]: mean_loss=0.034203150076791644
Online_Training [332/700]: mean_loss=0.05274969665333629
Online_Training [333/700]: mean_loss=0.02799253910779953
Online_Training [334/700]: mean_loss=0.03747169114649296
Online_Training [335/700]: mean_loss=0.052131743635982275
Online_Training [336/700]: mean_loss=0.048318708315491676
Online_Training [337/700]: mean_loss=0.04363871505483985
Online_Training [338/700]: mean_loss=0.028698013396933675
Online_Training [339/700]: mean_loss=0.06193791702389717
Online_Training [340/700]: mean_loss=0.015657985815778375
Online_Training [341/700]: mean_loss=0.056951452512294054
Online_Training [342/700]: mean_loss=0.08884582202881575
Online_Training [343/700]: mean_loss=0.036360415164381266
Online_Training [344/700]: mean_loss=0.020883309189230204
Online_Training [345/700]: mean_loss=0.06196496915072203
Online_Training [346/700]: mean_loss=0.010893460363149643
Online_Training [347/700]: mean_loss=0.027795050758868456
Online_Training [348/700]: mean_loss=0.09400495234876871
Online_Training [349/700]: mean_loss=0.04428540635854006
Online_Training [350/700]: mean_loss=0.023274985142052174
Online_Training [351/700]: mean_loss=0.025041229091584682
Online_Training [352/700]: mean_loss=0.042419429402798414
Online_Training [353/700]: mean_loss=0.029160083970054984
Online_Training [354/700]: mean_loss=0.038135571870952845
Online_Training [355/700]: mean_loss=0.023338483879342675
Online_Training [356/700]: mean_loss=0.039788755122572184
Online_Training [357/700]: mean_loss=0.0463809734210372
Online_Training [358/700]: mean_loss=0.0325903445482254
Online_Training [359/700]: mean_loss=0.019938203040510416
Online_Training [360/700]: mean_loss=0.18116365559399128
Online_Training [361/700]: mean_loss=0.04222117830067873
Online_Training [362/700]: mean_loss=0.032563217682763934
Online_Training [363/700]: mean_loss=0.03544285800307989
Online_Training [364/700]: mean_loss=0.03597277496010065
Online_Training [365/700]: mean_loss=0.023281422210857272
Online_Training [366/700]: mean_loss=0.026338930474594235
Online_Training [367/700]: mean_loss=0.03360483003780246
Online_Training [368/700]: mean_loss=0.029682692140340805
Online_Training [369/700]: mean_loss=0.04148208815604448
Online_Training [370/700]: mean_loss=0.03978485194966197
Online_Training [371/700]: mean_loss=0.034007919020950794
Online_Training [372/700]: mean_loss=0.04652624996379018
Online_Training [373/700]: mean_loss=0.02547359257005155
Online_Training [374/700]: mean_loss=0.019321118015795946
Online_Training [375/700]: mean_loss=0.04405499715358019
Online_Training [376/700]: mean_loss=0.0202512766700238
Online_Training [377/700]: mean_loss=0.019322348292917013
Online_Training [378/700]: mean_loss=0.023314118618145585
Online_Training [379/700]: mean_loss=0.012819217052310705
Online_Training [380/700]: mean_loss=0.009764470858499408
Online_Training [381/700]: mean_loss=0.012287706951610744
Online_Training [382/700]: mean_loss=0.018754116725176573
Online_Training [383/700]: mean_loss=0.015692968387156725
Online_Training [384/700]: mean_loss=0.018516836455091834
Online_Training [385/700]: mean_loss=0.024216877995058894
Online_Training [386/700]: mean_loss=0.021208832738921046
Online_Training [387/700]: mean_loss=0.015608035842888057
Online_Training [388/700]: mean_loss=0.012968209222890437
Online_Training [389/700]: mean_loss=0.0299394226167351
Online_Training [390/700]: mean_loss=0.04219074780121446
Online_Training [391/700]: mean_loss=0.02501284913159907
Online_Training [392/700]: mean_loss=0.04316983139142394
Online_Training [393/700]: mean_loss=0.036366801243275404
Online_Training [394/700]: mean_loss=0.021739591844379902
Online_Training [395/700]: mean_loss=0.055478403344750404
Online_Training [396/700]: mean_loss=0.015917303855530918
Online_Training [397/700]: mean_loss=0.019504190189763904
Online_Training [398/700]: mean_loss=0.017507260898128152
Online_Training [399/700]: mean_loss=0.01942649856209755
Online_Training [400/700]: mean_loss=0.007922859396785498
Online_Training [401/700]: mean_loss=0.07072651106864214
Online_Training [402/700]: mean_loss=0.16169740818440914
Online_Training [403/700]: mean_loss=0.02965603000484407
Online_Training [404/700]: mean_loss=0.020155917387455702
Online_Training [405/700]: mean_loss=0.068414940033108
Online_Training [406/700]: mean_loss=0.05210419278591871
Online_Training [407/700]: mean_loss=0.08773450646549463
Online_Training [408/700]: mean_loss=0.21845263242721558
Online_Training [409/700]: mean_loss=0.02288899477571249
Online_Training [410/700]: mean_loss=0.04761610832065344
Online_Training [411/700]: mean_loss=0.031105445697903633
Online_Training [412/700]: mean_loss=0.02886350709013641
Online_Training [413/700]: mean_loss=0.1435877326875925
Online_Training [414/700]: mean_loss=0.014540230273269117
Online_Training [415/700]: mean_loss=0.01826282124966383
Online_Training [416/700]: mean_loss=0.009645777638070285
Online_Training [417/700]: mean_loss=0.02885534381493926
Online_Training [418/700]: mean_loss=0.024611589964479208
Online_Training [419/700]: mean_loss=0.023745491402223706
Online_Training [420/700]: mean_loss=0.023710560286417603
Online_Training [421/700]: mean_loss=0.021913325414061546
Online_Training [422/700]: mean_loss=0.02520981803536415
Online_Training [423/700]: mean_loss=0.012818361050449312
Online_Training [424/700]: mean_loss=0.03503439063206315
Online_Training [425/700]: mean_loss=0.07526505924761295
Online_Training [426/700]: mean_loss=0.08085982501506805
Online_Training [427/700]: mean_loss=0.02171579678542912
Online_Training [428/700]: mean_loss=0.02531478274613619
Online_Training [429/700]: mean_loss=0.022602339508011937
Online_Training [430/700]: mean_loss=0.03388284286484122
Online_Training [431/700]: mean_loss=0.009832312469370663
Online_Training [432/700]: mean_loss=0.009476352948695421
Online_Training [433/700]: mean_loss=0.041149858850985765
Online_Training [434/700]: mean_loss=0.01717886864207685
Online_Training [435/700]: mean_loss=0.022965240525081754
Online_Training [436/700]: mean_loss=0.004936676181387156
Online_Training [437/700]: mean_loss=0.043252382427453995
Online_Training [438/700]: mean_loss=0.06787593010812998
Online_Training [439/700]: mean_loss=0.06508197914808989
Online_Training [440/700]: mean_loss=0.022953175473958254
Online_Training [441/700]: mean_loss=0.02378603699617088
Online_Training [442/700]: mean_loss=0.046098342165350914
Online_Training [443/700]: mean_loss=0.04845199687406421
Online_Training [444/700]: mean_loss=0.015325922286137938
Online_Training [445/700]: mean_loss=0.0471561630256474
Online_Training [446/700]: mean_loss=0.02366995415650308
Online_Training [447/700]: mean_loss=0.0421816729940474
Online_Training [448/700]: mean_loss=0.05359991267323494
Online_Training [449/700]: mean_loss=0.0431078327819705
Online_Training [450/700]: mean_loss=0.06154563929885626
Online_Training [451/700]: mean_loss=0.031421133782714605
Online_Training [452/700]: mean_loss=0.04087249655276537
Online_Training [453/700]: mean_loss=0.029733960051089525
Online_Training [454/700]: mean_loss=0.029519015224650502
Online_Training [455/700]: mean_loss=0.021946951048448682
Online_Training [456/700]: mean_loss=0.02427796833217144
Online_Training [457/700]: mean_loss=0.033846919192001224
Online_Training [458/700]: mean_loss=0.0694610201753676
Online_Training [459/700]: mean_loss=0.015618857112713158
Online_Training [460/700]: mean_loss=0.015383847523480654
Online_Training [461/700]: mean_loss=0.017965649720281363
Online_Training [462/700]: mean_loss=0.02718887268565595
Online_Training [463/700]: mean_loss=0.0491330511868
Online_Training [464/700]: mean_loss=0.040813900995999575
Online_Training [465/700]: mean_loss=0.02372076059691608
Online_Training [466/700]: mean_loss=0.007021477736998349
Online_Training [467/700]: mean_loss=0.015236007864587009
Online_Training [468/700]: mean_loss=0.020940888905897737
Online_Training [469/700]: mean_loss=0.04066916974261403
Online_Training [470/700]: mean_loss=0.03429812425747514
Online_Training [471/700]: mean_loss=0.010259309667162597
Online_Training [472/700]: mean_loss=0.014464335283264518
Online_Training [473/700]: mean_loss=0.01504097692668438
Online_Training [474/700]: mean_loss=0.018434058059938252
Online_Training [475/700]: mean_loss=0.018600115552544594
Online_Training [476/700]: mean_loss=0.029968801653012633
Online_Training [477/700]: mean_loss=0.032128020422533154
Online_Training [478/700]: mean_loss=0.01635268155951053
Online_Training [479/700]: mean_loss=0.0684314095415175
Online_Training [480/700]: mean_loss=0.03526145964860916
Online_Training [481/700]: mean_loss=0.010016604326665401
Online_Training [482/700]: mean_loss=0.024941031588241458
Online_Training [483/700]: mean_loss=0.05283930664882064
Online_Training [484/700]: mean_loss=0.037634982261806726
Online_Training [485/700]: mean_loss=0.022895629750564694
Online_Training [486/700]: mean_loss=0.02000194089487195
Online_Training [487/700]: mean_loss=0.04494121577590704
Online_Training [488/700]: mean_loss=0.02430942072533071
Online_Training [489/700]: mean_loss=0.0163589168805629
Online_Training [490/700]: mean_loss=0.09758531488478184
Online_Training [491/700]: mean_loss=0.09351014066487551
Online_Training [492/700]: mean_loss=0.09296810161322355
Online_Training [493/700]: mean_loss=0.04258846212178469
Online_Training [494/700]: mean_loss=0.016472167568281293
Online_Training [495/700]: mean_loss=0.008809512597508729
Online_Training [496/700]: mean_loss=0.013549050083383918
Online_Training [497/700]: mean_loss=0.02637576125562191
Online_Training [498/700]: mean_loss=0.009906574268825352
Online_Training [499/700]: mean_loss=0.0289520260412246
Online_Training [500/700]: mean_loss=0.01638630300294608
Online_Training [501/700]: mean_loss=0.024136312305927277
Online_Training [502/700]: mean_loss=0.02966732857748866
Online_Training [503/700]: mean_loss=0.013605627929791808
Online_Training [504/700]: mean_loss=0.02025253023020923
Online_Training [505/700]: mean_loss=0.10083488561213017
Online_Training [506/700]: mean_loss=0.07819294836372137
Online_Training [507/700]: mean_loss=0.017847889801487327
Online_Training [508/700]: mean_loss=0.04261499783024192
Online_Training [509/700]: mean_loss=0.018724362598732114
Online_Training [510/700]: mean_loss=0.020218324847519398
Online_Training [511/700]: mean_loss=0.011070505599491298
Online_Training [512/700]: mean_loss=0.022234053583815694
Online_Training [513/700]: mean_loss=0.03377091605216265
Online_Training [514/700]: mean_loss=0.031508779153227806
Online_Training [515/700]: mean_loss=0.008394888835027814
Online_Training [516/700]: mean_loss=0.004509933467488736
Online_Training [517/700]: mean_loss=0.014334954204969108
Online_Training [518/700]: mean_loss=0.02581006265245378
Online_Training [519/700]: mean_loss=0.007975718122906983
Online_Training [520/700]: mean_loss=0.01576129370369017
Online_Training [521/700]: mean_loss=0.02306645503267646
Online_Training [522/700]: mean_loss=0.021598911844193935
Online_Training [523/700]: mean_loss=0.040093304589390755
Online_Training [524/700]: mean_loss=0.006693600153084844
Online_Training [525/700]: mean_loss=0.03540095221251249
Online_Training [526/700]: mean_loss=0.029479745542630553
Online_Training [527/700]: mean_loss=0.02038901182822883
Online_Training [528/700]: mean_loss=0.011060004588216543
Online_Training [529/700]: mean_loss=0.034766599303111434
Online_Training [530/700]: mean_loss=0.030552625888958573
Online_Training [531/700]: mean_loss=0.031978052109479904
Online_Training [532/700]: mean_loss=0.04572522547096014
Online_Training [533/700]: mean_loss=0.03448830032721162
Online_Training [534/700]: mean_loss=0.006811819097492844
Online_Training [535/700]: mean_loss=0.054378336761146784
Online_Training [536/700]: mean_loss=0.07931070867925882
Online_Training [537/700]: mean_loss=0.023228782461956143
Online_Training [538/700]: mean_loss=0.015232247184030712
Online_Training [539/700]: mean_loss=0.020778555423021317
Online_Training [540/700]: mean_loss=0.02132276026532054
Online_Training [541/700]: mean_loss=0.07775105722248554
Online_Training [542/700]: mean_loss=0.018380434485152364
Online_Training [543/700]: mean_loss=0.07948504481464624
Online_Training [544/700]: mean_loss=0.03493127878755331
Online_Training [545/700]: mean_loss=0.04109360184520483
Online_Training [546/700]: mean_loss=0.04203296219930053
Online_Training [547/700]: mean_loss=0.010631450568325818
Online_Training [548/700]: mean_loss=0.05146599421277642
Online_Training [549/700]: mean_loss=0.008406688342802227
Online_Training [550/700]: mean_loss=0.029554459499195218
Online_Training [551/700]: mean_loss=0.016911858809180558
Online_Training [552/700]: mean_loss=0.036629870999604464
Online_Training [553/700]: mean_loss=0.019375204807147384
Online_Training [554/700]: mean_loss=0.015644725179299712
Online_Training [555/700]: mean_loss=0.026338471099734306
Online_Training [556/700]: mean_loss=0.020625525154173374
Online_Training [557/700]: mean_loss=0.010857076500542462
Online_Training [558/700]: mean_loss=0.08876117039471865
Online_Training [559/700]: mean_loss=0.02012554055545479
Online_Training [560/700]: mean_loss=0.0351932211779058
Online_Training [561/700]: mean_loss=0.017101681092754006
Online_Training [562/700]: mean_loss=0.01374169741757214
Online_Training [563/700]: mean_loss=0.022349462378770113
Online_Training [564/700]: mean_loss=0.04857157962396741
Online_Training [565/700]: mean_loss=0.023560187313705683
Online_Training [566/700]: mean_loss=0.016007544822059572
Online_Training [567/700]: mean_loss=0.01416349969804287
Online_Training [568/700]: mean_loss=0.04948175419121981
Online_Training [569/700]: mean_loss=0.015310312970541418
Online_Training [570/700]: mean_loss=0.03607316664420068
Online_Training [571/700]: mean_loss=0.011517541017383337
Online_Training [572/700]: mean_loss=0.05238733533769846
Online_Training [573/700]: mean_loss=0.06305393110960722
Online_Training [574/700]: mean_loss=0.010255107772536576
Online_Training [575/700]: mean_loss=0.04322029044851661
Online_Training [576/700]: mean_loss=0.04315293673425913
Online_Training [577/700]: mean_loss=0.015891666640527546
Online_Training [578/700]: mean_loss=0.02418339578434825
Online_Training [579/700]: mean_loss=0.02200082060880959
Online_Training [580/700]: mean_loss=0.047529932111501694
Online_Training [581/700]: mean_loss=0.018031986197456717
Online_Training [582/700]: mean_loss=0.02931389887817204
Online_Training [583/700]: mean_loss=0.016660495777614415
Online_Training [584/700]: mean_loss=0.012300189351662993
Online_Training [585/700]: mean_loss=0.009404126205481589
Online_Training [586/700]: mean_loss=0.03177695767953992
Online_Training [587/700]: mean_loss=0.055072986986488104
Online_Training [588/700]: mean_loss=0.02341119758784771
Online_Training [589/700]: mean_loss=0.019918254343792796
Online_Training [590/700]: mean_loss=0.19279726408421993
Online_Training [591/700]: mean_loss=0.13515820633620024
Online_Training [592/700]: mean_loss=0.04184109577909112
Online_Training [593/700]: mean_loss=0.02760653500445187
Online_Training [594/700]: mean_loss=0.043301962316036224
Online_Training [595/700]: mean_loss=0.04738792823627591
Online_Training [596/700]: mean_loss=0.028793924255296588
Online_Training [597/700]: mean_loss=0.01731713453773409
Online_Training [598/700]: mean_loss=0.01950199995189905
Online_Training [599/700]: mean_loss=0.05946995271369815
Online_Training [600/700]: mean_loss=0.19620206579566002
Online_Training [601/700]: mean_loss=0.05171942710876465
Online_Training [602/700]: mean_loss=0.02433700836263597
Online_Training [603/700]: mean_loss=0.022900020238012075
Online_Training [604/700]: mean_loss=0.06164356879889965
Online_Training [605/700]: mean_loss=0.0745607502758503
Online_Training [606/700]: mean_loss=0.041563746985048056
Online_Training [607/700]: mean_loss=0.010027049807831645
Online_Training [608/700]: mean_loss=0.035057361237704754
Online_Training [609/700]: mean_loss=0.09207361098378897
Online_Training [610/700]: mean_loss=0.11793637461960316
Online_Training [611/700]: mean_loss=0.02446066727861762
Online_Training [612/700]: mean_loss=0.01381653395947069
Online_Training [613/700]: mean_loss=0.03622760227881372
Online_Training [614/700]: mean_loss=0.06976312026381493
Online_Training [615/700]: mean_loss=0.2918609455227852
Online_Training [616/700]: mean_loss=0.02336545567959547
Online_Training [617/700]: mean_loss=0.0527039198204875
Online_Training [618/700]: mean_loss=0.04382839985191822
Online_Training [619/700]: mean_loss=0.028433767147362232
Online_Training [620/700]: mean_loss=0.037914885208010674
Online_Training [621/700]: mean_loss=0.06548050045967102
Online_Training [622/700]: mean_loss=0.06398650351911783
Online_Training [623/700]: mean_loss=0.03192069963552058
Online_Training [624/700]: mean_loss=0.04855877906084061
Online_Training [625/700]: mean_loss=0.015746353194117546
Online_Training [626/700]: mean_loss=0.019426249200478196
Online_Training [627/700]: mean_loss=0.016629222547635436
Online_Training [628/700]: mean_loss=0.024019786855205894
Online_Training [629/700]: mean_loss=0.015196517808362842
Online_Training [630/700]: mean_loss=0.0646359184756875
Online_Training [631/700]: mean_loss=0.01825547474436462
Online_Training [632/700]: mean_loss=0.045537426602095366
Online_Training [633/700]: mean_loss=0.014241424039937556
Online_Training [634/700]: mean_loss=0.019826537230983377
Online_Training [635/700]: mean_loss=0.02187099982984364
Online_Training [636/700]: mean_loss=0.01851174863986671
Online_Training [637/700]: mean_loss=0.016288832877762616
Online_Training [638/700]: mean_loss=0.027525447541847825
Online_Training [639/700]: mean_loss=0.05336187453940511
Online_Training [640/700]: mean_loss=0.021727601531893015
Online_Training [641/700]: mean_loss=0.011833098251372576
Online_Training [642/700]: mean_loss=0.03388291108421981
Online_Training [643/700]: mean_loss=0.024221057537943125
Online_Training [644/700]: mean_loss=0.08416629396378994
Online_Training [645/700]: mean_loss=0.01868644985370338
Online_Training [646/700]: mean_loss=0.023360576713457704
Online_Training [647/700]: mean_loss=0.06114232074469328
Online_Training [648/700]: mean_loss=0.010595472296699882
Online_Training [649/700]: mean_loss=0.019977101357653737
Online_Training [650/700]: mean_loss=0.06523691397160292
Online_Training [651/700]: mean_loss=0.02408620808273554
Online_Training [652/700]: mean_loss=0.02452756930142641
Online_Training [653/700]: mean_loss=0.036792739760130644
Online_Training [654/700]: mean_loss=0.02093975618481636
Online_Training [655/700]: mean_loss=0.015139003400690854
Online_Training [656/700]: mean_loss=0.022987656062468886
Online_Training [657/700]: mean_loss=0.036393594928085804
Online_Training [658/700]: mean_loss=0.037848979234695435
Online_Training [659/700]: mean_loss=0.027908581541851163
Online_Training [660/700]: mean_loss=0.03896679263561964
Online_Training [661/700]: mean_loss=0.02014179970137775
Online_Training [662/700]: mean_loss=0.018440659157931805
Online_Training [663/700]: mean_loss=0.011453568236902356
Online_Training [664/700]: mean_loss=0.021209789207205176
Online_Training [665/700]: mean_loss=0.08602185361087322
Online_Training [666/700]: mean_loss=0.03865918563678861
Online_Training [667/700]: mean_loss=0.018221213947981596
Online_Training [668/700]: mean_loss=0.023171975510194898
Online_Training [669/700]: mean_loss=0.034587292931973934
Online_Training [670/700]: mean_loss=0.04512496292591095
Online_Training [671/700]: mean_loss=0.04106744006276131
Online_Training [672/700]: mean_loss=0.015184057643637061
Online_Training [673/700]: mean_loss=0.035439162980765104
Online_Training [674/700]: mean_loss=0.024712618673220277
Online_Training [675/700]: mean_loss=0.025244252057746053
Online_Training [676/700]: mean_loss=0.00943260604981333
Online_Training [677/700]: mean_loss=0.05254941713064909
Online_Training [678/700]: mean_loss=0.017228515003807843
Online_Training [679/700]: mean_loss=0.024915976217016578
Online_Training [680/700]: mean_loss=0.041450574062764645
Online_Training [681/700]: mean_loss=0.011365636484697461
Online_Training [682/700]: mean_loss=0.026180562563240528
Online_Training [683/700]: mean_loss=0.05893116071820259
Online_Training [684/700]: mean_loss=0.014339070883579552
Online_Training [685/700]: mean_loss=0.017273563775233924
Online_Training [686/700]: mean_loss=0.012836831505410373
Online_Training [687/700]: mean_loss=0.07255212310701609
Online_Training [688/700]: mean_loss=0.016884806915186346
Online_Training [689/700]: mean_loss=0.010586424497887492
Online_Training [690/700]: mean_loss=0.10389598645269871
Online_Training [691/700]: mean_loss=0.05793638760223985
Online_Training [692/700]: mean_loss=0.06527342833578587
Online_Training [693/700]: mean_loss=0.017800311325117946
Online_Training [694/700]: mean_loss=0.11352671217173338
Online_Training [695/700]: mean_loss=0.1178407147526741
Online_Training [696/700]: mean_loss=0.03205740498378873
Online_Training [697/700]: mean_loss=0.033188433619216084
Online_Training [698/700]: mean_loss=0.009911095257848501
Online_Training [699/700]: mean_loss=0.028221239103004336
Online_Training [700/700]: mean_loss=0.047389264684170485
Q_Learning [1/300]: mean_loss=0.37041374668478966
Q_Learning [2/300]: mean_loss=0.14701982773840427
Q_Learning [3/300]: mean_loss=0.23655742779374123
Q_Learning [4/300]: mean_loss=0.13740210607647896
Q_Learning [5/300]: mean_loss=0.18680274300277233
Q_Learning [6/300]: mean_loss=0.11873102560639381
Q_Learning [7/300]: mean_loss=0.0882771648466587
Q_Learning [8/300]: mean_loss=0.12249359302222729
Q_Learning [9/300]: mean_loss=0.1315347608178854
Q_Learning [10/300]: mean_loss=0.09002522379159927
Q_Learning [11/300]: mean_loss=0.13681597169488668
Q_Learning [12/300]: mean_loss=0.09716070350259542
Q_Learning [13/300]: mean_loss=0.038587227929383516
Q_Learning [14/300]: mean_loss=0.13945105113089085
Q_Learning [15/300]: mean_loss=0.055312913842499256
Q_Learning [16/300]: mean_loss=0.05968768894672394
Q_Learning [17/300]: mean_loss=0.027791400672867894
Q_Learning [18/300]: mean_loss=0.0878488328307867
Q_Learning [19/300]: mean_loss=0.03167422069236636
Q_Learning [20/300]: mean_loss=0.023521044058725238
Q_Learning [21/300]: mean_loss=0.025595201877877116
Q_Learning [22/300]: mean_loss=0.05650171497836709
Q_Learning [23/300]: mean_loss=0.4153177998960018
Q_Learning [24/300]: mean_loss=0.14672502130270004
Q_Learning [25/300]: mean_loss=0.03596802894026041
Q_Learning [26/300]: mean_loss=0.12077843211591244
Q_Learning [27/300]: mean_loss=0.08909592311829329
Q_Learning [28/300]: mean_loss=0.15983080491423607
Q_Learning [29/300]: mean_loss=0.07773512974381447
Q_Learning [30/300]: mean_loss=0.08616785984486341
Q_Learning [31/300]: mean_loss=0.1657737549394369
Q_Learning [32/300]: mean_loss=0.10091410018503666
Q_Learning [33/300]: mean_loss=0.07771144341677427
Q_Learning [34/300]: mean_loss=0.46132805570960045
Q_Learning [35/300]: mean_loss=0.25020928494632244
Q_Learning [36/300]: mean_loss=0.10468360874801874
Q_Learning [37/300]: mean_loss=0.07258762698620558
Q_Learning [38/300]: mean_loss=0.11361780110746622
Q_Learning [39/300]: mean_loss=0.07616629265248775
Q_Learning [40/300]: mean_loss=0.12812631390988827
Q_Learning [41/300]: mean_loss=0.12039064802229404
Q_Learning [42/300]: mean_loss=0.07669110782444477
Q_Learning [43/300]: mean_loss=0.10046321712434292
Q_Learning [44/300]: mean_loss=0.23530584387481213
Q_Learning [45/300]: mean_loss=0.08687528781592846
Q_Learning [46/300]: mean_loss=0.05208242451772094
Q_Learning [47/300]: mean_loss=0.07235487084835768
Q_Learning [48/300]: mean_loss=0.09665247052907944
Q_Learning [49/300]: mean_loss=0.04636055137962103
Q_Learning [50/300]: mean_loss=0.05201401887461543
Q_Learning [51/300]: mean_loss=0.05037973215803504
Q_Learning [52/300]: mean_loss=0.04604370705783367
Q_Learning [53/300]: mean_loss=0.047720547299832106
Q_Learning [54/300]: mean_loss=0.10050298366695642
Q_Learning [55/300]: mean_loss=0.07236435264348984
Q_Learning [56/300]: mean_loss=0.044201248325407505
Q_Learning [57/300]: mean_loss=0.036109503358602524
Q_Learning [58/300]: mean_loss=0.0451065287925303
Q_Learning [59/300]: mean_loss=0.04745828686282039
Q_Learning [60/300]: mean_loss=0.026027873158454895
Q_Learning [61/300]: mean_loss=0.032095004338771105
Q_Learning [62/300]: mean_loss=0.019528003060258925
Q_Learning [63/300]: mean_loss=0.030908192740753293
Q_Learning [64/300]: mean_loss=0.017180209630168974
Q_Learning [65/300]: mean_loss=0.33153940364718437
Q_Learning [66/300]: mean_loss=0.14533177763223648
Q_Learning [67/300]: mean_loss=0.07708119787275791
Q_Learning [68/300]: mean_loss=0.03825882077217102
Q_Learning [69/300]: mean_loss=0.06794014479964972
Q_Learning [70/300]: mean_loss=0.06012225104495883
Q_Learning [71/300]: mean_loss=0.037440011743456125
Q_Learning [72/300]: mean_loss=0.07038639206439257
Q_Learning [73/300]: mean_loss=0.05803449498489499
Q_Learning [74/300]: mean_loss=0.046683572232723236
Q_Learning [75/300]: mean_loss=0.023510875180363655
Q_Learning [76/300]: mean_loss=0.02670711139217019
Q_Learning [77/300]: mean_loss=0.027076089289039373
Q_Learning [78/300]: mean_loss=0.04202205082401633
Q_Learning [79/300]: mean_loss=0.04012154554948211
Q_Learning [80/300]: mean_loss=0.04182752734050155
Q_Learning [81/300]: mean_loss=0.06674373522400856
Q_Learning [82/300]: mean_loss=0.05755410250276327
Q_Learning [83/300]: mean_loss=0.03131308080628514
Q_Learning [84/300]: mean_loss=0.03347590658813715
Q_Learning [85/300]: mean_loss=0.05085113737732172
Q_Learning [86/300]: mean_loss=0.051850307267159224
Q_Learning [87/300]: mean_loss=0.042882722336798906
Q_Learning [88/300]: mean_loss=0.029518016381189227
Q_Learning [89/300]: mean_loss=0.025812336476519704
Q_Learning [90/300]: mean_loss=0.03413970395922661
Q_Learning [91/300]: mean_loss=0.025616351747885346
Q_Learning [92/300]: mean_loss=0.047302066814154387
Q_Learning [93/300]: mean_loss=0.039011156652122736
Q_Learning [94/300]: mean_loss=0.05194780416786671
Q_Learning [95/300]: mean_loss=0.0157510171411559
Q_Learning [96/300]: mean_loss=0.04510186426341534
Q_Learning [97/300]: mean_loss=0.11024831421673298
Q_Learning [98/300]: mean_loss=0.02010547393001616
Q_Learning [99/300]: mean_loss=0.025534897344186902
Q_Learning [100/300]: mean_loss=0.05709824524819851
Q_Learning [101/300]: mean_loss=0.046618981985375285
Q_Learning [102/300]: mean_loss=0.07277471758425236
Q_Learning [103/300]: mean_loss=0.0583755555562675
Q_Learning [104/300]: mean_loss=0.027609516633674502
Q_Learning [105/300]: mean_loss=0.018390757264569402
Q_Learning [106/300]: mean_loss=0.0297237578779459
Q_Learning [107/300]: mean_loss=0.03454855806194246
Q_Learning [108/300]: mean_loss=0.027762381825596094
Q_Learning [109/300]: mean_loss=0.02500155079178512
Q_Learning [110/300]: mean_loss=0.03176052961498499
Q_Learning [111/300]: mean_loss=0.03484894195571542
Q_Learning [112/300]: mean_loss=0.02544570667669177
Q_Learning [113/300]: mean_loss=0.032133571803569794
Q_Learning [114/300]: mean_loss=0.05636910954490304
Q_Learning [115/300]: mean_loss=0.11889050342142582
Q_Learning [116/300]: mean_loss=0.13937134481966496
Q_Learning [117/300]: mean_loss=0.04618277261033654
Q_Learning [118/300]: mean_loss=0.052077331114560366
Q_Learning [119/300]: mean_loss=0.021767521742731333
Q_Learning [120/300]: mean_loss=0.034979759249836206
Q_Learning [121/300]: mean_loss=0.058966392651200294
Q_Learning [122/300]: mean_loss=0.024623433127999306
Q_Learning [123/300]: mean_loss=0.1637945268303156
Q_Learning [124/300]: mean_loss=0.03673743223771453
Q_Learning [125/300]: mean_loss=0.015012998133897781
Q_Learning [126/300]: mean_loss=0.008298822969663888
Q_Learning [127/300]: mean_loss=0.02239955822005868
Q_Learning [128/300]: mean_loss=0.024634123779833317
Q_Learning [129/300]: mean_loss=0.06849689781665802
Q_Learning [130/300]: mean_loss=0.01987042697146535
Q_Learning [131/300]: mean_loss=0.07907330803573132
Q_Learning [132/300]: mean_loss=0.02989312121644616
Q_Learning [133/300]: mean_loss=0.056934076361358166
Q_Learning [134/300]: mean_loss=0.0436448659747839
Q_Learning [135/300]: mean_loss=0.025990313617512584
Q_Learning [136/300]: mean_loss=0.051038654055446386
Q_Learning [137/300]: mean_loss=0.0802721343934536
Q_Learning [138/300]: mean_loss=0.05426269490271807
Q_Learning [139/300]: mean_loss=0.03614852949976921
Q_Learning [140/300]: mean_loss=0.011476462241262197
Q_Learning [141/300]: mean_loss=0.021572529338300228
Q_Learning [142/300]: mean_loss=0.006542679620906711
Q_Learning [143/300]: mean_loss=0.020986550953239202
Q_Learning [144/300]: mean_loss=0.044013191014528275
Q_Learning [145/300]: mean_loss=0.01689661806449294
Q_Learning [146/300]: mean_loss=0.025163111509755254
Q_Learning [147/300]: mean_loss=0.014910498051904142
Q_Learning [148/300]: mean_loss=0.05545955058187246
Q_Learning [149/300]: mean_loss=0.006263157702051103
Q_Learning [150/300]: mean_loss=0.029742911225184798
Q_Learning [151/300]: mean_loss=0.018784666899591684
Q_Learning [152/300]: mean_loss=0.030049180379137397
Q_Learning [153/300]: mean_loss=0.07364764157682657
Q_Learning [154/300]: mean_loss=0.02584926411509514
Q_Learning [155/300]: mean_loss=0.041755244601517916
Q_Learning [156/300]: mean_loss=0.031068714568391442
Q_Learning [157/300]: mean_loss=0.020672571612522006
Q_Learning [158/300]: mean_loss=0.09724843688309193
Q_Learning [159/300]: mean_loss=0.011186689487658441
Q_Learning [160/300]: mean_loss=0.020127069670706987
Q_Learning [161/300]: mean_loss=0.02039201301522553
Q_Learning [162/300]: mean_loss=0.03456486063078046
Q_Learning [163/300]: mean_loss=0.013527313712984324
Q_Learning [164/300]: mean_loss=0.016438808641396463
Q_Learning [165/300]: mean_loss=0.035023758420720696
Q_Learning [166/300]: mean_loss=0.012987606693059206
Q_Learning [167/300]: mean_loss=0.05290492344647646
Q_Learning [168/300]: mean_loss=0.04806722281500697
Q_Learning [169/300]: mean_loss=0.040975218173116446
Q_Learning [170/300]: mean_loss=0.034893924137577415
Q_Learning [171/300]: mean_loss=0.06757381977513433
Q_Learning [172/300]: mean_loss=0.027230543782934546
Q_Learning [173/300]: mean_loss=0.031163758132606745
Q_Learning [174/300]: mean_loss=0.013409168692305684
Q_Learning [175/300]: mean_loss=0.039455979596823454
Q_Learning [176/300]: mean_loss=0.011689526145346463
Q_Learning [177/300]: mean_loss=0.11426954437047243
Q_Learning [178/300]: mean_loss=0.0636355197057128
Q_Learning [179/300]: mean_loss=0.06881939759477973
Q_Learning [180/300]: mean_loss=0.032108048209920526
Q_Learning [181/300]: mean_loss=0.05122114950791001
Q_Learning [182/300]: mean_loss=0.042765033431351185
Q_Learning [183/300]: mean_loss=0.061587704345583916
Q_Learning [184/300]: mean_loss=0.016005686251446605
Q_Learning [185/300]: mean_loss=0.03608632739633322
Q_Learning [186/300]: mean_loss=0.013016484561376274
Q_Learning [187/300]: mean_loss=0.02425665920600295
Q_Learning [188/300]: mean_loss=0.06076964735984802
Q_Learning [189/300]: mean_loss=0.03933060262352228
Q_Learning [190/300]: mean_loss=0.02371556032449007
Q_Learning [191/300]: mean_loss=0.08328642416745424
Q_Learning [192/300]: mean_loss=0.05081939371302724
Q_Learning [193/300]: mean_loss=0.027328307973220944
Q_Learning [194/300]: mean_loss=0.030765314120799303
Q_Learning [195/300]: mean_loss=0.0334312142804265
Q_Learning [196/300]: mean_loss=0.026973056374117732
Q_Learning [197/300]: mean_loss=0.07109950250014663
Q_Learning [198/300]: mean_loss=0.017159812385216355
Q_Learning [199/300]: mean_loss=0.04644598066806793
Q_Learning [200/300]: mean_loss=0.01068811397999525
Q_Learning [201/300]: mean_loss=0.040093967225402594
Q_Learning [202/300]: mean_loss=0.028384211473166943
Q_Learning [203/300]: mean_loss=0.022792496718466282
Q_Learning [204/300]: mean_loss=0.07251467602327466
Q_Learning [205/300]: mean_loss=0.037855681497603655
Q_Learning [206/300]: mean_loss=0.04419994726777077
Q_Learning [207/300]: mean_loss=0.011312285903841257
Q_Learning [208/300]: mean_loss=0.028679010923951864
Q_Learning [209/300]: mean_loss=0.025800277944654226
Q_Learning [210/300]: mean_loss=0.059571792371571064
Q_Learning [211/300]: mean_loss=0.04568183235824108
Q_Learning [212/300]: mean_loss=0.02695962111465633
Q_Learning [213/300]: mean_loss=0.042096787597984076
Q_Learning [214/300]: mean_loss=0.04929459607228637
Q_Learning [215/300]: mean_loss=0.069766731467098
Q_Learning [216/300]: mean_loss=0.029627235140651464
Q_Learning [217/300]: mean_loss=0.025410574860870838
Q_Learning [218/300]: mean_loss=0.046422623097896576
Q_Learning [219/300]: mean_loss=0.03535693930462003
Q_Learning [220/300]: mean_loss=0.02030614926479757
Q_Learning [221/300]: mean_loss=0.03472729539498687
Q_Learning [222/300]: mean_loss=0.036280710250139236
Q_Learning [223/300]: mean_loss=0.010670353658497334
Q_Learning [224/300]: mean_loss=0.10967137757688761
Q_Learning [225/300]: mean_loss=0.04486361285671592
Q_Learning [226/300]: mean_loss=0.04692808911204338
Q_Learning [227/300]: mean_loss=0.02762935310602188
Q_Learning [228/300]: mean_loss=0.039980793837457895
Q_Learning [229/300]: mean_loss=0.018812982132658362
Q_Learning [230/300]: mean_loss=0.04294376727193594
Q_Learning [231/300]: mean_loss=0.024937338894233108
Q_Learning [232/300]: mean_loss=0.051748158410191536
Q_Learning [233/300]: mean_loss=0.022652078652754426
Q_Learning [234/300]: mean_loss=0.032217676751315594
Q_Learning [235/300]: mean_loss=0.04896284593269229
Q_Learning [236/300]: mean_loss=0.0477138627320528
Q_Learning [237/300]: mean_loss=0.013905205763876438
Q_Learning [238/300]: mean_loss=0.0642669158987701
Q_Learning [239/300]: mean_loss=0.04084035009145737
Q_Learning [240/300]: mean_loss=0.041268976870924234
Q_Learning [241/300]: mean_loss=0.037292731925845146
Q_Learning [242/300]: mean_loss=0.015072016278281808
Q_Learning [243/300]: mean_loss=0.013527410803362727
Q_Learning [244/300]: mean_loss=0.009491116681601852
Q_Learning [245/300]: mean_loss=0.005604937730822712
Q_Learning [246/300]: mean_loss=0.048496522940695286
Q_Learning [247/300]: mean_loss=0.07240203022956848
Q_Learning [248/300]: mean_loss=0.03975760703906417
Q_Learning [249/300]: mean_loss=0.10492624528706074
Q_Learning [250/300]: mean_loss=0.046094395220279694
Q_Learning [251/300]: mean_loss=0.048986952286213636
Q_Learning [252/300]: mean_loss=0.008017353946343064
Q_Learning [253/300]: mean_loss=0.021774656837806106
Q_Learning [254/300]: mean_loss=0.129318387247622
Q_Learning [255/300]: mean_loss=0.009344478719867766
Q_Learning [256/300]: mean_loss=0.016455214703455567
Q_Learning [257/300]: mean_loss=0.03365249978378415
Q_Learning [258/300]: mean_loss=0.0352684804238379
Q_Learning [259/300]: mean_loss=0.05809772992506623
Q_Learning [260/300]: mean_loss=0.029291485901921988
Q_Learning [261/300]: mean_loss=0.03029021085239947
Q_Learning [262/300]: mean_loss=0.014416951918974519
Q_Learning [263/300]: mean_loss=0.02073887293227017
Q_Learning [264/300]: mean_loss=0.010092875687405467
Q_Learning [265/300]: mean_loss=0.05529306922107935
Q_Learning [266/300]: mean_loss=0.04268463794142008
Q_Learning [267/300]: mean_loss=0.035624036099761724
Q_Learning [268/300]: mean_loss=0.031395073514431715
Q_Learning [269/300]: mean_loss=0.04036555765196681
Q_Learning [270/300]: mean_loss=0.07212575152516365
Q_Learning [271/300]: mean_loss=0.10243301559239626
Q_Learning [272/300]: mean_loss=0.08199685905128717
Q_Learning [273/300]: mean_loss=0.057908028829842806
Q_Learning [274/300]: mean_loss=0.05304357968270779
Q_Learning [275/300]: mean_loss=0.09781533479690552
Q_Learning [276/300]: mean_loss=0.03023706329986453
Q_Learning [277/300]: mean_loss=0.027220115065574646
Q_Learning [278/300]: mean_loss=0.017801281763240695
Q_Learning [279/300]: mean_loss=0.027822701493278146
Q_Learning [280/300]: mean_loss=0.0585482120513916
Q_Learning [281/300]: mean_loss=0.03541976120322943
Q_Learning [282/300]: mean_loss=0.027076163794845343
Q_Learning [283/300]: mean_loss=0.021364394342526793
Q_Learning [284/300]: mean_loss=0.06151098757982254
Q_Learning [285/300]: mean_loss=0.02939732209779322
Q_Learning [286/300]: mean_loss=0.07159370742738247
Q_Learning [287/300]: mean_loss=0.013655846589244902
Q_Learning [288/300]: mean_loss=0.041307900566607714
Q_Learning [289/300]: mean_loss=0.032233057310804725
Q_Learning [290/300]: mean_loss=0.017802999587729573
Q_Learning [291/300]: mean_loss=0.05783020192757249
Q_Learning [292/300]: mean_loss=0.017511454061605036
Q_Learning [293/300]: mean_loss=0.021678135031834245
Q_Learning [294/300]: mean_loss=0.013991811661981046
Q_Learning [295/300]: mean_loss=0.05729975551366806
Q_Learning [296/300]: mean_loss=0.05826112348586321
Q_Learning [297/300]: mean_loss=0.034367410000413656
Q_Learning [298/300]: mean_loss=0.05449562333524227
Q_Learning [299/300]: mean_loss=0.04844055650755763
Q_Learning [300/300]: mean_loss=0.02049112436361611
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-1.9066215   0.33755434]
[0, 0, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 0, 2, 2, 1, 2, 0, 0, 1, 1, 1, 0, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 1, 1, 2, 2, 1, 0, 2, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 2, 0, 2, 2, 1, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1, 0, 2, 1, 0, 1, 2, 0, 2, 2, 1, 1, 2, 2, 0, 0, 1, 1, 1, 2, 2, 1, 0, 1, 2, 2, 2, 0, 0, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 1, 0, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 2, 2, 0, 0, 2, 0, 2, 0, 1, 1, 0, 2, 0, 0, 2, 0, 2, 0, 1, 0, 1, 0, 1, 2, 1, 0, 1, 2, 2, 0, 2, 0, 1, 0, 1, 0, 1, 0, 0, 2, 2, 0, 2, 2, 2, 1, 1, 0, 0, 2, 1, 0, 0, 2, 1, 1, 1, 0, 2, 1, 0, 1, 2, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 1, 1, 2, 1, 2, 0, 2, 1, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 1, 1, 0, 2, 2, 0, 1, 2, 0, 1, 0, 0, 1, 2, 2, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 1, 0, 1, 2]
[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]
Centroids: [[-1.1787871, 0.12213829], [1.6022819, 0.46957994], [-0.2624788, 0.4500549]]
Centroids: [[-0.795433, 0.26007938], [1.5785266, 0.48436213]]
Contingency Matrix: 
[[108   0]
 [  2  99]
 [ 85   6]]
[[108, 0], [2, 99], [85, 6]]
[[108, 0, 0], [2, 99, 0], [85, 6, 0]]
[0, 1, 2]
[[-1, -1, -1], [-1, 99, 0], [-1, 6, 0]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 0]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[108   0   0]
 [  2  99   0]
 [ 85   6   0]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [108, 99, 0], Sum: 207
All_Elements: [108, 0, 0, 2, 99, 0, 85, 6, 0], Sum: 300
Accuracy: 0.69
