Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_9_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_9_opt_temp_noisy/C_Easy2_noise010.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-15_40_01
Punishment_Coefficient: 0.7
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017D0168A160>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.22984569147229195
Online_Training [2/700]: mean_loss=0.1446281224489212
Online_Training [3/700]: mean_loss=0.1903734654188156
Online_Training [4/700]: mean_loss=0.1921613160520792
Online_Training [5/700]: mean_loss=0.11071547865867615
Online_Training [6/700]: mean_loss=0.18923038057982922
Online_Training [7/700]: mean_loss=0.1732693910598755
Online_Training [8/700]: mean_loss=0.11567330826073885
Online_Training [9/700]: mean_loss=0.12196548469364643
Online_Training [10/700]: mean_loss=0.12064539827406406
Online_Training [11/700]: mean_loss=0.0640038033016026
Online_Training [12/700]: mean_loss=0.078603720292449
Online_Training [13/700]: mean_loss=0.11834658496081829
Online_Training [14/700]: mean_loss=0.13924693688750267
Online_Training [15/700]: mean_loss=0.0647319545969367
Online_Training [16/700]: mean_loss=0.04651808412745595
Online_Training [17/700]: mean_loss=0.14976632222533226
Online_Training [18/700]: mean_loss=0.07927068136632442
Online_Training [19/700]: mean_loss=0.09240580722689629
Online_Training [20/700]: mean_loss=0.08091053552925587
Online_Training [21/700]: mean_loss=0.06564342649653554
Online_Training [22/700]: mean_loss=0.159101577475667
Online_Training [23/700]: mean_loss=0.18254006654024124
Online_Training [24/700]: mean_loss=0.031052908394485712
Online_Training [25/700]: mean_loss=0.050375732127577066
Online_Training [26/700]: mean_loss=0.10890268534421921
Online_Training [27/700]: mean_loss=0.05841910932213068
Online_Training [28/700]: mean_loss=0.1844107285141945
Online_Training [29/700]: mean_loss=0.040236266795545816
Online_Training [30/700]: mean_loss=0.029289643513038754
Online_Training [31/700]: mean_loss=0.08400561846792698
Online_Training [32/700]: mean_loss=0.057361370883882046
Online_Training [33/700]: mean_loss=0.027683190070092678
Online_Training [34/700]: mean_loss=0.0686061643064022
Online_Training [35/700]: mean_loss=0.038984608836472034
Online_Training [36/700]: mean_loss=0.06420687679201365
Online_Training [37/700]: mean_loss=0.029865203658118844
Online_Training [38/700]: mean_loss=0.033518722746521235
Online_Training [39/700]: mean_loss=0.031221280340105295
Online_Training [40/700]: mean_loss=0.03905748715624213
Online_Training [41/700]: mean_loss=0.05821238411590457
Online_Training [42/700]: mean_loss=0.04551865393295884
Online_Training [43/700]: mean_loss=0.02077032858505845
Online_Training [44/700]: mean_loss=0.03305713087320328
Online_Training [45/700]: mean_loss=0.025263817980885506
Online_Training [46/700]: mean_loss=0.04120849911123514
Online_Training [47/700]: mean_loss=0.024692430393770337
Online_Training [48/700]: mean_loss=0.03934966214001179
Online_Training [49/700]: mean_loss=0.028654457768425345
Online_Training [50/700]: mean_loss=0.013951034867204726
Online_Training [51/700]: mean_loss=0.03557633445598185
Online_Training [52/700]: mean_loss=0.03254688298329711
Online_Training [53/700]: mean_loss=0.023823440074920654
Online_Training [54/700]: mean_loss=0.018636846216395497
Online_Training [55/700]: mean_loss=0.03612667974084616
Online_Training [56/700]: mean_loss=0.04369881097227335
Online_Training [57/700]: mean_loss=0.011175030493177474
Online_Training [58/700]: mean_loss=0.03097123373299837
Online_Training [59/700]: mean_loss=0.04854295775294304
Online_Training [60/700]: mean_loss=0.032089798245579004
Online_Training [61/700]: mean_loss=0.026344362646341324
Online_Training [62/700]: mean_loss=0.04771607369184494
Online_Training [63/700]: mean_loss=0.020236316369846463
Online_Training [64/700]: mean_loss=0.03610446210950613
Online_Training [65/700]: mean_loss=0.015809105127118528
Online_Training [66/700]: mean_loss=0.020157416816800833
Online_Training [67/700]: mean_loss=0.018149292445741594
Online_Training [68/700]: mean_loss=0.03337397635914385
Online_Training [69/700]: mean_loss=0.024737362749874592
Online_Training [70/700]: mean_loss=0.016820967895910144
Online_Training [71/700]: mean_loss=0.047000505961477757
Online_Training [72/700]: mean_loss=0.020211179042235017
Online_Training [73/700]: mean_loss=0.022123886505141854
Online_Training [74/700]: mean_loss=0.013135554734617472
Online_Training [75/700]: mean_loss=0.018342030234634876
Online_Training [76/700]: mean_loss=0.02198091265745461
Online_Training [77/700]: mean_loss=0.014235768700018525
Online_Training [78/700]: mean_loss=0.013680544216185808
Online_Training [79/700]: mean_loss=0.007055851339828223
Online_Training [80/700]: mean_loss=0.0131277812179178
Online_Training [81/700]: mean_loss=0.02685626852326095
Online_Training [82/700]: mean_loss=0.016521376674063504
Online_Training [83/700]: mean_loss=0.017483777133747935
Online_Training [84/700]: mean_loss=0.011041489080525935
Online_Training [85/700]: mean_loss=0.00951469165738672
Online_Training [86/700]: mean_loss=0.01578844035975635
Online_Training [87/700]: mean_loss=0.11887121666222811
Online_Training [88/700]: mean_loss=0.21236909553408623
Online_Training [89/700]: mean_loss=0.0287454251665622
Online_Training [90/700]: mean_loss=0.012993674608878791
Online_Training [91/700]: mean_loss=0.03310153027996421
Online_Training [92/700]: mean_loss=0.030606522224843502
Online_Training [93/700]: mean_loss=0.02003168361261487
Online_Training [94/700]: mean_loss=0.027464587008580565
Online_Training [95/700]: mean_loss=0.09969302080571651
Online_Training [96/700]: mean_loss=0.10039678774774075
Online_Training [97/700]: mean_loss=0.02321829623542726
Online_Training [98/700]: mean_loss=0.012650376185774803
Online_Training [99/700]: mean_loss=0.07006371533498168
Online_Training [100/700]: mean_loss=0.10451953765004873
Online_Training [101/700]: mean_loss=0.023787330370396376
Online_Training [102/700]: mean_loss=0.04737059911713004
Online_Training [103/700]: mean_loss=0.019846139010041952
Online_Training [104/700]: mean_loss=0.04408856248483062
Online_Training [105/700]: mean_loss=0.025888361735269427
Online_Training [106/700]: mean_loss=0.023554528132081032
Online_Training [107/700]: mean_loss=0.01884721650276333
Online_Training [108/700]: mean_loss=0.01418521860614419
Online_Training [109/700]: mean_loss=0.02203393168747425
Online_Training [110/700]: mean_loss=0.008595240593422204
Online_Training [111/700]: mean_loss=0.05599840823560953
Online_Training [112/700]: mean_loss=0.016152574215084314
Online_Training [113/700]: mean_loss=0.023380483267828822
Online_Training [114/700]: mean_loss=0.035619099624454975
Online_Training [115/700]: mean_loss=0.015329169109463692
Online_Training [116/700]: mean_loss=0.006151761277578771
Online_Training [117/700]: mean_loss=0.018453734694048762
Online_Training [118/700]: mean_loss=0.017592994961887598
Online_Training [119/700]: mean_loss=0.008061401371378452
Online_Training [120/700]: mean_loss=0.02401578309945762
Online_Training [121/700]: mean_loss=0.025352487107738853
Online_Training [122/700]: mean_loss=0.019262550864368677
Online_Training [123/700]: mean_loss=0.009115580236539245
Online_Training [124/700]: mean_loss=0.017726304125972092
Online_Training [125/700]: mean_loss=0.006501079013105482
Online_Training [126/700]: mean_loss=0.0258462680503726
Online_Training [127/700]: mean_loss=0.021553677041083574
Online_Training [128/700]: mean_loss=0.013436007662676275
Online_Training [129/700]: mean_loss=0.0034930481342598796
Online_Training [130/700]: mean_loss=0.08810344990342855
Online_Training [131/700]: mean_loss=0.11041061021387577
Online_Training [132/700]: mean_loss=0.04329280788078904
Online_Training [133/700]: mean_loss=0.05528324702754617
Online_Training [134/700]: mean_loss=0.013911763555370271
Online_Training [135/700]: mean_loss=0.01897130743600428
Online_Training [136/700]: mean_loss=0.0131950993090868
Online_Training [137/700]: mean_loss=0.06528731901198626
Online_Training [138/700]: mean_loss=0.04727371223270893
Online_Training [139/700]: mean_loss=0.025596311083063483
Online_Training [140/700]: mean_loss=0.025596588850021362
Online_Training [141/700]: mean_loss=0.01825588895007968
Online_Training [142/700]: mean_loss=0.020179286948405206
Online_Training [143/700]: mean_loss=0.025171255692839622
Online_Training [144/700]: mean_loss=0.018245558021590114
Online_Training [145/700]: mean_loss=0.06152750039473176
Online_Training [146/700]: mean_loss=0.14182249270379543
Online_Training [147/700]: mean_loss=0.04277229495346546
Online_Training [148/700]: mean_loss=0.020947430981323123
Online_Training [149/700]: mean_loss=0.011017950717359781
Online_Training [150/700]: mean_loss=0.020049378043040633
Online_Training [151/700]: mean_loss=0.009113506705034524
Online_Training [152/700]: mean_loss=0.011814850382506847
Online_Training [153/700]: mean_loss=0.01725016674026847
Online_Training [154/700]: mean_loss=0.018886225763708353
Online_Training [155/700]: mean_loss=0.009356886090245098
Online_Training [156/700]: mean_loss=0.037247829837724566
Online_Training [157/700]: mean_loss=0.06324194325134158
Online_Training [158/700]: mean_loss=0.06117040617391467
Online_Training [159/700]: mean_loss=0.0176648908527568
Online_Training [160/700]: mean_loss=0.04116751439869404
Online_Training [161/700]: mean_loss=0.005953751562628895
Online_Training [162/700]: mean_loss=0.019568876479752362
Online_Training [163/700]: mean_loss=0.01711360877379775
Online_Training [164/700]: mean_loss=0.015766375930979848
Online_Training [165/700]: mean_loss=0.006925862398929894
Online_Training [166/700]: mean_loss=0.005652800988173112
Online_Training [167/700]: mean_loss=0.006334141653496772
Online_Training [168/700]: mean_loss=0.009035746159497648
Online_Training [169/700]: mean_loss=0.010783753357827663
Online_Training [170/700]: mean_loss=0.05292933713644743
Online_Training [171/700]: mean_loss=0.036775498650968075
Online_Training [172/700]: mean_loss=0.048278349917382
Online_Training [173/700]: mean_loss=0.017760571092367172
Online_Training [174/700]: mean_loss=0.01765152788721025
Online_Training [175/700]: mean_loss=0.014159437036141753
Online_Training [176/700]: mean_loss=0.011669648112729192
Online_Training [177/700]: mean_loss=0.06538464967161417
Online_Training [178/700]: mean_loss=0.07775143999606371
Online_Training [179/700]: mean_loss=0.04265197413042188
Online_Training [180/700]: mean_loss=0.019034234806895256
Online_Training [181/700]: mean_loss=0.01350951858330518
Online_Training [182/700]: mean_loss=0.018895458662882447
Online_Training [183/700]: mean_loss=0.0094576824340038
Online_Training [184/700]: mean_loss=0.01837650965899229
Online_Training [185/700]: mean_loss=0.02218257705681026
Online_Training [186/700]: mean_loss=0.008546936966013163
Online_Training [187/700]: mean_loss=0.016362987458705902
Online_Training [188/700]: mean_loss=0.02936909021809697
Online_Training [189/700]: mean_loss=0.017223584232851863
Online_Training [190/700]: mean_loss=0.07628612965345383
Online_Training [191/700]: mean_loss=0.09319958835840225
Online_Training [192/700]: mean_loss=0.013414818560704589
Online_Training [193/700]: mean_loss=0.030466575175523758
Online_Training [194/700]: mean_loss=0.03047238034196198
Online_Training [195/700]: mean_loss=0.016968839103356004
Online_Training [196/700]: mean_loss=0.2151778656989336
Online_Training [197/700]: mean_loss=0.08218030817806721
Online_Training [198/700]: mean_loss=0.02613637549802661
Online_Training [199/700]: mean_loss=0.015893905074335635
Online_Training [200/700]: mean_loss=0.12608332838863134
Online_Training [201/700]: mean_loss=0.1350012542679906
Online_Training [202/700]: mean_loss=0.014669343247078359
Online_Training [203/700]: mean_loss=0.06322350911796093
Online_Training [204/700]: mean_loss=0.017253775848075747
Online_Training [205/700]: mean_loss=0.013159371563233435
Online_Training [206/700]: mean_loss=0.02144243661314249
Online_Training [207/700]: mean_loss=0.023866902804002166
Online_Training [208/700]: mean_loss=0.020138041814789176
Online_Training [209/700]: mean_loss=0.00689222919754684
Online_Training [210/700]: mean_loss=0.0500131924636662
Online_Training [211/700]: mean_loss=0.018879317212849855
Online_Training [212/700]: mean_loss=0.01059164060279727
Online_Training [213/700]: mean_loss=0.012326863594353199
Online_Training [214/700]: mean_loss=0.10451334435492754
Online_Training [215/700]: mean_loss=0.07597077917307615
Online_Training [216/700]: mean_loss=0.018140318687073886
Online_Training [217/700]: mean_loss=0.019387402338907123
Online_Training [218/700]: mean_loss=0.013788096839562058
Online_Training [219/700]: mean_loss=0.013935894588939846
Online_Training [220/700]: mean_loss=0.011065884842537344
Online_Training [221/700]: mean_loss=0.013749685836955905
Online_Training [222/700]: mean_loss=0.011598973302170634
Online_Training [223/700]: mean_loss=0.004976572119630873
Online_Training [224/700]: mean_loss=0.01019113149959594
Online_Training [225/700]: mean_loss=0.006397287244908512
Online_Training [226/700]: mean_loss=0.004604497749824077
Online_Training [227/700]: mean_loss=0.03752371156588197
Online_Training [228/700]: mean_loss=0.03131797816604376
Online_Training [229/700]: mean_loss=0.021636173594743013
Online_Training [230/700]: mean_loss=0.007286340929567814
Online_Training [231/700]: mean_loss=0.02826577704399824
Online_Training [232/700]: mean_loss=0.014982895227149129
Online_Training [233/700]: mean_loss=0.007748387579340488
Online_Training [234/700]: mean_loss=0.011824531597085297
Online_Training [235/700]: mean_loss=0.009051271306816489
Online_Training [236/700]: mean_loss=0.019470900064334273
Online_Training [237/700]: mean_loss=0.018096817657351494
Online_Training [238/700]: mean_loss=0.012144783861003816
Online_Training [239/700]: mean_loss=0.09197136107832193
Online_Training [240/700]: mean_loss=0.016099461005069315
Online_Training [241/700]: mean_loss=0.024746101582422853
Online_Training [242/700]: mean_loss=0.006403214065358043
Online_Training [243/700]: mean_loss=0.02597202081233263
Online_Training [244/700]: mean_loss=0.1201113285496831
Online_Training [245/700]: mean_loss=0.12870927900075912
Online_Training [246/700]: mean_loss=0.02275324915535748
Online_Training [247/700]: mean_loss=0.02664166735485196
Online_Training [248/700]: mean_loss=0.03898616530932486
Online_Training [249/700]: mean_loss=0.009198611602187157
Online_Training [250/700]: mean_loss=0.009244607761502266
Online_Training [251/700]: mean_loss=0.009536041761748493
Online_Training [252/700]: mean_loss=0.025325213558971882
Online_Training [253/700]: mean_loss=0.002372799499426037
Online_Training [254/700]: mean_loss=0.017273740842938423
Online_Training [255/700]: mean_loss=0.007835006806999445
Online_Training [256/700]: mean_loss=0.01589800661895424
Online_Training [257/700]: mean_loss=0.017188691650517285
Online_Training [258/700]: mean_loss=0.007839191530365497
Online_Training [259/700]: mean_loss=0.011100744712166488
Online_Training [260/700]: mean_loss=0.006553984887432307
Online_Training [261/700]: mean_loss=0.01940088369883597
Online_Training [262/700]: mean_loss=0.01815120643004775
Online_Training [263/700]: mean_loss=0.015627646702341735
Online_Training [264/700]: mean_loss=0.011651286738924682
Online_Training [265/700]: mean_loss=0.019775137770920992
Online_Training [266/700]: mean_loss=0.005155345250386745
Online_Training [267/700]: mean_loss=0.012231259723193944
Online_Training [268/700]: mean_loss=0.021298359613865614
Online_Training [269/700]: mean_loss=0.01352533686440438
Online_Training [270/700]: mean_loss=0.00933746644295752
Online_Training [271/700]: mean_loss=0.016604956705123186
Online_Training [272/700]: mean_loss=0.009699123678728938
Online_Training [273/700]: mean_loss=0.012675425969064236
Online_Training [274/700]: mean_loss=0.013964110985398293
Online_Training [275/700]: mean_loss=0.026775068137794733
Online_Training [276/700]: mean_loss=0.03770495858043432
Online_Training [277/700]: mean_loss=0.014207132277078927
Online_Training [278/700]: mean_loss=0.012299504247494042
Online_Training [279/700]: mean_loss=0.015001325169578195
Online_Training [280/700]: mean_loss=0.00816206744639203
Online_Training [281/700]: mean_loss=0.026061340235173702
Online_Training [282/700]: mean_loss=0.005987379758153111
Online_Training [283/700]: mean_loss=0.005188389855902642
Online_Training [284/700]: mean_loss=0.03599003655835986
Online_Training [285/700]: mean_loss=0.006509682920295745
Online_Training [286/700]: mean_loss=0.008445901796221733
Online_Training [287/700]: mean_loss=0.028337621595710516
Online_Training [288/700]: mean_loss=0.010000952053815126
Online_Training [289/700]: mean_loss=0.009276154276449233
Online_Training [290/700]: mean_loss=0.015940216137096286
Online_Training [291/700]: mean_loss=0.00604204717092216
Online_Training [292/700]: mean_loss=0.006601980829145759
Online_Training [293/700]: mean_loss=0.013127206591889262
Online_Training [294/700]: mean_loss=0.005398747191065922
Online_Training [295/700]: mean_loss=0.008882099529728293
Online_Training [296/700]: mean_loss=0.011457630898803473
Online_Training [297/700]: mean_loss=0.01677756744902581
Online_Training [298/700]: mean_loss=0.02620245236903429
Online_Training [299/700]: mean_loss=0.021139543503522873
Online_Training [300/700]: mean_loss=0.005355855741072446
Online_Training [301/700]: mean_loss=0.013864187058061361
Online_Training [302/700]: mean_loss=0.024998544016852975
Online_Training [303/700]: mean_loss=0.01018764910986647
Online_Training [304/700]: mean_loss=0.013138444162905216
Online_Training [305/700]: mean_loss=0.011686317040584981
Online_Training [306/700]: mean_loss=0.01694202027283609
Online_Training [307/700]: mean_loss=0.02000882150605321
Online_Training [308/700]: mean_loss=0.013073799316771328
Online_Training [309/700]: mean_loss=0.03556711343117058
Online_Training [310/700]: mean_loss=0.009501903434284031
Online_Training [311/700]: mean_loss=0.04174714465625584
Online_Training [312/700]: mean_loss=0.017240750952623785
Online_Training [313/700]: mean_loss=0.008238683047238737
Online_Training [314/700]: mean_loss=0.019745501806028187
Online_Training [315/700]: mean_loss=0.02070009708404541
Online_Training [316/700]: mean_loss=0.005231892806477845
Online_Training [317/700]: mean_loss=0.016376593965105712
Online_Training [318/700]: mean_loss=0.011862594343256205
Online_Training [319/700]: mean_loss=0.019827630720101297
Online_Training [320/700]: mean_loss=0.01449280430097133
Online_Training [321/700]: mean_loss=0.013684190576896071
Online_Training [322/700]: mean_loss=0.017169123166240752
Online_Training [323/700]: mean_loss=0.01703117648139596
Online_Training [324/700]: mean_loss=0.008089672250207514
Online_Training [325/700]: mean_loss=0.011678577749989927
Online_Training [326/700]: mean_loss=0.015827449853532016
Online_Training [327/700]: mean_loss=0.01280642650090158
Online_Training [328/700]: mean_loss=0.017209043726325035
Online_Training [329/700]: mean_loss=0.009619489195756614
Online_Training [330/700]: mean_loss=0.009619459218811244
Online_Training [331/700]: mean_loss=0.01586995937395841
Online_Training [332/700]: mean_loss=0.004790157196111977
Online_Training [333/700]: mean_loss=0.006274077401030809
Online_Training [334/700]: mean_loss=0.008718447294086218
Online_Training [335/700]: mean_loss=0.014377423212863505
Online_Training [336/700]: mean_loss=0.016974358935840428
Online_Training [337/700]: mean_loss=0.008450343448203057
Online_Training [338/700]: mean_loss=0.010433978168293834
Online_Training [339/700]: mean_loss=0.010726964217610657
Online_Training [340/700]: mean_loss=0.007296405441593379
Online_Training [341/700]: mean_loss=0.00851607508957386
Online_Training [342/700]: mean_loss=0.006779112387448549
Online_Training [343/700]: mean_loss=0.005504930217284709
Online_Training [344/700]: mean_loss=0.012919853674247861
Online_Training [345/700]: mean_loss=0.022526450222358108
Online_Training [346/700]: mean_loss=0.005038903444074094
Online_Training [347/700]: mean_loss=0.009168467717245221
Online_Training [348/700]: mean_loss=0.006191220425534993
Online_Training [349/700]: mean_loss=0.004693237598985434
Online_Training [350/700]: mean_loss=0.015526597620919347
Online_Training [351/700]: mean_loss=0.027702014660462737
Online_Training [352/700]: mean_loss=0.007114326232112944
Online_Training [353/700]: mean_loss=0.008046052069403231
Online_Training [354/700]: mean_loss=0.014496957301162183
Online_Training [355/700]: mean_loss=0.014604228432290256
Online_Training [356/700]: mean_loss=0.005635840003378689
Online_Training [357/700]: mean_loss=0.019819812616333365
Online_Training [358/700]: mean_loss=0.00989845977164805
Online_Training [359/700]: mean_loss=0.04460205091163516
Online_Training [360/700]: mean_loss=0.07055799569934607
Online_Training [361/700]: mean_loss=0.01133891404606402
Online_Training [362/700]: mean_loss=0.02778869471512735
Online_Training [363/700]: mean_loss=0.012422965606674552
Online_Training [364/700]: mean_loss=0.04779608198441565
Online_Training [365/700]: mean_loss=0.021218487760052085
Online_Training [366/700]: mean_loss=0.02293422748334706
Online_Training [367/700]: mean_loss=0.0062116008484736085
Online_Training [368/700]: mean_loss=0.005900195916183293
Online_Training [369/700]: mean_loss=0.013612226815894246
Online_Training [370/700]: mean_loss=0.010987206478603184
Online_Training [371/700]: mean_loss=0.006522772309836
Online_Training [372/700]: mean_loss=0.005159297434147447
Online_Training [373/700]: mean_loss=0.006387493049260229
Online_Training [374/700]: mean_loss=0.0062592155882157385
Online_Training [375/700]: mean_loss=0.017257690895348787
Online_Training [376/700]: mean_loss=0.0084396154852584
Online_Training [377/700]: mean_loss=0.023516910383477807
Online_Training [378/700]: mean_loss=0.004826104093808681
Online_Training [379/700]: mean_loss=0.007407007564324886
Online_Training [380/700]: mean_loss=0.016788746579550207
Online_Training [381/700]: mean_loss=0.01830253517255187
Online_Training [382/700]: mean_loss=0.004421327874297276
Online_Training [383/700]: mean_loss=0.03155454550869763
Online_Training [384/700]: mean_loss=0.002778397378278896
Online_Training [385/700]: mean_loss=0.024209513794630766
Online_Training [386/700]: mean_loss=0.0144627729896456
Online_Training [387/700]: mean_loss=0.015893739880993962
Online_Training [388/700]: mean_loss=0.006933242955710739
Online_Training [389/700]: mean_loss=0.009122962597757578
Online_Training [390/700]: mean_loss=0.00900401663966477
Online_Training [391/700]: mean_loss=0.007942835916765034
Online_Training [392/700]: mean_loss=0.006462385121267289
Online_Training [393/700]: mean_loss=0.01401218434330076
Online_Training [394/700]: mean_loss=0.009647823870182037
Online_Training [395/700]: mean_loss=0.006764219200704247
Online_Training [396/700]: mean_loss=0.014230610802769661
Online_Training [397/700]: mean_loss=0.23487128131091595
Online_Training [398/700]: mean_loss=0.08617412392050028
Online_Training [399/700]: mean_loss=0.018893232801929116
Online_Training [400/700]: mean_loss=0.07832339638844132
Online_Training [401/700]: mean_loss=0.12582352384924889
Online_Training [402/700]: mean_loss=0.02567670587450266
Online_Training [403/700]: mean_loss=0.05920492811128497
Online_Training [404/700]: mean_loss=0.009812931821215898
Online_Training [405/700]: mean_loss=0.00570538523606956
Online_Training [406/700]: mean_loss=0.022435737308114767
Online_Training [407/700]: mean_loss=0.0062966361292637885
Online_Training [408/700]: mean_loss=0.013028956251218915
Online_Training [409/700]: mean_loss=0.14285966381430626
Online_Training [410/700]: mean_loss=0.05923589784651995
Online_Training [411/700]: mean_loss=0.02048842574004084
Online_Training [412/700]: mean_loss=0.010482717887498438
Online_Training [413/700]: mean_loss=0.0056679382105357945
Online_Training [414/700]: mean_loss=0.007585564802866429
Online_Training [415/700]: mean_loss=0.007283009705133736
Online_Training [416/700]: mean_loss=0.03975517861545086
Online_Training [417/700]: mean_loss=0.028432508697733283
Online_Training [418/700]: mean_loss=0.014197811833582819
Online_Training [419/700]: mean_loss=0.011813943914603442
Online_Training [420/700]: mean_loss=0.010415055905468762
Online_Training [421/700]: mean_loss=0.00848106254125014
Online_Training [422/700]: mean_loss=0.0060245750937610865
Online_Training [423/700]: mean_loss=0.01752564264461398
Online_Training [424/700]: mean_loss=0.005913365574087948
Online_Training [425/700]: mean_loss=0.06518830917775631
Online_Training [426/700]: mean_loss=0.13897211756557226
Online_Training [427/700]: mean_loss=0.008157510368619114
Online_Training [428/700]: mean_loss=0.025716408155858517
Online_Training [429/700]: mean_loss=0.02990671480074525
Online_Training [430/700]: mean_loss=0.010344814974814653
Online_Training [431/700]: mean_loss=0.01597162743564695
Online_Training [432/700]: mean_loss=0.009365863399580121
Online_Training [433/700]: mean_loss=0.02167557366192341
Online_Training [434/700]: mean_loss=0.017616136698052287
Online_Training [435/700]: mean_loss=0.005495712335687131
Online_Training [436/700]: mean_loss=0.031108675990253687
Online_Training [437/700]: mean_loss=0.004693940514698625
Online_Training [438/700]: mean_loss=0.11475796159356833
Online_Training [439/700]: mean_loss=0.02660637185908854
Online_Training [440/700]: mean_loss=0.042539605405181646
Online_Training [441/700]: mean_loss=0.09277808014303446
Online_Training [442/700]: mean_loss=0.019225266529247165
Online_Training [443/700]: mean_loss=0.016269999439828098
Online_Training [444/700]: mean_loss=0.022477532736957073
Online_Training [445/700]: mean_loss=0.007368983933702111
Online_Training [446/700]: mean_loss=0.004718293435871601
Online_Training [447/700]: mean_loss=0.019118504133075476
Online_Training [448/700]: mean_loss=0.012649810872972012
Online_Training [449/700]: mean_loss=0.006030207907315344
Online_Training [450/700]: mean_loss=0.012037300853990018
Online_Training [451/700]: mean_loss=0.0055840067798271775
Online_Training [452/700]: mean_loss=0.02056010952219367
Online_Training [453/700]: mean_loss=0.005631261272355914
Online_Training [454/700]: mean_loss=0.013172692735679448
Online_Training [455/700]: mean_loss=0.010145054082386196
Online_Training [456/700]: mean_loss=0.007874930801335722
Online_Training [457/700]: mean_loss=0.006671634968370199
Online_Training [458/700]: mean_loss=0.005698859633412212
Online_Training [459/700]: mean_loss=0.015192577731795609
Online_Training [460/700]: mean_loss=0.011195564758963883
Online_Training [461/700]: mean_loss=0.010672053904272616
Online_Training [462/700]: mean_loss=0.01536973484326154
Online_Training [463/700]: mean_loss=0.00957888545235619
Online_Training [464/700]: mean_loss=0.012784903752617538
Online_Training [465/700]: mean_loss=0.01271236059255898
Online_Training [466/700]: mean_loss=0.00947061541955918
Online_Training [467/700]: mean_loss=0.020568655570968986
Online_Training [468/700]: mean_loss=0.004517417517490685
Online_Training [469/700]: mean_loss=0.008318630862049758
Online_Training [470/700]: mean_loss=0.009341549768578261
Online_Training [471/700]: mean_loss=0.019211526727303863
Online_Training [472/700]: mean_loss=0.0050302844610996544
Online_Training [473/700]: mean_loss=0.003792742994846776
Online_Training [474/700]: mean_loss=0.0174173730192706
Online_Training [475/700]: mean_loss=0.009301794460043311
Online_Training [476/700]: mean_loss=0.00691797339823097
Online_Training [477/700]: mean_loss=0.007058188086375594
Online_Training [478/700]: mean_loss=0.005226355220656842
Online_Training [479/700]: mean_loss=0.006625817448366433
Online_Training [480/700]: mean_loss=0.01772891462314874
Online_Training [481/700]: mean_loss=0.014135329984128475
Online_Training [482/700]: mean_loss=0.007393789244815707
Online_Training [483/700]: mean_loss=0.008139799756463617
Online_Training [484/700]: mean_loss=0.005829876114148647
Online_Training [485/700]: mean_loss=0.004788426740560681
Online_Training [486/700]: mean_loss=0.006345475267153233
Online_Training [487/700]: mean_loss=0.0025168892461806536
Online_Training [488/700]: mean_loss=0.015687849489040673
Online_Training [489/700]: mean_loss=0.008426129235886037
Online_Training [490/700]: mean_loss=0.01740818191319704
Online_Training [491/700]: mean_loss=0.005556389456614852
Online_Training [492/700]: mean_loss=0.003987722040619701
Online_Training [493/700]: mean_loss=0.004888242488959804
Online_Training [494/700]: mean_loss=0.007147522235754877
Online_Training [495/700]: mean_loss=0.00415032560704276
Online_Training [496/700]: mean_loss=0.008507943246513605
Online_Training [497/700]: mean_loss=0.01682478014845401
Online_Training [498/700]: mean_loss=0.02665995666757226
Online_Training [499/700]: mean_loss=0.029753987211734056
Online_Training [500/700]: mean_loss=0.05205257888883352
Online_Training [501/700]: mean_loss=0.07698506722226739
Online_Training [502/700]: mean_loss=0.014565408462658525
Online_Training [503/700]: mean_loss=0.010622214060276747
Online_Training [504/700]: mean_loss=0.010811474057845771
Online_Training [505/700]: mean_loss=0.0067785835126414895
Online_Training [506/700]: mean_loss=0.009584403480403125
Online_Training [507/700]: mean_loss=0.021338749211281538
Online_Training [508/700]: mean_loss=0.005307535466272384
Online_Training [509/700]: mean_loss=0.009194458834826946
Online_Training [510/700]: mean_loss=0.007375838351435959
Online_Training [511/700]: mean_loss=0.0038765237550251186
Online_Training [512/700]: mean_loss=0.023529052734375
Online_Training [513/700]: mean_loss=0.01423992810305208
Online_Training [514/700]: mean_loss=0.00838931422913447
Online_Training [515/700]: mean_loss=0.0186249827966094
Online_Training [516/700]: mean_loss=0.008375123259611428
Online_Training [517/700]: mean_loss=0.00893429055577144
Online_Training [518/700]: mean_loss=0.0034157627960667014
Online_Training [519/700]: mean_loss=0.005220748658757657
Online_Training [520/700]: mean_loss=0.04007978388108313
Online_Training [521/700]: mean_loss=0.006997449556365609
Online_Training [522/700]: mean_loss=0.00981153518659994
Online_Training [523/700]: mean_loss=0.005369849328417331
Online_Training [524/700]: mean_loss=0.010353301069699228
Online_Training [525/700]: mean_loss=0.009427158744074404
Online_Training [526/700]: mean_loss=0.0054985611932352185
Online_Training [527/700]: mean_loss=0.010402472980786115
Online_Training [528/700]: mean_loss=0.014573883032426238
Online_Training [529/700]: mean_loss=0.001960697351023555
Online_Training [530/700]: mean_loss=0.008603837748523802
Online_Training [531/700]: mean_loss=0.018487814581021667
Online_Training [532/700]: mean_loss=0.004845576942898333
Online_Training [533/700]: mean_loss=0.005374477885197848
Online_Training [534/700]: mean_loss=0.005919370334595442
Online_Training [535/700]: mean_loss=0.01157498697284609
Online_Training [536/700]: mean_loss=0.006731266796123236
Online_Training [537/700]: mean_loss=0.004613839671947062
Online_Training [538/700]: mean_loss=0.013982341042719781
Online_Training [539/700]: mean_loss=0.008818615402560681
Online_Training [540/700]: mean_loss=0.004707629937911406
Online_Training [541/700]: mean_loss=0.012491133064031601
Online_Training [542/700]: mean_loss=0.09599386248737574
Online_Training [543/700]: mean_loss=0.07189320912584662
Online_Training [544/700]: mean_loss=0.010029205121099949
Online_Training [545/700]: mean_loss=0.011497541680000722
Online_Training [546/700]: mean_loss=0.007569731154944748
Online_Training [547/700]: mean_loss=0.005733088531997055
Online_Training [548/700]: mean_loss=0.014106551185250282
Online_Training [549/700]: mean_loss=0.008248155703768134
Online_Training [550/700]: mean_loss=0.018365052994340658
Online_Training [551/700]: mean_loss=0.007124294817913324
Online_Training [552/700]: mean_loss=0.01609642431139946
Online_Training [553/700]: mean_loss=0.014677437487989664
Online_Training [554/700]: mean_loss=0.006184894009493291
Online_Training [555/700]: mean_loss=0.014181722071953118
Online_Training [556/700]: mean_loss=0.01110444136429578
Online_Training [557/700]: mean_loss=0.004340692074038088
Online_Training [558/700]: mean_loss=0.003067379439016804
Online_Training [559/700]: mean_loss=0.01119196618674323
Online_Training [560/700]: mean_loss=0.013689205632545054
Online_Training [561/700]: mean_loss=0.008385228808037937
Online_Training [562/700]: mean_loss=0.0030902832513675094
Online_Training [563/700]: mean_loss=0.01599685160908848
Online_Training [564/700]: mean_loss=0.17388333939015865
Online_Training [565/700]: mean_loss=0.04419044964015484
Online_Training [566/700]: mean_loss=0.007508948969189078
Online_Training [567/700]: mean_loss=0.016815460519865155
Online_Training [568/700]: mean_loss=0.013739042216911912
Online_Training [569/700]: mean_loss=0.011399002280086279
Online_Training [570/700]: mean_loss=0.009457230567932129
Online_Training [571/700]: mean_loss=0.005936265864875168
Online_Training [572/700]: mean_loss=0.003995068691438064
Online_Training [573/700]: mean_loss=0.008156620780937374
Online_Training [574/700]: mean_loss=0.012036946951411664
Online_Training [575/700]: mean_loss=0.0095914711127989
Online_Training [576/700]: mean_loss=0.0076903997687622905
Online_Training [577/700]: mean_loss=0.008682198822498322
Online_Training [578/700]: mean_loss=0.0060362000949680805
Online_Training [579/700]: mean_loss=0.006371148687321693
Online_Training [580/700]: mean_loss=0.005528982495889068
Online_Training [581/700]: mean_loss=0.007750574150122702
Online_Training [582/700]: mean_loss=0.007816836354322731
Online_Training [583/700]: mean_loss=0.015050536720082164
Online_Training [584/700]: mean_loss=0.006947789457626641
Online_Training [585/700]: mean_loss=0.005992988415528089
Online_Training [586/700]: mean_loss=0.01942656608298421
Online_Training [587/700]: mean_loss=0.01462195545900613
Online_Training [588/700]: mean_loss=0.006927202921360731
Online_Training [589/700]: mean_loss=0.01215285249054432
Online_Training [590/700]: mean_loss=0.007676041452214122
Online_Training [591/700]: mean_loss=0.013654240872710943
Online_Training [592/700]: mean_loss=0.014802113990299404
Online_Training [593/700]: mean_loss=0.007538078469224274
Online_Training [594/700]: mean_loss=0.005653750558849424
Online_Training [595/700]: mean_loss=0.019976837560534477
Online_Training [596/700]: mean_loss=0.006129511806648225
Online_Training [597/700]: mean_loss=0.006735997798386961
Online_Training [598/700]: mean_loss=0.009949613770004362
Online_Training [599/700]: mean_loss=0.016566688776947558
Online_Training [600/700]: mean_loss=0.006969140551518649
Online_Training [601/700]: mean_loss=0.011200632085092366
Online_Training [602/700]: mean_loss=0.008395566197577864
Online_Training [603/700]: mean_loss=0.004896708589512855
Online_Training [604/700]: mean_loss=0.012448728550225496
Online_Training [605/700]: mean_loss=0.0039707608229946345
Online_Training [606/700]: mean_loss=0.0051742722862400115
Online_Training [607/700]: mean_loss=0.00969285937026143
Online_Training [608/700]: mean_loss=0.006191714259330183
Online_Training [609/700]: mean_loss=0.011202224995940924
Online_Training [610/700]: mean_loss=0.002428908657748252
Online_Training [611/700]: mean_loss=0.018636018503457308
Online_Training [612/700]: mean_loss=0.0045007495500613
Online_Training [613/700]: mean_loss=0.00509564473759383
Online_Training [614/700]: mean_loss=0.006445124628953636
Online_Training [615/700]: mean_loss=0.0036867536255158484
Online_Training [616/700]: mean_loss=0.008537477580830455
Online_Training [617/700]: mean_loss=0.026619876036420465
Online_Training [618/700]: mean_loss=0.010266029625199735
Online_Training [619/700]: mean_loss=0.0064306374988518655
Online_Training [620/700]: mean_loss=0.018146138172596693
Online_Training [621/700]: mean_loss=0.006690935813821852
Online_Training [622/700]: mean_loss=0.012662848108448088
Online_Training [623/700]: mean_loss=0.025747488834895194
Online_Training [624/700]: mean_loss=0.12782935611903667
Online_Training [625/700]: mean_loss=0.0351386615075171
Online_Training [626/700]: mean_loss=0.015948036452755332
Online_Training [627/700]: mean_loss=0.013039365294389427
Online_Training [628/700]: mean_loss=0.012901456095278263
Online_Training [629/700]: mean_loss=0.008413710223976523
Online_Training [630/700]: mean_loss=0.01522214780561626
Online_Training [631/700]: mean_loss=0.008238355745561421
Online_Training [632/700]: mean_loss=0.004137840267503634
Online_Training [633/700]: mean_loss=0.00727575266500935
Online_Training [634/700]: mean_loss=0.008653025142848492
Online_Training [635/700]: mean_loss=0.007569703098852187
Online_Training [636/700]: mean_loss=0.004124372499063611
Online_Training [637/700]: mean_loss=0.023054869147017598
Online_Training [638/700]: mean_loss=0.012550818151794374
Online_Training [639/700]: mean_loss=0.04771740734577179
Online_Training [640/700]: mean_loss=0.06560433655977249
Online_Training [641/700]: mean_loss=0.012027077260427177
Online_Training [642/700]: mean_loss=0.033819040516391397
Online_Training [643/700]: mean_loss=0.013801473309285939
Online_Training [644/700]: mean_loss=0.012588196084834635
Online_Training [645/700]: mean_loss=0.010385658359155059
Online_Training [646/700]: mean_loss=0.01090096915140748
Online_Training [647/700]: mean_loss=0.017031491501256824
Online_Training [648/700]: mean_loss=0.0028567045519594103
Online_Training [649/700]: mean_loss=0.004090069705853239
Online_Training [650/700]: mean_loss=0.012929394491948187
Online_Training [651/700]: mean_loss=0.008409237547311932
Online_Training [652/700]: mean_loss=0.01188874151557684
Online_Training [653/700]: mean_loss=0.009826145134866238
Online_Training [654/700]: mean_loss=0.003870642278343439
Online_Training [655/700]: mean_loss=0.10252684075385332
Online_Training [656/700]: mean_loss=0.024500997504219413
Online_Training [657/700]: mean_loss=0.010997424251399934
Online_Training [658/700]: mean_loss=0.014812643988989294
Online_Training [659/700]: mean_loss=0.0063161373836919665
Online_Training [660/700]: mean_loss=0.005862145510036498
Online_Training [661/700]: mean_loss=0.006521759438328445
Online_Training [662/700]: mean_loss=0.01256987126544118
Online_Training [663/700]: mean_loss=0.011790018412284553
Online_Training [664/700]: mean_loss=0.013248013914562762
Online_Training [665/700]: mean_loss=0.00873021106235683
Online_Training [666/700]: mean_loss=0.004309830255806446
Online_Training [667/700]: mean_loss=0.010330254561267793
Online_Training [668/700]: mean_loss=0.008404858410358429
Online_Training [669/700]: mean_loss=0.005643090815283358
Online_Training [670/700]: mean_loss=0.006739165051840246
Online_Training [671/700]: mean_loss=0.004386231652460992
Online_Training [672/700]: mean_loss=0.004501702205743641
Online_Training [673/700]: mean_loss=0.007795913552399725
Online_Training [674/700]: mean_loss=0.009889432927593589
Online_Training [675/700]: mean_loss=0.014724977663718164
Online_Training [676/700]: mean_loss=0.017491594655439258
Online_Training [677/700]: mean_loss=0.006523267657030374
Online_Training [678/700]: mean_loss=0.013956400216557086
Online_Training [679/700]: mean_loss=0.003580697695724666
Online_Training [680/700]: mean_loss=0.010838577873073518
Online_Training [681/700]: mean_loss=0.005245978245511651
Online_Training [682/700]: mean_loss=0.009946235921233892
Online_Training [683/700]: mean_loss=0.007130726182367653
Online_Training [684/700]: mean_loss=0.07002181373536587
Online_Training [685/700]: mean_loss=0.01573938620276749
Online_Training [686/700]: mean_loss=0.01429602864664048
Online_Training [687/700]: mean_loss=0.007328774023335427
Online_Training [688/700]: mean_loss=0.004990816087229177
Online_Training [689/700]: mean_loss=0.008858620829414576
Online_Training [690/700]: mean_loss=0.006345465430058539
Online_Training [691/700]: mean_loss=0.011306162341497838
Online_Training [692/700]: mean_loss=0.012522596400231123
Online_Training [693/700]: mean_loss=0.023444616934284568
Online_Training [694/700]: mean_loss=0.00720724806888029
Online_Training [695/700]: mean_loss=0.015072093927301466
Online_Training [696/700]: mean_loss=0.007098332745954394
Online_Training [697/700]: mean_loss=0.012187807820737362
Online_Training [698/700]: mean_loss=0.004165504447882995
Online_Training [699/700]: mean_loss=0.012596227694302797
Online_Training [700/700]: mean_loss=0.007737374864518642
Q_Learning [1/300]: mean_loss=0.22984569147229195
Q_Learning [2/300]: mean_loss=0.1446281224489212
Q_Learning [3/300]: mean_loss=0.1903734654188156
Q_Learning [4/300]: mean_loss=0.1921613160520792
Q_Learning [5/300]: mean_loss=0.11071547865867615
Q_Learning [6/300]: mean_loss=0.18923038057982922
Q_Learning [7/300]: mean_loss=0.1732693910598755
Q_Learning [8/300]: mean_loss=0.11567330826073885
Q_Learning [9/300]: mean_loss=0.12196548469364643
Q_Learning [10/300]: mean_loss=0.12064539827406406
Q_Learning [11/300]: mean_loss=0.0640038033016026
Q_Learning [12/300]: mean_loss=0.078603720292449
Q_Learning [13/300]: mean_loss=0.11834658496081829
Q_Learning [14/300]: mean_loss=0.13924693688750267
Q_Learning [15/300]: mean_loss=0.0647319545969367
Q_Learning [16/300]: mean_loss=0.04651808412745595
Q_Learning [17/300]: mean_loss=0.14976632222533226
Q_Learning [18/300]: mean_loss=0.07927068136632442
Q_Learning [19/300]: mean_loss=0.09240580722689629
Q_Learning [20/300]: mean_loss=0.08091053552925587
Q_Learning [21/300]: mean_loss=0.06564342649653554
Q_Learning [22/300]: mean_loss=0.159101577475667
Q_Learning [23/300]: mean_loss=0.18254006654024124
Q_Learning [24/300]: mean_loss=0.031052908394485712
Q_Learning [25/300]: mean_loss=0.050375732127577066
Q_Learning [26/300]: mean_loss=0.10890268534421921
Q_Learning [27/300]: mean_loss=0.05841910932213068
Q_Learning [28/300]: mean_loss=0.1844107285141945
Q_Learning [29/300]: mean_loss=0.040236266795545816
Q_Learning [30/300]: mean_loss=0.029289643513038754
Q_Learning [31/300]: mean_loss=0.08400561846792698
Q_Learning [32/300]: mean_loss=0.057361370883882046
Q_Learning [33/300]: mean_loss=0.027683190070092678
Q_Learning [34/300]: mean_loss=0.0686061643064022
Q_Learning [35/300]: mean_loss=0.038984608836472034
Q_Learning [36/300]: mean_loss=0.06420687679201365
Q_Learning [37/300]: mean_loss=0.029865203658118844
Q_Learning [38/300]: mean_loss=0.033518722746521235
Q_Learning [39/300]: mean_loss=0.031221280340105295
Q_Learning [40/300]: mean_loss=0.03905748715624213
Q_Learning [41/300]: mean_loss=0.05821238411590457
Q_Learning [42/300]: mean_loss=0.04551865393295884
Q_Learning [43/300]: mean_loss=0.02077032858505845
Q_Learning [44/300]: mean_loss=0.03305713087320328
Q_Learning [45/300]: mean_loss=0.025263817980885506
Q_Learning [46/300]: mean_loss=0.04120849911123514
Q_Learning [47/300]: mean_loss=0.024692430393770337
Q_Learning [48/300]: mean_loss=0.03934966214001179
Q_Learning [49/300]: mean_loss=0.028654457768425345
Q_Learning [50/300]: mean_loss=0.013951034867204726
Q_Learning [51/300]: mean_loss=0.03557633445598185
Q_Learning [52/300]: mean_loss=0.03254688298329711
Q_Learning [53/300]: mean_loss=0.023823440074920654
Q_Learning [54/300]: mean_loss=0.018636846216395497
Q_Learning [55/300]: mean_loss=0.03612667974084616
Q_Learning [56/300]: mean_loss=0.04369881097227335
Q_Learning [57/300]: mean_loss=0.011175030493177474
Q_Learning [58/300]: mean_loss=0.03097123373299837
Q_Learning [59/300]: mean_loss=0.04854295775294304
Q_Learning [60/300]: mean_loss=0.032089798245579004
Q_Learning [61/300]: mean_loss=0.026344362646341324
Q_Learning [62/300]: mean_loss=0.04771607369184494
Q_Learning [63/300]: mean_loss=0.020236316369846463
Q_Learning [64/300]: mean_loss=0.03610446210950613
Q_Learning [65/300]: mean_loss=0.015809105127118528
Q_Learning [66/300]: mean_loss=0.020157416816800833
Q_Learning [67/300]: mean_loss=0.018149292445741594
Q_Learning [68/300]: mean_loss=0.03337397635914385
Q_Learning [69/300]: mean_loss=0.024737362749874592
Q_Learning [70/300]: mean_loss=0.016820967895910144
Q_Learning [71/300]: mean_loss=0.047000505961477757
Q_Learning [72/300]: mean_loss=0.020211179042235017
Q_Learning [73/300]: mean_loss=0.022123886505141854
Q_Learning [74/300]: mean_loss=0.013135554734617472
Q_Learning [75/300]: mean_loss=0.018342030234634876
Q_Learning [76/300]: mean_loss=0.02198091265745461
Q_Learning [77/300]: mean_loss=0.014235768700018525
Q_Learning [78/300]: mean_loss=0.013680544216185808
Q_Learning [79/300]: mean_loss=0.007055851339828223
Q_Learning [80/300]: mean_loss=0.0131277812179178
Q_Learning [81/300]: mean_loss=0.02685626852326095
Q_Learning [82/300]: mean_loss=0.016521376674063504
Q_Learning [83/300]: mean_loss=0.017483777133747935
Q_Learning [84/300]: mean_loss=0.011041489080525935
Q_Learning [85/300]: mean_loss=0.00951469165738672
Q_Learning [86/300]: mean_loss=0.01578844035975635
Q_Learning [87/300]: mean_loss=0.11887121666222811
Q_Learning [88/300]: mean_loss=0.21236909553408623
Q_Learning [89/300]: mean_loss=0.0287454251665622
Q_Learning [90/300]: mean_loss=0.012993674608878791
Q_Learning [91/300]: mean_loss=0.03310153027996421
Q_Learning [92/300]: mean_loss=0.030606522224843502
Q_Learning [93/300]: mean_loss=0.02003168361261487
Q_Learning [94/300]: mean_loss=0.027464587008580565
Q_Learning [95/300]: mean_loss=0.09969302080571651
Q_Learning [96/300]: mean_loss=0.10039678774774075
Q_Learning [97/300]: mean_loss=0.02321829623542726
Q_Learning [98/300]: mean_loss=0.012650376185774803
Q_Learning [99/300]: mean_loss=0.07006371533498168
Q_Learning [100/300]: mean_loss=0.10451953765004873
Q_Learning [101/300]: mean_loss=0.023787330370396376
Q_Learning [102/300]: mean_loss=0.04737059911713004
Q_Learning [103/300]: mean_loss=0.019846139010041952
Q_Learning [104/300]: mean_loss=0.04408856248483062
Q_Learning [105/300]: mean_loss=0.025888361735269427
Q_Learning [106/300]: mean_loss=0.023554528132081032
Q_Learning [107/300]: mean_loss=0.01884721650276333
Q_Learning [108/300]: mean_loss=0.01418521860614419
Q_Learning [109/300]: mean_loss=0.02203393168747425
Q_Learning [110/300]: mean_loss=0.008595240593422204
Q_Learning [111/300]: mean_loss=0.05599840823560953
Q_Learning [112/300]: mean_loss=0.016152574215084314
Q_Learning [113/300]: mean_loss=0.023380483267828822
Q_Learning [114/300]: mean_loss=0.035619099624454975
Q_Learning [115/300]: mean_loss=0.015329169109463692
Q_Learning [116/300]: mean_loss=0.006151761277578771
Q_Learning [117/300]: mean_loss=0.018453734694048762
Q_Learning [118/300]: mean_loss=0.017592994961887598
Q_Learning [119/300]: mean_loss=0.008061401371378452
Q_Learning [120/300]: mean_loss=0.02401578309945762
Q_Learning [121/300]: mean_loss=0.025352487107738853
Q_Learning [122/300]: mean_loss=0.019262550864368677
Q_Learning [123/300]: mean_loss=0.009115580236539245
Q_Learning [124/300]: mean_loss=0.017726304125972092
Q_Learning [125/300]: mean_loss=0.006501079013105482
Q_Learning [126/300]: mean_loss=0.0258462680503726
Q_Learning [127/300]: mean_loss=0.021553677041083574
Q_Learning [128/300]: mean_loss=0.013436007662676275
Q_Learning [129/300]: mean_loss=0.0034930481342598796
Q_Learning [130/300]: mean_loss=0.08810344990342855
Q_Learning [131/300]: mean_loss=0.11041061021387577
Q_Learning [132/300]: mean_loss=0.04329280788078904
Q_Learning [133/300]: mean_loss=0.05528324702754617
Q_Learning [134/300]: mean_loss=0.013911763555370271
Q_Learning [135/300]: mean_loss=0.01897130743600428
Q_Learning [136/300]: mean_loss=0.0131950993090868
Q_Learning [137/300]: mean_loss=0.06528731901198626
Q_Learning [138/300]: mean_loss=0.04727371223270893
Q_Learning [139/300]: mean_loss=0.025596311083063483
Q_Learning [140/300]: mean_loss=0.025596588850021362
Q_Learning [141/300]: mean_loss=0.01825588895007968
Q_Learning [142/300]: mean_loss=0.020179286948405206
Q_Learning [143/300]: mean_loss=0.025171255692839622
Q_Learning [144/300]: mean_loss=0.018245558021590114
Q_Learning [145/300]: mean_loss=0.06152750039473176
Q_Learning [146/300]: mean_loss=0.14182249270379543
Q_Learning [147/300]: mean_loss=0.04277229495346546
Q_Learning [148/300]: mean_loss=0.020947430981323123
Q_Learning [149/300]: mean_loss=0.011017950717359781
Q_Learning [150/300]: mean_loss=0.020049378043040633
Q_Learning [151/300]: mean_loss=0.009113506705034524
Q_Learning [152/300]: mean_loss=0.011814850382506847
Q_Learning [153/300]: mean_loss=0.01725016674026847
Q_Learning [154/300]: mean_loss=0.018886225763708353
Q_Learning [155/300]: mean_loss=0.009356886090245098
Q_Learning [156/300]: mean_loss=0.037247829837724566
Q_Learning [157/300]: mean_loss=0.06324194325134158
Q_Learning [158/300]: mean_loss=0.06117040617391467
Q_Learning [159/300]: mean_loss=0.0176648908527568
Q_Learning [160/300]: mean_loss=0.04116751439869404
Q_Learning [161/300]: mean_loss=0.005953751562628895
Q_Learning [162/300]: mean_loss=0.019568876479752362
Q_Learning [163/300]: mean_loss=0.01711360877379775
Q_Learning [164/300]: mean_loss=0.015766375930979848
Q_Learning [165/300]: mean_loss=0.006925862398929894
Q_Learning [166/300]: mean_loss=0.005652800988173112
Q_Learning [167/300]: mean_loss=0.006334141653496772
Q_Learning [168/300]: mean_loss=0.009035746159497648
Q_Learning [169/300]: mean_loss=0.010783753357827663
Q_Learning [170/300]: mean_loss=0.05292933713644743
Q_Learning [171/300]: mean_loss=0.036775498650968075
Q_Learning [172/300]: mean_loss=0.048278349917382
Q_Learning [173/300]: mean_loss=0.017760571092367172
Q_Learning [174/300]: mean_loss=0.01765152788721025
Q_Learning [175/300]: mean_loss=0.014159437036141753
Q_Learning [176/300]: mean_loss=0.011669648112729192
Q_Learning [177/300]: mean_loss=0.06538464967161417
Q_Learning [178/300]: mean_loss=0.07775143999606371
Q_Learning [179/300]: mean_loss=0.04265197413042188
Q_Learning [180/300]: mean_loss=0.019034234806895256
Q_Learning [181/300]: mean_loss=0.01350951858330518
Q_Learning [182/300]: mean_loss=0.018895458662882447
Q_Learning [183/300]: mean_loss=0.0094576824340038
Q_Learning [184/300]: mean_loss=0.01837650965899229
Q_Learning [185/300]: mean_loss=0.02218257705681026
Q_Learning [186/300]: mean_loss=0.008546936966013163
Q_Learning [187/300]: mean_loss=0.016362987458705902
Q_Learning [188/300]: mean_loss=0.02936909021809697
Q_Learning [189/300]: mean_loss=0.017223584232851863
Q_Learning [190/300]: mean_loss=0.07628612965345383
Q_Learning [191/300]: mean_loss=0.09319958835840225
Q_Learning [192/300]: mean_loss=0.013414818560704589
Q_Learning [193/300]: mean_loss=0.030466575175523758
Q_Learning [194/300]: mean_loss=0.03047238034196198
Q_Learning [195/300]: mean_loss=0.016968839103356004
Q_Learning [196/300]: mean_loss=0.2151778656989336
Q_Learning [197/300]: mean_loss=0.08218030817806721
Q_Learning [198/300]: mean_loss=0.02613637549802661
Q_Learning [199/300]: mean_loss=0.015893905074335635
Q_Learning [200/300]: mean_loss=0.12608332838863134
Q_Learning [201/300]: mean_loss=0.1350012542679906
Q_Learning [202/300]: mean_loss=0.014669343247078359
Q_Learning [203/300]: mean_loss=0.06322350911796093
Q_Learning [204/300]: mean_loss=0.017253775848075747
Q_Learning [205/300]: mean_loss=0.013159371563233435
Q_Learning [206/300]: mean_loss=0.02144243661314249
Q_Learning [207/300]: mean_loss=0.023866902804002166
Q_Learning [208/300]: mean_loss=0.020138041814789176
Q_Learning [209/300]: mean_loss=0.00689222919754684
Q_Learning [210/300]: mean_loss=0.0500131924636662
Q_Learning [211/300]: mean_loss=0.018879317212849855
Q_Learning [212/300]: mean_loss=0.01059164060279727
Q_Learning [213/300]: mean_loss=0.012326863594353199
Q_Learning [214/300]: mean_loss=0.10451334435492754
Q_Learning [215/300]: mean_loss=0.07597077917307615
Q_Learning [216/300]: mean_loss=0.018140318687073886
Q_Learning [217/300]: mean_loss=0.019387402338907123
Q_Learning [218/300]: mean_loss=0.013788096839562058
Q_Learning [219/300]: mean_loss=0.013935894588939846
Q_Learning [220/300]: mean_loss=0.011065884842537344
Q_Learning [221/300]: mean_loss=0.013749685836955905
Q_Learning [222/300]: mean_loss=0.011598973302170634
Q_Learning [223/300]: mean_loss=0.004976572119630873
Q_Learning [224/300]: mean_loss=0.01019113149959594
Q_Learning [225/300]: mean_loss=0.006397287244908512
Q_Learning [226/300]: mean_loss=0.004604497749824077
Q_Learning [227/300]: mean_loss=0.03752371156588197
Q_Learning [228/300]: mean_loss=0.03131797816604376
Q_Learning [229/300]: mean_loss=0.021636173594743013
Q_Learning [230/300]: mean_loss=0.007286340929567814
Q_Learning [231/300]: mean_loss=0.02826577704399824
Q_Learning [232/300]: mean_loss=0.014982895227149129
Q_Learning [233/300]: mean_loss=0.007748387579340488
Q_Learning [234/300]: mean_loss=0.011824531597085297
Q_Learning [235/300]: mean_loss=0.009051271306816489
Q_Learning [236/300]: mean_loss=0.019470900064334273
Q_Learning [237/300]: mean_loss=0.018096817657351494
Q_Learning [238/300]: mean_loss=0.012144783861003816
Q_Learning [239/300]: mean_loss=0.09197136107832193
Q_Learning [240/300]: mean_loss=0.016099461005069315
Q_Learning [241/300]: mean_loss=0.024746101582422853
Q_Learning [242/300]: mean_loss=0.006403214065358043
Q_Learning [243/300]: mean_loss=0.02597202081233263
Q_Learning [244/300]: mean_loss=0.1201113285496831
Q_Learning [245/300]: mean_loss=0.12870927900075912
Q_Learning [246/300]: mean_loss=0.02275324915535748
Q_Learning [247/300]: mean_loss=0.02664166735485196
Q_Learning [248/300]: mean_loss=0.03898616530932486
Q_Learning [249/300]: mean_loss=0.009198611602187157
Q_Learning [250/300]: mean_loss=0.009244607761502266
Q_Learning [251/300]: mean_loss=0.009536041761748493
Q_Learning [252/300]: mean_loss=0.025325213558971882
Q_Learning [253/300]: mean_loss=0.002372799499426037
Q_Learning [254/300]: mean_loss=0.017273740842938423
Q_Learning [255/300]: mean_loss=0.007835006806999445
Q_Learning [256/300]: mean_loss=0.01589800661895424
Q_Learning [257/300]: mean_loss=0.017188691650517285
Q_Learning [258/300]: mean_loss=0.007839191530365497
Q_Learning [259/300]: mean_loss=0.011100744712166488
Q_Learning [260/300]: mean_loss=0.006553984887432307
Q_Learning [261/300]: mean_loss=0.01940088369883597
Q_Learning [262/300]: mean_loss=0.01815120643004775
Q_Learning [263/300]: mean_loss=0.015627646702341735
Q_Learning [264/300]: mean_loss=0.011651286738924682
Q_Learning [265/300]: mean_loss=0.019775137770920992
Q_Learning [266/300]: mean_loss=0.005155345250386745
Q_Learning [267/300]: mean_loss=0.012231259723193944
Q_Learning [268/300]: mean_loss=0.021298359613865614
Q_Learning [269/300]: mean_loss=0.01352533686440438
Q_Learning [270/300]: mean_loss=0.00933746644295752
Q_Learning [271/300]: mean_loss=0.016604956705123186
Q_Learning [272/300]: mean_loss=0.009699123678728938
Q_Learning [273/300]: mean_loss=0.012675425969064236
Q_Learning [274/300]: mean_loss=0.013964110985398293
Q_Learning [275/300]: mean_loss=0.026775068137794733
Q_Learning [276/300]: mean_loss=0.03770495858043432
Q_Learning [277/300]: mean_loss=0.014207132277078927
Q_Learning [278/300]: mean_loss=0.012299504247494042
Q_Learning [279/300]: mean_loss=0.015001325169578195
Q_Learning [280/300]: mean_loss=0.00816206744639203
Q_Learning [281/300]: mean_loss=0.026061340235173702
Q_Learning [282/300]: mean_loss=0.005987379758153111
Q_Learning [283/300]: mean_loss=0.005188389855902642
Q_Learning [284/300]: mean_loss=0.03599003655835986
Q_Learning [285/300]: mean_loss=0.006509682920295745
Q_Learning [286/300]: mean_loss=0.008445901796221733
Q_Learning [287/300]: mean_loss=0.028337621595710516
Q_Learning [288/300]: mean_loss=0.010000952053815126
Q_Learning [289/300]: mean_loss=0.009276154276449233
Q_Learning [290/300]: mean_loss=0.015940216137096286
Q_Learning [291/300]: mean_loss=0.00604204717092216
Q_Learning [292/300]: mean_loss=0.006601980829145759
Q_Learning [293/300]: mean_loss=0.013127206591889262
Q_Learning [294/300]: mean_loss=0.005398747191065922
Q_Learning [295/300]: mean_loss=0.008882099529728293
Q_Learning [296/300]: mean_loss=0.011457630898803473
Q_Learning [297/300]: mean_loss=0.01677756744902581
Q_Learning [298/300]: mean_loss=0.02620245236903429
Q_Learning [299/300]: mean_loss=0.021139543503522873
Q_Learning [300/300]: mean_loss=0.005355855741072446
Number of Samples after Autoencoder testing: 300
First Spike after testing: [0.5466007 3.5404353]
[2, 0, 1, 2, 0, 2, 0, 2, 0, 1, 2, 0, 1, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 0, 2, 1, 0, 2, 0, 1, 1, 0, 1, 1, 2, 0, 1, 2, 1, 1, 1, 0, 1, 2, 1, 2, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 0, 1, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 0, 2, 1, 2, 1, 1, 0, 2, 1, 1, 2, 2, 2, 2, 1, 1, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 2, 2, 1, 0, 1, 2, 0, 2, 2, 2, 1, 1, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 1, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 1, 1, 1, 2, 2, 1, 1, 0, 2, 1, 2, 0, 2, 1, 2, 0, 1, 0, 1, 0, 2, 0, 1, 1, 1, 0, 2, 0, 2, 1, 2, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 1, 0, 0, 1, 2, 2, 0, 2, 2, 2, 1, 1, 0, 2, 0, 2, 1, 0, 2, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 1, 0, 0, 2, 1, 2, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 2, 1, 2, 0, 0, 1, 2, 0, 1, 2, 2, 2, 0, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0, 2, 1, 2, 2, 1, 0, 2, 1, 1, 0, 1, 2]
[0, 1, 2, 0, 1, 0, 1, 0, 1, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 3, 1, 0, 2, 0, 0, 4, 0, 4, 1, 0, 0, 2, 0, 4, 5, 2, 4, 0, 1, 2, 2, 1, 2, 2, 0, 6, 2, 0, 2, 2, 2, 6, 2, 0, 2, 0, 4, 6, 0, 2, 2, 0, 4, 2, 2, 4, 0, 0, 4, 0, 0, 2, 0, 0, 6, 0, 4, 2, 1, 6, 0, 2, 2, 6, 0, 4, 4, 2, 4, 0, 7, 8, 2, 2, 4, 0, 4, 4, 0, 0, 0, 9, 2, 2, 6, 8, 10, 8, 8, 10, 10, 10, 8, 6, 10, 11, 12, 10, 10, 7, 8, 13, 12, 10, 6, 11, 10, 11, 11, 14, 15, 12, 14, 11, 16, 11, 10, 11, 11, 12, 11, 11, 12, 8, 10, 10, 11, 14, 11, 10, 10, 11, 10, 11, 11, 7, 12, 7, 11, 8, 6, 6, 10, 14, 12, 11, 10, 14, 6, 11, 10, 12, 15, 15, 10, 13, 6, 12, 12, 12, 10, 8, 10, 11, 12, 11, 11, 15, 12, 8, 6, 17, 10, 12, 18, 12, 12, 6, 10, 10, 10, 6, 6, 15, 17, 10, 10, 17, 12, 6, 6, 6, 18, 18, 10, 18, 18, 18, 12, 6, 10, 18, 6, 17, 6, 15, 19, 17, 20, 17, 10, 6, 12, 6, 17, 17, 15, 12, 15, 10, 17, 15, 18, 10, 21, 6, 12, 21, 6, 12, 12, 17, 21, 18, 7, 17, 6, 15, 12, 21, 6, 15, 18, 21, 18, 6, 12, 22, 21, 6, 15, 6, 15, 15, 17, 15, 21, 15, 17, 18, 12, 12, 21, 12, 12, 6, 23, 17]
Centroids: [[-4.3014617, 0.55263495], [-2.493692, 1.6307015], [3.4221566, 6.381358]]
Centroids: [[1.107465, 3.3580625], [-2.7643611, -0.23478341], [-1.3783286, 0.8665206], [-2.401388, -1.4784551], [-2.9042697, 0.45567057], [1.2023038, 1.1965183], [-4.2095156, 1.1117817], [-2.1202474, 3.4192786], [2.6634364, 6.5722938], [-0.27644527, 4.4724503], [-5.8145285, 0.30500206], [4.174892, 8.484743], [-3.0357356, 2.2586777], [3.013194, 7.8536325], [5.3664675, 10.2487], [-4.162341, 2.1501284], [-7.2823763, -0.3477364], [4.87029, 7.0429225], [6.168955, 8.348756], [9.240589, 11.740804], [7.7412915, 9.379341], [3.9372923, 6.418352], [1.332505, 5.814934], [-7.5421247, 1.2547935]]
Contingency Matrix: 
[[ 0 19  0  1 13  0 23  0  0  0 32  0  1  0  0 10  1  0  0  0  0  0  0  0]
 [ 0  1 36  0  2  0 10  5  0  0  0  0 28  0  0  6  0  0  0  0  0  0  1  1]
 [34  0  0  0  0  1  0  0 10  1  0 21  0  2  5  0  0 14 12  1  1  8  0  0]]
[[0, 19, 0, 1, 13, 0, 23, 0, 0, 0, 32, 0, 1, 0, 0, 10, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 36, 0, 2, 0, 10, 5, 0, 0, 0, 0, 28, 0, 0, 6, 0, 0, 0, 0, 0, 0, 1, 1], [34, 0, 0, 0, 0, 1, 0, 0, 10, 1, 0, 21, 0, 2, 5, 0, 0, 14, 12, 1, 1, 8, 0, 0]]
[[0, 19, 0, 1, 13, 0, 23, 0, 0, 0, 32, 0, 1, 0, 0, 10, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 36, 0, 2, 0, 10, 5, 0, 0, 0, 0, 28, 0, 0, 6, 0, 0, 0, 0, 0, 0, 1, 1], [34, 0, 0, 0, 0, 1, 0, 0, 10, 1, 0, 21, 0, 2, 5, 0, 0, 14, 12, 1, 1, 8, 0, 0]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
[[0, 19, -1, 1, 13, 0, 23, 0, 0, 0, 32, 0, 1, 0, 0, 10, 1, 0, 0, 0, 0, 0, 0, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [34, 0, -1, 0, 0, 1, 0, 0, 10, 1, 0, 21, 0, 2, 5, 0, 0, 14, 12, 1, 1, 8, 0, 0]]
[[-1, 19, -1, 1, 13, 0, 23, 0, 0, 0, 32, 0, 1, 0, 0, 10, 1, 0, 0, 0, 0, 0, 0, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 2, 2: 0, 0: 10}
New Contingency Matrix: 
[[32  0  0 19  1 13  0 23  0  0  0  0  1  0  0 10  1  0  0  0  0  0  0  0]
 [ 0 36  0  1  0  2  0 10  5  0  0  0 28  0  0  6  0  0  0  0  0  0  1  1]
 [ 0  0 34  0  0  0  1  0  0 10  1 21  0  2  5  0  0 14 12  1  1  8  0  0]]
New Clustered Label Sequence: [10, 2, 0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
Diagonal_Elements: [32, 36, 34], Sum: 102
All_Elements: [32, 0, 0, 19, 1, 13, 0, 23, 0, 0, 0, 0, 1, 0, 0, 10, 1, 0, 0, 0, 0, 0, 0, 0, 0, 36, 0, 1, 0, 2, 0, 10, 5, 0, 0, 0, 28, 0, 0, 6, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 34, 0, 0, 0, 1, 0, 0, 10, 1, 21, 0, 2, 5, 0, 0, 14, 12, 1, 1, 8, 0, 0], Sum: 300
Accuracy: 0.34
