Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_4_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_4_opt_temp_noisy/C_Difficult1_noise010.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-13_39_55
Punishment_Coefficient: 0.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000016564262748>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.20533564314246178
Online_Training [2/700]: mean_loss=0.26729371026158333
Online_Training [3/700]: mean_loss=0.21582980826497078
Online_Training [4/700]: mean_loss=0.1391459722071886
Online_Training [5/700]: mean_loss=0.10455501358956099
Online_Training [6/700]: mean_loss=0.09426395036280155
Online_Training [7/700]: mean_loss=0.11695495247840881
Online_Training [8/700]: mean_loss=0.14821366034448147
Online_Training [9/700]: mean_loss=0.09760813880711794
Online_Training [10/700]: mean_loss=0.05576801020652056
Online_Training [11/700]: mean_loss=0.04922409076243639
Online_Training [12/700]: mean_loss=0.04597739037126303
Online_Training [13/700]: mean_loss=0.06726138899102807
Online_Training [14/700]: mean_loss=0.04100631223991513
Online_Training [15/700]: mean_loss=0.019742262782528996
Online_Training [16/700]: mean_loss=0.02730305609293282
Online_Training [17/700]: mean_loss=0.029547221725806594
Online_Training [18/700]: mean_loss=0.03293125471100211
Online_Training [19/700]: mean_loss=0.1178695559501648
Online_Training [20/700]: mean_loss=0.04109598509967327
Online_Training [21/700]: mean_loss=0.017440151423215866
Online_Training [22/700]: mean_loss=0.043977562338113785
Online_Training [23/700]: mean_loss=0.02431846084073186
Online_Training [24/700]: mean_loss=0.012887434451840818
Online_Training [25/700]: mean_loss=0.032598117366433144
Online_Training [26/700]: mean_loss=0.03930354118347168
Online_Training [27/700]: mean_loss=0.0690967496484518
Online_Training [28/700]: mean_loss=0.027993010124191642
Online_Training [29/700]: mean_loss=0.014782075071707368
Online_Training [30/700]: mean_loss=0.017875588266178966
Online_Training [31/700]: mean_loss=0.015737181529402733
Online_Training [32/700]: mean_loss=0.0448038992471993
Online_Training [33/700]: mean_loss=0.025657531805336475
Online_Training [34/700]: mean_loss=0.0168192102573812
Online_Training [35/700]: mean_loss=0.02997708390466869
Online_Training [36/700]: mean_loss=0.026382951997220516
Online_Training [37/700]: mean_loss=0.005294308823067695
Online_Training [38/700]: mean_loss=0.0152793750166893
Online_Training [39/700]: mean_loss=0.021953927353024483
Online_Training [40/700]: mean_loss=0.010625084047205746
Online_Training [41/700]: mean_loss=0.030541897285729647
Online_Training [42/700]: mean_loss=0.05494431359693408
Online_Training [43/700]: mean_loss=0.042787233367562294
Online_Training [44/700]: mean_loss=0.009289288544096053
Online_Training [45/700]: mean_loss=0.01828327646944672
Online_Training [46/700]: mean_loss=0.008470419677905738
Online_Training [47/700]: mean_loss=0.02537340810522437
Online_Training [48/700]: mean_loss=0.03506775153800845
Online_Training [49/700]: mean_loss=0.015200909227132797
Online_Training [50/700]: mean_loss=0.005605338898021728
Online_Training [51/700]: mean_loss=0.010888767428696156
Online_Training [52/700]: mean_loss=0.024564052699133754
Online_Training [53/700]: mean_loss=0.02939798543229699
Online_Training [54/700]: mean_loss=0.017272420693188906
Online_Training [55/700]: mean_loss=0.01893377467058599
Online_Training [56/700]: mean_loss=0.01645084237679839
Online_Training [57/700]: mean_loss=0.011201694491319358
Online_Training [58/700]: mean_loss=0.023112619994208217
Online_Training [59/700]: mean_loss=0.13549305871129036
Online_Training [60/700]: mean_loss=0.030636195559054613
Online_Training [61/700]: mean_loss=0.0522825107909739
Online_Training [62/700]: mean_loss=0.0067361348774284124
Online_Training [63/700]: mean_loss=0.017613466596230865
Online_Training [64/700]: mean_loss=0.016388772637583315
Online_Training [65/700]: mean_loss=0.026849578833207488
Online_Training [66/700]: mean_loss=0.05981601355597377
Online_Training [67/700]: mean_loss=0.0139146214351058
Online_Training [68/700]: mean_loss=0.03523467993363738
Online_Training [69/700]: mean_loss=0.020721305394545197
Online_Training [70/700]: mean_loss=0.014063811860978603
Online_Training [71/700]: mean_loss=0.01405773707665503
Online_Training [72/700]: mean_loss=0.033515280578285456
Online_Training [73/700]: mean_loss=0.01700748095754534
Online_Training [74/700]: mean_loss=0.0237111106980592
Online_Training [75/700]: mean_loss=0.017203791649080813
Online_Training [76/700]: mean_loss=0.02763976319693029
Online_Training [77/700]: mean_loss=0.03675140277482569
Online_Training [78/700]: mean_loss=0.009990701684728265
Online_Training [79/700]: mean_loss=0.0038392216083593667
Online_Training [80/700]: mean_loss=0.018791145412251353
Online_Training [81/700]: mean_loss=0.024273649556562304
Online_Training [82/700]: mean_loss=0.0374619853682816
Online_Training [83/700]: mean_loss=0.007880792254582047
Online_Training [84/700]: mean_loss=0.01898891618475318
Online_Training [85/700]: mean_loss=0.02084829774685204
Online_Training [86/700]: mean_loss=0.07256190292537212
Online_Training [87/700]: mean_loss=0.04684145422652364
Online_Training [88/700]: mean_loss=0.017954389797523618
Online_Training [89/700]: mean_loss=0.020449807634577155
Online_Training [90/700]: mean_loss=0.03792232181876898
Online_Training [91/700]: mean_loss=0.012305156094953418
Online_Training [92/700]: mean_loss=0.006740475946571678
Online_Training [93/700]: mean_loss=0.01707141159567982
Online_Training [94/700]: mean_loss=0.015858599916100502
Online_Training [95/700]: mean_loss=0.016034017549827695
Online_Training [96/700]: mean_loss=0.010718075092881918
Online_Training [97/700]: mean_loss=0.015115856775082648
Online_Training [98/700]: mean_loss=0.008164071128703654
Online_Training [99/700]: mean_loss=0.013302903971634805
Online_Training [100/700]: mean_loss=0.010045232600532472
Online_Training [101/700]: mean_loss=0.014879799447953701
Online_Training [102/700]: mean_loss=0.00897652271669358
Online_Training [103/700]: mean_loss=0.035322850570082664
Online_Training [104/700]: mean_loss=0.007538947043940425
Online_Training [105/700]: mean_loss=0.0126132300356403
Online_Training [106/700]: mean_loss=0.01090760831721127
Online_Training [107/700]: mean_loss=0.02752226614393294
Online_Training [108/700]: mean_loss=0.009444075054489076
Online_Training [109/700]: mean_loss=0.014921404188498855
Online_Training [110/700]: mean_loss=0.020808920031413436
Online_Training [111/700]: mean_loss=0.007862472266424447
Online_Training [112/700]: mean_loss=0.012446803040802479
Online_Training [113/700]: mean_loss=0.019971384666860104
Online_Training [114/700]: mean_loss=0.01016737858299166
Online_Training [115/700]: mean_loss=0.010543813114054501
Online_Training [116/700]: mean_loss=0.016336572007276118
Online_Training [117/700]: mean_loss=0.004767563135828823
Online_Training [118/700]: mean_loss=0.013218217762187123
Online_Training [119/700]: mean_loss=0.00887456291820854
Online_Training [120/700]: mean_loss=0.008403348794672638
Online_Training [121/700]: mean_loss=0.03815168468281627
Online_Training [122/700]: mean_loss=0.016849426086992025
Online_Training [123/700]: mean_loss=0.014558357186615467
Online_Training [124/700]: mean_loss=0.004486009303946048
Online_Training [125/700]: mean_loss=0.0167115090880543
Online_Training [126/700]: mean_loss=0.02787734498269856
Online_Training [127/700]: mean_loss=0.008662979875225574
Online_Training [128/700]: mean_loss=0.09856515936553478
Online_Training [129/700]: mean_loss=0.08125816285610199
Online_Training [130/700]: mean_loss=0.01621775992680341
Online_Training [131/700]: mean_loss=0.02738891984336078
Online_Training [132/700]: mean_loss=0.04314719466492534
Online_Training [133/700]: mean_loss=0.022078315960243344
Online_Training [134/700]: mean_loss=0.014242012868635356
Online_Training [135/700]: mean_loss=0.013924249331466854
Online_Training [136/700]: mean_loss=0.0029363303328864276
Online_Training [137/700]: mean_loss=0.015540544642135501
Online_Training [138/700]: mean_loss=0.014481129124760628
Online_Training [139/700]: mean_loss=0.013585833716206253
Online_Training [140/700]: mean_loss=0.12975298147648573
Online_Training [141/700]: mean_loss=0.02973700105212629
Online_Training [142/700]: mean_loss=0.035727453883737326
Online_Training [143/700]: mean_loss=0.012065640999935567
Online_Training [144/700]: mean_loss=0.0074296745005995035
Online_Training [145/700]: mean_loss=0.02231326582841575
Online_Training [146/700]: mean_loss=0.014204854378476739
Online_Training [147/700]: mean_loss=0.0756743922829628
Online_Training [148/700]: mean_loss=0.04760744562372565
Online_Training [149/700]: mean_loss=0.013685130863450468
Online_Training [150/700]: mean_loss=0.03040668019093573
Online_Training [151/700]: mean_loss=0.017369050532579422
Online_Training [152/700]: mean_loss=0.019009334966540337
Online_Training [153/700]: mean_loss=0.009348827064968646
Online_Training [154/700]: mean_loss=0.005636392568703741
Online_Training [155/700]: mean_loss=0.012563584139570594
Online_Training [156/700]: mean_loss=0.024330003652721643
Online_Training [157/700]: mean_loss=0.019525391282513738
Online_Training [158/700]: mean_loss=0.01672817801591009
Online_Training [159/700]: mean_loss=0.02783449087291956
Online_Training [160/700]: mean_loss=0.006625553243793547
Online_Training [161/700]: mean_loss=0.010631703888066113
Online_Training [162/700]: mean_loss=0.011674418346956372
Online_Training [163/700]: mean_loss=0.009270950802601874
Online_Training [164/700]: mean_loss=0.012153482297435403
Online_Training [165/700]: mean_loss=0.009141063666902483
Online_Training [166/700]: mean_loss=0.015907245688140392
Online_Training [167/700]: mean_loss=0.008754244132433087
Online_Training [168/700]: mean_loss=0.0091515495441854
Online_Training [169/700]: mean_loss=0.009226257679983974
Online_Training [170/700]: mean_loss=0.01838994980789721
Online_Training [171/700]: mean_loss=0.04602578794583678
Online_Training [172/700]: mean_loss=0.016870777355507016
Online_Training [173/700]: mean_loss=0.004723826714325696
Online_Training [174/700]: mean_loss=0.0038004681118763983
Online_Training [175/700]: mean_loss=0.02095285290852189
Online_Training [176/700]: mean_loss=0.007904116180725396
Online_Training [177/700]: mean_loss=0.029734866693615913
Online_Training [178/700]: mean_loss=0.016557467868551612
Online_Training [179/700]: mean_loss=0.07880077883601189
Online_Training [180/700]: mean_loss=0.0586773338727653
Online_Training [181/700]: mean_loss=0.02284631715156138
Online_Training [182/700]: mean_loss=0.014306275639683008
Online_Training [183/700]: mean_loss=0.009754848899319768
Online_Training [184/700]: mean_loss=0.013269739458337426
Online_Training [185/700]: mean_loss=0.013001108076423407
Online_Training [186/700]: mean_loss=0.014704049215652049
Online_Training [187/700]: mean_loss=0.020060548093169928
Online_Training [188/700]: mean_loss=0.011841167695820332
Online_Training [189/700]: mean_loss=0.011180007713846862
Online_Training [190/700]: mean_loss=0.009137092099990696
Online_Training [191/700]: mean_loss=0.007456462015397847
Online_Training [192/700]: mean_loss=0.01088104525115341
Online_Training [193/700]: mean_loss=0.0083257716614753
Online_Training [194/700]: mean_loss=0.016929239383898675
Online_Training [195/700]: mean_loss=0.005689709156285971
Online_Training [196/700]: mean_loss=0.006920102052390575
Online_Training [197/700]: mean_loss=0.004689652501838282
Online_Training [198/700]: mean_loss=0.00912880280520767
Online_Training [199/700]: mean_loss=0.004494485561735928
Online_Training [200/700]: mean_loss=0.020342963049188256
Online_Training [201/700]: mean_loss=0.0037499235768336803
Online_Training [202/700]: mean_loss=0.11166900396347046
Online_Training [203/700]: mean_loss=0.02296706777997315
Online_Training [204/700]: mean_loss=0.0156945688650012
Online_Training [205/700]: mean_loss=0.012798005947843194
Online_Training [206/700]: mean_loss=0.010747187188826501
Online_Training [207/700]: mean_loss=0.006271799968089908
Online_Training [208/700]: mean_loss=0.030758411856368184
Online_Training [209/700]: mean_loss=0.010976325487717986
Online_Training [210/700]: mean_loss=0.011902866652235389
Online_Training [211/700]: mean_loss=0.02669704076834023
Online_Training [212/700]: mean_loss=0.009051107801496983
Online_Training [213/700]: mean_loss=0.014407909358851612
Online_Training [214/700]: mean_loss=0.0063315958250314
Online_Training [215/700]: mean_loss=0.024687133729457855
Online_Training [216/700]: mean_loss=0.03083335398696363
Online_Training [217/700]: mean_loss=0.012253573164343834
Online_Training [218/700]: mean_loss=0.007641805044841021
Online_Training [219/700]: mean_loss=0.015230780700221658
Online_Training [220/700]: mean_loss=0.01679448375944048
Online_Training [221/700]: mean_loss=0.00890019815415144
Online_Training [222/700]: mean_loss=0.012661628308705986
Online_Training [223/700]: mean_loss=0.01827041758224368
Online_Training [224/700]: mean_loss=0.007147221069317311
Online_Training [225/700]: mean_loss=0.003696941421367228
Online_Training [226/700]: mean_loss=0.020481393206864595
Online_Training [227/700]: mean_loss=0.018879644805565476
Online_Training [228/700]: mean_loss=0.003685687348479405
Online_Training [229/700]: mean_loss=0.013535088044591248
Online_Training [230/700]: mean_loss=0.012197356787510216
Online_Training [231/700]: mean_loss=0.027167645283043385
Online_Training [232/700]: mean_loss=0.006526298995595425
Online_Training [233/700]: mean_loss=0.004726430197479203
Online_Training [234/700]: mean_loss=0.07183210738003254
Online_Training [235/700]: mean_loss=0.09668983332812786
Online_Training [236/700]: mean_loss=0.011712979292497039
Online_Training [237/700]: mean_loss=0.021140944212675095
Online_Training [238/700]: mean_loss=0.00840988993877545
Online_Training [239/700]: mean_loss=0.015079651959240437
Online_Training [240/700]: mean_loss=0.012467712978832424
Online_Training [241/700]: mean_loss=0.02003659470938146
Online_Training [242/700]: mean_loss=0.009143962990492582
Online_Training [243/700]: mean_loss=0.0173183890292421
Online_Training [244/700]: mean_loss=0.009275540360249579
Online_Training [245/700]: mean_loss=0.02087549795396626
Online_Training [246/700]: mean_loss=0.013967271661385894
Online_Training [247/700]: mean_loss=0.016765178414061666
Online_Training [248/700]: mean_loss=0.01530116971116513
Online_Training [249/700]: mean_loss=0.021536836866289377
Online_Training [250/700]: mean_loss=0.011890606838278472
Online_Training [251/700]: mean_loss=0.00883675494696945
Online_Training [252/700]: mean_loss=0.02075736061669886
Online_Training [253/700]: mean_loss=0.014189606299623847
Online_Training [254/700]: mean_loss=0.0036689549451693892
Online_Training [255/700]: mean_loss=0.007496262202039361
Online_Training [256/700]: mean_loss=0.019336681347340345
Online_Training [257/700]: mean_loss=0.007509483955800533
Online_Training [258/700]: mean_loss=0.010012730257585645
Online_Training [259/700]: mean_loss=0.006815313070546836
Online_Training [260/700]: mean_loss=0.008262241433840245
Online_Training [261/700]: mean_loss=0.009909601765684783
Online_Training [262/700]: mean_loss=0.013843508320860565
Online_Training [263/700]: mean_loss=0.007709489087574184
Online_Training [264/700]: mean_loss=0.00462495259125717
Online_Training [265/700]: mean_loss=0.10925675835460424
Online_Training [266/700]: mean_loss=0.0900502260774374
Online_Training [267/700]: mean_loss=0.010616513667628169
Online_Training [268/700]: mean_loss=0.02147183008491993
Online_Training [269/700]: mean_loss=0.02137208334170282
Online_Training [270/700]: mean_loss=0.1040850905701518
Online_Training [271/700]: mean_loss=0.03552776062861085
Online_Training [272/700]: mean_loss=0.013825280009768903
Online_Training [273/700]: mean_loss=0.02308784518390894
Online_Training [274/700]: mean_loss=0.015685321181081235
Online_Training [275/700]: mean_loss=0.02041136077605188
Online_Training [276/700]: mean_loss=0.01421551697421819
Online_Training [277/700]: mean_loss=0.008467054227367043
Online_Training [278/700]: mean_loss=0.006220808543730527
Online_Training [279/700]: mean_loss=0.009988368954509497
Online_Training [280/700]: mean_loss=0.010501995217055082
Online_Training [281/700]: mean_loss=0.009170237695798278
Online_Training [282/700]: mean_loss=0.016935947351157665
Online_Training [283/700]: mean_loss=0.020115690655075014
Online_Training [284/700]: mean_loss=0.009146333439275622
Online_Training [285/700]: mean_loss=0.03981070872396231
Online_Training [286/700]: mean_loss=0.00863766169641167
Online_Training [287/700]: mean_loss=0.008749406319111586
Online_Training [288/700]: mean_loss=0.017443462507799268
Online_Training [289/700]: mean_loss=0.005495798890478909
Online_Training [290/700]: mean_loss=0.005440001783426851
Online_Training [291/700]: mean_loss=0.014745642663910985
Online_Training [292/700]: mean_loss=0.008393415773753077
Online_Training [293/700]: mean_loss=0.10664157569408417
Online_Training [294/700]: mean_loss=0.03525902749970555
Online_Training [295/700]: mean_loss=0.009541621548123658
Online_Training [296/700]: mean_loss=0.015752956038340926
Online_Training [297/700]: mean_loss=0.013845424517057836
Online_Training [298/700]: mean_loss=0.006410791189409792
Online_Training [299/700]: mean_loss=0.010924513451755047
Online_Training [300/700]: mean_loss=0.01139382750261575
Online_Training [301/700]: mean_loss=0.01604472892358899
Online_Training [302/700]: mean_loss=0.011285605956800282
Online_Training [303/700]: mean_loss=0.024957235902547836
Online_Training [304/700]: mean_loss=0.003645447868620977
Online_Training [305/700]: mean_loss=0.02127529983408749
Online_Training [306/700]: mean_loss=0.011647783103398979
Online_Training [307/700]: mean_loss=0.023198475828394294
Online_Training [308/700]: mean_loss=0.0071854087873362005
Online_Training [309/700]: mean_loss=0.01925366767682135
Online_Training [310/700]: mean_loss=0.01807014038786292
Online_Training [311/700]: mean_loss=0.01365436299238354
Online_Training [312/700]: mean_loss=0.15123452804982662
Online_Training [313/700]: mean_loss=0.057577339466661215
Online_Training [314/700]: mean_loss=0.029733687406405807
Online_Training [315/700]: mean_loss=0.019818467553704977
Online_Training [316/700]: mean_loss=0.01557571825105697
Online_Training [317/700]: mean_loss=0.03378341835923493
Online_Training [318/700]: mean_loss=0.007124319672584534
Online_Training [319/700]: mean_loss=0.01008511078543961
Online_Training [320/700]: mean_loss=0.013090749620459974
Online_Training [321/700]: mean_loss=0.005251350114122033
Online_Training [322/700]: mean_loss=0.014468007837422192
Online_Training [323/700]: mean_loss=0.020720838103443384
Online_Training [324/700]: mean_loss=0.011534441611729562
Online_Training [325/700]: mean_loss=0.06437307270243764
Online_Training [326/700]: mean_loss=0.02782690478488803
Online_Training [327/700]: mean_loss=0.03797551291063428
Online_Training [328/700]: mean_loss=0.011610070476308465
Online_Training [329/700]: mean_loss=0.07428665552288294
Online_Training [330/700]: mean_loss=0.05823113303631544
Online_Training [331/700]: mean_loss=0.0399472750723362
Online_Training [332/700]: mean_loss=0.016345894429832697
Online_Training [333/700]: mean_loss=0.009646827122196555
Online_Training [334/700]: mean_loss=0.003696490341098979
Online_Training [335/700]: mean_loss=0.014475079951807857
Online_Training [336/700]: mean_loss=0.006679367681499571
Online_Training [337/700]: mean_loss=0.00823211926035583
Online_Training [338/700]: mean_loss=0.017124785343185067
Online_Training [339/700]: mean_loss=0.024513251380994916
Online_Training [340/700]: mean_loss=0.016225099214352667
Online_Training [341/700]: mean_loss=0.013572961208410561
Online_Training [342/700]: mean_loss=0.013466855161823332
Online_Training [343/700]: mean_loss=0.01410925795789808
Online_Training [344/700]: mean_loss=0.013707303325645626
Online_Training [345/700]: mean_loss=0.009323781938292086
Online_Training [346/700]: mean_loss=0.005477271042764187
Online_Training [347/700]: mean_loss=0.024492062162607908
Online_Training [348/700]: mean_loss=0.0027893484802916646
Online_Training [349/700]: mean_loss=0.020401433808729053
Online_Training [350/700]: mean_loss=0.11492323316633701
Online_Training [351/700]: mean_loss=0.022886274848133326
Online_Training [352/700]: mean_loss=0.017226328956894577
Online_Training [353/700]: mean_loss=0.03186343377456069
Online_Training [354/700]: mean_loss=0.012108595110476017
Online_Training [355/700]: mean_loss=0.01360307540744543
Online_Training [356/700]: mean_loss=0.01844106148928404
Online_Training [357/700]: mean_loss=0.019800083246082067
Online_Training [358/700]: mean_loss=0.00729950366076082
Online_Training [359/700]: mean_loss=0.006993271759711206
Online_Training [360/700]: mean_loss=0.012802628451026976
Online_Training [361/700]: mean_loss=0.007528047077357769
Online_Training [362/700]: mean_loss=0.09952495340257883
Online_Training [363/700]: mean_loss=0.10865263920277357
Online_Training [364/700]: mean_loss=0.01647809089627117
Online_Training [365/700]: mean_loss=0.014960908680222929
Online_Training [366/700]: mean_loss=0.015212693717330694
Online_Training [367/700]: mean_loss=0.020703771384432912
Online_Training [368/700]: mean_loss=0.020442864391952753
Online_Training [369/700]: mean_loss=0.007532809861004353
Online_Training [370/700]: mean_loss=0.006217377143912017
Online_Training [371/700]: mean_loss=0.01257083925884217
Online_Training [372/700]: mean_loss=0.010419453145004809
Online_Training [373/700]: mean_loss=0.015293973381631076
Online_Training [374/700]: mean_loss=0.007021542405709624
Online_Training [375/700]: mean_loss=0.009185764589346945
Online_Training [376/700]: mean_loss=0.003240458929212764
Online_Training [377/700]: mean_loss=0.015652253641746938
Online_Training [378/700]: mean_loss=0.011584671214222908
Online_Training [379/700]: mean_loss=0.08856263570487499
Online_Training [380/700]: mean_loss=0.02029051212593913
Online_Training [381/700]: mean_loss=0.019408639054745436
Online_Training [382/700]: mean_loss=0.01361499389167875
Online_Training [383/700]: mean_loss=0.08867660397663713
Online_Training [384/700]: mean_loss=0.0371966150123626
Online_Training [385/700]: mean_loss=0.032994074281305075
Online_Training [386/700]: mean_loss=0.015735550434328616
Online_Training [387/700]: mean_loss=0.012483868165872991
Online_Training [388/700]: mean_loss=0.019549365155398846
Online_Training [389/700]: mean_loss=0.008214190835133195
Online_Training [390/700]: mean_loss=0.10249729920178652
Online_Training [391/700]: mean_loss=0.016003232449293137
Online_Training [392/700]: mean_loss=0.010331037687137723
Online_Training [393/700]: mean_loss=0.010020039277151227
Online_Training [394/700]: mean_loss=0.0055881412117742
Online_Training [395/700]: mean_loss=0.01250675437040627
Online_Training [396/700]: mean_loss=0.017061482183635235
Online_Training [397/700]: mean_loss=0.0017301848420174792
Online_Training [398/700]: mean_loss=0.01899297838099301
Online_Training [399/700]: mean_loss=0.011155463522300124
Online_Training [400/700]: mean_loss=0.027742346050217748
Online_Training [401/700]: mean_loss=0.018483667401596904
Online_Training [402/700]: mean_loss=0.01094391429796815
Online_Training [403/700]: mean_loss=0.01146839838474989
Online_Training [404/700]: mean_loss=0.005849068285897374
Online_Training [405/700]: mean_loss=0.012502727680839598
Online_Training [406/700]: mean_loss=0.008302539528813213
Online_Training [407/700]: mean_loss=0.010380745632573962
Online_Training [408/700]: mean_loss=0.009448921424336731
Online_Training [409/700]: mean_loss=0.008760143828112632
Online_Training [410/700]: mean_loss=0.0130389838013798
Online_Training [411/700]: mean_loss=0.00836420658743009
Online_Training [412/700]: mean_loss=0.015190062462352216
Online_Training [413/700]: mean_loss=0.006244106218218803
Online_Training [414/700]: mean_loss=0.007653230102732778
Online_Training [415/700]: mean_loss=0.008823231386486441
Online_Training [416/700]: mean_loss=0.011344416183419526
Online_Training [417/700]: mean_loss=0.01582879468332976
Online_Training [418/700]: mean_loss=0.008109189104288816
Online_Training [419/700]: mean_loss=0.015690146712586284
Online_Training [420/700]: mean_loss=0.010558478301391006
Online_Training [421/700]: mean_loss=0.015546953422017395
Online_Training [422/700]: mean_loss=0.021812815219163895
Online_Training [423/700]: mean_loss=0.008071672637015581
Online_Training [424/700]: mean_loss=0.0091669064713642
Online_Training [425/700]: mean_loss=0.013063410529866815
Online_Training [426/700]: mean_loss=0.01262111181858927
Online_Training [427/700]: mean_loss=0.019244066206738353
Online_Training [428/700]: mean_loss=0.006911925855092704
Online_Training [429/700]: mean_loss=0.014481935882940888
Online_Training [430/700]: mean_loss=0.01644739182665944
Online_Training [431/700]: mean_loss=0.004696728428825736
Online_Training [432/700]: mean_loss=0.009872931521385908
Online_Training [433/700]: mean_loss=0.007920058560557663
Online_Training [434/700]: mean_loss=0.011364129954017699
Online_Training [435/700]: mean_loss=0.00990646448917687
Online_Training [436/700]: mean_loss=0.008657740196213126
Online_Training [437/700]: mean_loss=0.007799731858540326
Online_Training [438/700]: mean_loss=0.003029788378626108
Online_Training [439/700]: mean_loss=0.01151190570089966
Online_Training [440/700]: mean_loss=0.02254346921108663
Online_Training [441/700]: mean_loss=0.01840197341516614
Online_Training [442/700]: mean_loss=0.009611377958208323
Online_Training [443/700]: mean_loss=0.07023974228650331
Online_Training [444/700]: mean_loss=0.030709264567121863
Online_Training [445/700]: mean_loss=0.015360263641923666
Online_Training [446/700]: mean_loss=0.005516820354387164
Online_Training [447/700]: mean_loss=0.0076263301889412105
Online_Training [448/700]: mean_loss=0.015605128137394786
Online_Training [449/700]: mean_loss=0.014127440401352942
Online_Training [450/700]: mean_loss=0.011082562035880983
Online_Training [451/700]: mean_loss=0.008084985078312457
Online_Training [452/700]: mean_loss=0.031587440287694335
Online_Training [453/700]: mean_loss=0.006822443101555109
Online_Training [454/700]: mean_loss=0.0035809572436846793
Online_Training [455/700]: mean_loss=0.014186792192049325
Online_Training [456/700]: mean_loss=0.00918097817339003
Online_Training [457/700]: mean_loss=0.01121342706028372
Online_Training [458/700]: mean_loss=0.01300061889924109
Online_Training [459/700]: mean_loss=0.00435015419498086
Online_Training [460/700]: mean_loss=0.004464993457077071
Online_Training [461/700]: mean_loss=0.008311639248859137
Online_Training [462/700]: mean_loss=0.004903366439975798
Online_Training [463/700]: mean_loss=0.014599670772440732
Online_Training [464/700]: mean_loss=0.016715594800189137
Online_Training [465/700]: mean_loss=0.013241297798231244
Online_Training [466/700]: mean_loss=0.007283843122422695
Online_Training [467/700]: mean_loss=0.006112433562520891
Online_Training [468/700]: mean_loss=0.01122784405015409
Online_Training [469/700]: mean_loss=0.007905633246991783
Online_Training [470/700]: mean_loss=0.01868147077038884
Online_Training [471/700]: mean_loss=0.02104582660831511
Online_Training [472/700]: mean_loss=0.02394837629981339
Online_Training [473/700]: mean_loss=0.01464565726928413
Online_Training [474/700]: mean_loss=0.015509390272200108
Online_Training [475/700]: mean_loss=0.00387463768129237
Online_Training [476/700]: mean_loss=0.009914079564623535
Online_Training [477/700]: mean_loss=0.023790688021108508
Online_Training [478/700]: mean_loss=0.014488901942968369
Online_Training [479/700]: mean_loss=0.004150114313233644
Online_Training [480/700]: mean_loss=0.005346045480109751
Online_Training [481/700]: mean_loss=0.009972528088837862
Online_Training [482/700]: mean_loss=0.01169590896461159
Online_Training [483/700]: mean_loss=0.016620381153188646
Online_Training [484/700]: mean_loss=0.02586742676794529
Online_Training [485/700]: mean_loss=0.014243302401155233
Online_Training [486/700]: mean_loss=0.012030807207338512
Online_Training [487/700]: mean_loss=0.009647049591876566
Online_Training [488/700]: mean_loss=0.018181956140324473
Online_Training [489/700]: mean_loss=0.016499242512509227
Online_Training [490/700]: mean_loss=0.05952328909188509
Online_Training [491/700]: mean_loss=0.1329837702214718
Online_Training [492/700]: mean_loss=0.012955557904206216
Online_Training [493/700]: mean_loss=0.01100865297485143
Online_Training [494/700]: mean_loss=0.009994938503950834
Online_Training [495/700]: mean_loss=0.009293103474192321
Online_Training [496/700]: mean_loss=0.006612606754060835
Online_Training [497/700]: mean_loss=0.017270298441872
Online_Training [498/700]: mean_loss=0.009203858557157218
Online_Training [499/700]: mean_loss=0.015242411871440709
Online_Training [500/700]: mean_loss=0.006699125631712377
Online_Training [501/700]: mean_loss=0.01677958050277084
Online_Training [502/700]: mean_loss=0.029652234399691224
Online_Training [503/700]: mean_loss=0.011393903521820903
Online_Training [504/700]: mean_loss=0.007074689259752631
Online_Training [505/700]: mean_loss=0.009373761247843504
Online_Training [506/700]: mean_loss=0.014631199068389833
Online_Training [507/700]: mean_loss=0.011957331211306155
Online_Training [508/700]: mean_loss=0.05915856780484319
Online_Training [509/700]: mean_loss=0.028062067460268736
Online_Training [510/700]: mean_loss=0.012936313287355006
Online_Training [511/700]: mean_loss=0.008313635480590165
Online_Training [512/700]: mean_loss=0.008022634079679847
Online_Training [513/700]: mean_loss=0.011795034515671432
Online_Training [514/700]: mean_loss=0.006680218793917447
Online_Training [515/700]: mean_loss=0.01307508791796863
Online_Training [516/700]: mean_loss=0.0188879098277539
Online_Training [517/700]: mean_loss=0.005092894454719499
Online_Training [518/700]: mean_loss=0.005552555259782821
Online_Training [519/700]: mean_loss=0.01688259281218052
Online_Training [520/700]: mean_loss=0.009563297498971224
Online_Training [521/700]: mean_loss=0.007022343808785081
Online_Training [522/700]: mean_loss=0.014876994770020247
Online_Training [523/700]: mean_loss=0.009066930157132447
Online_Training [524/700]: mean_loss=0.00273822175222449
Online_Training [525/700]: mean_loss=0.011391405947506428
Online_Training [526/700]: mean_loss=0.011661635478958488
Online_Training [527/700]: mean_loss=0.008240938419476151
Online_Training [528/700]: mean_loss=0.005345260608009994
Online_Training [529/700]: mean_loss=0.006965602689888328
Online_Training [530/700]: mean_loss=0.012355110025964677
Online_Training [531/700]: mean_loss=0.007044361729640514
Online_Training [532/700]: mean_loss=0.012357681873254478
Online_Training [533/700]: mean_loss=0.0036252909631002694
Online_Training [534/700]: mean_loss=0.004889744392130524
Online_Training [535/700]: mean_loss=0.017265543108806014
Online_Training [536/700]: mean_loss=0.007923675642814487
Online_Training [537/700]: mean_loss=0.012677905382588506
Online_Training [538/700]: mean_loss=0.011620659031905234
Online_Training [539/700]: mean_loss=0.007569945475552231
Online_Training [540/700]: mean_loss=0.011292414157651365
Online_Training [541/700]: mean_loss=0.012538624461740255
Online_Training [542/700]: mean_loss=0.00890435348264873
Online_Training [543/700]: mean_loss=0.01563108793925494
Online_Training [544/700]: mean_loss=0.01660478999838233
Online_Training [545/700]: mean_loss=0.07718575093895197
Online_Training [546/700]: mean_loss=0.09360906947404146
Online_Training [547/700]: mean_loss=0.011200192966498435
Online_Training [548/700]: mean_loss=0.1449616178870201
Online_Training [549/700]: mean_loss=0.08283769432455301
Online_Training [550/700]: mean_loss=0.022519150050356984
Online_Training [551/700]: mean_loss=0.022740448359400034
Online_Training [552/700]: mean_loss=0.011634349008090794
Online_Training [553/700]: mean_loss=0.01937747187912464
Online_Training [554/700]: mean_loss=0.012666073394939303
Online_Training [555/700]: mean_loss=0.008735380019061267
Online_Training [556/700]: mean_loss=0.014919864945113659
Online_Training [557/700]: mean_loss=0.011766389245167375
Online_Training [558/700]: mean_loss=0.010548428283073008
Online_Training [559/700]: mean_loss=0.00619317521341145
Online_Training [560/700]: mean_loss=0.003831068373983726
Online_Training [561/700]: mean_loss=0.004773307708092034
Online_Training [562/700]: mean_loss=0.007935084751807153
Online_Training [563/700]: mean_loss=0.008510367129929364
Online_Training [564/700]: mean_loss=0.007521671010181308
Online_Training [565/700]: mean_loss=0.02679855958558619
Online_Training [566/700]: mean_loss=0.009529591538012028
Online_Training [567/700]: mean_loss=0.013121034717187285
Online_Training [568/700]: mean_loss=0.009119251277297735
Online_Training [569/700]: mean_loss=0.008744029211811721
Online_Training [570/700]: mean_loss=0.007556525175459683
Online_Training [571/700]: mean_loss=0.012698296457529068
Online_Training [572/700]: mean_loss=0.0061078371945768595
Online_Training [573/700]: mean_loss=0.004077830002643168
Online_Training [574/700]: mean_loss=0.006376115081366152
Online_Training [575/700]: mean_loss=0.009696138673461974
Online_Training [576/700]: mean_loss=0.0037127579853404313
Online_Training [577/700]: mean_loss=0.00861528841778636
Online_Training [578/700]: mean_loss=0.015756497508846223
Online_Training [579/700]: mean_loss=0.011820230749435723
Online_Training [580/700]: mean_loss=0.009676279383711517
Online_Training [581/700]: mean_loss=0.013856739969924092
Online_Training [582/700]: mean_loss=0.007154490565881133
Online_Training [583/700]: mean_loss=0.009894745773635805
Online_Training [584/700]: mean_loss=0.004263274691766128
Online_Training [585/700]: mean_loss=0.08685089275240898
Online_Training [586/700]: mean_loss=0.007764589041471481
Online_Training [587/700]: mean_loss=0.011065647937357426
Online_Training [588/700]: mean_loss=0.007693089311942458
Online_Training [589/700]: mean_loss=0.006351366580929607
Online_Training [590/700]: mean_loss=0.0180111862719059
Online_Training [591/700]: mean_loss=0.01057383487932384
Online_Training [592/700]: mean_loss=0.003937168599804863
Online_Training [593/700]: mean_loss=0.005012628389522433
Online_Training [594/700]: mean_loss=0.010495398426428437
Online_Training [595/700]: mean_loss=0.013888357440009713
Online_Training [596/700]: mean_loss=0.0023493418557336554
Online_Training [597/700]: mean_loss=0.010342955705709755
Online_Training [598/700]: mean_loss=0.005890341999474913
Online_Training [599/700]: mean_loss=0.015773823484778404
Online_Training [600/700]: mean_loss=0.012728382367640734
Online_Training [601/700]: mean_loss=0.005766172602307051
Online_Training [602/700]: mean_loss=0.005090642691357061
Online_Training [603/700]: mean_loss=0.005784614302683622
Online_Training [604/700]: mean_loss=0.0850344393402338
Online_Training [605/700]: mean_loss=0.017190445913001895
Online_Training [606/700]: mean_loss=0.029979401035234332
Online_Training [607/700]: mean_loss=0.02338678715750575
Online_Training [608/700]: mean_loss=0.0053985241102054715
Online_Training [609/700]: mean_loss=0.01735742692835629
Online_Training [610/700]: mean_loss=0.009429382509551942
Online_Training [611/700]: mean_loss=0.0042204509663861245
Online_Training [612/700]: mean_loss=0.008366244961507618
Online_Training [613/700]: mean_loss=0.010577581939287484
Online_Training [614/700]: mean_loss=0.023979855701327324
Online_Training [615/700]: mean_loss=0.010146531276404858
Online_Training [616/700]: mean_loss=0.0078813168220222
Online_Training [617/700]: mean_loss=0.009435129235498607
Online_Training [618/700]: mean_loss=0.010508273262530565
Online_Training [619/700]: mean_loss=0.00872174184769392
Online_Training [620/700]: mean_loss=0.009999851579777896
Online_Training [621/700]: mean_loss=0.005991234502289444
Online_Training [622/700]: mean_loss=0.00598588609136641
Online_Training [623/700]: mean_loss=0.013189547113142908
Online_Training [624/700]: mean_loss=0.009826118010096252
Online_Training [625/700]: mean_loss=0.005213722761254758
Online_Training [626/700]: mean_loss=0.008782315300777555
Online_Training [627/700]: mean_loss=0.1089351000264287
Online_Training [628/700]: mean_loss=0.02363918931223452
Online_Training [629/700]: mean_loss=0.005345724523067474
Online_Training [630/700]: mean_loss=0.009566217311657965
Online_Training [631/700]: mean_loss=0.016779589699581265
Online_Training [632/700]: mean_loss=0.02085322025232017
Online_Training [633/700]: mean_loss=0.007805845933035016
Online_Training [634/700]: mean_loss=0.016735147451981902
Online_Training [635/700]: mean_loss=0.011310188681818545
Online_Training [636/700]: mean_loss=0.015014322474598885
Online_Training [637/700]: mean_loss=0.011699629365466535
Online_Training [638/700]: mean_loss=0.010499704803805798
Online_Training [639/700]: mean_loss=0.006331346929073334
Online_Training [640/700]: mean_loss=0.02111778617836535
Online_Training [641/700]: mean_loss=0.016953994752839208
Online_Training [642/700]: mean_loss=0.008191389788407832
Online_Training [643/700]: mean_loss=0.0027296312619000673
Online_Training [644/700]: mean_loss=0.015459100832231343
Online_Training [645/700]: mean_loss=0.0027508132625371218
Online_Training [646/700]: mean_loss=0.005356546782422811
Online_Training [647/700]: mean_loss=0.004756306065246463
Online_Training [648/700]: mean_loss=0.005213378579355776
Online_Training [649/700]: mean_loss=0.004544386814814061
Online_Training [650/700]: mean_loss=0.018768008798360825
Online_Training [651/700]: mean_loss=0.0061724246479570866
Online_Training [652/700]: mean_loss=0.018813367700204253
Online_Training [653/700]: mean_loss=0.006686439737677574
Online_Training [654/700]: mean_loss=0.0026819751074071974
Online_Training [655/700]: mean_loss=0.011284366017207503
Online_Training [656/700]: mean_loss=0.008635680074803531
Online_Training [657/700]: mean_loss=0.033022894291207194
Online_Training [658/700]: mean_loss=0.014595793560147285
Online_Training [659/700]: mean_loss=0.0017131270142272115
Online_Training [660/700]: mean_loss=0.018269330728799105
Online_Training [661/700]: mean_loss=0.008871684374753386
Online_Training [662/700]: mean_loss=0.008289421792142093
Online_Training [663/700]: mean_loss=0.009974611573852599
Online_Training [664/700]: mean_loss=0.01115618390031159
Online_Training [665/700]: mean_loss=0.003921280964277685
Online_Training [666/700]: mean_loss=0.02162122749723494
Online_Training [667/700]: mean_loss=0.00505802157567814
Online_Training [668/700]: mean_loss=0.00886621349491179
Online_Training [669/700]: mean_loss=0.007522205007262528
Online_Training [670/700]: mean_loss=0.009415901848115027
Online_Training [671/700]: mean_loss=0.005784637527540326
Online_Training [672/700]: mean_loss=0.009302802965976298
Online_Training [673/700]: mean_loss=0.002469230385031551
Online_Training [674/700]: mean_loss=0.02148105506785214
Online_Training [675/700]: mean_loss=0.006491294130682945
Online_Training [676/700]: mean_loss=0.011679038521833718
Online_Training [677/700]: mean_loss=0.06035578437149525
Online_Training [678/700]: mean_loss=0.019519480876624584
Online_Training [679/700]: mean_loss=0.004703962069470435
Online_Training [680/700]: mean_loss=0.011697970796376467
Online_Training [681/700]: mean_loss=0.01079767884220928
Online_Training [682/700]: mean_loss=0.008354399527888745
Online_Training [683/700]: mean_loss=0.010891323327086866
Online_Training [684/700]: mean_loss=0.00475039443699643
Online_Training [685/700]: mean_loss=0.022520550759509206
Online_Training [686/700]: mean_loss=0.005345036508515477
Online_Training [687/700]: mean_loss=0.014166706358082592
Online_Training [688/700]: mean_loss=0.006153172813355923
Online_Training [689/700]: mean_loss=0.01801982056349516
Online_Training [690/700]: mean_loss=0.0059217181405983865
Online_Training [691/700]: mean_loss=0.025931129697710276
Online_Training [692/700]: mean_loss=0.005176141683477908
Online_Training [693/700]: mean_loss=0.011689683422446251
Online_Training [694/700]: mean_loss=0.01193186454474926
Online_Training [695/700]: mean_loss=0.02093145903199911
Online_Training [696/700]: mean_loss=0.10849135462194681
Online_Training [697/700]: mean_loss=0.09317078441381454
Online_Training [698/700]: mean_loss=0.011837468016892672
Online_Training [699/700]: mean_loss=0.008061239321250468
Online_Training [700/700]: mean_loss=0.005219960759859532
Q_Learning [1/300]: mean_loss=0.20533564314246178
Q_Learning [2/300]: mean_loss=0.26729371026158333
Q_Learning [3/300]: mean_loss=0.21582980826497078
Q_Learning [4/300]: mean_loss=0.1391459722071886
Q_Learning [5/300]: mean_loss=0.10455501358956099
Q_Learning [6/300]: mean_loss=0.09426395036280155
Q_Learning [7/300]: mean_loss=0.11695495247840881
Q_Learning [8/300]: mean_loss=0.14821366034448147
Q_Learning [9/300]: mean_loss=0.09760813880711794
Q_Learning [10/300]: mean_loss=0.05576801020652056
Q_Learning [11/300]: mean_loss=0.04922409076243639
Q_Learning [12/300]: mean_loss=0.04597739037126303
Q_Learning [13/300]: mean_loss=0.06726138899102807
Q_Learning [14/300]: mean_loss=0.04100631223991513
Q_Learning [15/300]: mean_loss=0.019742262782528996
Q_Learning [16/300]: mean_loss=0.02730305609293282
Q_Learning [17/300]: mean_loss=0.029547221725806594
Q_Learning [18/300]: mean_loss=0.03293125471100211
Q_Learning [19/300]: mean_loss=0.1178695559501648
Q_Learning [20/300]: mean_loss=0.04109598509967327
Q_Learning [21/300]: mean_loss=0.017440151423215866
Q_Learning [22/300]: mean_loss=0.043977562338113785
Q_Learning [23/300]: mean_loss=0.02431846084073186
Q_Learning [24/300]: mean_loss=0.012887434451840818
Q_Learning [25/300]: mean_loss=0.032598117366433144
Q_Learning [26/300]: mean_loss=0.03930354118347168
Q_Learning [27/300]: mean_loss=0.0690967496484518
Q_Learning [28/300]: mean_loss=0.027993010124191642
Q_Learning [29/300]: mean_loss=0.014782075071707368
Q_Learning [30/300]: mean_loss=0.017875588266178966
Q_Learning [31/300]: mean_loss=0.015737181529402733
Q_Learning [32/300]: mean_loss=0.0448038992471993
Q_Learning [33/300]: mean_loss=0.025657531805336475
Q_Learning [34/300]: mean_loss=0.0168192102573812
Q_Learning [35/300]: mean_loss=0.02997708390466869
Q_Learning [36/300]: mean_loss=0.026382951997220516
Q_Learning [37/300]: mean_loss=0.005294308823067695
Q_Learning [38/300]: mean_loss=0.0152793750166893
Q_Learning [39/300]: mean_loss=0.021953927353024483
Q_Learning [40/300]: mean_loss=0.010625084047205746
Q_Learning [41/300]: mean_loss=0.030541897285729647
Q_Learning [42/300]: mean_loss=0.05494431359693408
Q_Learning [43/300]: mean_loss=0.042787233367562294
Q_Learning [44/300]: mean_loss=0.009289288544096053
Q_Learning [45/300]: mean_loss=0.01828327646944672
Q_Learning [46/300]: mean_loss=0.008470419677905738
Q_Learning [47/300]: mean_loss=0.02537340810522437
Q_Learning [48/300]: mean_loss=0.03506775153800845
Q_Learning [49/300]: mean_loss=0.015200909227132797
Q_Learning [50/300]: mean_loss=0.005605338898021728
Q_Learning [51/300]: mean_loss=0.010888767428696156
Q_Learning [52/300]: mean_loss=0.024564052699133754
Q_Learning [53/300]: mean_loss=0.02939798543229699
Q_Learning [54/300]: mean_loss=0.017272420693188906
Q_Learning [55/300]: mean_loss=0.01893377467058599
Q_Learning [56/300]: mean_loss=0.01645084237679839
Q_Learning [57/300]: mean_loss=0.011201694491319358
Q_Learning [58/300]: mean_loss=0.023112619994208217
Q_Learning [59/300]: mean_loss=0.13549305871129036
Q_Learning [60/300]: mean_loss=0.030636195559054613
Q_Learning [61/300]: mean_loss=0.0522825107909739
Q_Learning [62/300]: mean_loss=0.0067361348774284124
Q_Learning [63/300]: mean_loss=0.017613466596230865
Q_Learning [64/300]: mean_loss=0.016388772637583315
Q_Learning [65/300]: mean_loss=0.026849578833207488
Q_Learning [66/300]: mean_loss=0.05981601355597377
Q_Learning [67/300]: mean_loss=0.0139146214351058
Q_Learning [68/300]: mean_loss=0.03523467993363738
Q_Learning [69/300]: mean_loss=0.020721305394545197
Q_Learning [70/300]: mean_loss=0.014063811860978603
Q_Learning [71/300]: mean_loss=0.01405773707665503
Q_Learning [72/300]: mean_loss=0.033515280578285456
Q_Learning [73/300]: mean_loss=0.01700748095754534
Q_Learning [74/300]: mean_loss=0.0237111106980592
Q_Learning [75/300]: mean_loss=0.017203791649080813
Q_Learning [76/300]: mean_loss=0.02763976319693029
Q_Learning [77/300]: mean_loss=0.03675140277482569
Q_Learning [78/300]: mean_loss=0.009990701684728265
Q_Learning [79/300]: mean_loss=0.0038392216083593667
Q_Learning [80/300]: mean_loss=0.018791145412251353
Q_Learning [81/300]: mean_loss=0.024273649556562304
Q_Learning [82/300]: mean_loss=0.0374619853682816
Q_Learning [83/300]: mean_loss=0.007880792254582047
Q_Learning [84/300]: mean_loss=0.01898891618475318
Q_Learning [85/300]: mean_loss=0.02084829774685204
Q_Learning [86/300]: mean_loss=0.07256190292537212
Q_Learning [87/300]: mean_loss=0.04684145422652364
Q_Learning [88/300]: mean_loss=0.017954389797523618
Q_Learning [89/300]: mean_loss=0.020449807634577155
Q_Learning [90/300]: mean_loss=0.03792232181876898
Q_Learning [91/300]: mean_loss=0.012305156094953418
Q_Learning [92/300]: mean_loss=0.006740475946571678
Q_Learning [93/300]: mean_loss=0.01707141159567982
Q_Learning [94/300]: mean_loss=0.015858599916100502
Q_Learning [95/300]: mean_loss=0.016034017549827695
Q_Learning [96/300]: mean_loss=0.010718075092881918
Q_Learning [97/300]: mean_loss=0.015115856775082648
Q_Learning [98/300]: mean_loss=0.008164071128703654
Q_Learning [99/300]: mean_loss=0.013302903971634805
Q_Learning [100/300]: mean_loss=0.010045232600532472
Q_Learning [101/300]: mean_loss=0.014879799447953701
Q_Learning [102/300]: mean_loss=0.00897652271669358
Q_Learning [103/300]: mean_loss=0.035322850570082664
Q_Learning [104/300]: mean_loss=0.007538947043940425
Q_Learning [105/300]: mean_loss=0.0126132300356403
Q_Learning [106/300]: mean_loss=0.01090760831721127
Q_Learning [107/300]: mean_loss=0.02752226614393294
Q_Learning [108/300]: mean_loss=0.009444075054489076
Q_Learning [109/300]: mean_loss=0.014921404188498855
Q_Learning [110/300]: mean_loss=0.020808920031413436
Q_Learning [111/300]: mean_loss=0.007862472266424447
Q_Learning [112/300]: mean_loss=0.012446803040802479
Q_Learning [113/300]: mean_loss=0.019971384666860104
Q_Learning [114/300]: mean_loss=0.01016737858299166
Q_Learning [115/300]: mean_loss=0.010543813114054501
Q_Learning [116/300]: mean_loss=0.016336572007276118
Q_Learning [117/300]: mean_loss=0.004767563135828823
Q_Learning [118/300]: mean_loss=0.013218217762187123
Q_Learning [119/300]: mean_loss=0.00887456291820854
Q_Learning [120/300]: mean_loss=0.008403348794672638
Q_Learning [121/300]: mean_loss=0.03815168468281627
Q_Learning [122/300]: mean_loss=0.016849426086992025
Q_Learning [123/300]: mean_loss=0.014558357186615467
Q_Learning [124/300]: mean_loss=0.004486009303946048
Q_Learning [125/300]: mean_loss=0.0167115090880543
Q_Learning [126/300]: mean_loss=0.02787734498269856
Q_Learning [127/300]: mean_loss=0.008662979875225574
Q_Learning [128/300]: mean_loss=0.09856515936553478
Q_Learning [129/300]: mean_loss=0.08125816285610199
Q_Learning [130/300]: mean_loss=0.01621775992680341
Q_Learning [131/300]: mean_loss=0.02738891984336078
Q_Learning [132/300]: mean_loss=0.04314719466492534
Q_Learning [133/300]: mean_loss=0.022078315960243344
Q_Learning [134/300]: mean_loss=0.014242012868635356
Q_Learning [135/300]: mean_loss=0.013924249331466854
Q_Learning [136/300]: mean_loss=0.0029363303328864276
Q_Learning [137/300]: mean_loss=0.015540544642135501
Q_Learning [138/300]: mean_loss=0.014481129124760628
Q_Learning [139/300]: mean_loss=0.013585833716206253
Q_Learning [140/300]: mean_loss=0.12975298147648573
Q_Learning [141/300]: mean_loss=0.02973700105212629
Q_Learning [142/300]: mean_loss=0.035727453883737326
Q_Learning [143/300]: mean_loss=0.012065640999935567
Q_Learning [144/300]: mean_loss=0.0074296745005995035
Q_Learning [145/300]: mean_loss=0.02231326582841575
Q_Learning [146/300]: mean_loss=0.014204854378476739
Q_Learning [147/300]: mean_loss=0.0756743922829628
Q_Learning [148/300]: mean_loss=0.04760744562372565
Q_Learning [149/300]: mean_loss=0.013685130863450468
Q_Learning [150/300]: mean_loss=0.03040668019093573
Q_Learning [151/300]: mean_loss=0.017369050532579422
Q_Learning [152/300]: mean_loss=0.019009334966540337
Q_Learning [153/300]: mean_loss=0.009348827064968646
Q_Learning [154/300]: mean_loss=0.005636392568703741
Q_Learning [155/300]: mean_loss=0.012563584139570594
Q_Learning [156/300]: mean_loss=0.024330003652721643
Q_Learning [157/300]: mean_loss=0.019525391282513738
Q_Learning [158/300]: mean_loss=0.01672817801591009
Q_Learning [159/300]: mean_loss=0.02783449087291956
Q_Learning [160/300]: mean_loss=0.006625553243793547
Q_Learning [161/300]: mean_loss=0.010631703888066113
Q_Learning [162/300]: mean_loss=0.011674418346956372
Q_Learning [163/300]: mean_loss=0.009270950802601874
Q_Learning [164/300]: mean_loss=0.012153482297435403
Q_Learning [165/300]: mean_loss=0.009141063666902483
Q_Learning [166/300]: mean_loss=0.015907245688140392
Q_Learning [167/300]: mean_loss=0.008754244132433087
Q_Learning [168/300]: mean_loss=0.0091515495441854
Q_Learning [169/300]: mean_loss=0.009226257679983974
Q_Learning [170/300]: mean_loss=0.01838994980789721
Q_Learning [171/300]: mean_loss=0.04602578794583678
Q_Learning [172/300]: mean_loss=0.016870777355507016
Q_Learning [173/300]: mean_loss=0.004723826714325696
Q_Learning [174/300]: mean_loss=0.0038004681118763983
Q_Learning [175/300]: mean_loss=0.02095285290852189
Q_Learning [176/300]: mean_loss=0.007904116180725396
Q_Learning [177/300]: mean_loss=0.029734866693615913
Q_Learning [178/300]: mean_loss=0.016557467868551612
Q_Learning [179/300]: mean_loss=0.07880077883601189
Q_Learning [180/300]: mean_loss=0.0586773338727653
Q_Learning [181/300]: mean_loss=0.02284631715156138
Q_Learning [182/300]: mean_loss=0.014306275639683008
Q_Learning [183/300]: mean_loss=0.009754848899319768
Q_Learning [184/300]: mean_loss=0.013269739458337426
Q_Learning [185/300]: mean_loss=0.013001108076423407
Q_Learning [186/300]: mean_loss=0.014704049215652049
Q_Learning [187/300]: mean_loss=0.020060548093169928
Q_Learning [188/300]: mean_loss=0.011841167695820332
Q_Learning [189/300]: mean_loss=0.011180007713846862
Q_Learning [190/300]: mean_loss=0.009137092099990696
Q_Learning [191/300]: mean_loss=0.007456462015397847
Q_Learning [192/300]: mean_loss=0.01088104525115341
Q_Learning [193/300]: mean_loss=0.0083257716614753
Q_Learning [194/300]: mean_loss=0.016929239383898675
Q_Learning [195/300]: mean_loss=0.005689709156285971
Q_Learning [196/300]: mean_loss=0.006920102052390575
Q_Learning [197/300]: mean_loss=0.004689652501838282
Q_Learning [198/300]: mean_loss=0.00912880280520767
Q_Learning [199/300]: mean_loss=0.004494485561735928
Q_Learning [200/300]: mean_loss=0.020342963049188256
Q_Learning [201/300]: mean_loss=0.0037499235768336803
Q_Learning [202/300]: mean_loss=0.11166900396347046
Q_Learning [203/300]: mean_loss=0.02296706777997315
Q_Learning [204/300]: mean_loss=0.0156945688650012
Q_Learning [205/300]: mean_loss=0.012798005947843194
Q_Learning [206/300]: mean_loss=0.010747187188826501
Q_Learning [207/300]: mean_loss=0.006271799968089908
Q_Learning [208/300]: mean_loss=0.030758411856368184
Q_Learning [209/300]: mean_loss=0.010976325487717986
Q_Learning [210/300]: mean_loss=0.011902866652235389
Q_Learning [211/300]: mean_loss=0.02669704076834023
Q_Learning [212/300]: mean_loss=0.009051107801496983
Q_Learning [213/300]: mean_loss=0.014407909358851612
Q_Learning [214/300]: mean_loss=0.0063315958250314
Q_Learning [215/300]: mean_loss=0.024687133729457855
Q_Learning [216/300]: mean_loss=0.03083335398696363
Q_Learning [217/300]: mean_loss=0.012253573164343834
Q_Learning [218/300]: mean_loss=0.007641805044841021
Q_Learning [219/300]: mean_loss=0.015230780700221658
Q_Learning [220/300]: mean_loss=0.01679448375944048
Q_Learning [221/300]: mean_loss=0.00890019815415144
Q_Learning [222/300]: mean_loss=0.012661628308705986
Q_Learning [223/300]: mean_loss=0.01827041758224368
Q_Learning [224/300]: mean_loss=0.007147221069317311
Q_Learning [225/300]: mean_loss=0.003696941421367228
Q_Learning [226/300]: mean_loss=0.020481393206864595
Q_Learning [227/300]: mean_loss=0.018879644805565476
Q_Learning [228/300]: mean_loss=0.003685687348479405
Q_Learning [229/300]: mean_loss=0.013535088044591248
Q_Learning [230/300]: mean_loss=0.012197356787510216
Q_Learning [231/300]: mean_loss=0.027167645283043385
Q_Learning [232/300]: mean_loss=0.006526298995595425
Q_Learning [233/300]: mean_loss=0.004726430197479203
Q_Learning [234/300]: mean_loss=0.07183210738003254
Q_Learning [235/300]: mean_loss=0.09668983332812786
Q_Learning [236/300]: mean_loss=0.011712979292497039
Q_Learning [237/300]: mean_loss=0.021140944212675095
Q_Learning [238/300]: mean_loss=0.00840988993877545
Q_Learning [239/300]: mean_loss=0.015079651959240437
Q_Learning [240/300]: mean_loss=0.012467712978832424
Q_Learning [241/300]: mean_loss=0.02003659470938146
Q_Learning [242/300]: mean_loss=0.009143962990492582
Q_Learning [243/300]: mean_loss=0.0173183890292421
Q_Learning [244/300]: mean_loss=0.009275540360249579
Q_Learning [245/300]: mean_loss=0.02087549795396626
Q_Learning [246/300]: mean_loss=0.013967271661385894
Q_Learning [247/300]: mean_loss=0.016765178414061666
Q_Learning [248/300]: mean_loss=0.01530116971116513
Q_Learning [249/300]: mean_loss=0.021536836866289377
Q_Learning [250/300]: mean_loss=0.011890606838278472
Q_Learning [251/300]: mean_loss=0.00883675494696945
Q_Learning [252/300]: mean_loss=0.02075736061669886
Q_Learning [253/300]: mean_loss=0.014189606299623847
Q_Learning [254/300]: mean_loss=0.0036689549451693892
Q_Learning [255/300]: mean_loss=0.007496262202039361
Q_Learning [256/300]: mean_loss=0.019336681347340345
Q_Learning [257/300]: mean_loss=0.007509483955800533
Q_Learning [258/300]: mean_loss=0.010012730257585645
Q_Learning [259/300]: mean_loss=0.006815313070546836
Q_Learning [260/300]: mean_loss=0.008262241433840245
Q_Learning [261/300]: mean_loss=0.009909601765684783
Q_Learning [262/300]: mean_loss=0.013843508320860565
Q_Learning [263/300]: mean_loss=0.007709489087574184
Q_Learning [264/300]: mean_loss=0.00462495259125717
Q_Learning [265/300]: mean_loss=0.10925675835460424
Q_Learning [266/300]: mean_loss=0.0900502260774374
Q_Learning [267/300]: mean_loss=0.010616513667628169
Q_Learning [268/300]: mean_loss=0.02147183008491993
Q_Learning [269/300]: mean_loss=0.02137208334170282
Q_Learning [270/300]: mean_loss=0.1040850905701518
Q_Learning [271/300]: mean_loss=0.03552776062861085
Q_Learning [272/300]: mean_loss=0.013825280009768903
Q_Learning [273/300]: mean_loss=0.02308784518390894
Q_Learning [274/300]: mean_loss=0.015685321181081235
Q_Learning [275/300]: mean_loss=0.02041136077605188
Q_Learning [276/300]: mean_loss=0.01421551697421819
Q_Learning [277/300]: mean_loss=0.008467054227367043
Q_Learning [278/300]: mean_loss=0.006220808543730527
Q_Learning [279/300]: mean_loss=0.009988368954509497
Q_Learning [280/300]: mean_loss=0.010501995217055082
Q_Learning [281/300]: mean_loss=0.009170237695798278
Q_Learning [282/300]: mean_loss=0.016935947351157665
Q_Learning [283/300]: mean_loss=0.020115690655075014
Q_Learning [284/300]: mean_loss=0.009146333439275622
Q_Learning [285/300]: mean_loss=0.03981070872396231
Q_Learning [286/300]: mean_loss=0.00863766169641167
Q_Learning [287/300]: mean_loss=0.008749406319111586
Q_Learning [288/300]: mean_loss=0.017443462507799268
Q_Learning [289/300]: mean_loss=0.005495798890478909
Q_Learning [290/300]: mean_loss=0.005440001783426851
Q_Learning [291/300]: mean_loss=0.014745642663910985
Q_Learning [292/300]: mean_loss=0.008393415773753077
Q_Learning [293/300]: mean_loss=0.10664157569408417
Q_Learning [294/300]: mean_loss=0.03525902749970555
Q_Learning [295/300]: mean_loss=0.009541621548123658
Q_Learning [296/300]: mean_loss=0.015752956038340926
Q_Learning [297/300]: mean_loss=0.013845424517057836
Q_Learning [298/300]: mean_loss=0.006410791189409792
Q_Learning [299/300]: mean_loss=0.010924513451755047
Q_Learning [300/300]: mean_loss=0.01139382750261575
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 0.11107048 -0.4674956 ]
[0, 2, 1, 0, 2, 1, 1, 2, 2, 0, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0, 1, 2, 2, 1, 0, 0, 1, 0, 2, 2, 0, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 1, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0, 2, 2, 2, 0, 1, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 2, 0, 0, 2, 2, 2, 1, 1, 2, 1, 0, 2, 0, 1, 1, 1, 1, 2, 0, 2, 1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 2, 2, 2, 2, 1, 2, 0, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 2, 2, 2, 1, 2, 0, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 0, 0, 2, 2, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 2, 0, 2, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 0]
[0, 0, 1, 0, 0, 2, 1, 0, 0, 2, 3, 2, 1, 1, 2, 2, 1, 2, 1, 0, 0, 2, 0, 2, 1, 1, 2, 0, 3, 0, 1, 2, 2, 1, 0, 0, 3, 0, 3, 3, 1, 1, 1, 0, 0, 1, 3, 3, 2, 3, 0, 3, 0, 3, 0, 2, 2, 4, 5, 1, 0, 3, 3, 3, 2, 2, 0, 3, 6, 2, 0, 2, 2, 0, 0, 0, 7, 2, 0, 8, 6, 7, 7, 8, 6, 6, 9, 9, 9, 6, 0, 6, 7, 0, 0, 10, 11, 8, 9, 9, 6, 8, 8, 11, 9, 8, 6, 8, 8, 0, 6, 10, 8, 11, 12, 12, 8, 0, 8, 13, 14, 14, 12, 8, 0, 7, 12, 6, 6, 10, 15, 8, 12, 11, 8, 9, 16, 16, 8, 8, 17, 8, 8, 7, 7, 9, 8, 16, 16, 8, 8, 8, 6, 9, 8, 6, 7, 12, 18, 12, 7, 12, 16, 8, 7, 7, 8, 18, 7, 8, 9, 7, 6, 7, 9, 7, 16, 7, 7, 0, 19, 16, 7, 9, 8, 12, 9, 8, 7, 7, 7, 16, 7, 9, 7, 16, 7, 6, 8, 7, 7, 9, 8, 7, 7, 9, 18, 18, 12, 7, 16, 20, 18, 9, 20, 7, 20, 20, 7, 7, 20, 2, 20, 7, 21, 5, 20, 20, 22, 7, 22, 20, 20, 22, 7, 20, 7, 23, 2, 20, 20, 20, 2, 22, 2, 20, 7, 2, 7, 20, 20, 7, 22, 20, 7, 7, 22, 22, 7, 22, 20, 22, 7, 7, 20, 22, 2, 7, 19, 22, 7, 7, 20, 2, 24, 2, 24, 24, 2, 24, 7, 24, 2, 22, 7, 24, 24, 7, 24, 20, 2, 20, 24, 18, 18, 20, 20, 20, 20, 24]
Centroids: [[1.2483703, 1.7541832], [1.0284928, 0.64084744], [1.5016257, 0.18044752]]
Centroids: [[0.9003214, -0.74024546], [-0.33679262, -1.0500044], [0.248394, 0.1339855], [0.51353353, -1.5280111], [-1.0973281, -3.7343514], [0.26695013, -2.7041955], [2.055326, 0.04359091], [1.0579884, 1.1571319], [2.5874872, 1.716892], [1.9701111, 1.4044809], [4.033928, 0.50713265], [3.4462776, 2.4563136], [2.5826824, 0.8004589], [3.1719468, -0.9035636], [4.2109222, 4.2157383], [5.678048, 3.5571966], [2.2512066, 2.9831724], [0.6758264, -4.7729607], [1.9153174, 3.883939], [1.3110256, 0.3125451], [0.6729884, 2.1123896], [-0.4979889, -5.944343], [0.8916342, 3.0113423], [0.99883825, 4.2010894], [0.3452312, 1.1753715]]
Contingency Matrix: 
[[ 7  0 13  1  0  0  0 10  9  4  1  3  0  0  1  0  8  0  4  0 18  0 12  1
   3]
 [12 13 11  1  1  0  5 27 12  9  0  1  1  0  1  0  2  0  2  0  5  1  0  0
   5]
 [14  2  7 12  0  2 10 13  9  4  2  0  9  1  0  1  0  1  1  2  4  0  0  0
   2]]
[[7, 0, 13, 1, 0, 0, 0, 10, 9, 4, 1, 3, 0, 0, 1, 0, 8, 0, 4, 0, 18, 0, 12, 1, 3], [12, 13, 11, 1, 1, 0, 5, 27, 12, 9, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 5, 1, 0, 0, 5], [14, 2, 7, 12, 0, 2, 10, 13, 9, 4, 2, 0, 9, 1, 0, 1, 0, 1, 1, 2, 4, 0, 0, 0, 2]]
[[7, 0, 13, 1, 0, 0, 0, 10, 9, 4, 1, 3, 0, 0, 1, 0, 8, 0, 4, 0, 18, 0, 12, 1, 3], [12, 13, 11, 1, 1, 0, 5, 27, 12, 9, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 5, 1, 0, 0, 5], [14, 2, 7, 12, 0, 2, 10, 13, 9, 4, 2, 0, 9, 1, 0, 1, 0, 1, 1, 2, 4, 0, 0, 0, 2]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
[[7, 0, 13, 1, 0, 0, 0, -1, 9, 4, 1, 3, 0, 0, 1, 0, 8, 0, 4, 0, 18, 0, 12, 1, 3], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [14, 2, 7, 12, 0, 2, 10, -1, 9, 4, 2, 0, 9, 1, 0, 1, 0, 1, 1, 2, 4, 0, 0, 0, 2]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [14, 2, 7, 12, 0, 2, 10, -1, 9, 4, 2, 0, 9, 1, 0, 1, 0, 1, 1, 2, -1, 0, 0, 0, 2]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 7, 0: 20, 2: 0}
New Contingency Matrix: 
[[18 10  7  0 13  1  0  0  0  9  4  1  3  0  0  1  0  8  0  4  0  0 12  1
   3]
 [ 5 27 12 13 11  1  1  0  5 12  9  0  1  1  0  1  0  2  0  2  0  1  0  0
   5]
 [ 4 13 14  2  7 12  0  2 10  9  4  2  0  9  1  0  1  0  1  1  2  0  0  0
   2]]
New Clustered Label Sequence: [20, 7, 0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24]
Diagonal_Elements: [18, 27, 14], Sum: 59
All_Elements: [18, 10, 7, 0, 13, 1, 0, 0, 0, 9, 4, 1, 3, 0, 0, 1, 0, 8, 0, 4, 0, 0, 12, 1, 3, 5, 27, 12, 13, 11, 1, 1, 0, 5, 12, 9, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 5, 4, 13, 14, 2, 7, 12, 0, 2, 10, 9, 4, 2, 0, 9, 1, 0, 1, 0, 1, 1, 2, 0, 0, 0, 2], Sum: 300
Accuracy: 0.19666666666666666
