Seed: 4
Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_4_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_4_opt_temp_noisy/C_Difficult1_noise005.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-13_32_40
Normalisation: False
Template Matching: True
Optimising Autoencoder: True
Update Factor: 1
Noisy Batches: True
Noisy Factor: 0.1
Epochs: 8
Batch Size: 1
maximal Spikes for Autoencoder Training : 700
maximal Spikes for Training: 1000
Input Size: 47
Chosen Model: Convolutional Autoencoder
ConvolutionalAutoencoder(
  (encoder): Sequential(
    (0): Conv1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Conv1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=37, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): ConvTranspose1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=12, out_features=47, bias=True)
  )
)
MSELoss()
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0
)
---Q Learning Parameters---
Normalisation: False
Punishment Coefficient: 0.4
Alpha: 0.8
Epsilon: 0.01
Gamma: 0.97
Initial Episode Number: 0
Episode Number Coefficient: 1.4
Number of Random Features: 20
Planning Number: 20
Max Random Features: 60
New Episode Number: 72
New Episode Number: 143
New Episode Number: 215
New Episode Number: 286
New Episode Number: 358
New Episode Number: 429
New Episode Number: 500
New Episode Number: 572
New Episode Number: 643
New Episode Number: 715
New Episode Number: 786
New Episode Number: 858
New Episode Number: 929
New Episode Number: 1000
New Episode Number: 1072
               0     1     2     3     4   ...    11    12    13    14     15
new_cluster -3.01 -5.34 -4.18 -3.84 -2.75  ... -9.47 -8.04 -3.84 -3.67 -15.50
c1          -3.05 -5.35 -4.06 -3.77 -2.76  ... -9.26 -7.94 -3.80 -3.78 -15.30
c2          -2.95 -5.45 -4.24 -3.67 -2.82  ... -9.30 -8.03 -3.81 -3.70 -15.56
c3          -3.04 -5.41 -4.07 -3.66 -2.76  ... -9.32 -8.02 -3.54 -3.76 -14.80
c4          -3.13 -5.62 -3.94 -3.88 -2.83  ... -9.32 -8.03 -3.94 -3.97 -15.27
c5          -3.14 -5.36 -4.02 -3.84 -2.76  ... -9.41 -8.04 -4.00 -3.98 -15.48
c6          -2.95 -5.41 -4.15 -3.61 -2.83  ... -9.45 -8.02 -3.77 -3.86 -15.65
c7          -3.05 -5.41 -4.17 -4.01 -2.66  ... -9.33 -8.00 -3.66 -3.95 -15.22
c8          -3.04 -5.35 -4.03 -3.59 -2.90  ... -9.21 -8.00 -3.79 -4.08 -15.03
c9          -3.13 -5.09 -3.99 -3.94 -2.65  ... -9.38 -7.95 -3.86 -3.88 -15.43
c10         -3.05 -5.58 -4.07 -3.78 -2.99  ... -9.39 -8.03 -3.90 -3.74 -15.33
c11         -3.03 -5.12 -3.97 -3.75 -2.80  ... -9.30 -8.02 -4.13 -3.66 -15.30
c12         -3.04 -5.40 -4.10 -3.65 -2.72  ... -9.32 -8.03 -4.01 -3.70 -15.50
c13         -3.12 -5.40 -3.98 -3.92 -2.62  ... -9.32 -8.06 -3.45 -3.87 -15.13
c14         -3.04 -5.21 -4.41 -3.65 -2.70  ... -9.39 -8.02 -3.76 -3.88 -15.70
c15         -3.15 -5.27 -3.90 -3.99 -2.70  ... -9.32 -8.02 -3.85 -3.79 -15.27

[16 rows x 16 columns]
\begin{tabular}{lrrrrrrrrrrrrrrrr}
\toprule
{} &    0  &    1  &    2  &    3  &    4  &    5  &    6  &    7  &    8  &    9  &    10 &    11 &    12 &    13 &    14 &     15 \\
\midrule
new\_cluster & -3.01 & -5.34 & -4.18 & -3.84 & -2.75 & -2.60 & -3.21 & -4.65 & -2.64 & -8.32 & -7.26 & -9.47 & -8.04 & -3.84 & -3.67 & -15.50 \\
c1          & -3.05 & -5.35 & -4.06 & -3.77 & -2.76 & -2.59 & -3.07 & -4.64 & -2.80 & -8.31 & -8.08 & -9.26 & -7.94 & -3.80 & -3.78 & -15.30 \\
c2          & -2.95 & -5.45 & -4.24 & -3.67 & -2.82 & -2.70 & -2.95 & -4.82 & -2.62 & -8.24 & -7.55 & -9.30 & -8.03 & -3.81 & -3.70 & -15.56 \\
c3          & -3.04 & -5.41 & -4.07 & -3.66 & -2.76 & -2.64 & -3.28 & -4.79 & -2.54 & -8.32 & -8.00 & -9.32 & -8.02 & -3.54 & -3.76 & -14.80 \\
c4          & -3.13 & -5.62 & -3.94 & -3.88 & -2.83 & -2.55 & -3.10 & -4.58 & -2.66 & -8.32 & -7.48 & -9.32 & -8.03 & -3.94 & -3.97 & -15.27 \\
c5          & -3.14 & -5.36 & -4.02 & -3.84 & -2.76 & -2.71 & -2.92 & -4.65 & -2.75 & -8.25 & -7.77 & -9.41 & -8.04 & -4.00 & -3.98 & -15.48 \\
c6          & -2.95 & -5.41 & -4.15 & -3.61 & -2.83 & -2.55 & -2.95 & -4.69 & -2.74 & -8.24 & -7.56 & -9.45 & -8.02 & -3.77 & -3.86 & -15.65 \\
c7          & -3.05 & -5.41 & -4.17 & -4.01 & -2.66 & -2.61 & -3.12 & -4.80 & -2.53 & -8.29 & -7.78 & -9.33 & -8.00 & -3.66 & -3.95 & -15.22 \\
c8          & -3.04 & -5.35 & -4.03 & -3.59 & -2.90 & -2.66 & -2.94 & -5.03 & -2.62 & -8.24 & -7.70 & -9.21 & -8.00 & -3.79 & -4.08 & -15.03 \\
c9          & -3.13 & -5.09 & -3.99 & -3.94 & -2.65 & -2.65 & -2.89 & -4.58 & -2.56 & -8.24 & -7.70 & -9.38 & -7.95 & -3.86 & -3.88 & -15.43 \\
c10         & -3.05 & -5.58 & -4.07 & -3.78 & -2.99 & -2.60 & -3.20 & -4.96 & -2.67 & -8.20 & -7.50 & -9.39 & -8.03 & -3.90 & -3.74 & -15.33 \\
c11         & -3.03 & -5.12 & -3.97 & -3.75 & -2.80 & -2.58 & -3.05 & -4.72 & -2.61 & -8.25 & -7.70 & -9.30 & -8.02 & -4.13 & -3.66 & -15.30 \\
c12         & -3.04 & -5.40 & -4.10 & -3.65 & -2.72 & -2.58 & -2.88 & -4.78 & -2.60 & -8.24 & -7.50 & -9.32 & -8.03 & -4.01 & -3.70 & -15.50 \\
c13         & -3.12 & -5.40 & -3.98 & -3.92 & -2.62 & -2.44 & -3.02 & -4.68 & -2.61 & -8.25 & -7.65 & -9.32 & -8.06 & -3.45 & -3.87 & -15.13 \\
c14         & -3.04 & -5.21 & -4.41 & -3.65 & -2.70 & -2.52 & -3.16 & -4.70 & -2.64 & -8.25 & -7.59 & -9.39 & -8.02 & -3.76 & -3.88 & -15.70 \\
c15         & -3.15 & -5.27 & -3.90 & -3.99 & -2.70 & -2.62 & -2.99 & -4.88 & -2.52 & -8.24 & -7.44 & -9.32 & -8.02 & -3.85 & -3.79 & -15.27 \\
\bottomrule
\end{tabular}

                               0            1   ...            14             15
new_cluster  [-0.64, new_cluster]  [-2.96, c1]  ...   [-1.5, c14]  [-13.09, c15]
c1           [-0.64, new_cluster]  [-2.86, c1]  ...  [-1.38, c14]   [-12.9, c15]
c2           [-0.64, new_cluster]  [-3.06, c1]  ...  [-1.54, c14]  [-13.14, c15]
c3           [-0.64, new_cluster]  [-3.02, c1]  ...  [-1.36, c14]  [-12.42, c15]
c4           [-0.64, new_cluster]  [-3.14, c1]  ...  [-1.54, c14]  [-12.86, c15]
c5           [-0.64, new_cluster]  [-2.87, c1]  ...  [-1.58, c14]  [-13.17, c15]
c6           [-0.64, new_cluster]  [-2.93, c1]  ...  [-1.45, c14]  [-13.25, c15]
c7           [-0.64, new_cluster]  [-3.02, c1]  ...  [-1.54, c14]  [-12.82, c15]
c8           [-0.64, new_cluster]  [-3.06, c1]  ...  [-1.65, c14]  [-12.72, c15]
c9           [-0.64, new_cluster]   [-2.6, c1]  ...  [-1.64, c14]  [-13.12, c15]
c10          [-0.64, new_cluster]  [-3.19, c1]  ...  [-1.51, c14]   [-12.9, c15]
c11          [-0.64, new_cluster]  [-2.75, c1]  ...  [-1.42, c14]  [-12.91, c15]
c12          [-0.64, new_cluster]  [-2.89, c1]  ...  [-1.45, c14]  [-13.02, c15]
c13          [-0.64, new_cluster]  [-3.01, c1]  ...  [-1.65, c14]  [-12.83, c15]
c14          [-0.64, new_cluster]  [-2.72, c1]  ...  [-1.64, c14]  [-13.26, c15]
c15          [-0.64, new_cluster]  [-2.88, c1]  ...  [-1.38, c14]  [-12.86, c15]

[16 rows x 16 columns]
\begin{tabular}{lllllllllllllllll}
\toprule
{} &                    0  &           1  &           2  &           3  &           4  &           5  &           6  &           7  &           8  &           9  &            10 &            11 &            12 &            13 &            14 &             15 \\
\midrule
new\_cluster &  [-0.64, new\_cluster] &  [-2.96, c1] &  [-1.78, c2] &   [-1.4, c3] &  [-0.41, c4] &  [-0.07, c5] &  [-0.78, c6] &  [-2.22, c7] &  [-0.21, c8] &  [-5.88, c9] &  [-5.07, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.48, c13] &   [-1.5, c14] &  [-13.09, c15] \\
c1          &  [-0.64, new\_cluster] &  [-2.86, c1] &  [-1.67, c2] &  [-1.37, c3] &  [-0.42, c4] &  [-0.07, c5] &  [-0.78, c6] &  [-2.31, c7] &  [-0.27, c8] &  [-5.88, c9] &  [-5.57, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.44, c13] &  [-1.38, c14] &   [-12.9, c15] \\
c2          &  [-0.64, new\_cluster] &  [-3.06, c1] &  [-1.77, c2] &  [-1.22, c3] &  [-0.48, c4] &   [-0.1, c5] &  [-0.69, c6] &  [-2.44, c7] &  [-0.19, c8] &  [-5.88, c9] &  [-5.11, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.44, c13] &  [-1.54, c14] &  [-13.14, c15] \\
c3          &  [-0.64, new\_cluster] &  [-3.02, c1] &  [-1.65, c2] &  [-1.21, c3] &  [-0.46, c4] &  [-0.13, c5] &  [-0.86, c6] &  [-2.35, c7] &  [-0.13, c8] &  [-5.88, c9] &  [-5.53, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.25, c13] &  [-1.36, c14] &  [-12.42, c15] \\
c4          &  [-0.64, new\_cluster] &  [-3.14, c1] &  [-1.54, c2] &  [-1.48, c3] &  [-0.38, c4] &  [-0.02, c5] &  [-0.84, c6] &  [-2.13, c7] &  [-0.23, c8] &  [-5.88, c9] &  [-5.14, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.58, c13] &  [-1.54, c14] &  [-12.86, c15] \\
c5          &  [-0.64, new\_cluster] &  [-2.87, c1] &  [-1.62, c2] &  [-1.41, c3] &  [-0.48, c4] &  [-0.18, c5] &  [-0.67, c6] &  [-2.32, c7] &  [-0.24, c8] &  [-5.88, c9] &  [-5.33, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.63, c13] &  [-1.58, c14] &  [-13.17, c15] \\
c6          &  [-0.64, new\_cluster] &  [-2.93, c1] &  [-1.67, c2] &  [-1.21, c3] &  [-0.41, c4] &  [-0.05, c5] &  [-0.69, c6] &  [-2.36, c7] &  [-0.23, c8] &  [-5.88, c9] &  [-5.21, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.41, c13] &  [-1.45, c14] &  [-13.25, c15] \\
c7          &  [-0.64, new\_cluster] &  [-3.02, c1] &  [-1.71, c2] &  [-1.45, c3] &  [-0.38, c4] &  [-0.07, c5] &  [-0.85, c6] &  [-2.47, c7] &  [-0.16, c8] &  [-5.88, c9] &  [-5.33, c10] &  [-6.97, c11] &  [-5.53, c12] &   [-1.3, c13] &  [-1.54, c14] &  [-12.82, c15] \\
c8          &  [-0.64, new\_cluster] &  [-3.06, c1] &  [-1.56, c2] &   [-1.3, c3] &  [-0.56, c4] &  [-0.04, c5] &  [-0.68, c6] &  [-2.59, c7] &  [-0.18, c8] &  [-5.88, c9] &  [-5.26, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.52, c13] &  [-1.65, c14] &  [-12.72, c15] \\
c9          &  [-0.64, new\_cluster] &   [-2.6, c1] &  [-1.59, c2] &   [-1.5, c3] &   [-0.3, c4] &  [-0.06, c5] &  [-0.63, c6] &  [-2.25, c7] &  [-0.18, c8] &  [-5.88, c9] &  [-5.26, c10] &  [-6.97, c11] &  [-5.53, c12] &   [-1.5, c13] &  [-1.64, c14] &  [-13.12, c15] \\
c10         &  [-0.64, new\_cluster] &  [-3.19, c1] &  [-1.67, c2] &  [-1.36, c3] &  [-0.51, c4] &  [-0.05, c5] &  [-0.78, c6] &  [-2.63, c7] &  [-0.16, c8] &  [-5.88, c9] &  [-5.18, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.54, c13] &  [-1.51, c14] &   [-12.9, c15] \\
c11         &  [-0.64, new\_cluster] &  [-2.75, c1] &  [-1.58, c2] &  [-1.34, c3] &  [-0.35, c4] &  [-0.05, c5] &  [-0.82, c6] &  [-2.39, c7] &  [-0.22, c8] &  [-5.88, c9] &  [-5.35, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.76, c13] &  [-1.42, c14] &  [-12.91, c15] \\
c12         &  [-0.64, new\_cluster] &  [-2.89, c1] &  [-1.63, c2] &  [-1.24, c3] &  [-0.39, c4] &  [-0.12, c5] &  [-0.61, c6] &  [-2.34, c7] &  [-0.14, c8] &  [-5.88, c9] &  [-5.16, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.64, c13] &  [-1.45, c14] &  [-13.02, c15] \\
c13         &  [-0.64, new\_cluster] &  [-3.01, c1] &  [-1.58, c2] &  [-1.52, c3] &  [-0.31, c4] &  [-0.06, c5] &  [-0.77, c6] &  [-2.25, c7] &  [-0.19, c8] &  [-5.88, c9] &   [-5.3, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.18, c13] &  [-1.65, c14] &  [-12.83, c15] \\
c14         &  [-0.64, new\_cluster] &  [-2.72, c1] &  [-1.93, c2] &  [-1.23, c3] &  [-0.35, c4] &  [-0.02, c5] &  [-0.73, c6] &  [-2.27, c7] &  [-0.21, c8] &  [-5.88, c9] &  [-5.14, c10] &  [-6.97, c11] &  [-5.53, c12] &  [-1.39, c13] &  [-1.64, c14] &  [-13.26, c15] \\
c15         &  [-0.64, new\_cluster] &  [-2.88, c1] &   [-1.5, c2] &  [-1.56, c3] &  [-0.37, c4] &  [-0.11, c5] &  [-0.75, c6] &  [-2.46, c7] &  [-0.14, c8] &  [-5.88, c9] &  [-5.11, c10] &  [-6.97, c11] &  [-5.53, c12] &   [-1.5, c13] &  [-1.38, c14] &  [-12.86, c15] \\
\bottomrule
\end{tabular}

