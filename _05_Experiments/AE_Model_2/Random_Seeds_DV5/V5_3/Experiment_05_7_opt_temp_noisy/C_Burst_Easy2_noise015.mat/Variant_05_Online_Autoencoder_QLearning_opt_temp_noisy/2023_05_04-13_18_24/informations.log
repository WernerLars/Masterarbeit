Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_7_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_7_opt_temp_noisy/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_05_04-13_18_24
Punishment_Coefficient: 0.7
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001C97C841A90>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.1895903293043375
Online_Training [2/700]: mean_loss=0.2467041015625
Online_Training [3/700]: mean_loss=0.21693621389567852
Online_Training [4/700]: mean_loss=0.07338020671159029
Online_Training [5/700]: mean_loss=0.2605546601116657
Online_Training [6/700]: mean_loss=0.11347876861691475
Online_Training [7/700]: mean_loss=0.14744226820766926
Online_Training [8/700]: mean_loss=0.06867936346679926
Online_Training [9/700]: mean_loss=0.2142276782542467
Online_Training [10/700]: mean_loss=0.1317233219742775
Online_Training [11/700]: mean_loss=0.08285926189273596
Online_Training [12/700]: mean_loss=0.07985638454556465
Online_Training [13/700]: mean_loss=0.07466005627065897
Online_Training [14/700]: mean_loss=0.06931501999497414
Online_Training [15/700]: mean_loss=0.05520763387903571
Online_Training [16/700]: mean_loss=0.13015847094357014
Online_Training [17/700]: mean_loss=0.15417707152664661
Online_Training [18/700]: mean_loss=0.09887586254626513
Online_Training [19/700]: mean_loss=0.03836151398718357
Online_Training [20/700]: mean_loss=0.19060741364955902
Online_Training [21/700]: mean_loss=0.13185076788067818
Online_Training [22/700]: mean_loss=0.07240475993603468
Online_Training [23/700]: mean_loss=0.03591492376290262
Online_Training [24/700]: mean_loss=0.09404979553073645
Online_Training [25/700]: mean_loss=0.04757803678512573
Online_Training [26/700]: mean_loss=0.07671214360743761
Online_Training [27/700]: mean_loss=0.09620349854230881
Online_Training [28/700]: mean_loss=0.06480872677639127
Online_Training [29/700]: mean_loss=0.04912357032299042
Online_Training [30/700]: mean_loss=0.0344541035592556
Online_Training [31/700]: mean_loss=0.030175609281286597
Online_Training [32/700]: mean_loss=0.048608620185405016
Online_Training [33/700]: mean_loss=0.02409054897725582
Online_Training [34/700]: mean_loss=0.20444980822503567
Online_Training [35/700]: mean_loss=0.06442699488252401
Online_Training [36/700]: mean_loss=0.09392751473933458
Online_Training [37/700]: mean_loss=0.07017509220167994
Online_Training [38/700]: mean_loss=0.04329793993383646
Online_Training [39/700]: mean_loss=0.13884173706173897
Online_Training [40/700]: mean_loss=0.027160761412233114
Online_Training [41/700]: mean_loss=0.03885328723117709
Online_Training [42/700]: mean_loss=0.05700618866831064
Online_Training [43/700]: mean_loss=0.13120346516370773
Online_Training [44/700]: mean_loss=0.15305098332464695
Online_Training [45/700]: mean_loss=0.1100233206525445
Online_Training [46/700]: mean_loss=0.07949479576200247
Online_Training [47/700]: mean_loss=0.10357826109975576
Online_Training [48/700]: mean_loss=0.06784848030656576
Online_Training [49/700]: mean_loss=0.1062292717397213
Online_Training [50/700]: mean_loss=0.11871081963181496
Online_Training [51/700]: mean_loss=0.039867434184998274
Online_Training [52/700]: mean_loss=0.17131741158664227
Online_Training [53/700]: mean_loss=0.03864911384880543
Online_Training [54/700]: mean_loss=0.09649469889700413
Online_Training [55/700]: mean_loss=0.0896864477545023
Online_Training [56/700]: mean_loss=0.03600984998047352
Online_Training [57/700]: mean_loss=0.12106274627149105
Online_Training [58/700]: mean_loss=0.20995546132326126
Online_Training [59/700]: mean_loss=0.09199123596772552
Online_Training [60/700]: mean_loss=0.050028592348098755
Online_Training [61/700]: mean_loss=0.028678842587396502
Online_Training [62/700]: mean_loss=0.09705209266394377
Online_Training [63/700]: mean_loss=0.052660523913800716
Online_Training [64/700]: mean_loss=0.004988527332898229
Online_Training [65/700]: mean_loss=0.05500885518267751
Online_Training [66/700]: mean_loss=0.03592481929808855
Online_Training [67/700]: mean_loss=0.06253271643072367
Online_Training [68/700]: mean_loss=0.03198270220309496
Online_Training [69/700]: mean_loss=0.07862639287486672
Online_Training [70/700]: mean_loss=0.03936920780688524
Online_Training [71/700]: mean_loss=0.08287644572556019
Online_Training [72/700]: mean_loss=0.0743930684402585
Online_Training [73/700]: mean_loss=0.041684530675411224
Online_Training [74/700]: mean_loss=0.040034613106399775
Online_Training [75/700]: mean_loss=0.024304028833284974
Online_Training [76/700]: mean_loss=0.03593753697350621
Online_Training [77/700]: mean_loss=0.03326807077974081
Online_Training [78/700]: mean_loss=0.030134549597278237
Online_Training [79/700]: mean_loss=0.03961094003170729
Online_Training [80/700]: mean_loss=0.03553447453305125
Online_Training [81/700]: mean_loss=0.01781692646909505
Online_Training [82/700]: mean_loss=0.030443146592006087
Online_Training [83/700]: mean_loss=0.028484667651355267
Online_Training [84/700]: mean_loss=0.03286669170483947
Online_Training [85/700]: mean_loss=0.024356221314519644
Online_Training [86/700]: mean_loss=0.035165545996278524
Online_Training [87/700]: mean_loss=0.018259948818013072
Online_Training [88/700]: mean_loss=0.024626733269542456
Online_Training [89/700]: mean_loss=0.04334089299663901
Online_Training [90/700]: mean_loss=0.02006463147699833
Online_Training [91/700]: mean_loss=0.030955958180129528
Online_Training [92/700]: mean_loss=0.033142253290861845
Online_Training [93/700]: mean_loss=0.025630449410527945
Online_Training [94/700]: mean_loss=0.04051772691309452
Online_Training [95/700]: mean_loss=0.030628161504864693
Online_Training [96/700]: mean_loss=0.01999684004113078
Online_Training [97/700]: mean_loss=0.038704012986272573
Online_Training [98/700]: mean_loss=0.04358638543635607
Online_Training [99/700]: mean_loss=0.022000011056661606
Online_Training [100/700]: mean_loss=0.04268283769488335
Online_Training [101/700]: mean_loss=0.018299604067578912
Online_Training [102/700]: mean_loss=0.05808372749015689
Online_Training [103/700]: mean_loss=0.04166980180889368
Online_Training [104/700]: mean_loss=0.03245160961523652
Online_Training [105/700]: mean_loss=0.03893128223717213
Online_Training [106/700]: mean_loss=0.019788875244557858
Online_Training [107/700]: mean_loss=0.019995275884866714
Online_Training [108/700]: mean_loss=0.0315719919744879
Online_Training [109/700]: mean_loss=0.029645623406395316
Online_Training [110/700]: mean_loss=0.025926943169906735
Online_Training [111/700]: mean_loss=0.0286777731962502
Online_Training [112/700]: mean_loss=0.14592140819877386
Online_Training [113/700]: mean_loss=0.018127736635506153
Online_Training [114/700]: mean_loss=0.029307556804269552
Online_Training [115/700]: mean_loss=0.03955031372606754
Online_Training [116/700]: mean_loss=0.02390407328493893
Online_Training [117/700]: mean_loss=0.05432693986222148
Online_Training [118/700]: mean_loss=0.04263154091313481
Online_Training [119/700]: mean_loss=0.14001471363008022
Online_Training [120/700]: mean_loss=0.053569482173770666
Online_Training [121/700]: mean_loss=0.050166061613708735
Online_Training [122/700]: mean_loss=0.05727423680946231
Online_Training [123/700]: mean_loss=0.03597107622772455
Online_Training [124/700]: mean_loss=0.011557184625416994
Online_Training [125/700]: mean_loss=0.06440499471500516
Online_Training [126/700]: mean_loss=0.04354993859305978
Online_Training [127/700]: mean_loss=0.03573634289205074
Online_Training [128/700]: mean_loss=0.028647811384871602
Online_Training [129/700]: mean_loss=0.034192024264484644
Online_Training [130/700]: mean_loss=0.018993720412254333
Online_Training [131/700]: mean_loss=0.019762893905863166
Online_Training [132/700]: mean_loss=0.0183438885724172
Online_Training [133/700]: mean_loss=0.02467755228281021
Online_Training [134/700]: mean_loss=0.014695225399918854
Online_Training [135/700]: mean_loss=0.10874307341873646
Online_Training [136/700]: mean_loss=0.017576622776687145
Online_Training [137/700]: mean_loss=0.01868321537040174
Online_Training [138/700]: mean_loss=0.012252305285073817
Online_Training [139/700]: mean_loss=0.0190535387955606
Online_Training [140/700]: mean_loss=0.02937873685732484
Online_Training [141/700]: mean_loss=0.03182143229059875
Online_Training [142/700]: mean_loss=0.016560910502448678
Online_Training [143/700]: mean_loss=0.02205818798393011
Online_Training [144/700]: mean_loss=0.011436300002969801
Online_Training [145/700]: mean_loss=0.038886052556335926
Online_Training [146/700]: mean_loss=0.022018922260031104
Online_Training [147/700]: mean_loss=0.01686536252964288
Online_Training [148/700]: mean_loss=0.034039369551464915
Online_Training [149/700]: mean_loss=0.06695819040760398
Online_Training [150/700]: mean_loss=0.06132041243836284
Online_Training [151/700]: mean_loss=0.024505740497261286
Online_Training [152/700]: mean_loss=0.01617810723837465
Online_Training [153/700]: mean_loss=0.02817039331421256
Online_Training [154/700]: mean_loss=0.02579850982874632
Online_Training [155/700]: mean_loss=0.01096313341986388
Online_Training [156/700]: mean_loss=0.02103390754200518
Online_Training [157/700]: mean_loss=0.14083343837410212
Online_Training [158/700]: mean_loss=0.006923933688085526
Online_Training [159/700]: mean_loss=0.027692341711372137
Online_Training [160/700]: mean_loss=0.02379388501867652
Online_Training [161/700]: mean_loss=0.03096781112253666
Online_Training [162/700]: mean_loss=0.014210239285603166
Online_Training [163/700]: mean_loss=0.05736538115888834
Online_Training [164/700]: mean_loss=0.014940239954739809
Online_Training [165/700]: mean_loss=0.010815372690558434
Online_Training [166/700]: mean_loss=0.017925090272910893
Online_Training [167/700]: mean_loss=0.03797804517671466
Online_Training [168/700]: mean_loss=0.032141632633283734
Online_Training [169/700]: mean_loss=0.05728799384087324
Online_Training [170/700]: mean_loss=0.17343797534704208
Online_Training [171/700]: mean_loss=0.011879471829161048
Online_Training [172/700]: mean_loss=0.015280407504178584
Online_Training [173/700]: mean_loss=0.02830288652330637
Online_Training [174/700]: mean_loss=0.014708562870509923
Online_Training [175/700]: mean_loss=0.011415913118980825
Online_Training [176/700]: mean_loss=0.006650502094998956
Online_Training [177/700]: mean_loss=0.02756109624169767
Online_Training [178/700]: mean_loss=0.04145605722442269
Online_Training [179/700]: mean_loss=0.01831407123245299
Online_Training [180/700]: mean_loss=0.020175544545054436
Online_Training [181/700]: mean_loss=0.02390630287118256
Online_Training [182/700]: mean_loss=0.033152695978060365
Online_Training [183/700]: mean_loss=0.012402264052070677
Online_Training [184/700]: mean_loss=0.004220265487674624
Online_Training [185/700]: mean_loss=0.02869934239424765
Online_Training [186/700]: mean_loss=0.032864436972886324
Online_Training [187/700]: mean_loss=0.028433554340153933
Online_Training [188/700]: mean_loss=0.018309989594854414
Online_Training [189/700]: mean_loss=0.0561166713014245
Online_Training [190/700]: mean_loss=0.02714362437836826
Online_Training [191/700]: mean_loss=0.14899923466145992
Online_Training [192/700]: mean_loss=0.025480461306869984
Online_Training [193/700]: mean_loss=0.02148122852668166
Online_Training [194/700]: mean_loss=0.01318039686884731
Online_Training [195/700]: mean_loss=0.025652113370597363
Online_Training [196/700]: mean_loss=0.013170978636480868
Online_Training [197/700]: mean_loss=0.03811882669106126
Online_Training [198/700]: mean_loss=0.02166575926821679
Online_Training [199/700]: mean_loss=0.09232950489968061
Online_Training [200/700]: mean_loss=0.026309995679184794
Online_Training [201/700]: mean_loss=0.0359326908364892
Online_Training [202/700]: mean_loss=0.013341613812372088
Online_Training [203/700]: mean_loss=0.012476281845010817
Online_Training [204/700]: mean_loss=0.01377506647258997
Online_Training [205/700]: mean_loss=0.06294719595462084
Online_Training [206/700]: mean_loss=0.018552934983745217
Online_Training [207/700]: mean_loss=0.04064890369772911
Online_Training [208/700]: mean_loss=0.036691142711788416
Online_Training [209/700]: mean_loss=0.05231465119868517
Online_Training [210/700]: mean_loss=0.02988092740997672
Online_Training [211/700]: mean_loss=0.014376836828887463
Online_Training [212/700]: mean_loss=0.08989411871880293
Online_Training [213/700]: mean_loss=0.03441197518259287
Online_Training [214/700]: mean_loss=0.011389186838641763
Online_Training [215/700]: mean_loss=0.03527590585872531
Online_Training [216/700]: mean_loss=0.029182566097006202
Online_Training [217/700]: mean_loss=0.011440523667261004
Online_Training [218/700]: mean_loss=0.006819571717642248
Online_Training [219/700]: mean_loss=0.04660117207095027
Online_Training [220/700]: mean_loss=0.013576687662862241
Online_Training [221/700]: mean_loss=0.03178301500156522
Online_Training [222/700]: mean_loss=0.019140883814543486
Online_Training [223/700]: mean_loss=0.03098164522089064
Online_Training [224/700]: mean_loss=0.007682566239964217
Online_Training [225/700]: mean_loss=0.02907291892915964
Online_Training [226/700]: mean_loss=0.02806835644878447
Online_Training [227/700]: mean_loss=0.015560418018139899
Online_Training [228/700]: mean_loss=0.0222073036711663
Online_Training [229/700]: mean_loss=0.043821005150675774
Online_Training [230/700]: mean_loss=0.016688609728589654
Online_Training [231/700]: mean_loss=0.02004822250455618
Online_Training [232/700]: mean_loss=0.022971135564148426
Online_Training [233/700]: mean_loss=0.020362624898552895
Online_Training [234/700]: mean_loss=0.0396073036827147
Online_Training [235/700]: mean_loss=0.09915875550359488
Online_Training [236/700]: mean_loss=0.059517210349440575
Online_Training [237/700]: mean_loss=0.01836623763665557
Online_Training [238/700]: mean_loss=0.09560559131205082
Online_Training [239/700]: mean_loss=0.07239448046311736
Online_Training [240/700]: mean_loss=0.03634555684402585
Online_Training [241/700]: mean_loss=0.034549648175016046
Online_Training [242/700]: mean_loss=0.03223427711054683
Online_Training [243/700]: mean_loss=0.04120059963315725
Online_Training [244/700]: mean_loss=0.025606634095311165
Online_Training [245/700]: mean_loss=0.03835763130337
Online_Training [246/700]: mean_loss=0.023266951786354184
Online_Training [247/700]: mean_loss=0.010078839841298759
Online_Training [248/700]: mean_loss=0.07509126886725426
Online_Training [249/700]: mean_loss=0.007351602194830775
Online_Training [250/700]: mean_loss=0.016618333291262388
Online_Training [251/700]: mean_loss=0.014475699164904654
Online_Training [252/700]: mean_loss=0.019395496230572462
Online_Training [253/700]: mean_loss=0.01807345193810761
Online_Training [254/700]: mean_loss=0.019622469320893288
Online_Training [255/700]: mean_loss=0.027836377965286374
Online_Training [256/700]: mean_loss=0.01859089860226959
Online_Training [257/700]: mean_loss=0.01995526277460158
Online_Training [258/700]: mean_loss=0.021618521073833108
Online_Training [259/700]: mean_loss=0.01094713993370533
Online_Training [260/700]: mean_loss=0.010973568772897124
Online_Training [261/700]: mean_loss=0.025586003670468926
Online_Training [262/700]: mean_loss=0.030369487823918462
Online_Training [263/700]: mean_loss=0.01146344537846744
Online_Training [264/700]: mean_loss=0.01923596579581499
Online_Training [265/700]: mean_loss=0.01967715029604733
Online_Training [266/700]: mean_loss=0.015633242786861956
Online_Training [267/700]: mean_loss=0.012718014302663505
Online_Training [268/700]: mean_loss=0.005919334944337606
Online_Training [269/700]: mean_loss=0.018091914476826787
Online_Training [270/700]: mean_loss=0.011491925921291113
Online_Training [271/700]: mean_loss=0.02928773406893015
Online_Training [272/700]: mean_loss=0.008024282928090543
Online_Training [273/700]: mean_loss=0.007220822793897241
Online_Training [274/700]: mean_loss=0.009401925723068416
Online_Training [275/700]: mean_loss=0.014885009150020778
Online_Training [276/700]: mean_loss=0.01719969930127263
Online_Training [277/700]: mean_loss=0.02606169250793755
Online_Training [278/700]: mean_loss=0.021051509073004127
Online_Training [279/700]: mean_loss=0.017025106819346547
Online_Training [280/700]: mean_loss=0.02210504817776382
Online_Training [281/700]: mean_loss=0.02533464482985437
Online_Training [282/700]: mean_loss=0.03144270530901849
Online_Training [283/700]: mean_loss=0.02267412655055523
Online_Training [284/700]: mean_loss=0.008749037457164377
Online_Training [285/700]: mean_loss=0.015819068998098373
Online_Training [286/700]: mean_loss=0.021439043805003166
Online_Training [287/700]: mean_loss=0.016482569044455886
Online_Training [288/700]: mean_loss=0.01514725189190358
Online_Training [289/700]: mean_loss=0.04221686255186796
Online_Training [290/700]: mean_loss=0.007100993127096444
Online_Training [291/700]: mean_loss=0.010295285377651453
Online_Training [292/700]: mean_loss=0.0071697497041895986
Online_Training [293/700]: mean_loss=0.012551500694826245
Online_Training [294/700]: mean_loss=0.01327998354099691
Online_Training [295/700]: mean_loss=0.03368569049052894
Online_Training [296/700]: mean_loss=0.038656906224787235
Online_Training [297/700]: mean_loss=0.018942217575386167
Online_Training [298/700]: mean_loss=0.011383434641174972
Online_Training [299/700]: mean_loss=0.01808900642208755
Online_Training [300/700]: mean_loss=0.03607264719903469
Online_Training [301/700]: mean_loss=0.016426611109636724
Online_Training [302/700]: mean_loss=0.01696219388395548
Online_Training [303/700]: mean_loss=0.024672612780705094
Online_Training [304/700]: mean_loss=0.011869731126353145
Online_Training [305/700]: mean_loss=0.05301856668666005
Online_Training [306/700]: mean_loss=0.0643373392522335
Online_Training [307/700]: mean_loss=0.07100971043109894
Online_Training [308/700]: mean_loss=0.023610658943653107
Online_Training [309/700]: mean_loss=0.013300716411322355
Online_Training [310/700]: mean_loss=0.00824196613393724
Online_Training [311/700]: mean_loss=0.01291795913130045
Online_Training [312/700]: mean_loss=0.05250054411590099
Online_Training [313/700]: mean_loss=0.017640241887420416
Online_Training [314/700]: mean_loss=0.011697459383867681
Online_Training [315/700]: mean_loss=0.008495298854541034
Online_Training [316/700]: mean_loss=0.017780354944989085
Online_Training [317/700]: mean_loss=0.008481024822685868
Online_Training [318/700]: mean_loss=0.01869842247106135
Online_Training [319/700]: mean_loss=0.029437470017001033
Online_Training [320/700]: mean_loss=0.009242351225111634
Online_Training [321/700]: mean_loss=0.019663091516122222
Online_Training [322/700]: mean_loss=0.030680681578814983
Online_Training [323/700]: mean_loss=0.01941859722137451
Online_Training [324/700]: mean_loss=0.024852909613400698
Online_Training [325/700]: mean_loss=0.02957139676436782
Online_Training [326/700]: mean_loss=0.012032552738673985
Online_Training [327/700]: mean_loss=0.02316752541810274
Online_Training [328/700]: mean_loss=0.022068943129852414
Online_Training [329/700]: mean_loss=0.012403385830111802
Online_Training [330/700]: mean_loss=0.023113876581192017
Online_Training [331/700]: mean_loss=0.022853016387671232
Online_Training [332/700]: mean_loss=0.02558859554119408
Online_Training [333/700]: mean_loss=0.009178175474517047
Online_Training [334/700]: mean_loss=0.01007479673717171
Online_Training [335/700]: mean_loss=0.06423520063981414
Online_Training [336/700]: mean_loss=0.06112663308158517
Online_Training [337/700]: mean_loss=0.08530022948980331
Online_Training [338/700]: mean_loss=0.021049130242317915
Online_Training [339/700]: mean_loss=0.01069344871211797
Online_Training [340/700]: mean_loss=0.00807233084924519
Online_Training [341/700]: mean_loss=0.023147386964410543
Online_Training [342/700]: mean_loss=0.05166525160893798
Online_Training [343/700]: mean_loss=0.010859825182706118
Online_Training [344/700]: mean_loss=0.020351430168375373
Online_Training [345/700]: mean_loss=0.035086840856820345
Online_Training [346/700]: mean_loss=0.02420276263728738
Online_Training [347/700]: mean_loss=0.12362622749060392
Online_Training [348/700]: mean_loss=0.022218834375962615
Online_Training [349/700]: mean_loss=0.03130358434282243
Online_Training [350/700]: mean_loss=0.01324076286982745
Online_Training [351/700]: mean_loss=0.013957513147033751
Online_Training [352/700]: mean_loss=0.017341562430374324
Online_Training [353/700]: mean_loss=0.011426621698774397
Online_Training [354/700]: mean_loss=0.026514004915952682
Online_Training [355/700]: mean_loss=0.016997680999338627
Online_Training [356/700]: mean_loss=0.01950060552917421
Online_Training [357/700]: mean_loss=0.09019490424543619
Online_Training [358/700]: mean_loss=0.0687905210070312
Online_Training [359/700]: mean_loss=0.09295248053967953
Online_Training [360/700]: mean_loss=0.026165169896557927
Online_Training [361/700]: mean_loss=0.025467836996540427
Online_Training [362/700]: mean_loss=0.0484940898604691
Online_Training [363/700]: mean_loss=0.01721957977861166
Online_Training [364/700]: mean_loss=0.010020927176810801
Online_Training [365/700]: mean_loss=0.018023301614448428
Online_Training [366/700]: mean_loss=0.03371116332709789
Online_Training [367/700]: mean_loss=0.022541875252500176
Online_Training [368/700]: mean_loss=0.015749118058010936
Online_Training [369/700]: mean_loss=0.014183745021000504
Online_Training [370/700]: mean_loss=0.035403027664870024
Online_Training [371/700]: mean_loss=0.007102061063051224
Online_Training [372/700]: mean_loss=0.02212243853136897
Online_Training [373/700]: mean_loss=0.017119498690590262
Online_Training [374/700]: mean_loss=0.015063717379234731
Online_Training [375/700]: mean_loss=0.01873924513347447
Online_Training [376/700]: mean_loss=0.00815702328691259
Online_Training [377/700]: mean_loss=0.017886341782286763
Online_Training [378/700]: mean_loss=0.012009849306195974
Online_Training [379/700]: mean_loss=0.01735124457627535
Online_Training [380/700]: mean_loss=0.011705914745107293
Online_Training [381/700]: mean_loss=0.02240696013905108
Online_Training [382/700]: mean_loss=0.012344736547674984
Online_Training [383/700]: mean_loss=0.008197216782718897
Online_Training [384/700]: mean_loss=0.11653695348650217
Online_Training [385/700]: mean_loss=0.007966279750689864
Online_Training [386/700]: mean_loss=0.02742792060598731
Online_Training [387/700]: mean_loss=0.022174475016072392
Online_Training [388/700]: mean_loss=0.025008152006193995
Online_Training [389/700]: mean_loss=0.008562810253351927
Online_Training [390/700]: mean_loss=0.025770980399101973
Online_Training [391/700]: mean_loss=0.01000667316839099
Online_Training [392/700]: mean_loss=0.023796226363629103
Online_Training [393/700]: mean_loss=0.015523954993113875
Online_Training [394/700]: mean_loss=0.024909591767936945
Online_Training [395/700]: mean_loss=0.009768497897312045
Online_Training [396/700]: mean_loss=0.021368495654314756
Online_Training [397/700]: mean_loss=0.011265271925367415
Online_Training [398/700]: mean_loss=0.01826006080955267
Online_Training [399/700]: mean_loss=0.01932015107013285
Online_Training [400/700]: mean_loss=0.023605318274348974
Online_Training [401/700]: mean_loss=0.015096337418071926
Online_Training [402/700]: mean_loss=0.015411220956593752
Online_Training [403/700]: mean_loss=0.017753299209289253
Online_Training [404/700]: mean_loss=0.0659966841340065
Online_Training [405/700]: mean_loss=0.07151502324268222
Online_Training [406/700]: mean_loss=0.024238136829808354
Online_Training [407/700]: mean_loss=0.02991634141653776
Online_Training [408/700]: mean_loss=0.020218431251123548
Online_Training [409/700]: mean_loss=0.008238724782131612
Online_Training [410/700]: mean_loss=0.019837375497445464
Online_Training [411/700]: mean_loss=0.024745964910835028
Online_Training [412/700]: mean_loss=0.11552583053708076
Online_Training [413/700]: mean_loss=0.04336488666012883
Online_Training [414/700]: mean_loss=0.047703235410153866
Online_Training [415/700]: mean_loss=0.022841228172183037
Online_Training [416/700]: mean_loss=0.0199171113781631
Online_Training [417/700]: mean_loss=0.05889760749414563
Online_Training [418/700]: mean_loss=0.01199773175176233
Online_Training [419/700]: mean_loss=0.010515795438550413
Online_Training [420/700]: mean_loss=0.04940070956945419
Online_Training [421/700]: mean_loss=0.02920190547592938
Online_Training [422/700]: mean_loss=0.01904735225252807
Online_Training [423/700]: mean_loss=0.03444040520116687
Online_Training [424/700]: mean_loss=0.05505403224378824
Online_Training [425/700]: mean_loss=0.023551662219688296
Online_Training [426/700]: mean_loss=0.01028544339351356
Online_Training [427/700]: mean_loss=0.016733500291593373
Online_Training [428/700]: mean_loss=0.028054540511220694
Online_Training [429/700]: mean_loss=0.013093244517222047
Online_Training [430/700]: mean_loss=0.008570720150601119
Online_Training [431/700]: mean_loss=0.011716606793925166
Online_Training [432/700]: mean_loss=0.06947649782523513
Online_Training [433/700]: mean_loss=0.019502934766933322
Online_Training [434/700]: mean_loss=0.019341302337124944
Online_Training [435/700]: mean_loss=0.01589615468401462
Online_Training [436/700]: mean_loss=0.05296272458508611
Online_Training [437/700]: mean_loss=0.01446550979744643
Online_Training [438/700]: mean_loss=0.12965682707726955
Online_Training [439/700]: mean_loss=0.06811486883088946
Online_Training [440/700]: mean_loss=0.03375938511453569
Online_Training [441/700]: mean_loss=0.045738411601632833
Online_Training [442/700]: mean_loss=0.005791258125100285
Online_Training [443/700]: mean_loss=0.016178278485313058
Online_Training [444/700]: mean_loss=0.03344457340426743
Online_Training [445/700]: mean_loss=0.01963481237180531
Online_Training [446/700]: mean_loss=0.021442047553136945
Online_Training [447/700]: mean_loss=0.010029667406342924
Online_Training [448/700]: mean_loss=0.024107831995934248
Online_Training [449/700]: mean_loss=0.020441539119929075
Online_Training [450/700]: mean_loss=0.033660366432741284
Online_Training [451/700]: mean_loss=0.023987548891454935
Online_Training [452/700]: mean_loss=0.03675365447998047
Online_Training [453/700]: mean_loss=0.06351546524092555
Online_Training [454/700]: mean_loss=0.017287405906245112
Online_Training [455/700]: mean_loss=0.05492222402244806
Online_Training [456/700]: mean_loss=0.01472792832646519
Online_Training [457/700]: mean_loss=0.007737293839454651
Online_Training [458/700]: mean_loss=0.008239288174081594
Online_Training [459/700]: mean_loss=0.011287088738754392
Online_Training [460/700]: mean_loss=0.016477033379487693
Online_Training [461/700]: mean_loss=0.02643668372184038
Online_Training [462/700]: mean_loss=0.010750331450253725
Online_Training [463/700]: mean_loss=0.004154007066972554
Online_Training [464/700]: mean_loss=0.016910610836930573
Online_Training [465/700]: mean_loss=0.0706822881475091
Online_Training [466/700]: mean_loss=0.02203353284858167
Online_Training [467/700]: mean_loss=0.015380369848571718
Online_Training [468/700]: mean_loss=0.018067591241560876
Online_Training [469/700]: mean_loss=0.020879460498690605
Online_Training [470/700]: mean_loss=0.06290369853377342
Online_Training [471/700]: mean_loss=0.0191915612667799
Online_Training [472/700]: mean_loss=0.034791722195222974
Online_Training [473/700]: mean_loss=0.006017900363076478
Online_Training [474/700]: mean_loss=0.011049507069401443
Online_Training [475/700]: mean_loss=0.00902905932161957
Online_Training [476/700]: mean_loss=0.17763590067625046
Online_Training [477/700]: mean_loss=0.0990409879013896
Online_Training [478/700]: mean_loss=0.0419844021089375
Online_Training [479/700]: mean_loss=0.012699243845418096
Online_Training [480/700]: mean_loss=0.0100765828974545
Online_Training [481/700]: mean_loss=0.013789257500320673
Online_Training [482/700]: mean_loss=0.02414969145320356
Online_Training [483/700]: mean_loss=0.016975981765426695
Online_Training [484/700]: mean_loss=0.015492638107389212
Online_Training [485/700]: mean_loss=0.007902147190179676
Online_Training [486/700]: mean_loss=0.01819723192602396
Online_Training [487/700]: mean_loss=0.03632419975474477
Online_Training [488/700]: mean_loss=0.020579796517267823
Online_Training [489/700]: mean_loss=0.016561285825446248
Online_Training [490/700]: mean_loss=0.01682393066585064
Online_Training [491/700]: mean_loss=0.0365497013553977
Online_Training [492/700]: mean_loss=0.013753411010839045
Online_Training [493/700]: mean_loss=0.015098953619599342
Online_Training [494/700]: mean_loss=0.05938256485387683
Online_Training [495/700]: mean_loss=0.0077026496874168515
Online_Training [496/700]: mean_loss=0.02448017429560423
Online_Training [497/700]: mean_loss=0.017636214499361813
Online_Training [498/700]: mean_loss=0.013303360319696367
Online_Training [499/700]: mean_loss=0.018112602178007364
Online_Training [500/700]: mean_loss=0.008372361306101084
Online_Training [501/700]: mean_loss=0.012946263188496232
Online_Training [502/700]: mean_loss=0.015119563322514296
Online_Training [503/700]: mean_loss=0.01679064950440079
Online_Training [504/700]: mean_loss=0.007249423651956022
Online_Training [505/700]: mean_loss=0.014228723477572203
Online_Training [506/700]: mean_loss=0.10739767272025347
Online_Training [507/700]: mean_loss=0.10857436526566744
Online_Training [508/700]: mean_loss=0.026044807163998485
Online_Training [509/700]: mean_loss=0.016832603607326746
Online_Training [510/700]: mean_loss=0.021785954711958766
Online_Training [511/700]: mean_loss=0.004205486591672525
Online_Training [512/700]: mean_loss=0.007781524094752967
Online_Training [513/700]: mean_loss=0.03911729040555656
Online_Training [514/700]: mean_loss=0.021075436612591147
Online_Training [515/700]: mean_loss=0.032771535916253924
Online_Training [516/700]: mean_loss=0.020371175603941083
Online_Training [517/700]: mean_loss=0.030907632317394018
Online_Training [518/700]: mean_loss=0.018994823563843966
Online_Training [519/700]: mean_loss=0.007777090359013528
Online_Training [520/700]: mean_loss=0.009986228309571743
Online_Training [521/700]: mean_loss=0.03205724200233817
Online_Training [522/700]: mean_loss=0.013426205841824412
Online_Training [523/700]: mean_loss=0.021859079599380493
Online_Training [524/700]: mean_loss=0.08072726614773273
Online_Training [525/700]: mean_loss=0.02589834202080965
Online_Training [526/700]: mean_loss=0.012938042404130101
Online_Training [527/700]: mean_loss=0.017812080681324005
Online_Training [528/700]: mean_loss=0.02247492875903845
Online_Training [529/700]: mean_loss=0.030756597639992833
Online_Training [530/700]: mean_loss=0.01838441879954189
Online_Training [531/700]: mean_loss=0.012742001796141267
Online_Training [532/700]: mean_loss=0.02477377583272755
Online_Training [533/700]: mean_loss=0.012259902316145599
Online_Training [534/700]: mean_loss=0.01175337890163064
Online_Training [535/700]: mean_loss=0.02870560111477971
Online_Training [536/700]: mean_loss=0.10408447217196226
Online_Training [537/700]: mean_loss=0.009995750267989933
Online_Training [538/700]: mean_loss=0.014462955412454903
Online_Training [539/700]: mean_loss=0.006743559322785586
Online_Training [540/700]: mean_loss=0.042465902864933014
Online_Training [541/700]: mean_loss=0.1133728502318263
Online_Training [542/700]: mean_loss=0.009431762737222016
Online_Training [543/700]: mean_loss=0.03100462257862091
Online_Training [544/700]: mean_loss=0.011725724209100008
Online_Training [545/700]: mean_loss=0.023890068754553795
Online_Training [546/700]: mean_loss=0.009298091637901962
Online_Training [547/700]: mean_loss=0.025829805061221123
Online_Training [548/700]: mean_loss=0.02528880536556244
Online_Training [549/700]: mean_loss=0.00672068219864741
Online_Training [550/700]: mean_loss=0.014538974734023213
Online_Training [551/700]: mean_loss=0.01564311806578189
Online_Training [552/700]: mean_loss=0.029490993358194828
Online_Training [553/700]: mean_loss=0.03620428475551307
Online_Training [554/700]: mean_loss=0.0247203775215894
Online_Training [555/700]: mean_loss=0.023512615356594324
Online_Training [556/700]: mean_loss=0.01867274707183242
Online_Training [557/700]: mean_loss=0.01536393293645233
Online_Training [558/700]: mean_loss=0.0061030955403111875
Online_Training [559/700]: mean_loss=0.002554368111304939
Online_Training [560/700]: mean_loss=0.008210695057641715
Online_Training [561/700]: mean_loss=0.01954423845745623
Online_Training [562/700]: mean_loss=0.03514523897320032
Online_Training [563/700]: mean_loss=0.04345384240150452
Online_Training [564/700]: mean_loss=0.012666808324865997
Online_Training [565/700]: mean_loss=0.019957460463047028
Online_Training [566/700]: mean_loss=0.015693467226810753
Online_Training [567/700]: mean_loss=0.03571231593377888
Online_Training [568/700]: mean_loss=0.018279360607266426
Online_Training [569/700]: mean_loss=0.026139568304643035
Online_Training [570/700]: mean_loss=0.0127661416772753
Online_Training [571/700]: mean_loss=0.02578307525254786
Online_Training [572/700]: mean_loss=0.01649586227722466
Online_Training [573/700]: mean_loss=0.024704763665795326
Online_Training [574/700]: mean_loss=0.047729681711643934
Online_Training [575/700]: mean_loss=0.054066955111920834
Online_Training [576/700]: mean_loss=0.012942136963829398
Online_Training [577/700]: mean_loss=0.017414373345673084
Online_Training [578/700]: mean_loss=0.008335551712661982
Online_Training [579/700]: mean_loss=0.019548945827409625
Online_Training [580/700]: mean_loss=0.0340910404920578
Online_Training [581/700]: mean_loss=0.013014781754463911
Online_Training [582/700]: mean_loss=0.007114114239811897
Online_Training [583/700]: mean_loss=0.005557318567298353
Online_Training [584/700]: mean_loss=0.016355081112124026
Online_Training [585/700]: mean_loss=0.024687373312190175
Online_Training [586/700]: mean_loss=0.10561274457722902
Online_Training [587/700]: mean_loss=0.022381777642294765
Online_Training [588/700]: mean_loss=0.009372301865369081
Online_Training [589/700]: mean_loss=0.02131827804259956
Online_Training [590/700]: mean_loss=0.030007795663550496
Online_Training [591/700]: mean_loss=0.015365845058113337
Online_Training [592/700]: mean_loss=0.014419192681089044
Online_Training [593/700]: mean_loss=0.043502382934093475
Online_Training [594/700]: mean_loss=0.010672197677195072
Online_Training [595/700]: mean_loss=0.031731895403936505
Online_Training [596/700]: mean_loss=0.011192845995537937
Online_Training [597/700]: mean_loss=0.01009276625700295
Online_Training [598/700]: mean_loss=0.013574526295997202
Online_Training [599/700]: mean_loss=0.017632150324061513
Online_Training [600/700]: mean_loss=0.013385219732299447
Online_Training [601/700]: mean_loss=0.03137392085045576
Online_Training [602/700]: mean_loss=0.008394402277190238
Online_Training [603/700]: mean_loss=0.009321929886937141
Online_Training [604/700]: mean_loss=0.0298331284429878
Online_Training [605/700]: mean_loss=0.010469535947777331
Online_Training [606/700]: mean_loss=0.0084657579427585
Online_Training [607/700]: mean_loss=0.010873309918679297
Online_Training [608/700]: mean_loss=0.011536412639543414
Online_Training [609/700]: mean_loss=0.0145555465715006
Online_Training [610/700]: mean_loss=0.018567894119769335
Online_Training [611/700]: mean_loss=0.011434436892159283
Online_Training [612/700]: mean_loss=0.13089200016111135
Online_Training [613/700]: mean_loss=0.06277168728411198
Online_Training [614/700]: mean_loss=0.008504759869538248
Online_Training [615/700]: mean_loss=0.00967630639206618
Online_Training [616/700]: mean_loss=0.01806282834149897
Online_Training [617/700]: mean_loss=0.0066986618912778795
Online_Training [618/700]: mean_loss=0.02247560047544539
Online_Training [619/700]: mean_loss=0.012757553602568805
Online_Training [620/700]: mean_loss=0.060640867333859205
Online_Training [621/700]: mean_loss=0.0075214923126623034
Online_Training [622/700]: mean_loss=0.04741687094792724
Online_Training [623/700]: mean_loss=0.031172178452834487
Online_Training [624/700]: mean_loss=0.01563243311829865
Online_Training [625/700]: mean_loss=0.010854327818378806
Online_Training [626/700]: mean_loss=0.011199216940440238
Online_Training [627/700]: mean_loss=0.008490853128023446
Online_Training [628/700]: mean_loss=0.011391738429665565
Online_Training [629/700]: mean_loss=0.01716623129323125
Online_Training [630/700]: mean_loss=0.0425111074000597
Online_Training [631/700]: mean_loss=0.01563572243321687
Online_Training [632/700]: mean_loss=0.02801090106368065
Online_Training [633/700]: mean_loss=0.009966442827135324
Online_Training [634/700]: mean_loss=0.015142360236495733
Online_Training [635/700]: mean_loss=0.018692727433517575
Online_Training [636/700]: mean_loss=0.007221581065095961
Online_Training [637/700]: mean_loss=0.013206660747528076
Online_Training [638/700]: mean_loss=0.018327869474887848
Online_Training [639/700]: mean_loss=0.017340903053991497
Online_Training [640/700]: mean_loss=0.006910235737450421
Online_Training [641/700]: mean_loss=0.02013413794338703
Online_Training [642/700]: mean_loss=0.011155077838338912
Online_Training [643/700]: mean_loss=0.005542251106817275
Online_Training [644/700]: mean_loss=0.005130212171934545
Online_Training [645/700]: mean_loss=0.014248272636905313
Online_Training [646/700]: mean_loss=0.03320588660426438
Online_Training [647/700]: mean_loss=0.010801391559652984
Online_Training [648/700]: mean_loss=0.014247440034523606
Online_Training [649/700]: mean_loss=0.009013651870191097
Online_Training [650/700]: mean_loss=0.014418681268580258
Online_Training [651/700]: mean_loss=0.007848243927583098
Online_Training [652/700]: mean_loss=0.011324844905175269
Online_Training [653/700]: mean_loss=0.1024270923808217
Online_Training [654/700]: mean_loss=0.016350765712559223
Online_Training [655/700]: mean_loss=0.015875192591920495
Online_Training [656/700]: mean_loss=0.018762160558253527
Online_Training [657/700]: mean_loss=0.03055811021476984
Online_Training [658/700]: mean_loss=0.012372511206194758
Online_Training [659/700]: mean_loss=0.011549428221769631
Online_Training [660/700]: mean_loss=0.01328483852557838
Online_Training [661/700]: mean_loss=0.0404907763004303
Online_Training [662/700]: mean_loss=0.06327201519161463
Online_Training [663/700]: mean_loss=0.02296769293025136
Online_Training [664/700]: mean_loss=0.006336824735626578
Online_Training [665/700]: mean_loss=0.04366919305175543
Online_Training [666/700]: mean_loss=0.029827795922756195
Online_Training [667/700]: mean_loss=0.006293012120295316
Online_Training [668/700]: mean_loss=0.009738836903125048
Online_Training [669/700]: mean_loss=0.007622130971867591
Online_Training [670/700]: mean_loss=0.012840139213949442
Online_Training [671/700]: mean_loss=0.01935289753600955
Online_Training [672/700]: mean_loss=0.014624389237724245
Online_Training [673/700]: mean_loss=0.011512030498124659
Online_Training [674/700]: mean_loss=0.013969959458336234
Online_Training [675/700]: mean_loss=0.0152804417302832
Online_Training [676/700]: mean_loss=0.03278516186401248
Online_Training [677/700]: mean_loss=0.046546284575015306
Online_Training [678/700]: mean_loss=0.02138491766527295
Online_Training [679/700]: mean_loss=0.023608874063938856
Online_Training [680/700]: mean_loss=0.005898005503695458
Online_Training [681/700]: mean_loss=0.021336145233362913
Online_Training [682/700]: mean_loss=0.013332956237718463
Online_Training [683/700]: mean_loss=0.00745732372161001
Online_Training [684/700]: mean_loss=0.00724223128054291
Online_Training [685/700]: mean_loss=0.026870257453992963
Online_Training [686/700]: mean_loss=0.012131735333241522
Online_Training [687/700]: mean_loss=0.0211413218639791
Online_Training [688/700]: mean_loss=0.05435153562575579
Online_Training [689/700]: mean_loss=0.013564573368057609
Online_Training [690/700]: mean_loss=0.007984183146618307
Online_Training [691/700]: mean_loss=0.010318619897589087
Online_Training [692/700]: mean_loss=0.025092485826462507
Online_Training [693/700]: mean_loss=0.00962204858660698
Online_Training [694/700]: mean_loss=0.03399377246387303
Online_Training [695/700]: mean_loss=0.013879340258426964
Online_Training [696/700]: mean_loss=0.030071418965235353
Online_Training [697/700]: mean_loss=0.0031926022202242166
Online_Training [698/700]: mean_loss=0.004493487940635532
Online_Training [699/700]: mean_loss=0.04988715099170804
Online_Training [700/700]: mean_loss=0.008505795849487185
Q_Learning [1/300]: mean_loss=0.1895903293043375
Q_Learning [2/300]: mean_loss=0.2467041015625
Q_Learning [3/300]: mean_loss=0.21693621389567852
Q_Learning [4/300]: mean_loss=0.07338020671159029
Q_Learning [5/300]: mean_loss=0.2605546601116657
Q_Learning [6/300]: mean_loss=0.11347876861691475
Q_Learning [7/300]: mean_loss=0.14744226820766926
Q_Learning [8/300]: mean_loss=0.06867936346679926
Q_Learning [9/300]: mean_loss=0.2142276782542467
Q_Learning [10/300]: mean_loss=0.1317233219742775
Q_Learning [11/300]: mean_loss=0.08285926189273596
Q_Learning [12/300]: mean_loss=0.07985638454556465
Q_Learning [13/300]: mean_loss=0.07466005627065897
Q_Learning [14/300]: mean_loss=0.06931501999497414
Q_Learning [15/300]: mean_loss=0.05520763387903571
Q_Learning [16/300]: mean_loss=0.13015847094357014
Q_Learning [17/300]: mean_loss=0.15417707152664661
Q_Learning [18/300]: mean_loss=0.09887586254626513
Q_Learning [19/300]: mean_loss=0.03836151398718357
Q_Learning [20/300]: mean_loss=0.19060741364955902
Q_Learning [21/300]: mean_loss=0.13185076788067818
Q_Learning [22/300]: mean_loss=0.07240475993603468
Q_Learning [23/300]: mean_loss=0.03591492376290262
Q_Learning [24/300]: mean_loss=0.09404979553073645
Q_Learning [25/300]: mean_loss=0.04757803678512573
Q_Learning [26/300]: mean_loss=0.07671214360743761
Q_Learning [27/300]: mean_loss=0.09620349854230881
Q_Learning [28/300]: mean_loss=0.06480872677639127
Q_Learning [29/300]: mean_loss=0.04912357032299042
Q_Learning [30/300]: mean_loss=0.0344541035592556
Q_Learning [31/300]: mean_loss=0.030175609281286597
Q_Learning [32/300]: mean_loss=0.048608620185405016
Q_Learning [33/300]: mean_loss=0.02409054897725582
Q_Learning [34/300]: mean_loss=0.20444980822503567
Q_Learning [35/300]: mean_loss=0.06442699488252401
Q_Learning [36/300]: mean_loss=0.09392751473933458
Q_Learning [37/300]: mean_loss=0.07017509220167994
Q_Learning [38/300]: mean_loss=0.04329793993383646
Q_Learning [39/300]: mean_loss=0.13884173706173897
Q_Learning [40/300]: mean_loss=0.027160761412233114
Q_Learning [41/300]: mean_loss=0.03885328723117709
Q_Learning [42/300]: mean_loss=0.05700618866831064
Q_Learning [43/300]: mean_loss=0.13120346516370773
Q_Learning [44/300]: mean_loss=0.15305098332464695
Q_Learning [45/300]: mean_loss=0.1100233206525445
Q_Learning [46/300]: mean_loss=0.07949479576200247
Q_Learning [47/300]: mean_loss=0.10357826109975576
Q_Learning [48/300]: mean_loss=0.06784848030656576
Q_Learning [49/300]: mean_loss=0.1062292717397213
Q_Learning [50/300]: mean_loss=0.11871081963181496
Q_Learning [51/300]: mean_loss=0.039867434184998274
Q_Learning [52/300]: mean_loss=0.17131741158664227
Q_Learning [53/300]: mean_loss=0.03864911384880543
Q_Learning [54/300]: mean_loss=0.09649469889700413
Q_Learning [55/300]: mean_loss=0.0896864477545023
Q_Learning [56/300]: mean_loss=0.03600984998047352
Q_Learning [57/300]: mean_loss=0.12106274627149105
Q_Learning [58/300]: mean_loss=0.20995546132326126
Q_Learning [59/300]: mean_loss=0.09199123596772552
Q_Learning [60/300]: mean_loss=0.050028592348098755
Q_Learning [61/300]: mean_loss=0.028678842587396502
Q_Learning [62/300]: mean_loss=0.09705209266394377
Q_Learning [63/300]: mean_loss=0.052660523913800716
Q_Learning [64/300]: mean_loss=0.004988527332898229
Q_Learning [65/300]: mean_loss=0.05500885518267751
Q_Learning [66/300]: mean_loss=0.03592481929808855
Q_Learning [67/300]: mean_loss=0.06253271643072367
Q_Learning [68/300]: mean_loss=0.03198270220309496
Q_Learning [69/300]: mean_loss=0.07862639287486672
Q_Learning [70/300]: mean_loss=0.03936920780688524
Q_Learning [71/300]: mean_loss=0.08287644572556019
Q_Learning [72/300]: mean_loss=0.0743930684402585
Q_Learning [73/300]: mean_loss=0.041684530675411224
Q_Learning [74/300]: mean_loss=0.040034613106399775
Q_Learning [75/300]: mean_loss=0.024304028833284974
Q_Learning [76/300]: mean_loss=0.03593753697350621
Q_Learning [77/300]: mean_loss=0.03326807077974081
Q_Learning [78/300]: mean_loss=0.030134549597278237
Q_Learning [79/300]: mean_loss=0.03961094003170729
Q_Learning [80/300]: mean_loss=0.03553447453305125
Q_Learning [81/300]: mean_loss=0.01781692646909505
Q_Learning [82/300]: mean_loss=0.030443146592006087
Q_Learning [83/300]: mean_loss=0.028484667651355267
Q_Learning [84/300]: mean_loss=0.03286669170483947
Q_Learning [85/300]: mean_loss=0.024356221314519644
Q_Learning [86/300]: mean_loss=0.035165545996278524
Q_Learning [87/300]: mean_loss=0.018259948818013072
Q_Learning [88/300]: mean_loss=0.024626733269542456
Q_Learning [89/300]: mean_loss=0.04334089299663901
Q_Learning [90/300]: mean_loss=0.02006463147699833
Q_Learning [91/300]: mean_loss=0.030955958180129528
Q_Learning [92/300]: mean_loss=0.033142253290861845
Q_Learning [93/300]: mean_loss=0.025630449410527945
Q_Learning [94/300]: mean_loss=0.04051772691309452
Q_Learning [95/300]: mean_loss=0.030628161504864693
Q_Learning [96/300]: mean_loss=0.01999684004113078
Q_Learning [97/300]: mean_loss=0.038704012986272573
Q_Learning [98/300]: mean_loss=0.04358638543635607
Q_Learning [99/300]: mean_loss=0.022000011056661606
Q_Learning [100/300]: mean_loss=0.04268283769488335
Q_Learning [101/300]: mean_loss=0.018299604067578912
Q_Learning [102/300]: mean_loss=0.05808372749015689
Q_Learning [103/300]: mean_loss=0.04166980180889368
Q_Learning [104/300]: mean_loss=0.03245160961523652
Q_Learning [105/300]: mean_loss=0.03893128223717213
Q_Learning [106/300]: mean_loss=0.019788875244557858
Q_Learning [107/300]: mean_loss=0.019995275884866714
Q_Learning [108/300]: mean_loss=0.0315719919744879
Q_Learning [109/300]: mean_loss=0.029645623406395316
Q_Learning [110/300]: mean_loss=0.025926943169906735
Q_Learning [111/300]: mean_loss=0.0286777731962502
Q_Learning [112/300]: mean_loss=0.14592140819877386
Q_Learning [113/300]: mean_loss=0.018127736635506153
Q_Learning [114/300]: mean_loss=0.029307556804269552
Q_Learning [115/300]: mean_loss=0.03955031372606754
Q_Learning [116/300]: mean_loss=0.02390407328493893
Q_Learning [117/300]: mean_loss=0.05432693986222148
Q_Learning [118/300]: mean_loss=0.04263154091313481
Q_Learning [119/300]: mean_loss=0.14001471363008022
Q_Learning [120/300]: mean_loss=0.053569482173770666
Q_Learning [121/300]: mean_loss=0.050166061613708735
Q_Learning [122/300]: mean_loss=0.05727423680946231
Q_Learning [123/300]: mean_loss=0.03597107622772455
Q_Learning [124/300]: mean_loss=0.011557184625416994
Q_Learning [125/300]: mean_loss=0.06440499471500516
Q_Learning [126/300]: mean_loss=0.04354993859305978
Q_Learning [127/300]: mean_loss=0.03573634289205074
Q_Learning [128/300]: mean_loss=0.028647811384871602
Q_Learning [129/300]: mean_loss=0.034192024264484644
Q_Learning [130/300]: mean_loss=0.018993720412254333
Q_Learning [131/300]: mean_loss=0.019762893905863166
Q_Learning [132/300]: mean_loss=0.0183438885724172
Q_Learning [133/300]: mean_loss=0.02467755228281021
Q_Learning [134/300]: mean_loss=0.014695225399918854
Q_Learning [135/300]: mean_loss=0.10874307341873646
Q_Learning [136/300]: mean_loss=0.017576622776687145
Q_Learning [137/300]: mean_loss=0.01868321537040174
Q_Learning [138/300]: mean_loss=0.012252305285073817
Q_Learning [139/300]: mean_loss=0.0190535387955606
Q_Learning [140/300]: mean_loss=0.02937873685732484
Q_Learning [141/300]: mean_loss=0.03182143229059875
Q_Learning [142/300]: mean_loss=0.016560910502448678
Q_Learning [143/300]: mean_loss=0.02205818798393011
Q_Learning [144/300]: mean_loss=0.011436300002969801
Q_Learning [145/300]: mean_loss=0.038886052556335926
Q_Learning [146/300]: mean_loss=0.022018922260031104
Q_Learning [147/300]: mean_loss=0.01686536252964288
Q_Learning [148/300]: mean_loss=0.034039369551464915
Q_Learning [149/300]: mean_loss=0.06695819040760398
Q_Learning [150/300]: mean_loss=0.06132041243836284
Q_Learning [151/300]: mean_loss=0.024505740497261286
Q_Learning [152/300]: mean_loss=0.01617810723837465
Q_Learning [153/300]: mean_loss=0.02817039331421256
Q_Learning [154/300]: mean_loss=0.02579850982874632
Q_Learning [155/300]: mean_loss=0.01096313341986388
Q_Learning [156/300]: mean_loss=0.02103390754200518
Q_Learning [157/300]: mean_loss=0.14083343837410212
Q_Learning [158/300]: mean_loss=0.006923933688085526
Q_Learning [159/300]: mean_loss=0.027692341711372137
Q_Learning [160/300]: mean_loss=0.02379388501867652
Q_Learning [161/300]: mean_loss=0.03096781112253666
Q_Learning [162/300]: mean_loss=0.014210239285603166
Q_Learning [163/300]: mean_loss=0.05736538115888834
Q_Learning [164/300]: mean_loss=0.014940239954739809
Q_Learning [165/300]: mean_loss=0.010815372690558434
Q_Learning [166/300]: mean_loss=0.017925090272910893
Q_Learning [167/300]: mean_loss=0.03797804517671466
Q_Learning [168/300]: mean_loss=0.032141632633283734
Q_Learning [169/300]: mean_loss=0.05728799384087324
Q_Learning [170/300]: mean_loss=0.17343797534704208
Q_Learning [171/300]: mean_loss=0.011879471829161048
Q_Learning [172/300]: mean_loss=0.015280407504178584
Q_Learning [173/300]: mean_loss=0.02830288652330637
Q_Learning [174/300]: mean_loss=0.014708562870509923
Q_Learning [175/300]: mean_loss=0.011415913118980825
Q_Learning [176/300]: mean_loss=0.006650502094998956
Q_Learning [177/300]: mean_loss=0.02756109624169767
Q_Learning [178/300]: mean_loss=0.04145605722442269
Q_Learning [179/300]: mean_loss=0.01831407123245299
Q_Learning [180/300]: mean_loss=0.020175544545054436
Q_Learning [181/300]: mean_loss=0.02390630287118256
Q_Learning [182/300]: mean_loss=0.033152695978060365
Q_Learning [183/300]: mean_loss=0.012402264052070677
Q_Learning [184/300]: mean_loss=0.004220265487674624
Q_Learning [185/300]: mean_loss=0.02869934239424765
Q_Learning [186/300]: mean_loss=0.032864436972886324
Q_Learning [187/300]: mean_loss=0.028433554340153933
Q_Learning [188/300]: mean_loss=0.018309989594854414
Q_Learning [189/300]: mean_loss=0.0561166713014245
Q_Learning [190/300]: mean_loss=0.02714362437836826
Q_Learning [191/300]: mean_loss=0.14899923466145992
Q_Learning [192/300]: mean_loss=0.025480461306869984
Q_Learning [193/300]: mean_loss=0.02148122852668166
Q_Learning [194/300]: mean_loss=0.01318039686884731
Q_Learning [195/300]: mean_loss=0.025652113370597363
Q_Learning [196/300]: mean_loss=0.013170978636480868
Q_Learning [197/300]: mean_loss=0.03811882669106126
Q_Learning [198/300]: mean_loss=0.02166575926821679
Q_Learning [199/300]: mean_loss=0.09232950489968061
Q_Learning [200/300]: mean_loss=0.026309995679184794
Q_Learning [201/300]: mean_loss=0.0359326908364892
Q_Learning [202/300]: mean_loss=0.013341613812372088
Q_Learning [203/300]: mean_loss=0.012476281845010817
Q_Learning [204/300]: mean_loss=0.01377506647258997
Q_Learning [205/300]: mean_loss=0.06294719595462084
Q_Learning [206/300]: mean_loss=0.018552934983745217
Q_Learning [207/300]: mean_loss=0.04064890369772911
Q_Learning [208/300]: mean_loss=0.036691142711788416
Q_Learning [209/300]: mean_loss=0.05231465119868517
Q_Learning [210/300]: mean_loss=0.02988092740997672
Q_Learning [211/300]: mean_loss=0.014376836828887463
Q_Learning [212/300]: mean_loss=0.08989411871880293
Q_Learning [213/300]: mean_loss=0.03441197518259287
Q_Learning [214/300]: mean_loss=0.011389186838641763
Q_Learning [215/300]: mean_loss=0.03527590585872531
Q_Learning [216/300]: mean_loss=0.029182566097006202
Q_Learning [217/300]: mean_loss=0.011440523667261004
Q_Learning [218/300]: mean_loss=0.006819571717642248
Q_Learning [219/300]: mean_loss=0.04660117207095027
Q_Learning [220/300]: mean_loss=0.013576687662862241
Q_Learning [221/300]: mean_loss=0.03178301500156522
Q_Learning [222/300]: mean_loss=0.019140883814543486
Q_Learning [223/300]: mean_loss=0.03098164522089064
Q_Learning [224/300]: mean_loss=0.007682566239964217
Q_Learning [225/300]: mean_loss=0.02907291892915964
Q_Learning [226/300]: mean_loss=0.02806835644878447
Q_Learning [227/300]: mean_loss=0.015560418018139899
Q_Learning [228/300]: mean_loss=0.0222073036711663
Q_Learning [229/300]: mean_loss=0.043821005150675774
Q_Learning [230/300]: mean_loss=0.016688609728589654
Q_Learning [231/300]: mean_loss=0.02004822250455618
Q_Learning [232/300]: mean_loss=0.022971135564148426
Q_Learning [233/300]: mean_loss=0.020362624898552895
Q_Learning [234/300]: mean_loss=0.0396073036827147
Q_Learning [235/300]: mean_loss=0.09915875550359488
Q_Learning [236/300]: mean_loss=0.059517210349440575
Q_Learning [237/300]: mean_loss=0.01836623763665557
Q_Learning [238/300]: mean_loss=0.09560559131205082
Q_Learning [239/300]: mean_loss=0.07239448046311736
Q_Learning [240/300]: mean_loss=0.03634555684402585
Q_Learning [241/300]: mean_loss=0.034549648175016046
Q_Learning [242/300]: mean_loss=0.03223427711054683
Q_Learning [243/300]: mean_loss=0.04120059963315725
Q_Learning [244/300]: mean_loss=0.025606634095311165
Q_Learning [245/300]: mean_loss=0.03835763130337
Q_Learning [246/300]: mean_loss=0.023266951786354184
Q_Learning [247/300]: mean_loss=0.010078839841298759
Q_Learning [248/300]: mean_loss=0.07509126886725426
Q_Learning [249/300]: mean_loss=0.007351602194830775
Q_Learning [250/300]: mean_loss=0.016618333291262388
Q_Learning [251/300]: mean_loss=0.014475699164904654
Q_Learning [252/300]: mean_loss=0.019395496230572462
Q_Learning [253/300]: mean_loss=0.01807345193810761
Q_Learning [254/300]: mean_loss=0.019622469320893288
Q_Learning [255/300]: mean_loss=0.027836377965286374
Q_Learning [256/300]: mean_loss=0.01859089860226959
Q_Learning [257/300]: mean_loss=0.01995526277460158
Q_Learning [258/300]: mean_loss=0.021618521073833108
Q_Learning [259/300]: mean_loss=0.01094713993370533
Q_Learning [260/300]: mean_loss=0.010973568772897124
Q_Learning [261/300]: mean_loss=0.025586003670468926
Q_Learning [262/300]: mean_loss=0.030369487823918462
Q_Learning [263/300]: mean_loss=0.01146344537846744
Q_Learning [264/300]: mean_loss=0.01923596579581499
Q_Learning [265/300]: mean_loss=0.01967715029604733
Q_Learning [266/300]: mean_loss=0.015633242786861956
Q_Learning [267/300]: mean_loss=0.012718014302663505
Q_Learning [268/300]: mean_loss=0.005919334944337606
Q_Learning [269/300]: mean_loss=0.018091914476826787
Q_Learning [270/300]: mean_loss=0.011491925921291113
Q_Learning [271/300]: mean_loss=0.02928773406893015
Q_Learning [272/300]: mean_loss=0.008024282928090543
Q_Learning [273/300]: mean_loss=0.007220822793897241
Q_Learning [274/300]: mean_loss=0.009401925723068416
Q_Learning [275/300]: mean_loss=0.014885009150020778
Q_Learning [276/300]: mean_loss=0.01719969930127263
Q_Learning [277/300]: mean_loss=0.02606169250793755
Q_Learning [278/300]: mean_loss=0.021051509073004127
Q_Learning [279/300]: mean_loss=0.017025106819346547
Q_Learning [280/300]: mean_loss=0.02210504817776382
Q_Learning [281/300]: mean_loss=0.02533464482985437
Q_Learning [282/300]: mean_loss=0.03144270530901849
Q_Learning [283/300]: mean_loss=0.02267412655055523
Q_Learning [284/300]: mean_loss=0.008749037457164377
Q_Learning [285/300]: mean_loss=0.015819068998098373
Q_Learning [286/300]: mean_loss=0.021439043805003166
Q_Learning [287/300]: mean_loss=0.016482569044455886
Q_Learning [288/300]: mean_loss=0.01514725189190358
Q_Learning [289/300]: mean_loss=0.04221686255186796
Q_Learning [290/300]: mean_loss=0.007100993127096444
Q_Learning [291/300]: mean_loss=0.010295285377651453
Q_Learning [292/300]: mean_loss=0.0071697497041895986
Q_Learning [293/300]: mean_loss=0.012551500694826245
Q_Learning [294/300]: mean_loss=0.01327998354099691
Q_Learning [295/300]: mean_loss=0.03368569049052894
Q_Learning [296/300]: mean_loss=0.038656906224787235
Q_Learning [297/300]: mean_loss=0.018942217575386167
Q_Learning [298/300]: mean_loss=0.011383434641174972
Q_Learning [299/300]: mean_loss=0.01808900642208755
Q_Learning [300/300]: mean_loss=0.03607264719903469
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 1.1112493 -1.1433992]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 3, 0, 2, 3, 4, 3, 1, 5, 4, 4, 3, 1, 3, 3, 2, 0, 4, 1, 0, 1, 4, 2, 0, 0, 6, 2, 1, 4, 1, 3, 4, 7, 1, 0, 7, 2, 3, 4, 4, 5, 7, 3, 7, 1, 3, 8, 5, 3, 7, 5, 7, 0, 4, 0, 7, 9, 10, 6, 4, 7, 7, 8, 7, 0, 4, 7, 7, 2, 3, 11, 0, 12, 9, 1, 0, 12, 5, 0, 6, 7, 12, 9, 11, 4, 12, 12, 10, 12, 4, 12, 13, 4, 13, 12, 12, 2, 4, 14, 10, 15, 2, 3, 0, 2, 7, 7, 4, 4, 8, 1, 16, 17, 6, 7, 1, 5, 16, 17, 11, 12, 16, 18, 7, 19, 20, 19, 1, 20, 10, 5, 8, 21, 7, 11, 19, 17, 22, 23, 4, 14, 21, 16, 19, 19, 3, 4, 6, 24, 12, 16, 19, 17, 17, 6, 8, 20, 14, 17, 2, 4, 24, 17, 24, 19, 5, 16, 7, 17, 21, 7, 16, 3, 15, 2, 22, 10, 4, 1, 17, 1, 21, 16, 10, 17, 3, 19, 16, 9, 20, 6, 21, 12, 25, 26, 17, 16, 27, 28, 27, 6, 27, 17, 29, 8, 7, 17, 4, 7, 1, 16, 10, 20, 0, 25, 10, 16, 4, 3, 6, 4, 22, 3, 10, 27, 30, 3, 12, 3, 16, 2, 8, 22, 15, 0, 0, 4, 25, 15, 15, 0, 10, 6, 10, 25, 16, 0, 4, 7, 1, 31, 1, 25, 7, 6, 14, 3, 10, 8, 15, 24, 19, 17, 15, 5, 6, 16, 22, 15, 12, 31, 17, 4, 10, 22, 32, 4, 10, 25, 0, 15, 7, 3, 16, 1, 16]
Centroids: [[1.8667727, 4.9224405], [0.172079, 2.0910747], [2.2214594, -1.8454305]]
Centroids: [[1.0414519, -1.668597], [-0.68383795, 1.1980342], [0.55819803, 2.7563727], [0.6236468, 1.5441414], [2.400694, -1.754749], [0.42501235, -0.231054], [-1.5888897, 0.48068407], [1.1221952, 3.7547293], [4.069989, -1.2247822], [2.026577, 2.4054995], [-0.56933445, 2.5271378], [4.5236073, 4.8095894], [2.774756, 4.379187], [3.6135256, 0.7249166], [5.163107, 6.6326656], [2.4156556, -0.6989268], [2.1873198, 6.253545], [1.986514, -3.2878492], [3.1022243, 9.780898], [4.3304954, 8.3324175], [3.5016932, -2.7019076], [2.6112595, 7.787005], [0.4862865, 5.8140316], [4.212282, -4.3231134], [-2.1663015, 1.8821265], [0.73321724, 4.7716255], [-0.39003587, -2.7923658], [3.5893176, 8.406964], [5.149372, 9.750291], [4.484772, 0.0997497], [6.458929, -2.5285997], [-1.2295344, 4.3735123], [7.4050097, 7.2168856]]
Contingency Matrix: 
[[ 0  4  8  3  1  0  0 18  0  1  4  3 12  1  3  0 15  0  1  7  0  5  6  0
   0  5  0  4  0  0  0  2  0]
 [ 0 24  5 18  0  6 12  7  0  3 10  1  2  0  1  0  2  0  0  2  0  0  0  0
   4  1  0  0  1  0  0  0  1]
 [23  0  0  1 28  3  0  0  8  0  0  0  0  1  0  9  0 15  0  0  5  0  0  1
   0  0  1  0  0  1  1  0  0]]
[[0, 4, 8, 3, 1, 0, 0, 18, 0, 1, 4, 3, 12, 1, 3, 0, 15, 0, 1, 7, 0, 5, 6, 0, 0, 5, 0, 4, 0, 0, 0, 2, 0], [0, 24, 5, 18, 0, 6, 12, 7, 0, 3, 10, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 1], [23, 0, 0, 1, 28, 3, 0, 0, 8, 0, 0, 0, 0, 1, 0, 9, 0, 15, 0, 0, 5, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]]
[[0, 4, 8, 3, 1, 0, 0, 18, 0, 1, 4, 3, 12, 1, 3, 0, 15, 0, 1, 7, 0, 5, 6, 0, 0, 5, 0, 4, 0, 0, 0, 2, 0], [0, 24, 5, 18, 0, 6, 12, 7, 0, 3, 10, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 1], [23, 0, 0, 1, 28, 3, 0, 0, 8, 0, 0, 0, 0, 1, 0, 9, 0, 15, 0, 0, 5, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]
[[0, 4, 8, 3, -1, 0, 0, 18, 0, 1, 4, 3, 12, 1, 3, 0, 15, 0, 1, 7, 0, 5, 6, 0, 0, 5, 0, 4, 0, 0, 0, 2, 0], [0, 24, 5, 18, -1, 6, 12, 7, 0, 3, 10, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[0, -1, 8, 3, -1, 0, 0, 18, 0, 1, 4, 3, 12, 1, 3, 0, 15, 0, 1, 7, 0, 5, 6, 0, 0, 5, 0, 4, 0, 0, 0, 2, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {2: 4, 1: 1, 0: 7}
New Contingency Matrix: 
[[18  4  1  0  8  3  0  0  0  1  4  3 12  1  3  0 15  0  1  7  0  5  6  0
   0  5  0  4  0  0  0  2  0]
 [ 7 24  0  0  5 18  6 12  0  3 10  1  2  0  1  0  2  0  0  2  0  0  0  0
   4  1  0  0  1  0  0  0  1]
 [ 0  0 28 23  0  1  3  0  8  0  0  0  0  1  0  9  0 15  0  0  5  0  0  1
   0  0  1  0  0  1  1  0  0]]
New Clustered Label Sequence: [7, 1, 4, 0, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]
Diagonal_Elements: [18, 24, 28], Sum: 70
All_Elements: [18, 4, 1, 0, 8, 3, 0, 0, 0, 1, 4, 3, 12, 1, 3, 0, 15, 0, 1, 7, 0, 5, 6, 0, 0, 5, 0, 4, 0, 0, 0, 2, 0, 7, 24, 0, 0, 5, 18, 6, 12, 0, 3, 10, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 28, 23, 0, 1, 3, 0, 8, 0, 0, 0, 0, 1, 0, 9, 0, 15, 0, 0, 5, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0], Sum: 300
Accuracy: 0.23333333333333334
