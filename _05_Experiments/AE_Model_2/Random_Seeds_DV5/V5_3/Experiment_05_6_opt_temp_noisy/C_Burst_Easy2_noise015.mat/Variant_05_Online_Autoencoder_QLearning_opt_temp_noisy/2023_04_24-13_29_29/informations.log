Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_6_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_6_opt_temp_noisy/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-13_29_29
Punishment_Coefficient: 0.9
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000220022637B8>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.20193304121494293
Online_Training [2/700]: mean_loss=0.26200466230511665
Online_Training [3/700]: mean_loss=0.22960380464792252
Online_Training [4/700]: mean_loss=0.08313705585896969
Online_Training [5/700]: mean_loss=0.2732812389731407
Online_Training [6/700]: mean_loss=0.13327863812446594
Online_Training [7/700]: mean_loss=0.1575044672936201
Online_Training [8/700]: mean_loss=0.07783331163227558
Online_Training [9/700]: mean_loss=0.2605192195624113
Online_Training [10/700]: mean_loss=0.14282446540892124
Online_Training [11/700]: mean_loss=0.09217849187552929
Online_Training [12/700]: mean_loss=0.06965467892587185
Online_Training [13/700]: mean_loss=0.09962007030844688
Online_Training [14/700]: mean_loss=0.09169263951480389
Online_Training [15/700]: mean_loss=0.06290029408410192
Online_Training [16/700]: mean_loss=0.14196028653532267
Online_Training [17/700]: mean_loss=0.1787282545119524
Online_Training [18/700]: mean_loss=0.13567963987588882
Online_Training [19/700]: mean_loss=0.03264113096520305
Online_Training [20/700]: mean_loss=0.18645749613642693
Online_Training [21/700]: mean_loss=0.12722435593605042
Online_Training [22/700]: mean_loss=0.08304465748369694
Online_Training [23/700]: mean_loss=0.03735841065645218
Online_Training [24/700]: mean_loss=0.08711723983287811
Online_Training [25/700]: mean_loss=0.05026010237634182
Online_Training [26/700]: mean_loss=0.08960546180605888
Online_Training [27/700]: mean_loss=0.09338712505996227
Online_Training [28/700]: mean_loss=0.06347407726570964
Online_Training [29/700]: mean_loss=0.05132378777489066
Online_Training [30/700]: mean_loss=0.03285938943736255
Online_Training [31/700]: mean_loss=0.029274391941726208
Online_Training [32/700]: mean_loss=0.045772431418299675
Online_Training [33/700]: mean_loss=0.017943386686965823
Online_Training [34/700]: mean_loss=0.22711434960365295
Online_Training [35/700]: mean_loss=0.06922392453998327
Online_Training [36/700]: mean_loss=0.107826909981668
Online_Training [37/700]: mean_loss=0.0830272575840354
Online_Training [38/700]: mean_loss=0.044396660290658474
Online_Training [39/700]: mean_loss=0.13465450890362263
Online_Training [40/700]: mean_loss=0.026250553550198674
Online_Training [41/700]: mean_loss=0.04743449995294213
Online_Training [42/700]: mean_loss=0.06054850481450558
Online_Training [43/700]: mean_loss=0.13160598650574684
Online_Training [44/700]: mean_loss=0.1531011089682579
Online_Training [45/700]: mean_loss=0.12021529115736485
Online_Training [46/700]: mean_loss=0.08478387538343668
Online_Training [47/700]: mean_loss=0.10456054471433163
Online_Training [48/700]: mean_loss=0.06988717243075371
Online_Training [49/700]: mean_loss=0.11268502846360207
Online_Training [50/700]: mean_loss=0.12760792765766382
Online_Training [51/700]: mean_loss=0.04758149990811944
Online_Training [52/700]: mean_loss=0.1820789948105812
Online_Training [53/700]: mean_loss=0.04908496420830488
Online_Training [54/700]: mean_loss=0.11047179438173771
Online_Training [55/700]: mean_loss=0.12898757308721542
Online_Training [56/700]: mean_loss=0.03726669168099761
Online_Training [57/700]: mean_loss=0.2207279186695814
Online_Training [58/700]: mean_loss=0.2834987938404083
Online_Training [59/700]: mean_loss=0.13298190385103226
Online_Training [60/700]: mean_loss=0.08046318963170052
Online_Training [61/700]: mean_loss=0.097362513653934
Online_Training [62/700]: mean_loss=0.14814550057053566
Online_Training [63/700]: mean_loss=0.09339055977761745
Online_Training [64/700]: mean_loss=0.03036450012587011
Online_Training [65/700]: mean_loss=0.08932477235794067
Online_Training [66/700]: mean_loss=0.10435839556157589
Online_Training [67/700]: mean_loss=0.05990217672660947
Online_Training [68/700]: mean_loss=0.08718504849821329
Online_Training [69/700]: mean_loss=0.2339621651917696
Online_Training [70/700]: mean_loss=0.03888821788132191
Online_Training [71/700]: mean_loss=0.09127150196582079
Online_Training [72/700]: mean_loss=0.08148456178605556
Online_Training [73/700]: mean_loss=0.04608799563720822
Online_Training [74/700]: mean_loss=0.05096141900867224
Online_Training [75/700]: mean_loss=0.07610311917960644
Online_Training [76/700]: mean_loss=0.0957694323733449
Online_Training [77/700]: mean_loss=0.1301408652216196
Online_Training [78/700]: mean_loss=0.1328725665807724
Online_Training [79/700]: mean_loss=0.044112738221883774
Online_Training [80/700]: mean_loss=0.04319260874763131
Online_Training [81/700]: mean_loss=0.02851867233403027
Online_Training [82/700]: mean_loss=0.03970305621623993
Online_Training [83/700]: mean_loss=0.16027101874351501
Online_Training [84/700]: mean_loss=0.03874377254396677
Online_Training [85/700]: mean_loss=0.03130953316576779
Online_Training [86/700]: mean_loss=0.1274389736354351
Online_Training [87/700]: mean_loss=0.016246518353000283
Online_Training [88/700]: mean_loss=0.06113154161721468
Online_Training [89/700]: mean_loss=0.07759122271090746
Online_Training [90/700]: mean_loss=0.07600119058042765
Online_Training [91/700]: mean_loss=0.04048475809395313
Online_Training [92/700]: mean_loss=0.05127903586253524
Online_Training [93/700]: mean_loss=0.1131517207249999
Online_Training [94/700]: mean_loss=0.0687433211132884
Online_Training [95/700]: mean_loss=0.10636624321341515
Online_Training [96/700]: mean_loss=0.05076712882146239
Online_Training [97/700]: mean_loss=0.05640594661235809
Online_Training [98/700]: mean_loss=0.08127335924655199
Online_Training [99/700]: mean_loss=0.024848346365615726
Online_Training [100/700]: mean_loss=0.15968474932014942
Online_Training [101/700]: mean_loss=0.10287892632186413
Online_Training [102/700]: mean_loss=0.060666030272841454
Online_Training [103/700]: mean_loss=0.04769592359662056
Online_Training [104/700]: mean_loss=0.06543130753561854
Online_Training [105/700]: mean_loss=0.03852061973884702
Online_Training [106/700]: mean_loss=0.016030655475333333
Online_Training [107/700]: mean_loss=0.028084440855309367
Online_Training [108/700]: mean_loss=0.04269336489960551
Online_Training [109/700]: mean_loss=0.036507655400782824
Online_Training [110/700]: mean_loss=0.07511696498841047
Online_Training [111/700]: mean_loss=0.03437274228781462
Online_Training [112/700]: mean_loss=0.1279168203473091
Online_Training [113/700]: mean_loss=0.060805900022387505
Online_Training [114/700]: mean_loss=0.09419858828186989
Online_Training [115/700]: mean_loss=0.06402129726484418
Online_Training [116/700]: mean_loss=0.04337962390854955
Online_Training [117/700]: mean_loss=0.047828941605985165
Online_Training [118/700]: mean_loss=0.044184207916259766
Online_Training [119/700]: mean_loss=0.14822707697749138
Online_Training [120/700]: mean_loss=0.09708171524107456
Online_Training [121/700]: mean_loss=0.09747538063675165
Online_Training [122/700]: mean_loss=0.08049630746245384
Online_Training [123/700]: mean_loss=0.039851507637649775
Online_Training [124/700]: mean_loss=0.014837360009551048
Online_Training [125/700]: mean_loss=0.203919667750597
Online_Training [126/700]: mean_loss=0.06342644616961479
Online_Training [127/700]: mean_loss=0.07377106230705976
Online_Training [128/700]: mean_loss=0.041012398432940245
Online_Training [129/700]: mean_loss=0.04199812561273575
Online_Training [130/700]: mean_loss=0.019359216326847672
Online_Training [131/700]: mean_loss=0.04185199202038348
Online_Training [132/700]: mean_loss=0.01951538270805031
Online_Training [133/700]: mean_loss=0.029101521475240588
Online_Training [134/700]: mean_loss=0.019100474193692207
Online_Training [135/700]: mean_loss=0.09996016696095467
Online_Training [136/700]: mean_loss=0.029120814753696322
Online_Training [137/700]: mean_loss=0.030056742718443274
Online_Training [138/700]: mean_loss=0.013625489082187414
Online_Training [139/700]: mean_loss=0.017251837183721364
Online_Training [140/700]: mean_loss=0.03407680103555322
Online_Training [141/700]: mean_loss=0.04412834998220205
Online_Training [142/700]: mean_loss=0.021418607095256448
Online_Training [143/700]: mean_loss=0.024502008454874158
Online_Training [144/700]: mean_loss=0.01136985095217824
Online_Training [145/700]: mean_loss=0.05092861410230398
Online_Training [146/700]: mean_loss=0.017754381289705634
Online_Training [147/700]: mean_loss=0.01483847526833415
Online_Training [148/700]: mean_loss=0.047427147161215544
Online_Training [149/700]: mean_loss=0.07807079935446382
Online_Training [150/700]: mean_loss=0.11460045631974936
Online_Training [151/700]: mean_loss=0.034161382587626576
Online_Training [152/700]: mean_loss=0.016976040904410183
Online_Training [153/700]: mean_loss=0.031056241132318974
Online_Training [154/700]: mean_loss=0.024372030748054385
Online_Training [155/700]: mean_loss=0.012170689878985286
Online_Training [156/700]: mean_loss=0.018887453014031053
Online_Training [157/700]: mean_loss=0.1438712403178215
Online_Training [158/700]: mean_loss=0.009549056645482779
Online_Training [159/700]: mean_loss=0.02840854972600937
Online_Training [160/700]: mean_loss=0.027117787394672632
Online_Training [161/700]: mean_loss=0.03540971037000418
Online_Training [162/700]: mean_loss=0.017717213020659983
Online_Training [163/700]: mean_loss=0.061393116135150194
Online_Training [164/700]: mean_loss=0.014501641155220568
Online_Training [165/700]: mean_loss=0.012192752677947283
Online_Training [166/700]: mean_loss=0.024455273058265448
Online_Training [167/700]: mean_loss=0.03572407132014632
Online_Training [168/700]: mean_loss=0.03335045836865902
Online_Training [169/700]: mean_loss=0.05278467945754528
Online_Training [170/700]: mean_loss=0.18648156337440014
Online_Training [171/700]: mean_loss=0.019053876749239862
Online_Training [172/700]: mean_loss=0.019975891336798668
Online_Training [173/700]: mean_loss=0.02477378281764686
Online_Training [174/700]: mean_loss=0.012076536775566638
Online_Training [175/700]: mean_loss=0.010870469035580754
Online_Training [176/700]: mean_loss=0.004230939201079309
Online_Training [177/700]: mean_loss=0.03892750828526914
Online_Training [178/700]: mean_loss=0.035106555093079805
Online_Training [179/700]: mean_loss=0.026514603290706873
Online_Training [180/700]: mean_loss=0.02727631409652531
Online_Training [181/700]: mean_loss=0.029346601106226444
Online_Training [182/700]: mean_loss=0.031822371762245893
Online_Training [183/700]: mean_loss=0.013200173387303948
Online_Training [184/700]: mean_loss=0.004989452485460788
Online_Training [185/700]: mean_loss=0.025906305760145187
Online_Training [186/700]: mean_loss=0.031779904616996646
Online_Training [187/700]: mean_loss=0.030013553565368056
Online_Training [188/700]: mean_loss=0.023097099270671606
Online_Training [189/700]: mean_loss=0.062441373243927956
Online_Training [190/700]: mean_loss=0.025103784166276455
Online_Training [191/700]: mean_loss=0.12233906798064709
Online_Training [192/700]: mean_loss=0.02350183855742216
Online_Training [193/700]: mean_loss=0.01959861791692674
Online_Training [194/700]: mean_loss=0.018472485011443496
Online_Training [195/700]: mean_loss=0.024193902732804418
Online_Training [196/700]: mean_loss=0.016261022072285414
Online_Training [197/700]: mean_loss=0.0404694932512939
Online_Training [198/700]: mean_loss=0.017518741195090115
Online_Training [199/700]: mean_loss=0.09148031007498503
Online_Training [200/700]: mean_loss=0.01863576890900731
Online_Training [201/700]: mean_loss=0.03154645301401615
Online_Training [202/700]: mean_loss=0.01481998129747808
Online_Training [203/700]: mean_loss=0.011514315963722765
Online_Training [204/700]: mean_loss=0.012496128329075873
Online_Training [205/700]: mean_loss=0.07188315037637949
Online_Training [206/700]: mean_loss=0.013119007577188313
Online_Training [207/700]: mean_loss=0.05437413556501269
Online_Training [208/700]: mean_loss=0.046565556433051825
Online_Training [209/700]: mean_loss=0.054554101545363665
Online_Training [210/700]: mean_loss=0.027821390889585018
Online_Training [211/700]: mean_loss=0.016469352296553552
Online_Training [212/700]: mean_loss=0.08034188020974398
Online_Training [213/700]: mean_loss=0.04192838864400983
Online_Training [214/700]: mean_loss=0.010789255728013813
Online_Training [215/700]: mean_loss=0.03683825070038438
Online_Training [216/700]: mean_loss=0.03885545069351792
Online_Training [217/700]: mean_loss=0.011783231166191399
Online_Training [218/700]: mean_loss=0.00775389454793185
Online_Training [219/700]: mean_loss=0.060400469694286585
Online_Training [220/700]: mean_loss=0.012859840877354145
Online_Training [221/700]: mean_loss=0.03330897679552436
Online_Training [222/700]: mean_loss=0.018095526611432433
Online_Training [223/700]: mean_loss=0.02834930131211877
Online_Training [224/700]: mean_loss=0.0063982942956499755
Online_Training [225/700]: mean_loss=0.027199577540159225
Online_Training [226/700]: mean_loss=0.028858187841251493
Online_Training [227/700]: mean_loss=0.01589537237305194
Online_Training [228/700]: mean_loss=0.024868543725460768
Online_Training [229/700]: mean_loss=0.04683773359283805
Online_Training [230/700]: mean_loss=0.01593818236142397
Online_Training [231/700]: mean_loss=0.021108091110363603
Online_Training [232/700]: mean_loss=0.021069497801363468
Online_Training [233/700]: mean_loss=0.016920038033276796
Online_Training [234/700]: mean_loss=0.03512222692370415
Online_Training [235/700]: mean_loss=0.09611125756055117
Online_Training [236/700]: mean_loss=0.06918447138741612
Online_Training [237/700]: mean_loss=0.03390331519767642
Online_Training [238/700]: mean_loss=0.10830639116466045
Online_Training [239/700]: mean_loss=0.06615924462676048
Online_Training [240/700]: mean_loss=0.059248954290524125
Online_Training [241/700]: mean_loss=0.03453618520870805
Online_Training [242/700]: mean_loss=0.0329293766990304
Online_Training [243/700]: mean_loss=0.03904229821637273
Online_Training [244/700]: mean_loss=0.02217289572581649
Online_Training [245/700]: mean_loss=0.043268267065286636
Online_Training [246/700]: mean_loss=0.018858761992305517
Online_Training [247/700]: mean_loss=0.007111396000254899
Online_Training [248/700]: mean_loss=0.07310525886714458
Online_Training [249/700]: mean_loss=0.012559286435134709
Online_Training [250/700]: mean_loss=0.018376697087660432
Online_Training [251/700]: mean_loss=0.010037719854153693
Online_Training [252/700]: mean_loss=0.022341580130159855
Online_Training [253/700]: mean_loss=0.013836189056746662
Online_Training [254/700]: mean_loss=0.01804698328487575
Online_Training [255/700]: mean_loss=0.03787972847931087
Online_Training [256/700]: mean_loss=0.0165041193831712
Online_Training [257/700]: mean_loss=0.01597034779842943
Online_Training [258/700]: mean_loss=0.026489969110116363
Online_Training [259/700]: mean_loss=0.009650474763475358
Online_Training [260/700]: mean_loss=0.006077651516534388
Online_Training [261/700]: mean_loss=0.021088876761496067
Online_Training [262/700]: mean_loss=0.026347859064117074
Online_Training [263/700]: mean_loss=0.011586170410737395
Online_Training [264/700]: mean_loss=0.021141829900443554
Online_Training [265/700]: mean_loss=0.016299897339195013
Online_Training [266/700]: mean_loss=0.01420142117422074
Online_Training [267/700]: mean_loss=0.010501316632144153
Online_Training [268/700]: mean_loss=0.0050443007494322956
Online_Training [269/700]: mean_loss=0.02183657535351813
Online_Training [270/700]: mean_loss=0.013436898356303573
Online_Training [271/700]: mean_loss=0.022585688391700387
Online_Training [272/700]: mean_loss=0.007302077778149396
Online_Training [273/700]: mean_loss=0.00881027418654412
Online_Training [274/700]: mean_loss=0.010896381922066212
Online_Training [275/700]: mean_loss=0.012456489843316376
Online_Training [276/700]: mean_loss=0.012808773783035576
Online_Training [277/700]: mean_loss=0.02883460628800094
Online_Training [278/700]: mean_loss=0.021762894233688712
Online_Training [279/700]: mean_loss=0.018454586155712605
Online_Training [280/700]: mean_loss=0.02704302640631795
Online_Training [281/700]: mean_loss=0.020977457519620657
Online_Training [282/700]: mean_loss=0.032253514509648085
Online_Training [283/700]: mean_loss=0.01983213471248746
Online_Training [284/700]: mean_loss=0.013234883197583258
Online_Training [285/700]: mean_loss=0.022379318485036492
Online_Training [286/700]: mean_loss=0.014575326116755605
Online_Training [287/700]: mean_loss=0.018013773951679468
Online_Training [288/700]: mean_loss=0.01745623128954321
Online_Training [289/700]: mean_loss=0.04436727752909064
Online_Training [290/700]: mean_loss=0.0073453832301311195
Online_Training [291/700]: mean_loss=0.011146597098559141
Online_Training [292/700]: mean_loss=0.007602346304338425
Online_Training [293/700]: mean_loss=0.014879458583891392
Online_Training [294/700]: mean_loss=0.013488798402249813
Online_Training [295/700]: mean_loss=0.034843266941607
Online_Training [296/700]: mean_loss=0.03703977353870869
Online_Training [297/700]: mean_loss=0.019451649393886328
Online_Training [298/700]: mean_loss=0.017042365157976747
Online_Training [299/700]: mean_loss=0.019427502062171698
Online_Training [300/700]: mean_loss=0.04454251937568188
Online_Training [301/700]: mean_loss=0.014356217812746763
Online_Training [302/700]: mean_loss=0.015671591507270932
Online_Training [303/700]: mean_loss=0.019776025786995888
Online_Training [304/700]: mean_loss=0.01013650675304234
Online_Training [305/700]: mean_loss=0.04649573704227805
Online_Training [306/700]: mean_loss=0.06123048905283213
Online_Training [307/700]: mean_loss=0.07116284128278494
Online_Training [308/700]: mean_loss=0.022018323419615626
Online_Training [309/700]: mean_loss=0.009781726752407849
Online_Training [310/700]: mean_loss=0.007321169308852404
Online_Training [311/700]: mean_loss=0.010707969544455409
Online_Training [312/700]: mean_loss=0.05398026341572404
Online_Training [313/700]: mean_loss=0.015212733182124794
Online_Training [314/700]: mean_loss=0.013156353030353785
Online_Training [315/700]: mean_loss=0.008260529371909797
Online_Training [316/700]: mean_loss=0.015631292713806033
Online_Training [317/700]: mean_loss=0.00757429248187691
Online_Training [318/700]: mean_loss=0.01832102471962571
Online_Training [319/700]: mean_loss=0.0248037229757756
Online_Training [320/700]: mean_loss=0.01216109364759177
Online_Training [321/700]: mean_loss=0.022579419426620007
Online_Training [322/700]: mean_loss=0.03509956132620573
Online_Training [323/700]: mean_loss=0.021613797405734658
Online_Training [324/700]: mean_loss=0.021662532351911068
Online_Training [325/700]: mean_loss=0.031164824962615967
Online_Training [326/700]: mean_loss=0.011391005362384021
Online_Training [327/700]: mean_loss=0.026863339124247432
Online_Training [328/700]: mean_loss=0.026640744879841805
Online_Training [329/700]: mean_loss=0.010618079802952707
Online_Training [330/700]: mean_loss=0.030840873019769788
Online_Training [331/700]: mean_loss=0.03609585948288441
Online_Training [332/700]: mean_loss=0.021910106297582388
Online_Training [333/700]: mean_loss=0.015557970618829131
Online_Training [334/700]: mean_loss=0.011368201347067952
Online_Training [335/700]: mean_loss=0.06429073261097074
Online_Training [336/700]: mean_loss=0.05220053903758526
Online_Training [337/700]: mean_loss=0.0648188404738903
Online_Training [338/700]: mean_loss=0.028214770136401057
Online_Training [339/700]: mean_loss=0.014585590804927051
Online_Training [340/700]: mean_loss=0.008098978199996054
Online_Training [341/700]: mean_loss=0.038421253906562924
Online_Training [342/700]: mean_loss=0.051213113591074944
Online_Training [343/700]: mean_loss=0.015408776234835386
Online_Training [344/700]: mean_loss=0.021959172561764717
Online_Training [345/700]: mean_loss=0.0410270388238132
Online_Training [346/700]: mean_loss=0.023756812792271376
Online_Training [347/700]: mean_loss=0.12292671017348766
Online_Training [348/700]: mean_loss=0.020391937578096986
Online_Training [349/700]: mean_loss=0.030342453392222524
Online_Training [350/700]: mean_loss=0.010400423663668334
Online_Training [351/700]: mean_loss=0.009510094881989062
Online_Training [352/700]: mean_loss=0.010433670715428889
Online_Training [353/700]: mean_loss=0.019270499935373664
Online_Training [354/700]: mean_loss=0.020346693927422166
Online_Training [355/700]: mean_loss=0.012093749828636646
Online_Training [356/700]: mean_loss=0.017799744964577258
Online_Training [357/700]: mean_loss=0.08488946780562401
Online_Training [358/700]: mean_loss=0.0728710750117898
Online_Training [359/700]: mean_loss=0.08495614491403103
Online_Training [360/700]: mean_loss=0.03290062164887786
Online_Training [361/700]: mean_loss=0.026568214409053326
Online_Training [362/700]: mean_loss=0.04840332409366965
Online_Training [363/700]: mean_loss=0.016620661481283605
Online_Training [364/700]: mean_loss=0.010444674640893936
Online_Training [365/700]: mean_loss=0.016240456025116146
Online_Training [366/700]: mean_loss=0.025564880575984716
Online_Training [367/700]: mean_loss=0.02200232120230794
Online_Training [368/700]: mean_loss=0.013654248439706862
Online_Training [369/700]: mean_loss=0.01216999173630029
Online_Training [370/700]: mean_loss=0.035242503974586725
Online_Training [371/700]: mean_loss=0.00622128281975165
Online_Training [372/700]: mean_loss=0.019035156117752194
Online_Training [373/700]: mean_loss=0.018145275069400668
Online_Training [374/700]: mean_loss=0.01553891459479928
Online_Training [375/700]: mean_loss=0.017976525938138366
Online_Training [376/700]: mean_loss=0.00851345417322591
Online_Training [377/700]: mean_loss=0.018909146543592215
Online_Training [378/700]: mean_loss=0.018111357931047678
Online_Training [379/700]: mean_loss=0.021015214268118143
Online_Training [380/700]: mean_loss=0.011778564425185323
Online_Training [381/700]: mean_loss=0.020508092362433672
Online_Training [382/700]: mean_loss=0.009958917275071144
Online_Training [383/700]: mean_loss=0.008366287220269442
Online_Training [384/700]: mean_loss=0.1203433396294713
Online_Training [385/700]: mean_loss=0.00790869421325624
Online_Training [386/700]: mean_loss=0.029005161952227354
Online_Training [387/700]: mean_loss=0.018020618241280317
Online_Training [388/700]: mean_loss=0.02233339403755963
Online_Training [389/700]: mean_loss=0.0074962443322874606
Online_Training [390/700]: mean_loss=0.02211662125773728
Online_Training [391/700]: mean_loss=0.007906439597718418
Online_Training [392/700]: mean_loss=0.025190386455506086
Online_Training [393/700]: mean_loss=0.014949350384995341
Online_Training [394/700]: mean_loss=0.02305353432893753
Online_Training [395/700]: mean_loss=0.011817810242064297
Online_Training [396/700]: mean_loss=0.022647038334980607
Online_Training [397/700]: mean_loss=0.011526579735800624
Online_Training [398/700]: mean_loss=0.021893009077757597
Online_Training [399/700]: mean_loss=0.019451101776212454
Online_Training [400/700]: mean_loss=0.033862187061458826
Online_Training [401/700]: mean_loss=0.011735757812857628
Online_Training [402/700]: mean_loss=0.011934570968151093
Online_Training [403/700]: mean_loss=0.01932888850569725
Online_Training [404/700]: mean_loss=0.0548224956728518
Online_Training [405/700]: mean_loss=0.07201890600845218
Online_Training [406/700]: mean_loss=0.024799537379294634
Online_Training [407/700]: mean_loss=0.03482662793248892
Online_Training [408/700]: mean_loss=0.016281714430078864
Online_Training [409/700]: mean_loss=0.00823612289968878
Online_Training [410/700]: mean_loss=0.021231735590845346
Online_Training [411/700]: mean_loss=0.021160583244636655
Online_Training [412/700]: mean_loss=0.10618077591061592
Online_Training [413/700]: mean_loss=0.033541916171088815
Online_Training [414/700]: mean_loss=0.035720860585570335
Online_Training [415/700]: mean_loss=0.029866157565265894
Online_Training [416/700]: mean_loss=0.01975010079331696
Online_Training [417/700]: mean_loss=0.059753337409347296
Online_Training [418/700]: mean_loss=0.012783901300281286
Online_Training [419/700]: mean_loss=0.016201236052438617
Online_Training [420/700]: mean_loss=0.05054244166240096
Online_Training [421/700]: mean_loss=0.031225991435348988
Online_Training [422/700]: mean_loss=0.013832593220286071
Online_Training [423/700]: mean_loss=0.02787618595175445
Online_Training [424/700]: mean_loss=0.05484841810539365
Online_Training [425/700]: mean_loss=0.023314710706472397
Online_Training [426/700]: mean_loss=0.008627434901427478
Online_Training [427/700]: mean_loss=0.01676074182614684
Online_Training [428/700]: mean_loss=0.022656980901956558
Online_Training [429/700]: mean_loss=0.011916046845726669
Online_Training [430/700]: mean_loss=0.008108155278023332
Online_Training [431/700]: mean_loss=0.011006087297573686
Online_Training [432/700]: mean_loss=0.07790486887097359
Online_Training [433/700]: mean_loss=0.02422489842865616
Online_Training [434/700]: mean_loss=0.06070646666921675
Online_Training [435/700]: mean_loss=0.016745474189519882
Online_Training [436/700]: mean_loss=0.07861356902867556
Online_Training [437/700]: mean_loss=0.025804670993238688
Online_Training [438/700]: mean_loss=0.10562862642109394
Online_Training [439/700]: mean_loss=0.05957794422283769
Online_Training [440/700]: mean_loss=0.034223806113004684
Online_Training [441/700]: mean_loss=0.035783301340416074
Online_Training [442/700]: mean_loss=0.010624950751662254
Online_Training [443/700]: mean_loss=0.020700918277725577
Online_Training [444/700]: mean_loss=0.028749491553753614
Online_Training [445/700]: mean_loss=0.019144773948937654
Online_Training [446/700]: mean_loss=0.024342569522559643
Online_Training [447/700]: mean_loss=0.013258776627480984
Online_Training [448/700]: mean_loss=0.02153708296827972
Online_Training [449/700]: mean_loss=0.01940221944823861
Online_Training [450/700]: mean_loss=0.02986411703750491
Online_Training [451/700]: mean_loss=0.020169505150988698
Online_Training [452/700]: mean_loss=0.04202807508409023
Online_Training [453/700]: mean_loss=0.06452618632465601
Online_Training [454/700]: mean_loss=0.014561844407580793
Online_Training [455/700]: mean_loss=0.05022469349205494
Online_Training [456/700]: mean_loss=0.008601364213973284
Online_Training [457/700]: mean_loss=0.009137825691141188
Online_Training [458/700]: mean_loss=0.009206683025695384
Online_Training [459/700]: mean_loss=0.010228564380668104
Online_Training [460/700]: mean_loss=0.018781076185405254
Online_Training [461/700]: mean_loss=0.021652438677847385
Online_Training [462/700]: mean_loss=0.011102469055913389
Online_Training [463/700]: mean_loss=0.00596799241611734
Online_Training [464/700]: mean_loss=0.01834430731832981
Online_Training [465/700]: mean_loss=0.05932054575532675
Online_Training [466/700]: mean_loss=0.019928145920857787
Online_Training [467/700]: mean_loss=0.015199097455479205
Online_Training [468/700]: mean_loss=0.01760863175150007
Online_Training [469/700]: mean_loss=0.03160851774737239
Online_Training [470/700]: mean_loss=0.06532494258135557
Online_Training [471/700]: mean_loss=0.024986195610836148
Online_Training [472/700]: mean_loss=0.028657030314207077
Online_Training [473/700]: mean_loss=0.00616158073535189
Online_Training [474/700]: mean_loss=0.010556748718954623
Online_Training [475/700]: mean_loss=0.01033112418372184
Online_Training [476/700]: mean_loss=0.17692956514656544
Online_Training [477/700]: mean_loss=0.08699739165604115
Online_Training [478/700]: mean_loss=0.03525190660730004
Online_Training [479/700]: mean_loss=0.015309638110920787
Online_Training [480/700]: mean_loss=0.012052565580233932
Online_Training [481/700]: mean_loss=0.015982520999386907
Online_Training [482/700]: mean_loss=0.030827397713437676
Online_Training [483/700]: mean_loss=0.01686859829351306
Online_Training [484/700]: mean_loss=0.019216877641156316
Online_Training [485/700]: mean_loss=0.01184955018106848
Online_Training [486/700]: mean_loss=0.019102577585726976
Online_Training [487/700]: mean_loss=0.03609180776402354
Online_Training [488/700]: mean_loss=0.02126679033972323
Online_Training [489/700]: mean_loss=0.014749362366274
Online_Training [490/700]: mean_loss=0.018659930676221848
Online_Training [491/700]: mean_loss=0.03396639786660671
Online_Training [492/700]: mean_loss=0.01499758311547339
Online_Training [493/700]: mean_loss=0.01702508155722171
Online_Training [494/700]: mean_loss=0.059804517310112715
Online_Training [495/700]: mean_loss=0.0065981761435978115
Online_Training [496/700]: mean_loss=0.032066300278529525
Online_Training [497/700]: mean_loss=0.022686014766804874
Online_Training [498/700]: mean_loss=0.02056012232787907
Online_Training [499/700]: mean_loss=0.01729279407300055
Online_Training [500/700]: mean_loss=0.00978372956160456
Online_Training [501/700]: mean_loss=0.01184217247646302
Online_Training [502/700]: mean_loss=0.024775934172794223
Online_Training [503/700]: mean_loss=0.013272182084619999
Online_Training [504/700]: mean_loss=0.0098957127192989
Online_Training [505/700]: mean_loss=0.014712447067722678
Online_Training [506/700]: mean_loss=0.11402698326855898
Online_Training [507/700]: mean_loss=0.08124403096735477
Online_Training [508/700]: mean_loss=0.03577759535983205
Online_Training [509/700]: mean_loss=0.01780964562203735
Online_Training [510/700]: mean_loss=0.01854627998545766
Online_Training [511/700]: mean_loss=0.00505988032091409
Online_Training [512/700]: mean_loss=0.008353204582817852
Online_Training [513/700]: mean_loss=0.035673324251547456
Online_Training [514/700]: mean_loss=0.021469265688210726
Online_Training [515/700]: mean_loss=0.03026052610948682
Online_Training [516/700]: mean_loss=0.018077848246321082
Online_Training [517/700]: mean_loss=0.03029586747288704
Online_Training [518/700]: mean_loss=0.02001021523028612
Online_Training [519/700]: mean_loss=0.008609730692114681
Online_Training [520/700]: mean_loss=0.014782692887820303
Online_Training [521/700]: mean_loss=0.03032347816042602
Online_Training [522/700]: mean_loss=0.007179357053246349
Online_Training [523/700]: mean_loss=0.02030155621469021
Online_Training [524/700]: mean_loss=0.07564390543848276
Online_Training [525/700]: mean_loss=0.024459236301481724
Online_Training [526/700]: mean_loss=0.01373088697437197
Online_Training [527/700]: mean_loss=0.016238449490629137
Online_Training [528/700]: mean_loss=0.01910261856392026
Online_Training [529/700]: mean_loss=0.027507037157192826
Online_Training [530/700]: mean_loss=0.018473168020136654
Online_Training [531/700]: mean_loss=0.021542870439589024
Online_Training [532/700]: mean_loss=0.026843571104109287
Online_Training [533/700]: mean_loss=0.008955641300417483
Online_Training [534/700]: mean_loss=0.013699336675927043
Online_Training [535/700]: mean_loss=0.028521547559648752
Online_Training [536/700]: mean_loss=0.10297740995883942
Online_Training [537/700]: mean_loss=0.011928296531550586
Online_Training [538/700]: mean_loss=0.015637085773050785
Online_Training [539/700]: mean_loss=0.005508670641575009
Online_Training [540/700]: mean_loss=0.032737453700974584
Online_Training [541/700]: mean_loss=0.10489726718515158
Online_Training [542/700]: mean_loss=0.008926739799790084
Online_Training [543/700]: mean_loss=0.03794220648705959
Online_Training [544/700]: mean_loss=0.011180090717971325
Online_Training [545/700]: mean_loss=0.0242726132273674
Online_Training [546/700]: mean_loss=0.009717432432807982
Online_Training [547/700]: mean_loss=0.021680304780602455
Online_Training [548/700]: mean_loss=0.02369909198023379
Online_Training [549/700]: mean_loss=0.0067730171722359955
Online_Training [550/700]: mean_loss=0.018385406583547592
Online_Training [551/700]: mean_loss=0.020571002271026373
Online_Training [552/700]: mean_loss=0.027047911193221807
Online_Training [553/700]: mean_loss=0.034190351609140635
Online_Training [554/700]: mean_loss=0.017252449179068208
Online_Training [555/700]: mean_loss=0.03125186893157661
Online_Training [556/700]: mean_loss=0.01623849105089903
Online_Training [557/700]: mean_loss=0.013343671103939414
Online_Training [558/700]: mean_loss=0.007252497016452253
Online_Training [559/700]: mean_loss=0.0079457190586254
Online_Training [560/700]: mean_loss=0.007918534451164305
Online_Training [561/700]: mean_loss=0.020486617926508188
Online_Training [562/700]: mean_loss=0.03536156052723527
Online_Training [563/700]: mean_loss=0.031118523329496384
Online_Training [564/700]: mean_loss=0.012878433102741838
Online_Training [565/700]: mean_loss=0.019787353230640292
Online_Training [566/700]: mean_loss=0.014124423149041831
Online_Training [567/700]: mean_loss=0.025107942055910826
Online_Training [568/700]: mean_loss=0.018556231167167425
Online_Training [569/700]: mean_loss=0.02663978561758995
Online_Training [570/700]: mean_loss=0.010901856236159801
Online_Training [571/700]: mean_loss=0.021595685742795467
Online_Training [572/700]: mean_loss=0.01647276058793068
Online_Training [573/700]: mean_loss=0.027770327171310782
Online_Training [574/700]: mean_loss=0.05188214126974344
Online_Training [575/700]: mean_loss=0.05810532113537192
Online_Training [576/700]: mean_loss=0.009685453376732767
Online_Training [577/700]: mean_loss=0.015091780107468367
Online_Training [578/700]: mean_loss=0.007398516812827438
Online_Training [579/700]: mean_loss=0.014486568397842348
Online_Training [580/700]: mean_loss=0.03523645899258554
Online_Training [581/700]: mean_loss=0.02306080493144691
Online_Training [582/700]: mean_loss=0.011154562933370471
Online_Training [583/700]: mean_loss=0.014076093037147075
Online_Training [584/700]: mean_loss=0.013143657590262592
Online_Training [585/700]: mean_loss=0.025934281758964062
Online_Training [586/700]: mean_loss=0.10157733224332333
Online_Training [587/700]: mean_loss=0.02513036341406405
Online_Training [588/700]: mean_loss=0.007275191252119839
Online_Training [589/700]: mean_loss=0.026675926987081766
Online_Training [590/700]: mean_loss=0.026631556684151292
Online_Training [591/700]: mean_loss=0.017975099151954055
Online_Training [592/700]: mean_loss=0.013452263199724257
Online_Training [593/700]: mean_loss=0.04123532120138407
Online_Training [594/700]: mean_loss=0.013621756457723677
Online_Training [595/700]: mean_loss=0.03798342333175242
Online_Training [596/700]: mean_loss=0.0137065484886989
Online_Training [597/700]: mean_loss=0.00902265659533441
Online_Training [598/700]: mean_loss=0.016307714860886335
Online_Training [599/700]: mean_loss=0.028563614701852202
Online_Training [600/700]: mean_loss=0.011688196333125234
Online_Training [601/700]: mean_loss=0.03899997193366289
Online_Training [602/700]: mean_loss=0.008060408639721572
Online_Training [603/700]: mean_loss=0.008564827498048544
Online_Training [604/700]: mean_loss=0.023711135145276785
Online_Training [605/700]: mean_loss=0.009555688477121294
Online_Training [606/700]: mean_loss=0.003906823723809794
Online_Training [607/700]: mean_loss=0.00987781654112041
Online_Training [608/700]: mean_loss=0.011950001236982644
Online_Training [609/700]: mean_loss=0.01354520011227578
Online_Training [610/700]: mean_loss=0.01882770482916385
Online_Training [611/700]: mean_loss=0.010618534637615085
Online_Training [612/700]: mean_loss=0.11512162536382675
Online_Training [613/700]: mean_loss=0.0552430571988225
Online_Training [614/700]: mean_loss=0.013414020009804517
Online_Training [615/700]: mean_loss=0.010616087354719639
Online_Training [616/700]: mean_loss=0.02006767364218831
Online_Training [617/700]: mean_loss=0.004657979356124997
Online_Training [618/700]: mean_loss=0.025879357242956758
Online_Training [619/700]: mean_loss=0.015990498824976385
Online_Training [620/700]: mean_loss=0.06459148973226547
Online_Training [621/700]: mean_loss=0.0065168041619472206
Online_Training [622/700]: mean_loss=0.06327068991959095
Online_Training [623/700]: mean_loss=0.03455346543341875
Online_Training [624/700]: mean_loss=0.015514245838858187
Online_Training [625/700]: mean_loss=0.011210235534235835
Online_Training [626/700]: mean_loss=0.008798336028121412
Online_Training [627/700]: mean_loss=0.008889032062143087
Online_Training [628/700]: mean_loss=0.009690192178823054
Online_Training [629/700]: mean_loss=0.025561673566699028
Online_Training [630/700]: mean_loss=0.04265198623761535
Online_Training [631/700]: mean_loss=0.011855514836497605
Online_Training [632/700]: mean_loss=0.020707414485514164
Online_Training [633/700]: mean_loss=0.012344796909019351
Online_Training [634/700]: mean_loss=0.023396033560857177
Online_Training [635/700]: mean_loss=0.015668972744606435
Online_Training [636/700]: mean_loss=0.00701598240993917
Online_Training [637/700]: mean_loss=0.015114722307771444
Online_Training [638/700]: mean_loss=0.02058699680492282
Online_Training [639/700]: mean_loss=0.018118432839401066
Online_Training [640/700]: mean_loss=0.006021879147738218
Online_Training [641/700]: mean_loss=0.016994610778056085
Online_Training [642/700]: mean_loss=0.013034276198595762
Online_Training [643/700]: mean_loss=0.007907843682914972
Online_Training [644/700]: mean_loss=0.00540804595220834
Online_Training [645/700]: mean_loss=0.016946727875620127
Online_Training [646/700]: mean_loss=0.03279001824557781
Online_Training [647/700]: mean_loss=0.009279497782699764
Online_Training [648/700]: mean_loss=0.012895991210825741
Online_Training [649/700]: mean_loss=0.008828007616102695
Online_Training [650/700]: mean_loss=0.014340142020955682
Online_Training [651/700]: mean_loss=0.00810860568890348
Online_Training [652/700]: mean_loss=0.008727543870918453
Online_Training [653/700]: mean_loss=0.1105094337835908
Online_Training [654/700]: mean_loss=0.0158990491181612
Online_Training [655/700]: mean_loss=0.023349913302809
Online_Training [656/700]: mean_loss=0.025262872222810984
Online_Training [657/700]: mean_loss=0.019636609009467065
Online_Training [658/700]: mean_loss=0.013340892852284014
Online_Training [659/700]: mean_loss=0.013376609305851161
Online_Training [660/700]: mean_loss=0.013635705574415624
Online_Training [661/700]: mean_loss=0.03702150238677859
Online_Training [662/700]: mean_loss=0.04463361203670502
Online_Training [663/700]: mean_loss=0.019176697358489037
Online_Training [664/700]: mean_loss=0.004956538381520659
Online_Training [665/700]: mean_loss=0.041162570007145405
Online_Training [666/700]: mean_loss=0.026824380736798048
Online_Training [667/700]: mean_loss=0.008118873462080956
Online_Training [668/700]: mean_loss=0.009649382205680013
Online_Training [669/700]: mean_loss=0.00789135874947533
Online_Training [670/700]: mean_loss=0.012865490396507084
Online_Training [671/700]: mean_loss=0.020127805415540934
Online_Training [672/700]: mean_loss=0.012150206253863871
Online_Training [673/700]: mean_loss=0.010471299523487687
Online_Training [674/700]: mean_loss=0.014733655378222466
Online_Training [675/700]: mean_loss=0.015743225696496665
Online_Training [676/700]: mean_loss=0.0320623186416924
Online_Training [677/700]: mean_loss=0.04608374275267124
Online_Training [678/700]: mean_loss=0.020496427081525326
Online_Training [679/700]: mean_loss=0.020283257588744164
Online_Training [680/700]: mean_loss=0.012277799425646663
Online_Training [681/700]: mean_loss=0.02493671141564846
Online_Training [682/700]: mean_loss=0.015412453562021255
Online_Training [683/700]: mean_loss=0.006844965973868966
Online_Training [684/700]: mean_loss=0.005651109502650797
Online_Training [685/700]: mean_loss=0.02478438289836049
Online_Training [686/700]: mean_loss=0.010338682564906776
Online_Training [687/700]: mean_loss=0.017113856505602598
Online_Training [688/700]: mean_loss=0.05281722126528621
Online_Training [689/700]: mean_loss=0.011764556868001819
Online_Training [690/700]: mean_loss=0.006024634523782879
Online_Training [691/700]: mean_loss=0.011412373161874712
Online_Training [692/700]: mean_loss=0.02173201646655798
Online_Training [693/700]: mean_loss=0.011844539199955761
Online_Training [694/700]: mean_loss=0.03451395267620683
Online_Training [695/700]: mean_loss=0.011619632598012686
Online_Training [696/700]: mean_loss=0.028552249306812882
Online_Training [697/700]: mean_loss=0.003684131457703188
Online_Training [698/700]: mean_loss=0.005625079560559243
Online_Training [699/700]: mean_loss=0.04981890460476279
Online_Training [700/700]: mean_loss=0.006260586844291538
Q_Learning [1/300]: mean_loss=0.20193304121494293
Q_Learning [2/300]: mean_loss=0.26200466230511665
Q_Learning [3/300]: mean_loss=0.22960380464792252
Q_Learning [4/300]: mean_loss=0.08313705585896969
Q_Learning [5/300]: mean_loss=0.2732812389731407
Q_Learning [6/300]: mean_loss=0.13327863812446594
Q_Learning [7/300]: mean_loss=0.1575044672936201
Q_Learning [8/300]: mean_loss=0.07783331163227558
Q_Learning [9/300]: mean_loss=0.2605192195624113
Q_Learning [10/300]: mean_loss=0.14282446540892124
Q_Learning [11/300]: mean_loss=0.09217849187552929
Q_Learning [12/300]: mean_loss=0.06965467892587185
Q_Learning [13/300]: mean_loss=0.09962007030844688
Q_Learning [14/300]: mean_loss=0.09169263951480389
Q_Learning [15/300]: mean_loss=0.06290029408410192
Q_Learning [16/300]: mean_loss=0.14196028653532267
Q_Learning [17/300]: mean_loss=0.1787282545119524
Q_Learning [18/300]: mean_loss=0.13567963987588882
Q_Learning [19/300]: mean_loss=0.03264113096520305
Q_Learning [20/300]: mean_loss=0.18645749613642693
Q_Learning [21/300]: mean_loss=0.12722435593605042
Q_Learning [22/300]: mean_loss=0.08304465748369694
Q_Learning [23/300]: mean_loss=0.03735841065645218
Q_Learning [24/300]: mean_loss=0.08711723983287811
Q_Learning [25/300]: mean_loss=0.05026010237634182
Q_Learning [26/300]: mean_loss=0.08960546180605888
Q_Learning [27/300]: mean_loss=0.09338712505996227
Q_Learning [28/300]: mean_loss=0.06347407726570964
Q_Learning [29/300]: mean_loss=0.05132378777489066
Q_Learning [30/300]: mean_loss=0.03285938943736255
Q_Learning [31/300]: mean_loss=0.029274391941726208
Q_Learning [32/300]: mean_loss=0.045772431418299675
Q_Learning [33/300]: mean_loss=0.017943386686965823
Q_Learning [34/300]: mean_loss=0.22711434960365295
Q_Learning [35/300]: mean_loss=0.06922392453998327
Q_Learning [36/300]: mean_loss=0.107826909981668
Q_Learning [37/300]: mean_loss=0.0830272575840354
Q_Learning [38/300]: mean_loss=0.044396660290658474
Q_Learning [39/300]: mean_loss=0.13465450890362263
Q_Learning [40/300]: mean_loss=0.026250553550198674
Q_Learning [41/300]: mean_loss=0.04743449995294213
Q_Learning [42/300]: mean_loss=0.06054850481450558
Q_Learning [43/300]: mean_loss=0.13160598650574684
Q_Learning [44/300]: mean_loss=0.1531011089682579
Q_Learning [45/300]: mean_loss=0.12021529115736485
Q_Learning [46/300]: mean_loss=0.08478387538343668
Q_Learning [47/300]: mean_loss=0.10456054471433163
Q_Learning [48/300]: mean_loss=0.06988717243075371
Q_Learning [49/300]: mean_loss=0.11268502846360207
Q_Learning [50/300]: mean_loss=0.12760792765766382
Q_Learning [51/300]: mean_loss=0.04758149990811944
Q_Learning [52/300]: mean_loss=0.1820789948105812
Q_Learning [53/300]: mean_loss=0.04908496420830488
Q_Learning [54/300]: mean_loss=0.11047179438173771
Q_Learning [55/300]: mean_loss=0.12898757308721542
Q_Learning [56/300]: mean_loss=0.03726669168099761
Q_Learning [57/300]: mean_loss=0.2207279186695814
Q_Learning [58/300]: mean_loss=0.2834987938404083
Q_Learning [59/300]: mean_loss=0.13298190385103226
Q_Learning [60/300]: mean_loss=0.08046318963170052
Q_Learning [61/300]: mean_loss=0.097362513653934
Q_Learning [62/300]: mean_loss=0.14814550057053566
Q_Learning [63/300]: mean_loss=0.09339055977761745
Q_Learning [64/300]: mean_loss=0.03036450012587011
Q_Learning [65/300]: mean_loss=0.08932477235794067
Q_Learning [66/300]: mean_loss=0.10435839556157589
Q_Learning [67/300]: mean_loss=0.05990217672660947
Q_Learning [68/300]: mean_loss=0.08718504849821329
Q_Learning [69/300]: mean_loss=0.2339621651917696
Q_Learning [70/300]: mean_loss=0.03888821788132191
Q_Learning [71/300]: mean_loss=0.09127150196582079
Q_Learning [72/300]: mean_loss=0.08148456178605556
Q_Learning [73/300]: mean_loss=0.04608799563720822
Q_Learning [74/300]: mean_loss=0.05096141900867224
Q_Learning [75/300]: mean_loss=0.07610311917960644
Q_Learning [76/300]: mean_loss=0.0957694323733449
Q_Learning [77/300]: mean_loss=0.1301408652216196
Q_Learning [78/300]: mean_loss=0.1328725665807724
Q_Learning [79/300]: mean_loss=0.044112738221883774
Q_Learning [80/300]: mean_loss=0.04319260874763131
Q_Learning [81/300]: mean_loss=0.02851867233403027
Q_Learning [82/300]: mean_loss=0.03970305621623993
Q_Learning [83/300]: mean_loss=0.16027101874351501
Q_Learning [84/300]: mean_loss=0.03874377254396677
Q_Learning [85/300]: mean_loss=0.03130953316576779
Q_Learning [86/300]: mean_loss=0.1274389736354351
Q_Learning [87/300]: mean_loss=0.016246518353000283
Q_Learning [88/300]: mean_loss=0.06113154161721468
Q_Learning [89/300]: mean_loss=0.07759122271090746
Q_Learning [90/300]: mean_loss=0.07600119058042765
Q_Learning [91/300]: mean_loss=0.04048475809395313
Q_Learning [92/300]: mean_loss=0.05127903586253524
Q_Learning [93/300]: mean_loss=0.1131517207249999
Q_Learning [94/300]: mean_loss=0.0687433211132884
Q_Learning [95/300]: mean_loss=0.10636624321341515
Q_Learning [96/300]: mean_loss=0.05076712882146239
Q_Learning [97/300]: mean_loss=0.05640594661235809
Q_Learning [98/300]: mean_loss=0.08127335924655199
Q_Learning [99/300]: mean_loss=0.024848346365615726
Q_Learning [100/300]: mean_loss=0.15968474932014942
Q_Learning [101/300]: mean_loss=0.10287892632186413
Q_Learning [102/300]: mean_loss=0.060666030272841454
Q_Learning [103/300]: mean_loss=0.04769592359662056
Q_Learning [104/300]: mean_loss=0.06543130753561854
Q_Learning [105/300]: mean_loss=0.03852061973884702
Q_Learning [106/300]: mean_loss=0.016030655475333333
Q_Learning [107/300]: mean_loss=0.028084440855309367
Q_Learning [108/300]: mean_loss=0.04269336489960551
Q_Learning [109/300]: mean_loss=0.036507655400782824
Q_Learning [110/300]: mean_loss=0.07511696498841047
Q_Learning [111/300]: mean_loss=0.03437274228781462
Q_Learning [112/300]: mean_loss=0.1279168203473091
Q_Learning [113/300]: mean_loss=0.060805900022387505
Q_Learning [114/300]: mean_loss=0.09419858828186989
Q_Learning [115/300]: mean_loss=0.06402129726484418
Q_Learning [116/300]: mean_loss=0.04337962390854955
Q_Learning [117/300]: mean_loss=0.047828941605985165
Q_Learning [118/300]: mean_loss=0.044184207916259766
Q_Learning [119/300]: mean_loss=0.14822707697749138
Q_Learning [120/300]: mean_loss=0.09708171524107456
Q_Learning [121/300]: mean_loss=0.09747538063675165
Q_Learning [122/300]: mean_loss=0.08049630746245384
Q_Learning [123/300]: mean_loss=0.039851507637649775
Q_Learning [124/300]: mean_loss=0.014837360009551048
Q_Learning [125/300]: mean_loss=0.203919667750597
Q_Learning [126/300]: mean_loss=0.06342644616961479
Q_Learning [127/300]: mean_loss=0.07377106230705976
Q_Learning [128/300]: mean_loss=0.041012398432940245
Q_Learning [129/300]: mean_loss=0.04199812561273575
Q_Learning [130/300]: mean_loss=0.019359216326847672
Q_Learning [131/300]: mean_loss=0.04185199202038348
Q_Learning [132/300]: mean_loss=0.01951538270805031
Q_Learning [133/300]: mean_loss=0.029101521475240588
Q_Learning [134/300]: mean_loss=0.019100474193692207
Q_Learning [135/300]: mean_loss=0.09996016696095467
Q_Learning [136/300]: mean_loss=0.029120814753696322
Q_Learning [137/300]: mean_loss=0.030056742718443274
Q_Learning [138/300]: mean_loss=0.013625489082187414
Q_Learning [139/300]: mean_loss=0.017251837183721364
Q_Learning [140/300]: mean_loss=0.03407680103555322
Q_Learning [141/300]: mean_loss=0.04412834998220205
Q_Learning [142/300]: mean_loss=0.021418607095256448
Q_Learning [143/300]: mean_loss=0.024502008454874158
Q_Learning [144/300]: mean_loss=0.01136985095217824
Q_Learning [145/300]: mean_loss=0.05092861410230398
Q_Learning [146/300]: mean_loss=0.017754381289705634
Q_Learning [147/300]: mean_loss=0.01483847526833415
Q_Learning [148/300]: mean_loss=0.047427147161215544
Q_Learning [149/300]: mean_loss=0.07807079935446382
Q_Learning [150/300]: mean_loss=0.11460045631974936
Q_Learning [151/300]: mean_loss=0.034161382587626576
Q_Learning [152/300]: mean_loss=0.016976040904410183
Q_Learning [153/300]: mean_loss=0.031056241132318974
Q_Learning [154/300]: mean_loss=0.024372030748054385
Q_Learning [155/300]: mean_loss=0.012170689878985286
Q_Learning [156/300]: mean_loss=0.018887453014031053
Q_Learning [157/300]: mean_loss=0.1438712403178215
Q_Learning [158/300]: mean_loss=0.009549056645482779
Q_Learning [159/300]: mean_loss=0.02840854972600937
Q_Learning [160/300]: mean_loss=0.027117787394672632
Q_Learning [161/300]: mean_loss=0.03540971037000418
Q_Learning [162/300]: mean_loss=0.017717213020659983
Q_Learning [163/300]: mean_loss=0.061393116135150194
Q_Learning [164/300]: mean_loss=0.014501641155220568
Q_Learning [165/300]: mean_loss=0.012192752677947283
Q_Learning [166/300]: mean_loss=0.024455273058265448
Q_Learning [167/300]: mean_loss=0.03572407132014632
Q_Learning [168/300]: mean_loss=0.03335045836865902
Q_Learning [169/300]: mean_loss=0.05278467945754528
Q_Learning [170/300]: mean_loss=0.18648156337440014
Q_Learning [171/300]: mean_loss=0.019053876749239862
Q_Learning [172/300]: mean_loss=0.019975891336798668
Q_Learning [173/300]: mean_loss=0.02477378281764686
Q_Learning [174/300]: mean_loss=0.012076536775566638
Q_Learning [175/300]: mean_loss=0.010870469035580754
Q_Learning [176/300]: mean_loss=0.004230939201079309
Q_Learning [177/300]: mean_loss=0.03892750828526914
Q_Learning [178/300]: mean_loss=0.035106555093079805
Q_Learning [179/300]: mean_loss=0.026514603290706873
Q_Learning [180/300]: mean_loss=0.02727631409652531
Q_Learning [181/300]: mean_loss=0.029346601106226444
Q_Learning [182/300]: mean_loss=0.031822371762245893
Q_Learning [183/300]: mean_loss=0.013200173387303948
Q_Learning [184/300]: mean_loss=0.004989452485460788
Q_Learning [185/300]: mean_loss=0.025906305760145187
Q_Learning [186/300]: mean_loss=0.031779904616996646
Q_Learning [187/300]: mean_loss=0.030013553565368056
Q_Learning [188/300]: mean_loss=0.023097099270671606
Q_Learning [189/300]: mean_loss=0.062441373243927956
Q_Learning [190/300]: mean_loss=0.025103784166276455
Q_Learning [191/300]: mean_loss=0.12233906798064709
Q_Learning [192/300]: mean_loss=0.02350183855742216
Q_Learning [193/300]: mean_loss=0.01959861791692674
Q_Learning [194/300]: mean_loss=0.018472485011443496
Q_Learning [195/300]: mean_loss=0.024193902732804418
Q_Learning [196/300]: mean_loss=0.016261022072285414
Q_Learning [197/300]: mean_loss=0.0404694932512939
Q_Learning [198/300]: mean_loss=0.017518741195090115
Q_Learning [199/300]: mean_loss=0.09148031007498503
Q_Learning [200/300]: mean_loss=0.01863576890900731
Q_Learning [201/300]: mean_loss=0.03154645301401615
Q_Learning [202/300]: mean_loss=0.01481998129747808
Q_Learning [203/300]: mean_loss=0.011514315963722765
Q_Learning [204/300]: mean_loss=0.012496128329075873
Q_Learning [205/300]: mean_loss=0.07188315037637949
Q_Learning [206/300]: mean_loss=0.013119007577188313
Q_Learning [207/300]: mean_loss=0.05437413556501269
Q_Learning [208/300]: mean_loss=0.046565556433051825
Q_Learning [209/300]: mean_loss=0.054554101545363665
Q_Learning [210/300]: mean_loss=0.027821390889585018
Q_Learning [211/300]: mean_loss=0.016469352296553552
Q_Learning [212/300]: mean_loss=0.08034188020974398
Q_Learning [213/300]: mean_loss=0.04192838864400983
Q_Learning [214/300]: mean_loss=0.010789255728013813
Q_Learning [215/300]: mean_loss=0.03683825070038438
Q_Learning [216/300]: mean_loss=0.03885545069351792
Q_Learning [217/300]: mean_loss=0.011783231166191399
Q_Learning [218/300]: mean_loss=0.00775389454793185
Q_Learning [219/300]: mean_loss=0.060400469694286585
Q_Learning [220/300]: mean_loss=0.012859840877354145
Q_Learning [221/300]: mean_loss=0.03330897679552436
Q_Learning [222/300]: mean_loss=0.018095526611432433
Q_Learning [223/300]: mean_loss=0.02834930131211877
Q_Learning [224/300]: mean_loss=0.0063982942956499755
Q_Learning [225/300]: mean_loss=0.027199577540159225
Q_Learning [226/300]: mean_loss=0.028858187841251493
Q_Learning [227/300]: mean_loss=0.01589537237305194
Q_Learning [228/300]: mean_loss=0.024868543725460768
Q_Learning [229/300]: mean_loss=0.04683773359283805
Q_Learning [230/300]: mean_loss=0.01593818236142397
Q_Learning [231/300]: mean_loss=0.021108091110363603
Q_Learning [232/300]: mean_loss=0.021069497801363468
Q_Learning [233/300]: mean_loss=0.016920038033276796
Q_Learning [234/300]: mean_loss=0.03512222692370415
Q_Learning [235/300]: mean_loss=0.09611125756055117
Q_Learning [236/300]: mean_loss=0.06918447138741612
Q_Learning [237/300]: mean_loss=0.03390331519767642
Q_Learning [238/300]: mean_loss=0.10830639116466045
Q_Learning [239/300]: mean_loss=0.06615924462676048
Q_Learning [240/300]: mean_loss=0.059248954290524125
Q_Learning [241/300]: mean_loss=0.03453618520870805
Q_Learning [242/300]: mean_loss=0.0329293766990304
Q_Learning [243/300]: mean_loss=0.03904229821637273
Q_Learning [244/300]: mean_loss=0.02217289572581649
Q_Learning [245/300]: mean_loss=0.043268267065286636
Q_Learning [246/300]: mean_loss=0.018858761992305517
Q_Learning [247/300]: mean_loss=0.007111396000254899
Q_Learning [248/300]: mean_loss=0.07310525886714458
Q_Learning [249/300]: mean_loss=0.012559286435134709
Q_Learning [250/300]: mean_loss=0.018376697087660432
Q_Learning [251/300]: mean_loss=0.010037719854153693
Q_Learning [252/300]: mean_loss=0.022341580130159855
Q_Learning [253/300]: mean_loss=0.013836189056746662
Q_Learning [254/300]: mean_loss=0.01804698328487575
Q_Learning [255/300]: mean_loss=0.03787972847931087
Q_Learning [256/300]: mean_loss=0.0165041193831712
Q_Learning [257/300]: mean_loss=0.01597034779842943
Q_Learning [258/300]: mean_loss=0.026489969110116363
Q_Learning [259/300]: mean_loss=0.009650474763475358
Q_Learning [260/300]: mean_loss=0.006077651516534388
Q_Learning [261/300]: mean_loss=0.021088876761496067
Q_Learning [262/300]: mean_loss=0.026347859064117074
Q_Learning [263/300]: mean_loss=0.011586170410737395
Q_Learning [264/300]: mean_loss=0.021141829900443554
Q_Learning [265/300]: mean_loss=0.016299897339195013
Q_Learning [266/300]: mean_loss=0.01420142117422074
Q_Learning [267/300]: mean_loss=0.010501316632144153
Q_Learning [268/300]: mean_loss=0.0050443007494322956
Q_Learning [269/300]: mean_loss=0.02183657535351813
Q_Learning [270/300]: mean_loss=0.013436898356303573
Q_Learning [271/300]: mean_loss=0.022585688391700387
Q_Learning [272/300]: mean_loss=0.007302077778149396
Q_Learning [273/300]: mean_loss=0.00881027418654412
Q_Learning [274/300]: mean_loss=0.010896381922066212
Q_Learning [275/300]: mean_loss=0.012456489843316376
Q_Learning [276/300]: mean_loss=0.012808773783035576
Q_Learning [277/300]: mean_loss=0.02883460628800094
Q_Learning [278/300]: mean_loss=0.021762894233688712
Q_Learning [279/300]: mean_loss=0.018454586155712605
Q_Learning [280/300]: mean_loss=0.02704302640631795
Q_Learning [281/300]: mean_loss=0.020977457519620657
Q_Learning [282/300]: mean_loss=0.032253514509648085
Q_Learning [283/300]: mean_loss=0.01983213471248746
Q_Learning [284/300]: mean_loss=0.013234883197583258
Q_Learning [285/300]: mean_loss=0.022379318485036492
Q_Learning [286/300]: mean_loss=0.014575326116755605
Q_Learning [287/300]: mean_loss=0.018013773951679468
Q_Learning [288/300]: mean_loss=0.01745623128954321
Q_Learning [289/300]: mean_loss=0.04436727752909064
Q_Learning [290/300]: mean_loss=0.0073453832301311195
Q_Learning [291/300]: mean_loss=0.011146597098559141
Q_Learning [292/300]: mean_loss=0.007602346304338425
Q_Learning [293/300]: mean_loss=0.014879458583891392
Q_Learning [294/300]: mean_loss=0.013488798402249813
Q_Learning [295/300]: mean_loss=0.034843266941607
Q_Learning [296/300]: mean_loss=0.03703977353870869
Q_Learning [297/300]: mean_loss=0.019451649393886328
Q_Learning [298/300]: mean_loss=0.017042365157976747
Q_Learning [299/300]: mean_loss=0.019427502062171698
Q_Learning [300/300]: mean_loss=0.04454251937568188
Number of Samples after Autoencoder testing: 300
First Spike after testing: [0.7634661 1.3648105]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 1, 1, 1, 0, 3, 2, 1, 1, 2, 2, 0, 3, 1, 0, 1, 3, 1, 0, 0, 1, 2, 1, 0, 1, 2, 3, 2, 1, 0, 2, 1, 1, 0, 3, 1, 1, 0, 2, 1, 2, 3, 3, 1, 2, 0, 2, 0, 0, 0, 2, 2, 1, 1, 0, 2, 2, 3, 2, 4, 0, 2, 5, 1, 2, 2, 0, 2, 1, 1, 4, 2, 1, 0, 1, 5, 2, 1, 2, 0, 1, 2, 1, 5, 0, 5, 0, 0, 1, 5, 5, 2, 0, 2, 2, 0, 2, 1, 4, 2, 1, 5, 0, 0, 0, 1, 5, 0, 1, 5, 1, 1, 5, 0, 2, 2, 5, 5, 5, 2, 0, 5, 1, 0, 1, 1, 0, 5, 1, 2, 5, 0, 1, 0, 0, 2, 5, 1, 5, 5, 1, 0, 1, 1, 1, 5, 2, 0, 0, 1, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 0, 1, 2, 0, 5, 1, 1, 1, 0, 1, 5, 1, 0, 1, 0, 1, 5, 2, 1, 0, 1, 2, 2, 2, 0, 1, 5, 2, 1, 4, 0, 2, 2, 2, 5, 1, 5, 0, 0, 3, 2, 0, 0, 2, 1, 5, 1, 0, 4, 5, 1, 5, 0, 1, 1, 0, 5, 1, 1, 5, 3, 1, 2, 1, 5, 1, 0, 5, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 2, 5, 0, 3, 2, 1, 1, 1, 5, 2, 1, 2, 1, 1, 0, 0, 1, 2, 3, 0, 0, 1, 2, 5, 0, 2, 1, 0, 0, 1, 5, 2, 2, 1, 1, 0, 0, 1, 1, 5, 1, 5]
Centroids: [[-1.9645367, -0.53223836], [-0.824867, -0.24980225], [0.74662906, 1.3828627]]
Centroids: [[0.7844504, 1.2954669], [-0.7551267, -0.47812313], [-1.9847733, -0.038453292], [-0.007864296, 2.4001877], [1.6539551, 0.4257385], [-2.14291, -0.8023582]]
Contingency Matrix: 
[[ 0 24 41  0  0 38]
 [ 1 75 22  1  0  1]
 [80  1  0 11  5  0]]
[[0, 24, 41, 0, 0, 38], [1, 75, 22, 1, 0, 1], [80, 1, 0, 11, 5, 0]]
[[0, 24, 41, 0, 0, 38], [1, 75, 22, 1, 0, 1], [80, 1, 0, 11, 5, 0]]
[0, 1, 2, 3, 4, 5]
[[-1, 24, 41, 0, 0, 38], [-1, 75, 22, 1, 0, 1], [-1, -1, -1, -1, -1, -1]]
[[-1, -1, 41, 0, 0, 38], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
Match_Labels: {2: 0, 1: 1, 0: 2}
New Contingency Matrix: 
[[41 24  0  0  0 38]
 [22 75  1  1  0  1]
 [ 0  1 80 11  5  0]]
New Clustered Label Sequence: [2, 1, 0, 3, 4, 5]
Diagonal_Elements: [41, 75, 80], Sum: 196
All_Elements: [41, 24, 0, 0, 0, 38, 22, 75, 1, 1, 0, 1, 0, 1, 80, 11, 5, 0], Sum: 300
Accuracy: 0.6533333333333333
