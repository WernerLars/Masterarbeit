Seed: 6
Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_6_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_6_opt_temp_noisy/C_Easy1_noise005.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-14_37_27
Normalisation: False
Template Matching: True
Optimising Autoencoder: True
Update Factor: 1
Noisy Batches: True
Noisy Factor: 0.1
Epochs: 8
Batch Size: 1
maximal Spikes for Autoencoder Training : 700
maximal Spikes for Training: 1000
Input Size: 47
Chosen Model: Convolutional Autoencoder
ConvolutionalAutoencoder(
  (encoder): Sequential(
    (0): Conv1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Conv1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=37, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): ConvTranspose1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=12, out_features=47, bias=True)
  )
)
MSELoss()
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0
)
---Q Learning Parameters---
Normalisation: False
Punishment Coefficient: 1.1
Alpha: 0.8
Epsilon: 0.01
Gamma: 0.97
Initial Episode Number: 0
Episode Number Coefficient: 1.4
Number of Random Features: 20
Planning Number: 20
Max Random Features: 60
New Episode Number: 72
New Episode Number: 143
New Episode Number: 215
New Episode Number: 286
New Episode Number: 358
New Episode Number: 429
New Episode Number: 500
New Episode Number: 572
New Episode Number: 643
New Episode Number: 715
               0       1      2       3   ...      7      8      9     10
new_cluster -7.73 -116.22 -48.92 -128.76  ... -214.40 -12.86 -70.70 -2.84
c1          -7.62 -120.87 -48.65 -129.07  ... -214.41 -14.86 -70.83 -2.82
c2          -7.60 -118.32 -45.80 -128.37  ... -214.80 -13.75 -70.83 -2.70
c3          -7.60 -120.18 -47.49 -133.95  ... -214.41 -13.61 -70.71 -2.64
c4          -7.61 -117.01 -45.78 -128.19  ... -214.40 -14.65 -70.71 -2.79
c5          -7.61 -121.04 -47.93 -131.15  ... -214.74 -14.91 -70.82 -3.16
c6          -7.79 -123.09 -51.97 -133.28  ... -214.80 -14.64 -70.83 -2.80
c7          -7.84 -122.14 -46.85 -130.04  ... -214.41 -12.83 -70.82 -2.71
c8          -7.64 -117.15 -47.99 -129.96  ... -214.81 -12.24 -70.71 -2.87
c9          -7.62 -116.34 -47.95 -129.59  ... -214.53 -13.34 -70.73 -2.83
c10         -7.62 -120.76 -48.21 -132.94  ... -214.46 -13.30 -70.82 -2.75

[11 rows x 11 columns]
\begin{tabular}{lrrrrrrrrrrr}
\toprule
{} &    0  &      1  &     2  &      3  &     4  &      5  &      6  &      7  &     8  &     9  &    10 \\
\midrule
new\_cluster & -7.73 & -116.22 & -48.92 & -128.76 & -62.06 & -144.22 & -242.14 & -214.40 & -12.86 & -70.70 & -2.84 \\
c1          & -7.62 & -120.87 & -48.65 & -129.07 & -62.08 & -146.98 & -241.97 & -214.41 & -14.86 & -70.83 & -2.82 \\
c2          & -7.60 & -118.32 & -45.80 & -128.37 & -62.06 & -143.79 & -241.91 & -214.80 & -13.75 & -70.83 & -2.70 \\
c3          & -7.60 & -120.18 & -47.49 & -133.95 & -62.10 & -140.75 & -242.05 & -214.41 & -13.61 & -70.71 & -2.64 \\
c4          & -7.61 & -117.01 & -45.78 & -128.19 & -62.08 & -150.42 & -241.90 & -214.40 & -14.65 & -70.71 & -2.79 \\
c5          & -7.61 & -121.04 & -47.93 & -131.15 & -62.06 & -147.54 & -241.98 & -214.74 & -14.91 & -70.82 & -3.16 \\
c6          & -7.79 & -123.09 & -51.97 & -133.28 & -62.06 & -150.64 & -242.00 & -214.80 & -14.64 & -70.83 & -2.80 \\
c7          & -7.84 & -122.14 & -46.85 & -130.04 & -62.08 & -143.58 & -242.03 & -214.41 & -12.83 & -70.82 & -2.71 \\
c8          & -7.64 & -117.15 & -47.99 & -129.96 & -62.08 & -146.35 & -241.91 & -214.81 & -12.24 & -70.71 & -2.87 \\
c9          & -7.62 & -116.34 & -47.95 & -129.59 & -62.08 & -149.00 & -241.97 & -214.53 & -13.34 & -70.73 & -2.83 \\
c10         & -7.62 & -120.76 & -48.21 & -132.94 & -62.06 & -144.83 & -241.98 & -214.46 & -13.30 & -70.82 & -2.75 \\
\bottomrule
\end{tabular}

                               0              1   ...            9             10
new_cluster  [-4.84, new_cluster]  [-113.47, c1]  ...  [-67.95, c9]  [-0.14, c10]
c1           [-4.84, new_cluster]  [-118.08, c1]  ...  [-67.95, c9]  [-0.18, c10]
c2           [-4.84, new_cluster]  [-115.58, c1]  ...  [-67.95, c9]  [-0.04, c10]
c3           [-4.84, new_cluster]  [-117.43, c1]  ...  [-67.95, c9]  [-0.01, c10]
c4           [-4.84, new_cluster]  [-113.99, c1]  ...  [-67.95, c9]  [-0.02, c10]
c5           [-4.84, new_cluster]   [-118.3, c1]  ...  [-67.95, c9]   [-0.4, c10]
c6           [-4.84, new_cluster]  [-120.34, c1]  ...  [-67.95, c9]  [-0.03, c10]
c7           [-4.84, new_cluster]  [-119.35, c1]  ...  [-67.95, c9]  [-0.05, c10]
c8           [-4.84, new_cluster]  [-114.41, c1]  ...  [-67.95, c9]  [-0.18, c10]
c9           [-4.84, new_cluster]   [-113.6, c1]  ...  [-67.95, c9]  [-0.14, c10]
c10          [-4.84, new_cluster]  [-117.96, c1]  ...  [-67.95, c9]  [-0.04, c10]

[11 rows x 11 columns]
\begin{tabular}{llllllllllll}
\toprule
{} &                    0  &             1  &            2  &             3  &            4  &             5  &             6  &             7  &            8  &            9  &            10 \\
\midrule
new\_cluster &  [-4.84, new\_cluster] &  [-113.47, c1] &  [-46.28, c2] &  [-126.13, c3] &  [-59.35, c4] &  [-141.14, c5] &  [-239.28, c6] &  [-211.89, c7] &  [-10.14, c8] &  [-67.95, c9] &  [-0.14, c10] \\
c1          &  [-4.84, new\_cluster] &  [-118.08, c1] &  [-46.01, c2] &   [-126.5, c3] &  [-59.35, c4] &  [-143.91, c5] &  [-239.28, c6] &  [-211.89, c7] &   [-12.1, c8] &  [-67.95, c9] &  [-0.18, c10] \\
c2          &  [-4.84, new\_cluster] &  [-115.58, c1] &  [-43.21, c2] &  [-125.79, c3] &  [-59.35, c4] &  [-140.63, c5] &  [-239.28, c6] &  [-211.89, c7] &  [-10.98, c8] &  [-67.95, c9] &  [-0.04, c10] \\
c3          &  [-4.84, new\_cluster] &  [-117.43, c1] &  [-44.64, c2] &  [-131.08, c3] &  [-59.35, c4] &  [-137.67, c5] &  [-239.28, c6] &  [-211.89, c7] &  [-10.71, c8] &  [-67.95, c9] &  [-0.01, c10] \\
c4          &  [-4.84, new\_cluster] &  [-113.99, c1] &  [-43.16, c2] &  [-125.61, c3] &  [-59.35, c4] &  [-147.36, c5] &  [-239.28, c6] &  [-211.89, c7] &  [-11.88, c8] &  [-67.95, c9] &  [-0.02, c10] \\
c5          &  [-4.84, new\_cluster] &   [-118.3, c1] &  [-45.03, c2] &  [-128.55, c3] &  [-59.35, c4] &  [-144.47, c5] &  [-239.28, c6] &  [-211.89, c7] &  [-12.18, c8] &  [-67.95, c9] &   [-0.4, c10] \\
c6          &  [-4.84, new\_cluster] &  [-120.34, c1] &  [-49.07, c2] &  [-130.67, c3] &  [-59.35, c4] &  [-147.56, c5] &  [-239.28, c6] &  [-211.89, c7] &  [-11.91, c8] &  [-67.95, c9] &  [-0.03, c10] \\
c7          &  [-4.84, new\_cluster] &  [-119.35, c1] &  [-43.95, c2] &  [-127.29, c3] &  [-59.35, c4] &  [-140.42, c5] &  [-239.28, c6] &  [-211.89, c7] &   [-9.94, c8] &  [-67.95, c9] &  [-0.05, c10] \\
c8          &  [-4.84, new\_cluster] &  [-114.41, c1] &  [-45.07, c2] &  [-127.21, c3] &  [-59.35, c4] &  [-143.27, c5] &  [-239.28, c6] &  [-211.89, c7] &   [-9.46, c8] &  [-67.95, c9] &  [-0.18, c10] \\
c9          &  [-4.84, new\_cluster] &   [-113.6, c1] &  [-45.03, c2] &  [-126.96, c3] &  [-59.35, c4] &  [-145.85, c5] &  [-239.28, c6] &  [-211.89, c7] &  [-10.32, c8] &  [-67.95, c9] &  [-0.14, c10] \\
c10         &  [-4.84, new\_cluster] &  [-117.96, c1] &  [-45.62, c2] &  [-130.37, c3] &  [-59.35, c4] &  [-141.76, c5] &  [-239.28, c6] &  [-211.89, c7] &  [-10.57, c8] &  [-67.95, c9] &  [-0.04, c10] \\
\bottomrule
\end{tabular}

