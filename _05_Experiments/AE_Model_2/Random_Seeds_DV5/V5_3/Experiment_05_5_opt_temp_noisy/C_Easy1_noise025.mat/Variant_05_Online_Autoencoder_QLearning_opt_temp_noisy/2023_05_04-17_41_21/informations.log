Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_5_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise025.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise025.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_5_opt_temp_noisy/C_Easy1_noise025.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_05_04-17_41_21
Punishment_Coefficient: 1.0
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000125B3B6C898>
Sampling rate: 24000.0
Raw: [-0.1861928  -0.15538047 -0.11159897 ... -0.04566289 -0.07495693
 -0.11387027]
Times: [    288     764     962 ... 1439565 1439599 1439750]
Cluster: [2 1 1 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3298
First aligned Spike Frame: [ 0.30343498  0.30504401  0.30003499  0.28306832  0.25612953  0.20234245
  0.11026158  0.00607927 -0.07206812 -0.11511366 -0.12845949 -0.13294027
 -0.18390234 -0.33132976 -0.53531084 -0.64122966 -0.43321471  0.14319913
  0.78508862  1.13178271  1.12964756  0.95557126  0.768731    0.62108183
  0.50039946  0.39401216  0.30447426  0.22854935  0.15922545  0.09984913
  0.06405489  0.05593058  0.05062423  0.00682243 -0.07060307 -0.1367616
 -0.15929316 -0.15555753 -0.15669153 -0.16914157 -0.17192467 -0.15578403
 -0.14071413 -0.14785593 -0.17738608 -0.22110055 -0.28163013]
Cluster 0, Occurrences: 1094
Cluster 1, Occurrences: 1089
Cluster 2, Occurrences: 1115
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.20337089337408543
Online_Training [2/700]: mean_loss=0.2017868608236313
Online_Training [3/700]: mean_loss=0.15198389813303947
Online_Training [4/700]: mean_loss=0.2820863202214241
Online_Training [5/700]: mean_loss=0.16840779781341553
Online_Training [6/700]: mean_loss=0.15858956798911095
Online_Training [7/700]: mean_loss=0.17847954854369164
Online_Training [8/700]: mean_loss=0.09129387885332108
Online_Training [9/700]: mean_loss=0.11712037865072489
Online_Training [10/700]: mean_loss=0.11126863770186901
Online_Training [11/700]: mean_loss=0.38338272273540497
Online_Training [12/700]: mean_loss=0.1237321961671114
Online_Training [13/700]: mean_loss=0.23252342455089092
Online_Training [14/700]: mean_loss=0.10500611271709204
Online_Training [15/700]: mean_loss=0.10160288587212563
Online_Training [16/700]: mean_loss=0.18220343813300133
Online_Training [17/700]: mean_loss=0.07978120632469654
Online_Training [18/700]: mean_loss=0.28956998884677887
Online_Training [19/700]: mean_loss=0.17605344764888287
Online_Training [20/700]: mean_loss=0.37399910390377045
Online_Training [21/700]: mean_loss=0.17122997716069221
Online_Training [22/700]: mean_loss=0.23329322040081024
Online_Training [23/700]: mean_loss=0.25218608044087887
Online_Training [24/700]: mean_loss=0.3864858001470566
Online_Training [25/700]: mean_loss=0.16804698295891285
Online_Training [26/700]: mean_loss=0.04709403356537223
Online_Training [27/700]: mean_loss=0.23879838176071644
Online_Training [28/700]: mean_loss=0.1255134791135788
Online_Training [29/700]: mean_loss=0.24480359628796577
Online_Training [30/700]: mean_loss=0.36982839554548264
Online_Training [31/700]: mean_loss=0.1625987235456705
Online_Training [32/700]: mean_loss=0.12237303704023361
Online_Training [33/700]: mean_loss=0.14219552278518677
Online_Training [34/700]: mean_loss=0.10428106691688299
Online_Training [35/700]: mean_loss=0.2880443222820759
Online_Training [36/700]: mean_loss=0.04430908523499966
Online_Training [37/700]: mean_loss=0.050878317561000586
Online_Training [38/700]: mean_loss=0.04343660781159997
Online_Training [39/700]: mean_loss=0.07871304173022509
Online_Training [40/700]: mean_loss=0.11375144124031067
Online_Training [41/700]: mean_loss=0.09990696888417006
Online_Training [42/700]: mean_loss=0.1982093919068575
Online_Training [43/700]: mean_loss=0.1465886738151312
Online_Training [44/700]: mean_loss=0.04287227289751172
Online_Training [45/700]: mean_loss=0.13042439986020327
Online_Training [46/700]: mean_loss=0.06652869516983628
Online_Training [47/700]: mean_loss=0.06865856796503067
Online_Training [48/700]: mean_loss=0.20514936186373234
Online_Training [49/700]: mean_loss=0.06533984839916229
Online_Training [50/700]: mean_loss=0.11257582996040583
Online_Training [51/700]: mean_loss=0.10250973142683506
Online_Training [52/700]: mean_loss=0.08936732541769743
Online_Training [53/700]: mean_loss=0.13530505262315273
Online_Training [54/700]: mean_loss=0.04006466222926974
Online_Training [55/700]: mean_loss=0.13044742960482836
Online_Training [56/700]: mean_loss=0.3050197660923004
Online_Training [57/700]: mean_loss=0.0753350262530148
Online_Training [58/700]: mean_loss=0.028304068371653557
Online_Training [59/700]: mean_loss=0.21452614478766918
Online_Training [60/700]: mean_loss=0.05332785798236728
Online_Training [61/700]: mean_loss=0.03284042701125145
Online_Training [62/700]: mean_loss=0.14277231879532337
Online_Training [63/700]: mean_loss=0.14722192753106356
Online_Training [64/700]: mean_loss=0.13281036727130413
Online_Training [65/700]: mean_loss=0.10134249646216631
Online_Training [66/700]: mean_loss=0.19974866323173046
Online_Training [67/700]: mean_loss=0.17260758951306343
Online_Training [68/700]: mean_loss=0.42828697338700294
Online_Training [69/700]: mean_loss=0.17702176235616207
Online_Training [70/700]: mean_loss=0.07057943847030401
Online_Training [71/700]: mean_loss=0.13418683223426342
Online_Training [72/700]: mean_loss=0.16968274861574173
Online_Training [73/700]: mean_loss=0.050286497455090284
Online_Training [74/700]: mean_loss=0.22974571585655212
Online_Training [75/700]: mean_loss=0.11250477097928524
Online_Training [76/700]: mean_loss=0.22113780677318573
Online_Training [77/700]: mean_loss=0.06476841680705547
Online_Training [78/700]: mean_loss=0.1142712077125907
Online_Training [79/700]: mean_loss=0.10897821746766567
Online_Training [80/700]: mean_loss=0.12633755430579185
Online_Training [81/700]: mean_loss=0.06289202440530062
Online_Training [82/700]: mean_loss=0.07121473317965865
Online_Training [83/700]: mean_loss=0.1271408163011074
Online_Training [84/700]: mean_loss=0.22932658903300762
Online_Training [85/700]: mean_loss=0.39274150505661964
Online_Training [86/700]: mean_loss=0.1747860498726368
Online_Training [87/700]: mean_loss=0.054717452730983496
Online_Training [88/700]: mean_loss=0.06017858907580376
Online_Training [89/700]: mean_loss=0.1465131752192974
Online_Training [90/700]: mean_loss=0.038079403806477785
Online_Training [91/700]: mean_loss=0.043571979738771915
Online_Training [92/700]: mean_loss=0.18799971230328083
Online_Training [93/700]: mean_loss=0.09169918857514858
Online_Training [94/700]: mean_loss=0.20651528984308243
Online_Training [95/700]: mean_loss=0.10959208849817514
Online_Training [96/700]: mean_loss=0.09048463311046362
Online_Training [97/700]: mean_loss=0.05260735331103206
Online_Training [98/700]: mean_loss=0.08618417289108038
Online_Training [99/700]: mean_loss=0.048552149441093206
Online_Training [100/700]: mean_loss=0.07266703713685274
Online_Training [101/700]: mean_loss=0.022228311514481902
Online_Training [102/700]: mean_loss=0.03871307196095586
Online_Training [103/700]: mean_loss=0.029634556267410517
Online_Training [104/700]: mean_loss=0.04963451158255339
Online_Training [105/700]: mean_loss=0.08736659493297338
Online_Training [106/700]: mean_loss=0.20927131921052933
Online_Training [107/700]: mean_loss=0.13786709308624268
Online_Training [108/700]: mean_loss=0.03766769263893366
Online_Training [109/700]: mean_loss=0.1297057569026947
Online_Training [110/700]: mean_loss=0.11202639993280172
Online_Training [111/700]: mean_loss=0.08304452989250422
Online_Training [112/700]: mean_loss=0.03734820755198598
Online_Training [113/700]: mean_loss=0.024177926243282855
Online_Training [114/700]: mean_loss=0.028122673276811838
Online_Training [115/700]: mean_loss=0.11614195071160793
Online_Training [116/700]: mean_loss=0.023671774193644524
Online_Training [117/700]: mean_loss=0.05681106308475137
Online_Training [118/700]: mean_loss=0.13021459057927132
Online_Training [119/700]: mean_loss=0.11295523587614298
Online_Training [120/700]: mean_loss=0.127491126768291
Online_Training [121/700]: mean_loss=0.04283965239301324
Online_Training [122/700]: mean_loss=0.014007246820256114
Online_Training [123/700]: mean_loss=0.06493207579478621
Online_Training [124/700]: mean_loss=0.025673321448266506
Online_Training [125/700]: mean_loss=0.031073963968083262
Online_Training [126/700]: mean_loss=0.03941617952659726
Online_Training [127/700]: mean_loss=0.03159020282328129
Online_Training [128/700]: mean_loss=0.11188799981027842
Online_Training [129/700]: mean_loss=0.12666335236281157
Online_Training [130/700]: mean_loss=0.04117934592068195
Online_Training [131/700]: mean_loss=0.04670885996893048
Online_Training [132/700]: mean_loss=0.02364340820349753
Online_Training [133/700]: mean_loss=0.0713894497603178
Online_Training [134/700]: mean_loss=0.023760532727465034
Online_Training [135/700]: mean_loss=0.04191145487129688
Online_Training [136/700]: mean_loss=0.04377448745071888
Online_Training [137/700]: mean_loss=0.06158916652202606
Online_Training [138/700]: mean_loss=0.036974921356886625
Online_Training [139/700]: mean_loss=0.0220665717497468
Online_Training [140/700]: mean_loss=0.019795736530795693
Online_Training [141/700]: mean_loss=0.07078665122389793
Online_Training [142/700]: mean_loss=0.031889943638816476
Online_Training [143/700]: mean_loss=0.14932313375175
Online_Training [144/700]: mean_loss=0.047306325286626816
Online_Training [145/700]: mean_loss=0.0229321860242635
Online_Training [146/700]: mean_loss=0.0773340305313468
Online_Training [147/700]: mean_loss=0.08806874789297581
Online_Training [148/700]: mean_loss=0.08009669836610556
Online_Training [149/700]: mean_loss=0.024173933546990156
Online_Training [150/700]: mean_loss=0.021452041575685143
Online_Training [151/700]: mean_loss=0.015691450098529458
Online_Training [152/700]: mean_loss=0.018534697825089097
Online_Training [153/700]: mean_loss=0.012380339321680367
Online_Training [154/700]: mean_loss=0.010596065665595233
Online_Training [155/700]: mean_loss=0.02638908918015659
Online_Training [156/700]: mean_loss=0.049042887054383755
Online_Training [157/700]: mean_loss=0.040730237029492855
Online_Training [158/700]: mean_loss=0.05699815833941102
Online_Training [159/700]: mean_loss=0.07035653805360198
Online_Training [160/700]: mean_loss=0.012483284343034029
Online_Training [161/700]: mean_loss=0.16013635508716106
Online_Training [162/700]: mean_loss=0.12046623043715954
Online_Training [163/700]: mean_loss=0.01976426807232201
Online_Training [164/700]: mean_loss=0.06856060167774558
Online_Training [165/700]: mean_loss=0.0864762719720602
Online_Training [166/700]: mean_loss=0.043214181903749704
Online_Training [167/700]: mean_loss=0.05113892210647464
Online_Training [168/700]: mean_loss=0.10955984704196453
Online_Training [169/700]: mean_loss=0.1345285102725029
Online_Training [170/700]: mean_loss=0.06427434738725424
Online_Training [171/700]: mean_loss=0.02580830710940063
Online_Training [172/700]: mean_loss=0.018165246350690722
Online_Training [173/700]: mean_loss=0.04047477664425969
Online_Training [174/700]: mean_loss=0.05728831235319376
Online_Training [175/700]: mean_loss=0.10946614854037762
Online_Training [176/700]: mean_loss=0.02038030093535781
Online_Training [177/700]: mean_loss=0.06051847571507096
Online_Training [178/700]: mean_loss=0.056418065913021564
Online_Training [179/700]: mean_loss=0.036755794659256935
Online_Training [180/700]: mean_loss=0.08335398696362972
Online_Training [181/700]: mean_loss=0.06835448322817683
Online_Training [182/700]: mean_loss=0.05267097568139434
Online_Training [183/700]: mean_loss=0.05484203342348337
Online_Training [184/700]: mean_loss=0.033436867874115705
Online_Training [185/700]: mean_loss=0.03102023876272142
Online_Training [186/700]: mean_loss=0.021138365380465984
Online_Training [187/700]: mean_loss=0.05993197998031974
Online_Training [188/700]: mean_loss=0.03260600892826915
Online_Training [189/700]: mean_loss=0.02668977132998407
Online_Training [190/700]: mean_loss=0.07201682031154633
Online_Training [191/700]: mean_loss=0.02158931246958673
Online_Training [192/700]: mean_loss=0.05654730414971709
Online_Training [193/700]: mean_loss=0.045448978431522846
Online_Training [194/700]: mean_loss=0.06895569618791342
Online_Training [195/700]: mean_loss=0.04027457255870104
Online_Training [196/700]: mean_loss=0.029332341393455863
Online_Training [197/700]: mean_loss=0.02334561152383685
Online_Training [198/700]: mean_loss=0.046982649713754654
Online_Training [199/700]: mean_loss=0.06609922740608454
Online_Training [200/700]: mean_loss=0.024124914780259132
Online_Training [201/700]: mean_loss=0.1063920110464096
Online_Training [202/700]: mean_loss=0.1269757431000471
Online_Training [203/700]: mean_loss=0.06395766092464328
Online_Training [204/700]: mean_loss=0.14425866678357124
Online_Training [205/700]: mean_loss=0.09495189040899277
Online_Training [206/700]: mean_loss=0.20517040602862835
Online_Training [207/700]: mean_loss=0.02417021943256259
Online_Training [208/700]: mean_loss=0.01117709930986166
Online_Training [209/700]: mean_loss=0.03386459080502391
Online_Training [210/700]: mean_loss=0.10769330710172653
Online_Training [211/700]: mean_loss=0.03352505597285926
Online_Training [212/700]: mean_loss=0.028860810911282897
Online_Training [213/700]: mean_loss=0.046270076651126146
Online_Training [214/700]: mean_loss=0.04803754203021526
Online_Training [215/700]: mean_loss=0.07894718926399946
Online_Training [216/700]: mean_loss=0.03707660082727671
Online_Training [217/700]: mean_loss=0.08170184958726168
Online_Training [218/700]: mean_loss=0.05563001660630107
Online_Training [219/700]: mean_loss=0.025307458359748125
Online_Training [220/700]: mean_loss=0.018117233412340283
Online_Training [221/700]: mean_loss=0.05832388671115041
Online_Training [222/700]: mean_loss=0.034173705615103245
Online_Training [223/700]: mean_loss=0.01635018363595009
Online_Training [224/700]: mean_loss=0.03455410385504365
Online_Training [225/700]: mean_loss=0.023251352598890662
Online_Training [226/700]: mean_loss=0.020229276502504945
Online_Training [227/700]: mean_loss=0.026447031646966934
Online_Training [228/700]: mean_loss=0.040259774308651686
Online_Training [229/700]: mean_loss=0.024946705903857946
Online_Training [230/700]: mean_loss=0.02471071551553905
Online_Training [231/700]: mean_loss=0.028342709876596928
Online_Training [232/700]: mean_loss=0.03786064079031348
Online_Training [233/700]: mean_loss=0.034881944535300136
Online_Training [234/700]: mean_loss=0.011099537019617856
Online_Training [235/700]: mean_loss=0.0903125237673521
Online_Training [236/700]: mean_loss=0.04635164141654968
Online_Training [237/700]: mean_loss=0.10847737826406956
Online_Training [238/700]: mean_loss=0.025060327956452966
Online_Training [239/700]: mean_loss=0.03256152546964586
Online_Training [240/700]: mean_loss=0.053147911094129086
Online_Training [241/700]: mean_loss=0.03595199901610613
Online_Training [242/700]: mean_loss=0.08405913691967726
Online_Training [243/700]: mean_loss=0.07991563435643911
Online_Training [244/700]: mean_loss=0.12035572621971369
Online_Training [245/700]: mean_loss=0.022335970075801015
Online_Training [246/700]: mean_loss=0.05121668754145503
Online_Training [247/700]: mean_loss=0.04458959586918354
Online_Training [248/700]: mean_loss=0.03600203525274992
Online_Training [249/700]: mean_loss=0.052351722959429026
Online_Training [250/700]: mean_loss=0.04861457319930196
Online_Training [251/700]: mean_loss=0.04667460918426514
Online_Training [252/700]: mean_loss=0.01641460321843624
Online_Training [253/700]: mean_loss=0.45062098652124405
Online_Training [254/700]: mean_loss=0.09702554997056723
Online_Training [255/700]: mean_loss=0.04036033945158124
Online_Training [256/700]: mean_loss=0.06165798660367727
Online_Training [257/700]: mean_loss=0.07734615169465542
Online_Training [258/700]: mean_loss=0.04407363012433052
Online_Training [259/700]: mean_loss=0.11056896392256021
Online_Training [260/700]: mean_loss=0.14074050448834896
Online_Training [261/700]: mean_loss=0.04461879702284932
Online_Training [262/700]: mean_loss=0.032889648573473096
Online_Training [263/700]: mean_loss=0.048156242817640305
Online_Training [264/700]: mean_loss=0.030264846747741103
Online_Training [265/700]: mean_loss=0.0188943890389055
Online_Training [266/700]: mean_loss=0.06935992371290922
Online_Training [267/700]: mean_loss=0.03009029128588736
Online_Training [268/700]: mean_loss=0.016534236492589116
Online_Training [269/700]: mean_loss=0.05265691829845309
Online_Training [270/700]: mean_loss=0.04106521233916283
Online_Training [271/700]: mean_loss=0.04259486263617873
Online_Training [272/700]: mean_loss=0.12372112739831209
Online_Training [273/700]: mean_loss=0.04443460376933217
Online_Training [274/700]: mean_loss=0.10330314561724663
Online_Training [275/700]: mean_loss=0.04341076407581568
Online_Training [276/700]: mean_loss=0.059016176499426365
Online_Training [277/700]: mean_loss=0.028720476431772113
Online_Training [278/700]: mean_loss=0.08354526106268167
Online_Training [279/700]: mean_loss=0.020819720113649964
Online_Training [280/700]: mean_loss=0.06393581908196211
Online_Training [281/700]: mean_loss=0.04265337157994509
Online_Training [282/700]: mean_loss=0.049708832055330276
Online_Training [283/700]: mean_loss=0.02742852922528982
Online_Training [284/700]: mean_loss=0.1180853433907032
Online_Training [285/700]: mean_loss=0.10005684848874807
Online_Training [286/700]: mean_loss=0.043104084208607674
Online_Training [287/700]: mean_loss=0.025711443042382598
Online_Training [288/700]: mean_loss=0.04568130662664771
Online_Training [289/700]: mean_loss=0.05815496714785695
Online_Training [290/700]: mean_loss=0.06801305525004864
Online_Training [291/700]: mean_loss=0.09616523701697588
Online_Training [292/700]: mean_loss=0.027043816167861223
Online_Training [293/700]: mean_loss=0.033015235560014844
Online_Training [294/700]: mean_loss=0.05621595261618495
Online_Training [295/700]: mean_loss=0.07005684915930033
Online_Training [296/700]: mean_loss=0.03382512531243265
Online_Training [297/700]: mean_loss=0.0640307366847992
Online_Training [298/700]: mean_loss=0.06774613354355097
Online_Training [299/700]: mean_loss=0.03710843110457063
Online_Training [300/700]: mean_loss=0.06698251981288195
Online_Training [301/700]: mean_loss=0.015059979516081512
Online_Training [302/700]: mean_loss=0.08066967502236366
Online_Training [303/700]: mean_loss=0.02006790298037231
Online_Training [304/700]: mean_loss=0.009557467652484775
Online_Training [305/700]: mean_loss=0.015099779469892383
Online_Training [306/700]: mean_loss=0.06046260055154562
Online_Training [307/700]: mean_loss=0.024804385844618082
Online_Training [308/700]: mean_loss=0.017857945756986737
Online_Training [309/700]: mean_loss=0.021038335748016834
Online_Training [310/700]: mean_loss=0.02735794964246452
Online_Training [311/700]: mean_loss=0.020566007122397423
Online_Training [312/700]: mean_loss=0.2471579723060131
Online_Training [313/700]: mean_loss=0.042303523514419794
Online_Training [314/700]: mean_loss=0.013861397746950388
Online_Training [315/700]: mean_loss=0.030804551672190428
Online_Training [316/700]: mean_loss=0.1352842003107071
Online_Training [317/700]: mean_loss=0.03328657755628228
Online_Training [318/700]: mean_loss=0.08570378180593252
Online_Training [319/700]: mean_loss=0.0387189956381917
Online_Training [320/700]: mean_loss=0.009890704415738583
Online_Training [321/700]: mean_loss=0.09268139116466045
Online_Training [322/700]: mean_loss=0.13679312355816364
Online_Training [323/700]: mean_loss=0.10924773942679167
Online_Training [324/700]: mean_loss=0.02695832890458405
Online_Training [325/700]: mean_loss=0.025279461639001966
Online_Training [326/700]: mean_loss=0.01771089807152748
Online_Training [327/700]: mean_loss=0.04042746499180794
Online_Training [328/700]: mean_loss=0.013865573448128998
Online_Training [329/700]: mean_loss=0.0605286443606019
Online_Training [330/700]: mean_loss=0.11917190253734589
Online_Training [331/700]: mean_loss=0.021678405115380883
Online_Training [332/700]: mean_loss=0.05182068655267358
Online_Training [333/700]: mean_loss=0.037752771750092506
Online_Training [334/700]: mean_loss=0.028565376298502088
Online_Training [335/700]: mean_loss=0.13933305069804192
Online_Training [336/700]: mean_loss=0.028105138335376978
Online_Training [337/700]: mean_loss=0.06194298481568694
Online_Training [338/700]: mean_loss=0.04566065547987819
Online_Training [339/700]: mean_loss=0.02775424299761653
Online_Training [340/700]: mean_loss=0.031138369347900152
Online_Training [341/700]: mean_loss=0.02265680581331253
Online_Training [342/700]: mean_loss=0.1520712450146675
Online_Training [343/700]: mean_loss=0.034898482728749514
Online_Training [344/700]: mean_loss=0.04918320709839463
Online_Training [345/700]: mean_loss=0.04625487932935357
Online_Training [346/700]: mean_loss=0.07663942687213421
Online_Training [347/700]: mean_loss=0.07871572021394968
Online_Training [348/700]: mean_loss=0.07362592499703169
Online_Training [349/700]: mean_loss=0.07817563228309155
Online_Training [350/700]: mean_loss=0.14403335470706224
Online_Training [351/700]: mean_loss=0.44685521349310875
Online_Training [352/700]: mean_loss=0.05861866008490324
Online_Training [353/700]: mean_loss=0.10165060218423605
Online_Training [354/700]: mean_loss=0.016482560662552714
Online_Training [355/700]: mean_loss=0.010825958685018122
Online_Training [356/700]: mean_loss=0.045217664912343025
Online_Training [357/700]: mean_loss=0.025060187792405486
Online_Training [358/700]: mean_loss=0.14177043829113245
Online_Training [359/700]: mean_loss=0.10310312360525131
Online_Training [360/700]: mean_loss=0.1788344457745552
Online_Training [361/700]: mean_loss=0.1229289136826992
Online_Training [362/700]: mean_loss=0.048048779368400574
Online_Training [363/700]: mean_loss=0.05149841541424394
Online_Training [364/700]: mean_loss=0.04271046910434961
Online_Training [365/700]: mean_loss=0.068443413823843
Online_Training [366/700]: mean_loss=0.046841247007250786
Online_Training [367/700]: mean_loss=0.03917840914800763
Online_Training [368/700]: mean_loss=0.18223491683602333
Online_Training [369/700]: mean_loss=0.018478992860764265
Online_Training [370/700]: mean_loss=0.0779581991955638
Online_Training [371/700]: mean_loss=0.047952745109796524
Online_Training [372/700]: mean_loss=0.03224546508863568
Online_Training [373/700]: mean_loss=0.12055611703544855
Online_Training [374/700]: mean_loss=0.031473371433094144
Online_Training [375/700]: mean_loss=0.017090222565457225
Online_Training [376/700]: mean_loss=0.05411011725664139
Online_Training [377/700]: mean_loss=0.02571588894352317
Online_Training [378/700]: mean_loss=0.026189730502665043
Online_Training [379/700]: mean_loss=0.03327885502949357
Online_Training [380/700]: mean_loss=0.02788824401795864
Online_Training [381/700]: mean_loss=0.03781957505270839
Online_Training [382/700]: mean_loss=0.06021059025079012
Online_Training [383/700]: mean_loss=0.25807277113199234
Online_Training [384/700]: mean_loss=0.09749854262918234
Online_Training [385/700]: mean_loss=0.06736083840951324
Online_Training [386/700]: mean_loss=0.01246876863297075
Online_Training [387/700]: mean_loss=0.02741672028787434
Online_Training [388/700]: mean_loss=0.13630271144211292
Online_Training [389/700]: mean_loss=0.23019477725028992
Online_Training [390/700]: mean_loss=0.02885490981861949
Online_Training [391/700]: mean_loss=0.030858762562274933
Online_Training [392/700]: mean_loss=0.03510140720754862
Online_Training [393/700]: mean_loss=0.03553196927532554
Online_Training [394/700]: mean_loss=0.031742938328534365
Online_Training [395/700]: mean_loss=0.018985594855621457
Online_Training [396/700]: mean_loss=0.018006146885454655
Online_Training [397/700]: mean_loss=0.02006689365953207
Online_Training [398/700]: mean_loss=0.06967263855040073
Online_Training [399/700]: mean_loss=0.018215283402241766
Online_Training [400/700]: mean_loss=0.021008440759032965
Online_Training [401/700]: mean_loss=0.010024244664236903
Online_Training [402/700]: mean_loss=0.030717877903953195
Online_Training [403/700]: mean_loss=0.04979443736374378
Online_Training [404/700]: mean_loss=0.0397923500277102
Online_Training [405/700]: mean_loss=0.06225957442075014
Online_Training [406/700]: mean_loss=0.1047827573493123
Online_Training [407/700]: mean_loss=0.03374607884325087
Online_Training [408/700]: mean_loss=0.0598401646129787
Online_Training [409/700]: mean_loss=0.027630416909232736
Online_Training [410/700]: mean_loss=0.06902084592729807
Online_Training [411/700]: mean_loss=0.07773036975413561
Online_Training [412/700]: mean_loss=0.03379468573257327
Online_Training [413/700]: mean_loss=0.05479884007945657
Online_Training [414/700]: mean_loss=0.02738967351615429
Online_Training [415/700]: mean_loss=0.12198455538600683
Online_Training [416/700]: mean_loss=0.026163345202803612
Online_Training [417/700]: mean_loss=0.027570849750190973
Online_Training [418/700]: mean_loss=0.06119413860142231
Online_Training [419/700]: mean_loss=0.02870980487205088
Online_Training [420/700]: mean_loss=0.03867636853829026
Online_Training [421/700]: mean_loss=0.03967425273731351
Online_Training [422/700]: mean_loss=0.18183876760303974
Online_Training [423/700]: mean_loss=0.017615570919588208
Online_Training [424/700]: mean_loss=0.07501980196684599
Online_Training [425/700]: mean_loss=0.03839421458542347
Online_Training [426/700]: mean_loss=0.03244299674406648
Online_Training [427/700]: mean_loss=0.0718629527837038
Online_Training [428/700]: mean_loss=0.12213874328881502
Online_Training [429/700]: mean_loss=0.06994250882416964
Online_Training [430/700]: mean_loss=0.004738357092719525
Online_Training [431/700]: mean_loss=0.009739115368574858
Online_Training [432/700]: mean_loss=0.06343544367700815
Online_Training [433/700]: mean_loss=0.047654037829488516
Online_Training [434/700]: mean_loss=0.0462259235791862
Online_Training [435/700]: mean_loss=0.11098269373178482
Online_Training [436/700]: mean_loss=0.01240530435461551
Online_Training [437/700]: mean_loss=0.09772508032619953
Online_Training [438/700]: mean_loss=0.06497814087197185
Online_Training [439/700]: mean_loss=0.05605022143572569
Online_Training [440/700]: mean_loss=0.06351205380633473
Online_Training [441/700]: mean_loss=0.0538451187312603
Online_Training [442/700]: mean_loss=0.033977442188188434
Online_Training [443/700]: mean_loss=0.021119860699400306
Online_Training [444/700]: mean_loss=0.022138478234410286
Online_Training [445/700]: mean_loss=0.08097775559872389
Online_Training [446/700]: mean_loss=0.21162783354520798
Online_Training [447/700]: mean_loss=0.15065771900117397
Online_Training [448/700]: mean_loss=0.08212285209447145
Online_Training [449/700]: mean_loss=0.027473783353343606
Online_Training [450/700]: mean_loss=0.022262938553467393
Online_Training [451/700]: mean_loss=0.02758259861730039
Online_Training [452/700]: mean_loss=0.04976570187136531
Online_Training [453/700]: mean_loss=0.03321888600476086
Online_Training [454/700]: mean_loss=0.013903019134886563
Online_Training [455/700]: mean_loss=0.006920373474713415
Online_Training [456/700]: mean_loss=0.03994793724268675
Online_Training [457/700]: mean_loss=0.08794639725238085
Online_Training [458/700]: mean_loss=0.08264295943081379
Online_Training [459/700]: mean_loss=0.06305707711726427
Online_Training [460/700]: mean_loss=0.14524191059172153
Online_Training [461/700]: mean_loss=0.07496478874236345
Online_Training [462/700]: mean_loss=0.1175675168633461
Online_Training [463/700]: mean_loss=0.038593854289501905
Online_Training [464/700]: mean_loss=0.08909471891820431
Online_Training [465/700]: mean_loss=0.022234634961932898
Online_Training [466/700]: mean_loss=0.07505084574222565
Online_Training [467/700]: mean_loss=0.09899310674518347
Online_Training [468/700]: mean_loss=0.05574566591531038
Online_Training [469/700]: mean_loss=0.015725728473626077
Online_Training [470/700]: mean_loss=0.043973243329674006
Online_Training [471/700]: mean_loss=0.024216689867898822
Online_Training [472/700]: mean_loss=0.02161818719469011
Online_Training [473/700]: mean_loss=0.04832131648436189
Online_Training [474/700]: mean_loss=0.04448849521577358
Online_Training [475/700]: mean_loss=0.054532993119210005
Online_Training [476/700]: mean_loss=0.02755983965471387
Online_Training [477/700]: mean_loss=0.02519468078389764
Online_Training [478/700]: mean_loss=0.009001557307783514
Online_Training [479/700]: mean_loss=0.1085680378600955
Online_Training [480/700]: mean_loss=0.009666995494626462
Online_Training [481/700]: mean_loss=0.06930525600910187
Online_Training [482/700]: mean_loss=0.07866440154612064
Online_Training [483/700]: mean_loss=0.05335103441029787
Online_Training [484/700]: mean_loss=0.018997013103216887
Online_Training [485/700]: mean_loss=0.03682745806872845
Online_Training [486/700]: mean_loss=0.10730513464659452
Online_Training [487/700]: mean_loss=0.05649184761568904
Online_Training [488/700]: mean_loss=0.04548711841925979
Online_Training [489/700]: mean_loss=0.06021654140204191
Online_Training [490/700]: mean_loss=0.014910501195117831
Online_Training [491/700]: mean_loss=0.03892690688371658
Online_Training [492/700]: mean_loss=0.08478210959583521
Online_Training [493/700]: mean_loss=0.010190333588980138
Online_Training [494/700]: mean_loss=0.06561499554663897
Online_Training [495/700]: mean_loss=0.09492608718574047
Online_Training [496/700]: mean_loss=0.05466046743094921
Online_Training [497/700]: mean_loss=0.022647724952548742
Online_Training [498/700]: mean_loss=0.020749175222590566
Online_Training [499/700]: mean_loss=0.09268784336745739
Online_Training [500/700]: mean_loss=0.022486880887299776
Online_Training [501/700]: mean_loss=0.026622673263773322
Online_Training [502/700]: mean_loss=0.03555676760151982
Online_Training [503/700]: mean_loss=0.030275068478658795
Online_Training [504/700]: mean_loss=0.05734697496518493
Online_Training [505/700]: mean_loss=0.0407436559908092
Online_Training [506/700]: mean_loss=0.047864488791674376
Online_Training [507/700]: mean_loss=0.0253411834128201
Online_Training [508/700]: mean_loss=0.0421340293250978
Online_Training [509/700]: mean_loss=0.0693059153854847
Online_Training [510/700]: mean_loss=0.1116047827526927
Online_Training [511/700]: mean_loss=0.07843681797385216
Online_Training [512/700]: mean_loss=0.048369006253778934
Online_Training [513/700]: mean_loss=0.04957346199080348
Online_Training [514/700]: mean_loss=0.069044035859406
Online_Training [515/700]: mean_loss=0.08009105641394854
Online_Training [516/700]: mean_loss=0.04705791175365448
Online_Training [517/700]: mean_loss=0.08179030194878578
Online_Training [518/700]: mean_loss=0.012673712219111621
Online_Training [519/700]: mean_loss=0.038764710538089275
Online_Training [520/700]: mean_loss=0.05130865331739187
Online_Training [521/700]: mean_loss=0.0702868141233921
Online_Training [522/700]: mean_loss=0.12318253796547651
Online_Training [523/700]: mean_loss=0.0631034136749804
Online_Training [524/700]: mean_loss=0.04403191898018122
Online_Training [525/700]: mean_loss=0.03681046701967716
Online_Training [526/700]: mean_loss=0.056914825923740864
Online_Training [527/700]: mean_loss=0.15156647935509682
Online_Training [528/700]: mean_loss=0.0697378721088171
Online_Training [529/700]: mean_loss=0.04179636808112264
Online_Training [530/700]: mean_loss=0.09026402235031128
Online_Training [531/700]: mean_loss=0.031867502722889185
Online_Training [532/700]: mean_loss=0.032472559018060565
Online_Training [533/700]: mean_loss=0.08600659854710102
Online_Training [534/700]: mean_loss=0.05191133776679635
Online_Training [535/700]: mean_loss=0.024962202413007617
Online_Training [536/700]: mean_loss=0.029382206965237856
Online_Training [537/700]: mean_loss=0.033201940823346376
Online_Training [538/700]: mean_loss=0.109308079816401
Online_Training [539/700]: mean_loss=0.03857010672800243
Online_Training [540/700]: mean_loss=0.021196368848904967
Online_Training [541/700]: mean_loss=0.16597620211541653
Online_Training [542/700]: mean_loss=0.02793394634500146
Online_Training [543/700]: mean_loss=0.1405656337738037
Online_Training [544/700]: mean_loss=0.017952378373593092
Online_Training [545/700]: mean_loss=0.0464427201077342
Online_Training [546/700]: mean_loss=0.01907060411758721
Online_Training [547/700]: mean_loss=0.09637596923857927
Online_Training [548/700]: mean_loss=0.12082304526120424
Online_Training [549/700]: mean_loss=0.023837260203436017
Online_Training [550/700]: mean_loss=0.02944299695082009
Online_Training [551/700]: mean_loss=0.010611812700517476
Online_Training [552/700]: mean_loss=0.03268529544584453
Online_Training [553/700]: mean_loss=0.019822957227006555
Online_Training [554/700]: mean_loss=0.03245554049499333
Online_Training [555/700]: mean_loss=0.06732991896569729
Online_Training [556/700]: mean_loss=0.03156905062496662
Online_Training [557/700]: mean_loss=0.05149079114198685
Online_Training [558/700]: mean_loss=0.035997910890728235
Online_Training [559/700]: mean_loss=0.020069904625415802
Online_Training [560/700]: mean_loss=0.04650894133374095
Online_Training [561/700]: mean_loss=0.04133444931358099
Online_Training [562/700]: mean_loss=0.03434845665469766
Online_Training [563/700]: mean_loss=0.04982899688184261
Online_Training [564/700]: mean_loss=0.026046399725601077
Online_Training [565/700]: mean_loss=0.14248374104499817
Online_Training [566/700]: mean_loss=0.0466362708248198
Online_Training [567/700]: mean_loss=0.020925280870869756
Online_Training [568/700]: mean_loss=0.014462110819295049
Online_Training [569/700]: mean_loss=0.12084786873310804
Online_Training [570/700]: mean_loss=0.04318925179541111
Online_Training [571/700]: mean_loss=0.011742296046577394
Online_Training [572/700]: mean_loss=0.07944959495216608
Online_Training [573/700]: mean_loss=0.02811389695852995
Online_Training [574/700]: mean_loss=0.07242281176149845
Online_Training [575/700]: mean_loss=0.10832048021256924
Online_Training [576/700]: mean_loss=0.08525898214429617
Online_Training [577/700]: mean_loss=0.11922172736376524
Online_Training [578/700]: mean_loss=0.03831023583188653
Online_Training [579/700]: mean_loss=0.04517120495438576
Online_Training [580/700]: mean_loss=0.03450533654540777
Online_Training [581/700]: mean_loss=0.042745811864733696
Online_Training [582/700]: mean_loss=0.026091963052749634
Online_Training [583/700]: mean_loss=0.06976027600467205
Online_Training [584/700]: mean_loss=0.02106448169797659
Online_Training [585/700]: mean_loss=0.10356472991406918
Online_Training [586/700]: mean_loss=0.02121446607634425
Online_Training [587/700]: mean_loss=0.09638177324086428
Online_Training [588/700]: mean_loss=0.04601928498595953
Online_Training [589/700]: mean_loss=0.11933906842023134
Online_Training [590/700]: mean_loss=0.02567302156239748
Online_Training [591/700]: mean_loss=0.059256010223180056
Online_Training [592/700]: mean_loss=0.014432841097004712
Online_Training [593/700]: mean_loss=0.07168222684413195
Online_Training [594/700]: mean_loss=0.02198225143365562
Online_Training [595/700]: mean_loss=0.07628789357841015
Online_Training [596/700]: mean_loss=0.0352926068007946
Online_Training [597/700]: mean_loss=0.03633533860556781
Online_Training [598/700]: mean_loss=0.059158057905733585
Online_Training [599/700]: mean_loss=0.019751892192289233
Online_Training [600/700]: mean_loss=0.05085428198799491
Online_Training [601/700]: mean_loss=0.03792783338576555
Online_Training [602/700]: mean_loss=0.16611958295106888
Online_Training [603/700]: mean_loss=0.37008702754974365
Online_Training [604/700]: mean_loss=0.020510582020506263
Online_Training [605/700]: mean_loss=0.10898472927510738
Online_Training [606/700]: mean_loss=0.04529719240963459
Online_Training [607/700]: mean_loss=0.05061947926878929
Online_Training [608/700]: mean_loss=0.04644079227000475
Online_Training [609/700]: mean_loss=0.06202789582312107
Online_Training [610/700]: mean_loss=0.035410559736192226
Online_Training [611/700]: mean_loss=0.0585759412497282
Online_Training [612/700]: mean_loss=0.03256241627968848
Online_Training [613/700]: mean_loss=0.06410549627617002
Online_Training [614/700]: mean_loss=0.06401492794975638
Online_Training [615/700]: mean_loss=0.05378663865849376
Online_Training [616/700]: mean_loss=0.121448396705091
Online_Training [617/700]: mean_loss=0.049175201915204525
Online_Training [618/700]: mean_loss=0.06008853390812874
Online_Training [619/700]: mean_loss=0.054542012978345156
Online_Training [620/700]: mean_loss=0.021542806643992662
Online_Training [621/700]: mean_loss=0.027387955458834767
Online_Training [622/700]: mean_loss=0.08009373303502798
Online_Training [623/700]: mean_loss=0.1767746675759554
Online_Training [624/700]: mean_loss=0.06413956824690104
Online_Training [625/700]: mean_loss=0.06394310900941491
Online_Training [626/700]: mean_loss=0.02835585968568921
Online_Training [627/700]: mean_loss=0.04137768130749464
Online_Training [628/700]: mean_loss=0.154578210785985
Online_Training [629/700]: mean_loss=0.058975026942789555
Online_Training [630/700]: mean_loss=0.18079987913370132
Online_Training [631/700]: mean_loss=0.019395840587094426
Online_Training [632/700]: mean_loss=0.24673635698854923
Online_Training [633/700]: mean_loss=0.047504307236522436
Online_Training [634/700]: mean_loss=0.01300727145280689
Online_Training [635/700]: mean_loss=0.018807609798386693
Online_Training [636/700]: mean_loss=0.05155154038220644
Online_Training [637/700]: mean_loss=0.012937315972521901
Online_Training [638/700]: mean_loss=0.04544551996514201
Online_Training [639/700]: mean_loss=0.17024377547204494
Online_Training [640/700]: mean_loss=0.04185888031497598
Online_Training [641/700]: mean_loss=0.029621999245136976
Online_Training [642/700]: mean_loss=0.027042070170864463
Online_Training [643/700]: mean_loss=0.034063626546412706
Online_Training [644/700]: mean_loss=0.07311977073550224
Online_Training [645/700]: mean_loss=0.030889730667695403
Online_Training [646/700]: mean_loss=0.04348431387916207
Online_Training [647/700]: mean_loss=0.012860847054980695
Online_Training [648/700]: mean_loss=0.03770230803638697
Online_Training [649/700]: mean_loss=0.047257810831069946
Online_Training [650/700]: mean_loss=0.056581792421638966
Online_Training [651/700]: mean_loss=0.0454076430760324
Online_Training [652/700]: mean_loss=0.07669775374233723
Online_Training [653/700]: mean_loss=0.0666522835381329
Online_Training [654/700]: mean_loss=0.028993753483518958
Online_Training [655/700]: mean_loss=0.11154814902693033
Online_Training [656/700]: mean_loss=0.028147797798737884
Online_Training [657/700]: mean_loss=0.07047032471746206
Online_Training [658/700]: mean_loss=0.034382808255031705
Online_Training [659/700]: mean_loss=0.08291227463632822
Online_Training [660/700]: mean_loss=0.030715497443452477
Online_Training [661/700]: mean_loss=0.07049792911857367
Online_Training [662/700]: mean_loss=0.07933786418288946
Online_Training [663/700]: mean_loss=0.10973779950290918
Online_Training [664/700]: mean_loss=0.04015125473961234
Online_Training [665/700]: mean_loss=0.07784556690603495
Online_Training [666/700]: mean_loss=0.036521659698337317
Online_Training [667/700]: mean_loss=0.04302748618647456
Online_Training [668/700]: mean_loss=0.07590211182832718
Online_Training [669/700]: mean_loss=0.0444274116307497
Online_Training [670/700]: mean_loss=0.017789326608181
Online_Training [671/700]: mean_loss=0.03358161193318665
Online_Training [672/700]: mean_loss=0.09220717195421457
Online_Training [673/700]: mean_loss=0.25763366371393204
Online_Training [674/700]: mean_loss=0.04759032232686877
Online_Training [675/700]: mean_loss=0.13987040519714355
Online_Training [676/700]: mean_loss=0.02917002630420029
Online_Training [677/700]: mean_loss=0.055027753580361605
Online_Training [678/700]: mean_loss=0.060934304259717464
Online_Training [679/700]: mean_loss=0.11659771110862494
Online_Training [680/700]: mean_loss=0.03262537135742605
Online_Training [681/700]: mean_loss=0.031151733128353953
Online_Training [682/700]: mean_loss=0.05018510203808546
Online_Training [683/700]: mean_loss=0.02986543462611735
Online_Training [684/700]: mean_loss=0.02357662608847022
Online_Training [685/700]: mean_loss=0.07754329778254032
Online_Training [686/700]: mean_loss=0.013053929666057229
Online_Training [687/700]: mean_loss=0.028627900406718254
Online_Training [688/700]: mean_loss=0.06389901135116816
Online_Training [689/700]: mean_loss=0.027135592885315418
Online_Training [690/700]: mean_loss=0.06629614438861609
Online_Training [691/700]: mean_loss=0.041731119621545076
Online_Training [692/700]: mean_loss=0.08223111368715763
Online_Training [693/700]: mean_loss=0.020731388358399272
Online_Training [694/700]: mean_loss=0.03256426006555557
Online_Training [695/700]: mean_loss=0.06789152976125479
Online_Training [696/700]: mean_loss=0.03377142967656255
Online_Training [697/700]: mean_loss=0.09226367715746164
Online_Training [698/700]: mean_loss=0.05257899546995759
Online_Training [699/700]: mean_loss=0.04074504692107439
Online_Training [700/700]: mean_loss=0.07312519289553165
Q_Learning [1/300]: mean_loss=0.20337089337408543
Q_Learning [2/300]: mean_loss=0.2017868608236313
Q_Learning [3/300]: mean_loss=0.15198389813303947
Q_Learning [4/300]: mean_loss=0.2820863202214241
Q_Learning [5/300]: mean_loss=0.16840779781341553
Q_Learning [6/300]: mean_loss=0.15858956798911095
Q_Learning [7/300]: mean_loss=0.17847954854369164
Q_Learning [8/300]: mean_loss=0.09129387885332108
Q_Learning [9/300]: mean_loss=0.11712037865072489
Q_Learning [10/300]: mean_loss=0.11126863770186901
Q_Learning [11/300]: mean_loss=0.38338272273540497
Q_Learning [12/300]: mean_loss=0.1237321961671114
Q_Learning [13/300]: mean_loss=0.23252342455089092
Q_Learning [14/300]: mean_loss=0.10500611271709204
Q_Learning [15/300]: mean_loss=0.10160288587212563
Q_Learning [16/300]: mean_loss=0.18220343813300133
Q_Learning [17/300]: mean_loss=0.07978120632469654
Q_Learning [18/300]: mean_loss=0.28956998884677887
Q_Learning [19/300]: mean_loss=0.17605344764888287
Q_Learning [20/300]: mean_loss=0.37399910390377045
Q_Learning [21/300]: mean_loss=0.17122997716069221
Q_Learning [22/300]: mean_loss=0.23329322040081024
Q_Learning [23/300]: mean_loss=0.25218608044087887
Q_Learning [24/300]: mean_loss=0.3864858001470566
Q_Learning [25/300]: mean_loss=0.16804698295891285
Q_Learning [26/300]: mean_loss=0.04709403356537223
Q_Learning [27/300]: mean_loss=0.23879838176071644
Q_Learning [28/300]: mean_loss=0.1255134791135788
Q_Learning [29/300]: mean_loss=0.24480359628796577
Q_Learning [30/300]: mean_loss=0.36982839554548264
Q_Learning [31/300]: mean_loss=0.1625987235456705
Q_Learning [32/300]: mean_loss=0.12237303704023361
Q_Learning [33/300]: mean_loss=0.14219552278518677
Q_Learning [34/300]: mean_loss=0.10428106691688299
Q_Learning [35/300]: mean_loss=0.2880443222820759
Q_Learning [36/300]: mean_loss=0.04430908523499966
Q_Learning [37/300]: mean_loss=0.050878317561000586
Q_Learning [38/300]: mean_loss=0.04343660781159997
Q_Learning [39/300]: mean_loss=0.07871304173022509
Q_Learning [40/300]: mean_loss=0.11375144124031067
Q_Learning [41/300]: mean_loss=0.09990696888417006
Q_Learning [42/300]: mean_loss=0.1982093919068575
Q_Learning [43/300]: mean_loss=0.1465886738151312
Q_Learning [44/300]: mean_loss=0.04287227289751172
Q_Learning [45/300]: mean_loss=0.13042439986020327
Q_Learning [46/300]: mean_loss=0.06652869516983628
Q_Learning [47/300]: mean_loss=0.06865856796503067
Q_Learning [48/300]: mean_loss=0.20514936186373234
Q_Learning [49/300]: mean_loss=0.06533984839916229
Q_Learning [50/300]: mean_loss=0.11257582996040583
Q_Learning [51/300]: mean_loss=0.10250973142683506
Q_Learning [52/300]: mean_loss=0.08936732541769743
Q_Learning [53/300]: mean_loss=0.13530505262315273
Q_Learning [54/300]: mean_loss=0.04006466222926974
Q_Learning [55/300]: mean_loss=0.13044742960482836
Q_Learning [56/300]: mean_loss=0.3050197660923004
Q_Learning [57/300]: mean_loss=0.0753350262530148
Q_Learning [58/300]: mean_loss=0.028304068371653557
Q_Learning [59/300]: mean_loss=0.21452614478766918
Q_Learning [60/300]: mean_loss=0.05332785798236728
Q_Learning [61/300]: mean_loss=0.03284042701125145
Q_Learning [62/300]: mean_loss=0.14277231879532337
Q_Learning [63/300]: mean_loss=0.14722192753106356
Q_Learning [64/300]: mean_loss=0.13281036727130413
Q_Learning [65/300]: mean_loss=0.10134249646216631
Q_Learning [66/300]: mean_loss=0.19974866323173046
Q_Learning [67/300]: mean_loss=0.17260758951306343
Q_Learning [68/300]: mean_loss=0.42828697338700294
Q_Learning [69/300]: mean_loss=0.17702176235616207
Q_Learning [70/300]: mean_loss=0.07057943847030401
Q_Learning [71/300]: mean_loss=0.13418683223426342
Q_Learning [72/300]: mean_loss=0.16968274861574173
Q_Learning [73/300]: mean_loss=0.050286497455090284
Q_Learning [74/300]: mean_loss=0.22974571585655212
Q_Learning [75/300]: mean_loss=0.11250477097928524
Q_Learning [76/300]: mean_loss=0.22113780677318573
Q_Learning [77/300]: mean_loss=0.06476841680705547
Q_Learning [78/300]: mean_loss=0.1142712077125907
Q_Learning [79/300]: mean_loss=0.10897821746766567
Q_Learning [80/300]: mean_loss=0.12633755430579185
Q_Learning [81/300]: mean_loss=0.06289202440530062
Q_Learning [82/300]: mean_loss=0.07121473317965865
Q_Learning [83/300]: mean_loss=0.1271408163011074
Q_Learning [84/300]: mean_loss=0.22932658903300762
Q_Learning [85/300]: mean_loss=0.39274150505661964
Q_Learning [86/300]: mean_loss=0.1747860498726368
Q_Learning [87/300]: mean_loss=0.054717452730983496
Q_Learning [88/300]: mean_loss=0.06017858907580376
Q_Learning [89/300]: mean_loss=0.1465131752192974
Q_Learning [90/300]: mean_loss=0.038079403806477785
Q_Learning [91/300]: mean_loss=0.043571979738771915
Q_Learning [92/300]: mean_loss=0.18799971230328083
Q_Learning [93/300]: mean_loss=0.09169918857514858
Q_Learning [94/300]: mean_loss=0.20651528984308243
Q_Learning [95/300]: mean_loss=0.10959208849817514
Q_Learning [96/300]: mean_loss=0.09048463311046362
Q_Learning [97/300]: mean_loss=0.05260735331103206
Q_Learning [98/300]: mean_loss=0.08618417289108038
Q_Learning [99/300]: mean_loss=0.048552149441093206
Q_Learning [100/300]: mean_loss=0.07266703713685274
Q_Learning [101/300]: mean_loss=0.022228311514481902
Q_Learning [102/300]: mean_loss=0.03871307196095586
Q_Learning [103/300]: mean_loss=0.029634556267410517
Q_Learning [104/300]: mean_loss=0.04963451158255339
Q_Learning [105/300]: mean_loss=0.08736659493297338
Q_Learning [106/300]: mean_loss=0.20927131921052933
Q_Learning [107/300]: mean_loss=0.13786709308624268
Q_Learning [108/300]: mean_loss=0.03766769263893366
Q_Learning [109/300]: mean_loss=0.1297057569026947
Q_Learning [110/300]: mean_loss=0.11202639993280172
Q_Learning [111/300]: mean_loss=0.08304452989250422
Q_Learning [112/300]: mean_loss=0.03734820755198598
Q_Learning [113/300]: mean_loss=0.024177926243282855
Q_Learning [114/300]: mean_loss=0.028122673276811838
Q_Learning [115/300]: mean_loss=0.11614195071160793
Q_Learning [116/300]: mean_loss=0.023671774193644524
Q_Learning [117/300]: mean_loss=0.05681106308475137
Q_Learning [118/300]: mean_loss=0.13021459057927132
Q_Learning [119/300]: mean_loss=0.11295523587614298
Q_Learning [120/300]: mean_loss=0.127491126768291
Q_Learning [121/300]: mean_loss=0.04283965239301324
Q_Learning [122/300]: mean_loss=0.014007246820256114
Q_Learning [123/300]: mean_loss=0.06493207579478621
Q_Learning [124/300]: mean_loss=0.025673321448266506
Q_Learning [125/300]: mean_loss=0.031073963968083262
Q_Learning [126/300]: mean_loss=0.03941617952659726
Q_Learning [127/300]: mean_loss=0.03159020282328129
Q_Learning [128/300]: mean_loss=0.11188799981027842
Q_Learning [129/300]: mean_loss=0.12666335236281157
Q_Learning [130/300]: mean_loss=0.04117934592068195
Q_Learning [131/300]: mean_loss=0.04670885996893048
Q_Learning [132/300]: mean_loss=0.02364340820349753
Q_Learning [133/300]: mean_loss=0.0713894497603178
Q_Learning [134/300]: mean_loss=0.023760532727465034
Q_Learning [135/300]: mean_loss=0.04191145487129688
Q_Learning [136/300]: mean_loss=0.04377448745071888
Q_Learning [137/300]: mean_loss=0.06158916652202606
Q_Learning [138/300]: mean_loss=0.036974921356886625
Q_Learning [139/300]: mean_loss=0.0220665717497468
Q_Learning [140/300]: mean_loss=0.019795736530795693
Q_Learning [141/300]: mean_loss=0.07078665122389793
Q_Learning [142/300]: mean_loss=0.031889943638816476
Q_Learning [143/300]: mean_loss=0.14932313375175
Q_Learning [144/300]: mean_loss=0.047306325286626816
Q_Learning [145/300]: mean_loss=0.0229321860242635
Q_Learning [146/300]: mean_loss=0.0773340305313468
Q_Learning [147/300]: mean_loss=0.08806874789297581
Q_Learning [148/300]: mean_loss=0.08009669836610556
Q_Learning [149/300]: mean_loss=0.024173933546990156
Q_Learning [150/300]: mean_loss=0.021452041575685143
Q_Learning [151/300]: mean_loss=0.015691450098529458
Q_Learning [152/300]: mean_loss=0.018534697825089097
Q_Learning [153/300]: mean_loss=0.012380339321680367
Q_Learning [154/300]: mean_loss=0.010596065665595233
Q_Learning [155/300]: mean_loss=0.02638908918015659
Q_Learning [156/300]: mean_loss=0.049042887054383755
Q_Learning [157/300]: mean_loss=0.040730237029492855
Q_Learning [158/300]: mean_loss=0.05699815833941102
Q_Learning [159/300]: mean_loss=0.07035653805360198
Q_Learning [160/300]: mean_loss=0.012483284343034029
Q_Learning [161/300]: mean_loss=0.16013635508716106
Q_Learning [162/300]: mean_loss=0.12046623043715954
Q_Learning [163/300]: mean_loss=0.01976426807232201
Q_Learning [164/300]: mean_loss=0.06856060167774558
Q_Learning [165/300]: mean_loss=0.0864762719720602
Q_Learning [166/300]: mean_loss=0.043214181903749704
Q_Learning [167/300]: mean_loss=0.05113892210647464
Q_Learning [168/300]: mean_loss=0.10955984704196453
Q_Learning [169/300]: mean_loss=0.1345285102725029
Q_Learning [170/300]: mean_loss=0.06427434738725424
Q_Learning [171/300]: mean_loss=0.02580830710940063
Q_Learning [172/300]: mean_loss=0.018165246350690722
Q_Learning [173/300]: mean_loss=0.04047477664425969
Q_Learning [174/300]: mean_loss=0.05728831235319376
Q_Learning [175/300]: mean_loss=0.10946614854037762
Q_Learning [176/300]: mean_loss=0.02038030093535781
Q_Learning [177/300]: mean_loss=0.06051847571507096
Q_Learning [178/300]: mean_loss=0.056418065913021564
Q_Learning [179/300]: mean_loss=0.036755794659256935
Q_Learning [180/300]: mean_loss=0.08335398696362972
Q_Learning [181/300]: mean_loss=0.06835448322817683
Q_Learning [182/300]: mean_loss=0.05267097568139434
Q_Learning [183/300]: mean_loss=0.05484203342348337
Q_Learning [184/300]: mean_loss=0.033436867874115705
Q_Learning [185/300]: mean_loss=0.03102023876272142
Q_Learning [186/300]: mean_loss=0.021138365380465984
Q_Learning [187/300]: mean_loss=0.05993197998031974
Q_Learning [188/300]: mean_loss=0.03260600892826915
Q_Learning [189/300]: mean_loss=0.02668977132998407
Q_Learning [190/300]: mean_loss=0.07201682031154633
Q_Learning [191/300]: mean_loss=0.02158931246958673
Q_Learning [192/300]: mean_loss=0.05654730414971709
Q_Learning [193/300]: mean_loss=0.045448978431522846
Q_Learning [194/300]: mean_loss=0.06895569618791342
Q_Learning [195/300]: mean_loss=0.04027457255870104
Q_Learning [196/300]: mean_loss=0.029332341393455863
Q_Learning [197/300]: mean_loss=0.02334561152383685
Q_Learning [198/300]: mean_loss=0.046982649713754654
Q_Learning [199/300]: mean_loss=0.06609922740608454
Q_Learning [200/300]: mean_loss=0.024124914780259132
Q_Learning [201/300]: mean_loss=0.1063920110464096
Q_Learning [202/300]: mean_loss=0.1269757431000471
Q_Learning [203/300]: mean_loss=0.06395766092464328
Q_Learning [204/300]: mean_loss=0.14425866678357124
Q_Learning [205/300]: mean_loss=0.09495189040899277
Q_Learning [206/300]: mean_loss=0.20517040602862835
Q_Learning [207/300]: mean_loss=0.02417021943256259
Q_Learning [208/300]: mean_loss=0.01117709930986166
Q_Learning [209/300]: mean_loss=0.03386459080502391
Q_Learning [210/300]: mean_loss=0.10769330710172653
Q_Learning [211/300]: mean_loss=0.03352505597285926
Q_Learning [212/300]: mean_loss=0.028860810911282897
Q_Learning [213/300]: mean_loss=0.046270076651126146
Q_Learning [214/300]: mean_loss=0.04803754203021526
Q_Learning [215/300]: mean_loss=0.07894718926399946
Q_Learning [216/300]: mean_loss=0.03707660082727671
Q_Learning [217/300]: mean_loss=0.08170184958726168
Q_Learning [218/300]: mean_loss=0.05563001660630107
Q_Learning [219/300]: mean_loss=0.025307458359748125
Q_Learning [220/300]: mean_loss=0.018117233412340283
Q_Learning [221/300]: mean_loss=0.05832388671115041
Q_Learning [222/300]: mean_loss=0.034173705615103245
Q_Learning [223/300]: mean_loss=0.01635018363595009
Q_Learning [224/300]: mean_loss=0.03455410385504365
Q_Learning [225/300]: mean_loss=0.023251352598890662
Q_Learning [226/300]: mean_loss=0.020229276502504945
Q_Learning [227/300]: mean_loss=0.026447031646966934
Q_Learning [228/300]: mean_loss=0.040259774308651686
Q_Learning [229/300]: mean_loss=0.024946705903857946
Q_Learning [230/300]: mean_loss=0.02471071551553905
Q_Learning [231/300]: mean_loss=0.028342709876596928
Q_Learning [232/300]: mean_loss=0.03786064079031348
Q_Learning [233/300]: mean_loss=0.034881944535300136
Q_Learning [234/300]: mean_loss=0.011099537019617856
Q_Learning [235/300]: mean_loss=0.0903125237673521
Q_Learning [236/300]: mean_loss=0.04635164141654968
Q_Learning [237/300]: mean_loss=0.10847737826406956
Q_Learning [238/300]: mean_loss=0.025060327956452966
Q_Learning [239/300]: mean_loss=0.03256152546964586
Q_Learning [240/300]: mean_loss=0.053147911094129086
Q_Learning [241/300]: mean_loss=0.03595199901610613
Q_Learning [242/300]: mean_loss=0.08405913691967726
Q_Learning [243/300]: mean_loss=0.07991563435643911
Q_Learning [244/300]: mean_loss=0.12035572621971369
Q_Learning [245/300]: mean_loss=0.022335970075801015
Q_Learning [246/300]: mean_loss=0.05121668754145503
Q_Learning [247/300]: mean_loss=0.04458959586918354
Q_Learning [248/300]: mean_loss=0.03600203525274992
Q_Learning [249/300]: mean_loss=0.052351722959429026
Q_Learning [250/300]: mean_loss=0.04861457319930196
Q_Learning [251/300]: mean_loss=0.04667460918426514
Q_Learning [252/300]: mean_loss=0.01641460321843624
Q_Learning [253/300]: mean_loss=0.45062098652124405
Q_Learning [254/300]: mean_loss=0.09702554997056723
Q_Learning [255/300]: mean_loss=0.04036033945158124
Q_Learning [256/300]: mean_loss=0.06165798660367727
Q_Learning [257/300]: mean_loss=0.07734615169465542
Q_Learning [258/300]: mean_loss=0.04407363012433052
Q_Learning [259/300]: mean_loss=0.11056896392256021
Q_Learning [260/300]: mean_loss=0.14074050448834896
Q_Learning [261/300]: mean_loss=0.04461879702284932
Q_Learning [262/300]: mean_loss=0.032889648573473096
Q_Learning [263/300]: mean_loss=0.048156242817640305
Q_Learning [264/300]: mean_loss=0.030264846747741103
Q_Learning [265/300]: mean_loss=0.0188943890389055
Q_Learning [266/300]: mean_loss=0.06935992371290922
Q_Learning [267/300]: mean_loss=0.03009029128588736
Q_Learning [268/300]: mean_loss=0.016534236492589116
Q_Learning [269/300]: mean_loss=0.05265691829845309
Q_Learning [270/300]: mean_loss=0.04106521233916283
Q_Learning [271/300]: mean_loss=0.04259486263617873
Q_Learning [272/300]: mean_loss=0.12372112739831209
Q_Learning [273/300]: mean_loss=0.04443460376933217
Q_Learning [274/300]: mean_loss=0.10330314561724663
Q_Learning [275/300]: mean_loss=0.04341076407581568
Q_Learning [276/300]: mean_loss=0.059016176499426365
Q_Learning [277/300]: mean_loss=0.028720476431772113
Q_Learning [278/300]: mean_loss=0.08354526106268167
Q_Learning [279/300]: mean_loss=0.020819720113649964
Q_Learning [280/300]: mean_loss=0.06393581908196211
Q_Learning [281/300]: mean_loss=0.04265337157994509
Q_Learning [282/300]: mean_loss=0.049708832055330276
Q_Learning [283/300]: mean_loss=0.02742852922528982
Q_Learning [284/300]: mean_loss=0.1180853433907032
Q_Learning [285/300]: mean_loss=0.10005684848874807
Q_Learning [286/300]: mean_loss=0.043104084208607674
Q_Learning [287/300]: mean_loss=0.025711443042382598
Q_Learning [288/300]: mean_loss=0.04568130662664771
Q_Learning [289/300]: mean_loss=0.05815496714785695
Q_Learning [290/300]: mean_loss=0.06801305525004864
Q_Learning [291/300]: mean_loss=0.09616523701697588
Q_Learning [292/300]: mean_loss=0.027043816167861223
Q_Learning [293/300]: mean_loss=0.033015235560014844
Q_Learning [294/300]: mean_loss=0.05621595261618495
Q_Learning [295/300]: mean_loss=0.07005684915930033
Q_Learning [296/300]: mean_loss=0.03382512531243265
Q_Learning [297/300]: mean_loss=0.0640307366847992
Q_Learning [298/300]: mean_loss=0.06774613354355097
Q_Learning [299/300]: mean_loss=0.03710843110457063
Q_Learning [300/300]: mean_loss=0.06698251981288195
Number of Samples after Autoencoder testing: 300
First Spike after testing: [1.5000272  0.13984522]
[0, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 1, 0, 1, 1, 0, 2, 2, 0, 0, 2, 1, 1, 0, 2, 1, 1, 2, 1, 2, 1, 0, 2, 2, 1, 1, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1, 2, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 1, 2, 1, 0, 1, 1, 2, 2, 2, 0, 1, 2, 0, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 1, 1, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2, 1, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 1, 0, 0, 1, 1, 2, 0, 1, 2, 1, 2, 2, 2, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 1, 0, 0, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0]
[0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 1, 0, 0, 3, 1, 1, 1, 0, 0, 2, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2, 4, 1, 0, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 5, 0, 0, 3, 1, 0, 2, 0, 4, 1, 0, 0, 2, 0, 2, 2, 0, 1, 6, 1, 0, 1, 2, 2, 0, 1, 2, 2, 6, 2, 5, 2, 0, 1, 6, 2, 7, 5, 7, 2, 5, 2, 4, 7, 1, 0, 7, 5, 7, 1, 0, 0, 8, 4, 5, 9, 6, 5, 8, 6, 2, 0, 2, 2, 1, 1, 5, 0, 10, 6, 0, 7, 7, 1, 5, 0, 0, 11, 1, 7, 11, 5, 0, 6, 5, 0, 6, 3, 1, 6, 1, 0, 12, 5, 0, 7, 12, 7, 0, 2, 6, 5, 6, 0, 5, 0, 2, 5, 0, 2, 6, 6, 12, 11, 1, 11, 13, 13, 10, 0, 12, 11, 11, 12, 5, 1, 5, 0, 5, 14, 14, 7, 0, 15, 6, 16, 12, 15, 4, 11, 13, 2, 16, 12, 15, 5, 17, 3, 12, 11, 10, 9, 12, 13, 7, 11, 18, 3, 0, 13, 19, 19, 20, 3, 5, 4, 7, 11, 0, 13, 7, 11, 5, 8, 19, 21, 10, 19, 17, 22, 6, 0, 16, 23, 17, 19, 17, 21, 17, 9, 21, 18, 5, 10, 4, 13, 11, 21, 13, 18, 13, 12, 4, 19, 24, 1, 19, 13, 5, 19, 21, 6, 21, 25, 12, 10, 25, 13, 12, 23, 4, 19, 9, 23, 11, 13, 16, 16, 18, 5, 19, 17, 19, 7, 19, 5, 25, 26, 21, 26, 13, 1, 0, 10, 9, 1]
Centroids: [[2.0746694, 1.027753], [-2.8772373, -1.653291], [-2.218697, 4.384926]]
Centroids: [[1.2114602, 0.9023675], [-1.0695583, 3.1037703], [-1.4910003, -0.79323184], [-0.14412634, -1.8090777], [2.4367418, -0.87978804], [-3.2699223, 4.3733015], [-2.745767, 3.0364988], [-2.9859672, -0.8598186], [-1.5559734, -2.4993145], [3.5394027, 3.8091817], [-5.1403136, -0.78325474], [-2.273831, 5.288315], [3.2671242, 1.3329724], [-5.4222913, -2.6502795], [-7.1452074, 2.5216475], [-0.77665395, 5.106026], [-4.247641, 6.488772], [-2.5629683, -4.846947], [4.8812957, -0.047305144], [-1.4633247, 7.908818], [-8.353994, 4.838187], [-6.6973653, -4.11065], [2.775244, -6.7752323], [3.9173024, -1.3776354], [-3.807933, 9.404555], [4.703057, 2.1201918], [-8.447477, -3.3499212]]
Contingency Matrix: 
[[43  5  0  0  9  0  1  0  0  5  0  0 12  0  0  0  0  0  4  0  0  0  0  3
   0  3  0]
 [ 4  0 38  6  0  0  0 15  3  0  7  0  0 13  1  0  0  6  0  0  0  7  1  0
   0  0  2]
 [ 3 33  0  0  0 25 15  0  0  0  0 13  0  0  1  3  5  0  0 12  1  0  0  0
   1  0  0]]
[[43, 5, 0, 0, 9, 0, 1, 0, 0, 5, 0, 0, 12, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 3, 0, 3, 0], [4, 0, 38, 6, 0, 0, 0, 15, 3, 0, 7, 0, 0, 13, 1, 0, 0, 6, 0, 0, 0, 7, 1, 0, 0, 0, 2], [3, 33, 0, 0, 0, 25, 15, 0, 0, 0, 0, 13, 0, 0, 1, 3, 5, 0, 0, 12, 1, 0, 0, 0, 1, 0, 0]]
[[43, 5, 0, 0, 9, 0, 1, 0, 0, 5, 0, 0, 12, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 3, 0, 3, 0], [4, 0, 38, 6, 0, 0, 0, 15, 3, 0, 7, 0, 0, 13, 1, 0, 0, 6, 0, 0, 0, 7, 1, 0, 0, 0, 2], [3, 33, 0, 0, 0, 25, 15, 0, 0, 0, 0, 13, 0, 0, 1, 3, 5, 0, 0, 12, 1, 0, 0, 0, 1, 0, 0]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 0, 38, 6, 0, 0, 0, 15, 3, 0, 7, 0, 0, 13, 1, 0, 0, 6, 0, 0, 0, 7, 1, 0, 0, 0, 2], [-1, 33, 0, 0, 0, 25, 15, 0, 0, 0, 0, 13, 0, 0, 1, 3, 5, 0, 0, 12, 1, 0, 0, 0, 1, 0, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 33, -1, 0, 0, 25, 15, 0, 0, 0, 0, 13, 0, 0, 1, 3, 5, 0, 0, 12, 1, 0, 0, 0, 1, 0, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 0, 1: 2, 2: 1}
New Contingency Matrix: 
[[43  0  5  0  9  0  1  0  0  5  0  0 12  0  0  0  0  0  4  0  0  0  0  3
   0  3  0]
 [ 4 38  0  6  0  0  0 15  3  0  7  0  0 13  1  0  0  6  0  0  0  7  1  0
   0  0  2]
 [ 3  0 33  0  0 25 15  0  0  0  0 13  0  0  1  3  5  0  0 12  1  0  0  0
   1  0  0]]
New Clustered Label Sequence: [0, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]
Diagonal_Elements: [43, 38, 33], Sum: 114
All_Elements: [43, 0, 5, 0, 9, 0, 1, 0, 0, 5, 0, 0, 12, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 3, 0, 3, 0, 4, 38, 0, 6, 0, 0, 0, 15, 3, 0, 7, 0, 0, 13, 1, 0, 0, 6, 0, 0, 0, 7, 1, 0, 0, 0, 2, 3, 0, 33, 0, 0, 25, 15, 0, 0, 0, 0, 13, 0, 0, 1, 3, 5, 0, 0, 12, 1, 0, 0, 0, 1, 0, 0], Sum: 300
Accuracy: 0.38
