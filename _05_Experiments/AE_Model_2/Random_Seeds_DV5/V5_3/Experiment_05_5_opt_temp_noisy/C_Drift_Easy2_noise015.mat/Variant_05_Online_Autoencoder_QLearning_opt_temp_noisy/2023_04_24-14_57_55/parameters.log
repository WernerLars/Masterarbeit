Seed: 5
Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_5_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_5_opt_temp_noisy/C_Drift_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-14_57_55
Normalisation: False
Template Matching: True
Optimising Autoencoder: True
Update Factor: 1
Noisy Batches: True
Noisy Factor: 0.1
Epochs: 8
Batch Size: 1
maximal Spikes for Autoencoder Training : 700
maximal Spikes for Training: 1000
Input Size: 47
Chosen Model: Convolutional Autoencoder
ConvolutionalAutoencoder(
  (encoder): Sequential(
    (0): Conv1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Conv1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=37, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): ConvTranspose1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=12, out_features=47, bias=True)
  )
)
MSELoss()
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0
)
---Q Learning Parameters---
Normalisation: False
Punishment Coefficient: 1.1
Alpha: 0.8
Epsilon: 0.01
Gamma: 0.97
Initial Episode Number: 0
Episode Number Coefficient: 1.4
Number of Random Features: 20
Planning Number: 20
Max Random Features: 60
New Episode Number: 72
New Episode Number: 143
New Episode Number: 215
New Episode Number: 286
New Episode Number: 358
New Episode Number: 429
New Episode Number: 500
New Episode Number: 572
New Episode Number: 643
New Episode Number: 715
                0      1      2      3   ...     7      8      9      10
new_cluster -73.25 -75.20 -93.31 -80.04  ... -70.43 -86.14 -72.28 -80.63
c1          -73.40 -75.82 -94.36 -80.60  ... -70.53 -87.25 -71.70 -80.24
c2          -73.45 -73.84 -96.06 -80.77  ... -71.72 -89.04 -72.83 -80.14
c3          -73.44 -74.67 -94.13 -80.34  ... -72.06 -87.47 -73.03 -80.16
c4          -73.60 -73.87 -93.50 -79.07  ... -70.58 -86.94 -72.05 -80.14
c5          -73.53 -72.37 -93.51 -79.80  ... -70.56 -89.46 -72.48 -80.16
c6          -73.38 -74.61 -95.02 -79.48  ... -70.75 -87.13 -73.30 -80.62
c7          -74.63 -75.51 -94.70 -80.94  ... -69.86 -86.28 -73.21 -80.22
c8          -74.64 -73.54 -94.53 -80.98  ... -71.43 -88.35 -72.36 -80.14
c9          -74.27 -74.92 -94.30 -81.17  ... -71.47 -87.82 -73.43 -80.16
c10         -74.63 -75.46 -94.07 -80.07  ... -71.51 -86.33 -72.71 -80.62

[11 rows x 11 columns]
\begin{tabular}{lrrrrrrrrrrr}
\toprule
{} &     0  &     1  &     2  &     3  &      4  &      5  &      6  &     7  &     8  &     9  &     10 \\
\midrule
new\_cluster & -73.25 & -75.20 & -93.31 & -80.04 & -101.66 & -160.77 & -113.00 & -70.43 & -86.14 & -72.28 & -80.63 \\
c1          & -73.40 & -75.82 & -94.36 & -80.60 &  -97.77 & -163.50 & -115.85 & -70.53 & -87.25 & -71.70 & -80.24 \\
c2          & -73.45 & -73.84 & -96.06 & -80.77 &  -99.45 & -162.60 & -119.89 & -71.72 & -89.04 & -72.83 & -80.14 \\
c3          & -73.44 & -74.67 & -94.13 & -80.34 &  -98.45 & -160.16 & -117.47 & -72.06 & -87.47 & -73.03 & -80.16 \\
c4          & -73.60 & -73.87 & -93.50 & -79.07 &  -98.66 & -159.62 & -116.91 & -70.58 & -86.94 & -72.05 & -80.14 \\
c5          & -73.53 & -72.37 & -93.51 & -79.80 &  -98.39 & -160.60 & -116.97 & -70.56 & -89.46 & -72.48 & -80.16 \\
c6          & -73.38 & -74.61 & -95.02 & -79.48 & -100.43 & -157.75 & -115.39 & -70.75 & -87.13 & -73.30 & -80.62 \\
c7          & -74.63 & -75.51 & -94.70 & -80.94 &  -99.74 & -155.35 & -112.92 & -69.86 & -86.28 & -73.21 & -80.22 \\
c8          & -74.64 & -73.54 & -94.53 & -80.98 &  -97.70 & -163.68 & -112.09 & -71.43 & -88.35 & -72.36 & -80.14 \\
c9          & -74.27 & -74.92 & -94.30 & -81.17 & -100.47 & -162.08 & -116.84 & -71.47 & -87.82 & -73.43 & -80.16 \\
c10         & -74.63 & -75.46 & -94.07 & -80.07 &  -98.71 & -157.62 & -118.16 & -71.51 & -86.33 & -72.71 & -80.62 \\
\bottomrule
\end{tabular}

                               0            1   ...           9              10
new_cluster  [-4.84, new_cluster]  [-5.98, c1]  ...  [-2.96, c9]  [-10.78, c10]
c1           [-4.84, new_cluster]   [-6.6, c1]  ...  [-2.37, c9]  [-10.78, c10]
c2           [-4.84, new_cluster]  [-4.91, c1]  ...   [-3.5, c9]  [-10.78, c10]
c3           [-4.84, new_cluster]  [-5.21, c1]  ...  [-3.57, c9]  [-10.78, c10]
c4           [-4.84, new_cluster]  [-5.06, c1]  ...  [-2.71, c9]  [-10.78, c10]
c5           [-4.84, new_cluster]  [-3.88, c1]  ...  [-3.13, c9]  [-10.78, c10]
c6           [-4.84, new_cluster]  [-5.13, c1]  ...   [-3.4, c9]  [-10.78, c10]
c7           [-4.84, new_cluster]  [-5.78, c1]  ...  [-3.77, c9]  [-10.78, c10]
c8           [-4.84, new_cluster]  [-5.11, c1]  ...  [-2.94, c9]  [-10.78, c10]
c9           [-4.84, new_cluster]  [-5.41, c1]  ...   [-4.1, c9]  [-10.78, c10]
c10          [-4.84, new_cluster]  [-6.23, c1]  ...  [-3.38, c9]  [-10.78, c10]

[11 rows x 11 columns]
\begin{tabular}{llllllllllll}
\toprule
{} &                    0  &           1  &            2  &            3  &            4  &            5  &            6  &           7  &            8  &           9  &             10 \\
\midrule
new\_cluster &  [-4.84, new\_cluster] &  [-5.98, c1] &  [-23.75, c2] &   [-9.94, c3] &  [-33.05, c4] &  [-91.87, c5] &  [-42.62, c6] &  [-2.03, c7] &  [-16.56, c8] &  [-2.96, c9] &  [-10.78, c10] \\
c1          &  [-4.84, new\_cluster] &   [-6.6, c1] &  [-24.79, c2] &  [-10.66, c3] &  [-29.22, c4] &  [-94.13, c5] &   [-46.1, c6] &  [-1.98, c7] &  [-17.51, c8] &  [-2.37, c9] &  [-10.78, c10] \\
c2          &  [-4.84, new\_cluster] &  [-4.91, c1] &  [-26.57, c2] &  [-10.78, c3] &  [-30.29, c4] &   [-93.7, c5] &  [-50.14, c6] &   [-2.3, c7] &  [-19.55, c8] &   [-3.5, c9] &  [-10.78, c10] \\
c3          &  [-4.84, new\_cluster] &  [-5.21, c1] &  [-24.59, c2] &  [-10.46, c3] &  [-29.01, c4] &  [-91.34, c5] &  [-47.72, c6] &  [-2.68, c7] &  [-18.17, c8] &  [-3.57, c9] &  [-10.78, c10] \\
c4          &  [-4.84, new\_cluster] &  [-5.06, c1] &  [-23.93, c2] &   [-9.13, c3] &  [-30.05, c4] &  [-90.97, c5] &  [-47.28, c6] &  [-2.12, c7] &  [-16.53, c8] &  [-2.71, c9] &  [-10.78, c10] \\
c5          &  [-4.84, new\_cluster] &  [-3.88, c1] &  [-24.06, c2] &   [-9.86, c3] &  [-29.08, c4] &  [-91.98, c5] &  [-47.22, c6] &  [-1.66, c7] &  [-19.71, c8] &  [-3.13, c9] &  [-10.78, c10] \\
c6          &  [-4.84, new\_cluster] &  [-5.13, c1] &  [-25.44, c2] &   [-9.57, c3] &  [-31.82, c4] &   [-89.1, c5] &  [-45.27, c6] &  [-2.74, c7] &  [-16.82, c8] &   [-3.4, c9] &  [-10.78, c10] \\
c7          &  [-4.84, new\_cluster] &  [-5.78, c1] &  [-25.13, c2] &   [-10.7, c3] &  [-31.25, c4] &  [-86.04, c5] &  [-42.55, c6] &  [-1.36, c7] &  [-16.58, c8] &  [-3.77, c9] &  [-10.78, c10] \\
c8          &  [-4.84, new\_cluster] &  [-5.11, c1] &  [-24.96, c2] &  [-10.85, c3] &   [-28.4, c4] &  [-94.35, c5] &  [-42.49, c6] &  [-3.01, c7] &  [-18.02, c8] &  [-2.94, c9] &  [-10.78, c10] \\
c9          &  [-4.84, new\_cluster] &  [-5.41, c1] &  [-24.73, c2] &  [-11.84, c3] &  [-31.37, c4] &  [-93.13, c5] &  [-46.46, c6] &  [-2.21, c7] &  [-18.12, c8] &   [-4.1, c9] &  [-10.78, c10] \\
c10         &  [-4.84, new\_cluster] &  [-6.23, c1] &   [-24.5, c2] &   [-9.97, c3] &   [-29.4, c4] &  [-89.16, c5] &  [-48.41, c6] &  [-2.25, c7] &  [-16.58, c8] &  [-3.38, c9] &  [-10.78, c10] \\
\bottomrule
\end{tabular}

