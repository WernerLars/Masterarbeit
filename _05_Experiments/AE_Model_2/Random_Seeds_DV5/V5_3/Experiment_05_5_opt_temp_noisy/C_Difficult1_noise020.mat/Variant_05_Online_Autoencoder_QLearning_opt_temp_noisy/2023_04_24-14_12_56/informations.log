Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_5_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_5_opt_temp_noisy/C_Difficult1_noise020.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-14_12_56
Punishment_Coefficient: 1.2
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001B65312B470>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.17768424563109875
Online_Training [2/700]: mean_loss=0.2293134666979313
Online_Training [3/700]: mean_loss=0.21032082103192806
Online_Training [4/700]: mean_loss=0.17700419016182423
Online_Training [5/700]: mean_loss=0.132999612018466
Online_Training [6/700]: mean_loss=0.07679529674351215
Online_Training [7/700]: mean_loss=0.11864354647696018
Online_Training [8/700]: mean_loss=0.12231648340821266
Online_Training [9/700]: mean_loss=0.05428364034742117
Online_Training [10/700]: mean_loss=0.12848705239593983
Online_Training [11/700]: mean_loss=0.06588777946308255
Online_Training [12/700]: mean_loss=0.09581219870597124
Online_Training [13/700]: mean_loss=0.11489417962729931
Online_Training [14/700]: mean_loss=0.055788031313568354
Online_Training [15/700]: mean_loss=0.031239155447110534
Online_Training [16/700]: mean_loss=0.043273625429719687
Online_Training [17/700]: mean_loss=0.03982788324356079
Online_Training [18/700]: mean_loss=0.024294932140037417
Online_Training [19/700]: mean_loss=0.09592264611274004
Online_Training [20/700]: mean_loss=0.03289787867106497
Online_Training [21/700]: mean_loss=0.0440607899799943
Online_Training [22/700]: mean_loss=0.07463826518505812
Online_Training [23/700]: mean_loss=0.0331519627943635
Online_Training [24/700]: mean_loss=0.040963276755064726
Online_Training [25/700]: mean_loss=0.024426867021247745
Online_Training [26/700]: mean_loss=0.09175802487879992
Online_Training [27/700]: mean_loss=0.10572593379765749
Online_Training [28/700]: mean_loss=0.04169469699263573
Online_Training [29/700]: mean_loss=0.0679589407518506
Online_Training [30/700]: mean_loss=0.03251363057643175
Online_Training [31/700]: mean_loss=0.11310218460857868
Online_Training [32/700]: mean_loss=0.02791013359092176
Online_Training [33/700]: mean_loss=0.0155514448415488
Online_Training [34/700]: mean_loss=0.023325031623244286
Online_Training [35/700]: mean_loss=0.13582201674580574
Online_Training [36/700]: mean_loss=0.054358630906790495
Online_Training [37/700]: mean_loss=0.10269625578075647
Online_Training [38/700]: mean_loss=0.055749244056642056
Online_Training [39/700]: mean_loss=0.021305073285475373
Online_Training [40/700]: mean_loss=0.11256379261612892
Online_Training [41/700]: mean_loss=0.083229367621243
Online_Training [42/700]: mean_loss=0.07308934163302183
Online_Training [43/700]: mean_loss=0.04929291969165206
Online_Training [44/700]: mean_loss=0.17038460075855255
Online_Training [45/700]: mean_loss=0.08631460927426815
Online_Training [46/700]: mean_loss=0.06850697193294764
Online_Training [47/700]: mean_loss=0.05292169749736786
Online_Training [48/700]: mean_loss=0.02168991230428219
Online_Training [49/700]: mean_loss=0.0444017737172544
Online_Training [50/700]: mean_loss=0.030576501274481416
Online_Training [51/700]: mean_loss=0.02501118159852922
Online_Training [52/700]: mean_loss=0.06607366306707263
Online_Training [53/700]: mean_loss=0.01459118362981826
Online_Training [54/700]: mean_loss=0.021704106824472547
Online_Training [55/700]: mean_loss=0.10825465992093086
Online_Training [56/700]: mean_loss=0.03811630280688405
Online_Training [57/700]: mean_loss=0.0600162916816771
Online_Training [58/700]: mean_loss=0.05973101546987891
Online_Training [59/700]: mean_loss=0.03239040239714086
Online_Training [60/700]: mean_loss=0.036400643177330494
Online_Training [61/700]: mean_loss=0.06206285208463669
Online_Training [62/700]: mean_loss=0.036121084820479155
Online_Training [63/700]: mean_loss=0.03018522006459534
Online_Training [64/700]: mean_loss=0.006898549618199468
Online_Training [65/700]: mean_loss=0.046487894374877214
Online_Training [66/700]: mean_loss=0.06169221270829439
Online_Training [67/700]: mean_loss=0.05983116989955306
Online_Training [68/700]: mean_loss=0.014818069175817072
Online_Training [69/700]: mean_loss=0.1365622840821743
Online_Training [70/700]: mean_loss=0.06115381792187691
Online_Training [71/700]: mean_loss=0.02654519211500883
Online_Training [72/700]: mean_loss=0.05133091704919934
Online_Training [73/700]: mean_loss=0.025676284451037645
Online_Training [74/700]: mean_loss=0.054317822214215994
Online_Training [75/700]: mean_loss=0.010067865019664168
Online_Training [76/700]: mean_loss=0.03366040764376521
Online_Training [77/700]: mean_loss=0.04163406463339925
Online_Training [78/700]: mean_loss=0.06295720487833023
Online_Training [79/700]: mean_loss=0.09038065187633038
Online_Training [80/700]: mean_loss=0.02085325261577964
Online_Training [81/700]: mean_loss=0.058542067650705576
Online_Training [82/700]: mean_loss=0.03663361165672541
Online_Training [83/700]: mean_loss=0.021643388317897916
Online_Training [84/700]: mean_loss=0.012348294258117676
Online_Training [85/700]: mean_loss=0.03537394059821963
Online_Training [86/700]: mean_loss=0.0404198975302279
Online_Training [87/700]: mean_loss=0.02244548685848713
Online_Training [88/700]: mean_loss=0.051326361019164324
Online_Training [89/700]: mean_loss=0.028929366962984204
Online_Training [90/700]: mean_loss=0.07805864699184895
Online_Training [91/700]: mean_loss=0.025558603694662452
Online_Training [92/700]: mean_loss=0.09105113986879587
Online_Training [93/700]: mean_loss=0.027743597282096744
Online_Training [94/700]: mean_loss=0.03784482320770621
Online_Training [95/700]: mean_loss=0.06754032801836729
Online_Training [96/700]: mean_loss=0.014553723856806755
Online_Training [97/700]: mean_loss=0.013347551692277193
Online_Training [98/700]: mean_loss=0.02730109845288098
Online_Training [99/700]: mean_loss=0.04826702689751983
Online_Training [100/700]: mean_loss=0.03416151227429509
Online_Training [101/700]: mean_loss=0.033261862117797136
Online_Training [102/700]: mean_loss=0.0640229219570756
Online_Training [103/700]: mean_loss=0.040318925864994526
Online_Training [104/700]: mean_loss=0.01256606460083276
Online_Training [105/700]: mean_loss=0.01185359270311892
Online_Training [106/700]: mean_loss=0.06155447429046035
Online_Training [107/700]: mean_loss=0.01301894849166274
Online_Training [108/700]: mean_loss=0.04909211164340377
Online_Training [109/700]: mean_loss=0.03331001498736441
Online_Training [110/700]: mean_loss=0.024407458025962114
Online_Training [111/700]: mean_loss=0.07218565605580807
Online_Training [112/700]: mean_loss=0.08798038121312857
Online_Training [113/700]: mean_loss=0.07289536390453577
Online_Training [114/700]: mean_loss=0.04624020680785179
Online_Training [115/700]: mean_loss=0.028448613127693534
Online_Training [116/700]: mean_loss=0.05231936927884817
Online_Training [117/700]: mean_loss=0.03234091401100159
Online_Training [118/700]: mean_loss=0.15642757155001163
Online_Training [119/700]: mean_loss=0.03294902294874191
Online_Training [120/700]: mean_loss=0.04025092115625739
Online_Training [121/700]: mean_loss=0.04431608086451888
Online_Training [122/700]: mean_loss=0.06436082208529115
Online_Training [123/700]: mean_loss=0.04103560792282224
Online_Training [124/700]: mean_loss=0.04126637615263462
Online_Training [125/700]: mean_loss=0.03206213563680649
Online_Training [126/700]: mean_loss=0.03925596550107002
Online_Training [127/700]: mean_loss=0.03077642433345318
Online_Training [128/700]: mean_loss=0.053475400898605585
Online_Training [129/700]: mean_loss=0.04358912445604801
Online_Training [130/700]: mean_loss=0.031878467882052064
Online_Training [131/700]: mean_loss=0.049710944294929504
Online_Training [132/700]: mean_loss=0.05924837803468108
Online_Training [133/700]: mean_loss=0.07782264519482851
Online_Training [134/700]: mean_loss=0.012664055335335433
Online_Training [135/700]: mean_loss=0.17111892439424992
Online_Training [136/700]: mean_loss=0.11533017735928297
Online_Training [137/700]: mean_loss=0.05576658574864268
Online_Training [138/700]: mean_loss=0.17395075596868992
Online_Training [139/700]: mean_loss=0.07766954321414232
Online_Training [140/700]: mean_loss=0.03136602183803916
Online_Training [141/700]: mean_loss=0.05810893652960658
Online_Training [142/700]: mean_loss=0.04199468903243542
Online_Training [143/700]: mean_loss=0.07042983639985323
Online_Training [144/700]: mean_loss=0.026969147380441427
Online_Training [145/700]: mean_loss=0.07839974481612444
Online_Training [146/700]: mean_loss=0.0441633015871048
Online_Training [147/700]: mean_loss=0.021262499736621976
Online_Training [148/700]: mean_loss=0.09492924716323614
Online_Training [149/700]: mean_loss=0.05277856206521392
Online_Training [150/700]: mean_loss=0.025610313983634114
Online_Training [151/700]: mean_loss=0.03564836084842682
Online_Training [152/700]: mean_loss=0.015809881617315114
Online_Training [153/700]: mean_loss=0.038721383549273014
Online_Training [154/700]: mean_loss=0.06900127977132797
Online_Training [155/700]: mean_loss=0.05034807464107871
Online_Training [156/700]: mean_loss=0.03389785625040531
Online_Training [157/700]: mean_loss=0.03466266859322786
Online_Training [158/700]: mean_loss=0.026893767761066556
Online_Training [159/700]: mean_loss=0.057317500934004784
Online_Training [160/700]: mean_loss=0.012212261091917753
Online_Training [161/700]: mean_loss=0.029384783701971173
Online_Training [162/700]: mean_loss=0.0618594572879374
Online_Training [163/700]: mean_loss=0.06432500248774886
Online_Training [164/700]: mean_loss=0.058312092907726765
Online_Training [165/700]: mean_loss=0.025466385995969176
Online_Training [166/700]: mean_loss=0.008985336520709097
Online_Training [167/700]: mean_loss=0.02615454141050577
Online_Training [168/700]: mean_loss=0.03169264690950513
Online_Training [169/700]: mean_loss=0.07127786241471767
Online_Training [170/700]: mean_loss=0.008273665385786444
Online_Training [171/700]: mean_loss=0.04112183442339301
Online_Training [172/700]: mean_loss=0.01764765428379178
Online_Training [173/700]: mean_loss=0.03489309595897794
Online_Training [174/700]: mean_loss=0.16501469910144806
Online_Training [175/700]: mean_loss=0.11485905200242996
Online_Training [176/700]: mean_loss=0.04263318330049515
Online_Training [177/700]: mean_loss=0.04556299792602658
Online_Training [178/700]: mean_loss=0.041157579980790615
Online_Training [179/700]: mean_loss=0.02802034979686141
Online_Training [180/700]: mean_loss=0.0206443821080029
Online_Training [181/700]: mean_loss=0.04157947935163975
Online_Training [182/700]: mean_loss=0.0716327428817749
Online_Training [183/700]: mean_loss=0.0441774963401258
Online_Training [184/700]: mean_loss=0.04182602418586612
Online_Training [185/700]: mean_loss=0.0786276226863265
Online_Training [186/700]: mean_loss=0.31029776856303215
Online_Training [187/700]: mean_loss=0.05858460394665599
Online_Training [188/700]: mean_loss=0.02814992913044989
Online_Training [189/700]: mean_loss=0.04150039190426469
Online_Training [190/700]: mean_loss=0.08147722389549017
Online_Training [191/700]: mean_loss=0.06632773764431477
Online_Training [192/700]: mean_loss=0.021065242355689406
Online_Training [193/700]: mean_loss=0.02618026710115373
Online_Training [194/700]: mean_loss=0.052787842229008675
Online_Training [195/700]: mean_loss=0.03504813648760319
Online_Training [196/700]: mean_loss=0.021773205837234855
Online_Training [197/700]: mean_loss=0.01886206096969545
Online_Training [198/700]: mean_loss=0.12511266861110926
Online_Training [199/700]: mean_loss=0.07230758387595415
Online_Training [200/700]: mean_loss=0.02112292731180787
Online_Training [201/700]: mean_loss=0.014171803602948785
Online_Training [202/700]: mean_loss=0.04196204990148544
Online_Training [203/700]: mean_loss=0.02055295091122389
Online_Training [204/700]: mean_loss=0.04370401008054614
Online_Training [205/700]: mean_loss=0.023231655824929476
Online_Training [206/700]: mean_loss=0.028243757551535964
Online_Training [207/700]: mean_loss=0.013442595605738461
Online_Training [208/700]: mean_loss=0.03868777956813574
Online_Training [209/700]: mean_loss=0.040370482951402664
Online_Training [210/700]: mean_loss=0.01945902267470956
Online_Training [211/700]: mean_loss=0.020233928225934505
Online_Training [212/700]: mean_loss=0.014188247383572161
Online_Training [213/700]: mean_loss=0.023543836316093802
Online_Training [214/700]: mean_loss=0.020470350980758667
Online_Training [215/700]: mean_loss=0.012341265566647053
Online_Training [216/700]: mean_loss=0.025649453047662973
Online_Training [217/700]: mean_loss=0.033867357298731804
Online_Training [218/700]: mean_loss=0.03258939110673964
Online_Training [219/700]: mean_loss=0.028031047200784087
Online_Training [220/700]: mean_loss=0.03535032016225159
Online_Training [221/700]: mean_loss=0.015617364551872015
Online_Training [222/700]: mean_loss=0.028132919454947114
Online_Training [223/700]: mean_loss=0.026620492804795504
Online_Training [224/700]: mean_loss=0.03899524314329028
Online_Training [225/700]: mean_loss=0.03193393815308809
Online_Training [226/700]: mean_loss=0.013433092972263694
Online_Training [227/700]: mean_loss=0.015098902978934348
Online_Training [228/700]: mean_loss=0.03944595903158188
Online_Training [229/700]: mean_loss=0.03173720929771662
Online_Training [230/700]: mean_loss=0.03386464132927358
Online_Training [231/700]: mean_loss=0.029849078273400664
Online_Training [232/700]: mean_loss=0.019465174758806825
Online_Training [233/700]: mean_loss=0.011412969790399075
Online_Training [234/700]: mean_loss=0.06004709145054221
Online_Training [235/700]: mean_loss=0.10166732408106327
Online_Training [236/700]: mean_loss=0.04182137502357364
Online_Training [237/700]: mean_loss=0.03634677641093731
Online_Training [238/700]: mean_loss=0.09912549424916506
Online_Training [239/700]: mean_loss=0.058776797726750374
Online_Training [240/700]: mean_loss=0.0450075464323163
Online_Training [241/700]: mean_loss=0.07426731754094362
Online_Training [242/700]: mean_loss=0.015177993453107774
Online_Training [243/700]: mean_loss=0.03294427087530494
Online_Training [244/700]: mean_loss=0.02542860130779445
Online_Training [245/700]: mean_loss=0.034623281797394156
Online_Training [246/700]: mean_loss=0.020026954356580973
Online_Training [247/700]: mean_loss=0.03276155469939113
Online_Training [248/700]: mean_loss=0.04559795977547765
Online_Training [249/700]: mean_loss=0.044030637945979834
Online_Training [250/700]: mean_loss=0.014635713421739638
Online_Training [251/700]: mean_loss=0.04202139424160123
Online_Training [252/700]: mean_loss=0.03159999451600015
Online_Training [253/700]: mean_loss=0.02384236198849976
Online_Training [254/700]: mean_loss=0.019521361915394664
Online_Training [255/700]: mean_loss=0.03814807953312993
Online_Training [256/700]: mean_loss=0.032061298843473196
Online_Training [257/700]: mean_loss=0.044906552881002426
Online_Training [258/700]: mean_loss=0.022986406227573752
Online_Training [259/700]: mean_loss=0.03635825775563717
Online_Training [260/700]: mean_loss=0.02341172005981207
Online_Training [261/700]: mean_loss=0.05461942870169878
Online_Training [262/700]: mean_loss=0.20761611126363277
Online_Training [263/700]: mean_loss=0.03807615349069238
Online_Training [264/700]: mean_loss=0.01231418747920543
Online_Training [265/700]: mean_loss=0.038183697033673525
Online_Training [266/700]: mean_loss=0.02974242903292179
Online_Training [267/700]: mean_loss=0.043352986220270395
Online_Training [268/700]: mean_loss=0.021309595555067062
Online_Training [269/700]: mean_loss=0.026913606096059084
Online_Training [270/700]: mean_loss=0.018198123900219798
Online_Training [271/700]: mean_loss=0.019760839641094208
Online_Training [272/700]: mean_loss=0.036447858437895775
Online_Training [273/700]: mean_loss=0.020881567150354385
Online_Training [274/700]: mean_loss=0.0276895584538579
Online_Training [275/700]: mean_loss=0.022283816942945123
Online_Training [276/700]: mean_loss=0.034276722464710474
Online_Training [277/700]: mean_loss=0.03071661526337266
Online_Training [278/700]: mean_loss=0.023138461401686072
Online_Training [279/700]: mean_loss=0.044473419431596994
Online_Training [280/700]: mean_loss=0.01584836351685226
Online_Training [281/700]: mean_loss=0.02452312712557614
Online_Training [282/700]: mean_loss=0.016611583065241575
Online_Training [283/700]: mean_loss=0.043456916231662035
Online_Training [284/700]: mean_loss=0.02194389933720231
Online_Training [285/700]: mean_loss=0.028759446926414967
Online_Training [286/700]: mean_loss=0.007321680604945868
Online_Training [287/700]: mean_loss=0.03402702324092388
Online_Training [288/700]: mean_loss=0.06637554755434394
Online_Training [289/700]: mean_loss=0.019743713783100247
Online_Training [290/700]: mean_loss=0.025252998108044267
Online_Training [291/700]: mean_loss=0.03103613038547337
Online_Training [292/700]: mean_loss=0.04125935351476073
Online_Training [293/700]: mean_loss=0.015896063181571662
Online_Training [294/700]: mean_loss=0.06841093441471457
Online_Training [295/700]: mean_loss=0.0247476187068969
Online_Training [296/700]: mean_loss=0.03353992127813399
Online_Training [297/700]: mean_loss=0.024445940973237157
Online_Training [298/700]: mean_loss=0.016013105399906635
Online_Training [299/700]: mean_loss=0.00637426198227331
Online_Training [300/700]: mean_loss=0.009146637981757522
Online_Training [301/700]: mean_loss=0.04082717280834913
Online_Training [302/700]: mean_loss=0.0274130473844707
Online_Training [303/700]: mean_loss=0.042655554600059986
Online_Training [304/700]: mean_loss=0.014350010897032917
Online_Training [305/700]: mean_loss=0.030401459662243724
Online_Training [306/700]: mean_loss=0.015141370124183595
Online_Training [307/700]: mean_loss=0.03731212951242924
Online_Training [308/700]: mean_loss=0.01453850558027625
Online_Training [309/700]: mean_loss=0.015581266488879919
Online_Training [310/700]: mean_loss=0.057988996617496014
Online_Training [311/700]: mean_loss=0.008843760238960385
Online_Training [312/700]: mean_loss=0.029398482060059905
Online_Training [313/700]: mean_loss=0.06597572099417448
Online_Training [314/700]: mean_loss=0.030942166689783335
Online_Training [315/700]: mean_loss=0.08073429483920336
Online_Training [316/700]: mean_loss=0.017778276465833187
Online_Training [317/700]: mean_loss=0.017638105200603604
Online_Training [318/700]: mean_loss=0.005059878982137889
Online_Training [319/700]: mean_loss=0.008982650877442211
Online_Training [320/700]: mean_loss=0.016935424064286053
Online_Training [321/700]: mean_loss=0.02201957069337368
Online_Training [322/700]: mean_loss=0.009042604826390743
Online_Training [323/700]: mean_loss=0.013381381402723491
Online_Training [324/700]: mean_loss=0.026603123173117638
Online_Training [325/700]: mean_loss=0.02277892013080418
Online_Training [326/700]: mean_loss=0.009496878483332694
Online_Training [327/700]: mean_loss=0.015566938789561391
Online_Training [328/700]: mean_loss=0.020714659243822098
Online_Training [329/700]: mean_loss=0.04599315673112869
Online_Training [330/700]: mean_loss=0.012094342149794102
Online_Training [331/700]: mean_loss=0.008723279344849288
Online_Training [332/700]: mean_loss=0.013658894109539688
Online_Training [333/700]: mean_loss=0.03097094316035509
Online_Training [334/700]: mean_loss=0.012519906158559024
Online_Training [335/700]: mean_loss=0.009371587890200317
Online_Training [336/700]: mean_loss=0.02342510991729796
Online_Training [337/700]: mean_loss=0.023066441528499126
Online_Training [338/700]: mean_loss=0.01143436087295413
Online_Training [339/700]: mean_loss=0.0071392852696590126
Online_Training [340/700]: mean_loss=0.021638774778693914
Online_Training [341/700]: mean_loss=0.016633276594802737
Online_Training [342/700]: mean_loss=0.017112434143200517
Online_Training [343/700]: mean_loss=0.012725134496577084
Online_Training [344/700]: mean_loss=0.009261989500373602
Online_Training [345/700]: mean_loss=0.016492057824507356
Online_Training [346/700]: mean_loss=0.07292218506336212
Online_Training [347/700]: mean_loss=0.019499038229696453
Online_Training [348/700]: mean_loss=0.032626161351799965
Online_Training [349/700]: mean_loss=0.05058036698028445
Online_Training [350/700]: mean_loss=0.031488494481891394
Online_Training [351/700]: mean_loss=0.027729210909456015
Online_Training [352/700]: mean_loss=0.016689135693013668
Online_Training [353/700]: mean_loss=0.0256367907859385
Online_Training [354/700]: mean_loss=0.01079164503607899
Online_Training [355/700]: mean_loss=0.04992839228361845
Online_Training [356/700]: mean_loss=0.009697158937342465
Online_Training [357/700]: mean_loss=0.043216828256845474
Online_Training [358/700]: mean_loss=0.022776417434215546
Online_Training [359/700]: mean_loss=0.016316054039634764
Online_Training [360/700]: mean_loss=0.026063452940434217
Online_Training [361/700]: mean_loss=0.007642150798346847
Online_Training [362/700]: mean_loss=0.019867041613906622
Online_Training [363/700]: mean_loss=0.05747551657259464
Online_Training [364/700]: mean_loss=0.025021265260875225
Online_Training [365/700]: mean_loss=0.033735565608367324
Online_Training [366/700]: mean_loss=0.03300977125763893
Online_Training [367/700]: mean_loss=0.023046250455081463
Online_Training [368/700]: mean_loss=0.02111764601431787
Online_Training [369/700]: mean_loss=0.017773913335986435
Online_Training [370/700]: mean_loss=0.024673413019627333
Online_Training [371/700]: mean_loss=0.0205523194745183
Online_Training [372/700]: mean_loss=0.04967907955870032
Online_Training [373/700]: mean_loss=0.013783470494672656
Online_Training [374/700]: mean_loss=0.010252400767058134
Online_Training [375/700]: mean_loss=0.031849735882133245
Online_Training [376/700]: mean_loss=0.012977682752534747
Online_Training [377/700]: mean_loss=0.012562272953800857
Online_Training [378/700]: mean_loss=0.024473670404404402
Online_Training [379/700]: mean_loss=0.015348496614024043
Online_Training [380/700]: mean_loss=0.06080550001934171
Online_Training [381/700]: mean_loss=0.024594554910436273
Online_Training [382/700]: mean_loss=0.02386651304550469
Online_Training [383/700]: mean_loss=0.011096797417849302
Online_Training [384/700]: mean_loss=0.010583067662082613
Online_Training [385/700]: mean_loss=0.047937193885445595
Online_Training [386/700]: mean_loss=0.04016389651224017
Online_Training [387/700]: mean_loss=0.029405001318082213
Online_Training [388/700]: mean_loss=0.048624574206769466
Online_Training [389/700]: mean_loss=0.026069255778566003
Online_Training [390/700]: mean_loss=0.01463879260700196
Online_Training [391/700]: mean_loss=0.012948647141456604
Online_Training [392/700]: mean_loss=0.01867068582214415
Online_Training [393/700]: mean_loss=0.01595846691634506
Online_Training [394/700]: mean_loss=0.018749204464256763
Online_Training [395/700]: mean_loss=0.05059167370200157
Online_Training [396/700]: mean_loss=0.024002343649044633
Online_Training [397/700]: mean_loss=0.04151572426781058
Online_Training [398/700]: mean_loss=0.045264307875186205
Online_Training [399/700]: mean_loss=0.015324918320402503
Online_Training [400/700]: mean_loss=0.026109591126441956
Online_Training [401/700]: mean_loss=0.020973683800548315
Online_Training [402/700]: mean_loss=0.01101041550282389
Online_Training [403/700]: mean_loss=0.008703138213604689
Online_Training [404/700]: mean_loss=0.0473935604095459
Online_Training [405/700]: mean_loss=0.03466756781563163
Online_Training [406/700]: mean_loss=0.1357041299343109
Online_Training [407/700]: mean_loss=0.07906428258866072
Online_Training [408/700]: mean_loss=0.018778391182422638
Online_Training [409/700]: mean_loss=0.03433937719091773
Online_Training [410/700]: mean_loss=0.03180395648814738
Online_Training [411/700]: mean_loss=0.044126813765615225
Online_Training [412/700]: mean_loss=0.018077599932439625
Online_Training [413/700]: mean_loss=0.030767173506319523
Online_Training [414/700]: mean_loss=0.05306327762082219
Online_Training [415/700]: mean_loss=0.028754627099260688
Online_Training [416/700]: mean_loss=0.02844982943497598
Online_Training [417/700]: mean_loss=0.017849940108135343
Online_Training [418/700]: mean_loss=0.03335584281012416
Online_Training [419/700]: mean_loss=0.03391249873675406
Online_Training [420/700]: mean_loss=0.01167359878309071
Online_Training [421/700]: mean_loss=0.01325006503611803
Online_Training [422/700]: mean_loss=0.0353795881383121
Online_Training [423/700]: mean_loss=0.02746369270607829
Online_Training [424/700]: mean_loss=0.024086964316666126
Online_Training [425/700]: mean_loss=0.024742174660786986
Online_Training [426/700]: mean_loss=0.02201678161509335
Online_Training [427/700]: mean_loss=0.03373649436980486
Online_Training [428/700]: mean_loss=0.010357751976698637
Online_Training [429/700]: mean_loss=0.022885653655976057
Online_Training [430/700]: mean_loss=0.02504253387451172
Online_Training [431/700]: mean_loss=0.05244106240570545
Online_Training [432/700]: mean_loss=0.0349262875970453
Online_Training [433/700]: mean_loss=0.023780440911650658
Online_Training [434/700]: mean_loss=0.005461669992655516
Online_Training [435/700]: mean_loss=0.009408477460965514
Online_Training [436/700]: mean_loss=0.02339304843917489
Online_Training [437/700]: mean_loss=0.09957695938646793
Online_Training [438/700]: mean_loss=0.030980802373960614
Online_Training [439/700]: mean_loss=0.04821767192333937
Online_Training [440/700]: mean_loss=0.025227820966392756
Online_Training [441/700]: mean_loss=0.01863963040523231
Online_Training [442/700]: mean_loss=0.02118997322395444
Online_Training [443/700]: mean_loss=0.044954780489206314
Online_Training [444/700]: mean_loss=0.01732806325890124
Online_Training [445/700]: mean_loss=0.037062748335301876
Online_Training [446/700]: mean_loss=0.01309224870055914
Online_Training [447/700]: mean_loss=0.03851991891860962
Online_Training [448/700]: mean_loss=0.02211923780851066
Online_Training [449/700]: mean_loss=0.03869779594242573
Online_Training [450/700]: mean_loss=0.02874184213578701
Online_Training [451/700]: mean_loss=0.023523418931290507
Online_Training [452/700]: mean_loss=0.01149621163494885
Online_Training [453/700]: mean_loss=0.01732743566390127
Online_Training [454/700]: mean_loss=0.022730343276634812
Online_Training [455/700]: mean_loss=0.06793843489140272
Online_Training [456/700]: mean_loss=0.07612575218081474
Online_Training [457/700]: mean_loss=0.03821436455473304
Online_Training [458/700]: mean_loss=0.017956933239474893
Online_Training [459/700]: mean_loss=0.03518946561962366
Online_Training [460/700]: mean_loss=0.02583974157460034
Online_Training [461/700]: mean_loss=0.01958498964086175
Online_Training [462/700]: mean_loss=0.060274077113717794
Online_Training [463/700]: mean_loss=0.03226962755434215
Online_Training [464/700]: mean_loss=0.03158627380616963
Online_Training [465/700]: mean_loss=0.016042288043536246
Online_Training [466/700]: mean_loss=0.031121933134272695
Online_Training [467/700]: mean_loss=0.009526988724246621
Online_Training [468/700]: mean_loss=0.023797328816726804
Online_Training [469/700]: mean_loss=0.01589689776301384
Online_Training [470/700]: mean_loss=0.02663966710679233
Online_Training [471/700]: mean_loss=0.048358731903135777
Online_Training [472/700]: mean_loss=0.013936311239376664
Online_Training [473/700]: mean_loss=0.027282081311568618
Online_Training [474/700]: mean_loss=0.01808490348048508
Online_Training [475/700]: mean_loss=0.020536263706162572
Online_Training [476/700]: mean_loss=0.024349464802071452
Online_Training [477/700]: mean_loss=0.021231718827039003
Online_Training [478/700]: mean_loss=0.023242191644385457
Online_Training [479/700]: mean_loss=0.03437579213641584
Online_Training [480/700]: mean_loss=0.03422522218897939
Online_Training [481/700]: mean_loss=0.029210236854851246
Online_Training [482/700]: mean_loss=0.014100056723691523
Online_Training [483/700]: mean_loss=0.030248280614614487
Online_Training [484/700]: mean_loss=0.011928130756132305
Online_Training [485/700]: mean_loss=0.042544979602098465
Online_Training [486/700]: mean_loss=0.013789503835141659
Online_Training [487/700]: mean_loss=0.04025664087384939
Online_Training [488/700]: mean_loss=0.013437810936011374
Online_Training [489/700]: mean_loss=0.01857957663014531
Online_Training [490/700]: mean_loss=0.044275044463574886
Online_Training [491/700]: mean_loss=0.021705716382712126
Online_Training [492/700]: mean_loss=0.13964584097266197
Online_Training [493/700]: mean_loss=0.01519154035486281
Online_Training [494/700]: mean_loss=0.03405991289764643
Online_Training [495/700]: mean_loss=0.02773710060864687
Online_Training [496/700]: mean_loss=0.03350708959624171
Online_Training [497/700]: mean_loss=0.01864329818636179
Online_Training [498/700]: mean_loss=0.02013779408298433
Online_Training [499/700]: mean_loss=0.023428168380632997
Online_Training [500/700]: mean_loss=0.024122972507029772
Online_Training [501/700]: mean_loss=0.05404661642387509
Online_Training [502/700]: mean_loss=0.04263454396277666
Online_Training [503/700]: mean_loss=0.054263023659586906
Online_Training [504/700]: mean_loss=0.024956265464425087
Online_Training [505/700]: mean_loss=0.0198757688049227
Online_Training [506/700]: mean_loss=0.007946728321257979
Online_Training [507/700]: mean_loss=0.0285067199729383
Online_Training [508/700]: mean_loss=0.02022994519211352
Online_Training [509/700]: mean_loss=0.01854932028800249
Online_Training [510/700]: mean_loss=0.019590561976656318
Online_Training [511/700]: mean_loss=0.011669796658679843
Online_Training [512/700]: mean_loss=0.009413809166289866
Online_Training [513/700]: mean_loss=0.044026694260537624
Online_Training [514/700]: mean_loss=0.016336581436917186
Online_Training [515/700]: mean_loss=0.012147692847065628
Online_Training [516/700]: mean_loss=0.014850797364488244
Online_Training [517/700]: mean_loss=0.017844645772129297
Online_Training [518/700]: mean_loss=0.024877991527318954
Online_Training [519/700]: mean_loss=0.023928744718432426
Online_Training [520/700]: mean_loss=0.020439309533685446
Online_Training [521/700]: mean_loss=0.012888232595287263
Online_Training [522/700]: mean_loss=0.026164207374677062
Online_Training [523/700]: mean_loss=0.023324969923123717
Online_Training [524/700]: mean_loss=0.026049298467114568
Online_Training [525/700]: mean_loss=0.03742994414642453
Online_Training [526/700]: mean_loss=0.006382897729054093
Online_Training [527/700]: mean_loss=0.015587620320729911
Online_Training [528/700]: mean_loss=0.09122130740433931
Online_Training [529/700]: mean_loss=0.052730207331478596
Online_Training [530/700]: mean_loss=0.031404634937644005
Online_Training [531/700]: mean_loss=0.012258186470717192
Online_Training [532/700]: mean_loss=0.025330514879897237
Online_Training [533/700]: mean_loss=0.023757142713293433
Online_Training [534/700]: mean_loss=0.04647125629708171
Online_Training [535/700]: mean_loss=0.03269061306491494
Online_Training [536/700]: mean_loss=0.025858100270852447
Online_Training [537/700]: mean_loss=0.016921875532716513
Online_Training [538/700]: mean_loss=0.051499778404831886
Online_Training [539/700]: mean_loss=0.045385888777673244
Online_Training [540/700]: mean_loss=0.007294775336049497
Online_Training [541/700]: mean_loss=0.02062613284215331
Online_Training [542/700]: mean_loss=0.02481274027377367
Online_Training [543/700]: mean_loss=0.014453971292823553
Online_Training [544/700]: mean_loss=0.0219749235548079
Online_Training [545/700]: mean_loss=0.018968177726492286
Online_Training [546/700]: mean_loss=0.009967538877390325
Online_Training [547/700]: mean_loss=0.01398053951561451
Online_Training [548/700]: mean_loss=0.13841833733022213
Online_Training [549/700]: mean_loss=0.058818087447434664
Online_Training [550/700]: mean_loss=0.035825408063828945
Online_Training [551/700]: mean_loss=0.01074838696513325
Online_Training [552/700]: mean_loss=0.008082411077339202
Online_Training [553/700]: mean_loss=0.006433293456211686
Online_Training [554/700]: mean_loss=0.026796678779646754
Online_Training [555/700]: mean_loss=0.034445523750036955
Online_Training [556/700]: mean_loss=0.022856813855469227
Online_Training [557/700]: mean_loss=0.01851697266101837
Online_Training [558/700]: mean_loss=0.006566511758137494
Online_Training [559/700]: mean_loss=0.01960630645044148
Online_Training [560/700]: mean_loss=0.010080859181471169
Online_Training [561/700]: mean_loss=0.023601699387654662
Online_Training [562/700]: mean_loss=0.04379201726987958
Online_Training [563/700]: mean_loss=0.029619791312143207
Online_Training [564/700]: mean_loss=0.01715525286272168
Online_Training [565/700]: mean_loss=0.03968434501439333
Online_Training [566/700]: mean_loss=0.018327791476622224
Online_Training [567/700]: mean_loss=0.01661642547696829
Online_Training [568/700]: mean_loss=0.116058642975986
Online_Training [569/700]: mean_loss=0.022917931666597724
Online_Training [570/700]: mean_loss=0.019877394661307335
Online_Training [571/700]: mean_loss=0.011433321982622147
Online_Training [572/700]: mean_loss=0.07079578097909689
Online_Training [573/700]: mean_loss=0.04827084019780159
Online_Training [574/700]: mean_loss=0.06021517887711525
Online_Training [575/700]: mean_loss=0.061252888292074203
Online_Training [576/700]: mean_loss=0.060080443508923054
Online_Training [577/700]: mean_loss=0.014016216970048845
Online_Training [578/700]: mean_loss=0.021375808864831924
Online_Training [579/700]: mean_loss=0.017952266614884138
Online_Training [580/700]: mean_loss=0.029217971488833427
Online_Training [581/700]: mean_loss=0.04318090062588453
Online_Training [582/700]: mean_loss=0.018600223353132606
Online_Training [583/700]: mean_loss=0.031036420492455363
Online_Training [584/700]: mean_loss=0.02097880281507969
Online_Training [585/700]: mean_loss=0.031820361502468586
Online_Training [586/700]: mean_loss=0.020236631855368614
Online_Training [587/700]: mean_loss=0.029786031926050782
Online_Training [588/700]: mean_loss=0.02423795568756759
Online_Training [589/700]: mean_loss=0.06374516151845455
Online_Training [590/700]: mean_loss=0.03126951027661562
Online_Training [591/700]: mean_loss=0.018604799872264266
Online_Training [592/700]: mean_loss=0.03036200674250722
Online_Training [593/700]: mean_loss=0.19171375036239624
Online_Training [594/700]: mean_loss=0.07765880320221186
Online_Training [595/700]: mean_loss=0.02110998285934329
Online_Training [596/700]: mean_loss=0.007811253424733877
Online_Training [597/700]: mean_loss=0.011547221918590367
Online_Training [598/700]: mean_loss=0.06333630252629519
Online_Training [599/700]: mean_loss=0.02249733847565949
Online_Training [600/700]: mean_loss=0.007613952271640301
Online_Training [601/700]: mean_loss=0.03633264638483524
Online_Training [602/700]: mean_loss=0.028353716246783733
Online_Training [603/700]: mean_loss=0.03355849743820727
Online_Training [604/700]: mean_loss=0.025045489659532905
Online_Training [605/700]: mean_loss=0.027164335129782557
Online_Training [606/700]: mean_loss=0.023716949857771397
Online_Training [607/700]: mean_loss=0.036049592308700085
Online_Training [608/700]: mean_loss=0.0322593511082232
Online_Training [609/700]: mean_loss=0.021332420874387026
Online_Training [610/700]: mean_loss=0.02562867384403944
Online_Training [611/700]: mean_loss=0.014486019150353968
Online_Training [612/700]: mean_loss=0.02750289486721158
Online_Training [613/700]: mean_loss=0.03355035395361483
Online_Training [614/700]: mean_loss=0.007796920894179493
Online_Training [615/700]: mean_loss=0.022085639415308833
Online_Training [616/700]: mean_loss=0.032320312689989805
Online_Training [617/700]: mean_loss=0.02106208261102438
Online_Training [618/700]: mean_loss=0.04404393723234534
Online_Training [619/700]: mean_loss=0.027883923845365644
Online_Training [620/700]: mean_loss=0.032810583943501115
Online_Training [621/700]: mean_loss=0.0263776951469481
Online_Training [622/700]: mean_loss=0.02297701477073133
Online_Training [623/700]: mean_loss=0.0357465511187911
Online_Training [624/700]: mean_loss=0.014444218832068145
Online_Training [625/700]: mean_loss=0.014006414450705051
Online_Training [626/700]: mean_loss=0.029816701775416732
Online_Training [627/700]: mean_loss=0.03653470380231738
Online_Training [628/700]: mean_loss=0.0070833045756444335
Online_Training [629/700]: mean_loss=0.019608937203884125
Online_Training [630/700]: mean_loss=0.030387157574295998
Online_Training [631/700]: mean_loss=0.03021538257598877
Online_Training [632/700]: mean_loss=0.030960487900301814
Online_Training [633/700]: mean_loss=0.01728786271996796
Online_Training [634/700]: mean_loss=0.025161650264635682
Online_Training [635/700]: mean_loss=0.013383273500949144
Online_Training [636/700]: mean_loss=0.006030807679053396
Online_Training [637/700]: mean_loss=0.05020273802801967
Online_Training [638/700]: mean_loss=0.05156646855175495
Online_Training [639/700]: mean_loss=0.019838158506900072
Online_Training [640/700]: mean_loss=0.023076255340129137
Online_Training [641/700]: mean_loss=0.026405004085972905
Online_Training [642/700]: mean_loss=0.011976100504398346
Online_Training [643/700]: mean_loss=0.054363833740353584
Online_Training [644/700]: mean_loss=0.1660471074283123
Online_Training [645/700]: mean_loss=0.14545660838484764
Online_Training [646/700]: mean_loss=0.09445141162723303
Online_Training [647/700]: mean_loss=0.0340158655308187
Online_Training [648/700]: mean_loss=0.02382715931162238
Online_Training [649/700]: mean_loss=0.021823215065523982
Online_Training [650/700]: mean_loss=0.03831791551783681
Online_Training [651/700]: mean_loss=0.01597618730738759
Online_Training [652/700]: mean_loss=0.027968623209744692
Online_Training [653/700]: mean_loss=0.027625988237559795
Online_Training [654/700]: mean_loss=0.030608249828219414
Online_Training [655/700]: mean_loss=0.03727734088897705
Online_Training [656/700]: mean_loss=0.04153088992461562
Online_Training [657/700]: mean_loss=0.02013057447038591
Online_Training [658/700]: mean_loss=0.012083048466593027
Online_Training [659/700]: mean_loss=0.03614769270643592
Online_Training [660/700]: mean_loss=0.008720472571440041
Online_Training [661/700]: mean_loss=0.025436779018491507
Online_Training [662/700]: mean_loss=0.02224968816153705
Online_Training [663/700]: mean_loss=0.014336282038129866
Online_Training [664/700]: mean_loss=0.018272445537149906
Online_Training [665/700]: mean_loss=0.0224153115414083
Online_Training [666/700]: mean_loss=0.017581884749233723
Online_Training [667/700]: mean_loss=0.02033570152707398
Online_Training [668/700]: mean_loss=0.10371283814311028
Online_Training [669/700]: mean_loss=0.0977018903940916
Online_Training [670/700]: mean_loss=0.03384966682642698
Online_Training [671/700]: mean_loss=0.017138050869107246
Online_Training [672/700]: mean_loss=0.041573924012482166
Online_Training [673/700]: mean_loss=0.019119098782539368
Online_Training [674/700]: mean_loss=0.010701662860810757
Online_Training [675/700]: mean_loss=0.01253216597251594
Online_Training [676/700]: mean_loss=0.047269070986658335
Online_Training [677/700]: mean_loss=0.008773387875407934
Online_Training [678/700]: mean_loss=0.020566310035064816
Online_Training [679/700]: mean_loss=0.07754906266927719
Online_Training [680/700]: mean_loss=0.023232282605022192
Online_Training [681/700]: mean_loss=0.020854142028838396
Online_Training [682/700]: mean_loss=0.0055116439471021295
Online_Training [683/700]: mean_loss=0.008442881982773542
Online_Training [684/700]: mean_loss=0.035208547953516245
Online_Training [685/700]: mean_loss=0.02471647667698562
Online_Training [686/700]: mean_loss=0.012692413059994578
Online_Training [687/700]: mean_loss=0.03015017951838672
Online_Training [688/700]: mean_loss=0.03036513738334179
Online_Training [689/700]: mean_loss=0.03763231262564659
Online_Training [690/700]: mean_loss=0.018669786397367716
Online_Training [691/700]: mean_loss=0.016561355674639344
Online_Training [692/700]: mean_loss=0.011498998268507421
Online_Training [693/700]: mean_loss=0.021740035386756063
Online_Training [694/700]: mean_loss=0.0228972346521914
Online_Training [695/700]: mean_loss=0.01681928662583232
Online_Training [696/700]: mean_loss=0.02317877975292504
Online_Training [697/700]: mean_loss=0.017439966555684805
Online_Training [698/700]: mean_loss=0.031825347105041146
Online_Training [699/700]: mean_loss=0.03172949352301657
Online_Training [700/700]: mean_loss=0.06762724183499813
Q_Learning [1/300]: mean_loss=0.17768424563109875
Q_Learning [2/300]: mean_loss=0.2293134666979313
Q_Learning [3/300]: mean_loss=0.21032082103192806
Q_Learning [4/300]: mean_loss=0.17700419016182423
Q_Learning [5/300]: mean_loss=0.132999612018466
Q_Learning [6/300]: mean_loss=0.07679529674351215
Q_Learning [7/300]: mean_loss=0.11864354647696018
Q_Learning [8/300]: mean_loss=0.12231648340821266
Q_Learning [9/300]: mean_loss=0.05428364034742117
Q_Learning [10/300]: mean_loss=0.12848705239593983
Q_Learning [11/300]: mean_loss=0.06588777946308255
Q_Learning [12/300]: mean_loss=0.09581219870597124
Q_Learning [13/300]: mean_loss=0.11489417962729931
Q_Learning [14/300]: mean_loss=0.055788031313568354
Q_Learning [15/300]: mean_loss=0.031239155447110534
Q_Learning [16/300]: mean_loss=0.043273625429719687
Q_Learning [17/300]: mean_loss=0.03982788324356079
Q_Learning [18/300]: mean_loss=0.024294932140037417
Q_Learning [19/300]: mean_loss=0.09592264611274004
Q_Learning [20/300]: mean_loss=0.03289787867106497
Q_Learning [21/300]: mean_loss=0.0440607899799943
Q_Learning [22/300]: mean_loss=0.07463826518505812
Q_Learning [23/300]: mean_loss=0.0331519627943635
Q_Learning [24/300]: mean_loss=0.040963276755064726
Q_Learning [25/300]: mean_loss=0.024426867021247745
Q_Learning [26/300]: mean_loss=0.09175802487879992
Q_Learning [27/300]: mean_loss=0.10572593379765749
Q_Learning [28/300]: mean_loss=0.04169469699263573
Q_Learning [29/300]: mean_loss=0.0679589407518506
Q_Learning [30/300]: mean_loss=0.03251363057643175
Q_Learning [31/300]: mean_loss=0.11310218460857868
Q_Learning [32/300]: mean_loss=0.02791013359092176
Q_Learning [33/300]: mean_loss=0.0155514448415488
Q_Learning [34/300]: mean_loss=0.023325031623244286
Q_Learning [35/300]: mean_loss=0.13582201674580574
Q_Learning [36/300]: mean_loss=0.054358630906790495
Q_Learning [37/300]: mean_loss=0.10269625578075647
Q_Learning [38/300]: mean_loss=0.055749244056642056
Q_Learning [39/300]: mean_loss=0.021305073285475373
Q_Learning [40/300]: mean_loss=0.11256379261612892
Q_Learning [41/300]: mean_loss=0.083229367621243
Q_Learning [42/300]: mean_loss=0.07308934163302183
Q_Learning [43/300]: mean_loss=0.04929291969165206
Q_Learning [44/300]: mean_loss=0.17038460075855255
Q_Learning [45/300]: mean_loss=0.08631460927426815
Q_Learning [46/300]: mean_loss=0.06850697193294764
Q_Learning [47/300]: mean_loss=0.05292169749736786
Q_Learning [48/300]: mean_loss=0.02168991230428219
Q_Learning [49/300]: mean_loss=0.0444017737172544
Q_Learning [50/300]: mean_loss=0.030576501274481416
Q_Learning [51/300]: mean_loss=0.02501118159852922
Q_Learning [52/300]: mean_loss=0.06607366306707263
Q_Learning [53/300]: mean_loss=0.01459118362981826
Q_Learning [54/300]: mean_loss=0.021704106824472547
Q_Learning [55/300]: mean_loss=0.10825465992093086
Q_Learning [56/300]: mean_loss=0.03811630280688405
Q_Learning [57/300]: mean_loss=0.0600162916816771
Q_Learning [58/300]: mean_loss=0.05973101546987891
Q_Learning [59/300]: mean_loss=0.03239040239714086
Q_Learning [60/300]: mean_loss=0.036400643177330494
Q_Learning [61/300]: mean_loss=0.06206285208463669
Q_Learning [62/300]: mean_loss=0.036121084820479155
Q_Learning [63/300]: mean_loss=0.03018522006459534
Q_Learning [64/300]: mean_loss=0.006898549618199468
Q_Learning [65/300]: mean_loss=0.046487894374877214
Q_Learning [66/300]: mean_loss=0.06169221270829439
Q_Learning [67/300]: mean_loss=0.05983116989955306
Q_Learning [68/300]: mean_loss=0.014818069175817072
Q_Learning [69/300]: mean_loss=0.1365622840821743
Q_Learning [70/300]: mean_loss=0.06115381792187691
Q_Learning [71/300]: mean_loss=0.02654519211500883
Q_Learning [72/300]: mean_loss=0.05133091704919934
Q_Learning [73/300]: mean_loss=0.025676284451037645
Q_Learning [74/300]: mean_loss=0.054317822214215994
Q_Learning [75/300]: mean_loss=0.010067865019664168
Q_Learning [76/300]: mean_loss=0.03366040764376521
Q_Learning [77/300]: mean_loss=0.04163406463339925
Q_Learning [78/300]: mean_loss=0.06295720487833023
Q_Learning [79/300]: mean_loss=0.09038065187633038
Q_Learning [80/300]: mean_loss=0.02085325261577964
Q_Learning [81/300]: mean_loss=0.058542067650705576
Q_Learning [82/300]: mean_loss=0.03663361165672541
Q_Learning [83/300]: mean_loss=0.021643388317897916
Q_Learning [84/300]: mean_loss=0.012348294258117676
Q_Learning [85/300]: mean_loss=0.03537394059821963
Q_Learning [86/300]: mean_loss=0.0404198975302279
Q_Learning [87/300]: mean_loss=0.02244548685848713
Q_Learning [88/300]: mean_loss=0.051326361019164324
Q_Learning [89/300]: mean_loss=0.028929366962984204
Q_Learning [90/300]: mean_loss=0.07805864699184895
Q_Learning [91/300]: mean_loss=0.025558603694662452
Q_Learning [92/300]: mean_loss=0.09105113986879587
Q_Learning [93/300]: mean_loss=0.027743597282096744
Q_Learning [94/300]: mean_loss=0.03784482320770621
Q_Learning [95/300]: mean_loss=0.06754032801836729
Q_Learning [96/300]: mean_loss=0.014553723856806755
Q_Learning [97/300]: mean_loss=0.013347551692277193
Q_Learning [98/300]: mean_loss=0.02730109845288098
Q_Learning [99/300]: mean_loss=0.04826702689751983
Q_Learning [100/300]: mean_loss=0.03416151227429509
Q_Learning [101/300]: mean_loss=0.033261862117797136
Q_Learning [102/300]: mean_loss=0.0640229219570756
Q_Learning [103/300]: mean_loss=0.040318925864994526
Q_Learning [104/300]: mean_loss=0.01256606460083276
Q_Learning [105/300]: mean_loss=0.01185359270311892
Q_Learning [106/300]: mean_loss=0.06155447429046035
Q_Learning [107/300]: mean_loss=0.01301894849166274
Q_Learning [108/300]: mean_loss=0.04909211164340377
Q_Learning [109/300]: mean_loss=0.03331001498736441
Q_Learning [110/300]: mean_loss=0.024407458025962114
Q_Learning [111/300]: mean_loss=0.07218565605580807
Q_Learning [112/300]: mean_loss=0.08798038121312857
Q_Learning [113/300]: mean_loss=0.07289536390453577
Q_Learning [114/300]: mean_loss=0.04624020680785179
Q_Learning [115/300]: mean_loss=0.028448613127693534
Q_Learning [116/300]: mean_loss=0.05231936927884817
Q_Learning [117/300]: mean_loss=0.03234091401100159
Q_Learning [118/300]: mean_loss=0.15642757155001163
Q_Learning [119/300]: mean_loss=0.03294902294874191
Q_Learning [120/300]: mean_loss=0.04025092115625739
Q_Learning [121/300]: mean_loss=0.04431608086451888
Q_Learning [122/300]: mean_loss=0.06436082208529115
Q_Learning [123/300]: mean_loss=0.04103560792282224
Q_Learning [124/300]: mean_loss=0.04126637615263462
Q_Learning [125/300]: mean_loss=0.03206213563680649
Q_Learning [126/300]: mean_loss=0.03925596550107002
Q_Learning [127/300]: mean_loss=0.03077642433345318
Q_Learning [128/300]: mean_loss=0.053475400898605585
Q_Learning [129/300]: mean_loss=0.04358912445604801
Q_Learning [130/300]: mean_loss=0.031878467882052064
Q_Learning [131/300]: mean_loss=0.049710944294929504
Q_Learning [132/300]: mean_loss=0.05924837803468108
Q_Learning [133/300]: mean_loss=0.07782264519482851
Q_Learning [134/300]: mean_loss=0.012664055335335433
Q_Learning [135/300]: mean_loss=0.17111892439424992
Q_Learning [136/300]: mean_loss=0.11533017735928297
Q_Learning [137/300]: mean_loss=0.05576658574864268
Q_Learning [138/300]: mean_loss=0.17395075596868992
Q_Learning [139/300]: mean_loss=0.07766954321414232
Q_Learning [140/300]: mean_loss=0.03136602183803916
Q_Learning [141/300]: mean_loss=0.05810893652960658
Q_Learning [142/300]: mean_loss=0.04199468903243542
Q_Learning [143/300]: mean_loss=0.07042983639985323
Q_Learning [144/300]: mean_loss=0.026969147380441427
Q_Learning [145/300]: mean_loss=0.07839974481612444
Q_Learning [146/300]: mean_loss=0.0441633015871048
Q_Learning [147/300]: mean_loss=0.021262499736621976
Q_Learning [148/300]: mean_loss=0.09492924716323614
Q_Learning [149/300]: mean_loss=0.05277856206521392
Q_Learning [150/300]: mean_loss=0.025610313983634114
Q_Learning [151/300]: mean_loss=0.03564836084842682
Q_Learning [152/300]: mean_loss=0.015809881617315114
Q_Learning [153/300]: mean_loss=0.038721383549273014
Q_Learning [154/300]: mean_loss=0.06900127977132797
Q_Learning [155/300]: mean_loss=0.05034807464107871
Q_Learning [156/300]: mean_loss=0.03389785625040531
Q_Learning [157/300]: mean_loss=0.03466266859322786
Q_Learning [158/300]: mean_loss=0.026893767761066556
Q_Learning [159/300]: mean_loss=0.057317500934004784
Q_Learning [160/300]: mean_loss=0.012212261091917753
Q_Learning [161/300]: mean_loss=0.029384783701971173
Q_Learning [162/300]: mean_loss=0.0618594572879374
Q_Learning [163/300]: mean_loss=0.06432500248774886
Q_Learning [164/300]: mean_loss=0.058312092907726765
Q_Learning [165/300]: mean_loss=0.025466385995969176
Q_Learning [166/300]: mean_loss=0.008985336520709097
Q_Learning [167/300]: mean_loss=0.02615454141050577
Q_Learning [168/300]: mean_loss=0.03169264690950513
Q_Learning [169/300]: mean_loss=0.07127786241471767
Q_Learning [170/300]: mean_loss=0.008273665385786444
Q_Learning [171/300]: mean_loss=0.04112183442339301
Q_Learning [172/300]: mean_loss=0.01764765428379178
Q_Learning [173/300]: mean_loss=0.03489309595897794
Q_Learning [174/300]: mean_loss=0.16501469910144806
Q_Learning [175/300]: mean_loss=0.11485905200242996
Q_Learning [176/300]: mean_loss=0.04263318330049515
Q_Learning [177/300]: mean_loss=0.04556299792602658
Q_Learning [178/300]: mean_loss=0.041157579980790615
Q_Learning [179/300]: mean_loss=0.02802034979686141
Q_Learning [180/300]: mean_loss=0.0206443821080029
Q_Learning [181/300]: mean_loss=0.04157947935163975
Q_Learning [182/300]: mean_loss=0.0716327428817749
Q_Learning [183/300]: mean_loss=0.0441774963401258
Q_Learning [184/300]: mean_loss=0.04182602418586612
Q_Learning [185/300]: mean_loss=0.0786276226863265
Q_Learning [186/300]: mean_loss=0.31029776856303215
Q_Learning [187/300]: mean_loss=0.05858460394665599
Q_Learning [188/300]: mean_loss=0.02814992913044989
Q_Learning [189/300]: mean_loss=0.04150039190426469
Q_Learning [190/300]: mean_loss=0.08147722389549017
Q_Learning [191/300]: mean_loss=0.06632773764431477
Q_Learning [192/300]: mean_loss=0.021065242355689406
Q_Learning [193/300]: mean_loss=0.02618026710115373
Q_Learning [194/300]: mean_loss=0.052787842229008675
Q_Learning [195/300]: mean_loss=0.03504813648760319
Q_Learning [196/300]: mean_loss=0.021773205837234855
Q_Learning [197/300]: mean_loss=0.01886206096969545
Q_Learning [198/300]: mean_loss=0.12511266861110926
Q_Learning [199/300]: mean_loss=0.07230758387595415
Q_Learning [200/300]: mean_loss=0.02112292731180787
Q_Learning [201/300]: mean_loss=0.014171803602948785
Q_Learning [202/300]: mean_loss=0.04196204990148544
Q_Learning [203/300]: mean_loss=0.02055295091122389
Q_Learning [204/300]: mean_loss=0.04370401008054614
Q_Learning [205/300]: mean_loss=0.023231655824929476
Q_Learning [206/300]: mean_loss=0.028243757551535964
Q_Learning [207/300]: mean_loss=0.013442595605738461
Q_Learning [208/300]: mean_loss=0.03868777956813574
Q_Learning [209/300]: mean_loss=0.040370482951402664
Q_Learning [210/300]: mean_loss=0.01945902267470956
Q_Learning [211/300]: mean_loss=0.020233928225934505
Q_Learning [212/300]: mean_loss=0.014188247383572161
Q_Learning [213/300]: mean_loss=0.023543836316093802
Q_Learning [214/300]: mean_loss=0.020470350980758667
Q_Learning [215/300]: mean_loss=0.012341265566647053
Q_Learning [216/300]: mean_loss=0.025649453047662973
Q_Learning [217/300]: mean_loss=0.033867357298731804
Q_Learning [218/300]: mean_loss=0.03258939110673964
Q_Learning [219/300]: mean_loss=0.028031047200784087
Q_Learning [220/300]: mean_loss=0.03535032016225159
Q_Learning [221/300]: mean_loss=0.015617364551872015
Q_Learning [222/300]: mean_loss=0.028132919454947114
Q_Learning [223/300]: mean_loss=0.026620492804795504
Q_Learning [224/300]: mean_loss=0.03899524314329028
Q_Learning [225/300]: mean_loss=0.03193393815308809
Q_Learning [226/300]: mean_loss=0.013433092972263694
Q_Learning [227/300]: mean_loss=0.015098902978934348
Q_Learning [228/300]: mean_loss=0.03944595903158188
Q_Learning [229/300]: mean_loss=0.03173720929771662
Q_Learning [230/300]: mean_loss=0.03386464132927358
Q_Learning [231/300]: mean_loss=0.029849078273400664
Q_Learning [232/300]: mean_loss=0.019465174758806825
Q_Learning [233/300]: mean_loss=0.011412969790399075
Q_Learning [234/300]: mean_loss=0.06004709145054221
Q_Learning [235/300]: mean_loss=0.10166732408106327
Q_Learning [236/300]: mean_loss=0.04182137502357364
Q_Learning [237/300]: mean_loss=0.03634677641093731
Q_Learning [238/300]: mean_loss=0.09912549424916506
Q_Learning [239/300]: mean_loss=0.058776797726750374
Q_Learning [240/300]: mean_loss=0.0450075464323163
Q_Learning [241/300]: mean_loss=0.07426731754094362
Q_Learning [242/300]: mean_loss=0.015177993453107774
Q_Learning [243/300]: mean_loss=0.03294427087530494
Q_Learning [244/300]: mean_loss=0.02542860130779445
Q_Learning [245/300]: mean_loss=0.034623281797394156
Q_Learning [246/300]: mean_loss=0.020026954356580973
Q_Learning [247/300]: mean_loss=0.03276155469939113
Q_Learning [248/300]: mean_loss=0.04559795977547765
Q_Learning [249/300]: mean_loss=0.044030637945979834
Q_Learning [250/300]: mean_loss=0.014635713421739638
Q_Learning [251/300]: mean_loss=0.04202139424160123
Q_Learning [252/300]: mean_loss=0.03159999451600015
Q_Learning [253/300]: mean_loss=0.02384236198849976
Q_Learning [254/300]: mean_loss=0.019521361915394664
Q_Learning [255/300]: mean_loss=0.03814807953312993
Q_Learning [256/300]: mean_loss=0.032061298843473196
Q_Learning [257/300]: mean_loss=0.044906552881002426
Q_Learning [258/300]: mean_loss=0.022986406227573752
Q_Learning [259/300]: mean_loss=0.03635825775563717
Q_Learning [260/300]: mean_loss=0.02341172005981207
Q_Learning [261/300]: mean_loss=0.05461942870169878
Q_Learning [262/300]: mean_loss=0.20761611126363277
Q_Learning [263/300]: mean_loss=0.03807615349069238
Q_Learning [264/300]: mean_loss=0.01231418747920543
Q_Learning [265/300]: mean_loss=0.038183697033673525
Q_Learning [266/300]: mean_loss=0.02974242903292179
Q_Learning [267/300]: mean_loss=0.043352986220270395
Q_Learning [268/300]: mean_loss=0.021309595555067062
Q_Learning [269/300]: mean_loss=0.026913606096059084
Q_Learning [270/300]: mean_loss=0.018198123900219798
Q_Learning [271/300]: mean_loss=0.019760839641094208
Q_Learning [272/300]: mean_loss=0.036447858437895775
Q_Learning [273/300]: mean_loss=0.020881567150354385
Q_Learning [274/300]: mean_loss=0.0276895584538579
Q_Learning [275/300]: mean_loss=0.022283816942945123
Q_Learning [276/300]: mean_loss=0.034276722464710474
Q_Learning [277/300]: mean_loss=0.03071661526337266
Q_Learning [278/300]: mean_loss=0.023138461401686072
Q_Learning [279/300]: mean_loss=0.044473419431596994
Q_Learning [280/300]: mean_loss=0.01584836351685226
Q_Learning [281/300]: mean_loss=0.02452312712557614
Q_Learning [282/300]: mean_loss=0.016611583065241575
Q_Learning [283/300]: mean_loss=0.043456916231662035
Q_Learning [284/300]: mean_loss=0.02194389933720231
Q_Learning [285/300]: mean_loss=0.028759446926414967
Q_Learning [286/300]: mean_loss=0.007321680604945868
Q_Learning [287/300]: mean_loss=0.03402702324092388
Q_Learning [288/300]: mean_loss=0.06637554755434394
Q_Learning [289/300]: mean_loss=0.019743713783100247
Q_Learning [290/300]: mean_loss=0.025252998108044267
Q_Learning [291/300]: mean_loss=0.03103613038547337
Q_Learning [292/300]: mean_loss=0.04125935351476073
Q_Learning [293/300]: mean_loss=0.015896063181571662
Q_Learning [294/300]: mean_loss=0.06841093441471457
Q_Learning [295/300]: mean_loss=0.0247476187068969
Q_Learning [296/300]: mean_loss=0.03353992127813399
Q_Learning [297/300]: mean_loss=0.024445940973237157
Q_Learning [298/300]: mean_loss=0.016013105399906635
Q_Learning [299/300]: mean_loss=0.00637426198227331
Q_Learning [300/300]: mean_loss=0.009146637981757522
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.49398795  2.2087674 ]
[2, 0, 0, 1, 2, 0, 2, 0, 0, 1, 1, 0, 0, 0, 2, 1, 1, 0, 2, 2, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 2, 2, 2, 1, 0, 1, 2, 0, 1, 2, 1, 2, 1, 0, 2, 0, 0, 1, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 0, 2, 2, 2, 0, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 0, 1, 2, 1, 2, 1, 2, 0, 0, 1, 2, 1, 2, 1, 0, 2, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 2, 0, 1, 0, 1, 1, 2, 2, 2, 1, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 1, 0, 1, 1, 0, 2, 2, 1, 1, 2, 1, 0, 0, 2, 2, 0, 1, 2, 1, 2, 2, 2, 0, 0, 2, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 2, 1, 1, 0, 2, 2, 1, 0, 0, 1, 1, 1, 0, 2, 2, 2, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 1, 2, 0, 2, 1, 0, 2, 0, 2, 2]
[0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 2, 1, 3, 0, 1, 0, 0, 3, 0, 2, 1, 2, 2, 0, 1, 1, 0, 1, 1, 0, 3, 0, 0, 1, 2, 0, 3, 1, 3, 0, 0, 0, 0, 1, 1, 0, 1, 0, 3, 2, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 2, 1, 1, 0, 2, 2, 3, 1, 0, 3, 1, 1, 1, 1, 3, 1, 0, 0, 0, 0, 1, 1, 3, 2, 3, 0, 0, 0, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2, 3, 1, 1, 1, 1, 3, 0, 0, 1, 2, 3, 2, 1, 1, 3, 3, 3, 0, 2, 2, 2, 0, 2, 1, 1, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 3, 3, 2, 1, 3, 1, 1, 1, 0, 1, 1, 2, 2, 3, 2, 0, 1, 0, 2, 2, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2, 1, 1, 1, 0, 0, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 1, 2, 2, 3, 2, 0, 0, 2, 1, 1, 2, 1, 3, 0, 3, 2, 1, 1, 0, 3, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 3, 3, 0, 1, 3, 2, 2, 0, 3, 1, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 3, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1]
Centroids: [[0.28199896, 0.11430443], [-0.16241437, 0.48614445], [0.25834873, 1.1084869]]
Centroids: [[0.31260407, 1.3245709], [-0.04802206, -0.0046998686], [1.1663127, 0.2219803], [-1.2733694, 1.1732367]]
Contingency Matrix: 
[[11 59 26  9]
 [25 46 10 14]
 [52 18 18 12]]
[[11, 59, 26, 9], [25, 46, 10, 14], [52, 18, 18, 12]]
[[11, 59, 26, 9], [25, 46, 10, 14], [52, 18, 18, 12]]
[0, 1, 2, 3]
[[-1, -1, -1, -1], [25, -1, 10, 14], [52, -1, 18, 12]]
[[-1, -1, -1, -1], [-1, -1, 10, 14], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {0: 1, 2: 0, 1: 3}
New Contingency Matrix: 
[[59  9 11 26]
 [46 14 25 10]
 [18 12 52 18]]
New Clustered Label Sequence: [1, 3, 0, 2]
Diagonal_Elements: [59, 14, 52], Sum: 125
All_Elements: [59, 9, 11, 26, 46, 14, 25, 10, 18, 12, 52, 18], Sum: 300
Accuracy: 0.4166666666666667
