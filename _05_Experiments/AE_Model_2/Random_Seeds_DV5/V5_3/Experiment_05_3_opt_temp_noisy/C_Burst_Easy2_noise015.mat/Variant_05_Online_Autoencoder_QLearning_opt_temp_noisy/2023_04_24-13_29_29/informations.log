Experiment_path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_3_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: AE_Model_2/Random_Seeds_DV5//V5_3/Experiment_05_3_opt_temp_noisy/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_24-13_29_29
Punishment_Coefficient: 0.9
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002525A616320>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.16767941415309906
Online_Training [2/700]: mean_loss=0.2525527570396662
Online_Training [3/700]: mean_loss=0.19892032071948051
Online_Training [4/700]: mean_loss=0.05118644190952182
Online_Training [5/700]: mean_loss=0.25652807392179966
Online_Training [6/700]: mean_loss=0.08748406171798706
Online_Training [7/700]: mean_loss=0.12779228575527668
Online_Training [8/700]: mean_loss=0.07619846425950527
Online_Training [9/700]: mean_loss=0.20840296521782875
Online_Training [10/700]: mean_loss=0.15208757296204567
Online_Training [11/700]: mean_loss=0.07334634847939014
Online_Training [12/700]: mean_loss=0.06850581429898739
Online_Training [13/700]: mean_loss=0.0966894868761301
Online_Training [14/700]: mean_loss=0.07523268926888704
Online_Training [15/700]: mean_loss=0.057592031080275774
Online_Training [16/700]: mean_loss=0.141929991543293
Online_Training [17/700]: mean_loss=0.15038487873971462
Online_Training [18/700]: mean_loss=0.10122577752918005
Online_Training [19/700]: mean_loss=0.02469629584811628
Online_Training [20/700]: mean_loss=0.20412708446383476
Online_Training [21/700]: mean_loss=0.1348206428810954
Online_Training [22/700]: mean_loss=0.05091307684779167
Online_Training [23/700]: mean_loss=0.022093955660238862
Online_Training [24/700]: mean_loss=0.10470474325120449
Online_Training [25/700]: mean_loss=0.04841448413208127
Online_Training [26/700]: mean_loss=0.0765892444178462
Online_Training [27/700]: mean_loss=0.1025556679815054
Online_Training [28/700]: mean_loss=0.05096859531477094
Online_Training [29/700]: mean_loss=0.050845460034906864
Online_Training [30/700]: mean_loss=0.030646330444142222
Online_Training [31/700]: mean_loss=0.030585983535274863
Online_Training [32/700]: mean_loss=0.04833456547930837
Online_Training [33/700]: mean_loss=0.02288719406351447
Online_Training [34/700]: mean_loss=0.20195152051746845
Online_Training [35/700]: mean_loss=0.06444211257621646
Online_Training [36/700]: mean_loss=0.08650117181241512
Online_Training [37/700]: mean_loss=0.06709120329469442
Online_Training [38/700]: mean_loss=0.03900466999039054
Online_Training [39/700]: mean_loss=0.1383739449083805
Online_Training [40/700]: mean_loss=0.02807305916212499
Online_Training [41/700]: mean_loss=0.03403385542333126
Online_Training [42/700]: mean_loss=0.05864075664430857
Online_Training [43/700]: mean_loss=0.13186920247972012
Online_Training [44/700]: mean_loss=0.15288249775767326
Online_Training [45/700]: mean_loss=0.0983422938734293
Online_Training [46/700]: mean_loss=0.06526533095166087
Online_Training [47/700]: mean_loss=0.10400635376572609
Online_Training [48/700]: mean_loss=0.07381646055728197
Online_Training [49/700]: mean_loss=0.09107325412333012
Online_Training [50/700]: mean_loss=0.10598633531481028
Online_Training [51/700]: mean_loss=0.03428327385336161
Online_Training [52/700]: mean_loss=0.167131919413805
Online_Training [53/700]: mean_loss=0.03535336162894964
Online_Training [54/700]: mean_loss=0.09123489074409008
Online_Training [55/700]: mean_loss=0.07170522678643465
Online_Training [56/700]: mean_loss=0.0397677356377244
Online_Training [57/700]: mean_loss=0.10033018235117197
Online_Training [58/700]: mean_loss=0.2762283105403185
Online_Training [59/700]: mean_loss=0.09569341456517577
Online_Training [60/700]: mean_loss=0.05831606639549136
Online_Training [61/700]: mean_loss=0.0497137145139277
Online_Training [62/700]: mean_loss=0.10183988139033318
Online_Training [63/700]: mean_loss=0.07140860985964537
Online_Training [64/700]: mean_loss=0.006749207794200629
Online_Training [65/700]: mean_loss=0.06866688095033169
Online_Training [66/700]: mean_loss=0.04247738840058446
Online_Training [67/700]: mean_loss=0.05947238113731146
Online_Training [68/700]: mean_loss=0.03789705829694867
Online_Training [69/700]: mean_loss=0.07424865709617734
Online_Training [70/700]: mean_loss=0.03572019236162305
Online_Training [71/700]: mean_loss=0.07472446095198393
Online_Training [72/700]: mean_loss=0.08771421201527119
Online_Training [73/700]: mean_loss=0.043987888377159834
Online_Training [74/700]: mean_loss=0.04434369783848524
Online_Training [75/700]: mean_loss=0.028968256898224354
Online_Training [76/700]: mean_loss=0.025883557507768273
Online_Training [77/700]: mean_loss=0.039246165193617344
Online_Training [78/700]: mean_loss=0.028385073179379106
Online_Training [79/700]: mean_loss=0.03958803368732333
Online_Training [80/700]: mean_loss=0.03908867575228214
Online_Training [81/700]: mean_loss=0.02171849342994392
Online_Training [82/700]: mean_loss=0.026600241661071777
Online_Training [83/700]: mean_loss=0.044341875705868006
Online_Training [84/700]: mean_loss=0.030466527678072453
Online_Training [85/700]: mean_loss=0.022956233704462647
Online_Training [86/700]: mean_loss=0.04214702732861042
Online_Training [87/700]: mean_loss=0.016376143787056208
Online_Training [88/700]: mean_loss=0.032593403942883015
Online_Training [89/700]: mean_loss=0.044751403853297234
Online_Training [90/700]: mean_loss=0.018512542359530926
Online_Training [91/700]: mean_loss=0.037049475125968456
Online_Training [92/700]: mean_loss=0.04159840429201722
Online_Training [93/700]: mean_loss=0.03169418149627745
Online_Training [94/700]: mean_loss=0.04214531555771828
Online_Training [95/700]: mean_loss=0.03715119743719697
Online_Training [96/700]: mean_loss=0.027520400239154696
Online_Training [97/700]: mean_loss=0.046101582236588
Online_Training [98/700]: mean_loss=0.04546803794801235
Online_Training [99/700]: mean_loss=0.024538113735616207
Online_Training [100/700]: mean_loss=0.03225297946482897
Online_Training [101/700]: mean_loss=0.018704727408476174
Online_Training [102/700]: mean_loss=0.06212617643177509
Online_Training [103/700]: mean_loss=0.047351621091365814
Online_Training [104/700]: mean_loss=0.0402820217423141
Online_Training [105/700]: mean_loss=0.04051725286990404
Online_Training [106/700]: mean_loss=0.01737536513246596
Online_Training [107/700]: mean_loss=0.015253418823704123
Online_Training [108/700]: mean_loss=0.029533915920183063
Online_Training [109/700]: mean_loss=0.032219783402979374
Online_Training [110/700]: mean_loss=0.023099510231986642
Online_Training [111/700]: mean_loss=0.03160112886689603
Online_Training [112/700]: mean_loss=0.1585959829390049
Online_Training [113/700]: mean_loss=0.0208583720959723
Online_Training [114/700]: mean_loss=0.04315149551257491
Online_Training [115/700]: mean_loss=0.04997291974723339
Online_Training [116/700]: mean_loss=0.026601363206282258
Online_Training [117/700]: mean_loss=0.05391644034534693
Online_Training [118/700]: mean_loss=0.0578894317150116
Online_Training [119/700]: mean_loss=0.13585772551596165
Online_Training [120/700]: mean_loss=0.05354923428967595
Online_Training [121/700]: mean_loss=0.07135710027068853
Online_Training [122/700]: mean_loss=0.06839521694928408
Online_Training [123/700]: mean_loss=0.03279491770081222
Online_Training [124/700]: mean_loss=0.013673516688868403
Online_Training [125/700]: mean_loss=0.0716541176661849
Online_Training [126/700]: mean_loss=0.05619382578879595
Online_Training [127/700]: mean_loss=0.057969927322119474
Online_Training [128/700]: mean_loss=0.03059490188024938
Online_Training [129/700]: mean_loss=0.03199411160312593
Online_Training [130/700]: mean_loss=0.020673343911767006
Online_Training [131/700]: mean_loss=0.029969785828143358
Online_Training [132/700]: mean_loss=0.021096612326800823
Online_Training [133/700]: mean_loss=0.03044978016987443
Online_Training [134/700]: mean_loss=0.025176036404445767
Online_Training [135/700]: mean_loss=0.11750830989331007
Online_Training [136/700]: mean_loss=0.026694151107221842
Online_Training [137/700]: mean_loss=0.023933528922498226
Online_Training [138/700]: mean_loss=0.011866227025166154
Online_Training [139/700]: mean_loss=0.016322256880812347
Online_Training [140/700]: mean_loss=0.03631044877693057
Online_Training [141/700]: mean_loss=0.04940740345045924
Online_Training [142/700]: mean_loss=0.015363978105597198
Online_Training [143/700]: mean_loss=0.021879390347748995
Online_Training [144/700]: mean_loss=0.011303361738100648
Online_Training [145/700]: mean_loss=0.05922147538512945
Online_Training [146/700]: mean_loss=0.019376428797841072
Online_Training [147/700]: mean_loss=0.015971494605764747
Online_Training [148/700]: mean_loss=0.043265055399388075
Online_Training [149/700]: mean_loss=0.08805521205067635
Online_Training [150/700]: mean_loss=0.08529537077993155
Online_Training [151/700]: mean_loss=0.03069941815920174
Online_Training [152/700]: mean_loss=0.018079542787745595
Online_Training [153/700]: mean_loss=0.05227159708738327
Online_Training [154/700]: mean_loss=0.03167220717296004
Online_Training [155/700]: mean_loss=0.013083969475701451
Online_Training [156/700]: mean_loss=0.019947135355323553
Online_Training [157/700]: mean_loss=0.15144294314086437
Online_Training [158/700]: mean_loss=0.010532656393479556
Online_Training [159/700]: mean_loss=0.024555601878091693
Online_Training [160/700]: mean_loss=0.032971448730677366
Online_Training [161/700]: mean_loss=0.035486210603266954
Online_Training [162/700]: mean_loss=0.018448020331561565
Online_Training [163/700]: mean_loss=0.059786890633404255
Online_Training [164/700]: mean_loss=0.017157360911369324
Online_Training [165/700]: mean_loss=0.012435596669092774
Online_Training [166/700]: mean_loss=0.024058169219642878
Online_Training [167/700]: mean_loss=0.04368317453190684
Online_Training [168/700]: mean_loss=0.030269595328718424
Online_Training [169/700]: mean_loss=0.05616039875894785
Online_Training [170/700]: mean_loss=0.15758317150175571
Online_Training [171/700]: mean_loss=0.019820969318971038
Online_Training [172/700]: mean_loss=0.01593095320276916
Online_Training [173/700]: mean_loss=0.020225062733516097
Online_Training [174/700]: mean_loss=0.011418529087677598
Online_Training [175/700]: mean_loss=0.009467296418733895
Online_Training [176/700]: mean_loss=0.006335594167467207
Online_Training [177/700]: mean_loss=0.029461831785738468
Online_Training [178/700]: mean_loss=0.040641479194164276
Online_Training [179/700]: mean_loss=0.022376294480636716
Online_Training [180/700]: mean_loss=0.026267794892191887
Online_Training [181/700]: mean_loss=0.030197279527783394
Online_Training [182/700]: mean_loss=0.03582537779584527
Online_Training [183/700]: mean_loss=0.01328871923033148
Online_Training [184/700]: mean_loss=0.006150714179966599
Online_Training [185/700]: mean_loss=0.03156304662115872
Online_Training [186/700]: mean_loss=0.03369142999872565
Online_Training [187/700]: mean_loss=0.031261180993169546
Online_Training [188/700]: mean_loss=0.02472492214292288
Online_Training [189/700]: mean_loss=0.05755135789513588
Online_Training [190/700]: mean_loss=0.02411077660508454
Online_Training [191/700]: mean_loss=0.14270148240029812
Online_Training [192/700]: mean_loss=0.025294417748227715
Online_Training [193/700]: mean_loss=0.020812558010220528
Online_Training [194/700]: mean_loss=0.018870123545639217
Online_Training [195/700]: mean_loss=0.028394110267981887
Online_Training [196/700]: mean_loss=0.013232410070486367
Online_Training [197/700]: mean_loss=0.04289010865613818
Online_Training [198/700]: mean_loss=0.01671628304757178
Online_Training [199/700]: mean_loss=0.0877845287322998
Online_Training [200/700]: mean_loss=0.021954687777906656
Online_Training [201/700]: mean_loss=0.03067483939230442
Online_Training [202/700]: mean_loss=0.015465319971553981
Online_Training [203/700]: mean_loss=0.011333215050399303
Online_Training [204/700]: mean_loss=0.01336680247914046
Online_Training [205/700]: mean_loss=0.07817583903670311
Online_Training [206/700]: mean_loss=0.014339196495711803
Online_Training [207/700]: mean_loss=0.05290806479752064
Online_Training [208/700]: mean_loss=0.050388853531330824
Online_Training [209/700]: mean_loss=0.05429717293009162
Online_Training [210/700]: mean_loss=0.02822081884369254
Online_Training [211/700]: mean_loss=0.022839501267299056
Online_Training [212/700]: mean_loss=0.07981435488909483
Online_Training [213/700]: mean_loss=0.0451137232594192
Online_Training [214/700]: mean_loss=0.01579299313016236
Online_Training [215/700]: mean_loss=0.03759302245453
Online_Training [216/700]: mean_loss=0.03773865452967584
Online_Training [217/700]: mean_loss=0.02953249216079712
Online_Training [218/700]: mean_loss=0.007684728712774813
Online_Training [219/700]: mean_loss=0.04803106049075723
Online_Training [220/700]: mean_loss=0.014901102636940777
Online_Training [221/700]: mean_loss=0.030173328006640077
Online_Training [222/700]: mean_loss=0.02116317767649889
Online_Training [223/700]: mean_loss=0.03141875704750419
Online_Training [224/700]: mean_loss=0.006593075522687286
Online_Training [225/700]: mean_loss=0.031077917432412505
Online_Training [226/700]: mean_loss=0.030660692835226655
Online_Training [227/700]: mean_loss=0.01721055875532329
Online_Training [228/700]: mean_loss=0.02309716632589698
Online_Training [229/700]: mean_loss=0.0503082275390625
Online_Training [230/700]: mean_loss=0.022261594189330935
Online_Training [231/700]: mean_loss=0.023041311418637633
Online_Training [232/700]: mean_loss=0.02506712288595736
Online_Training [233/700]: mean_loss=0.021252745296806097
Online_Training [234/700]: mean_loss=0.04253956861793995
Online_Training [235/700]: mean_loss=0.09654315561056137
Online_Training [236/700]: mean_loss=0.07034066086634994
Online_Training [237/700]: mean_loss=0.02438789210282266
Online_Training [238/700]: mean_loss=0.12161505687981844
Online_Training [239/700]: mean_loss=0.07044818764552474
Online_Training [240/700]: mean_loss=0.04868696443736553
Online_Training [241/700]: mean_loss=0.03718715952709317
Online_Training [242/700]: mean_loss=0.04004319431260228
Online_Training [243/700]: mean_loss=0.044368688482791185
Online_Training [244/700]: mean_loss=0.03581628343090415
Online_Training [245/700]: mean_loss=0.04777240287512541
Online_Training [246/700]: mean_loss=0.028429866768419743
Online_Training [247/700]: mean_loss=0.010656303726136684
Online_Training [248/700]: mean_loss=0.07849946804344654
Online_Training [249/700]: mean_loss=0.012692419230006635
Online_Training [250/700]: mean_loss=0.01910597598180175
Online_Training [251/700]: mean_loss=0.018939751433208585
Online_Training [252/700]: mean_loss=0.019248427590355277
Online_Training [253/700]: mean_loss=0.018487469060346484
Online_Training [254/700]: mean_loss=0.016762332757934928
Online_Training [255/700]: mean_loss=0.03099772147834301
Online_Training [256/700]: mean_loss=0.016804668470285833
Online_Training [257/700]: mean_loss=0.017038285615853965
Online_Training [258/700]: mean_loss=0.02004067017696798
Online_Training [259/700]: mean_loss=0.01100732700433582
Online_Training [260/700]: mean_loss=0.009096913738176227
Online_Training [261/700]: mean_loss=0.02396587748080492
Online_Training [262/700]: mean_loss=0.03227770538069308
Online_Training [263/700]: mean_loss=0.011947444756515324
Online_Training [264/700]: mean_loss=0.023774762405082583
Online_Training [265/700]: mean_loss=0.0183378248475492
Online_Training [266/700]: mean_loss=0.012583497329615057
Online_Training [267/700]: mean_loss=0.011018565972335637
Online_Training [268/700]: mean_loss=0.007884489081334323
Online_Training [269/700]: mean_loss=0.016019031638279557
Online_Training [270/700]: mean_loss=0.009119327762164176
Online_Training [271/700]: mean_loss=0.024925771402195096
Online_Training [272/700]: mean_loss=0.007762540597468615
Online_Training [273/700]: mean_loss=0.01042108389083296
Online_Training [274/700]: mean_loss=0.011848631780594587
Online_Training [275/700]: mean_loss=0.01348615635652095
Online_Training [276/700]: mean_loss=0.014125259011052549
Online_Training [277/700]: mean_loss=0.028909737477079034
Online_Training [278/700]: mean_loss=0.02246027742512524
Online_Training [279/700]: mean_loss=0.01838568225502968
Online_Training [280/700]: mean_loss=0.023738668533042073
Online_Training [281/700]: mean_loss=0.019834698643535376
Online_Training [282/700]: mean_loss=0.03252821136265993
Online_Training [283/700]: mean_loss=0.025497639551758766
Online_Training [284/700]: mean_loss=0.014629210694693029
Online_Training [285/700]: mean_loss=0.026157704181969166
Online_Training [286/700]: mean_loss=0.023482628632336855
Online_Training [287/700]: mean_loss=0.016686119604855776
Online_Training [288/700]: mean_loss=0.013929886976256967
Online_Training [289/700]: mean_loss=0.047911816742271185
Online_Training [290/700]: mean_loss=0.008090164104942232
Online_Training [291/700]: mean_loss=0.011934011708945036
Online_Training [292/700]: mean_loss=0.0070212604478001595
Online_Training [293/700]: mean_loss=0.01215519558172673
Online_Training [294/700]: mean_loss=0.013737179921008646
Online_Training [295/700]: mean_loss=0.03340614680200815
Online_Training [296/700]: mean_loss=0.03516538254916668
Online_Training [297/700]: mean_loss=0.020639019086956978
Online_Training [298/700]: mean_loss=0.014565792982466519
Online_Training [299/700]: mean_loss=0.018062947550788522
Online_Training [300/700]: mean_loss=0.04268905334174633
Online_Training [301/700]: mean_loss=0.012973907752893865
Online_Training [302/700]: mean_loss=0.014010779792442918
Online_Training [303/700]: mean_loss=0.021584967151284218
Online_Training [304/700]: mean_loss=0.009470831719227135
Online_Training [305/700]: mean_loss=0.05369594553485513
Online_Training [306/700]: mean_loss=0.06539033306762576
Online_Training [307/700]: mean_loss=0.07586775720119476
Online_Training [308/700]: mean_loss=0.02647942933253944
Online_Training [309/700]: mean_loss=0.011513566132634878
Online_Training [310/700]: mean_loss=0.007651426247321069
Online_Training [311/700]: mean_loss=0.012027128133922815
Online_Training [312/700]: mean_loss=0.05404366645962
Online_Training [313/700]: mean_loss=0.014743844978511333
Online_Training [314/700]: mean_loss=0.014753709430806339
Online_Training [315/700]: mean_loss=0.009239972685463727
Online_Training [316/700]: mean_loss=0.01618609018623829
Online_Training [317/700]: mean_loss=0.007157808053307235
Online_Training [318/700]: mean_loss=0.02157631772570312
Online_Training [319/700]: mean_loss=0.023322600405663252
Online_Training [320/700]: mean_loss=0.009581060381606221
Online_Training [321/700]: mean_loss=0.026498536113649607
Online_Training [322/700]: mean_loss=0.035488721216097474
Online_Training [323/700]: mean_loss=0.021711361594498158
Online_Training [324/700]: mean_loss=0.02916981908492744
Online_Training [325/700]: mean_loss=0.03020430589094758
Online_Training [326/700]: mean_loss=0.012525770696811378
Online_Training [327/700]: mean_loss=0.02607320831157267
Online_Training [328/700]: mean_loss=0.02262301300652325
Online_Training [329/700]: mean_loss=0.011168306693434715
Online_Training [330/700]: mean_loss=0.027610559249296784
Online_Training [331/700]: mean_loss=0.022219840670004487
Online_Training [332/700]: mean_loss=0.022232025396078825
Online_Training [333/700]: mean_loss=0.011886533116921782
Online_Training [334/700]: mean_loss=0.009058406809344888
Online_Training [335/700]: mean_loss=0.06442124955356121
Online_Training [336/700]: mean_loss=0.06313795736059546
Online_Training [337/700]: mean_loss=0.07669764570891857
Online_Training [338/700]: mean_loss=0.030132601968944073
Online_Training [339/700]: mean_loss=0.012754026101902127
Online_Training [340/700]: mean_loss=0.009624482248909771
Online_Training [341/700]: mean_loss=0.025121062994003296
Online_Training [342/700]: mean_loss=0.04940161760896444
Online_Training [343/700]: mean_loss=0.012687775073572993
Online_Training [344/700]: mean_loss=0.020088937133550644
Online_Training [345/700]: mean_loss=0.035213923547416925
Online_Training [346/700]: mean_loss=0.02239078306593001
Online_Training [347/700]: mean_loss=0.1291829440742731
Online_Training [348/700]: mean_loss=0.019245226634666324
Online_Training [349/700]: mean_loss=0.024082654621452093
Online_Training [350/700]: mean_loss=0.010026414762251079
Online_Training [351/700]: mean_loss=0.010496138012968004
Online_Training [352/700]: mean_loss=0.013190045254305005
Online_Training [353/700]: mean_loss=0.013083017664030194
Online_Training [354/700]: mean_loss=0.023257355438545346
Online_Training [355/700]: mean_loss=0.01459159713704139
Online_Training [356/700]: mean_loss=0.015644161379896104
Online_Training [357/700]: mean_loss=0.08689755573868752
Online_Training [358/700]: mean_loss=0.07438579946756363
Online_Training [359/700]: mean_loss=0.09394460543990135
Online_Training [360/700]: mean_loss=0.026868945686146617
Online_Training [361/700]: mean_loss=0.026424776995554566
Online_Training [362/700]: mean_loss=0.04965377086773515
Online_Training [363/700]: mean_loss=0.017739055212587118
Online_Training [364/700]: mean_loss=0.011565702618099749
Online_Training [365/700]: mean_loss=0.01552742370404303
Online_Training [366/700]: mean_loss=0.03222856856882572
Online_Training [367/700]: mean_loss=0.021638030419126153
Online_Training [368/700]: mean_loss=0.018461002386175096
Online_Training [369/700]: mean_loss=0.01162862335331738
Online_Training [370/700]: mean_loss=0.03701135376468301
Online_Training [371/700]: mean_loss=0.007586148218251765
Online_Training [372/700]: mean_loss=0.020161093678325415
Online_Training [373/700]: mean_loss=0.019054735312238336
Online_Training [374/700]: mean_loss=0.015608388930559158
Online_Training [375/700]: mean_loss=0.017559680389240384
Online_Training [376/700]: mean_loss=0.008273442275822163
Online_Training [377/700]: mean_loss=0.01782268355600536
Online_Training [378/700]: mean_loss=0.014930792502127588
Online_Training [379/700]: mean_loss=0.01933056255802512
Online_Training [380/700]: mean_loss=0.01214777142740786
Online_Training [381/700]: mean_loss=0.02270071837119758
Online_Training [382/700]: mean_loss=0.009087937301956117
Online_Training [383/700]: mean_loss=0.008887974778190255
Online_Training [384/700]: mean_loss=0.12121183052659035
Online_Training [385/700]: mean_loss=0.006664141546934843
Online_Training [386/700]: mean_loss=0.02780971652828157
Online_Training [387/700]: mean_loss=0.01974168955348432
Online_Training [388/700]: mean_loss=0.02321520377881825
Online_Training [389/700]: mean_loss=0.008306157193146646
Online_Training [390/700]: mean_loss=0.020522684790194035
Online_Training [391/700]: mean_loss=0.008011178579181433
Online_Training [392/700]: mean_loss=0.02413385594263673
Online_Training [393/700]: mean_loss=0.016704554669559002
Online_Training [394/700]: mean_loss=0.022945758188143373
Online_Training [395/700]: mean_loss=0.008213203691411763
Online_Training [396/700]: mean_loss=0.021093652583658695
Online_Training [397/700]: mean_loss=0.010667031514458358
Online_Training [398/700]: mean_loss=0.020447069546207786
Online_Training [399/700]: mean_loss=0.020271164132282138
Online_Training [400/700]: mean_loss=0.03118501976132393
Online_Training [401/700]: mean_loss=0.01308726193383336
Online_Training [402/700]: mean_loss=0.012750139576382935
Online_Training [403/700]: mean_loss=0.015475980704650283
Online_Training [404/700]: mean_loss=0.06669054506346583
Online_Training [405/700]: mean_loss=0.0775107559747994
Online_Training [406/700]: mean_loss=0.01663003396242857
Online_Training [407/700]: mean_loss=0.03914014506153762
Online_Training [408/700]: mean_loss=0.021412322064861655
Online_Training [409/700]: mean_loss=0.006652064679656178
Online_Training [410/700]: mean_loss=0.019501337548717856
Online_Training [411/700]: mean_loss=0.023334477562457323
Online_Training [412/700]: mean_loss=0.10621567908674479
Online_Training [413/700]: mean_loss=0.03913359297439456
Online_Training [414/700]: mean_loss=0.04549711477011442
Online_Training [415/700]: mean_loss=0.023958221077919006
Online_Training [416/700]: mean_loss=0.02103063021786511
Online_Training [417/700]: mean_loss=0.061289805453270674
Online_Training [418/700]: mean_loss=0.015298248850740492
Online_Training [419/700]: mean_loss=0.01500626583583653
Online_Training [420/700]: mean_loss=0.050866696052253246
Online_Training [421/700]: mean_loss=0.033533968264237046
Online_Training [422/700]: mean_loss=0.0151926523540169
Online_Training [423/700]: mean_loss=0.03306880500167608
Online_Training [424/700]: mean_loss=0.05807037791237235
Online_Training [425/700]: mean_loss=0.023173239780589938
Online_Training [426/700]: mean_loss=0.01117664878256619
Online_Training [427/700]: mean_loss=0.01628837443422526
Online_Training [428/700]: mean_loss=0.02387982956133783
Online_Training [429/700]: mean_loss=0.013032555696554482
Online_Training [430/700]: mean_loss=0.006548955861944705
Online_Training [431/700]: mean_loss=0.01196798647288233
Online_Training [432/700]: mean_loss=0.07902596984058619
Online_Training [433/700]: mean_loss=0.021593331126496196
Online_Training [434/700]: mean_loss=0.02850486058741808
Online_Training [435/700]: mean_loss=0.026711171958595514
Online_Training [436/700]: mean_loss=0.06666370015591383
Online_Training [437/700]: mean_loss=0.015443239244632423
Online_Training [438/700]: mean_loss=0.11402029171586037
Online_Training [439/700]: mean_loss=0.05077738128602505
Online_Training [440/700]: mean_loss=0.03400102397426963
Online_Training [441/700]: mean_loss=0.04674810543656349
Online_Training [442/700]: mean_loss=0.011311607901006937
Online_Training [443/700]: mean_loss=0.019230554113164544
Online_Training [444/700]: mean_loss=0.01597107492852956
Online_Training [445/700]: mean_loss=0.018783249310217798
Online_Training [446/700]: mean_loss=0.02321783103980124
Online_Training [447/700]: mean_loss=0.011768476339057088
Online_Training [448/700]: mean_loss=0.022032935405150056
Online_Training [449/700]: mean_loss=0.019657503813505173
Online_Training [450/700]: mean_loss=0.027958815451711416
Online_Training [451/700]: mean_loss=0.020301088457927108
Online_Training [452/700]: mean_loss=0.04061197396367788
Online_Training [453/700]: mean_loss=0.06625743629410863
Online_Training [454/700]: mean_loss=0.014739389880560338
Online_Training [455/700]: mean_loss=0.051918551325798035
Online_Training [456/700]: mean_loss=0.008156806812621653
Online_Training [457/700]: mean_loss=0.012189132743515074
Online_Training [458/700]: mean_loss=0.007824208994861692
Online_Training [459/700]: mean_loss=0.012200449127703905
Online_Training [460/700]: mean_loss=0.0178097520256415
Online_Training [461/700]: mean_loss=0.023903333581984043
Online_Training [462/700]: mean_loss=0.01595271797850728
Online_Training [463/700]: mean_loss=0.005853125767316669
Online_Training [464/700]: mean_loss=0.014839398674666882
Online_Training [465/700]: mean_loss=0.06651057582348585
Online_Training [466/700]: mean_loss=0.01887519145384431
Online_Training [467/700]: mean_loss=0.017201710026711226
Online_Training [468/700]: mean_loss=0.01730496610980481
Online_Training [469/700]: mean_loss=0.022175501566380262
Online_Training [470/700]: mean_loss=0.06086145294830203
Online_Training [471/700]: mean_loss=0.021480205468833447
Online_Training [472/700]: mean_loss=0.03178240335546434
Online_Training [473/700]: mean_loss=0.006638813531026244
Online_Training [474/700]: mean_loss=0.009638981544412673
Online_Training [475/700]: mean_loss=0.010377867962233722
Online_Training [476/700]: mean_loss=0.2034214287996292
Online_Training [477/700]: mean_loss=0.09001677390187979
Online_Training [478/700]: mean_loss=0.0420332420617342
Online_Training [479/700]: mean_loss=0.015524260932579637
Online_Training [480/700]: mean_loss=0.011612826609052718
Online_Training [481/700]: mean_loss=0.016624921699985862
Online_Training [482/700]: mean_loss=0.026335136499255896
Online_Training [483/700]: mean_loss=0.017668724060058594
Online_Training [484/700]: mean_loss=0.01639651448931545
Online_Training [485/700]: mean_loss=0.008695563767105341
Online_Training [486/700]: mean_loss=0.01791930804029107
Online_Training [487/700]: mean_loss=0.03343721432611346
Online_Training [488/700]: mean_loss=0.01949753682129085
Online_Training [489/700]: mean_loss=0.016632057377137244
Online_Training [490/700]: mean_loss=0.018950705183669925
Online_Training [491/700]: mean_loss=0.03573198616504669
Online_Training [492/700]: mean_loss=0.01631377183366567
Online_Training [493/700]: mean_loss=0.01865899912081659
Online_Training [494/700]: mean_loss=0.055279165506362915
Online_Training [495/700]: mean_loss=0.00789523107232526
Online_Training [496/700]: mean_loss=0.03620734065771103
Online_Training [497/700]: mean_loss=0.020909178187139332
Online_Training [498/700]: mean_loss=0.017124708625487983
Online_Training [499/700]: mean_loss=0.018908658996224403
Online_Training [500/700]: mean_loss=0.009853528928942978
Online_Training [501/700]: mean_loss=0.013556626159697771
Online_Training [502/700]: mean_loss=0.015712005668319762
Online_Training [503/700]: mean_loss=0.013431247672997415
Online_Training [504/700]: mean_loss=0.009591530309990048
Online_Training [505/700]: mean_loss=0.015429836697876453
Online_Training [506/700]: mean_loss=0.12301941867917776
Online_Training [507/700]: mean_loss=0.0815385626628995
Online_Training [508/700]: mean_loss=0.036145979538559914
Online_Training [509/700]: mean_loss=0.0177816724171862
Online_Training [510/700]: mean_loss=0.02166915824636817
Online_Training [511/700]: mean_loss=0.005902061588130891
Online_Training [512/700]: mean_loss=0.008435112365987152
Online_Training [513/700]: mean_loss=0.033277658047154546
Online_Training [514/700]: mean_loss=0.0237674864474684
Online_Training [515/700]: mean_loss=0.03412852226756513
Online_Training [516/700]: mean_loss=0.018116935854777694
Online_Training [517/700]: mean_loss=0.030130540719255805
Online_Training [518/700]: mean_loss=0.02256783447228372
Online_Training [519/700]: mean_loss=0.007548434427008033
Online_Training [520/700]: mean_loss=0.012908878503367305
Online_Training [521/700]: mean_loss=0.03239228134043515
Online_Training [522/700]: mean_loss=0.012271229177713394
Online_Training [523/700]: mean_loss=0.02393686189316213
Online_Training [524/700]: mean_loss=0.07594728656113148
Online_Training [525/700]: mean_loss=0.02471124823205173
Online_Training [526/700]: mean_loss=0.012197368661873043
Online_Training [527/700]: mean_loss=0.014404327259398997
Online_Training [528/700]: mean_loss=0.0226972836535424
Online_Training [529/700]: mean_loss=0.027921988628804684
Online_Training [530/700]: mean_loss=0.017686363658867776
Online_Training [531/700]: mean_loss=0.017780350637622178
Online_Training [532/700]: mean_loss=0.027788342209532857
Online_Training [533/700]: mean_loss=0.009521447354927659
Online_Training [534/700]: mean_loss=0.013870020280592144
Online_Training [535/700]: mean_loss=0.02439614851027727
Online_Training [536/700]: mean_loss=0.10421899054199457
Online_Training [537/700]: mean_loss=0.008552594750653952
Online_Training [538/700]: mean_loss=0.012882630457170308
Online_Training [539/700]: mean_loss=0.0066503044799901545
Online_Training [540/700]: mean_loss=0.029177549062296748
Online_Training [541/700]: mean_loss=0.11075878888368607
Online_Training [542/700]: mean_loss=0.007240315666422248
Online_Training [543/700]: mean_loss=0.03629815112799406
Online_Training [544/700]: mean_loss=0.01184752571862191
Online_Training [545/700]: mean_loss=0.025013878475874662
Online_Training [546/700]: mean_loss=0.008626381284557283
Online_Training [547/700]: mean_loss=0.021176693961024284
Online_Training [548/700]: mean_loss=0.024642550153657794
Online_Training [549/700]: mean_loss=0.007202698790933937
Online_Training [550/700]: mean_loss=0.02035404392518103
Online_Training [551/700]: mean_loss=0.024815230863168836
Online_Training [552/700]: mean_loss=0.028198827989399433
Online_Training [553/700]: mean_loss=0.03582399990409613
Online_Training [554/700]: mean_loss=0.018338807625696063
Online_Training [555/700]: mean_loss=0.029924490256235003
Online_Training [556/700]: mean_loss=0.01548241195268929
Online_Training [557/700]: mean_loss=0.012613128055818379
Online_Training [558/700]: mean_loss=0.007386506127659231
Online_Training [559/700]: mean_loss=0.002928850444732234
Online_Training [560/700]: mean_loss=0.008808902464807034
Online_Training [561/700]: mean_loss=0.01710509741678834
Online_Training [562/700]: mean_loss=0.03591229906305671
Online_Training [563/700]: mean_loss=0.03761105751618743
Online_Training [564/700]: mean_loss=0.011292581097222865
Online_Training [565/700]: mean_loss=0.019250165671110153
Online_Training [566/700]: mean_loss=0.020107935182750225
Online_Training [567/700]: mean_loss=0.026502017863094807
Online_Training [568/700]: mean_loss=0.01882523437961936
Online_Training [569/700]: mean_loss=0.024311058688908815
Online_Training [570/700]: mean_loss=0.012484383536502719
Online_Training [571/700]: mean_loss=0.024804523214697838
Online_Training [572/700]: mean_loss=0.018810462672263384
Online_Training [573/700]: mean_loss=0.025622199755162
Online_Training [574/700]: mean_loss=0.05365638807415962
Online_Training [575/700]: mean_loss=0.05619670730084181
Online_Training [576/700]: mean_loss=0.010604081442579627
Online_Training [577/700]: mean_loss=0.015772038837894797
Online_Training [578/700]: mean_loss=0.008126299595460296
Online_Training [579/700]: mean_loss=0.017412618384696543
Online_Training [580/700]: mean_loss=0.03153431904502213
Online_Training [581/700]: mean_loss=0.024396631168201566
Online_Training [582/700]: mean_loss=0.012208240397740155
Online_Training [583/700]: mean_loss=0.00645949540194124
Online_Training [584/700]: mean_loss=0.01591006841044873
Online_Training [585/700]: mean_loss=0.02475086599588394
Online_Training [586/700]: mean_loss=0.09923305083066225
Online_Training [587/700]: mean_loss=0.023879018612205982
Online_Training [588/700]: mean_loss=0.008202152617741376
Online_Training [589/700]: mean_loss=0.02643480245023966
Online_Training [590/700]: mean_loss=0.02257016906514764
Online_Training [591/700]: mean_loss=0.013128283550031483
Online_Training [592/700]: mean_loss=0.014075905899517238
Online_Training [593/700]: mean_loss=0.039945950265973806
Online_Training [594/700]: mean_loss=0.015402478049509227
Online_Training [595/700]: mean_loss=0.03396534058265388
Online_Training [596/700]: mean_loss=0.011501980246976018
Online_Training [597/700]: mean_loss=0.010010278900153935
Online_Training [598/700]: mean_loss=0.01773349626455456
Online_Training [599/700]: mean_loss=0.018094252445735037
Online_Training [600/700]: mean_loss=0.014328210847452283
Online_Training [601/700]: mean_loss=0.03245261590927839
Online_Training [602/700]: mean_loss=0.00926149683073163
Online_Training [603/700]: mean_loss=0.007597128569614142
Online_Training [604/700]: mean_loss=0.026628959458321333
Online_Training [605/700]: mean_loss=0.010031871614046395
Online_Training [606/700]: mean_loss=0.006438651354983449
Online_Training [607/700]: mean_loss=0.009502336382865906
Online_Training [608/700]: mean_loss=0.01722300425171852
Online_Training [609/700]: mean_loss=0.013790147611871362
Online_Training [610/700]: mean_loss=0.01780821557622403
Online_Training [611/700]: mean_loss=0.010369778028689325
Online_Training [612/700]: mean_loss=0.1394885741174221
Online_Training [613/700]: mean_loss=0.05710777919739485
Online_Training [614/700]: mean_loss=0.01356236799620092
Online_Training [615/700]: mean_loss=0.01308447029441595
Online_Training [616/700]: mean_loss=0.025215464644134045
Online_Training [617/700]: mean_loss=0.0055081346072256565
Online_Training [618/700]: mean_loss=0.02394719491712749
Online_Training [619/700]: mean_loss=0.016705048154108226
Online_Training [620/700]: mean_loss=0.0641467859968543
Online_Training [621/700]: mean_loss=0.007281615922693163
Online_Training [622/700]: mean_loss=0.05571357998996973
Online_Training [623/700]: mean_loss=0.03427407331764698
Online_Training [624/700]: mean_loss=0.015432425891049206
Online_Training [625/700]: mean_loss=0.014723463798873127
Online_Training [626/700]: mean_loss=0.008454706752672791
Online_Training [627/700]: mean_loss=0.008210942731238902
Online_Training [628/700]: mean_loss=0.009287943714298308
Online_Training [629/700]: mean_loss=0.02747785532847047
Online_Training [630/700]: mean_loss=0.044558074325323105
Online_Training [631/700]: mean_loss=0.013552992139011621
Online_Training [632/700]: mean_loss=0.024864561855793
Online_Training [633/700]: mean_loss=0.011455238505732268
Online_Training [634/700]: mean_loss=0.01543050177861005
Online_Training [635/700]: mean_loss=0.01766146020963788
Online_Training [636/700]: mean_loss=0.006377164274454117
Online_Training [637/700]: mean_loss=0.012374469777569175
Online_Training [638/700]: mean_loss=0.028362598968669772
Online_Training [639/700]: mean_loss=0.021320429863408208
Online_Training [640/700]: mean_loss=0.010581387323327363
Online_Training [641/700]: mean_loss=0.027377649443224072
Online_Training [642/700]: mean_loss=0.010493292706087232
Online_Training [643/700]: mean_loss=0.008576251508202404
Online_Training [644/700]: mean_loss=0.0084765306673944
Online_Training [645/700]: mean_loss=0.016456759301945567
Online_Training [646/700]: mean_loss=0.040533195016905665
Online_Training [647/700]: mean_loss=0.011820234009064734
Online_Training [648/700]: mean_loss=0.011133327730931342
Online_Training [649/700]: mean_loss=0.009876683703623712
Online_Training [650/700]: mean_loss=0.014260080526582897
Online_Training [651/700]: mean_loss=0.007713795464951545
Online_Training [652/700]: mean_loss=0.007038445968646556
Online_Training [653/700]: mean_loss=0.1038539307191968
Online_Training [654/700]: mean_loss=0.01595357561018318
Online_Training [655/700]: mean_loss=0.022688187658786774
Online_Training [656/700]: mean_loss=0.021145056001842022
Online_Training [657/700]: mean_loss=0.01723695534747094
Online_Training [658/700]: mean_loss=0.014448886387981474
Online_Training [659/700]: mean_loss=0.01367563335224986
Online_Training [660/700]: mean_loss=0.013767768046818674
Online_Training [661/700]: mean_loss=0.03935366263613105
Online_Training [662/700]: mean_loss=0.04419375769793987
Online_Training [663/700]: mean_loss=0.020124036818742752
Online_Training [664/700]: mean_loss=0.0055292819160968065
Online_Training [665/700]: mean_loss=0.037710410775616765
Online_Training [666/700]: mean_loss=0.024639290291815996
Online_Training [667/700]: mean_loss=0.006340436229947954
Online_Training [668/700]: mean_loss=0.010230151121504605
Online_Training [669/700]: mean_loss=0.007355451816692948
Online_Training [670/700]: mean_loss=0.012110289302654564
Online_Training [671/700]: mean_loss=0.018599820556119084
Online_Training [672/700]: mean_loss=0.011189965181984007
Online_Training [673/700]: mean_loss=0.012493627960793674
Online_Training [674/700]: mean_loss=0.012901600683107972
Online_Training [675/700]: mean_loss=0.01303756923880428
Online_Training [676/700]: mean_loss=0.03306548041291535
Online_Training [677/700]: mean_loss=0.047987985890358686
Online_Training [678/700]: mean_loss=0.020807209191843867
Online_Training [679/700]: mean_loss=0.020467367488890886
Online_Training [680/700]: mean_loss=0.012890233658254147
Online_Training [681/700]: mean_loss=0.020417322171851993
Online_Training [682/700]: mean_loss=0.012384382425807416
Online_Training [683/700]: mean_loss=0.007340659969486296
Online_Training [684/700]: mean_loss=0.007038878102321178
Online_Training [685/700]: mean_loss=0.026834771037101746
Online_Training [686/700]: mean_loss=0.010812823311425745
Online_Training [687/700]: mean_loss=0.015830522519536316
Online_Training [688/700]: mean_loss=0.05475613847374916
Online_Training [689/700]: mean_loss=0.014288208330981433
Online_Training [690/700]: mean_loss=0.005603520548902452
Online_Training [691/700]: mean_loss=0.012365880538709462
Online_Training [692/700]: mean_loss=0.02339031919836998
Online_Training [693/700]: mean_loss=0.012874326901510358
Online_Training [694/700]: mean_loss=0.033324874471873045
Online_Training [695/700]: mean_loss=0.012547143502160907
Online_Training [696/700]: mean_loss=0.03284565079957247
Online_Training [697/700]: mean_loss=0.004814890678972006
Online_Training [698/700]: mean_loss=0.006064926506951451
Online_Training [699/700]: mean_loss=0.05925068072974682
Online_Training [700/700]: mean_loss=0.006381001614499837
Q_Learning [1/300]: mean_loss=0.16767941415309906
Q_Learning [2/300]: mean_loss=0.2525527570396662
Q_Learning [3/300]: mean_loss=0.19892032071948051
Q_Learning [4/300]: mean_loss=0.05118644190952182
Q_Learning [5/300]: mean_loss=0.25652807392179966
Q_Learning [6/300]: mean_loss=0.08748406171798706
Q_Learning [7/300]: mean_loss=0.12779228575527668
Q_Learning [8/300]: mean_loss=0.07619846425950527
Q_Learning [9/300]: mean_loss=0.20840296521782875
Q_Learning [10/300]: mean_loss=0.15208757296204567
Q_Learning [11/300]: mean_loss=0.07334634847939014
Q_Learning [12/300]: mean_loss=0.06850581429898739
Q_Learning [13/300]: mean_loss=0.0966894868761301
Q_Learning [14/300]: mean_loss=0.07523268926888704
Q_Learning [15/300]: mean_loss=0.057592031080275774
Q_Learning [16/300]: mean_loss=0.141929991543293
Q_Learning [17/300]: mean_loss=0.15038487873971462
Q_Learning [18/300]: mean_loss=0.10122577752918005
Q_Learning [19/300]: mean_loss=0.02469629584811628
Q_Learning [20/300]: mean_loss=0.20412708446383476
Q_Learning [21/300]: mean_loss=0.1348206428810954
Q_Learning [22/300]: mean_loss=0.05091307684779167
Q_Learning [23/300]: mean_loss=0.022093955660238862
Q_Learning [24/300]: mean_loss=0.10470474325120449
Q_Learning [25/300]: mean_loss=0.04841448413208127
Q_Learning [26/300]: mean_loss=0.0765892444178462
Q_Learning [27/300]: mean_loss=0.1025556679815054
Q_Learning [28/300]: mean_loss=0.05096859531477094
Q_Learning [29/300]: mean_loss=0.050845460034906864
Q_Learning [30/300]: mean_loss=0.030646330444142222
Q_Learning [31/300]: mean_loss=0.030585983535274863
Q_Learning [32/300]: mean_loss=0.04833456547930837
Q_Learning [33/300]: mean_loss=0.02288719406351447
Q_Learning [34/300]: mean_loss=0.20195152051746845
Q_Learning [35/300]: mean_loss=0.06444211257621646
Q_Learning [36/300]: mean_loss=0.08650117181241512
Q_Learning [37/300]: mean_loss=0.06709120329469442
Q_Learning [38/300]: mean_loss=0.03900466999039054
Q_Learning [39/300]: mean_loss=0.1383739449083805
Q_Learning [40/300]: mean_loss=0.02807305916212499
Q_Learning [41/300]: mean_loss=0.03403385542333126
Q_Learning [42/300]: mean_loss=0.05864075664430857
Q_Learning [43/300]: mean_loss=0.13186920247972012
Q_Learning [44/300]: mean_loss=0.15288249775767326
Q_Learning [45/300]: mean_loss=0.0983422938734293
Q_Learning [46/300]: mean_loss=0.06526533095166087
Q_Learning [47/300]: mean_loss=0.10400635376572609
Q_Learning [48/300]: mean_loss=0.07381646055728197
Q_Learning [49/300]: mean_loss=0.09107325412333012
Q_Learning [50/300]: mean_loss=0.10598633531481028
Q_Learning [51/300]: mean_loss=0.03428327385336161
Q_Learning [52/300]: mean_loss=0.167131919413805
Q_Learning [53/300]: mean_loss=0.03535336162894964
Q_Learning [54/300]: mean_loss=0.09123489074409008
Q_Learning [55/300]: mean_loss=0.07170522678643465
Q_Learning [56/300]: mean_loss=0.0397677356377244
Q_Learning [57/300]: mean_loss=0.10033018235117197
Q_Learning [58/300]: mean_loss=0.2762283105403185
Q_Learning [59/300]: mean_loss=0.09569341456517577
Q_Learning [60/300]: mean_loss=0.05831606639549136
Q_Learning [61/300]: mean_loss=0.0497137145139277
Q_Learning [62/300]: mean_loss=0.10183988139033318
Q_Learning [63/300]: mean_loss=0.07140860985964537
Q_Learning [64/300]: mean_loss=0.006749207794200629
Q_Learning [65/300]: mean_loss=0.06866688095033169
Q_Learning [66/300]: mean_loss=0.04247738840058446
Q_Learning [67/300]: mean_loss=0.05947238113731146
Q_Learning [68/300]: mean_loss=0.03789705829694867
Q_Learning [69/300]: mean_loss=0.07424865709617734
Q_Learning [70/300]: mean_loss=0.03572019236162305
Q_Learning [71/300]: mean_loss=0.07472446095198393
Q_Learning [72/300]: mean_loss=0.08771421201527119
Q_Learning [73/300]: mean_loss=0.043987888377159834
Q_Learning [74/300]: mean_loss=0.04434369783848524
Q_Learning [75/300]: mean_loss=0.028968256898224354
Q_Learning [76/300]: mean_loss=0.025883557507768273
Q_Learning [77/300]: mean_loss=0.039246165193617344
Q_Learning [78/300]: mean_loss=0.028385073179379106
Q_Learning [79/300]: mean_loss=0.03958803368732333
Q_Learning [80/300]: mean_loss=0.03908867575228214
Q_Learning [81/300]: mean_loss=0.02171849342994392
Q_Learning [82/300]: mean_loss=0.026600241661071777
Q_Learning [83/300]: mean_loss=0.044341875705868006
Q_Learning [84/300]: mean_loss=0.030466527678072453
Q_Learning [85/300]: mean_loss=0.022956233704462647
Q_Learning [86/300]: mean_loss=0.04214702732861042
Q_Learning [87/300]: mean_loss=0.016376143787056208
Q_Learning [88/300]: mean_loss=0.032593403942883015
Q_Learning [89/300]: mean_loss=0.044751403853297234
Q_Learning [90/300]: mean_loss=0.018512542359530926
Q_Learning [91/300]: mean_loss=0.037049475125968456
Q_Learning [92/300]: mean_loss=0.04159840429201722
Q_Learning [93/300]: mean_loss=0.03169418149627745
Q_Learning [94/300]: mean_loss=0.04214531555771828
Q_Learning [95/300]: mean_loss=0.03715119743719697
Q_Learning [96/300]: mean_loss=0.027520400239154696
Q_Learning [97/300]: mean_loss=0.046101582236588
Q_Learning [98/300]: mean_loss=0.04546803794801235
Q_Learning [99/300]: mean_loss=0.024538113735616207
Q_Learning [100/300]: mean_loss=0.03225297946482897
Q_Learning [101/300]: mean_loss=0.018704727408476174
Q_Learning [102/300]: mean_loss=0.06212617643177509
Q_Learning [103/300]: mean_loss=0.047351621091365814
Q_Learning [104/300]: mean_loss=0.0402820217423141
Q_Learning [105/300]: mean_loss=0.04051725286990404
Q_Learning [106/300]: mean_loss=0.01737536513246596
Q_Learning [107/300]: mean_loss=0.015253418823704123
Q_Learning [108/300]: mean_loss=0.029533915920183063
Q_Learning [109/300]: mean_loss=0.032219783402979374
Q_Learning [110/300]: mean_loss=0.023099510231986642
Q_Learning [111/300]: mean_loss=0.03160112886689603
Q_Learning [112/300]: mean_loss=0.1585959829390049
Q_Learning [113/300]: mean_loss=0.0208583720959723
Q_Learning [114/300]: mean_loss=0.04315149551257491
Q_Learning [115/300]: mean_loss=0.04997291974723339
Q_Learning [116/300]: mean_loss=0.026601363206282258
Q_Learning [117/300]: mean_loss=0.05391644034534693
Q_Learning [118/300]: mean_loss=0.0578894317150116
Q_Learning [119/300]: mean_loss=0.13585772551596165
Q_Learning [120/300]: mean_loss=0.05354923428967595
Q_Learning [121/300]: mean_loss=0.07135710027068853
Q_Learning [122/300]: mean_loss=0.06839521694928408
Q_Learning [123/300]: mean_loss=0.03279491770081222
Q_Learning [124/300]: mean_loss=0.013673516688868403
Q_Learning [125/300]: mean_loss=0.0716541176661849
Q_Learning [126/300]: mean_loss=0.05619382578879595
Q_Learning [127/300]: mean_loss=0.057969927322119474
Q_Learning [128/300]: mean_loss=0.03059490188024938
Q_Learning [129/300]: mean_loss=0.03199411160312593
Q_Learning [130/300]: mean_loss=0.020673343911767006
Q_Learning [131/300]: mean_loss=0.029969785828143358
Q_Learning [132/300]: mean_loss=0.021096612326800823
Q_Learning [133/300]: mean_loss=0.03044978016987443
Q_Learning [134/300]: mean_loss=0.025176036404445767
Q_Learning [135/300]: mean_loss=0.11750830989331007
Q_Learning [136/300]: mean_loss=0.026694151107221842
Q_Learning [137/300]: mean_loss=0.023933528922498226
Q_Learning [138/300]: mean_loss=0.011866227025166154
Q_Learning [139/300]: mean_loss=0.016322256880812347
Q_Learning [140/300]: mean_loss=0.03631044877693057
Q_Learning [141/300]: mean_loss=0.04940740345045924
Q_Learning [142/300]: mean_loss=0.015363978105597198
Q_Learning [143/300]: mean_loss=0.021879390347748995
Q_Learning [144/300]: mean_loss=0.011303361738100648
Q_Learning [145/300]: mean_loss=0.05922147538512945
Q_Learning [146/300]: mean_loss=0.019376428797841072
Q_Learning [147/300]: mean_loss=0.015971494605764747
Q_Learning [148/300]: mean_loss=0.043265055399388075
Q_Learning [149/300]: mean_loss=0.08805521205067635
Q_Learning [150/300]: mean_loss=0.08529537077993155
Q_Learning [151/300]: mean_loss=0.03069941815920174
Q_Learning [152/300]: mean_loss=0.018079542787745595
Q_Learning [153/300]: mean_loss=0.05227159708738327
Q_Learning [154/300]: mean_loss=0.03167220717296004
Q_Learning [155/300]: mean_loss=0.013083969475701451
Q_Learning [156/300]: mean_loss=0.019947135355323553
Q_Learning [157/300]: mean_loss=0.15144294314086437
Q_Learning [158/300]: mean_loss=0.010532656393479556
Q_Learning [159/300]: mean_loss=0.024555601878091693
Q_Learning [160/300]: mean_loss=0.032971448730677366
Q_Learning [161/300]: mean_loss=0.035486210603266954
Q_Learning [162/300]: mean_loss=0.018448020331561565
Q_Learning [163/300]: mean_loss=0.059786890633404255
Q_Learning [164/300]: mean_loss=0.017157360911369324
Q_Learning [165/300]: mean_loss=0.012435596669092774
Q_Learning [166/300]: mean_loss=0.024058169219642878
Q_Learning [167/300]: mean_loss=0.04368317453190684
Q_Learning [168/300]: mean_loss=0.030269595328718424
Q_Learning [169/300]: mean_loss=0.05616039875894785
Q_Learning [170/300]: mean_loss=0.15758317150175571
Q_Learning [171/300]: mean_loss=0.019820969318971038
Q_Learning [172/300]: mean_loss=0.01593095320276916
Q_Learning [173/300]: mean_loss=0.020225062733516097
Q_Learning [174/300]: mean_loss=0.011418529087677598
Q_Learning [175/300]: mean_loss=0.009467296418733895
Q_Learning [176/300]: mean_loss=0.006335594167467207
Q_Learning [177/300]: mean_loss=0.029461831785738468
Q_Learning [178/300]: mean_loss=0.040641479194164276
Q_Learning [179/300]: mean_loss=0.022376294480636716
Q_Learning [180/300]: mean_loss=0.026267794892191887
Q_Learning [181/300]: mean_loss=0.030197279527783394
Q_Learning [182/300]: mean_loss=0.03582537779584527
Q_Learning [183/300]: mean_loss=0.01328871923033148
Q_Learning [184/300]: mean_loss=0.006150714179966599
Q_Learning [185/300]: mean_loss=0.03156304662115872
Q_Learning [186/300]: mean_loss=0.03369142999872565
Q_Learning [187/300]: mean_loss=0.031261180993169546
Q_Learning [188/300]: mean_loss=0.02472492214292288
Q_Learning [189/300]: mean_loss=0.05755135789513588
Q_Learning [190/300]: mean_loss=0.02411077660508454
Q_Learning [191/300]: mean_loss=0.14270148240029812
Q_Learning [192/300]: mean_loss=0.025294417748227715
Q_Learning [193/300]: mean_loss=0.020812558010220528
Q_Learning [194/300]: mean_loss=0.018870123545639217
Q_Learning [195/300]: mean_loss=0.028394110267981887
Q_Learning [196/300]: mean_loss=0.013232410070486367
Q_Learning [197/300]: mean_loss=0.04289010865613818
Q_Learning [198/300]: mean_loss=0.01671628304757178
Q_Learning [199/300]: mean_loss=0.0877845287322998
Q_Learning [200/300]: mean_loss=0.021954687777906656
Q_Learning [201/300]: mean_loss=0.03067483939230442
Q_Learning [202/300]: mean_loss=0.015465319971553981
Q_Learning [203/300]: mean_loss=0.011333215050399303
Q_Learning [204/300]: mean_loss=0.01336680247914046
Q_Learning [205/300]: mean_loss=0.07817583903670311
Q_Learning [206/300]: mean_loss=0.014339196495711803
Q_Learning [207/300]: mean_loss=0.05290806479752064
Q_Learning [208/300]: mean_loss=0.050388853531330824
Q_Learning [209/300]: mean_loss=0.05429717293009162
Q_Learning [210/300]: mean_loss=0.02822081884369254
Q_Learning [211/300]: mean_loss=0.022839501267299056
Q_Learning [212/300]: mean_loss=0.07981435488909483
Q_Learning [213/300]: mean_loss=0.0451137232594192
Q_Learning [214/300]: mean_loss=0.01579299313016236
Q_Learning [215/300]: mean_loss=0.03759302245453
Q_Learning [216/300]: mean_loss=0.03773865452967584
Q_Learning [217/300]: mean_loss=0.02953249216079712
Q_Learning [218/300]: mean_loss=0.007684728712774813
Q_Learning [219/300]: mean_loss=0.04803106049075723
Q_Learning [220/300]: mean_loss=0.014901102636940777
Q_Learning [221/300]: mean_loss=0.030173328006640077
Q_Learning [222/300]: mean_loss=0.02116317767649889
Q_Learning [223/300]: mean_loss=0.03141875704750419
Q_Learning [224/300]: mean_loss=0.006593075522687286
Q_Learning [225/300]: mean_loss=0.031077917432412505
Q_Learning [226/300]: mean_loss=0.030660692835226655
Q_Learning [227/300]: mean_loss=0.01721055875532329
Q_Learning [228/300]: mean_loss=0.02309716632589698
Q_Learning [229/300]: mean_loss=0.0503082275390625
Q_Learning [230/300]: mean_loss=0.022261594189330935
Q_Learning [231/300]: mean_loss=0.023041311418637633
Q_Learning [232/300]: mean_loss=0.02506712288595736
Q_Learning [233/300]: mean_loss=0.021252745296806097
Q_Learning [234/300]: mean_loss=0.04253956861793995
Q_Learning [235/300]: mean_loss=0.09654315561056137
Q_Learning [236/300]: mean_loss=0.07034066086634994
Q_Learning [237/300]: mean_loss=0.02438789210282266
Q_Learning [238/300]: mean_loss=0.12161505687981844
Q_Learning [239/300]: mean_loss=0.07044818764552474
Q_Learning [240/300]: mean_loss=0.04868696443736553
Q_Learning [241/300]: mean_loss=0.03718715952709317
Q_Learning [242/300]: mean_loss=0.04004319431260228
Q_Learning [243/300]: mean_loss=0.044368688482791185
Q_Learning [244/300]: mean_loss=0.03581628343090415
Q_Learning [245/300]: mean_loss=0.04777240287512541
Q_Learning [246/300]: mean_loss=0.028429866768419743
Q_Learning [247/300]: mean_loss=0.010656303726136684
Q_Learning [248/300]: mean_loss=0.07849946804344654
Q_Learning [249/300]: mean_loss=0.012692419230006635
Q_Learning [250/300]: mean_loss=0.01910597598180175
Q_Learning [251/300]: mean_loss=0.018939751433208585
Q_Learning [252/300]: mean_loss=0.019248427590355277
Q_Learning [253/300]: mean_loss=0.018487469060346484
Q_Learning [254/300]: mean_loss=0.016762332757934928
Q_Learning [255/300]: mean_loss=0.03099772147834301
Q_Learning [256/300]: mean_loss=0.016804668470285833
Q_Learning [257/300]: mean_loss=0.017038285615853965
Q_Learning [258/300]: mean_loss=0.02004067017696798
Q_Learning [259/300]: mean_loss=0.01100732700433582
Q_Learning [260/300]: mean_loss=0.009096913738176227
Q_Learning [261/300]: mean_loss=0.02396587748080492
Q_Learning [262/300]: mean_loss=0.03227770538069308
Q_Learning [263/300]: mean_loss=0.011947444756515324
Q_Learning [264/300]: mean_loss=0.023774762405082583
Q_Learning [265/300]: mean_loss=0.0183378248475492
Q_Learning [266/300]: mean_loss=0.012583497329615057
Q_Learning [267/300]: mean_loss=0.011018565972335637
Q_Learning [268/300]: mean_loss=0.007884489081334323
Q_Learning [269/300]: mean_loss=0.016019031638279557
Q_Learning [270/300]: mean_loss=0.009119327762164176
Q_Learning [271/300]: mean_loss=0.024925771402195096
Q_Learning [272/300]: mean_loss=0.007762540597468615
Q_Learning [273/300]: mean_loss=0.01042108389083296
Q_Learning [274/300]: mean_loss=0.011848631780594587
Q_Learning [275/300]: mean_loss=0.01348615635652095
Q_Learning [276/300]: mean_loss=0.014125259011052549
Q_Learning [277/300]: mean_loss=0.028909737477079034
Q_Learning [278/300]: mean_loss=0.02246027742512524
Q_Learning [279/300]: mean_loss=0.01838568225502968
Q_Learning [280/300]: mean_loss=0.023738668533042073
Q_Learning [281/300]: mean_loss=0.019834698643535376
Q_Learning [282/300]: mean_loss=0.03252821136265993
Q_Learning [283/300]: mean_loss=0.025497639551758766
Q_Learning [284/300]: mean_loss=0.014629210694693029
Q_Learning [285/300]: mean_loss=0.026157704181969166
Q_Learning [286/300]: mean_loss=0.023482628632336855
Q_Learning [287/300]: mean_loss=0.016686119604855776
Q_Learning [288/300]: mean_loss=0.013929886976256967
Q_Learning [289/300]: mean_loss=0.047911816742271185
Q_Learning [290/300]: mean_loss=0.008090164104942232
Q_Learning [291/300]: mean_loss=0.011934011708945036
Q_Learning [292/300]: mean_loss=0.0070212604478001595
Q_Learning [293/300]: mean_loss=0.01215519558172673
Q_Learning [294/300]: mean_loss=0.013737179921008646
Q_Learning [295/300]: mean_loss=0.03340614680200815
Q_Learning [296/300]: mean_loss=0.03516538254916668
Q_Learning [297/300]: mean_loss=0.020639019086956978
Q_Learning [298/300]: mean_loss=0.014565792982466519
Q_Learning [299/300]: mean_loss=0.018062947550788522
Q_Learning [300/300]: mean_loss=0.04268905334174633
Number of Samples after Autoencoder testing: 300
First Spike after testing: [0.5455427 1.6421573]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 2, 2, 0, 1, 1, 1, 0, 3, 2, 1, 1, 1, 2, 0, 0, 1, 0, 1, 3, 1, 0, 0, 1, 2, 1, 0, 1, 2, 3, 2, 1, 0, 2, 1, 1, 0, 3, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 0, 2, 0, 0, 0, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 2, 1, 2, 0, 2, 2, 1, 2, 0, 2, 0, 0, 2, 2, 2, 1, 3, 2, 1, 0, 2, 1, 0, 2, 1, 2, 0, 3, 0, 1, 2, 3, 1, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 3, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 0, 1, 0, 0, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 2, 2, 0, 0, 1, 3, 0, 2, 0, 1, 0, 1, 0, 1, 2, 0, 2, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 2, 0, 0, 3, 2, 0, 0, 1, 1, 2, 1, 0, 0, 1, 1, 2, 0, 1, 1, 0, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 2, 2, 0, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3, 0, 1, 2, 3, 0, 0, 1, 2, 2, 0, 2, 1, 0, 3, 1, 2, 2, 1, 1, 2, 0, 0, 1, 1, 2, 1, 2]
Centroids: [[-1.2937026, -0.61940485], [-0.42804566, -0.115801714], [0.56024635, 1.6004999]]
Centroids: [[0.6908215, 1.4667673], [-0.40293497, -0.2483619], [-1.4591279, -0.51918566], [-0.048616387, 2.3310862]]
Contingency Matrix: 
[[ 0 27 76  0]
 [ 0 87 13  0]
 [80  1  0 16]]
[[0, 27, 76, 0], [0, 87, 13, 0], [80, 1, 0, 16]]
[[0, 27, 76, 0], [0, 87, 13, 0], [80, 1, 0, 16]]
[0, 1, 2, 3]
[[0, -1, 76, 0], [-1, -1, -1, -1], [80, -1, 0, 16]]
[[-1, -1, 76, 0], [-1, -1, -1, -1], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {1: 1, 2: 0, 0: 2}
New Contingency Matrix: 
[[76 27  0  0]
 [13 87  0  0]
 [ 0  1 80 16]]
New Clustered Label Sequence: [2, 1, 0, 3]
Diagonal_Elements: [76, 87, 80], Sum: 243
All_Elements: [76, 27, 0, 0, 13, 87, 0, 0, 0, 1, 80, 16], Sum: 300
Accuracy: 0.81
