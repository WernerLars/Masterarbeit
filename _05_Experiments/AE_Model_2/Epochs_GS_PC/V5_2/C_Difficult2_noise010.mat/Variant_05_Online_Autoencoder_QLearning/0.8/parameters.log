Seed: 0
Experiment_path: Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Epochs_GS_PC//V5_2/C_Difficult2_noise010.mat/Variant_05_Online_Autoencoder_QLearning/0.8
Normalisation: False
Template Matching: False
Optimising Autoencoder: False
Update Factor: 1
Noisy Batches: False
Noisy Factor: 0.001
Epochs: 2
Batch Size: 1
maximal Spikes for Autoencoder Training : 700
maximal Spikes for Training: 1000
Input Size: 47
Chosen Model: Convolutional Autoencoder
ConvolutionalAutoencoder(
  (encoder): Sequential(
    (0): Conv1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Conv1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=37, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose1d(1, 6, kernel_size=(6,), stride=(1,))
    (1): LeakyReLU(negative_slope=0.01)
    (2): ConvTranspose1d(6, 1, kernel_size=(6,), stride=(1,))
    (3): Flatten(start_dim=1, end_dim=-1)
    (4): Linear(in_features=12, out_features=47, bias=True)
  )
)
MSELoss()
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0
)
---Q Learning Parameters---
Normalisation: False
Punishment Coefficient: 0.8
Alpha: 0.8
Epsilon: 0.01
Gamma: 0.97
Initial Episode Number: 0
Episode Number Coefficient: 1.4
Number of Random Features: 20
Planning Number: 20
Max Random Features: 60
New Episode Number: 72
New Episode Number: 143
New Episode Number: 215
New Episode Number: 286
New Episode Number: 358
New Episode Number: 429
New Episode Number: 500
New Episode Number: 572
                0      1     2      3     4      5      6     7      8
new_cluster -5.33 -20.74 -2.76 -35.92 -4.22 -18.95 -44.49 -4.94 -56.25
c1          -5.32 -20.92 -2.75 -37.44 -3.85 -25.89 -44.46 -4.95 -56.24
c2          -5.32 -20.69 -2.68 -35.68 -3.92 -21.91 -44.46 -4.93 -56.25
c3          -5.33 -20.65 -2.76 -36.58 -4.18 -21.59 -44.48 -4.93 -56.28
c4          -5.25 -21.54 -2.78 -37.99 -3.84 -20.33 -44.47 -4.93 -56.24
c5          -5.33 -20.66 -2.76 -36.41 -4.43 -20.14 -44.49 -4.97 -56.24
c6          -5.32 -20.01 -2.74 -37.97 -3.98 -18.90 -44.47 -4.93 -56.24
c7          -5.32 -20.40 -2.79 -35.38 -3.89 -22.20 -44.49 -4.94 -56.28
c8          -5.32 -21.98 -2.77 -36.73 -3.95 -20.41 -44.49 -4.94 -56.25
\begin{tabular}{lrrrrrrrrr}
\toprule
{} &     0 &      1 &     2 &      3 &     4 &      5 &      6 &     7 &      8 \\
\midrule
new\_cluster & -5.33 & -20.74 & -2.76 & -35.92 & -4.22 & -18.95 & -44.49 & -4.94 & -56.25 \\
c1          & -5.32 & -20.92 & -2.75 & -37.44 & -3.85 & -25.89 & -44.46 & -4.95 & -56.24 \\
c2          & -5.32 & -20.69 & -2.68 & -35.68 & -3.92 & -21.91 & -44.46 & -4.93 & -56.25 \\
c3          & -5.33 & -20.65 & -2.76 & -36.58 & -4.18 & -21.59 & -44.48 & -4.93 & -56.28 \\
c4          & -5.25 & -21.54 & -2.78 & -37.99 & -3.84 & -20.33 & -44.47 & -4.93 & -56.24 \\
c5          & -5.33 & -20.66 & -2.76 & -36.41 & -4.43 & -20.14 & -44.49 & -4.97 & -56.24 \\
c6          & -5.32 & -20.01 & -2.74 & -37.97 & -3.98 & -18.90 & -44.47 & -4.93 & -56.24 \\
c7          & -5.32 & -20.40 & -2.79 & -35.38 & -3.89 & -22.20 & -44.49 & -4.94 & -56.28 \\
c8          & -5.32 & -21.98 & -2.77 & -36.73 & -3.95 & -20.41 & -44.49 & -4.94 & -56.25 \\
\bottomrule
\end{tabular}

                                0             1  ...            7             8
new_cluster  [-2.56, new_cluster]  [-18.04, c1]  ...  [-2.22, c7]  [-53.55, c8]
c1           [-2.56, new_cluster]  [-18.24, c1]  ...  [-2.22, c7]  [-53.55, c8]
c2           [-2.56, new_cluster]  [-18.02, c1]  ...  [-2.22, c7]  [-53.55, c8]
c3           [-2.56, new_cluster]  [-17.97, c1]  ...  [-2.22, c7]  [-53.55, c8]
c4           [-2.56, new_cluster]  [-18.87, c1]  ...  [-2.22, c7]  [-53.55, c8]
c5           [-2.56, new_cluster]  [-17.98, c1]  ...  [-2.22, c7]  [-53.55, c8]
c6           [-2.56, new_cluster]  [-17.32, c1]  ...  [-2.22, c7]  [-53.55, c8]
c7           [-2.56, new_cluster]  [-17.72, c1]  ...  [-2.22, c7]  [-53.55, c8]
c8           [-2.56, new_cluster]  [-19.26, c1]  ...  [-2.22, c7]  [-53.55, c8]

[9 rows x 9 columns]
\begin{tabular}{llllllllll}
\toprule
{} &                     0 &             1 &            2 &             3 &            4 &             5 &            6 &            7 &             8 \\
\midrule
new\_cluster &  [-2.56, new\_cluster] &  [-18.04, c1] &  [-0.14, c2] &  [-33.24, c3] &   [-1.5, c4] &  [-16.26, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
c1          &  [-2.56, new\_cluster] &  [-18.24, c1] &  [-0.04, c2] &  [-34.76, c3] &  [-1.16, c4] &   [-23.2, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
c2          &  [-2.56, new\_cluster] &  [-18.02, c1] &  [-0.02, c2] &  [-33.01, c3] &  [-1.22, c4] &  [-19.23, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
c3          &  [-2.56, new\_cluster] &  [-17.97, c1] &  [-0.08, c2] &  [-33.87, c3] &  [-1.48, c4] &   [-18.9, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
c4          &  [-2.56, new\_cluster] &  [-18.87, c1] &  [-0.09, c2] &  [-35.31, c3] &  [-1.14, c4] &  [-17.61, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
c5          &  [-2.56, new\_cluster] &  [-17.98, c1] &  [-0.08, c2] &  [-33.73, c3] &  [-1.71, c4] &  [-17.45, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
c6          &  [-2.56, new\_cluster] &  [-17.32, c1] &  [-0.06, c2] &  [-35.29, c3] &  [-1.26, c4] &  [-16.21, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
c7          &  [-2.56, new\_cluster] &  [-17.72, c1] &   [-0.1, c2] &  [-32.69, c3] &  [-1.19, c4] &  [-19.51, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
c8          &  [-2.56, new\_cluster] &  [-19.26, c1] &  [-0.07, c2] &  [-34.06, c3] &  [-1.24, c4] &  [-17.74, c5] &  [-41.8, c6] &  [-2.22, c7] &  [-53.55, c8] \\
\bottomrule
\end{tabular}

