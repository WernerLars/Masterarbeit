Experiment_path: Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise025.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise025.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Epochs_GS_PC//V5_4/C_Easy1_noise025.mat/Variant_05_Online_Autoencoder_QLearning/0.2
Punishment_Coefficient: 0.2
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001BF13DA66A0>
Sampling rate: 24000.0
Raw: [-0.1861928  -0.15538047 -0.11159897 ... -0.04566289 -0.07495693
 -0.11387027]
Times: [    288     764     962 ... 1439565 1439599 1439750]
Cluster: [2 1 1 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3298
First aligned Spike Frame: [ 0.30343498  0.30504401  0.30003499  0.28306832  0.25612953  0.20234245
  0.11026158  0.00607927 -0.07206812 -0.11511366 -0.12845949 -0.13294027
 -0.18390234 -0.33132976 -0.53531084 -0.64122966 -0.43321471  0.14319913
  0.78508862  1.13178271  1.12964756  0.95557126  0.768731    0.62108183
  0.50039946  0.39401216  0.30447426  0.22854935  0.15922545  0.09984913
  0.06405489  0.05593058  0.05062423  0.00682243 -0.07060307 -0.1367616
 -0.15929316 -0.15555753 -0.15669153 -0.16914157 -0.17192467 -0.15578403
 -0.14071413 -0.14785593 -0.17738608 -0.22110055 -0.28163013]
Cluster 0, Occurrences: 1094
Cluster 1, Occurrences: 1089
Cluster 2, Occurrences: 1115
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.2074219472706318
Online_Training [2/700]: mean_loss=0.2002808339893818
Online_Training [3/700]: mean_loss=0.15988878533244133
Online_Training [4/700]: mean_loss=0.2809447795152664
Online_Training [5/700]: mean_loss=0.1519269421696663
Online_Training [6/700]: mean_loss=0.14807728677988052
Online_Training [7/700]: mean_loss=0.20977990701794624
Online_Training [8/700]: mean_loss=0.10867961682379246
Online_Training [9/700]: mean_loss=0.150334894657135
Online_Training [10/700]: mean_loss=0.12927095592021942
Online_Training [11/700]: mean_loss=0.41191014647483826
Online_Training [12/700]: mean_loss=0.1239196453243494
Online_Training [13/700]: mean_loss=0.20071132108569145
Online_Training [14/700]: mean_loss=0.13051891699433327
Online_Training [15/700]: mean_loss=0.14337200298905373
Online_Training [16/700]: mean_loss=0.20081449672579765
Online_Training [17/700]: mean_loss=0.11036416329443455
Online_Training [18/700]: mean_loss=0.34481972455978394
Online_Training [19/700]: mean_loss=0.15745551139116287
Online_Training [20/700]: mean_loss=0.45039457827806473
Online_Training [21/700]: mean_loss=0.27597975730895996
Online_Training [22/700]: mean_loss=0.4125756546854973
Online_Training [23/700]: mean_loss=0.4828348606824875
Online_Training [24/700]: mean_loss=0.20220008492469788
Online_Training [25/700]: mean_loss=0.1485108584165573
Online_Training [26/700]: mean_loss=0.13732629269361496
Online_Training [27/700]: mean_loss=0.24263770505785942
Online_Training [28/700]: mean_loss=0.3076627105474472
Online_Training [29/700]: mean_loss=0.2262662723660469
Online_Training [30/700]: mean_loss=0.31640833616256714
Online_Training [31/700]: mean_loss=0.30911868810653687
Online_Training [32/700]: mean_loss=0.47789473086595535
Online_Training [33/700]: mean_loss=0.13745305314660072
Online_Training [34/700]: mean_loss=0.3326570764183998
Online_Training [35/700]: mean_loss=0.2693615257740021
Online_Training [36/700]: mean_loss=0.05428248457610607
Online_Training [37/700]: mean_loss=0.19122208282351494
Online_Training [38/700]: mean_loss=0.09788918681442738
Online_Training [39/700]: mean_loss=0.2169189117848873
Online_Training [40/700]: mean_loss=0.13804880902171135
Online_Training [41/700]: mean_loss=0.2022676132619381
Online_Training [42/700]: mean_loss=0.2526332959532738
Online_Training [43/700]: mean_loss=0.14096254482865334
Online_Training [44/700]: mean_loss=0.14655515924096107
Online_Training [45/700]: mean_loss=0.1376623772084713
Online_Training [46/700]: mean_loss=0.14292608201503754
Online_Training [47/700]: mean_loss=0.0950776468962431
Online_Training [48/700]: mean_loss=0.20290911570191383
Online_Training [49/700]: mean_loss=0.08140556886792183
Online_Training [50/700]: mean_loss=0.22666676342487335
Online_Training [51/700]: mean_loss=0.15398802980780602
Online_Training [52/700]: mean_loss=0.0728902816772461
Online_Training [53/700]: mean_loss=0.16213640570640564
Online_Training [54/700]: mean_loss=0.06430042535066605
Online_Training [55/700]: mean_loss=0.13405240699648857
Online_Training [56/700]: mean_loss=0.3268050476908684
Online_Training [57/700]: mean_loss=0.06397923827171326
Online_Training [58/700]: mean_loss=0.03631862625479698
Online_Training [59/700]: mean_loss=0.21626155078411102
Online_Training [60/700]: mean_loss=0.05981813371181488
Online_Training [61/700]: mean_loss=0.037786287255585194
Online_Training [62/700]: mean_loss=0.15198156237602234
Online_Training [63/700]: mean_loss=0.24181471019983292
Online_Training [64/700]: mean_loss=0.16448254883289337
Online_Training [65/700]: mean_loss=0.1135726198554039
Online_Training [66/700]: mean_loss=0.17350318655371666
Online_Training [67/700]: mean_loss=0.1830141507089138
Online_Training [68/700]: mean_loss=0.6161077469587326
Online_Training [69/700]: mean_loss=0.18742943555116653
Online_Training [70/700]: mean_loss=0.08106721565127373
Online_Training [71/700]: mean_loss=0.08041713573038578
Online_Training [72/700]: mean_loss=0.16910196840763092
Online_Training [73/700]: mean_loss=0.06731196120381355
Online_Training [74/700]: mean_loss=0.20169158652424812
Online_Training [75/700]: mean_loss=0.0518921222537756
Online_Training [76/700]: mean_loss=0.19153551384806633
Online_Training [77/700]: mean_loss=0.06030836794525385
Online_Training [78/700]: mean_loss=0.11846798844635487
Online_Training [79/700]: mean_loss=0.11910531669855118
Online_Training [80/700]: mean_loss=0.12404372915625572
Online_Training [81/700]: mean_loss=0.11237692832946777
Online_Training [82/700]: mean_loss=0.03902340680360794
Online_Training [83/700]: mean_loss=0.13530191406607628
Online_Training [84/700]: mean_loss=0.29110945388674736
Online_Training [85/700]: mean_loss=0.378825344145298
Online_Training [86/700]: mean_loss=0.22404992952942848
Online_Training [87/700]: mean_loss=0.11392060294747353
Online_Training [88/700]: mean_loss=0.08604241348803043
Online_Training [89/700]: mean_loss=0.15730390325188637
Online_Training [90/700]: mean_loss=0.09317132644355297
Online_Training [91/700]: mean_loss=0.09070354886353016
Online_Training [92/700]: mean_loss=0.22017912939190865
Online_Training [93/700]: mean_loss=0.17618975788354874
Online_Training [94/700]: mean_loss=0.27084997296333313
Online_Training [95/700]: mean_loss=0.1067563034594059
Online_Training [96/700]: mean_loss=0.12718475796282291
Online_Training [97/700]: mean_loss=0.1670519784092903
Online_Training [98/700]: mean_loss=0.11215261928737164
Online_Training [99/700]: mean_loss=0.10449852608144283
Online_Training [100/700]: mean_loss=0.08699543215334415
Online_Training [101/700]: mean_loss=0.025888442061841488
Online_Training [102/700]: mean_loss=0.09625323116779327
Online_Training [103/700]: mean_loss=0.08057579770684242
Online_Training [104/700]: mean_loss=0.06582453846931458
Online_Training [105/700]: mean_loss=0.09526077099144459
Online_Training [106/700]: mean_loss=0.3051038160920143
Online_Training [107/700]: mean_loss=0.14347917214035988
Online_Training [108/700]: mean_loss=0.10185600817203522
Online_Training [109/700]: mean_loss=0.17482826113700867
Online_Training [110/700]: mean_loss=0.20418979227542877
Online_Training [111/700]: mean_loss=0.11344631016254425
Online_Training [112/700]: mean_loss=0.09561046957969666
Online_Training [113/700]: mean_loss=0.01895898161455989
Online_Training [114/700]: mean_loss=0.02554615493863821
Online_Training [115/700]: mean_loss=0.2861356809735298
Online_Training [116/700]: mean_loss=0.026792258489876986
Online_Training [117/700]: mean_loss=0.09283806197345257
Online_Training [118/700]: mean_loss=0.1508844904601574
Online_Training [119/700]: mean_loss=0.25765105336904526
Online_Training [120/700]: mean_loss=0.15708337724208832
Online_Training [121/700]: mean_loss=0.07546074688434601
Online_Training [122/700]: mean_loss=0.06102133356034756
Online_Training [123/700]: mean_loss=0.13364136591553688
Online_Training [124/700]: mean_loss=0.13159053027629852
Online_Training [125/700]: mean_loss=0.12185037136077881
Online_Training [126/700]: mean_loss=0.10472305677831173
Online_Training [127/700]: mean_loss=0.04700546991080046
Online_Training [128/700]: mean_loss=0.13229411095380783
Online_Training [129/700]: mean_loss=0.25627952814102173
Online_Training [130/700]: mean_loss=0.11629363894462585
Online_Training [131/700]: mean_loss=0.04421563073992729
Online_Training [132/700]: mean_loss=0.06825833767652512
Online_Training [133/700]: mean_loss=0.09087714925408363
Online_Training [134/700]: mean_loss=0.05584152042865753
Online_Training [135/700]: mean_loss=0.07072748802602291
Online_Training [136/700]: mean_loss=0.04892446659505367
Online_Training [137/700]: mean_loss=0.06622845493257046
Online_Training [138/700]: mean_loss=0.08791858702898026
Online_Training [139/700]: mean_loss=0.07088488526642323
Online_Training [140/700]: mean_loss=0.11337860114872456
Online_Training [141/700]: mean_loss=0.07099853083491325
Online_Training [142/700]: mean_loss=0.0631187055259943
Online_Training [143/700]: mean_loss=0.15857790783047676
Online_Training [144/700]: mean_loss=0.06523890793323517
Online_Training [145/700]: mean_loss=0.05011671781539917
Online_Training [146/700]: mean_loss=0.20096157118678093
Online_Training [147/700]: mean_loss=0.09549344517290592
Online_Training [148/700]: mean_loss=0.09205797128379345
Online_Training [149/700]: mean_loss=0.013220676453784108
Online_Training [150/700]: mean_loss=0.04008576087653637
Online_Training [151/700]: mean_loss=0.01780074229463935
Online_Training [152/700]: mean_loss=0.04615131299942732
Online_Training [153/700]: mean_loss=0.021778113674372435
Online_Training [154/700]: mean_loss=0.014513984322547913
Online_Training [155/700]: mean_loss=0.04283332824707031
Online_Training [156/700]: mean_loss=0.15648281574249268
Online_Training [157/700]: mean_loss=0.04516450595110655
Online_Training [158/700]: mean_loss=0.06968654505908489
Online_Training [159/700]: mean_loss=0.06137857027351856
Online_Training [160/700]: mean_loss=0.016265383455902338
Online_Training [161/700]: mean_loss=0.18873871862888336
Online_Training [162/700]: mean_loss=0.09326444379985332
Online_Training [163/700]: mean_loss=0.03117233794182539
Online_Training [164/700]: mean_loss=0.05995150748640299
Online_Training [165/700]: mean_loss=0.12699064053595066
Online_Training [166/700]: mean_loss=0.04340337496250868
Online_Training [167/700]: mean_loss=0.09838883765041828
Online_Training [168/700]: mean_loss=0.11412888579070568
Online_Training [169/700]: mean_loss=0.18456145748496056
Online_Training [170/700]: mean_loss=0.07238436117768288
Online_Training [171/700]: mean_loss=0.038260179571807384
Online_Training [172/700]: mean_loss=0.03384355315938592
Online_Training [173/700]: mean_loss=0.11438689567148685
Online_Training [174/700]: mean_loss=0.07547452300786972
Online_Training [175/700]: mean_loss=0.2675931602716446
Online_Training [176/700]: mean_loss=0.0936563815921545
Online_Training [177/700]: mean_loss=0.113162100315094
Online_Training [178/700]: mean_loss=0.08011562004685402
Online_Training [179/700]: mean_loss=0.06479704566299915
Online_Training [180/700]: mean_loss=0.10779094696044922
Online_Training [181/700]: mean_loss=0.05577967409044504
Online_Training [182/700]: mean_loss=0.13093062117695808
Online_Training [183/700]: mean_loss=0.14247168973088264
Online_Training [184/700]: mean_loss=0.08171851374208927
Online_Training [185/700]: mean_loss=0.046423520892858505
Online_Training [186/700]: mean_loss=0.0865733940154314
Online_Training [187/700]: mean_loss=0.13157616183161736
Online_Training [188/700]: mean_loss=0.06897082552313805
Online_Training [189/700]: mean_loss=0.131397295743227
Online_Training [190/700]: mean_loss=0.12368745729327202
Online_Training [191/700]: mean_loss=0.08109171316027641
Online_Training [192/700]: mean_loss=0.05814231187105179
Online_Training [193/700]: mean_loss=0.06742878258228302
Online_Training [194/700]: mean_loss=0.12490399926900864
Online_Training [195/700]: mean_loss=0.10327299498021603
Online_Training [196/700]: mean_loss=0.10793016105890274
Online_Training [197/700]: mean_loss=0.08555631898343563
Online_Training [198/700]: mean_loss=0.08371780999004841
Online_Training [199/700]: mean_loss=0.1781492531299591
Online_Training [200/700]: mean_loss=0.09984537772834301
Online_Training [201/700]: mean_loss=0.10197685472667217
Online_Training [202/700]: mean_loss=0.21775304898619652
Online_Training [203/700]: mean_loss=0.13836128637194633
Online_Training [204/700]: mean_loss=0.14415868371725082
Online_Training [205/700]: mean_loss=0.0682237297296524
Online_Training [206/700]: mean_loss=0.22390328720211983
Online_Training [207/700]: mean_loss=0.03641303442418575
Online_Training [208/700]: mean_loss=0.0578813124448061
Online_Training [209/700]: mean_loss=0.028348094318062067
Online_Training [210/700]: mean_loss=0.0951400138437748
Online_Training [211/700]: mean_loss=0.09897946566343307
Online_Training [212/700]: mean_loss=0.08677446097135544
Online_Training [213/700]: mean_loss=0.08539970219135284
Online_Training [214/700]: mean_loss=0.04583881516009569
Online_Training [215/700]: mean_loss=0.08043809793889523
Online_Training [216/700]: mean_loss=0.10377564281225204
Online_Training [217/700]: mean_loss=0.08559765294194221
Online_Training [218/700]: mean_loss=0.1134278904646635
Online_Training [219/700]: mean_loss=0.05797577649354935
Online_Training [220/700]: mean_loss=0.10643048584461212
Online_Training [221/700]: mean_loss=0.16662247106432915
Online_Training [222/700]: mean_loss=0.087371326982975
Online_Training [223/700]: mean_loss=0.05581677518785
Online_Training [224/700]: mean_loss=0.10155540890991688
Online_Training [225/700]: mean_loss=0.022911319974809885
Online_Training [226/700]: mean_loss=0.019448813050985336
Online_Training [227/700]: mean_loss=0.02478665951639414
Online_Training [228/700]: mean_loss=0.03529014717787504
Online_Training [229/700]: mean_loss=0.07711075246334076
Online_Training [230/700]: mean_loss=0.024693955201655626
Online_Training [231/700]: mean_loss=0.08643788658082485
Online_Training [232/700]: mean_loss=0.07618098333477974
Online_Training [233/700]: mean_loss=0.17513877525925636
Online_Training [234/700]: mean_loss=0.09126671589910984
Online_Training [235/700]: mean_loss=0.10473579354584217
Online_Training [236/700]: mean_loss=0.09138562344014645
Online_Training [237/700]: mean_loss=0.09554524719715118
Online_Training [238/700]: mean_loss=0.03230562340468168
Online_Training [239/700]: mean_loss=0.08944115415215492
Online_Training [240/700]: mean_loss=0.07352002523839474
Online_Training [241/700]: mean_loss=0.09174699522554874
Online_Training [242/700]: mean_loss=0.15191859751939774
Online_Training [243/700]: mean_loss=0.12189741246402264
Online_Training [244/700]: mean_loss=0.14408518746495247
Online_Training [245/700]: mean_loss=0.03502693586051464
Online_Training [246/700]: mean_loss=0.054944868199527264
Online_Training [247/700]: mean_loss=0.07906132936477661
Online_Training [248/700]: mean_loss=0.04167597647756338
Online_Training [249/700]: mean_loss=0.06578863225877285
Online_Training [250/700]: mean_loss=0.0684772077947855
Online_Training [251/700]: mean_loss=0.12575307488441467
Online_Training [252/700]: mean_loss=0.03945149574428797
Online_Training [253/700]: mean_loss=0.566932812333107
Online_Training [254/700]: mean_loss=0.09214282035827637
Online_Training [255/700]: mean_loss=0.08125781454145908
Online_Training [256/700]: mean_loss=0.14336125925183296
Online_Training [257/700]: mean_loss=0.07327953539788723
Online_Training [258/700]: mean_loss=0.05355879291892052
Online_Training [259/700]: mean_loss=0.10985902324318886
Online_Training [260/700]: mean_loss=0.09591759741306305
Online_Training [261/700]: mean_loss=0.08302883058786392
Online_Training [262/700]: mean_loss=0.05119633115828037
Online_Training [263/700]: mean_loss=0.04365880414843559
Online_Training [264/700]: mean_loss=0.050451102666556835
Online_Training [265/700]: mean_loss=0.03422668669372797
Online_Training [266/700]: mean_loss=0.06732147932052612
Online_Training [267/700]: mean_loss=0.055716078728437424
Online_Training [268/700]: mean_loss=0.02858526213094592
Online_Training [269/700]: mean_loss=0.052135772071778774
Online_Training [270/700]: mean_loss=0.09133251570165157
Online_Training [271/700]: mean_loss=0.043375334702432156
Online_Training [272/700]: mean_loss=0.09128563478589058
Online_Training [273/700]: mean_loss=0.15250366926193237
Online_Training [274/700]: mean_loss=0.09470524080097675
Online_Training [275/700]: mean_loss=0.13433699682354927
Online_Training [276/700]: mean_loss=0.04685256443917751
Online_Training [277/700]: mean_loss=0.04531721584498882
Online_Training [278/700]: mean_loss=0.19969787448644638
Online_Training [279/700]: mean_loss=0.04623402655124664
Online_Training [280/700]: mean_loss=0.044554926455020905
Online_Training [281/700]: mean_loss=0.06065630540251732
Online_Training [282/700]: mean_loss=0.1098011452704668
Online_Training [283/700]: mean_loss=0.05506824515759945
Online_Training [284/700]: mean_loss=0.20096248760819435
Online_Training [285/700]: mean_loss=0.12947001121938229
Online_Training [286/700]: mean_loss=0.23367593809962273
Online_Training [287/700]: mean_loss=0.22595876455307007
Online_Training [288/700]: mean_loss=0.11181927286088467
Online_Training [289/700]: mean_loss=0.13542689755558968
Online_Training [290/700]: mean_loss=0.13384534046053886
Online_Training [291/700]: mean_loss=0.09640318900346756
Online_Training [292/700]: mean_loss=0.03746378235518932
Online_Training [293/700]: mean_loss=0.04656511079519987
Online_Training [294/700]: mean_loss=0.08670608699321747
Online_Training [295/700]: mean_loss=0.0695253238081932
Online_Training [296/700]: mean_loss=0.02731365291401744
Online_Training [297/700]: mean_loss=0.0511581776663661
Online_Training [298/700]: mean_loss=0.0648336187005043
Online_Training [299/700]: mean_loss=0.040040094405412674
Online_Training [300/700]: mean_loss=0.05970789957791567
Online_Training [301/700]: mean_loss=0.021997820120304823
Online_Training [302/700]: mean_loss=0.11322713643312454
Online_Training [303/700]: mean_loss=0.028184570837765932
Online_Training [304/700]: mean_loss=0.030878263991326094
Online_Training [305/700]: mean_loss=0.01927927043288946
Online_Training [306/700]: mean_loss=0.040674966759979725
Online_Training [307/700]: mean_loss=0.020022723823785782
Online_Training [308/700]: mean_loss=0.022444278933107853
Online_Training [309/700]: mean_loss=0.031296159606426954
Online_Training [310/700]: mean_loss=0.0453643174842
Online_Training [311/700]: mean_loss=0.023504459764808416
Online_Training [312/700]: mean_loss=0.21837467327713966
Online_Training [313/700]: mean_loss=0.03150661429390311
Online_Training [314/700]: mean_loss=0.00925463973544538
Online_Training [315/700]: mean_loss=0.02843894110992551
Online_Training [316/700]: mean_loss=0.10517261922359467
Online_Training [317/700]: mean_loss=0.03625865373760462
Online_Training [318/700]: mean_loss=0.07549135573208332
Online_Training [319/700]: mean_loss=0.04398014396429062
Online_Training [320/700]: mean_loss=0.013234918005764484
Online_Training [321/700]: mean_loss=0.10489517822861671
Online_Training [322/700]: mean_loss=0.4647545963525772
Online_Training [323/700]: mean_loss=0.11887436918914318
Online_Training [324/700]: mean_loss=0.04851059243083
Online_Training [325/700]: mean_loss=0.03537392243742943
Online_Training [326/700]: mean_loss=0.02126721851527691
Online_Training [327/700]: mean_loss=0.06162979733198881
Online_Training [328/700]: mean_loss=0.024759450927376747
Online_Training [329/700]: mean_loss=0.05152281001210213
Online_Training [330/700]: mean_loss=0.09833330288529396
Online_Training [331/700]: mean_loss=0.02366750780493021
Online_Training [332/700]: mean_loss=0.05184032395482063
Online_Training [333/700]: mean_loss=0.05530595127493143
Online_Training [334/700]: mean_loss=0.03594535682350397
Online_Training [335/700]: mean_loss=0.15335378050804138
Online_Training [336/700]: mean_loss=0.035552981309592724
Online_Training [337/700]: mean_loss=0.06052593793720007
Online_Training [338/700]: mean_loss=0.07622413337230682
Online_Training [339/700]: mean_loss=0.03212969331070781
Online_Training [340/700]: mean_loss=0.025520780589431524
Online_Training [341/700]: mean_loss=0.023737743496894836
Online_Training [342/700]: mean_loss=0.15816685557365417
Online_Training [343/700]: mean_loss=0.02941084001213312
Online_Training [344/700]: mean_loss=0.03292509913444519
Online_Training [345/700]: mean_loss=0.10508573055267334
Online_Training [346/700]: mean_loss=0.06141704320907593
Online_Training [347/700]: mean_loss=0.07816634885966778
Online_Training [348/700]: mean_loss=0.04327833000570536
Online_Training [349/700]: mean_loss=0.04824015125632286
Online_Training [350/700]: mean_loss=0.14625706151127815
Online_Training [351/700]: mean_loss=0.38158854842185974
Online_Training [352/700]: mean_loss=0.06009219493716955
Online_Training [353/700]: mean_loss=0.10538394935429096
Online_Training [354/700]: mean_loss=0.0328351859934628
Online_Training [355/700]: mean_loss=0.013440349604934454
Online_Training [356/700]: mean_loss=0.044204859994351864
Online_Training [357/700]: mean_loss=0.05589269008487463
Online_Training [358/700]: mean_loss=0.10814245603978634
Online_Training [359/700]: mean_loss=0.09411933086812496
Online_Training [360/700]: mean_loss=0.14824394136667252
Online_Training [361/700]: mean_loss=0.12083015777170658
Online_Training [362/700]: mean_loss=0.030704849399626255
Online_Training [363/700]: mean_loss=0.046131509356200695
Online_Training [364/700]: mean_loss=0.08638414181768894
Online_Training [365/700]: mean_loss=0.048441425897181034
Online_Training [366/700]: mean_loss=0.04116083402186632
Online_Training [367/700]: mean_loss=0.04466798156499863
Online_Training [368/700]: mean_loss=0.13306999579071999
Online_Training [369/700]: mean_loss=0.017208734527230263
Online_Training [370/700]: mean_loss=0.09517444856464863
Online_Training [371/700]: mean_loss=0.045280393213033676
Online_Training [372/700]: mean_loss=0.040970721282064915
Online_Training [373/700]: mean_loss=0.05461413413286209
Online_Training [374/700]: mean_loss=0.0317894690670073
Online_Training [375/700]: mean_loss=0.02249768329784274
Online_Training [376/700]: mean_loss=0.06797956116497517
Online_Training [377/700]: mean_loss=0.035482462495565414
Online_Training [378/700]: mean_loss=0.022758047096431255
Online_Training [379/700]: mean_loss=0.030365354847162962
Online_Training [380/700]: mean_loss=0.025177642703056335
Online_Training [381/700]: mean_loss=0.043403695337474346
Online_Training [382/700]: mean_loss=0.08230086788535118
Online_Training [383/700]: mean_loss=0.25771820545196533
Online_Training [384/700]: mean_loss=0.22549715638160706
Online_Training [385/700]: mean_loss=0.20898519828915596
Online_Training [386/700]: mean_loss=0.011147425277158618
Online_Training [387/700]: mean_loss=0.02788490243256092
Online_Training [388/700]: mean_loss=0.08763996697962284
Online_Training [389/700]: mean_loss=0.17636267840862274
Online_Training [390/700]: mean_loss=0.02837538020685315
Online_Training [391/700]: mean_loss=0.041156292892992496
Online_Training [392/700]: mean_loss=0.058627513237297535
Online_Training [393/700]: mean_loss=0.033673305064439774
Online_Training [394/700]: mean_loss=0.025066907983273268
Online_Training [395/700]: mean_loss=0.019126380793750286
Online_Training [396/700]: mean_loss=0.02280124183744192
Online_Training [397/700]: mean_loss=0.016689161770045757
Online_Training [398/700]: mean_loss=0.05482407007366419
Online_Training [399/700]: mean_loss=0.022020221687853336
Online_Training [400/700]: mean_loss=0.025227566249668598
Online_Training [401/700]: mean_loss=0.012525092344731092
Online_Training [402/700]: mean_loss=0.03158397413790226
Online_Training [403/700]: mean_loss=0.03885075356811285
Online_Training [404/700]: mean_loss=0.047686779871582985
Online_Training [405/700]: mean_loss=0.05571646336466074
Online_Training [406/700]: mean_loss=0.08000539802014828
Online_Training [407/700]: mean_loss=0.03551333677023649
Online_Training [408/700]: mean_loss=0.05379239283502102
Online_Training [409/700]: mean_loss=0.043402100913226604
Online_Training [410/700]: mean_loss=0.07697208225727081
Online_Training [411/700]: mean_loss=0.08554086834192276
Online_Training [412/700]: mean_loss=0.03633059002459049
Online_Training [413/700]: mean_loss=0.05778275057673454
Online_Training [414/700]: mean_loss=0.025253478437662125
Online_Training [415/700]: mean_loss=0.07134521566331387
Online_Training [416/700]: mean_loss=0.02075393684208393
Online_Training [417/700]: mean_loss=0.03475645277649164
Online_Training [418/700]: mean_loss=0.05821685865521431
Online_Training [419/700]: mean_loss=0.02685112366452813
Online_Training [420/700]: mean_loss=0.033930675126612186
Online_Training [421/700]: mean_loss=0.03534600976854563
Online_Training [422/700]: mean_loss=0.09810839220881462
Online_Training [423/700]: mean_loss=0.019040529150515795
Online_Training [424/700]: mean_loss=0.09923085384070873
Online_Training [425/700]: mean_loss=0.05901409965008497
Online_Training [426/700]: mean_loss=0.026555754709988832
Online_Training [427/700]: mean_loss=0.08049691282212734
Online_Training [428/700]: mean_loss=0.12294523976743221
Online_Training [429/700]: mean_loss=0.04899234138429165
Online_Training [430/700]: mean_loss=0.010259168688207865
Online_Training [431/700]: mean_loss=0.011638849508017302
Online_Training [432/700]: mean_loss=0.049389767460525036
Online_Training [433/700]: mean_loss=0.05912626348435879
Online_Training [434/700]: mean_loss=0.048897541128098965
Online_Training [435/700]: mean_loss=0.12221514992415905
Online_Training [436/700]: mean_loss=0.011452950304374099
Online_Training [437/700]: mean_loss=0.07281010411679745
Online_Training [438/700]: mean_loss=0.050323464907705784
Online_Training [439/700]: mean_loss=0.04933841526508331
Online_Training [440/700]: mean_loss=0.040624041110277176
Online_Training [441/700]: mean_loss=0.08775372430682182
Online_Training [442/700]: mean_loss=0.04078116547316313
Online_Training [443/700]: mean_loss=0.028391717933118343
Online_Training [444/700]: mean_loss=0.024172489996999502
Online_Training [445/700]: mean_loss=0.08901318535208702
Online_Training [446/700]: mean_loss=0.2946453392505646
Online_Training [447/700]: mean_loss=0.11710566282272339
Online_Training [448/700]: mean_loss=0.08868606388568878
Online_Training [449/700]: mean_loss=0.020422862377017736
Online_Training [450/700]: mean_loss=0.020005210302770138
Online_Training [451/700]: mean_loss=0.02598073799163103
Online_Training [452/700]: mean_loss=0.059843835420906544
Online_Training [453/700]: mean_loss=0.06738381460309029
Online_Training [454/700]: mean_loss=0.013284740969538689
Online_Training [455/700]: mean_loss=0.024000748991966248
Online_Training [456/700]: mean_loss=0.043158916756510735
Online_Training [457/700]: mean_loss=0.05088824778795242
Online_Training [458/700]: mean_loss=0.07746450789272785
Online_Training [459/700]: mean_loss=0.07708733342587948
Online_Training [460/700]: mean_loss=0.07776984013617039
Online_Training [461/700]: mean_loss=0.05251288041472435
Online_Training [462/700]: mean_loss=0.10649611800909042
Online_Training [463/700]: mean_loss=0.029803871177136898
Online_Training [464/700]: mean_loss=0.0394900469109416
Online_Training [465/700]: mean_loss=0.02538936072960496
Online_Training [466/700]: mean_loss=0.0689168181270361
Online_Training [467/700]: mean_loss=0.10463117435574532
Online_Training [468/700]: mean_loss=0.03929435275495052
Online_Training [469/700]: mean_loss=0.01880299299955368
Online_Training [470/700]: mean_loss=0.027332505211234093
Online_Training [471/700]: mean_loss=0.025944168213754892
Online_Training [472/700]: mean_loss=0.05202600546181202
Online_Training [473/700]: mean_loss=0.05036040488630533
Online_Training [474/700]: mean_loss=0.044776950031518936
Online_Training [475/700]: mean_loss=0.05981868226081133
Online_Training [476/700]: mean_loss=0.02428556839004159
Online_Training [477/700]: mean_loss=0.021934078074991703
Online_Training [478/700]: mean_loss=0.027135424315929413
Online_Training [479/700]: mean_loss=0.09426976926624775
Online_Training [480/700]: mean_loss=0.02162043796852231
Online_Training [481/700]: mean_loss=0.06347342673689127
Online_Training [482/700]: mean_loss=0.07085213251411915
Online_Training [483/700]: mean_loss=0.06313035544008017
Online_Training [484/700]: mean_loss=0.03053091885522008
Online_Training [485/700]: mean_loss=0.041936734691262245
Online_Training [486/700]: mean_loss=0.05475154332816601
Online_Training [487/700]: mean_loss=0.0525913592427969
Online_Training [488/700]: mean_loss=0.0478022750467062
Online_Training [489/700]: mean_loss=0.03867179900407791
Online_Training [490/700]: mean_loss=0.013503482798114419
Online_Training [491/700]: mean_loss=0.03607849311083555
Online_Training [492/700]: mean_loss=0.03822436276823282
Online_Training [493/700]: mean_loss=0.012147209141403437
Online_Training [494/700]: mean_loss=0.06969229131937027
Online_Training [495/700]: mean_loss=0.187692541629076
Online_Training [496/700]: mean_loss=0.06167050823569298
Online_Training [497/700]: mean_loss=0.038109385408461094
Online_Training [498/700]: mean_loss=0.02158096292987466
Online_Training [499/700]: mean_loss=0.04501152504235506
Online_Training [500/700]: mean_loss=0.01889405120164156
Online_Training [501/700]: mean_loss=0.032689785584807396
Online_Training [502/700]: mean_loss=0.04756038822233677
Online_Training [503/700]: mean_loss=0.02996793808415532
Online_Training [504/700]: mean_loss=0.06517262570559978
Online_Training [505/700]: mean_loss=0.03394894674420357
Online_Training [506/700]: mean_loss=0.04936868976801634
Online_Training [507/700]: mean_loss=0.02684570662677288
Online_Training [508/700]: mean_loss=0.03525503817945719
Online_Training [509/700]: mean_loss=0.05930801201611757
Online_Training [510/700]: mean_loss=0.0916889701038599
Online_Training [511/700]: mean_loss=0.04677863325923681
Online_Training [512/700]: mean_loss=0.06282599456608295
Online_Training [513/700]: mean_loss=0.054923526011407375
Online_Training [514/700]: mean_loss=0.053487906232476234
Online_Training [515/700]: mean_loss=0.06342903058975935
Online_Training [516/700]: mean_loss=0.038960703648626804
Online_Training [517/700]: mean_loss=0.0859794169664383
Online_Training [518/700]: mean_loss=0.024539229925721884
Online_Training [519/700]: mean_loss=0.048199551180005074
Online_Training [520/700]: mean_loss=0.05395031813532114
Online_Training [521/700]: mean_loss=0.03547368384897709
Online_Training [522/700]: mean_loss=0.08899730816483498
Online_Training [523/700]: mean_loss=0.04829030949622393
Online_Training [524/700]: mean_loss=0.043890426866710186
Online_Training [525/700]: mean_loss=0.03674053307622671
Online_Training [526/700]: mean_loss=0.04436550196260214
Online_Training [527/700]: mean_loss=0.2207927145063877
Online_Training [528/700]: mean_loss=0.07809910923242569
Online_Training [529/700]: mean_loss=0.0641751317307353
Online_Training [530/700]: mean_loss=0.08540635742247105
Online_Training [531/700]: mean_loss=0.04807395488023758
Online_Training [532/700]: mean_loss=0.015644165920093656
Online_Training [533/700]: mean_loss=0.07533668167889118
Online_Training [534/700]: mean_loss=0.046868063509464264
Online_Training [535/700]: mean_loss=0.02594182128086686
Online_Training [536/700]: mean_loss=0.012376910541206598
Online_Training [537/700]: mean_loss=0.030275005381554365
Online_Training [538/700]: mean_loss=0.08594407513737679
Online_Training [539/700]: mean_loss=0.10440838895738125
Online_Training [540/700]: mean_loss=0.05664768069982529
Online_Training [541/700]: mean_loss=0.12671748735010624
Online_Training [542/700]: mean_loss=0.05589304678142071
Online_Training [543/700]: mean_loss=0.11496812105178833
Online_Training [544/700]: mean_loss=0.05361246224492788
Online_Training [545/700]: mean_loss=0.04289533384144306
Online_Training [546/700]: mean_loss=0.022236734628677368
Online_Training [547/700]: mean_loss=0.08372988924384117
Online_Training [548/700]: mean_loss=0.1135074533522129
Online_Training [549/700]: mean_loss=0.024506996851414442
Online_Training [550/700]: mean_loss=0.029826151207089424
Online_Training [551/700]: mean_loss=0.012945986818522215
Online_Training [552/700]: mean_loss=0.05157715920358896
Online_Training [553/700]: mean_loss=0.0393310422077775
Online_Training [554/700]: mean_loss=0.011155657935887575
Online_Training [555/700]: mean_loss=0.07459518127143383
Online_Training [556/700]: mean_loss=0.01628593308851123
Online_Training [557/700]: mean_loss=0.07443030551075935
Online_Training [558/700]: mean_loss=0.02744084084406495
Online_Training [559/700]: mean_loss=0.020343185868114233
Online_Training [560/700]: mean_loss=0.03398688789457083
Online_Training [561/700]: mean_loss=0.02946665184572339
Online_Training [562/700]: mean_loss=0.02257464872673154
Online_Training [563/700]: mean_loss=0.049552167765796185
Online_Training [564/700]: mean_loss=0.028710137121379375
Online_Training [565/700]: mean_loss=0.10191477090120316
Online_Training [566/700]: mean_loss=0.040718717500567436
Online_Training [567/700]: mean_loss=0.023893189150840044
Online_Training [568/700]: mean_loss=0.027127315755933523
Online_Training [569/700]: mean_loss=0.10749994218349457
Online_Training [570/700]: mean_loss=0.04731786251068115
Online_Training [571/700]: mean_loss=0.01203904440626502
Online_Training [572/700]: mean_loss=0.046347183175385
Online_Training [573/700]: mean_loss=0.022949120495468378
Online_Training [574/700]: mean_loss=0.07910634018480778
Online_Training [575/700]: mean_loss=0.12639665976166725
Online_Training [576/700]: mean_loss=0.08233754895627499
Online_Training [577/700]: mean_loss=0.0691850557923317
Online_Training [578/700]: mean_loss=0.06187742482870817
Online_Training [579/700]: mean_loss=0.03770913742482662
Online_Training [580/700]: mean_loss=0.0287348129786551
Online_Training [581/700]: mean_loss=0.04405874479562044
Online_Training [582/700]: mean_loss=0.026359654031693935
Online_Training [583/700]: mean_loss=0.06415926292538643
Online_Training [584/700]: mean_loss=0.028102523647248745
Online_Training [585/700]: mean_loss=0.07205215096473694
Online_Training [586/700]: mean_loss=0.01759356865659356
Online_Training [587/700]: mean_loss=0.07911365292966366
Online_Training [588/700]: mean_loss=0.04615440033376217
Online_Training [589/700]: mean_loss=0.12792827561497688
Online_Training [590/700]: mean_loss=0.028244351502507925
Online_Training [591/700]: mean_loss=0.04652137402445078
Online_Training [592/700]: mean_loss=0.01653449237346649
Online_Training [593/700]: mean_loss=0.07434345223009586
Online_Training [594/700]: mean_loss=0.027291283011436462
Online_Training [595/700]: mean_loss=0.07032336294651031
Online_Training [596/700]: mean_loss=0.026015525683760643
Online_Training [597/700]: mean_loss=0.0446528447791934
Online_Training [598/700]: mean_loss=0.05816569272428751
Online_Training [599/700]: mean_loss=0.030405023135244846
Online_Training [600/700]: mean_loss=0.025803635828197002
Online_Training [601/700]: mean_loss=0.03346228413283825
Online_Training [602/700]: mean_loss=0.1860438846051693
Online_Training [603/700]: mean_loss=0.28428659588098526
Online_Training [604/700]: mean_loss=0.038327546790242195
Online_Training [605/700]: mean_loss=0.05567040201276541
Online_Training [606/700]: mean_loss=0.034911854192614555
Online_Training [607/700]: mean_loss=0.05062450189143419
Online_Training [608/700]: mean_loss=0.06146727688610554
Online_Training [609/700]: mean_loss=0.025641346350312233
Online_Training [610/700]: mean_loss=0.05400556232780218
Online_Training [611/700]: mean_loss=0.04899012576788664
Online_Training [612/700]: mean_loss=0.02859849063679576
Online_Training [613/700]: mean_loss=0.0706621278077364
Online_Training [614/700]: mean_loss=0.04830882418900728
Online_Training [615/700]: mean_loss=0.04978667013347149
Online_Training [616/700]: mean_loss=0.09666947834193707
Online_Training [617/700]: mean_loss=0.052575718611478806
Online_Training [618/700]: mean_loss=0.03455383609980345
Online_Training [619/700]: mean_loss=0.051433805376291275
Online_Training [620/700]: mean_loss=0.017708793748170137
Online_Training [621/700]: mean_loss=0.03394147753715515
Online_Training [622/700]: mean_loss=0.08778276666998863
Online_Training [623/700]: mean_loss=0.17977051436901093
Online_Training [624/700]: mean_loss=0.06732689402997494
Online_Training [625/700]: mean_loss=0.05227420944720507
Online_Training [626/700]: mean_loss=0.03739927802234888
Online_Training [627/700]: mean_loss=0.043206192553043365
Online_Training [628/700]: mean_loss=0.13102617673575878
Online_Training [629/700]: mean_loss=0.06986918300390244
Online_Training [630/700]: mean_loss=0.07874601613730192
Online_Training [631/700]: mean_loss=0.017492905724793673
Online_Training [632/700]: mean_loss=0.22476455941796303
Online_Training [633/700]: mean_loss=0.052143639884889126
Online_Training [634/700]: mean_loss=0.01952032931149006
Online_Training [635/700]: mean_loss=0.03583970386534929
Online_Training [636/700]: mean_loss=0.03753329534083605
Online_Training [637/700]: mean_loss=0.014202585443854332
Online_Training [638/700]: mean_loss=0.02954404940828681
Online_Training [639/700]: mean_loss=0.1531430371105671
Online_Training [640/700]: mean_loss=0.054630158469080925
Online_Training [641/700]: mean_loss=0.016285760793834925
Online_Training [642/700]: mean_loss=0.027204313781112432
Online_Training [643/700]: mean_loss=0.04574426170438528
Online_Training [644/700]: mean_loss=0.007695527863688767
Online_Training [645/700]: mean_loss=0.02644531661644578
Online_Training [646/700]: mean_loss=0.054994719102978706
Online_Training [647/700]: mean_loss=0.030563044361770153
Online_Training [648/700]: mean_loss=0.07707469165325165
Online_Training [649/700]: mean_loss=0.07955437898635864
Online_Training [650/700]: mean_loss=0.07654241845011711
Online_Training [651/700]: mean_loss=0.033367820084095
Online_Training [652/700]: mean_loss=0.0815887376666069
Online_Training [653/700]: mean_loss=0.05433490499854088
Online_Training [654/700]: mean_loss=0.013978119706735015
Online_Training [655/700]: mean_loss=0.09436291083693504
Online_Training [656/700]: mean_loss=0.024649932514876127
Online_Training [657/700]: mean_loss=0.05557866580784321
Online_Training [658/700]: mean_loss=0.04612724296748638
Online_Training [659/700]: mean_loss=0.0434678103774786
Online_Training [660/700]: mean_loss=0.02046952396631241
Online_Training [661/700]: mean_loss=0.055082653649151325
Online_Training [662/700]: mean_loss=0.08019569329917431
Online_Training [663/700]: mean_loss=0.13868001103401184
Online_Training [664/700]: mean_loss=0.04118791222572327
Online_Training [665/700]: mean_loss=0.0761307142674923
Online_Training [666/700]: mean_loss=0.029983910731971264
Online_Training [667/700]: mean_loss=0.04121351707726717
Online_Training [668/700]: mean_loss=0.08983108587563038
Online_Training [669/700]: mean_loss=0.05769173614680767
Online_Training [670/700]: mean_loss=0.022127780131995678
Online_Training [671/700]: mean_loss=0.02506397943943739
Online_Training [672/700]: mean_loss=0.1029897965490818
Online_Training [673/700]: mean_loss=0.22876380011439323
Online_Training [674/700]: mean_loss=0.04865209758281708
Online_Training [675/700]: mean_loss=0.09393302537500858
Online_Training [676/700]: mean_loss=0.03894241526722908
Online_Training [677/700]: mean_loss=0.08069589175283909
Online_Training [678/700]: mean_loss=0.06625546514987946
Online_Training [679/700]: mean_loss=0.09048503823578358
Online_Training [680/700]: mean_loss=0.04169897176325321
Online_Training [681/700]: mean_loss=0.007965236785821617
Online_Training [682/700]: mean_loss=0.055365885607898235
Online_Training [683/700]: mean_loss=0.024513815995305777
Online_Training [684/700]: mean_loss=0.029570048209279776
Online_Training [685/700]: mean_loss=0.09553260542452335
Online_Training [686/700]: mean_loss=0.01563372486270964
Online_Training [687/700]: mean_loss=0.02864188328385353
Online_Training [688/700]: mean_loss=0.06384207960218191
Online_Training [689/700]: mean_loss=0.03427079413086176
Online_Training [690/700]: mean_loss=0.095927894115448
Online_Training [691/700]: mean_loss=0.022270741406828165
Online_Training [692/700]: mean_loss=0.08738422952592373
Online_Training [693/700]: mean_loss=0.017201817128807306
Online_Training [694/700]: mean_loss=0.03758601937443018
Online_Training [695/700]: mean_loss=0.08080652728676796
Online_Training [696/700]: mean_loss=0.030730218160897493
Online_Training [697/700]: mean_loss=0.1313779465854168
Online_Training [698/700]: mean_loss=0.0617258520796895
Online_Training [699/700]: mean_loss=0.07040694169700146
Online_Training [700/700]: mean_loss=0.08494807966053486
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-2.249383   0.8940492]
[0, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 1, 0, 1, 1, 0, 2, 2, 0, 0, 2, 1, 1, 0, 2, 1, 1, 2, 1, 2, 1, 0, 2, 2, 1, 1, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1, 2, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 1, 2, 1, 0, 1, 1, 2, 2, 2, 0, 1, 2, 0, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 1, 1, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2, 1, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 1, 0, 0, 1, 1, 2, 0, 1, 2, 1, 2, 2, 2, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 1, 0, 0, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0]
[0, 1, 1, 2, 3, 4, 5, 6, 1, 7, 8, 9, 4, 10, 3, 9, 11, 0, 12, 13, 14, 8, 7, 15, 16, 6, 6, 17, 18, 19, 20, 6, 21, 20, 18, 22, 21, 23, 24, 10, 25, 26, 27, 0, 10, 14, 23, 12, 20, 23, 11, 28, 29, 2, 30, 0, 4, 31, 5, 0, 9, 32, 28, 18, 19, 11, 20, 33, 9, 9, 33, 34, 2, 27, 35, 34, 12, 14, 0, 2, 12, 3, 34, 9, 6, 31, 7, 36, 37, 38, 39, 1, 12, 12, 1, 23, 15, 20, 29, 12, 9, 40, 20, 8, 11, 0, 41, 26, 40, 17, 42, 5, 14, 5, 36, 41, 12, 9, 29, 6, 43, 0, 44, 1, 35, 14, 3, 5, 29, 13, 44, 21, 45, 12, 1, 5, 4, 45, 46, 47, 42, 9, 46, 46, 48, 7, 13, 27, 49, 50, 47, 12, 22, 43, 42, 51, 34, 52, 5, 19, 3, 51, 23, 53, 18, 18, 0, 21, 54, 55, 20, 20, 44, 54, 56, 21, 40, 47, 55, 2, 57, 58, 1, 59, 59, 9, 35, 54, 34, 60, 0, 32, 26, 29, 10, 12, 29, 56, 5, 34, 25, 44, 28, 51, 61, 59, 11, 20, 53, 29, 62, 20, 49, 63, 64, 6, 29, 9, 60, 11, 63, 1, 23, 9, 20, 62, 8, 44, 54, 10, 23, 65, 12, 62, 34, 0, 6, 15, 20, 30, 38, 10, 64, 18, 20, 11, 27, 23, 56, 61, 8, 38, 20, 28, 63, 66, 41, 54, 1, 51, 6, 63, 66, 46, 10, 58, 14, 67, 57, 23, 11, 63, 65, 15, 68, 30, 19, 62, 1, 14, 46, 67, 67, 8, 52, 20, 60, 54, 50, 66, 13, 56, 60, 69, 9, 62, 64, 63, 54, 67]
Centroids: [[-2.0192647, 1.0376511], [-0.041882683, -1.8677409], [-1.3999443, 3.629074]]
Centroids: [[-2.152992, 1.0654874], [-1.7586696, 4.1753793], [-0.8155672, 2.630891], [0.46468925, -1.6585286], [-1.1533072, 1.37591], [-1.1243565, 3.3532882], [-1.0588822, 3.9988298], [-2.2916527, 2.0042064], [-1.5276327, 3.1504238], [-0.029301235, -1.8057444], [-0.22567621, -3.0237525], [-1.9136392, 1.1474079], [-0.023335705, -1.3887082], [-1.0341992, 0.55262697], [0.094909355, -2.356708], [-2.2014244, -0.47439864], [-2.0643678, -3.1607387], [0.04472155, 1.591903], [-1.2777098, 2.0460408], [-1.3901277, 0.9828541], [-0.2813002, -2.21335], [-1.4824349, 4.4871955], [-1.8592654, 0.6909607], [0.57850343, -1.0765324], [-5.371997, 1.0278366], [-1.2090685, -3.222281], [-2.8336134, -0.07319478], [-2.8061168, 4.6155357], [-1.3937985, -0.15963572], [-1.557934, 4.101702], [-0.6046262, 4.035543], [-0.8755361, -1.6860056], [-0.40810257, 1.3941027], [-2.6223211, 0.6342985], [-1.9417694, 3.5476983], [-1.6195793, 0.3416742], [-0.11236141, 0.6011869], [-3.2572646, 4.2664332], [-0.20575078, -2.5409443], [-0.66905767, -0.5547871], [-0.18478286, 3.4556427], [-1.5485302, -0.43413952], [-2.563539, 3.6081078], [-1.1940211, 1.4878559], [-0.40981215, -1.1278255], [-1.2595298, 2.8324206], [-0.7351991, 3.2349994], [-2.5265563, 1.8102804], [-2.2897685, 3.0137255], [-2.9047022, 2.2634988], [-0.22009149, 1.4636439], [-2.5002515, 4.1216893], [-1.895513, 2.92653], [0.07757406, -0.8635473], [-0.5665351, 1.8776741], [-0.671754, 3.8225307], [-1.7838345, -0.14754063], [-1.2303412, 2.6879647], [-2.6555772, 2.783391], [-0.15006725, 1.5342288], [-1.2066165, 2.630983], [1.4250214, -2.0553236], [-2.282062, 0.7438434], [0.33807412, -1.7241243], [-1.6041065, 1.3526378], [-1.6461629, 2.2816558], [-2.1805546, 2.9688866], [-2.3389108, 2.048142], [-2.817445, 0.23169264], [-0.7964907, -2.3233716]]
Contingency Matrix: 
[[11  0  0  0  4  0  0  4  0  0  0  7  0  4  0  4  0  2  2  4  0  0  2  0
   1  0  3  1  4  0  0  0  1  2  0  3  0  0  0  0  0  2  0  0  0  0  0  3
   1  1  0  0  1  0  2  0  3  1  1  1  0  0  3  0  1  1  1  3  1  0]
 [ 0  0  0  5  0  0  0  0  0 13  7  0 12  0  7  0  1  0  0  0 15  0  0  9
   0  2  0  0  0  0  0  2  0  0  0  0  1  0  3  1  0  1  0  1  5  0  0  0
   0  0  1  0  0  2  1  0  1  0  0  1  1  2  1  6  1  0  0  0  0  1]
 [ 0 11  5  0  0  8  9  0  6  0  0  1  0  0  0  0  0  0  4  0  0  5  0  0
   0  0  0  3  0  8  3  0  1  0  7  0  1  1  0  0  3  0  3  1  0  2  5  0
   0  1  1  4  1  0  4  2  0  1  1  1  3  0  1  0  1  1  2  1  0  0]]
[[11, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 7, 0, 4, 0, 4, 0, 2, 2, 4, 0, 0, 2, 0, 1, 0, 3, 1, 4, 0, 0, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 0, 2, 0, 3, 1, 1, 1, 0, 0, 3, 0, 1, 1, 1, 3, 1, 0], [0, 0, 0, 5, 0, 0, 0, 0, 0, 13, 7, 0, 12, 0, 7, 0, 1, 0, 0, 0, 15, 0, 0, 9, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 3, 1, 0, 1, 0, 1, 5, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 1, 1, 2, 1, 6, 1, 0, 0, 0, 0, 1], [0, 11, 5, 0, 0, 8, 9, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 0, 0, 3, 0, 8, 3, 0, 1, 0, 7, 0, 1, 1, 0, 0, 3, 0, 3, 1, 0, 2, 5, 0, 0, 1, 1, 4, 1, 0, 4, 2, 0, 1, 1, 1, 3, 0, 1, 0, 1, 1, 2, 1, 0, 0]]
[[11, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 7, 0, 4, 0, 4, 0, 2, 2, 4, 0, 0, 2, 0, 1, 0, 3, 1, 4, 0, 0, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 0, 2, 0, 3, 1, 1, 1, 0, 0, 3, 0, 1, 1, 1, 3, 1, 0], [0, 0, 0, 5, 0, 0, 0, 0, 0, 13, 7, 0, 12, 0, 7, 0, 1, 0, 0, 0, 15, 0, 0, 9, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 3, 1, 0, 1, 0, 1, 5, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 1, 1, 2, 1, 6, 1, 0, 0, 0, 0, 1], [0, 11, 5, 0, 0, 8, 9, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 0, 0, 3, 0, 8, 3, 0, 1, 0, 7, 0, 1, 1, 0, 0, 3, 0, 3, 1, 0, 2, 5, 0, 0, 1, 1, 4, 1, 0, 4, 2, 0, 1, 1, 1, 3, 0, 1, 0, 1, 1, 2, 1, 0, 0]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]
[[11, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 7, 0, 4, 0, 4, 0, 2, 2, 4, -1, 0, 2, 0, 1, 0, 3, 1, 4, 0, 0, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 0, 2, 0, 3, 1, 1, 1, 0, 0, 3, 0, 1, 1, 1, 3, 1, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 11, 5, 0, 0, 8, 9, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, -1, 5, 0, 0, 0, 0, 0, 3, 0, 8, 3, 0, 1, 0, 7, 0, 1, 1, 0, 0, 3, 0, 3, 1, 0, 2, 5, 0, 0, 1, 1, 4, 1, 0, 4, 2, 0, 1, 1, 1, 3, 0, 1, 0, 1, 1, 2, 1, 0, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 11, 5, 0, 0, 8, 9, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, -1, 5, 0, 0, 0, 0, 0, 3, 0, 8, 3, 0, 1, 0, 7, 0, 1, 1, 0, 0, 3, 0, 3, 1, 0, 2, 5, 0, 0, 1, 1, 4, 1, 0, 4, 2, 0, 1, 1, 1, 3, 0, 1, 0, 1, 1, 2, 1, 0, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 20, 0: 0, 2: 1}
New Contingency Matrix: 
[[11  0  0  0  0  4  0  0  4  0  0  0  7  0  4  0  4  0  2  2  4  0  2  0
   1  0  3  1  4  0  0  0  1  2  0  3  0  0  0  0  0  2  0  0  0  0  0  3
   1  1  0  0  1  0  2  0  3  1  1  1  0  0  3  0  1  1  1  3  1  0]
 [ 0 15  0  0  5  0  0  0  0  0 13  7  0 12  0  7  0  1  0  0  0  0  0  9
   0  2  0  0  0  0  0  2  0  0  0  0  1  0  3  1  0  1  0  1  5  0  0  0
   0  0  1  0  0  2  1  0  1  0  0  1  1  2  1  6  1  0  0  0  0  1]
 [ 0  0 11  5  0  0  8  9  0  6  0  0  1  0  0  0  0  0  0  4  0  5  0  0
   0  0  0  3  0  8  3  0  1  0  7  0  1  1  0  0  3  0  3  1  0  2  5  0
   0  1  1  4  1  0  4  2  0  1  1  1  3  0  1  0  1  1  2  1  0  0]]
New Clustered Label Sequence: [0, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]
Diagonal_Elements: [11, 15, 11], Sum: 37
All_Elements: [11, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 7, 0, 4, 0, 4, 0, 2, 2, 4, 0, 2, 0, 1, 0, 3, 1, 4, 0, 0, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 0, 2, 0, 3, 1, 1, 1, 0, 0, 3, 0, 1, 1, 1, 3, 1, 0, 0, 15, 0, 0, 5, 0, 0, 0, 0, 0, 13, 7, 0, 12, 0, 7, 0, 1, 0, 0, 0, 0, 0, 9, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 3, 1, 0, 1, 0, 1, 5, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 1, 1, 2, 1, 6, 1, 0, 0, 0, 0, 1, 0, 0, 11, 5, 0, 0, 8, 9, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 5, 0, 0, 0, 0, 0, 3, 0, 8, 3, 0, 1, 0, 7, 0, 1, 1, 0, 0, 3, 0, 3, 1, 0, 2, 5, 0, 0, 1, 1, 4, 1, 0, 4, 2, 0, 1, 1, 1, 3, 0, 1, 0, 1, 1, 2, 1, 0, 0], Sum: 300
Accuracy: 0.12333333333333334
