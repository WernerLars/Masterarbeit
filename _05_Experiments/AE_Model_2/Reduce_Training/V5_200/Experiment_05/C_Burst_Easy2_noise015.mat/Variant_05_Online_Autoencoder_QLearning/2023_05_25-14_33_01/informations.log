Experiment_path: AE_Model_2/Reduce_Training//V5_200/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_200/Experiment_05/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-14_33_01
Punishment_Coefficient: 0.9
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000021A9AA3D898>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/200]: mean_loss=0.2006339505314827
Online_Training [2/200]: mean_loss=0.2430319171398878
Online_Training [3/200]: mean_loss=0.22050213254988194
Online_Training [4/200]: mean_loss=0.08446377236396074
Online_Training [5/200]: mean_loss=0.25137187726795673
Online_Training [6/200]: mean_loss=0.10796177014708519
Online_Training [7/200]: mean_loss=0.11403135862201452
Online_Training [8/200]: mean_loss=0.07530721183866262
Online_Training [9/200]: mean_loss=0.12204575445502996
Online_Training [10/200]: mean_loss=0.15029273927211761
Online_Training [11/200]: mean_loss=0.06494785845279694
Online_Training [12/200]: mean_loss=0.07111447770148516
Online_Training [13/200]: mean_loss=0.08543363772332668
Online_Training [14/200]: mean_loss=0.0352630908600986
Online_Training [15/200]: mean_loss=0.04451932059600949
Online_Training [16/200]: mean_loss=0.12520800530910492
Online_Training [17/200]: mean_loss=0.09295208565890789
Online_Training [18/200]: mean_loss=0.0564671796746552
Online_Training [19/200]: mean_loss=0.026302488055080175
Online_Training [20/200]: mean_loss=0.14758675545454025
Online_Training [21/200]: mean_loss=0.12977823242545128
Online_Training [22/200]: mean_loss=0.019443512661382556
Online_Training [23/200]: mean_loss=0.018300584517419338
Online_Training [24/200]: mean_loss=0.07178271654993296
Online_Training [25/200]: mean_loss=0.03866708232089877
Online_Training [26/200]: mean_loss=0.04723857855424285
Online_Training [27/200]: mean_loss=0.10611386317759752
Online_Training [28/200]: mean_loss=0.035896089393645525
Online_Training [29/200]: mean_loss=0.04460737854242325
Online_Training [30/200]: mean_loss=0.03173204930499196
Online_Training [31/200]: mean_loss=0.028062039287760854
Online_Training [32/200]: mean_loss=0.04436734225600958
Online_Training [33/200]: mean_loss=0.023949507158249617
Online_Training [34/200]: mean_loss=0.14377667382359505
Online_Training [35/200]: mean_loss=0.05411825329065323
Online_Training [36/200]: mean_loss=0.08588493801653385
Online_Training [37/200]: mean_loss=0.05232199653983116
Online_Training [38/200]: mean_loss=0.040948871057480574
Online_Training [39/200]: mean_loss=0.11715704295784235
Online_Training [40/200]: mean_loss=0.033325752476230264
Online_Training [41/200]: mean_loss=0.031153156189247966
Online_Training [42/200]: mean_loss=0.0577699551358819
Online_Training [43/200]: mean_loss=0.11939004436135292
Online_Training [44/200]: mean_loss=0.15081367641687393
Online_Training [45/200]: mean_loss=0.06321040214970708
Online_Training [46/200]: mean_loss=0.03800788428634405
Online_Training [47/200]: mean_loss=0.08822763618081808
Online_Training [48/200]: mean_loss=0.07015220634639263
Online_Training [49/200]: mean_loss=0.09023109171539545
Online_Training [50/200]: mean_loss=0.1199053218588233
Online_Training [51/200]: mean_loss=0.026291385293006897
Online_Training [52/200]: mean_loss=0.16657978668808937
Online_Training [53/200]: mean_loss=0.02095453324727714
Online_Training [54/200]: mean_loss=0.08665870502591133
Online_Training [55/200]: mean_loss=0.03816726943477988
Online_Training [56/200]: mean_loss=0.04069593036547303
Online_Training [57/200]: mean_loss=0.06534491712227464
Online_Training [58/200]: mean_loss=0.3484125882387161
Online_Training [59/200]: mean_loss=0.07024162588641047
Online_Training [60/200]: mean_loss=0.06856631208211184
Online_Training [61/200]: mean_loss=0.05523296119645238
Online_Training [62/200]: mean_loss=0.08747024228796363
Online_Training [63/200]: mean_loss=0.06703915633261204
Online_Training [64/200]: mean_loss=0.00816499680513516
Online_Training [65/200]: mean_loss=0.06413964787498116
Online_Training [66/200]: mean_loss=0.04327953141182661
Online_Training [67/200]: mean_loss=0.061305887065827847
Online_Training [68/200]: mean_loss=0.0730448691174388
Online_Training [69/200]: mean_loss=0.17818692326545715
Online_Training [70/200]: mean_loss=0.03714572498574853
Online_Training [71/200]: mean_loss=0.07513544801622629
Online_Training [72/200]: mean_loss=0.07723300904035568
Online_Training [73/200]: mean_loss=0.04133720276877284
Online_Training [74/200]: mean_loss=0.04172035586088896
Online_Training [75/200]: mean_loss=0.030572673538699746
Online_Training [76/200]: mean_loss=0.04238187009468675
Online_Training [77/200]: mean_loss=0.04193710698746145
Online_Training [78/200]: mean_loss=0.06769988685846329
Online_Training [79/200]: mean_loss=0.04319629538804293
Online_Training [80/200]: mean_loss=0.035978137981146574
Online_Training [81/200]: mean_loss=0.014137008460238576
Online_Training [82/200]: mean_loss=0.029106634203344584
Online_Training [83/200]: mean_loss=0.10961493477225304
Online_Training [84/200]: mean_loss=0.03134161210618913
Online_Training [85/200]: mean_loss=0.023666636552661657
Online_Training [86/200]: mean_loss=0.05738385906443
Online_Training [87/200]: mean_loss=0.013945995247922838
Online_Training [88/200]: mean_loss=0.03137581027112901
Online_Training [89/200]: mean_loss=0.04651913931593299
Online_Training [90/200]: mean_loss=0.02241769223473966
Online_Training [91/200]: mean_loss=0.03718185983598232
Online_Training [92/200]: mean_loss=0.04715253412723541
Online_Training [93/200]: mean_loss=0.058585465885698795
Online_Training [94/200]: mean_loss=0.056631291285157204
Online_Training [95/200]: mean_loss=0.06617959029972553
Online_Training [96/200]: mean_loss=0.020651123370043933
Online_Training [97/200]: mean_loss=0.0560779832303524
Online_Training [98/200]: mean_loss=0.04428124940022826
Online_Training [99/200]: mean_loss=0.01881395443342626
Online_Training [100/200]: mean_loss=0.04375685704872012
Online_Training [101/200]: mean_loss=0.031521196477115154
Online_Training [102/200]: mean_loss=0.058606951497495174
Online_Training [103/200]: mean_loss=0.04588177427649498
Online_Training [104/200]: mean_loss=0.05606377124786377
Online_Training [105/200]: mean_loss=0.03824298968538642
Online_Training [106/200]: mean_loss=0.01496502012014389
Online_Training [107/200]: mean_loss=0.017027721041813493
Online_Training [108/200]: mean_loss=0.031226832885295153
Online_Training [109/200]: mean_loss=0.03681512945331633
Online_Training [110/200]: mean_loss=0.03113732673227787
Online_Training [111/200]: mean_loss=0.029751094989478588
Online_Training [112/200]: mean_loss=0.15565561316907406
Online_Training [113/200]: mean_loss=0.026922553777694702
Online_Training [114/200]: mean_loss=0.05732702696695924
Online_Training [115/200]: mean_loss=0.04295912757515907
Online_Training [116/200]: mean_loss=0.028974503744393587
Online_Training [117/200]: mean_loss=0.05432074470445514
Online_Training [118/200]: mean_loss=0.056795123498886824
Online_Training [119/200]: mean_loss=0.12788630090653896
Online_Training [120/200]: mean_loss=0.06395474309101701
Online_Training [121/200]: mean_loss=0.06745206750929356
Online_Training [122/200]: mean_loss=0.07385201565921307
Online_Training [123/200]: mean_loss=0.035073064267635345
Online_Training [124/200]: mean_loss=0.013005473301745951
Online_Training [125/200]: mean_loss=0.08400718914344907
Online_Training [126/200]: mean_loss=0.039744215086102486
Online_Training [127/200]: mean_loss=0.0693319933488965
Online_Training [128/200]: mean_loss=0.02797252801246941
Online_Training [129/200]: mean_loss=0.03271903400309384
Online_Training [130/200]: mean_loss=0.020516570657491684
Online_Training [131/200]: mean_loss=0.027882908936589956
Online_Training [132/200]: mean_loss=0.018296118592843413
Online_Training [133/200]: mean_loss=0.02529704663902521
Online_Training [134/200]: mean_loss=0.025064500281587243
Online_Training [135/200]: mean_loss=0.10897853318601847
Online_Training [136/200]: mean_loss=0.022181940963491797
Online_Training [137/200]: mean_loss=0.02677396940998733
Online_Training [138/200]: mean_loss=0.011712275561876595
Online_Training [139/200]: mean_loss=0.020239447010681033
Online_Training [140/200]: mean_loss=0.03317991178482771
Online_Training [141/200]: mean_loss=0.030773463426157832
Online_Training [142/200]: mean_loss=0.013160407543182373
Online_Training [143/200]: mean_loss=0.028075278969481587
Online_Training [144/200]: mean_loss=0.014512298861518502
Online_Training [145/200]: mean_loss=0.06288888864219189
Online_Training [146/200]: mean_loss=0.021489011589437723
Online_Training [147/200]: mean_loss=0.016469066846184433
Online_Training [148/200]: mean_loss=0.051110494416207075
Online_Training [149/200]: mean_loss=0.09652089048177004
Online_Training [150/200]: mean_loss=0.11653646174818277
Online_Training [151/200]: mean_loss=0.022119836416095495
Online_Training [152/200]: mean_loss=0.019971338333562016
Online_Training [153/200]: mean_loss=0.05183590669184923
Online_Training [154/200]: mean_loss=0.038561627734452486
Online_Training [155/200]: mean_loss=0.013934488641098142
Online_Training [156/200]: mean_loss=0.020498201483860612
Online_Training [157/200]: mean_loss=0.14889876265078783
Online_Training [158/200]: mean_loss=0.013430431310553104
Online_Training [159/200]: mean_loss=0.018320608651265502
Online_Training [160/200]: mean_loss=0.036105782724916935
Online_Training [161/200]: mean_loss=0.033204405568540096
Online_Training [162/200]: mean_loss=0.015688073355704546
Online_Training [163/200]: mean_loss=0.04933762131258845
Online_Training [164/200]: mean_loss=0.014591657323762774
Online_Training [165/200]: mean_loss=0.010413410607725382
Online_Training [166/200]: mean_loss=0.02153017884120345
Online_Training [167/200]: mean_loss=0.03955838456749916
Online_Training [168/200]: mean_loss=0.04579492565244436
Online_Training [169/200]: mean_loss=0.05121366959065199
Online_Training [170/200]: mean_loss=0.18074725568294525
Online_Training [171/200]: mean_loss=0.020672898273915052
Online_Training [172/200]: mean_loss=0.016595662687905133
Online_Training [173/200]: mean_loss=0.02635489613749087
Online_Training [174/200]: mean_loss=0.013711231877095997
Online_Training [175/200]: mean_loss=0.012496649869717658
Online_Training [176/200]: mean_loss=0.0062939790659584105
Online_Training [177/200]: mean_loss=0.036527652060613036
Online_Training [178/200]: mean_loss=0.03487574029713869
Online_Training [179/200]: mean_loss=0.024289379362016916
Online_Training [180/200]: mean_loss=0.03565683378838003
Online_Training [181/200]: mean_loss=0.03773608151823282
Online_Training [182/200]: mean_loss=0.021283756708726287
Online_Training [183/200]: mean_loss=0.01409360091201961
Online_Training [184/200]: mean_loss=0.008574437350034714
Online_Training [185/200]: mean_loss=0.036075526382774115
Online_Training [186/200]: mean_loss=0.0344013930298388
Online_Training [187/200]: mean_loss=0.026932145236060023
Online_Training [188/200]: mean_loss=0.025777998380362988
Online_Training [189/200]: mean_loss=0.05469953361898661
Online_Training [190/200]: mean_loss=0.023901014123111963
Online_Training [191/200]: mean_loss=0.15187152661383152
Online_Training [192/200]: mean_loss=0.021969560300931334
Online_Training [193/200]: mean_loss=0.0242291996255517
Online_Training [194/200]: mean_loss=0.021388118620961905
Online_Training [195/200]: mean_loss=0.0234365938231349
Online_Training [196/200]: mean_loss=0.014048067037947476
Online_Training [197/200]: mean_loss=0.04716943670064211
Online_Training [198/200]: mean_loss=0.015883205691352487
Online_Training [199/200]: mean_loss=0.08217114489525557
Online_Training [200/200]: mean_loss=0.018270117812789977
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.27147797 -1.4523801 ]
[1, 2, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 1, 0, 1, 2, 0, 0, 2, 2, 2, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 0, 2, 0, 1, 2, 2, 1, 1, 1, 2, 0, 1, 0, 2, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 2, 1, 1, 2, 0, 2, 2, 2, 0, 2, 2, 1, 0, 0, 0, 2, 2, 2, 1, 2, 2, 1, 0, 2, 2, 1, 0, 0, 1, 0, 0, 0, 2, 2, 0, 1, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 2, 0, 1, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 0, 1, 0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 1, 1, 0, 0, 1, 2, 0, 2, 1, 0, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 0, 2, 1, 1, 2, 0, 2, 1, 0, 0, 1, 2, 2, 0, 1, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2, 0, 2]
[0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 0, 2, 3, 0, 0, 3, 3, 1, 2, 0, 0, 0, 0, 1, 3, 2, 0, 1, 2, 2, 4, 0, 3, 1, 4, 2, 3, 0, 3, 0, 2, 2, 2, 0, 5, 2, 1, 0, 1, 2, 0, 3, 0, 0, 1, 3, 2, 0, 2, 3, 0, 2, 0, 1, 0, 0, 3, 2, 3, 1, 2, 2, 2, 0, 3, 2, 0, 3, 0, 3, 3, 3, 4, 1, 1, 0, 0, 0, 0, 3, 2, 3, 2, 1, 3, 2, 0, 3, 3, 2, 0, 0, 2, 0, 0, 0, 1, 3, 0, 2, 0, 0, 2, 0, 0, 2, 3, 1, 3, 4, 1, 1, 2, 0, 2, 1, 3, 0, 1, 4, 0, 2, 4, 2, 1, 3, 1, 0, 0, 0, 0, 2, 2, 3, 4, 3, 0, 4, 4, 2, 2, 2, 4, 0, 0, 3, 3, 3, 4, 0, 1, 3, 2, 0, 0, 2, 3, 4, 2, 0, 0, 0, 4, 0, 3, 0, 0, 3, 0, 0, 1, 0, 2, 0, 2, 2, 3, 2, 3, 2, 0, 1, 2, 2, 2, 0, 2, 0, 1, 4, 4, 3, 2, 3, 2, 2, 2, 2, 1, 0, 2, 3, 4, 0, 0, 3, 0, 4, 2, 0, 1, 0, 1, 1, 2, 2, 0, 0, 2, 3, 0, 1, 2, 0, 2, 2, 2, 4, 3, 3, 0, 3, 2, 3, 1, 1, 2, 2, 1, 1, 2, 4, 0, 3, 2, 2, 3, 0, 3, 2, 4, 4, 0, 3, 3, 4, 2, 0, 1, 3, 0, 2, 4, 2, 2, 3, 1, 2, 0, 2, 2, 1, 2, 3, 2, 1, 3, 0, 1, 4, 5, 3, 1, 4, 3, 0, 1]
Centroids: [[-1.6888404, -2.218462], [-0.23332207, -1.7679737], [1.9561666, -0.23464845]]
Centroids: [[-1.396562, -2.1292937], [1.4730431, -0.25423592], [-0.10594394, -1.6925437], [2.3684597, -0.15366587], [-2.3303592, -2.4648924], [1.2316961, -2.2736406]]
Standard Derivations: [0.38787276, 0.4209763, 0.5073319]
Cluster Distances: [0.7147893, 3.2546859, 0.7147892, 1.744695, 3.2546859, 1.7446951]
Minimal Cluster Distance: 0.7147892117500305
Contingency Matrix: 
[[74  1  3  0 24  0]
 [17  0 74  0  1  2]
 [ 0 42  4 58  0  0]]
[[74, 1, 3, 0, 24, 0], [17, 0, 74, 0, 1, 2], [0, 42, 4, 58, 0, 0]]
[[74, 1, 3, 0, 24, 0], [17, 0, 74, 0, 1, 2], [0, 42, 4, 58, 0, 0]]
[0, 1, 2, 3, 4, 5]
[[-1, -1, -1, -1, -1, -1], [-1, 0, 74, 0, 1, 2], [-1, 42, 4, 58, 0, 0]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [-1, 42, -1, 58, 0, 0]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 0, 1: 2, 2: 3}
New Contingency Matrix: 
[[74  3  0  1 24  0]
 [17 74  0  0  1  2]
 [ 0  4 58 42  0  0]]
New Clustered Label Sequence: [0, 2, 3, 1, 4, 5]
Diagonal_Elements: [74, 74, 58], Sum: 206
All_Elements: [74, 3, 0, 1, 24, 0, 17, 74, 0, 0, 1, 2, 0, 4, 58, 42, 0, 0], Sum: 300
Accuracy: 0.6866666666666666
