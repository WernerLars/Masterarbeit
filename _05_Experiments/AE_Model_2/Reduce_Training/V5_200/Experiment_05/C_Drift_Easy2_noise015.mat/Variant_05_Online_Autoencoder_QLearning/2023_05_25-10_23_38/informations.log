Experiment_path: AE_Model_2/Reduce_Training//V5_200/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_200/Experiment_05/C_Drift_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-10_23_38
Punishment_Coefficient: 1.1
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002358792CEF0>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
Number of Clusters: 3
Online_Training [1/200]: mean_loss=0.1386891845613718
Online_Training [2/200]: mean_loss=0.1497445497661829
Online_Training [3/200]: mean_loss=0.2779655270278454
Online_Training [4/200]: mean_loss=0.1383659914135933
Online_Training [5/200]: mean_loss=0.14062516763806343
Online_Training [6/200]: mean_loss=0.11520449724048376
Online_Training [7/200]: mean_loss=0.03626192221418023
Online_Training [8/200]: mean_loss=0.0901311868801713
Online_Training [9/200]: mean_loss=0.1226275758817792
Online_Training [10/200]: mean_loss=0.08810629043728113
Online_Training [11/200]: mean_loss=0.05878388276323676
Online_Training [12/200]: mean_loss=0.03977879602462053
Online_Training [13/200]: mean_loss=0.09639801923185587
Online_Training [14/200]: mean_loss=0.14839691296219826
Online_Training [15/200]: mean_loss=0.0852551069110632
Online_Training [16/200]: mean_loss=0.076807064935565
Online_Training [17/200]: mean_loss=0.058581402990967035
Online_Training [18/200]: mean_loss=0.09216954093426466
Online_Training [19/200]: mean_loss=0.0379923521541059
Online_Training [20/200]: mean_loss=0.06016507092863321
Online_Training [21/200]: mean_loss=0.033609868958592415
Online_Training [22/200]: mean_loss=0.10138948913663626
Online_Training [23/200]: mean_loss=0.03482343070209026
Online_Training [24/200]: mean_loss=0.05260655423626304
Online_Training [25/200]: mean_loss=0.06338182743638754
Online_Training [26/200]: mean_loss=0.1542759370058775
Online_Training [27/200]: mean_loss=0.10424620658159256
Online_Training [28/200]: mean_loss=0.1026335870847106
Online_Training [29/200]: mean_loss=0.04172274889424443
Online_Training [30/200]: mean_loss=0.0990932947024703
Online_Training [31/200]: mean_loss=0.1135997911915183
Online_Training [32/200]: mean_loss=0.05867856368422508
Online_Training [33/200]: mean_loss=0.023510202765464783
Online_Training [34/200]: mean_loss=0.04083793517202139
Online_Training [35/200]: mean_loss=0.048160846810787916
Online_Training [36/200]: mean_loss=0.03938200371339917
Online_Training [37/200]: mean_loss=0.08847056329250336
Online_Training [38/200]: mean_loss=0.1424392145127058
Online_Training [39/200]: mean_loss=0.1286744438111782
Online_Training [40/200]: mean_loss=0.04801238002255559
Online_Training [41/200]: mean_loss=0.048298731446266174
Online_Training [42/200]: mean_loss=0.013975822017528117
Online_Training [43/200]: mean_loss=0.11654714122414589
Online_Training [44/200]: mean_loss=0.03709075786173344
Online_Training [45/200]: mean_loss=0.022186013171449304
Online_Training [46/200]: mean_loss=0.04031105153262615
Online_Training [47/200]: mean_loss=0.02182466513477266
Online_Training [48/200]: mean_loss=0.046980857849121094
Online_Training [49/200]: mean_loss=0.049511362332850695
Online_Training [50/200]: mean_loss=0.04064651299268007
Online_Training [51/200]: mean_loss=0.07195530366152525
Online_Training [52/200]: mean_loss=0.02545077702961862
Online_Training [53/200]: mean_loss=0.10789504088461399
Online_Training [54/200]: mean_loss=0.020545597886666656
Online_Training [55/200]: mean_loss=0.0438411277718842
Online_Training [56/200]: mean_loss=0.016564278746955097
Online_Training [57/200]: mean_loss=0.03564262203872204
Online_Training [58/200]: mean_loss=0.045573145151138306
Online_Training [59/200]: mean_loss=0.08358924090862274
Online_Training [60/200]: mean_loss=0.09910212643444538
Online_Training [61/200]: mean_loss=0.0496137673035264
Online_Training [62/200]: mean_loss=0.13169045001268387
Online_Training [63/200]: mean_loss=0.057230036705732346
Online_Training [64/200]: mean_loss=0.033875648165121675
Online_Training [65/200]: mean_loss=0.027812812011688948
Online_Training [66/200]: mean_loss=0.06358882831409574
Online_Training [67/200]: mean_loss=0.04362253472208977
Online_Training [68/200]: mean_loss=0.0531936502084136
Online_Training [69/200]: mean_loss=0.04999755695462227
Online_Training [70/200]: mean_loss=0.019571253331378102
Online_Training [71/200]: mean_loss=0.009841717663221061
Online_Training [72/200]: mean_loss=0.04190941248089075
Online_Training [73/200]: mean_loss=0.034238401567563415
Online_Training [74/200]: mean_loss=0.06379625434055924
Online_Training [75/200]: mean_loss=0.014792058616876602
Online_Training [76/200]: mean_loss=0.05527726840227842
Online_Training [77/200]: mean_loss=0.02331985766068101
Online_Training [78/200]: mean_loss=0.049761611968278885
Online_Training [79/200]: mean_loss=0.10654414631426334
Online_Training [80/200]: mean_loss=0.07881140895187855
Online_Training [81/200]: mean_loss=0.01623241521883756
Online_Training [82/200]: mean_loss=0.04849237110465765
Online_Training [83/200]: mean_loss=0.036528876051306725
Online_Training [84/200]: mean_loss=0.020957248052582145
Online_Training [85/200]: mean_loss=0.05747340666130185
Online_Training [86/200]: mean_loss=0.016773576266132295
Online_Training [87/200]: mean_loss=0.12566499132663012
Online_Training [88/200]: mean_loss=0.038180158007889986
Online_Training [89/200]: mean_loss=0.030290013877674937
Online_Training [90/200]: mean_loss=0.06181915896013379
Online_Training [91/200]: mean_loss=0.01872201939113438
Online_Training [92/200]: mean_loss=0.017286726739257574
Online_Training [93/200]: mean_loss=0.056962916161864996
Online_Training [94/200]: mean_loss=0.018101069377735257
Online_Training [95/200]: mean_loss=0.010587218566797674
Online_Training [96/200]: mean_loss=0.05456191347911954
Online_Training [97/200]: mean_loss=0.021622053114697337
Online_Training [98/200]: mean_loss=0.00993971707066521
Online_Training [99/200]: mean_loss=0.11166264954954386
Online_Training [100/200]: mean_loss=0.04974474245682359
Online_Training [101/200]: mean_loss=0.029735549120232463
Online_Training [102/200]: mean_loss=0.015328453271649778
Online_Training [103/200]: mean_loss=0.027933738427236676
Online_Training [104/200]: mean_loss=0.016806813539005816
Online_Training [105/200]: mean_loss=0.00818157836329192
Online_Training [106/200]: mean_loss=0.013953607762232423
Online_Training [107/200]: mean_loss=0.00979380082571879
Online_Training [108/200]: mean_loss=0.022784008644521236
Online_Training [109/200]: mean_loss=0.01001479709520936
Online_Training [110/200]: mean_loss=0.03147562243975699
Online_Training [111/200]: mean_loss=0.03575822548009455
Online_Training [112/200]: mean_loss=0.00517306721303612
Online_Training [113/200]: mean_loss=0.018297819420695305
Online_Training [114/200]: mean_loss=0.02662260178476572
Online_Training [115/200]: mean_loss=0.02882001013495028
Online_Training [116/200]: mean_loss=0.021098067285493016
Online_Training [117/200]: mean_loss=0.035807478008791804
Online_Training [118/200]: mean_loss=0.013046544627286494
Online_Training [119/200]: mean_loss=0.14509966038167477
Online_Training [120/200]: mean_loss=0.12482766155153513
Online_Training [121/200]: mean_loss=0.10644058417528868
Online_Training [122/200]: mean_loss=0.1576990783214569
Online_Training [123/200]: mean_loss=0.04603720991872251
Online_Training [124/200]: mean_loss=0.06572446506470442
Online_Training [125/200]: mean_loss=0.05696090729907155
Online_Training [126/200]: mean_loss=0.01865440676920116
Online_Training [127/200]: mean_loss=0.05164021113887429
Online_Training [128/200]: mean_loss=0.03745573200285435
Online_Training [129/200]: mean_loss=0.07867278158664703
Online_Training [130/200]: mean_loss=0.03604480158537626
Online_Training [131/200]: mean_loss=0.0996980108320713
Online_Training [132/200]: mean_loss=0.016423375462181866
Online_Training [133/200]: mean_loss=0.04018240957520902
Online_Training [134/200]: mean_loss=0.015793175320141017
Online_Training [135/200]: mean_loss=0.035141681553795934
Online_Training [136/200]: mean_loss=0.013029851368628442
Online_Training [137/200]: mean_loss=0.02318241586908698
Online_Training [138/200]: mean_loss=0.028753849677741528
Online_Training [139/200]: mean_loss=0.008333133708219975
Online_Training [140/200]: mean_loss=0.016547851730138063
Online_Training [141/200]: mean_loss=0.009036323754116893
Online_Training [142/200]: mean_loss=0.021532091544941068
Online_Training [143/200]: mean_loss=0.06175365811213851
Online_Training [144/200]: mean_loss=0.050393758341670036
Online_Training [145/200]: mean_loss=0.033674301113933325
Online_Training [146/200]: mean_loss=0.06076376512646675
Online_Training [147/200]: mean_loss=0.0398036097176373
Online_Training [148/200]: mean_loss=0.015778350760228932
Online_Training [149/200]: mean_loss=0.039403229020535946
Online_Training [150/200]: mean_loss=0.02458388963714242
Online_Training [151/200]: mean_loss=0.013176409876905382
Online_Training [152/200]: mean_loss=0.015859418781474233
Online_Training [153/200]: mean_loss=0.013367806212045252
Online_Training [154/200]: mean_loss=0.08448120672255754
Online_Training [155/200]: mean_loss=0.02171203913167119
Online_Training [156/200]: mean_loss=0.05749441357329488
Online_Training [157/200]: mean_loss=0.04519463609904051
Online_Training [158/200]: mean_loss=0.018660938600078225
Online_Training [159/200]: mean_loss=0.004743648634757847
Online_Training [160/200]: mean_loss=0.024772884557023644
Online_Training [161/200]: mean_loss=0.02676260587759316
Online_Training [162/200]: mean_loss=0.015987329534254968
Online_Training [163/200]: mean_loss=0.02849179646000266
Online_Training [164/200]: mean_loss=0.019784142379648983
Online_Training [165/200]: mean_loss=0.014111656579189003
Online_Training [166/200]: mean_loss=0.03800779627636075
Online_Training [167/200]: mean_loss=0.035923253279179335
Online_Training [168/200]: mean_loss=0.01830149325542152
Online_Training [169/200]: mean_loss=0.018970091361552477
Online_Training [170/200]: mean_loss=0.034882755018770695
Online_Training [171/200]: mean_loss=0.015426412457600236
Online_Training [172/200]: mean_loss=0.027884915005415678
Online_Training [173/200]: mean_loss=0.010213752626441419
Online_Training [174/200]: mean_loss=0.01859465939924121
Online_Training [175/200]: mean_loss=0.01843697566073388
Online_Training [176/200]: mean_loss=0.020177611149847507
Online_Training [177/200]: mean_loss=0.03721404494717717
Online_Training [178/200]: mean_loss=0.021728168707340956
Online_Training [179/200]: mean_loss=0.03867259109392762
Online_Training [180/200]: mean_loss=0.014111812692135572
Online_Training [181/200]: mean_loss=0.017574308905750513
Online_Training [182/200]: mean_loss=0.014115531463176012
Online_Training [183/200]: mean_loss=0.01442002400290221
Online_Training [184/200]: mean_loss=0.015493680257350206
Online_Training [185/200]: mean_loss=0.018929218058474362
Online_Training [186/200]: mean_loss=0.04988692980259657
Online_Training [187/200]: mean_loss=0.015777758439071476
Online_Training [188/200]: mean_loss=0.031781579833477736
Online_Training [189/200]: mean_loss=0.049793666228652
Online_Training [190/200]: mean_loss=0.011383047443814576
Online_Training [191/200]: mean_loss=0.024103828938677907
Online_Training [192/200]: mean_loss=0.03693155851215124
Online_Training [193/200]: mean_loss=0.04365531960502267
Online_Training [194/200]: mean_loss=0.028421754948794842
Online_Training [195/200]: mean_loss=0.03043316025286913
Online_Training [196/200]: mean_loss=0.022138883359730244
Online_Training [197/200]: mean_loss=0.02656226302497089
Online_Training [198/200]: mean_loss=0.008416979340836406
Online_Training [199/200]: mean_loss=0.01186742028221488
Online_Training [200/200]: mean_loss=0.014396533952094615
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-1.6889871 -1.928938 ]
[0, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 0, 0, 2, 2, 1, 2, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1, 2, 0, 0, 2, 0, 1, 2, 2, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 2, 0, 1, 0, 2, 0, 2, 1, 1, 1, 2, 1, 0, 2, 1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 2, 0, 0, 2, 2, 1, 0, 1, 0, 2, 1, 1, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 0, 1, 1, 2, 0, 1, 2, 0, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 0, 0, 2, 0, 1, 0, 2, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 2, 1, 2, 1, 1, 0, 1, 0, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 1, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0]
[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 0, 1, 0, 2, 1, 0, 2, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 1, 2, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 0, 0, 1, 1, 0, 2, 0, 2, 1, 0, 0, 1, 2, 0, 2, 3, 2, 0, 1, 1, 0, 2, 0, 0, 3, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 2, 0, 0, 1, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 2, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 1, 0, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 1, 0, 0, 1, 0, 1, 0, 2, 0, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0, 2, 2, 1, 1, 0, 2, 1, 1, 1, 0, 2, 2, 1, 1, 0, 2, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 0, 1, 0, 1, 2]
Centroids: [[-2.0108776, -1.9449784], [-1.1688796, -0.99523133], [-1.4273186, 2.0630157]]
Centroids: [[-1.2634621, -1.1123445], [-1.4057602, 2.0008407], [-2.2209618, -2.2262297], [-3.207656, 4.545426]]
Standard Derivations: [0.40427494, 0.4508916, 0.46295518]
Cluster Distances: [0.41407728, 3.1830242, 0.41407728, 2.1553009, 3.1830242, 2.1553006]
Minimal Cluster Distance: 0.4140772819519043
Contingency Matrix: 
[[ 38   0  54   0]
 [106   1   5   0]
 [  0  94   0   2]]
[[38, 0, 54, 0], [106, 1, 5, 0], [0, 94, 0, 2]]
[[38, 0, 54, 0], [106, 1, 5, 0], [0, 94, 0, 2]]
[0, 1, 2, 3]
[[-1, 0, 54, 0], [-1, -1, -1, -1], [-1, 94, 0, 2]]
[[-1, -1, 54, 0], [-1, -1, -1, -1], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {1: 0, 2: 1, 0: 2}
New Contingency Matrix: 
[[ 54  38   0   0]
 [  5 106   1   0]
 [  0   0  94   2]]
New Clustered Label Sequence: [2, 0, 1, 3]
Diagonal_Elements: [54, 106, 94], Sum: 254
All_Elements: [54, 38, 0, 0, 5, 106, 1, 0, 0, 0, 94, 2], Sum: 300
Accuracy: 0.8466666666666667
