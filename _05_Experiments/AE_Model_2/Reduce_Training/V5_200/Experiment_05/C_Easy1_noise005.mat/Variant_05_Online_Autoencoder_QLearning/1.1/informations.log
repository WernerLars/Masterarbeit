Experiment_path: AE_Model_2/Reduce_Training//V5_200/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_200/Experiment_05/C_Easy1_noise005.mat/Variant_05_Online_Autoencoder_QLearning/1.1
Punishment_Coefficient: 1.1
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000216A69D9AC8>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
Number of Clusters: 3
Online_Training [1/200]: mean_loss=0.12203092779964209
Online_Training [2/200]: mean_loss=0.0931862648576498
Online_Training [3/200]: mean_loss=0.31805216521024704
Online_Training [4/200]: mean_loss=0.297378022223711
Online_Training [5/200]: mean_loss=0.34334487840533257
Online_Training [6/200]: mean_loss=0.1183405527845025
Online_Training [7/200]: mean_loss=0.08711644075810909
Online_Training [8/200]: mean_loss=0.329997181892395
Online_Training [9/200]: mean_loss=0.09089411050081253
Online_Training [10/200]: mean_loss=0.08787775412201881
Online_Training [11/200]: mean_loss=0.07912520878016949
Online_Training [12/200]: mean_loss=0.07762576546519995
Online_Training [13/200]: mean_loss=0.0622808369807899
Online_Training [14/200]: mean_loss=0.13065756671130657
Online_Training [15/200]: mean_loss=0.26100360229611397
Online_Training [16/200]: mean_loss=0.12043617386370897
Online_Training [17/200]: mean_loss=0.2286447063088417
Online_Training [18/200]: mean_loss=0.1264693532139063
Online_Training [19/200]: mean_loss=0.07507376559078693
Online_Training [20/200]: mean_loss=0.05810216115787625
Online_Training [21/200]: mean_loss=0.08189860358834267
Online_Training [22/200]: mean_loss=0.1031818613409996
Online_Training [23/200]: mean_loss=0.0755965025164187
Online_Training [24/200]: mean_loss=0.027393420226871967
Online_Training [25/200]: mean_loss=0.09952157828956842
Online_Training [26/200]: mean_loss=0.07595342304557562
Online_Training [27/200]: mean_loss=0.06672346545383334
Online_Training [28/200]: mean_loss=0.0490247905254364
Online_Training [29/200]: mean_loss=0.048591998871415854
Online_Training [30/200]: mean_loss=0.015938426135107875
Online_Training [31/200]: mean_loss=0.06965378625318408
Online_Training [32/200]: mean_loss=0.012540768249891698
Online_Training [33/200]: mean_loss=0.008130267320666462
Online_Training [34/200]: mean_loss=0.04670473374426365
Online_Training [35/200]: mean_loss=0.006543702271301299
Online_Training [36/200]: mean_loss=0.09134126733988523
Online_Training [37/200]: mean_loss=0.021507256431505084
Online_Training [38/200]: mean_loss=0.026870762929320335
Online_Training [39/200]: mean_loss=0.0063714138232171535
Online_Training [40/200]: mean_loss=0.014921598485670984
Online_Training [41/200]: mean_loss=0.01079490757547319
Online_Training [42/200]: mean_loss=0.012578738620504737
Online_Training [43/200]: mean_loss=0.012706472771242261
Online_Training [44/200]: mean_loss=0.0028880933386972174
Online_Training [45/200]: mean_loss=0.01758958538994193
Online_Training [46/200]: mean_loss=0.007737124047707766
Online_Training [47/200]: mean_loss=0.07674396829679608
Online_Training [48/200]: mean_loss=0.07023495528846979
Online_Training [49/200]: mean_loss=0.007919178431620821
Online_Training [50/200]: mean_loss=0.0209225055295974
Online_Training [51/200]: mean_loss=0.007683334319153801
Online_Training [52/200]: mean_loss=0.0030892193026375026
Online_Training [53/200]: mean_loss=0.06921925395727158
Online_Training [54/200]: mean_loss=0.2015184499323368
Online_Training [55/200]: mean_loss=0.03383738617412746
Online_Training [56/200]: mean_loss=0.025460192700847983
Online_Training [57/200]: mean_loss=0.020284791011363268
Online_Training [58/200]: mean_loss=0.007941041025333107
Online_Training [59/200]: mean_loss=0.11421282775700092
Online_Training [60/200]: mean_loss=0.015304755070246756
Online_Training [61/200]: mean_loss=0.015768938581459224
Online_Training [62/200]: mean_loss=0.011719986447133124
Online_Training [63/200]: mean_loss=0.0018264470272697508
Online_Training [64/200]: mean_loss=0.0017685739730950445
Online_Training [65/200]: mean_loss=0.011415616958402097
Online_Training [66/200]: mean_loss=0.003790350310737267
Online_Training [67/200]: mean_loss=0.0025938300241250545
Online_Training [68/200]: mean_loss=0.07997014047577977
Online_Training [69/200]: mean_loss=0.005387542594689876
Online_Training [70/200]: mean_loss=0.0068326121545396745
Online_Training [71/200]: mean_loss=0.0019226814183639362
Online_Training [72/200]: mean_loss=0.007583118393085897
Online_Training [73/200]: mean_loss=0.002294769656145945
Online_Training [74/200]: mean_loss=0.0021047447517048568
Online_Training [75/200]: mean_loss=0.006164929596707225
Online_Training [76/200]: mean_loss=0.000674370807246305
Online_Training [77/200]: mean_loss=0.0017623755556996912
Online_Training [78/200]: mean_loss=0.0059223073767498136
Online_Training [79/200]: mean_loss=0.02058813744224608
Online_Training [80/200]: mean_loss=0.009670862113125622
Online_Training [81/200]: mean_loss=0.004684887069743127
Online_Training [82/200]: mean_loss=0.008785084704868495
Online_Training [83/200]: mean_loss=0.006259198184125125
Online_Training [84/200]: mean_loss=0.0022994791361270472
Online_Training [85/200]: mean_loss=0.004838208551518619
Online_Training [86/200]: mean_loss=0.010193676280323416
Online_Training [87/200]: mean_loss=0.003285627521108836
Online_Training [88/200]: mean_loss=0.013416142552159727
Online_Training [89/200]: mean_loss=0.003752735850866884
Online_Training [90/200]: mean_loss=0.006647070404142141
Online_Training [91/200]: mean_loss=0.0056008470710366964
Online_Training [92/200]: mean_loss=0.005320414202287793
Online_Training [93/200]: mean_loss=0.0014485380379483104
Online_Training [94/200]: mean_loss=0.003323216369608417
Online_Training [95/200]: mean_loss=0.001634342726902105
Online_Training [96/200]: mean_loss=0.005306373466737568
Online_Training [97/200]: mean_loss=0.005369988328311592
Online_Training [98/200]: mean_loss=0.0028850214439444244
Online_Training [99/200]: mean_loss=0.00393942859955132
Online_Training [100/200]: mean_loss=0.0008798450726317242
Online_Training [101/200]: mean_loss=0.0029317894659470767
Online_Training [102/200]: mean_loss=0.0033757791097741574
Online_Training [103/200]: mean_loss=0.008463712118100375
Online_Training [104/200]: mean_loss=0.004253039252944291
Online_Training [105/200]: mean_loss=0.019237485015764832
Online_Training [106/200]: mean_loss=0.016753169475123286
Online_Training [107/200]: mean_loss=0.005273351867799647
Online_Training [108/200]: mean_loss=0.009485549759119749
Online_Training [109/200]: mean_loss=0.010705141176003963
Online_Training [110/200]: mean_loss=0.00683646573452279
Online_Training [111/200]: mean_loss=0.0048384110268671066
Online_Training [112/200]: mean_loss=0.0038492492749355733
Online_Training [113/200]: mean_loss=0.006306650000624359
Online_Training [114/200]: mean_loss=0.0030338859069161117
Online_Training [115/200]: mean_loss=0.012874627485871315
Online_Training [116/200]: mean_loss=0.0018075316183967516
Online_Training [117/200]: mean_loss=0.003615634923335165
Online_Training [118/200]: mean_loss=0.002869071759050712
Online_Training [119/200]: mean_loss=0.003200821054633707
Online_Training [120/200]: mean_loss=0.006353940698318183
Online_Training [121/200]: mean_loss=0.0020865823898930103
Online_Training [122/200]: mean_loss=0.00941713631618768
Online_Training [123/200]: mean_loss=0.0005165708062122576
Online_Training [124/200]: mean_loss=0.009375505120260641
Online_Training [125/200]: mean_loss=0.0040382247971137986
Online_Training [126/200]: mean_loss=0.0019983357342425734
Online_Training [127/200]: mean_loss=0.005924240511376411
Online_Training [128/200]: mean_loss=0.00942013319581747
Online_Training [129/200]: mean_loss=0.0038585983274970204
Online_Training [130/200]: mean_loss=0.004480482719372958
Online_Training [131/200]: mean_loss=0.003806793421972543
Online_Training [132/200]: mean_loss=0.010431374539621174
Online_Training [133/200]: mean_loss=0.0038689736102242023
Online_Training [134/200]: mean_loss=0.01543070503976196
Online_Training [135/200]: mean_loss=0.007429225865053013
Online_Training [136/200]: mean_loss=0.001400843873852864
Online_Training [137/200]: mean_loss=0.005691270693205297
Online_Training [138/200]: mean_loss=0.0016625457647023723
Online_Training [139/200]: mean_loss=0.001800680547603406
Online_Training [140/200]: mean_loss=0.0016551887965761125
Online_Training [141/200]: mean_loss=0.0022657115187030286
Online_Training [142/200]: mean_loss=0.005571186076849699
Online_Training [143/200]: mean_loss=0.06558709568344057
Online_Training [144/200]: mean_loss=0.01989270420745015
Online_Training [145/200]: mean_loss=0.06539452588185668
Online_Training [146/200]: mean_loss=0.21638780646026134
Online_Training [147/200]: mean_loss=0.020259996177628636
Online_Training [148/200]: mean_loss=0.010850432212464511
Online_Training [149/200]: mean_loss=0.004788517020642757
Online_Training [150/200]: mean_loss=0.0856213141232729
Online_Training [151/200]: mean_loss=0.2837612181901932
Online_Training [152/200]: mean_loss=0.014596345485188067
Online_Training [153/200]: mean_loss=0.012506394064985216
Online_Training [154/200]: mean_loss=0.006519272166769952
Online_Training [155/200]: mean_loss=0.040842898190021515
Online_Training [156/200]: mean_loss=0.02216844609938562
Online_Training [157/200]: mean_loss=0.005725189461372793
Online_Training [158/200]: mean_loss=0.021348209818825126
Online_Training [159/200]: mean_loss=0.006050312687875703
Online_Training [160/200]: mean_loss=0.013716899673454463
Online_Training [161/200]: mean_loss=0.0042391135066282
Online_Training [162/200]: mean_loss=0.05173009913414717
Online_Training [163/200]: mean_loss=0.14234752021729946
Online_Training [164/200]: mean_loss=0.01568647613748908
Online_Training [165/200]: mean_loss=0.009312510723248124
Online_Training [166/200]: mean_loss=0.025287078460678458
Online_Training [167/200]: mean_loss=0.00825723831076175
Online_Training [168/200]: mean_loss=0.007017112919129431
Online_Training [169/200]: mean_loss=0.0017409864958608523
Online_Training [170/200]: mean_loss=0.004224601056193933
Online_Training [171/200]: mean_loss=0.012251887237653136
Online_Training [172/200]: mean_loss=0.02090983302332461
Online_Training [173/200]: mean_loss=0.02633884083479643
Online_Training [174/200]: mean_loss=0.008236137160565704
Online_Training [175/200]: mean_loss=0.017936445539817214
Online_Training [176/200]: mean_loss=0.0015452778025064617
Online_Training [177/200]: mean_loss=0.006525565142510459
Online_Training [178/200]: mean_loss=0.004786849371157587
Online_Training [179/200]: mean_loss=0.007598863099701703
Online_Training [180/200]: mean_loss=0.008565956028178334
Online_Training [181/200]: mean_loss=0.003398795408429578
Online_Training [182/200]: mean_loss=0.002598536972072907
Online_Training [183/200]: mean_loss=0.004764192213770002
Online_Training [184/200]: mean_loss=0.0036002065462525934
Online_Training [185/200]: mean_loss=0.004514160216785967
Online_Training [186/200]: mean_loss=0.002921095583587885
Online_Training [187/200]: mean_loss=0.0018637716566445306
Online_Training [188/200]: mean_loss=0.08752061426639557
Online_Training [189/200]: mean_loss=0.10405462514609098
Online_Training [190/200]: mean_loss=0.01561755279544741
Online_Training [191/200]: mean_loss=0.06012956704944372
Online_Training [192/200]: mean_loss=0.025026530027389526
Online_Training [193/200]: mean_loss=0.01271014113444835
Online_Training [194/200]: mean_loss=0.02263563498854637
Online_Training [195/200]: mean_loss=0.009625272417906672
Online_Training [196/200]: mean_loss=0.005698388442397118
Online_Training [197/200]: mean_loss=0.0051528908661566675
Online_Training [198/200]: mean_loss=0.007615544425789267
Online_Training [199/200]: mean_loss=0.010382022242993116
Online_Training [200/200]: mean_loss=0.0068147198762744665
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 0.26967597 -1.7447212 ]
[1, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 1, 2, 1, 2, 1, 0, 2, 2, 2, 0, 1, 0, 2, 0, 0, 1, 1, 0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 0, 2, 2, 1, 0, 2, 2, 2, 0, 1, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 2, 0, 2, 2, 1, 1, 1, 1, 2, 1, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 0, 2, 1, 0, 1, 2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 2, 0, 1, 1, 2, 1, 2, 1, 0, 1, 0, 1, 0, 0, 2, 1, 1, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 1, 2, 1, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2, 1, 1, 0, 1, 0, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 2, 0, 2, 2, 1, 1, 1, 2, 0, 2, 1, 1, 2, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1, 2, 1, 1, 0]
[0, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 0, 2, 0, 2, 0, 1, 2, 2, 2, 1, 0, 1, 2, 1, 1, 0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 2, 1, 0, 2, 1, 2, 1, 2, 1, 1, 2, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 0, 0, 1, 2, 1, 0, 2, 2, 1, 1, 1, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 1, 1, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, 2, 2, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 0, 0, 1, 1, 1, 2, 0, 1, 2, 1, 2, 0, 0, 1, 0, 1, 1, 0, 2, 2, 0, 0, 2, 0, 1, 2, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 2, 2, 2, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 1, 2, 2, 0, 0, 0, 2, 1, 2, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 3, 1, 0, 0, 1, 0, 0, 1, 2, 0, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0, 1, 0, 0, 2, 0, 1, 2, 0, 2, 0, 0, 2, 0, 0, 1]
Centroids: [[-1.1232202, 1.4385823], [0.28696567, -1.8662789], [2.0647223, 2.953588]]
Centroids: [[0.23757225, -1.8472537], [-1.1544031, 1.4513353], [2.0568254, 2.942351], [2.403655, -2.00963]]
Contingency Matrix: 
[[  1 100   1   0]
 [ 99   0   0   2]
 [  0   0  97   0]]
[[1, 100, 1, 0], [99, 0, 0, 2], [0, 0, 97, 0]]
[[1, 100, 1, 0], [99, 0, 0, 2], [0, 0, 97, 0]]
[0, 1, 2, 3]
[[-1, -1, -1, -1], [99, -1, 0, 2], [0, -1, 97, 0]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, 97, 0]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {0: 1, 1: 0, 2: 2}
New Contingency Matrix: 
[[100   1   1   0]
 [  0  99   0   2]
 [  0   0  97   0]]
New Clustered Label Sequence: [1, 0, 2, 3]
Diagonal_Elements: [100, 99, 97], Sum: 296
All_Elements: [100, 1, 1, 0, 0, 99, 0, 2, 0, 0, 97, 0], Sum: 300
Accuracy: 0.9866666666666667
