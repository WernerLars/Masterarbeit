Experiment_path: AE_Model_2/Reduce_Training//V5_100/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise020.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_100/Experiment_05/C_Easy1_noise020.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-10_23_12
Punishment_Coefficient: 1.1
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002C4D5B6BEB8>
Sampling rate: 24000.0
Raw: [-0.20218342 -0.1653919  -0.13236941 ...  0.26695674  0.20113134
  0.13708332]
Times: [    553     927    1270 ... 1437880 1438309 1439004]
Cluster: [1 2 2 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3474
First aligned Spike Frame: [-0.02428298 -0.07468906 -0.10332709 -0.10788142 -0.10649267 -0.11021489
 -0.10987225 -0.08885562 -0.04921868 -0.01240992  0.01146155  0.01660937
  0.02581569  0.2202783   0.78693477  1.36742658  1.33473907  0.72217426
  0.12183007 -0.12754948 -0.13495181 -0.08662948 -0.04057795  0.00340961
  0.02448001  0.00850378 -0.01157346  0.00458874  0.04572819  0.06172643
  0.0301382  -0.01498516 -0.0270755  -0.00657047  0.0093092   0.00369654
 -0.00788818 -0.00582791  0.0080957   0.01954062  0.01611345 -0.00497206
 -0.0357219  -0.0657767  -0.0887014  -0.1049796  -0.12649457]
Cluster 0, Occurrences: 1198
Cluster 1, Occurrences: 1128
Cluster 2, Occurrences: 1148
Number of Clusters: 3
Online_Training [1/100]: mean_loss=0.11569786164909601
Online_Training [2/100]: mean_loss=0.18770701251924038
Online_Training [3/100]: mean_loss=0.12840277515351772
Online_Training [4/100]: mean_loss=0.11226382944732904
Online_Training [5/100]: mean_loss=0.11469254922121763
Online_Training [6/100]: mean_loss=0.19865787774324417
Online_Training [7/100]: mean_loss=0.45871907845139503
Online_Training [8/100]: mean_loss=0.24337426386773586
Online_Training [9/100]: mean_loss=0.36654677614569664
Online_Training [10/100]: mean_loss=0.10459798388183117
Online_Training [11/100]: mean_loss=0.5583267062902451
Online_Training [12/100]: mean_loss=0.1266243178397417
Online_Training [13/100]: mean_loss=0.4117329940199852
Online_Training [14/100]: mean_loss=0.07650322560220957
Online_Training [15/100]: mean_loss=0.21789122186601162
Online_Training [16/100]: mean_loss=0.1611985433846712
Online_Training [17/100]: mean_loss=0.16308525390923023
Online_Training [18/100]: mean_loss=0.24079308658838272
Online_Training [19/100]: mean_loss=0.1402972750365734
Online_Training [20/100]: mean_loss=0.07576797064393759
Online_Training [21/100]: mean_loss=0.06894721649587154
Online_Training [22/100]: mean_loss=0.11924106627702713
Online_Training [23/100]: mean_loss=0.33724572882056236
Online_Training [24/100]: mean_loss=0.2341908309608698
Online_Training [25/100]: mean_loss=0.2584829665720463
Online_Training [26/100]: mean_loss=0.228639030829072
Online_Training [27/100]: mean_loss=0.19026374444365501
Online_Training [28/100]: mean_loss=0.12035753764212132
Online_Training [29/100]: mean_loss=0.1283183190971613
Online_Training [30/100]: mean_loss=0.1274277474731207
Online_Training [31/100]: mean_loss=0.16405543126165867
Online_Training [32/100]: mean_loss=0.117516178637743
Online_Training [33/100]: mean_loss=0.10481810197234154
Online_Training [34/100]: mean_loss=0.10518365539610386
Online_Training [35/100]: mean_loss=0.02970199240371585
Online_Training [36/100]: mean_loss=0.01996990479528904
Online_Training [37/100]: mean_loss=0.24611886590719223
Online_Training [38/100]: mean_loss=0.10542437620460987
Online_Training [39/100]: mean_loss=0.11083820927888155
Online_Training [40/100]: mean_loss=0.17485417239367962
Online_Training [41/100]: mean_loss=0.15007354132831097
Online_Training [42/100]: mean_loss=0.07898284122347832
Online_Training [43/100]: mean_loss=0.03732428001239896
Online_Training [44/100]: mean_loss=0.09719718620181084
Online_Training [45/100]: mean_loss=0.04408761765807867
Online_Training [46/100]: mean_loss=0.12083136383444071
Online_Training [47/100]: mean_loss=0.0359800742007792
Online_Training [48/100]: mean_loss=0.09508479107171297
Online_Training [49/100]: mean_loss=0.06747668795287609
Online_Training [50/100]: mean_loss=0.055800678208470345
Online_Training [51/100]: mean_loss=0.08201219607144594
Online_Training [52/100]: mean_loss=0.16228909976780415
Online_Training [53/100]: mean_loss=0.05484818224795163
Online_Training [54/100]: mean_loss=0.06279939692467451
Online_Training [55/100]: mean_loss=0.09521624725311995
Online_Training [56/100]: mean_loss=0.10721457656472921
Online_Training [57/100]: mean_loss=0.08570445980876684
Online_Training [58/100]: mean_loss=0.01794336165767163
Online_Training [59/100]: mean_loss=0.14910025894641876
Online_Training [60/100]: mean_loss=0.03214445919729769
Online_Training [61/100]: mean_loss=0.060800525825470686
Online_Training [62/100]: mean_loss=0.28389086201786995
Online_Training [63/100]: mean_loss=0.043620668817311525
Online_Training [64/100]: mean_loss=0.23859477695077658
Online_Training [65/100]: mean_loss=0.10524000506848097
Online_Training [66/100]: mean_loss=0.12352393846958876
Online_Training [67/100]: mean_loss=0.17310466803610325
Online_Training [68/100]: mean_loss=0.11957243178039789
Online_Training [69/100]: mean_loss=0.04588463809341192
Online_Training [70/100]: mean_loss=0.09333517495542765
Online_Training [71/100]: mean_loss=0.04426468722522259
Online_Training [72/100]: mean_loss=0.031399721279740334
Online_Training [73/100]: mean_loss=0.22806023806333542
Online_Training [74/100]: mean_loss=0.033744252286851406
Online_Training [75/100]: mean_loss=0.04594049695879221
Online_Training [76/100]: mean_loss=0.09690081048756838
Online_Training [77/100]: mean_loss=0.10296023264527321
Online_Training [78/100]: mean_loss=0.02365545742213726
Online_Training [79/100]: mean_loss=0.08062510704621673
Online_Training [80/100]: mean_loss=0.025190539890900254
Online_Training [81/100]: mean_loss=0.04137897724285722
Online_Training [82/100]: mean_loss=0.026039722375571728
Online_Training [83/100]: mean_loss=0.13016239553689957
Online_Training [84/100]: mean_loss=0.03190888511016965
Online_Training [85/100]: mean_loss=0.0526877730153501
Online_Training [86/100]: mean_loss=0.06717910151928663
Online_Training [87/100]: mean_loss=0.031354471342638135
Online_Training [88/100]: mean_loss=0.040844551753252745
Online_Training [89/100]: mean_loss=0.03944910457357764
Online_Training [90/100]: mean_loss=0.16060850769281387
Online_Training [91/100]: mean_loss=0.10477668885141611
Online_Training [92/100]: mean_loss=0.05527561251074076
Online_Training [93/100]: mean_loss=0.045169088523834944
Online_Training [94/100]: mean_loss=0.08315367670729756
Online_Training [95/100]: mean_loss=0.024769323179498315
Online_Training [96/100]: mean_loss=0.1305931666865945
Online_Training [97/100]: mean_loss=0.20314270444214344
Online_Training [98/100]: mean_loss=0.028167390730232
Online_Training [99/100]: mean_loss=0.19067498482763767
Online_Training [100/100]: mean_loss=0.24133202992379665
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.84912544 -0.59653586]
[0, 1, 1, 2, 0, 2, 1, 1, 2, 2, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0, 2, 0, 2, 2, 0, 1, 1, 0, 2, 0, 1, 0, 1, 2, 0, 1, 2, 1, 1, 2, 1, 0, 1, 0, 2, 0, 1, 0, 1, 2, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 2, 0, 1, 0, 2, 2, 1, 0, 0, 1, 0, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 2, 2, 1, 0, 0, 0, 0, 2, 1, 2, 1, 2, 2, 1, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 1, 0, 2, 2, 1, 1, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 1, 1, 0, 2, 2, 0, 2, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 2, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 2, 2, 2, 2, 0, 1, 1, 1, 1, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 2, 0, 2, 2, 0, 1, 2, 1, 2, 2, 2, 0, 0, 2, 1, 0, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 1, 2, 0, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 1, 0, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 1, 1, 2]
[0, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 2, 2, 0, 1, 0, 2, 0, 2, 0, 0, 2, 1, 3, 2, 1, 2, 0, 3, 0, 0, 0, 2, 4, 2, 1, 2, 0, 3, 1, 2, 0, 2, 0, 0, 1, 4, 0, 2, 0, 0, 1, 0, 1, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 2, 1, 0, 1, 0, 1, 1, 4, 1, 0, 1, 1, 2, 1, 5, 1, 2, 4, 1, 1, 1, 0, 2, 0, 4, 0, 0, 1, 2, 1, 2, 1, 1, 2, 0, 2, 0, 0, 1, 4, 0, 0, 0, 0, 2, 1, 1, 2, 2, 0, 2, 4, 0, 1, 2, 2, 0, 1, 4, 0, 1, 2, 0, 0, 1, 1, 1, 2, 2, 0, 1, 1, 0, 5, 1, 2, 0, 0, 0, 4, 2, 1, 0, 2, 0, 2, 4, 0, 0, 0, 2, 1, 4, 3, 1, 1, 0, 0, 4, 0, 0, 1, 2, 0, 0, 3, 1, 4, 0, 1, 1, 4, 2, 4, 1, 0, 2, 0, 5, 0, 2, 0, 1, 0, 1, 2, 2, 0, 2, 0, 0, 1, 2, 0, 1, 1, 1, 0, 4, 2, 2, 2, 0, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 4, 1, 1, 0, 2, 1, 4, 5, 5, 1, 4, 4, 1, 2, 0, 2, 2, 1, 3, 1, 2, 1, 3, 2, 2, 0, 1, 0, 4, 4, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 0, 0, 5, 1, 2, 0, 4, 2, 2, 5]
Centroids: [[-0.62872165, -0.70239824], [1.9392476, -1.4055791], [-2.2191856, -3.1386127]]
Centroids: [[-0.77660495, -0.91485363], [-2.255015, -3.1762207], [1.8842102, -1.3937755], [3.9665694, -2.381078], [0.26500407, -0.1251432], [-2.8157468, -4.6386347]]
Standard Derivations: [0.40431988, 0.6062218, 0.5244]
Cluster Distances: [1.6519626, 1.9806988, 1.6519626, 3.3744833, 1.9806987, 3.374483]
Minimal Cluster Distance: 1.6519626379013062
Contingency Matrix: 
[[91  0  1  0 20  0]
 [ 6  0 72  7  4  0]
 [ 9 83  0  0  0  7]]
[[91, 0, 1, 0, 20, 0], [6, 0, 72, 7, 4, 0], [9, 83, 0, 0, 0, 7]]
[[91, 0, 1, 0, 20, 0], [6, 0, 72, 7, 4, 0], [9, 83, 0, 0, 0, 7]]
[0, 1, 2, 3, 4, 5]
[[-1, -1, -1, -1, -1, -1], [-1, 0, 72, 7, 4, 0], [-1, 83, 0, 0, 0, 7]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, 72, 7, 4, 0], [-1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 0, 2: 1, 1: 2}
New Contingency Matrix: 
[[91  1  0  0 20  0]
 [ 6 72  0  7  4  0]
 [ 9  0 83  0  0  7]]
New Clustered Label Sequence: [0, 2, 1, 3, 4, 5]
Diagonal_Elements: [91, 72, 83], Sum: 246
All_Elements: [91, 1, 0, 0, 20, 0, 6, 72, 0, 7, 4, 0, 9, 0, 83, 0, 0, 7], Sum: 300
Accuracy: 0.82
