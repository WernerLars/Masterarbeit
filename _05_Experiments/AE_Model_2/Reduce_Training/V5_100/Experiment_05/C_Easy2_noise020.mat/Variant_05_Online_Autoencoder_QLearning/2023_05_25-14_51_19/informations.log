Experiment_path: AE_Model_2/Reduce_Training//V5_100/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise020.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_100/Experiment_05/C_Easy2_noise020.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-14_51_19
Punishment_Coefficient: 1.1
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000025910048A20>
Sampling rate: 24000.0
Raw: [ 0.06217714  0.08667759  0.11027728 ... -0.20242181 -0.23729255
 -0.22686598]
Times: [    275    1209    1637 ... 1439335 1439493 1439555]
Cluster: [3 1 3 ... 1 3 3]
Number of different clusters:  3
Number of Spikes: 3526
First aligned Spike Frame: [ 0.1985413   0.13105152  0.07019694  0.01293704 -0.04549478 -0.09355401
 -0.10898392 -0.08319484 -0.04338644 -0.02286395 -0.01669682  0.03736978
  0.228401    0.55158241  0.86822633  1.017223    0.95590368  0.7885242
  0.62729572  0.50651951  0.42415885  0.36744116  0.32697735  0.30083782
  0.28884086  0.28564604  0.27020338  0.23197964  0.18793799  0.15404375
  0.12614683  0.08867524  0.0478996   0.02814512  0.02523451  0.01117923
 -0.03609381 -0.11393271 -0.18622402 -0.21752562 -0.20411432 -0.1633565
 -0.106174   -0.0312361   0.06793406  0.17242405  0.24704307]
Cluster 0, Occurrences: 1186
Cluster 1, Occurrences: 1188
Cluster 2, Occurrences: 1152
Number of Clusters: 3
Online_Training [1/100]: mean_loss=0.13391449488699436
Online_Training [2/100]: mean_loss=0.1997530572116375
Online_Training [3/100]: mean_loss=0.2583862841129303
Online_Training [4/100]: mean_loss=0.1186278285458684
Online_Training [5/100]: mean_loss=0.09726851526647806
Online_Training [6/100]: mean_loss=0.09381941705942154
Online_Training [7/100]: mean_loss=0.1460478976368904
Online_Training [8/100]: mean_loss=0.20254375226795673
Online_Training [9/100]: mean_loss=0.19620205275714397
Online_Training [10/100]: mean_loss=0.12799994368106127
Online_Training [11/100]: mean_loss=0.11536553595215082
Online_Training [12/100]: mean_loss=0.1324551049619913
Online_Training [13/100]: mean_loss=0.09230933338403702
Online_Training [14/100]: mean_loss=0.07269607670605183
Online_Training [15/100]: mean_loss=0.06120419269427657
Online_Training [16/100]: mean_loss=0.08574952464550734
Online_Training [17/100]: mean_loss=0.13103464897722006
Online_Training [18/100]: mean_loss=0.040514247957617044
Online_Training [19/100]: mean_loss=0.12265970930457115
Online_Training [20/100]: mean_loss=0.07981892768293619
Online_Training [21/100]: mean_loss=0.14148795790970325
Online_Training [22/100]: mean_loss=0.07617768086493015
Online_Training [23/100]: mean_loss=0.043175066355615854
Online_Training [24/100]: mean_loss=0.1352199912071228
Online_Training [25/100]: mean_loss=0.04625697201117873
Online_Training [26/100]: mean_loss=0.03718976769596338
Online_Training [27/100]: mean_loss=0.0247471637558192
Online_Training [28/100]: mean_loss=0.04112581117078662
Online_Training [29/100]: mean_loss=0.05741337547078729
Online_Training [30/100]: mean_loss=0.1163321603089571
Online_Training [31/100]: mean_loss=0.1385077964514494
Online_Training [32/100]: mean_loss=0.09365138597786427
Online_Training [33/100]: mean_loss=0.07768914848566055
Online_Training [34/100]: mean_loss=0.09011929668486118
Online_Training [35/100]: mean_loss=0.10111588332802057
Online_Training [36/100]: mean_loss=0.08388308249413967
Online_Training [37/100]: mean_loss=0.06388542195782065
Online_Training [38/100]: mean_loss=0.028275696095079184
Online_Training [39/100]: mean_loss=0.09687625709921122
Online_Training [40/100]: mean_loss=0.027228381717577577
Online_Training [41/100]: mean_loss=0.0318347648717463
Online_Training [42/100]: mean_loss=0.03321350202895701
Online_Training [43/100]: mean_loss=0.04531588312238455
Online_Training [44/100]: mean_loss=0.0517364121042192
Online_Training [45/100]: mean_loss=0.03419028013013303
Online_Training [46/100]: mean_loss=0.03702149959281087
Online_Training [47/100]: mean_loss=0.01964595797471702
Online_Training [48/100]: mean_loss=0.013800071668811142
Online_Training [49/100]: mean_loss=0.040895264595746994
Online_Training [50/100]: mean_loss=0.05830685282126069
Online_Training [51/100]: mean_loss=0.12508295103907585
Online_Training [52/100]: mean_loss=0.07511370535939932
Online_Training [53/100]: mean_loss=0.06020351592451334
Online_Training [54/100]: mean_loss=0.2951016500592232
Online_Training [55/100]: mean_loss=0.0667713200673461
Online_Training [56/100]: mean_loss=0.28720142506062984
Online_Training [57/100]: mean_loss=0.09291438665241003
Online_Training [58/100]: mean_loss=0.03790334612131119
Online_Training [59/100]: mean_loss=0.05772395897656679
Online_Training [60/100]: mean_loss=0.03058334207162261
Online_Training [61/100]: mean_loss=0.026028841035440564
Online_Training [62/100]: mean_loss=0.04378952831029892
Online_Training [63/100]: mean_loss=0.021737383445724845
Online_Training [64/100]: mean_loss=0.035398293286561966
Online_Training [65/100]: mean_loss=0.03848035214468837
Online_Training [66/100]: mean_loss=0.0577700762078166
Online_Training [67/100]: mean_loss=0.1286114016547799
Online_Training [68/100]: mean_loss=0.11716221179813147
Online_Training [69/100]: mean_loss=0.019670448265969753
Online_Training [70/100]: mean_loss=0.05748021975159645
Online_Training [71/100]: mean_loss=0.047215614933520555
Online_Training [72/100]: mean_loss=0.21653319895267487
Online_Training [73/100]: mean_loss=0.08683315012603998
Online_Training [74/100]: mean_loss=0.017835650593042374
Online_Training [75/100]: mean_loss=0.048058715648949146
Online_Training [76/100]: mean_loss=0.08943702653050423
Online_Training [77/100]: mean_loss=0.05607372848317027
Online_Training [78/100]: mean_loss=0.06962881190702319
Online_Training [79/100]: mean_loss=0.023646659683436155
Online_Training [80/100]: mean_loss=0.6687803789973259
Online_Training [81/100]: mean_loss=0.04701332561671734
Online_Training [82/100]: mean_loss=0.19225079379975796
Online_Training [83/100]: mean_loss=0.08831857144832611
Online_Training [84/100]: mean_loss=0.0861366679891944
Online_Training [85/100]: mean_loss=0.0387959610670805
Online_Training [86/100]: mean_loss=0.05102472472935915
Online_Training [87/100]: mean_loss=0.06322294380515814
Online_Training [88/100]: mean_loss=0.03897112188860774
Online_Training [89/100]: mean_loss=0.048032415099442005
Online_Training [90/100]: mean_loss=0.09396293666213751
Online_Training [91/100]: mean_loss=0.07798320520669222
Online_Training [92/100]: mean_loss=0.027593690901994705
Online_Training [93/100]: mean_loss=0.04321844968944788
Online_Training [94/100]: mean_loss=0.03778870264068246
Online_Training [95/100]: mean_loss=0.04503907775506377
Online_Training [96/100]: mean_loss=0.017272136290557683
Online_Training [97/100]: mean_loss=0.0818177554756403
Online_Training [98/100]: mean_loss=0.04405921697616577
Online_Training [99/100]: mean_loss=0.020314001478254795
Online_Training [100/100]: mean_loss=0.03927618497982621
Number of Samples after Autoencoder testing: 300
First Spike after testing: [0.49490067 0.7287569 ]
[2, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 1, 0, 0, 0, 1, 2, 1, 0, 0, 1, 1, 2, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0, 0, 1, 0, 1, 0, 2, 1, 0, 1, 2, 1, 2, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 0, 2, 2, 0, 0, 2, 1, 1, 1, 0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 0, 2, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1, 0, 2, 2, 0, 1, 1, 2, 0, 2, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2, 2, 1, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 1, 2, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 2, 0, 1, 0, 1, 2, 2, 1, 1, 0, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 0, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 2, 1, 1, 1, 1, 2, 0, 1, 1, 2, 2, 2, 2, 0, 2, 1, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 2, 2, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 1]
[0, 1, 1, 1, 0, 1, 2, 0, 1, 0, 0, 1, 1, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 1, 2, 1, 0, 1, 2, 2, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 2, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 2, 2, 2, 0, 1, 0, 1, 2, 1, 2, 1, 2, 0, 2, 1, 2, 0, 1, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 1, 2, 0, 1, 0, 1, 2, 1, 0, 1, 2, 1, 3, 0, 0, 2, 1, 0, 2, 1, 1, 0, 0, 2, 2, 0, 0, 1, 2, 1, 1, 1, 2, 1, 2, 0, 1, 1, 0, 0, 3, 3, 1, 0, 1, 0, 1, 0, 1, 2, 2, 2, 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 3, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 1, 0, 3, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 0, 2, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 2, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 0, 1, 2, 2, 2, 1, 1, 1, 2, 3, 1, 1, 0, 1, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 0, 1, 0, 1, 2, 2, 3, 0, 2, 1, 2, 2, 2, 1, 0, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1]
Centroids: [[-1.7891079, -3.154238], [-0.838689, -1.9131343], [-0.056851726, 0.021843322]]
Centroids: [[0.0013214225, 0.07764325], [-0.896772, -1.8920668], [-1.845058, -3.315054], [-2.4334183, -4.170005]]
Standard Derivations: [0.54232645, 0.44479033, 0.43852985]
Cluster Distances: [0.57609594, 2.6369061, 0.57609594, 1.2036413, 2.6369061, 1.2036413]
Minimal Cluster Distance: 0.5760959386825562
Contingency Matrix: 
[[  0  28  62   6]
 [  5 100   9   1]
 [ 80   7   1   1]]
[[0, 28, 62, 6], [5, 100, 9, 1], [80, 7, 1, 1]]
[[0, 28, 62, 6], [5, 100, 9, 1], [80, 7, 1, 1]]
[0, 1, 2, 3]
[[0, -1, 62, 6], [-1, -1, -1, -1], [80, -1, 1, 1]]
[[-1, -1, 62, 6], [-1, -1, -1, -1], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {1: 1, 2: 0, 0: 2}
New Contingency Matrix: 
[[ 62  28   0   6]
 [  9 100   5   1]
 [  1   7  80   1]]
New Clustered Label Sequence: [2, 1, 0, 3]
Diagonal_Elements: [62, 100, 80], Sum: 242
All_Elements: [62, 28, 0, 6, 9, 100, 5, 1, 1, 7, 80, 1], Sum: 300
Accuracy: 0.8066666666666666
