Experiment_path: AE_Model_2/Reduce_Training//V5_100/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_100/Experiment_05/C_Difficult2_noise015.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-14_38_47
Punishment_Coefficient: 0.7
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002590B87F8D0>
Sampling rate: 24000.0
Raw: [-0.05565321 -0.04571496 -0.03115923 ...  0.1473638   0.13534729
  0.111692  ]
Times: [    418     529    1030 ... 1439028 1439080 1439623]
Cluster: [2 3 2 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3440
First aligned Spike Frame: [-0.17099344 -0.1945709  -0.20692804 -0.21224585 -0.21123273 -0.19839621
 -0.16928805 -0.13455314 -0.10755804 -0.09418858 -0.09168847 -0.09014646
 -0.07785681 -0.05220219 -0.010559    0.05141874  0.13325345  0.23429051
  0.3635645   0.52201137  0.68833941  0.84629252  0.96368446  0.9673675
  0.80566127  0.51814506  0.20703252 -0.04483802 -0.21878317 -0.33306068
 -0.39936966 -0.41844164 -0.40822894 -0.3999483  -0.40801198 -0.43204789
 -0.46902504 -0.51735316 -0.56113271 -0.57967205 -0.56696316 -0.53144438
 -0.47215401 -0.37953885 -0.25698053 -0.12693248 -0.00995817]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1185
Number of Clusters: 3
Online_Training [1/100]: mean_loss=0.18446957506239414
Online_Training [2/100]: mean_loss=0.11172703560441732
Online_Training [3/100]: mean_loss=0.18485629186034203
Online_Training [4/100]: mean_loss=0.1301359310746193
Online_Training [5/100]: mean_loss=0.11629625223577023
Online_Training [6/100]: mean_loss=0.2203611209988594
Online_Training [7/100]: mean_loss=0.1110638678073883
Online_Training [8/100]: mean_loss=0.10921876132488251
Online_Training [9/100]: mean_loss=0.08429794665426016
Online_Training [10/100]: mean_loss=0.05228965450078249
Online_Training [11/100]: mean_loss=0.10486048646271229
Online_Training [12/100]: mean_loss=0.12591034919023514
Online_Training [13/100]: mean_loss=0.08759073726832867
Online_Training [14/100]: mean_loss=0.10507099144160748
Online_Training [15/100]: mean_loss=0.08672009687870741
Online_Training [16/100]: mean_loss=0.04126755893230438
Online_Training [17/100]: mean_loss=0.028937151422724128
Online_Training [18/100]: mean_loss=0.14933925867080688
Online_Training [19/100]: mean_loss=0.04947682283818722
Online_Training [20/100]: mean_loss=0.04733496392145753
Online_Training [21/100]: mean_loss=0.27978135645389557
Online_Training [22/100]: mean_loss=0.17185796238481998
Online_Training [23/100]: mean_loss=0.04276338778436184
Online_Training [24/100]: mean_loss=0.13847879320383072
Online_Training [25/100]: mean_loss=0.054292422253638506
Online_Training [26/100]: mean_loss=0.1047003511339426
Online_Training [27/100]: mean_loss=0.1326118791475892
Online_Training [28/100]: mean_loss=0.051412546541541815
Online_Training [29/100]: mean_loss=0.07184154074639082
Online_Training [30/100]: mean_loss=0.06561017408967018
Online_Training [31/100]: mean_loss=0.0771239697933197
Online_Training [32/100]: mean_loss=0.05588565766811371
Online_Training [33/100]: mean_loss=0.03042350197210908
Online_Training [34/100]: mean_loss=0.10711554251611233
Online_Training [35/100]: mean_loss=0.05121393920853734
Online_Training [36/100]: mean_loss=0.023357212310656905
Online_Training [37/100]: mean_loss=0.09273706190288067
Online_Training [38/100]: mean_loss=0.05236541386693716
Online_Training [39/100]: mean_loss=0.06851617060601711
Online_Training [40/100]: mean_loss=0.028645372251048684
Online_Training [41/100]: mean_loss=0.11489155236631632
Online_Training [42/100]: mean_loss=0.08082917239516973
Online_Training [43/100]: mean_loss=0.07034695334732533
Online_Training [44/100]: mean_loss=0.09726837184280157
Online_Training [45/100]: mean_loss=0.02176311332732439
Online_Training [46/100]: mean_loss=0.03872649185359478
Online_Training [47/100]: mean_loss=0.16388625837862492
Online_Training [48/100]: mean_loss=0.05504634929820895
Online_Training [49/100]: mean_loss=0.0611370699480176
Online_Training [50/100]: mean_loss=0.024437928339466453
Online_Training [51/100]: mean_loss=0.045566614251583815
Online_Training [52/100]: mean_loss=0.016797439544461668
Online_Training [53/100]: mean_loss=0.10846319422125816
Online_Training [54/100]: mean_loss=0.03937615407630801
Online_Training [55/100]: mean_loss=0.03928231494501233
Online_Training [56/100]: mean_loss=0.017655567266047
Online_Training [57/100]: mean_loss=0.045203953981399536
Online_Training [58/100]: mean_loss=0.06008725706487894
Online_Training [59/100]: mean_loss=0.14677048102021217
Online_Training [60/100]: mean_loss=0.05022053932771087
Online_Training [61/100]: mean_loss=0.03985315840691328
Online_Training [62/100]: mean_loss=0.11498269438743591
Online_Training [63/100]: mean_loss=0.015139919007197022
Online_Training [64/100]: mean_loss=0.015737414360046387
Online_Training [65/100]: mean_loss=0.016905349912121892
Online_Training [66/100]: mean_loss=0.008553015941288322
Online_Training [67/100]: mean_loss=0.06371330469846725
Online_Training [68/100]: mean_loss=0.02641695155762136
Online_Training [69/100]: mean_loss=0.03366691246628761
Online_Training [70/100]: mean_loss=0.03665602160617709
Online_Training [71/100]: mean_loss=0.014657534193247557
Online_Training [72/100]: mean_loss=0.12590379361063242
Online_Training [73/100]: mean_loss=0.04107202356681228
Online_Training [74/100]: mean_loss=0.08860975410789251
Online_Training [75/100]: mean_loss=0.20009246096014977
Online_Training [76/100]: mean_loss=0.05592698510736227
Online_Training [77/100]: mean_loss=0.18628626316785812
Online_Training [78/100]: mean_loss=0.13183747790753841
Online_Training [79/100]: mean_loss=0.03436440508812666
Online_Training [80/100]: mean_loss=0.032887897454202175
Online_Training [81/100]: mean_loss=0.019246164709329605
Online_Training [82/100]: mean_loss=0.029643102549016476
Online_Training [83/100]: mean_loss=0.06512172520160675
Online_Training [84/100]: mean_loss=0.008151334768626839
Online_Training [85/100]: mean_loss=0.042204950004816055
Online_Training [86/100]: mean_loss=0.11512158531695604
Online_Training [87/100]: mean_loss=0.041876382660120726
Online_Training [88/100]: mean_loss=0.13098379038274288
Online_Training [89/100]: mean_loss=0.006040568638127297
Online_Training [90/100]: mean_loss=0.02594894729554653
Online_Training [91/100]: mean_loss=0.07643346209079027
Online_Training [92/100]: mean_loss=0.07529429346323013
Online_Training [93/100]: mean_loss=0.12801113910973072
Online_Training [94/100]: mean_loss=0.05525018973276019
Online_Training [95/100]: mean_loss=0.021572972182184458
Online_Training [96/100]: mean_loss=0.021047803107649088
Online_Training [97/100]: mean_loss=0.022139653097838163
Online_Training [98/100]: mean_loss=0.13443781808018684
Online_Training [99/100]: mean_loss=0.14032766036689281
Online_Training [100/100]: mean_loss=0.02228749869391322
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.91990614  0.5980714 ]
[1, 1, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 1, 1, 2, 1, 0, 2, 2, 2, 2, 1, 2, 1, 0, 2, 0, 2, 1, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 2, 0, 1, 0, 2, 1, 1, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 0, 2, 2, 1, 2, 0, 1, 1, 2, 0, 0, 2, 2, 1, 2, 0, 2, 1, 2, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 2, 0, 0, 2, 0, 1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 0, 2, 2, 1, 2, 1, 1, 0, 0, 1, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 1, 2, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 2, 1, 1, 0, 2, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 2, 1, 1, 0, 0, 2, 0, 1, 2]
[0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]
Centroids: [[-0.23995045, -0.9313297], [-0.92594796, 0.6731785], [-0.4909435, -0.8816291]]
Centroids: [[-0.9263975, 0.6661833], [-0.36689863, -0.9156079], [0.5278881, 0.027831892]]
Standard Derivations: [0.19030164, 0.13383113, 0.1513547]
Cluster Distances: [1.4208711, -0.085789874, 1.4208711, 1.3293282, -0.085789874, 1.3293282]
Minimal Cluster Distance: -0.08578987419605255
Contingency Matrix: 
[[  1  98   1]
 [100   0   0]
 [  0 100   0]]
[[1, 98, 1], [100, 0, 0], [0, 100, 0]]
[[1, 98, 1], [100, 0, 0], [0, 100, 0]]
[0, 1, 2]
[[-1, 98, 1], [-1, -1, -1], [-1, 100, 0]]
[[-1, -1, 1], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 0, 2: 1, 0: 2}
New Contingency Matrix: 
[[  1   1  98]
 [  0 100   0]
 [  0   0 100]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1, 100, 100], Sum: 201
All_Elements: [1, 1, 98, 0, 100, 0, 0, 0, 100], Sum: 300
Accuracy: 0.67
