Experiment_path: AE_Model_2/Reduce_Training//V5_100/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_100/Experiment_05/C_Drift_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-14_40_15
Punishment_Coefficient: 1.1
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002590F6EEF98>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
Number of Clusters: 3
Online_Training [1/100]: mean_loss=0.1386891845613718
Online_Training [2/100]: mean_loss=0.1497445497661829
Online_Training [3/100]: mean_loss=0.2779655270278454
Online_Training [4/100]: mean_loss=0.1383659914135933
Online_Training [5/100]: mean_loss=0.14062516763806343
Online_Training [6/100]: mean_loss=0.11520449724048376
Online_Training [7/100]: mean_loss=0.03626192221418023
Online_Training [8/100]: mean_loss=0.0901311868801713
Online_Training [9/100]: mean_loss=0.1226275758817792
Online_Training [10/100]: mean_loss=0.08810629043728113
Online_Training [11/100]: mean_loss=0.05878388276323676
Online_Training [12/100]: mean_loss=0.03977879602462053
Online_Training [13/100]: mean_loss=0.09639801923185587
Online_Training [14/100]: mean_loss=0.14839691296219826
Online_Training [15/100]: mean_loss=0.0852551069110632
Online_Training [16/100]: mean_loss=0.076807064935565
Online_Training [17/100]: mean_loss=0.058581402990967035
Online_Training [18/100]: mean_loss=0.09216954093426466
Online_Training [19/100]: mean_loss=0.0379923521541059
Online_Training [20/100]: mean_loss=0.06016507092863321
Online_Training [21/100]: mean_loss=0.033609868958592415
Online_Training [22/100]: mean_loss=0.10138948913663626
Online_Training [23/100]: mean_loss=0.03482343070209026
Online_Training [24/100]: mean_loss=0.05260655423626304
Online_Training [25/100]: mean_loss=0.06338182743638754
Online_Training [26/100]: mean_loss=0.1542759370058775
Online_Training [27/100]: mean_loss=0.10424620658159256
Online_Training [28/100]: mean_loss=0.1026335870847106
Online_Training [29/100]: mean_loss=0.04172274889424443
Online_Training [30/100]: mean_loss=0.0990932947024703
Online_Training [31/100]: mean_loss=0.1135997911915183
Online_Training [32/100]: mean_loss=0.05867856368422508
Online_Training [33/100]: mean_loss=0.023510202765464783
Online_Training [34/100]: mean_loss=0.04083793517202139
Online_Training [35/100]: mean_loss=0.048160846810787916
Online_Training [36/100]: mean_loss=0.03938200371339917
Online_Training [37/100]: mean_loss=0.08847056329250336
Online_Training [38/100]: mean_loss=0.1424392145127058
Online_Training [39/100]: mean_loss=0.1286744438111782
Online_Training [40/100]: mean_loss=0.04801238002255559
Online_Training [41/100]: mean_loss=0.048298731446266174
Online_Training [42/100]: mean_loss=0.013975822017528117
Online_Training [43/100]: mean_loss=0.11654714122414589
Online_Training [44/100]: mean_loss=0.03709075786173344
Online_Training [45/100]: mean_loss=0.022186013171449304
Online_Training [46/100]: mean_loss=0.04031105153262615
Online_Training [47/100]: mean_loss=0.02182466513477266
Online_Training [48/100]: mean_loss=0.046980857849121094
Online_Training [49/100]: mean_loss=0.049511362332850695
Online_Training [50/100]: mean_loss=0.04064651299268007
Online_Training [51/100]: mean_loss=0.07195530366152525
Online_Training [52/100]: mean_loss=0.02545077702961862
Online_Training [53/100]: mean_loss=0.10789504088461399
Online_Training [54/100]: mean_loss=0.020545597886666656
Online_Training [55/100]: mean_loss=0.0438411277718842
Online_Training [56/100]: mean_loss=0.016564278746955097
Online_Training [57/100]: mean_loss=0.03564262203872204
Online_Training [58/100]: mean_loss=0.045573145151138306
Online_Training [59/100]: mean_loss=0.08358924090862274
Online_Training [60/100]: mean_loss=0.09910212643444538
Online_Training [61/100]: mean_loss=0.0496137673035264
Online_Training [62/100]: mean_loss=0.13169045001268387
Online_Training [63/100]: mean_loss=0.057230036705732346
Online_Training [64/100]: mean_loss=0.033875648165121675
Online_Training [65/100]: mean_loss=0.027812812011688948
Online_Training [66/100]: mean_loss=0.06358882831409574
Online_Training [67/100]: mean_loss=0.04362253472208977
Online_Training [68/100]: mean_loss=0.0531936502084136
Online_Training [69/100]: mean_loss=0.04999755695462227
Online_Training [70/100]: mean_loss=0.019571253331378102
Online_Training [71/100]: mean_loss=0.009841717663221061
Online_Training [72/100]: mean_loss=0.04190941248089075
Online_Training [73/100]: mean_loss=0.034238401567563415
Online_Training [74/100]: mean_loss=0.06379625434055924
Online_Training [75/100]: mean_loss=0.014792058616876602
Online_Training [76/100]: mean_loss=0.05527726840227842
Online_Training [77/100]: mean_loss=0.02331985766068101
Online_Training [78/100]: mean_loss=0.049761611968278885
Online_Training [79/100]: mean_loss=0.10654414631426334
Online_Training [80/100]: mean_loss=0.07881140895187855
Online_Training [81/100]: mean_loss=0.01623241521883756
Online_Training [82/100]: mean_loss=0.04849237110465765
Online_Training [83/100]: mean_loss=0.036528876051306725
Online_Training [84/100]: mean_loss=0.020957248052582145
Online_Training [85/100]: mean_loss=0.05747340666130185
Online_Training [86/100]: mean_loss=0.016773576266132295
Online_Training [87/100]: mean_loss=0.12566499132663012
Online_Training [88/100]: mean_loss=0.038180158007889986
Online_Training [89/100]: mean_loss=0.030290013877674937
Online_Training [90/100]: mean_loss=0.06181915896013379
Online_Training [91/100]: mean_loss=0.01872201939113438
Online_Training [92/100]: mean_loss=0.017286726739257574
Online_Training [93/100]: mean_loss=0.056962916161864996
Online_Training [94/100]: mean_loss=0.018101069377735257
Online_Training [95/100]: mean_loss=0.010587218566797674
Online_Training [96/100]: mean_loss=0.05456191347911954
Online_Training [97/100]: mean_loss=0.021622053114697337
Online_Training [98/100]: mean_loss=0.00993971707066521
Online_Training [99/100]: mean_loss=0.11166264954954386
Online_Training [100/100]: mean_loss=0.04974474245682359
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-1.1957145 -2.30123  ]
[0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 1, 2, 1, 1, 2, 1, 2, 2, 0, 2, 2, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 1, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 0, 2, 2, 1, 2, 0, 1, 1, 2, 2, 1, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 2, 2, 1, 1, 0, 2, 1, 0, 2, 0, 2, 0, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 0, 0, 2, 2, 1, 2, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1, 2, 0, 0, 2, 0, 1, 2, 2, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 2, 0, 1, 0, 2, 0, 2, 1, 1, 1, 2, 1, 0, 2, 1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 2, 0, 0, 2, 2, 1, 0, 1, 0, 2, 1, 1, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 0, 1, 1, 2, 0, 1, 2, 0, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 0, 0, 2, 0, 1, 0, 2, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 1]
[0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 2, 2, 0, 2, 1, 1, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1, 0, 2, 0, 1, 1, 2, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 2, 2, 1, 0, 1, 2, 1, 0, 2, 1, 1, 0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 0, 1, 0, 2, 2, 1, 0, 0, 1, 0, 2, 1, 1, 0, 0, 2, 2, 2, 2, 1, 1, 0, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 1, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 2, 0, 0, 2, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 2, 2, 1, 0, 2, 3, 4, 0, 2, 1, 1, 0, 0, 2, 0, 4, 0, 2, 1, 0, 1, 2, 1, 2, 1, 2, 0, 1, 2, 2, 0, 2, 3, 1, 1, 0, 3, 3, 0, 0, 0, 2, 2, 1, 2, 2, 2, 0, 1, 0, 2, 0, 1, 1, 2, 2, 0, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2]
Centroids: [[-1.6654867, -2.7550712], [-1.2288749, -1.5413971], [-1.5229856, 1.4930081]]
Centroids: [[-1.6158756, -2.6659076], [-1.4799103, 1.4715899], [-1.1755377, -1.230667], [-2.2995565, -4.4820247], [-3.0982828, 3.730745]]
Standard Derivations: [0.46268496, 0.4227382, 0.44174033]
Cluster Distances: [0.4043964, 3.3460436, 0.40439644, 2.1841466, 3.3460436, 2.184147]
Minimal Cluster Distance: 0.4043964147567749
Contingency Matrix: 
[[90  0  5  3  0]
 [25  1 75  1  0]
 [ 0 95  3  0  2]]
[[90, 0, 5, 3, 0], [25, 1, 75, 1, 0], [0, 95, 3, 0, 2]]
[[90, 0, 5, 3, 0], [25, 1, 75, 1, 0], [0, 95, 3, 0, 2]]
[0, 1, 2, 3, 4]
[[90, -1, 5, 3, 0], [25, -1, 75, 1, 0], [-1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1], [-1, -1, 75, 1, 0], [-1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1]]
Match_Labels: {2: 1, 0: 0, 1: 2}
New Contingency Matrix: 
[[90  5  0  3  0]
 [25 75  1  1  0]
 [ 0  3 95  0  2]]
New Clustered Label Sequence: [0, 2, 1, 3, 4]
Diagonal_Elements: [90, 75, 95], Sum: 260
All_Elements: [90, 5, 0, 3, 0, 25, 75, 1, 1, 0, 0, 3, 95, 0, 2], Sum: 300
Accuracy: 0.8666666666666667
