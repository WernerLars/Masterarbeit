Experiment_path: AE_Model_2/Reduce_Training//V5_100/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise020.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_100/Experiment_05/C_Difficult2_noise020.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-14_39_30
Punishment_Coefficient: 1.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002590B803828>
Sampling rate: 24000.0
Raw: [-0.05920843 -0.02398302  0.01513494 ...  0.2971695   0.32984394
  0.35872829]
Times: [    337    1080    1305 ... 1438651 1438787 1439662]
Cluster: [2 1 1 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3493
First aligned Spike Frame: [ 0.50880334  0.56984686  0.60721022  0.60769692  0.58122704  0.55003969
  0.51479324  0.46436685  0.40848987  0.36206071  0.31750134  0.26828304
  0.23270096  0.2305818   0.25904633  0.30599383  0.36680145  0.45670025
  0.60261795  0.8012213   1.02149976  1.23478943  1.38977263  1.39868415
  1.211664    0.88028336  0.50425138  0.15449729 -0.12937778 -0.32272009
 -0.40685817 -0.38921932 -0.31829776 -0.24412685 -0.18860857 -0.1442941
 -0.0976923  -0.0504865  -0.01384986  0.00955437  0.03047694  0.05600466
  0.07308225  0.06101434  0.01148826 -0.0607151  -0.13636803]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1195
Cluster 2, Occurrences: 1147
Number of Clusters: 3
Online_Training [1/100]: mean_loss=0.3344338908791542
Online_Training [2/100]: mean_loss=0.13134394586086273
Online_Training [3/100]: mean_loss=0.2167550716549158
Online_Training [4/100]: mean_loss=0.1159316934645176
Online_Training [5/100]: mean_loss=0.1744824294000864
Online_Training [6/100]: mean_loss=0.12629021983593702
Online_Training [7/100]: mean_loss=0.09255310241132975
Online_Training [8/100]: mean_loss=0.12251323834061623
Online_Training [9/100]: mean_loss=0.13384366966784
Online_Training [10/100]: mean_loss=0.08815927803516388
Online_Training [11/100]: mean_loss=0.12745911162346601
Online_Training [12/100]: mean_loss=0.06488001625984907
Online_Training [13/100]: mean_loss=0.05404045665636659
Online_Training [14/100]: mean_loss=0.15798873268067837
Online_Training [15/100]: mean_loss=0.0685219094157219
Online_Training [16/100]: mean_loss=0.07077132258564234
Online_Training [17/100]: mean_loss=0.04321786621585488
Online_Training [18/100]: mean_loss=0.10139608662575483
Online_Training [19/100]: mean_loss=0.033006738405674696
Online_Training [20/100]: mean_loss=0.014796375413425267
Online_Training [21/100]: mean_loss=0.026920550735667348
Online_Training [22/100]: mean_loss=0.058643524535000324
Online_Training [23/100]: mean_loss=0.4226163476705551
Online_Training [24/100]: mean_loss=0.17927944473922253
Online_Training [25/100]: mean_loss=0.0360240638256073
Online_Training [26/100]: mean_loss=0.11915894690901041
Online_Training [27/100]: mean_loss=0.09282136429101229
Online_Training [28/100]: mean_loss=0.15397612936794758
Online_Training [29/100]: mean_loss=0.07876607589423656
Online_Training [30/100]: mean_loss=0.08407462108880281
Online_Training [31/100]: mean_loss=0.18341167084872723
Online_Training [32/100]: mean_loss=0.10503609012812376
Online_Training [33/100]: mean_loss=0.08205916732549667
Online_Training [34/100]: mean_loss=0.4712480939924717
Online_Training [35/100]: mean_loss=0.29284876212477684
Online_Training [36/100]: mean_loss=0.1087358957156539
Online_Training [37/100]: mean_loss=0.07878669165074825
Online_Training [38/100]: mean_loss=0.11537998542189598
Online_Training [39/100]: mean_loss=0.08531086519360542
Online_Training [40/100]: mean_loss=0.13661155104637146
Online_Training [41/100]: mean_loss=0.15606437250971794
Online_Training [42/100]: mean_loss=0.10470076743513346
Online_Training [43/100]: mean_loss=0.12600278574973345
Online_Training [44/100]: mean_loss=0.25593989714980125
Online_Training [45/100]: mean_loss=0.09711788594722748
Online_Training [46/100]: mean_loss=0.051247796043753624
Online_Training [47/100]: mean_loss=0.11786196380853653
Online_Training [48/100]: mean_loss=0.12685840670019388
Online_Training [49/100]: mean_loss=0.0875936346128583
Online_Training [50/100]: mean_loss=0.06172794196754694
Online_Training [51/100]: mean_loss=0.044347730465233326
Online_Training [52/100]: mean_loss=0.04758699610829353
Online_Training [53/100]: mean_loss=0.05283265979960561
Online_Training [54/100]: mean_loss=0.11153929959982634
Online_Training [55/100]: mean_loss=0.12232672050595284
Online_Training [56/100]: mean_loss=0.07671947870403528
Online_Training [57/100]: mean_loss=0.04357345122843981
Online_Training [58/100]: mean_loss=0.09632729925215244
Online_Training [59/100]: mean_loss=0.15275047160685062
Online_Training [60/100]: mean_loss=0.02824969682842493
Online_Training [61/100]: mean_loss=0.0510040819644928
Online_Training [62/100]: mean_loss=0.03716461546719074
Online_Training [63/100]: mean_loss=0.0743709048256278
Online_Training [64/100]: mean_loss=0.044978777412325144
Online_Training [65/100]: mean_loss=0.3889261968433857
Online_Training [66/100]: mean_loss=0.15166796743869781
Online_Training [67/100]: mean_loss=0.10771027766168118
Online_Training [68/100]: mean_loss=0.09505927190184593
Online_Training [69/100]: mean_loss=0.06444900296628475
Online_Training [70/100]: mean_loss=0.07702284678816795
Online_Training [71/100]: mean_loss=0.03835023008286953
Online_Training [72/100]: mean_loss=0.10516379587352276
Online_Training [73/100]: mean_loss=0.04440217185765505
Online_Training [74/100]: mean_loss=0.07596279680728912
Online_Training [75/100]: mean_loss=0.07014529313892126
Online_Training [76/100]: mean_loss=0.024197175400331616
Online_Training [77/100]: mean_loss=0.1121963718906045
Online_Training [78/100]: mean_loss=0.03616405604407191
Online_Training [79/100]: mean_loss=0.027316460153087974
Online_Training [80/100]: mean_loss=0.0527614438906312
Online_Training [81/100]: mean_loss=0.0755739500746131
Online_Training [82/100]: mean_loss=0.07779556140303612
Online_Training [83/100]: mean_loss=0.03425080794841051
Online_Training [84/100]: mean_loss=0.03890776541084051
Online_Training [85/100]: mean_loss=0.05406688712537289
Online_Training [86/100]: mean_loss=0.09204290620982647
Online_Training [87/100]: mean_loss=0.04699933435767889
Online_Training [88/100]: mean_loss=0.024688862962648273
Online_Training [89/100]: mean_loss=0.028289523674175143
Online_Training [90/100]: mean_loss=0.0936218909919262
Online_Training [91/100]: mean_loss=0.08973932825028896
Online_Training [92/100]: mean_loss=0.09567557182163
Online_Training [93/100]: mean_loss=0.032558716367930174
Online_Training [94/100]: mean_loss=0.05276659596711397
Online_Training [95/100]: mean_loss=0.012321144458837807
Online_Training [96/100]: mean_loss=0.08171347714960575
Online_Training [97/100]: mean_loss=0.11992481630295515
Online_Training [98/100]: mean_loss=0.0568523108959198
Online_Training [99/100]: mean_loss=0.09368001483380795
Online_Training [100/100]: mean_loss=0.07408168073743582
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-1.8437085 -2.063028 ]
[0, 0, 0, 2, 2, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0, 1, 2, 0, 0, 2, 2, 2, 2, 1, 0, 2, 0, 1, 0, 2, 1, 2, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 2, 2, 1, 1, 1, 2, 1, 0, 1, 2, 1, 0, 0, 1, 2, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 1, 0, 1, 1, 1, 0, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 2, 0, 1, 2, 2, 0, 1, 0, 2, 0, 0, 2, 1, 1, 0, 1, 2, 0, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 2, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 2, 2, 1, 2, 0, 1, 1, 0, 2, 1, 2, 0, 2, 1, 2, 0, 2, 1, 2, 0, 2, 1, 2, 0, 0, 0, 1, 1, 2, 1, 2, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 0, 1, 2, 2, 2, 1, 2, 2, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 2, 2, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 1, 2, 0, 2, 0, 0, 2, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1]
[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 3, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 3, 3, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 1, 0, 1, 1]
Centroids: [[-1.337006, -1.5750978], [-1.7563798, 1.3576128], [-1.7640384, -1.068069]]
Centroids: [[-1.5178654, -1.300525], [-1.7441673, 1.3580669], [-3.9124556, 4.2437882], [-2.781013, -2.5015545]]
Standard Derivations: [0.40683696, 0.5580247, 0.5023346]
Cluster Distances: [1.9976823, -0.24627265, 1.9976823, 1.3653347, -0.24627265, 1.3653347]
Minimal Cluster Distance: -0.24627265334129333
Contingency Matrix: 
[[ 93   0   0   2]
 [  1 103   1   1]
 [ 95   2   0   2]]
[[93, 0, 0, 2], [1, 103, 1, 1], [95, 2, 0, 2]]
[[93, 0, 0, 2], [1, 103, 1, 1], [95, 2, 0, 2]]
[0, 1, 2, 3]
[[93, -1, 0, 2], [-1, -1, -1, -1], [95, -1, 0, 2]]
[[-1, -1, 0, 2], [-1, -1, -1, -1], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {1: 1, 2: 0, 0: 3}
New Contingency Matrix: 
[[  2   0  93   0]
 [  1 103   1   1]
 [  2   2  95   0]]
New Clustered Label Sequence: [3, 1, 0, 2]
Diagonal_Elements: [2, 103, 95], Sum: 200
All_Elements: [2, 0, 93, 0, 1, 103, 1, 1, 2, 2, 95, 0], Sum: 300
Accuracy: 0.6666666666666666
