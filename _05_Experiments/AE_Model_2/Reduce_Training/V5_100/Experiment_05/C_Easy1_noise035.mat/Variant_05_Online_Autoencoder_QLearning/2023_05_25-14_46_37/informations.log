Experiment_path: AE_Model_2/Reduce_Training//V5_100/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_100/Experiment_05/C_Easy1_noise035.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-14_46_37
Punishment_Coefficient: 1.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002590B932668>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
Number of Clusters: 3
Online_Training [1/100]: mean_loss=0.24250935018062592
Online_Training [2/100]: mean_loss=0.30755768343806267
Online_Training [3/100]: mean_loss=0.8155114129185677
Online_Training [4/100]: mean_loss=0.3472812548279762
Online_Training [5/100]: mean_loss=0.3812336251139641
Online_Training [6/100]: mean_loss=0.10381869878619909
Online_Training [7/100]: mean_loss=0.20923802442848682
Online_Training [8/100]: mean_loss=0.19944708421826363
Online_Training [9/100]: mean_loss=0.12449843715876341
Online_Training [10/100]: mean_loss=0.737969383597374
Online_Training [11/100]: mean_loss=0.7861589342355728
Online_Training [12/100]: mean_loss=0.300646536052227
Online_Training [13/100]: mean_loss=0.3811856023967266
Online_Training [14/100]: mean_loss=0.17256972193717957
Online_Training [15/100]: mean_loss=0.29496733844280243
Online_Training [16/100]: mean_loss=0.08104617055505514
Online_Training [17/100]: mean_loss=0.2980463467538357
Online_Training [18/100]: mean_loss=0.17852269113063812
Online_Training [19/100]: mean_loss=0.10265733767300844
Online_Training [20/100]: mean_loss=0.3406606800854206
Online_Training [21/100]: mean_loss=0.17328646779060364
Online_Training [22/100]: mean_loss=0.3214990794658661
Online_Training [23/100]: mean_loss=0.10498737450689077
Online_Training [24/100]: mean_loss=0.22472275607287884
Online_Training [25/100]: mean_loss=0.1814324539154768
Online_Training [26/100]: mean_loss=0.11394559871405363
Online_Training [27/100]: mean_loss=0.08435830846428871
Online_Training [28/100]: mean_loss=0.17846021614968777
Online_Training [29/100]: mean_loss=0.42736342921853065
Online_Training [30/100]: mean_loss=0.3842437379062176
Online_Training [31/100]: mean_loss=0.127707258798182
Online_Training [32/100]: mean_loss=0.4381319731473923
Online_Training [33/100]: mean_loss=0.1560197789222002
Online_Training [34/100]: mean_loss=0.21332196332514286
Online_Training [35/100]: mean_loss=0.13425369560718536
Online_Training [36/100]: mean_loss=0.06914911139756441
Online_Training [37/100]: mean_loss=0.04237658157944679
Online_Training [38/100]: mean_loss=0.11574092041701078
Online_Training [39/100]: mean_loss=0.1709567829966545
Online_Training [40/100]: mean_loss=0.1310995826497674
Online_Training [41/100]: mean_loss=0.2507405485957861
Online_Training [42/100]: mean_loss=0.19832063652575016
Online_Training [43/100]: mean_loss=0.06710442528128624
Online_Training [44/100]: mean_loss=0.1915582101792097
Online_Training [45/100]: mean_loss=0.47513772919774055
Online_Training [46/100]: mean_loss=0.3133830167353153
Online_Training [47/100]: mean_loss=0.11611533630639315
Online_Training [48/100]: mean_loss=0.1863153837621212
Online_Training [49/100]: mean_loss=0.6050011813640594
Online_Training [50/100]: mean_loss=0.19875557720661163
Online_Training [51/100]: mean_loss=0.10160743072628975
Online_Training [52/100]: mean_loss=0.15908648818731308
Online_Training [53/100]: mean_loss=0.17773114517331123
Online_Training [54/100]: mean_loss=0.055809634272009134
Online_Training [55/100]: mean_loss=0.42927859351038933
Online_Training [56/100]: mean_loss=0.20681174844503403
Online_Training [57/100]: mean_loss=0.06268236972391605
Online_Training [58/100]: mean_loss=0.2005415242165327
Online_Training [59/100]: mean_loss=0.16286531649529934
Online_Training [60/100]: mean_loss=0.15645011328160763
Online_Training [61/100]: mean_loss=0.1182139040902257
Online_Training [62/100]: mean_loss=0.19859509356319904
Online_Training [63/100]: mean_loss=0.122573122382164
Online_Training [64/100]: mean_loss=0.08348744828253984
Online_Training [65/100]: mean_loss=0.23944700323045254
Online_Training [66/100]: mean_loss=0.6602336093783379
Online_Training [67/100]: mean_loss=0.10061898361891508
Online_Training [68/100]: mean_loss=0.13263578619807959
Online_Training [69/100]: mean_loss=0.1275299098342657
Online_Training [70/100]: mean_loss=0.04305675672367215
Online_Training [71/100]: mean_loss=0.07642880640923977
Online_Training [72/100]: mean_loss=0.1661215927451849
Online_Training [73/100]: mean_loss=0.04790127510204911
Online_Training [74/100]: mean_loss=0.1852447371929884
Online_Training [75/100]: mean_loss=0.258096843957901
Online_Training [76/100]: mean_loss=0.08542698482051492
Online_Training [77/100]: mean_loss=0.12374807707965374
Online_Training [78/100]: mean_loss=0.1198617396876216
Online_Training [79/100]: mean_loss=0.18945278227329254
Online_Training [80/100]: mean_loss=0.08891020249575377
Online_Training [81/100]: mean_loss=0.09193497058004141
Online_Training [82/100]: mean_loss=0.10045152436941862
Online_Training [83/100]: mean_loss=0.13301651179790497
Online_Training [84/100]: mean_loss=0.2922940328717232
Online_Training [85/100]: mean_loss=0.07180473674088717
Online_Training [86/100]: mean_loss=0.05662336386740208
Online_Training [87/100]: mean_loss=0.20660694036632776
Online_Training [88/100]: mean_loss=0.1383423414081335
Online_Training [89/100]: mean_loss=0.09715983597561717
Online_Training [90/100]: mean_loss=0.1463199406862259
Online_Training [91/100]: mean_loss=0.06103878701105714
Online_Training [92/100]: mean_loss=0.10491787921637297
Online_Training [93/100]: mean_loss=0.08011893648654222
Online_Training [94/100]: mean_loss=0.023564114468172193
Online_Training [95/100]: mean_loss=0.05492329690605402
Online_Training [96/100]: mean_loss=0.23988508433103561
Online_Training [97/100]: mean_loss=0.20026703737676144
Online_Training [98/100]: mean_loss=0.1017896980047226
Online_Training [99/100]: mean_loss=0.060731221456080675
Online_Training [100/100]: mean_loss=0.2419031821191311
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.00283192 -2.5609114 ]
[1, 0, 2, 1, 2, 1, 0, 0, 2, 2, 1, 1, 2, 1, 2, 1, 2, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 2, 2, 0, 1, 2, 0, 2, 1, 2, 0, 2, 1, 0, 0, 1, 2, 2, 0, 1, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 1, 0, 0, 1, 1, 0, 1, 2, 0, 1, 2, 2, 0, 0, 1, 2, 1, 2, 0, 0, 1, 1, 0, 1, 1, 0, 1, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 1, 2, 2, 1, 0, 1, 0, 0, 1, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 1, 2, 0, 2, 2, 0, 2, 2, 2, 1, 0, 0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 0, 1, 1, 2, 1, 2, 0, 0, 0, 1, 0, 2, 1, 2, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 0, 2, 2, 0, 0, 2, 2, 1, 1, 0, 0, 2, 0, 0, 1, 2, 2, 1, 2, 0, 0, 0, 2, 2, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 2, 2, 2, 0, 1, 0, 2, 1, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 2, 0, 0, 0, 0, 2, 1, 2, 0, 1, 1, 2, 1, 1, 1, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 0]
[0, 1, 1, 0, 1, 0, 2, 2, 1, 1, 0, 0, 0, 0, 1, 3, 1, 2, 2, 2, 0, 3, 1, 0, 3, 0, 0, 2, 1, 1, 2, 0, 1, 2, 2, 3, 1, 2, 1, 0, 1, 2, 3, 0, 2, 2, 0, 1, 1, 2, 3, 1, 0, 1, 1, 2, 1, 3, 2, 1, 1, 2, 2, 0, 2, 2, 3, 3, 2, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 0, 1, 2, 2, 3, 0, 2, 0, 3, 2, 0, 1, 2, 1, 3, 1, 2, 0, 0, 2, 0, 1, 3, 2, 1, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 2, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 1, 0, 0, 2, 0, 1, 2, 3, 1, 2, 2, 0, 0, 1, 2, 0, 0, 1, 3, 3, 2, 2, 2, 0, 2, 2, 0, 1, 3, 2, 3, 1, 0, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 0, 3, 0, 2, 2, 1, 1, 1, 2, 3, 1, 1, 0, 2, 2, 0, 0, 1, 1, 1, 2, 0, 2, 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 3, 3, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 2, 2, 2, 2, 2, 1, 1, 0, 1, 2, 3, 3, 1, 0, 0, 0, 2, 2, 1, 2, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 3, 1, 1, 2, 2, 0]
Centroids: [[-1.0489473, 1.2676007], [0.29436663, -1.4561812], [0.84269094, 2.7581053]]
Centroids: [[-0.020380227, -1.7454228], [0.7432526, 3.0061634], [-1.0202106, 1.152393], [1.2673795, -0.43083972]]
Standard Derivations: [0.63897103, 0.62190837, 0.6309566]
Cluster Distances: [1.7761385, 1.1383703, 1.7761385, 2.9969432, 1.1383703, 2.9969432]
Minimal Cluster Distance: 1.1383702754974365
Contingency Matrix: 
[[ 2 10 84  0]
 [70  1  0 23]
 [ 1 96  8  5]]
[[2, 10, 84, 0], [70, 1, 0, 23], [1, 96, 8, 5]]
[[2, 10, 84, 0], [70, 1, 0, 23], [1, 96, 8, 5]]
[0, 1, 2, 3]
[[2, -1, 84, 0], [70, -1, 0, 23], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [70, -1, -1, 23], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[84  2 10  0]
 [ 0 70  1 23]
 [ 8  1 96  5]]
New Clustered Label Sequence: [2, 0, 1, 3]
Diagonal_Elements: [84, 70, 96], Sum: 250
All_Elements: [84, 2, 10, 0, 0, 70, 1, 23, 8, 1, 96, 5], Sum: 300
Accuracy: 0.8333333333333334
