Experiment_path: AE_Model_2/Reduce_Training//V5_100/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Reduce_Training//V5_100/Experiment_05/C_Easy2_noise010.mat/Variant_05_Online_Autoencoder_QLearning/2023_05_25-10_28_50
Punishment_Coefficient: 0.7
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002C4D67877B8>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
Number of Clusters: 3
Online_Training [1/100]: mean_loss=0.19527359120547771
Online_Training [2/100]: mean_loss=0.11446700990200043
Online_Training [3/100]: mean_loss=0.16366861388087273
Online_Training [4/100]: mean_loss=0.1733571607619524
Online_Training [5/100]: mean_loss=0.08714599534869194
Online_Training [6/100]: mean_loss=0.13379769399762154
Online_Training [7/100]: mean_loss=0.09787097945809364
Online_Training [8/100]: mean_loss=0.13407660089433193
Online_Training [9/100]: mean_loss=0.10947480797767639
Online_Training [10/100]: mean_loss=0.11561282724142075
Online_Training [11/100]: mean_loss=0.06538240751251578
Online_Training [12/100]: mean_loss=0.08640924096107483
Online_Training [13/100]: mean_loss=0.07320245634764433
Online_Training [14/100]: mean_loss=0.09504516236484051
Online_Training [15/100]: mean_loss=0.08115658350288868
Online_Training [16/100]: mean_loss=0.06505122128874063
Online_Training [17/100]: mean_loss=0.11493020225316286
Online_Training [18/100]: mean_loss=0.0509871244430542
Online_Training [19/100]: mean_loss=0.06094505824148655
Online_Training [20/100]: mean_loss=0.059403580613434315
Online_Training [21/100]: mean_loss=0.05584857054054737
Online_Training [22/100]: mean_loss=0.12371100578457117
Online_Training [23/100]: mean_loss=0.15975791588425636
Online_Training [24/100]: mean_loss=0.029981949366629124
Online_Training [25/100]: mean_loss=0.04484987910836935
Online_Training [26/100]: mean_loss=0.12507416121661663
Online_Training [27/100]: mean_loss=0.07743923645466566
Online_Training [28/100]: mean_loss=0.20391037873923779
Online_Training [29/100]: mean_loss=0.03698872588574886
Online_Training [30/100]: mean_loss=0.033091042190790176
Online_Training [31/100]: mean_loss=0.09566742274910212
Online_Training [32/100]: mean_loss=0.06903451401740313
Online_Training [33/100]: mean_loss=0.019223765702918172
Online_Training [34/100]: mean_loss=0.0879120733588934
Online_Training [35/100]: mean_loss=0.036722722463309765
Online_Training [36/100]: mean_loss=0.09677619952708483
Online_Training [37/100]: mean_loss=0.030961033888161182
Online_Training [38/100]: mean_loss=0.029225562466308475
Online_Training [39/100]: mean_loss=0.02812477294355631
Online_Training [40/100]: mean_loss=0.04040983645245433
Online_Training [41/100]: mean_loss=0.10235720407217741
Online_Training [42/100]: mean_loss=0.07441815827041864
Online_Training [43/100]: mean_loss=0.02087478176690638
Online_Training [44/100]: mean_loss=0.05016411887481809
Online_Training [45/100]: mean_loss=0.019408483058214188
Online_Training [46/100]: mean_loss=0.09579417388886213
Online_Training [47/100]: mean_loss=0.029722961829975247
Online_Training [48/100]: mean_loss=0.06998549588024616
Online_Training [49/100]: mean_loss=0.015696620917879045
Online_Training [50/100]: mean_loss=0.01902663055807352
Online_Training [51/100]: mean_loss=0.024280880810692906
Online_Training [52/100]: mean_loss=0.02939424803480506
Online_Training [53/100]: mean_loss=0.019077429547905922
Online_Training [54/100]: mean_loss=0.031719275284558535
Online_Training [55/100]: mean_loss=0.07692536246031523
Online_Training [56/100]: mean_loss=0.08759458549320698
Online_Training [57/100]: mean_loss=0.012239724630489945
Online_Training [58/100]: mean_loss=0.027468736516311765
Online_Training [59/100]: mean_loss=0.1112309331074357
Online_Training [60/100]: mean_loss=0.08849829435348511
Online_Training [61/100]: mean_loss=0.02198309963569045
Online_Training [62/100]: mean_loss=0.035596434492617846
Online_Training [63/100]: mean_loss=0.0199763469863683
Online_Training [64/100]: mean_loss=0.04074232466518879
Online_Training [65/100]: mean_loss=0.016682534012943506
Online_Training [66/100]: mean_loss=0.021244085393846035
Online_Training [67/100]: mean_loss=0.025544110918417573
Online_Training [68/100]: mean_loss=0.07252408936619759
Online_Training [69/100]: mean_loss=0.02549512544646859
Online_Training [70/100]: mean_loss=0.02089731115847826
Online_Training [71/100]: mean_loss=0.034845079528167844
Online_Training [72/100]: mean_loss=0.07144157961010933
Online_Training [73/100]: mean_loss=0.024095118744298816
Online_Training [74/100]: mean_loss=0.0726832440122962
Online_Training [75/100]: mean_loss=0.021917622536420822
Online_Training [76/100]: mean_loss=0.05306348716840148
Online_Training [77/100]: mean_loss=0.07760914508253336
Online_Training [78/100]: mean_loss=0.008981736726127565
Online_Training [79/100]: mean_loss=0.005534355412237346
Online_Training [80/100]: mean_loss=0.02930263220332563
Online_Training [81/100]: mean_loss=0.023262592731043696
Online_Training [82/100]: mean_loss=0.01468038116581738
Online_Training [83/100]: mean_loss=0.029634277569130063
Online_Training [84/100]: mean_loss=0.03893078677356243
Online_Training [85/100]: mean_loss=0.018433382734656334
Online_Training [86/100]: mean_loss=0.010425892774946988
Online_Training [87/100]: mean_loss=0.12806371692568064
Online_Training [88/100]: mean_loss=0.17346026748418808
Online_Training [89/100]: mean_loss=0.028525551315397024
Online_Training [90/100]: mean_loss=0.020407208940014243
Online_Training [91/100]: mean_loss=0.01816408894956112
Online_Training [92/100]: mean_loss=0.041559658478945494
Online_Training [93/100]: mean_loss=0.016798792988993227
Online_Training [94/100]: mean_loss=0.02100001717917621
Online_Training [95/100]: mean_loss=0.09431785065680742
Online_Training [96/100]: mean_loss=0.12210843991488218
Online_Training [97/100]: mean_loss=0.015543868532404304
Online_Training [98/100]: mean_loss=0.019635755103081465
Online_Training [99/100]: mean_loss=0.07230424741283059
Online_Training [100/100]: mean_loss=0.15730352140963078
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-1.3344185 -1.7642791]
[0, 1, 0, 1, 0, 2, 2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 2, 2, 2, 0, 2, 2, 1, 0, 1, 1, 1, 1, 2, 0, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 0, 2, 1, 2, 1, 0, 0, 0, 2, 0, 0, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 2, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 2, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 0, 2, 1, 2, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 1, 2, 2, 1, 0, 1, 2, 0, 1, 1, 0, 0, 2, 0, 0, 1, 2, 1, 0, 2, 0, 0, 2, 2, 1, 1, 0, 1, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 0, 2, 0, 0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 1, 0, 0, 1, 0, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 0, 1, 1, 1, 2, 2, 0, 1, 0, 0, 2, 2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 0, 2, 1, 0, 1, 2, 0, 2, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 1, 1, 0, 0, 1, 1, 2, 0, 0, 0, 2, 1, 2, 0, 1, 2]
[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0, 2, 1, 0, 1, 0, 1, 0, 2, 2, 1, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 0, 2, 2, 1, 2, 2, 0, 1, 0, 2, 1, 2, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 1, 0, 2, 2, 0, 2, 1, 0, 1, 2, 1, 2, 1, 2, 2, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 2, 2, 1, 2, 0, 1, 0, 2, 0, 1, 0, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 0, 1, 2, 0, 0, 0, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 2, 2, 0, 0, 1, 0, 0, 3, 1, 0, 2, 0, 1, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 0, 2, 2, 0, 0, 1, 2, 2, 2, 1, 0, 0, 2, 0, 0]
Centroids: [[-1.5059625, -2.0274029], [-0.9288938, -1.2081072], [-0.34814653, 1.316764]]
Centroids: [[-1.0472559, -1.3453428], [-0.33173814, 1.3452008], [-1.5351543, -2.092844], [-2.416366, -3.1269746]]
Standard Derivations: [0.2402954, 0.27033502, 0.26571298]
Cluster Distances: [0.49149412, 3.0329165, 0.49149412, 2.0547516, 3.0329165, 2.0547516]
Minimal Cluster Distance: 0.4914941191673279
Contingency Matrix: 
[[ 34   0  65   1]
 [104   0   1   0]
 [  2  93   0   0]]
[[34, 0, 65, 1], [104, 0, 1, 0], [2, 93, 0, 0]]
[[34, 0, 65, 1], [104, 0, 1, 0], [2, 93, 0, 0]]
[0, 1, 2, 3]
[[-1, 0, 65, 1], [-1, -1, -1, -1], [-1, 93, 0, 0]]
[[-1, -1, 65, 1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
[[-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1]]
Match_Labels: {1: 0, 2: 1, 0: 2}
New Contingency Matrix: 
[[ 65  34   0   1]
 [  1 104   0   0]
 [  0   2  93   0]]
New Clustered Label Sequence: [2, 0, 1, 3]
Diagonal_Elements: [65, 104, 93], Sum: 262
All_Elements: [65, 34, 0, 1, 1, 104, 0, 0, 0, 2, 93, 0], Sum: 300
Accuracy: 0.8733333333333333
