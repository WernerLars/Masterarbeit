Experiment_path: Experiment_07
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: AE_Model_2/Grid_Search_PC//V5_2/C_Difficult1_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_05_03-15_00_48
Punishment_Coefficient: 1.4
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000168295CE8D0>
Sampling rate: 24000.0
Raw: [ 0.04887081  0.02693095 -0.0154249  ... -0.09301659 -0.11629005
 -0.14613101]
Times: [    340     491     641 ... 1439047 1439065 1439816]
Cluster: [1 1 1 ... 3 2 2]
Number of different clusters:  3
Number of Spikes: 3472
First aligned Spike Frame: [ 0.12751554  0.12305882  0.10482977  0.09479529  0.10214978  0.11675932
  0.11777927  0.09307299  0.04670706 -0.00574343 -0.06143573 -0.14637617
 -0.20942665 -0.00208103  0.52241508  0.81651544  0.46446121 -0.19226425
 -0.60927882 -0.6713583  -0.57871227 -0.49011309 -0.4269388  -0.3668903
 -0.30523219 -0.24747124 -0.19738203 -0.15189972 -0.10449507 -0.05533325
 -0.01452429  0.01008816  0.02570853  0.04365027  0.06334113  0.07980397
  0.08484457  0.07688513  0.06142919  0.04320028  0.02240626  0.00477291
 -0.00393242 -0.00135684  0.00575182  0.0026944  -0.01541647]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1172
Cluster 2, Occurrences: 1141
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.09397314582020044
Online_Training [2/700]: mean_loss=0.10217858664691448
Online_Training [3/700]: mean_loss=0.09752676729112864
Online_Training [4/700]: mean_loss=0.07433859445154667
Online_Training [5/700]: mean_loss=0.08873854018747807
Online_Training [6/700]: mean_loss=0.07786494679749012
Online_Training [7/700]: mean_loss=0.06350833689793944
Online_Training [8/700]: mean_loss=0.1179585661739111
Online_Training [9/700]: mean_loss=0.0712103908881545
Online_Training [10/700]: mean_loss=0.0705952225252986
Online_Training [11/700]: mean_loss=0.019701057579368353
Online_Training [12/700]: mean_loss=0.059673980344086885
Online_Training [13/700]: mean_loss=0.08085877448320389
Online_Training [14/700]: mean_loss=0.08632215019315481
Online_Training [15/700]: mean_loss=0.10559828951954842
Online_Training [16/700]: mean_loss=0.012644559144973755
Online_Training [17/700]: mean_loss=0.019465958001092076
Online_Training [18/700]: mean_loss=0.02917453832924366
Online_Training [19/700]: mean_loss=0.027949462179094553
Online_Training [20/700]: mean_loss=0.04780314210802317
Online_Training [21/700]: mean_loss=0.07443212158977985
Online_Training [22/700]: mean_loss=0.025448864325881004
Online_Training [23/700]: mean_loss=0.06842098059132695
Online_Training [24/700]: mean_loss=0.04349863715469837
Online_Training [25/700]: mean_loss=0.02611721050925553
Online_Training [26/700]: mean_loss=0.03701772494241595
Online_Training [27/700]: mean_loss=0.016134780133143067
Online_Training [28/700]: mean_loss=0.020377293461933732
Online_Training [29/700]: mean_loss=0.05835900641977787
Online_Training [30/700]: mean_loss=0.04126113187521696
Online_Training [31/700]: mean_loss=0.12738885171711445
Online_Training [32/700]: mean_loss=0.05684929946437478
Online_Training [33/700]: mean_loss=0.03933723317459226
Online_Training [34/700]: mean_loss=0.026335870381444693
Online_Training [35/700]: mean_loss=0.016278193099424243
Online_Training [36/700]: mean_loss=0.09356239438056946
Online_Training [37/700]: mean_loss=0.030475642532110214
Online_Training [38/700]: mean_loss=0.027286204043775797
Online_Training [39/700]: mean_loss=0.06328495685011148
Online_Training [40/700]: mean_loss=0.022326350677758455
Online_Training [41/700]: mean_loss=0.06296553974971175
Online_Training [42/700]: mean_loss=0.033823168370872736
Online_Training [43/700]: mean_loss=0.03569540334865451
Online_Training [44/700]: mean_loss=0.013359864242374897
Online_Training [45/700]: mean_loss=0.009938690811395645
Online_Training [46/700]: mean_loss=0.03053813916631043
Online_Training [47/700]: mean_loss=0.02080248761922121
Online_Training [48/700]: mean_loss=0.03534778719767928
Online_Training [49/700]: mean_loss=0.0054955981322564185
Online_Training [50/700]: mean_loss=0.03950990829616785
Online_Training [51/700]: mean_loss=0.04611998936161399
Online_Training [52/700]: mean_loss=0.1001456631347537
Online_Training [53/700]: mean_loss=0.01324718608520925
Online_Training [54/700]: mean_loss=0.010672280797734857
Online_Training [55/700]: mean_loss=0.02713759895414114
Online_Training [56/700]: mean_loss=0.0710312258452177
Online_Training [57/700]: mean_loss=0.07827310357242823
Online_Training [58/700]: mean_loss=0.05543779814615846
Online_Training [59/700]: mean_loss=0.042630007956176996
Online_Training [60/700]: mean_loss=0.07564797904342413
Online_Training [61/700]: mean_loss=0.043874428141862154
Online_Training [62/700]: mean_loss=0.09498889185488224
Online_Training [63/700]: mean_loss=0.04066305793821812
Online_Training [64/700]: mean_loss=0.026261977152898908
Online_Training [65/700]: mean_loss=0.028736030450090766
Online_Training [66/700]: mean_loss=0.028695827117189765
Online_Training [67/700]: mean_loss=0.04316624440252781
Online_Training [68/700]: mean_loss=0.015685392543673515
Online_Training [69/700]: mean_loss=0.023089387454092503
Online_Training [70/700]: mean_loss=0.05171227641403675
Online_Training [71/700]: mean_loss=0.07235103193670511
Online_Training [72/700]: mean_loss=0.023318362655118108
Online_Training [73/700]: mean_loss=0.039083731826394796
Online_Training [74/700]: mean_loss=0.03934704652056098
Online_Training [75/700]: mean_loss=0.03735246090218425
Online_Training [76/700]: mean_loss=0.027906429022550583
Online_Training [77/700]: mean_loss=0.04067141516134143
Online_Training [78/700]: mean_loss=0.041262330021709204
Online_Training [79/700]: mean_loss=0.014524680911563337
Online_Training [80/700]: mean_loss=0.022375137777999043
Online_Training [81/700]: mean_loss=0.08236963674426079
Online_Training [82/700]: mean_loss=0.0484643611125648
Online_Training [83/700]: mean_loss=0.03397712600417435
Online_Training [84/700]: mean_loss=0.033073111437261105
Online_Training [85/700]: mean_loss=0.016106265946291387
Online_Training [86/700]: mean_loss=0.03134338138625026
Online_Training [87/700]: mean_loss=0.1350499028339982
Online_Training [88/700]: mean_loss=0.09327582083642483
Online_Training [89/700]: mean_loss=0.03720394195988774
Online_Training [90/700]: mean_loss=0.023106751730665565
Online_Training [91/700]: mean_loss=0.016610271646641195
Online_Training [92/700]: mean_loss=0.08572633937001228
Online_Training [93/700]: mean_loss=0.031827476574108005
Online_Training [94/700]: mean_loss=0.031834934605285525
Online_Training [95/700]: mean_loss=0.0370706464163959
Online_Training [96/700]: mean_loss=0.02884936472401023
Online_Training [97/700]: mean_loss=0.03638620022684336
Online_Training [98/700]: mean_loss=0.0274060838855803
Online_Training [99/700]: mean_loss=0.05045072780922055
Online_Training [100/700]: mean_loss=0.022511999122798443
Online_Training [101/700]: mean_loss=0.027459373231977224
Online_Training [102/700]: mean_loss=0.03588941274210811
Online_Training [103/700]: mean_loss=0.008566202828660607
Online_Training [104/700]: mean_loss=0.06370636355131865
Online_Training [105/700]: mean_loss=0.045989800710231066
Online_Training [106/700]: mean_loss=0.05291416822001338
Online_Training [107/700]: mean_loss=0.03281687665730715
Online_Training [108/700]: mean_loss=0.015390274347737432
Online_Training [109/700]: mean_loss=0.017698266077786684
Online_Training [110/700]: mean_loss=0.017393815563991666
Online_Training [111/700]: mean_loss=0.024480399442836642
Online_Training [112/700]: mean_loss=0.03447575448080897
Online_Training [113/700]: mean_loss=0.1141852829605341
Online_Training [114/700]: mean_loss=0.07740298192948103
Online_Training [115/700]: mean_loss=0.02167863165959716
Online_Training [116/700]: mean_loss=0.043376816902309656
Online_Training [117/700]: mean_loss=0.024550122441723943
Online_Training [118/700]: mean_loss=0.029914291575551033
Online_Training [119/700]: mean_loss=0.03807640029117465
Online_Training [120/700]: mean_loss=0.012340189306996763
Online_Training [121/700]: mean_loss=0.0658495887182653
Online_Training [122/700]: mean_loss=0.06413992121815681
Online_Training [123/700]: mean_loss=0.02264370396733284
Online_Training [124/700]: mean_loss=0.015557818464003503
Online_Training [125/700]: mean_loss=0.0444643278606236
Online_Training [126/700]: mean_loss=0.1722047422081232
Online_Training [127/700]: mean_loss=0.054837801959365606
Online_Training [128/700]: mean_loss=0.045412583742290735
Online_Training [129/700]: mean_loss=0.035752585623413324
Online_Training [130/700]: mean_loss=0.042617976665496826
Online_Training [131/700]: mean_loss=0.12274495139718056
Online_Training [132/700]: mean_loss=0.13972090929746628
Online_Training [133/700]: mean_loss=0.019420343916863203
Online_Training [134/700]: mean_loss=0.02611474576406181
Online_Training [135/700]: mean_loss=0.06707540899515152
Online_Training [136/700]: mean_loss=0.16187377460300922
Online_Training [137/700]: mean_loss=0.01447483862284571
Online_Training [138/700]: mean_loss=0.048877769615501165
Online_Training [139/700]: mean_loss=0.02879344904795289
Online_Training [140/700]: mean_loss=0.024614609545096755
Online_Training [141/700]: mean_loss=0.033526604529470205
Online_Training [142/700]: mean_loss=0.05382490996271372
Online_Training [143/700]: mean_loss=0.017568274633958936
Online_Training [144/700]: mean_loss=0.01601964107248932
Online_Training [145/700]: mean_loss=0.02220876794308424
Online_Training [146/700]: mean_loss=0.02250588219612837
Online_Training [147/700]: mean_loss=0.016666294308379292
Online_Training [148/700]: mean_loss=0.022457221522927284
Online_Training [149/700]: mean_loss=0.02227833867073059
Online_Training [150/700]: mean_loss=0.025906966999173164
Online_Training [151/700]: mean_loss=0.012243580538779497
Online_Training [152/700]: mean_loss=0.026664480566978455
Online_Training [153/700]: mean_loss=0.04557977104559541
Online_Training [154/700]: mean_loss=0.013166398974135518
Online_Training [155/700]: mean_loss=0.041152570862323046
Online_Training [156/700]: mean_loss=0.03768535004928708
Online_Training [157/700]: mean_loss=0.03376830229535699
Online_Training [158/700]: mean_loss=0.03420779062435031
Online_Training [159/700]: mean_loss=0.01920084306038916
Online_Training [160/700]: mean_loss=0.037072671577334404
Online_Training [161/700]: mean_loss=0.0285677220672369
Online_Training [162/700]: mean_loss=0.042938674334436655
Online_Training [163/700]: mean_loss=0.011470193625427783
Online_Training [164/700]: mean_loss=0.028237066930159926
Online_Training [165/700]: mean_loss=0.02728505409322679
Online_Training [166/700]: mean_loss=0.027827756013721228
Online_Training [167/700]: mean_loss=0.031173710245639086
Online_Training [168/700]: mean_loss=0.03432101057842374
Online_Training [169/700]: mean_loss=0.03259240370243788
Online_Training [170/700]: mean_loss=0.019811106380075216
Online_Training [171/700]: mean_loss=0.030858374200761318
Online_Training [172/700]: mean_loss=0.017103155376389623
Online_Training [173/700]: mean_loss=0.020178163889795542
Online_Training [174/700]: mean_loss=0.026233994401991367
Online_Training [175/700]: mean_loss=0.03772301506251097
Online_Training [176/700]: mean_loss=0.0680127302184701
Online_Training [177/700]: mean_loss=0.012052952544763684
Online_Training [178/700]: mean_loss=0.020153285702690482
Online_Training [179/700]: mean_loss=0.01659165881574154
Online_Training [180/700]: mean_loss=0.014596333843655884
Online_Training [181/700]: mean_loss=0.01057110889814794
Online_Training [182/700]: mean_loss=0.07313288375735283
Online_Training [183/700]: mean_loss=0.013270320021547377
Online_Training [184/700]: mean_loss=0.017606857465580106
Online_Training [185/700]: mean_loss=0.03043968160636723
Online_Training [186/700]: mean_loss=0.024993411730974913
Online_Training [187/700]: mean_loss=0.019019316416233778
Online_Training [188/700]: mean_loss=0.02836164180189371
Online_Training [189/700]: mean_loss=0.030597115634009242
Online_Training [190/700]: mean_loss=0.013986588804982603
Online_Training [191/700]: mean_loss=0.02418771805241704
Online_Training [192/700]: mean_loss=0.013962609227746725
Online_Training [193/700]: mean_loss=0.029120062245056033
Online_Training [194/700]: mean_loss=0.0353299742564559
Online_Training [195/700]: mean_loss=0.0291827074252069
Online_Training [196/700]: mean_loss=0.0666397474706173
Online_Training [197/700]: mean_loss=0.060694434214383364
Online_Training [198/700]: mean_loss=0.029024755116552114
Online_Training [199/700]: mean_loss=0.02287673531100154
Online_Training [200/700]: mean_loss=0.028045291546732187
Online_Training [201/700]: mean_loss=0.017577962251380086
Online_Training [202/700]: mean_loss=0.029097864171490073
Online_Training [203/700]: mean_loss=0.011693244217894971
Online_Training [204/700]: mean_loss=0.015478612040169537
Online_Training [205/700]: mean_loss=0.01224723202176392
Online_Training [206/700]: mean_loss=0.03963551390916109
Online_Training [207/700]: mean_loss=0.01813094923272729
Online_Training [208/700]: mean_loss=0.029645745642483234
Online_Training [209/700]: mean_loss=0.028271488845348358
Online_Training [210/700]: mean_loss=0.03906992031261325
Online_Training [211/700]: mean_loss=0.01490464003290981
Online_Training [212/700]: mean_loss=0.031180500984191895
Online_Training [213/700]: mean_loss=0.016830351669341326
Online_Training [214/700]: mean_loss=0.024224175605922937
Online_Training [215/700]: mean_loss=0.02240510331466794
Online_Training [216/700]: mean_loss=0.03648871881887317
Online_Training [217/700]: mean_loss=0.011529344134032726
Online_Training [218/700]: mean_loss=0.01506362296640873
Online_Training [219/700]: mean_loss=0.012493350077420473
Online_Training [220/700]: mean_loss=0.023812714498490095
Online_Training [221/700]: mean_loss=0.016238417592830956
Online_Training [222/700]: mean_loss=0.01953015197068453
Online_Training [223/700]: mean_loss=0.07780478149652481
Online_Training [224/700]: mean_loss=0.0325621603988111
Online_Training [225/700]: mean_loss=0.014352764817886055
Online_Training [226/700]: mean_loss=0.010026139905676246
Online_Training [227/700]: mean_loss=0.02701192256063223
Online_Training [228/700]: mean_loss=0.10387047939002514
Online_Training [229/700]: mean_loss=0.09035975951701403
Online_Training [230/700]: mean_loss=0.012902536313049495
Online_Training [231/700]: mean_loss=0.023530657636001706
Online_Training [232/700]: mean_loss=0.014185465406626463
Online_Training [233/700]: mean_loss=0.013198726112022996
Online_Training [234/700]: mean_loss=0.06742752902209759
Online_Training [235/700]: mean_loss=0.02032006182707846
Online_Training [236/700]: mean_loss=0.01887163962237537
Online_Training [237/700]: mean_loss=0.02026451611891389
Online_Training [238/700]: mean_loss=0.03129729232750833
Online_Training [239/700]: mean_loss=0.02585566695779562
Online_Training [240/700]: mean_loss=0.01962413382716477
Online_Training [241/700]: mean_loss=0.031041596550494432
Online_Training [242/700]: mean_loss=0.01656209328211844
Online_Training [243/700]: mean_loss=0.019862559624016285
Online_Training [244/700]: mean_loss=0.01587703009136021
Online_Training [245/700]: mean_loss=0.014826732454821467
Online_Training [246/700]: mean_loss=0.022496439050883055
Online_Training [247/700]: mean_loss=0.03343129949644208
Online_Training [248/700]: mean_loss=0.02188418060541153
Online_Training [249/700]: mean_loss=0.024735886370763183
Online_Training [250/700]: mean_loss=0.01594859967008233
Online_Training [251/700]: mean_loss=0.007885186118073761
Online_Training [252/700]: mean_loss=0.026145205600187182
Online_Training [253/700]: mean_loss=0.0075667822966352105
Online_Training [254/700]: mean_loss=0.003777644509682432
Online_Training [255/700]: mean_loss=0.017903226427733898
Online_Training [256/700]: mean_loss=0.033164181280881166
Online_Training [257/700]: mean_loss=0.06357297208160162
Online_Training [258/700]: mean_loss=0.10680619720369577
Online_Training [259/700]: mean_loss=0.08898567128926516
Online_Training [260/700]: mean_loss=0.04664819082245231
Online_Training [261/700]: mean_loss=0.012561394483782351
Online_Training [262/700]: mean_loss=0.011959340539760888
Online_Training [263/700]: mean_loss=0.12833973858505487
Online_Training [264/700]: mean_loss=0.06618683785200119
Online_Training [265/700]: mean_loss=0.04446292435750365
Online_Training [266/700]: mean_loss=0.027588059660047293
Online_Training [267/700]: mean_loss=0.040557550732046366
Online_Training [268/700]: mean_loss=0.027573154773563147
Online_Training [269/700]: mean_loss=0.028074705507606268
Online_Training [270/700]: mean_loss=0.016120340209454298
Online_Training [271/700]: mean_loss=0.02446353156119585
Online_Training [272/700]: mean_loss=0.010927775467280298
Online_Training [273/700]: mean_loss=0.010713114868849516
Online_Training [274/700]: mean_loss=0.08870079554617405
Online_Training [275/700]: mean_loss=0.05799455940723419
Online_Training [276/700]: mean_loss=0.03945754235610366
Online_Training [277/700]: mean_loss=0.022396337473765016
Online_Training [278/700]: mean_loss=0.04023824259638786
Online_Training [279/700]: mean_loss=0.04334188811480999
Online_Training [280/700]: mean_loss=0.02670092135667801
Online_Training [281/700]: mean_loss=0.18430104851722717
Online_Training [282/700]: mean_loss=0.158487344160676
Online_Training [283/700]: mean_loss=0.11283648107200861
Online_Training [284/700]: mean_loss=0.033504603896290064
Online_Training [285/700]: mean_loss=0.035308219492435455
Online_Training [286/700]: mean_loss=0.042984812054783106
Online_Training [287/700]: mean_loss=0.04561829101294279
Online_Training [288/700]: mean_loss=0.01478592783678323
Online_Training [289/700]: mean_loss=0.029510913882404566
Online_Training [290/700]: mean_loss=0.012135219760239124
Online_Training [291/700]: mean_loss=0.10414674319326878
Online_Training [292/700]: mean_loss=0.025229043094441295
Online_Training [293/700]: mean_loss=0.010042436653748155
Online_Training [294/700]: mean_loss=0.005194538040086627
Online_Training [295/700]: mean_loss=0.03344368562102318
Online_Training [296/700]: mean_loss=0.01020329212769866
Online_Training [297/700]: mean_loss=0.026950020343065262
Online_Training [298/700]: mean_loss=0.00985189329367131
Online_Training [299/700]: mean_loss=0.01416964246891439
Online_Training [300/700]: mean_loss=0.015938651165924966
Online_Training [301/700]: mean_loss=0.02124266093596816
Online_Training [302/700]: mean_loss=0.010689790826290846
Online_Training [303/700]: mean_loss=0.00982437387574464
Online_Training [304/700]: mean_loss=0.029619408305734396
Online_Training [305/700]: mean_loss=0.029071488650515676
Online_Training [306/700]: mean_loss=0.010213696165010333
Online_Training [307/700]: mean_loss=0.024089322425425053
Online_Training [308/700]: mean_loss=0.03483331808820367
Online_Training [309/700]: mean_loss=0.008845158386975527
Online_Training [310/700]: mean_loss=0.025211228290572762
Online_Training [311/700]: mean_loss=0.03770169708877802
Online_Training [312/700]: mean_loss=0.027534210588783026
Online_Training [313/700]: mean_loss=0.0377179984934628
Online_Training [314/700]: mean_loss=0.02643327647820115
Online_Training [315/700]: mean_loss=0.01655321940779686
Online_Training [316/700]: mean_loss=0.018973263446241617
Online_Training [317/700]: mean_loss=0.050979627296328545
Online_Training [318/700]: mean_loss=0.018688085954636335
Online_Training [319/700]: mean_loss=0.017283784225583076
Online_Training [320/700]: mean_loss=0.019141473807394505
Online_Training [321/700]: mean_loss=0.027354679303243756
Online_Training [322/700]: mean_loss=0.03420901531353593
Online_Training [323/700]: mean_loss=0.009301716578193009
Online_Training [324/700]: mean_loss=0.010200080228969455
Online_Training [325/700]: mean_loss=0.014019938185811043
Online_Training [326/700]: mean_loss=0.02851912286132574
Online_Training [327/700]: mean_loss=0.006143229082226753
Online_Training [328/700]: mean_loss=0.0134300806093961
Online_Training [329/700]: mean_loss=0.023883873596787453
Online_Training [330/700]: mean_loss=0.03231651522219181
Online_Training [331/700]: mean_loss=0.028279990423470736
Online_Training [332/700]: mean_loss=0.02424358786083758
Online_Training [333/700]: mean_loss=0.016775419237092137
Online_Training [334/700]: mean_loss=0.020067655248567462
Online_Training [335/700]: mean_loss=0.04024259187281132
Online_Training [336/700]: mean_loss=0.016449029091745615
Online_Training [337/700]: mean_loss=0.028077604016289115
Online_Training [338/700]: mean_loss=0.02803350519388914
Online_Training [339/700]: mean_loss=0.013996660825796425
Online_Training [340/700]: mean_loss=0.0312859567347914
Online_Training [341/700]: mean_loss=0.03077527415007353
Online_Training [342/700]: mean_loss=0.015633024740964174
Online_Training [343/700]: mean_loss=0.009290624991990626
Online_Training [344/700]: mean_loss=0.022468638373538852
Online_Training [345/700]: mean_loss=0.03412788175046444
Online_Training [346/700]: mean_loss=0.015447064535692334
Online_Training [347/700]: mean_loss=0.010232041240669787
Online_Training [348/700]: mean_loss=0.03183503542095423
Online_Training [349/700]: mean_loss=0.02682932699099183
Online_Training [350/700]: mean_loss=0.020122671267017722
Online_Training [351/700]: mean_loss=0.022185734007507563
Online_Training [352/700]: mean_loss=0.026893777074292302
Online_Training [353/700]: mean_loss=0.017909112852066755
Online_Training [354/700]: mean_loss=0.019457366317510605
Online_Training [355/700]: mean_loss=0.023676492972299457
Online_Training [356/700]: mean_loss=0.010033019236288965
Online_Training [357/700]: mean_loss=0.012231149361468852
Online_Training [358/700]: mean_loss=0.018579203635454178
Online_Training [359/700]: mean_loss=0.015979320625774562
Online_Training [360/700]: mean_loss=0.040158843621611595
Online_Training [361/700]: mean_loss=0.008962189545854926
Online_Training [362/700]: mean_loss=0.04096179082989693
Online_Training [363/700]: mean_loss=0.03179072914645076
Online_Training [364/700]: mean_loss=0.011035478790290654
Online_Training [365/700]: mean_loss=0.018323223805055022
Online_Training [366/700]: mean_loss=0.029018227709457278
Online_Training [367/700]: mean_loss=0.016772086615674198
Online_Training [368/700]: mean_loss=0.05381185654550791
Online_Training [369/700]: mean_loss=0.03182896226644516
Online_Training [370/700]: mean_loss=0.02058645454235375
Online_Training [371/700]: mean_loss=0.05015589389950037
Online_Training [372/700]: mean_loss=0.00854294904274866
Online_Training [373/700]: mean_loss=0.009335493319667876
Online_Training [374/700]: mean_loss=0.032320325961336493
Online_Training [375/700]: mean_loss=0.02330807689577341
Online_Training [376/700]: mean_loss=0.022302950033918023
Online_Training [377/700]: mean_loss=0.015582868945784867
Online_Training [378/700]: mean_loss=0.02775239059701562
Online_Training [379/700]: mean_loss=0.022784604923799634
Online_Training [380/700]: mean_loss=0.02074626716785133
Online_Training [381/700]: mean_loss=0.01488654047716409
Online_Training [382/700]: mean_loss=0.03862005192786455
Online_Training [383/700]: mean_loss=0.030977460090070963
Online_Training [384/700]: mean_loss=0.13562026154249907
Online_Training [385/700]: mean_loss=0.0673454743809998
Online_Training [386/700]: mean_loss=0.03403324820101261
Online_Training [387/700]: mean_loss=0.016159819206222892
Online_Training [388/700]: mean_loss=0.018682501278817654
Online_Training [389/700]: mean_loss=0.020615164656192064
Online_Training [390/700]: mean_loss=0.013857434038072824
Online_Training [391/700]: mean_loss=0.021348658483475447
Online_Training [392/700]: mean_loss=0.00458744732895866
Online_Training [393/700]: mean_loss=0.0264514172449708
Online_Training [394/700]: mean_loss=0.014749761437997222
Online_Training [395/700]: mean_loss=0.013394139357842505
Online_Training [396/700]: mean_loss=0.025642164051532745
Online_Training [397/700]: mean_loss=0.009594292379915714
Online_Training [398/700]: mean_loss=0.021190028870478272
Online_Training [399/700]: mean_loss=0.03501513274386525
Online_Training [400/700]: mean_loss=0.021508043631911278
Online_Training [401/700]: mean_loss=0.030571975512430072
Online_Training [402/700]: mean_loss=0.10240250360220671
Online_Training [403/700]: mean_loss=0.026410923805087805
Online_Training [404/700]: mean_loss=0.028491246048361063
Online_Training [405/700]: mean_loss=0.03130795760080218
Online_Training [406/700]: mean_loss=0.03321521310135722
Online_Training [407/700]: mean_loss=0.016889999504201114
Online_Training [408/700]: mean_loss=0.01987404190003872
Online_Training [409/700]: mean_loss=0.03076741471886635
Online_Training [410/700]: mean_loss=0.012029407895170152
Online_Training [411/700]: mean_loss=0.029788132989779115
Online_Training [412/700]: mean_loss=0.017952590715140104
Online_Training [413/700]: mean_loss=0.020021969685330987
Online_Training [414/700]: mean_loss=0.025771761080250144
Online_Training [415/700]: mean_loss=0.01252900273539126
Online_Training [416/700]: mean_loss=0.01272803486790508
Online_Training [417/700]: mean_loss=0.0734487334266305
Online_Training [418/700]: mean_loss=0.0665592891164124
Online_Training [419/700]: mean_loss=0.029664136935025454
Online_Training [420/700]: mean_loss=0.030307402834296227
Online_Training [421/700]: mean_loss=0.008401775266975164
Online_Training [422/700]: mean_loss=0.025573901599273086
Online_Training [423/700]: mean_loss=0.015432818792760372
Online_Training [424/700]: mean_loss=0.03376452950760722
Online_Training [425/700]: mean_loss=0.03680327394977212
Online_Training [426/700]: mean_loss=0.03657775744795799
Online_Training [427/700]: mean_loss=0.014542844612151384
Online_Training [428/700]: mean_loss=0.02369255805388093
Online_Training [429/700]: mean_loss=0.022301840828731656
Online_Training [430/700]: mean_loss=0.023045691195875406
Online_Training [431/700]: mean_loss=0.007901665638200939
Online_Training [432/700]: mean_loss=0.04147796053439379
Online_Training [433/700]: mean_loss=0.012223253026604652
Online_Training [434/700]: mean_loss=0.010499643161892891
Online_Training [435/700]: mean_loss=0.013271730276755989
Online_Training [436/700]: mean_loss=0.0320582976564765
Online_Training [437/700]: mean_loss=0.015591135481372476
Online_Training [438/700]: mean_loss=0.06029356084764004
Online_Training [439/700]: mean_loss=0.021078271558508277
Online_Training [440/700]: mean_loss=0.02187170274555683
Online_Training [441/700]: mean_loss=0.11208511516451836
Online_Training [442/700]: mean_loss=0.07606151327490807
Online_Training [443/700]: mean_loss=0.010486806160770357
Online_Training [444/700]: mean_loss=0.026250148890540004
Online_Training [445/700]: mean_loss=0.04521027486771345
Online_Training [446/700]: mean_loss=0.01562879781704396
Online_Training [447/700]: mean_loss=0.014823875739239156
Online_Training [448/700]: mean_loss=0.07551073934882879
Online_Training [449/700]: mean_loss=0.11637642700225115
Online_Training [450/700]: mean_loss=0.04624547250568867
Online_Training [451/700]: mean_loss=0.021840974921360612
Online_Training [452/700]: mean_loss=0.03918140707537532
Online_Training [453/700]: mean_loss=0.02627258258871734
Online_Training [454/700]: mean_loss=0.020891493186354637
Online_Training [455/700]: mean_loss=0.00908711802912876
Online_Training [456/700]: mean_loss=0.017181182047352195
Online_Training [457/700]: mean_loss=0.01841057650744915
Online_Training [458/700]: mean_loss=0.01685988565441221
Online_Training [459/700]: mean_loss=0.019561711931601167
Online_Training [460/700]: mean_loss=0.037381372414529324
Online_Training [461/700]: mean_loss=0.008267687284387648
Online_Training [462/700]: mean_loss=0.01788234687410295
Online_Training [463/700]: mean_loss=0.022938384674489498
Online_Training [464/700]: mean_loss=0.02458496601320803
Online_Training [465/700]: mean_loss=0.023564289789646864
Online_Training [466/700]: mean_loss=0.021853221114724874
Online_Training [467/700]: mean_loss=0.007531965500675142
Online_Training [468/700]: mean_loss=0.004484160395804793
Online_Training [469/700]: mean_loss=0.01679749821778387
Online_Training [470/700]: mean_loss=0.013488185941241682
Online_Training [471/700]: mean_loss=0.015697767375968397
Online_Training [472/700]: mean_loss=0.008990556409116834
Online_Training [473/700]: mean_loss=0.00677932205144316
Online_Training [474/700]: mean_loss=0.10779982339590788
Online_Training [475/700]: mean_loss=0.16898399032652378
Online_Training [476/700]: mean_loss=0.006312688521575183
Online_Training [477/700]: mean_loss=0.018914861837401986
Online_Training [478/700]: mean_loss=0.02530051744543016
Online_Training [479/700]: mean_loss=0.0403736880980432
Online_Training [480/700]: mean_loss=0.010506244958378375
Online_Training [481/700]: mean_loss=0.015755711938254535
Online_Training [482/700]: mean_loss=0.020684494404122233
Online_Training [483/700]: mean_loss=0.017334233969449997
Online_Training [484/700]: mean_loss=0.01727763283997774
Online_Training [485/700]: mean_loss=0.07204871065914631
Online_Training [486/700]: mean_loss=0.02094615064561367
Online_Training [487/700]: mean_loss=0.023167071398347616
Online_Training [488/700]: mean_loss=0.021161026787012815
Online_Training [489/700]: mean_loss=0.009949004394002259
Online_Training [490/700]: mean_loss=0.020212278701364994
Online_Training [491/700]: mean_loss=0.017391259549185634
Online_Training [492/700]: mean_loss=0.014290707418695092
Online_Training [493/700]: mean_loss=0.011883752420544624
Online_Training [494/700]: mean_loss=0.018908420111984015
Online_Training [495/700]: mean_loss=0.058110395912081
Online_Training [496/700]: mean_loss=0.026770499302074313
Online_Training [497/700]: mean_loss=0.014158926205709577
Online_Training [498/700]: mean_loss=0.020713515114039183
Online_Training [499/700]: mean_loss=0.02186170546337962
Online_Training [500/700]: mean_loss=0.009647367056459188
Online_Training [501/700]: mean_loss=0.019451783504337072
Online_Training [502/700]: mean_loss=0.01918679801747203
Online_Training [503/700]: mean_loss=0.08797870576381683
Online_Training [504/700]: mean_loss=0.0544831152074039
Online_Training [505/700]: mean_loss=0.03561518341302872
Online_Training [506/700]: mean_loss=0.042834363877773285
Online_Training [507/700]: mean_loss=0.02462803781963885
Online_Training [508/700]: mean_loss=0.015721562202088535
Online_Training [509/700]: mean_loss=0.028183483984321356
Online_Training [510/700]: mean_loss=0.010371686774306
Online_Training [511/700]: mean_loss=0.014295333181507885
Online_Training [512/700]: mean_loss=0.016243110178038478
Online_Training [513/700]: mean_loss=0.011445483658462763
Online_Training [514/700]: mean_loss=0.009125390672124922
Online_Training [515/700]: mean_loss=0.018987096147611737
Online_Training [516/700]: mean_loss=0.02620371850207448
Online_Training [517/700]: mean_loss=0.003779074875637889
Online_Training [518/700]: mean_loss=0.01415780431125313
Online_Training [519/700]: mean_loss=0.03864249121397734
Online_Training [520/700]: mean_loss=0.021246178075671196
Online_Training [521/700]: mean_loss=0.01567864092066884
Online_Training [522/700]: mean_loss=0.0241272144485265
Online_Training [523/700]: mean_loss=0.022479898063465953
Online_Training [524/700]: mean_loss=0.020071909064427018
Online_Training [525/700]: mean_loss=0.014939140412025154
Online_Training [526/700]: mean_loss=0.01106030191294849
Online_Training [527/700]: mean_loss=0.014817560673691332
Online_Training [528/700]: mean_loss=0.05151430517435074
Online_Training [529/700]: mean_loss=0.020412895595654845
Online_Training [530/700]: mean_loss=0.011756571242585778
Online_Training [531/700]: mean_loss=0.04029680322855711
Online_Training [532/700]: mean_loss=0.02088788035325706
Online_Training [533/700]: mean_loss=0.01392918557394296
Online_Training [534/700]: mean_loss=0.01852748286910355
Online_Training [535/700]: mean_loss=0.016129289055243134
Online_Training [536/700]: mean_loss=0.022359344409778714
Online_Training [537/700]: mean_loss=0.01699982094578445
Online_Training [538/700]: mean_loss=0.006817432702519
Online_Training [539/700]: mean_loss=0.01690078596584499
Online_Training [540/700]: mean_loss=0.02853716560639441
Online_Training [541/700]: mean_loss=0.009734871215187013
Online_Training [542/700]: mean_loss=0.0066236513666808605
Online_Training [543/700]: mean_loss=0.02111543994396925
Online_Training [544/700]: mean_loss=0.02978534810245037
Online_Training [545/700]: mean_loss=0.019815719919279218
Online_Training [546/700]: mean_loss=0.011794891208410263
Online_Training [547/700]: mean_loss=0.01164104393683374
Online_Training [548/700]: mean_loss=0.06551306461915374
Online_Training [549/700]: mean_loss=0.04266087198629975
Online_Training [550/700]: mean_loss=0.0148960433434695
Online_Training [551/700]: mean_loss=0.021349221235141158
Online_Training [552/700]: mean_loss=0.05159548716619611
Online_Training [553/700]: mean_loss=0.01845448464155197
Online_Training [554/700]: mean_loss=0.013146915240213275
Online_Training [555/700]: mean_loss=0.05665169656276703
Online_Training [556/700]: mean_loss=0.014531996799632907
Online_Training [557/700]: mean_loss=0.014343144372105598
Online_Training [558/700]: mean_loss=0.012593657826073468
Online_Training [559/700]: mean_loss=0.02649927302263677
Online_Training [560/700]: mean_loss=0.018577276030555367
Online_Training [561/700]: mean_loss=0.013469866709783673
Online_Training [562/700]: mean_loss=0.017236573388800025
Online_Training [563/700]: mean_loss=0.009402965195477009
Online_Training [564/700]: mean_loss=0.005425747018307447
Online_Training [565/700]: mean_loss=0.0648851958103478
Online_Training [566/700]: mean_loss=0.008192569890525192
Online_Training [567/700]: mean_loss=0.012158040655776858
Online_Training [568/700]: mean_loss=0.013088713982142508
Online_Training [569/700]: mean_loss=0.007867069740314037
Online_Training [570/700]: mean_loss=0.02887474512681365
Online_Training [571/700]: mean_loss=0.033169724978506565
Online_Training [572/700]: mean_loss=0.010004613199271262
Online_Training [573/700]: mean_loss=0.02939881244674325
Online_Training [574/700]: mean_loss=0.015872000018134713
Online_Training [575/700]: mean_loss=0.024964299984276295
Online_Training [576/700]: mean_loss=0.023268970660865307
Online_Training [577/700]: mean_loss=0.013438251102343202
Online_Training [578/700]: mean_loss=0.010818739072419703
Online_Training [579/700]: mean_loss=0.016115382546558976
Online_Training [580/700]: mean_loss=0.010223311022855341
Online_Training [581/700]: mean_loss=0.021528736222535372
Online_Training [582/700]: mean_loss=0.021131371380761266
Online_Training [583/700]: mean_loss=0.007495776051655412
Online_Training [584/700]: mean_loss=0.014572498854249716
Online_Training [585/700]: mean_loss=0.07375229056924582
Online_Training [586/700]: mean_loss=0.0711235674098134
Online_Training [587/700]: mean_loss=0.013948145555332303
Online_Training [588/700]: mean_loss=0.028923106845468283
Online_Training [589/700]: mean_loss=0.02272165287286043
Online_Training [590/700]: mean_loss=0.042230143677443266
Online_Training [591/700]: mean_loss=0.01805219193920493
Online_Training [592/700]: mean_loss=0.016885343473404646
Online_Training [593/700]: mean_loss=0.011230987729504704
Online_Training [594/700]: mean_loss=0.05925004277378321
Online_Training [595/700]: mean_loss=0.008277553250081837
Online_Training [596/700]: mean_loss=0.018993433099240065
Online_Training [597/700]: mean_loss=0.025224826531484723
Online_Training [598/700]: mean_loss=0.016271121916361153
Online_Training [599/700]: mean_loss=0.009139568195678294
Online_Training [600/700]: mean_loss=0.014641345362178981
Online_Training [601/700]: mean_loss=0.014954310841858387
Online_Training [602/700]: mean_loss=0.014849684899672866
Online_Training [603/700]: mean_loss=0.011465040850453079
Online_Training [604/700]: mean_loss=0.01143426401540637
Online_Training [605/700]: mean_loss=0.0237546234857291
Online_Training [606/700]: mean_loss=0.01010475354269147
Online_Training [607/700]: mean_loss=0.13349425420165062
Online_Training [608/700]: mean_loss=0.05154327256605029
Online_Training [609/700]: mean_loss=0.016771002439782023
Online_Training [610/700]: mean_loss=0.04653815599158406
Online_Training [611/700]: mean_loss=0.02971125696785748
Online_Training [612/700]: mean_loss=0.025572121143341064
Online_Training [613/700]: mean_loss=0.02781195379793644
Online_Training [614/700]: mean_loss=0.01220389420632273
Online_Training [615/700]: mean_loss=0.01739765319507569
Online_Training [616/700]: mean_loss=0.015862030442804098
Online_Training [617/700]: mean_loss=0.01327854604460299
Online_Training [618/700]: mean_loss=0.007101001043338329
Online_Training [619/700]: mean_loss=0.011124031501822174
Online_Training [620/700]: mean_loss=0.017382753314450383
Online_Training [621/700]: mean_loss=0.0188814215362072
Online_Training [622/700]: mean_loss=0.004055780154885724
Online_Training [623/700]: mean_loss=0.007660617353394628
Online_Training [624/700]: mean_loss=0.02021088427864015
Online_Training [625/700]: mean_loss=0.0058204299421049654
Online_Training [626/700]: mean_loss=0.025686825858429074
Online_Training [627/700]: mean_loss=0.008906212635338306
Online_Training [628/700]: mean_loss=0.017874849261716008
Online_Training [629/700]: mean_loss=0.030558654107153416
Online_Training [630/700]: mean_loss=0.006991604808717966
Online_Training [631/700]: mean_loss=0.03571586450561881
Online_Training [632/700]: mean_loss=0.006629143375903368
Online_Training [633/700]: mean_loss=0.008438173565082252
Online_Training [634/700]: mean_loss=0.009485825547017157
Online_Training [635/700]: mean_loss=0.013645180617459118
Online_Training [636/700]: mean_loss=0.01588299428112805
Online_Training [637/700]: mean_loss=0.01122182176914066
Online_Training [638/700]: mean_loss=0.041431725025177
Online_Training [639/700]: mean_loss=0.023445161757990718
Online_Training [640/700]: mean_loss=0.014384935959242284
Online_Training [641/700]: mean_loss=0.022415894316509366
Online_Training [642/700]: mean_loss=0.01020370377227664
Online_Training [643/700]: mean_loss=0.04434930207207799
Online_Training [644/700]: mean_loss=0.015857674879953265
Online_Training [645/700]: mean_loss=0.01777453371323645
Online_Training [646/700]: mean_loss=0.03346046363003552
Online_Training [647/700]: mean_loss=0.012926655705086887
Online_Training [648/700]: mean_loss=0.012141151120886207
Online_Training [649/700]: mean_loss=0.011463250732049346
Online_Training [650/700]: mean_loss=0.017196221509948373
Online_Training [651/700]: mean_loss=0.019341370090842247
Online_Training [652/700]: mean_loss=0.02606750326231122
Online_Training [653/700]: mean_loss=0.01712499570567161
Online_Training [654/700]: mean_loss=0.02948688413016498
Online_Training [655/700]: mean_loss=0.014363516587764025
Online_Training [656/700]: mean_loss=0.02761986805126071
Online_Training [657/700]: mean_loss=0.00468241045018658
Online_Training [658/700]: mean_loss=0.03476352011784911
Online_Training [659/700]: mean_loss=0.09284094348549843
Online_Training [660/700]: mean_loss=0.06723156478255987
Online_Training [661/700]: mean_loss=0.026586324675008655
Online_Training [662/700]: mean_loss=0.046371280681341887
Online_Training [663/700]: mean_loss=0.02246858598664403
Online_Training [664/700]: mean_loss=0.017842415487393737
Online_Training [665/700]: mean_loss=0.02416027570143342
Online_Training [666/700]: mean_loss=0.036359633319079876
Online_Training [667/700]: mean_loss=0.015607467852532864
Online_Training [668/700]: mean_loss=0.017742966301739216
Online_Training [669/700]: mean_loss=0.013759044464677572
Online_Training [670/700]: mean_loss=0.04520441126078367
Online_Training [671/700]: mean_loss=0.033008227590471506
Online_Training [672/700]: mean_loss=0.008679723658133298
Online_Training [673/700]: mean_loss=0.01837750058621168
Online_Training [674/700]: mean_loss=0.026949777035042644
Online_Training [675/700]: mean_loss=0.014736417564563453
Online_Training [676/700]: mean_loss=0.009366712300106883
Online_Training [677/700]: mean_loss=0.03573785629123449
Online_Training [678/700]: mean_loss=0.009637687122449279
Online_Training [679/700]: mean_loss=0.013108576997183263
Online_Training [680/700]: mean_loss=0.009196879691444337
Online_Training [681/700]: mean_loss=0.027921896427869797
Online_Training [682/700]: mean_loss=0.015547239920124412
Online_Training [683/700]: mean_loss=0.0050194619107060134
Online_Training [684/700]: mean_loss=0.01039837789721787
Online_Training [685/700]: mean_loss=0.07047564536333084
Online_Training [686/700]: mean_loss=0.05538826109841466
Online_Training [687/700]: mean_loss=0.012090856209397316
Online_Training [688/700]: mean_loss=0.025621124310418963
Online_Training [689/700]: mean_loss=0.017343262676149607
Online_Training [690/700]: mean_loss=0.01284515904262662
Online_Training [691/700]: mean_loss=0.035365976858884096
Online_Training [692/700]: mean_loss=0.01999852084554732
Online_Training [693/700]: mean_loss=0.005913228611461818
Online_Training [694/700]: mean_loss=0.007960058806929737
Online_Training [695/700]: mean_loss=0.009031939902342856
Online_Training [696/700]: mean_loss=0.021023902110755444
Online_Training [697/700]: mean_loss=0.021938743768259883
Online_Training [698/700]: mean_loss=0.003395769512280822
Online_Training [699/700]: mean_loss=0.02347044530324638
Online_Training [700/700]: mean_loss=0.07499641086906195
Q_Learning [1/300]: mean_loss=0.09397314582020044
Q_Learning [2/300]: mean_loss=0.10217858664691448
Q_Learning [3/300]: mean_loss=0.09752676729112864
Q_Learning [4/300]: mean_loss=0.07433859445154667
Q_Learning [5/300]: mean_loss=0.08873854018747807
Q_Learning [6/300]: mean_loss=0.07786494679749012
Q_Learning [7/300]: mean_loss=0.06350833689793944
Q_Learning [8/300]: mean_loss=0.1179585661739111
Q_Learning [9/300]: mean_loss=0.0712103908881545
Q_Learning [10/300]: mean_loss=0.0705952225252986
Q_Learning [11/300]: mean_loss=0.019701057579368353
Q_Learning [12/300]: mean_loss=0.059673980344086885
Q_Learning [13/300]: mean_loss=0.08085877448320389
Q_Learning [14/300]: mean_loss=0.08632215019315481
Q_Learning [15/300]: mean_loss=0.10559828951954842
Q_Learning [16/300]: mean_loss=0.012644559144973755
Q_Learning [17/300]: mean_loss=0.019465958001092076
Q_Learning [18/300]: mean_loss=0.02917453832924366
Q_Learning [19/300]: mean_loss=0.027949462179094553
Q_Learning [20/300]: mean_loss=0.04780314210802317
Q_Learning [21/300]: mean_loss=0.07443212158977985
Q_Learning [22/300]: mean_loss=0.025448864325881004
Q_Learning [23/300]: mean_loss=0.06842098059132695
Q_Learning [24/300]: mean_loss=0.04349863715469837
Q_Learning [25/300]: mean_loss=0.02611721050925553
Q_Learning [26/300]: mean_loss=0.03701772494241595
Q_Learning [27/300]: mean_loss=0.016134780133143067
Q_Learning [28/300]: mean_loss=0.020377293461933732
Q_Learning [29/300]: mean_loss=0.05835900641977787
Q_Learning [30/300]: mean_loss=0.04126113187521696
Q_Learning [31/300]: mean_loss=0.12738885171711445
Q_Learning [32/300]: mean_loss=0.05684929946437478
Q_Learning [33/300]: mean_loss=0.03933723317459226
Q_Learning [34/300]: mean_loss=0.026335870381444693
Q_Learning [35/300]: mean_loss=0.016278193099424243
Q_Learning [36/300]: mean_loss=0.09356239438056946
Q_Learning [37/300]: mean_loss=0.030475642532110214
Q_Learning [38/300]: mean_loss=0.027286204043775797
Q_Learning [39/300]: mean_loss=0.06328495685011148
Q_Learning [40/300]: mean_loss=0.022326350677758455
Q_Learning [41/300]: mean_loss=0.06296553974971175
Q_Learning [42/300]: mean_loss=0.033823168370872736
Q_Learning [43/300]: mean_loss=0.03569540334865451
Q_Learning [44/300]: mean_loss=0.013359864242374897
Q_Learning [45/300]: mean_loss=0.009938690811395645
Q_Learning [46/300]: mean_loss=0.03053813916631043
Q_Learning [47/300]: mean_loss=0.02080248761922121
Q_Learning [48/300]: mean_loss=0.03534778719767928
Q_Learning [49/300]: mean_loss=0.0054955981322564185
Q_Learning [50/300]: mean_loss=0.03950990829616785
Q_Learning [51/300]: mean_loss=0.04611998936161399
Q_Learning [52/300]: mean_loss=0.1001456631347537
Q_Learning [53/300]: mean_loss=0.01324718608520925
Q_Learning [54/300]: mean_loss=0.010672280797734857
Q_Learning [55/300]: mean_loss=0.02713759895414114
Q_Learning [56/300]: mean_loss=0.0710312258452177
Q_Learning [57/300]: mean_loss=0.07827310357242823
Q_Learning [58/300]: mean_loss=0.05543779814615846
Q_Learning [59/300]: mean_loss=0.042630007956176996
Q_Learning [60/300]: mean_loss=0.07564797904342413
Q_Learning [61/300]: mean_loss=0.043874428141862154
Q_Learning [62/300]: mean_loss=0.09498889185488224
Q_Learning [63/300]: mean_loss=0.04066305793821812
Q_Learning [64/300]: mean_loss=0.026261977152898908
Q_Learning [65/300]: mean_loss=0.028736030450090766
Q_Learning [66/300]: mean_loss=0.028695827117189765
Q_Learning [67/300]: mean_loss=0.04316624440252781
Q_Learning [68/300]: mean_loss=0.015685392543673515
Q_Learning [69/300]: mean_loss=0.023089387454092503
Q_Learning [70/300]: mean_loss=0.05171227641403675
Q_Learning [71/300]: mean_loss=0.07235103193670511
Q_Learning [72/300]: mean_loss=0.023318362655118108
Q_Learning [73/300]: mean_loss=0.039083731826394796
Q_Learning [74/300]: mean_loss=0.03934704652056098
Q_Learning [75/300]: mean_loss=0.03735246090218425
Q_Learning [76/300]: mean_loss=0.027906429022550583
Q_Learning [77/300]: mean_loss=0.04067141516134143
Q_Learning [78/300]: mean_loss=0.041262330021709204
Q_Learning [79/300]: mean_loss=0.014524680911563337
Q_Learning [80/300]: mean_loss=0.022375137777999043
Q_Learning [81/300]: mean_loss=0.08236963674426079
Q_Learning [82/300]: mean_loss=0.0484643611125648
Q_Learning [83/300]: mean_loss=0.03397712600417435
Q_Learning [84/300]: mean_loss=0.033073111437261105
Q_Learning [85/300]: mean_loss=0.016106265946291387
Q_Learning [86/300]: mean_loss=0.03134338138625026
Q_Learning [87/300]: mean_loss=0.1350499028339982
Q_Learning [88/300]: mean_loss=0.09327582083642483
Q_Learning [89/300]: mean_loss=0.03720394195988774
Q_Learning [90/300]: mean_loss=0.023106751730665565
Q_Learning [91/300]: mean_loss=0.016610271646641195
Q_Learning [92/300]: mean_loss=0.08572633937001228
Q_Learning [93/300]: mean_loss=0.031827476574108005
Q_Learning [94/300]: mean_loss=0.031834934605285525
Q_Learning [95/300]: mean_loss=0.0370706464163959
Q_Learning [96/300]: mean_loss=0.02884936472401023
Q_Learning [97/300]: mean_loss=0.03638620022684336
Q_Learning [98/300]: mean_loss=0.0274060838855803
Q_Learning [99/300]: mean_loss=0.05045072780922055
Q_Learning [100/300]: mean_loss=0.022511999122798443
Q_Learning [101/300]: mean_loss=0.027459373231977224
Q_Learning [102/300]: mean_loss=0.03588941274210811
Q_Learning [103/300]: mean_loss=0.008566202828660607
Q_Learning [104/300]: mean_loss=0.06370636355131865
Q_Learning [105/300]: mean_loss=0.045989800710231066
Q_Learning [106/300]: mean_loss=0.05291416822001338
Q_Learning [107/300]: mean_loss=0.03281687665730715
Q_Learning [108/300]: mean_loss=0.015390274347737432
Q_Learning [109/300]: mean_loss=0.017698266077786684
Q_Learning [110/300]: mean_loss=0.017393815563991666
Q_Learning [111/300]: mean_loss=0.024480399442836642
Q_Learning [112/300]: mean_loss=0.03447575448080897
Q_Learning [113/300]: mean_loss=0.1141852829605341
Q_Learning [114/300]: mean_loss=0.07740298192948103
Q_Learning [115/300]: mean_loss=0.02167863165959716
Q_Learning [116/300]: mean_loss=0.043376816902309656
Q_Learning [117/300]: mean_loss=0.024550122441723943
Q_Learning [118/300]: mean_loss=0.029914291575551033
Q_Learning [119/300]: mean_loss=0.03807640029117465
Q_Learning [120/300]: mean_loss=0.012340189306996763
Q_Learning [121/300]: mean_loss=0.0658495887182653
Q_Learning [122/300]: mean_loss=0.06413992121815681
Q_Learning [123/300]: mean_loss=0.02264370396733284
Q_Learning [124/300]: mean_loss=0.015557818464003503
Q_Learning [125/300]: mean_loss=0.0444643278606236
Q_Learning [126/300]: mean_loss=0.1722047422081232
Q_Learning [127/300]: mean_loss=0.054837801959365606
Q_Learning [128/300]: mean_loss=0.045412583742290735
Q_Learning [129/300]: mean_loss=0.035752585623413324
Q_Learning [130/300]: mean_loss=0.042617976665496826
Q_Learning [131/300]: mean_loss=0.12274495139718056
Q_Learning [132/300]: mean_loss=0.13972090929746628
Q_Learning [133/300]: mean_loss=0.019420343916863203
Q_Learning [134/300]: mean_loss=0.02611474576406181
Q_Learning [135/300]: mean_loss=0.06707540899515152
Q_Learning [136/300]: mean_loss=0.16187377460300922
Q_Learning [137/300]: mean_loss=0.01447483862284571
Q_Learning [138/300]: mean_loss=0.048877769615501165
Q_Learning [139/300]: mean_loss=0.02879344904795289
Q_Learning [140/300]: mean_loss=0.024614609545096755
Q_Learning [141/300]: mean_loss=0.033526604529470205
Q_Learning [142/300]: mean_loss=0.05382490996271372
Q_Learning [143/300]: mean_loss=0.017568274633958936
Q_Learning [144/300]: mean_loss=0.01601964107248932
Q_Learning [145/300]: mean_loss=0.02220876794308424
Q_Learning [146/300]: mean_loss=0.02250588219612837
Q_Learning [147/300]: mean_loss=0.016666294308379292
Q_Learning [148/300]: mean_loss=0.022457221522927284
Q_Learning [149/300]: mean_loss=0.02227833867073059
Q_Learning [150/300]: mean_loss=0.025906966999173164
Q_Learning [151/300]: mean_loss=0.012243580538779497
Q_Learning [152/300]: mean_loss=0.026664480566978455
Q_Learning [153/300]: mean_loss=0.04557977104559541
Q_Learning [154/300]: mean_loss=0.013166398974135518
Q_Learning [155/300]: mean_loss=0.041152570862323046
Q_Learning [156/300]: mean_loss=0.03768535004928708
Q_Learning [157/300]: mean_loss=0.03376830229535699
Q_Learning [158/300]: mean_loss=0.03420779062435031
Q_Learning [159/300]: mean_loss=0.01920084306038916
Q_Learning [160/300]: mean_loss=0.037072671577334404
Q_Learning [161/300]: mean_loss=0.0285677220672369
Q_Learning [162/300]: mean_loss=0.042938674334436655
Q_Learning [163/300]: mean_loss=0.011470193625427783
Q_Learning [164/300]: mean_loss=0.028237066930159926
Q_Learning [165/300]: mean_loss=0.02728505409322679
Q_Learning [166/300]: mean_loss=0.027827756013721228
Q_Learning [167/300]: mean_loss=0.031173710245639086
Q_Learning [168/300]: mean_loss=0.03432101057842374
Q_Learning [169/300]: mean_loss=0.03259240370243788
Q_Learning [170/300]: mean_loss=0.019811106380075216
Q_Learning [171/300]: mean_loss=0.030858374200761318
Q_Learning [172/300]: mean_loss=0.017103155376389623
Q_Learning [173/300]: mean_loss=0.020178163889795542
Q_Learning [174/300]: mean_loss=0.026233994401991367
Q_Learning [175/300]: mean_loss=0.03772301506251097
Q_Learning [176/300]: mean_loss=0.0680127302184701
Q_Learning [177/300]: mean_loss=0.012052952544763684
Q_Learning [178/300]: mean_loss=0.020153285702690482
Q_Learning [179/300]: mean_loss=0.01659165881574154
Q_Learning [180/300]: mean_loss=0.014596333843655884
Q_Learning [181/300]: mean_loss=0.01057110889814794
Q_Learning [182/300]: mean_loss=0.07313288375735283
Q_Learning [183/300]: mean_loss=0.013270320021547377
Q_Learning [184/300]: mean_loss=0.017606857465580106
Q_Learning [185/300]: mean_loss=0.03043968160636723
Q_Learning [186/300]: mean_loss=0.024993411730974913
Q_Learning [187/300]: mean_loss=0.019019316416233778
Q_Learning [188/300]: mean_loss=0.02836164180189371
Q_Learning [189/300]: mean_loss=0.030597115634009242
Q_Learning [190/300]: mean_loss=0.013986588804982603
Q_Learning [191/300]: mean_loss=0.02418771805241704
Q_Learning [192/300]: mean_loss=0.013962609227746725
Q_Learning [193/300]: mean_loss=0.029120062245056033
Q_Learning [194/300]: mean_loss=0.0353299742564559
Q_Learning [195/300]: mean_loss=0.0291827074252069
Q_Learning [196/300]: mean_loss=0.0666397474706173
Q_Learning [197/300]: mean_loss=0.060694434214383364
Q_Learning [198/300]: mean_loss=0.029024755116552114
Q_Learning [199/300]: mean_loss=0.02287673531100154
Q_Learning [200/300]: mean_loss=0.028045291546732187
Q_Learning [201/300]: mean_loss=0.017577962251380086
Q_Learning [202/300]: mean_loss=0.029097864171490073
Q_Learning [203/300]: mean_loss=0.011693244217894971
Q_Learning [204/300]: mean_loss=0.015478612040169537
Q_Learning [205/300]: mean_loss=0.01224723202176392
Q_Learning [206/300]: mean_loss=0.03963551390916109
Q_Learning [207/300]: mean_loss=0.01813094923272729
Q_Learning [208/300]: mean_loss=0.029645745642483234
Q_Learning [209/300]: mean_loss=0.028271488845348358
Q_Learning [210/300]: mean_loss=0.03906992031261325
Q_Learning [211/300]: mean_loss=0.01490464003290981
Q_Learning [212/300]: mean_loss=0.031180500984191895
Q_Learning [213/300]: mean_loss=0.016830351669341326
Q_Learning [214/300]: mean_loss=0.024224175605922937
Q_Learning [215/300]: mean_loss=0.02240510331466794
Q_Learning [216/300]: mean_loss=0.03648871881887317
Q_Learning [217/300]: mean_loss=0.011529344134032726
Q_Learning [218/300]: mean_loss=0.01506362296640873
Q_Learning [219/300]: mean_loss=0.012493350077420473
Q_Learning [220/300]: mean_loss=0.023812714498490095
Q_Learning [221/300]: mean_loss=0.016238417592830956
Q_Learning [222/300]: mean_loss=0.01953015197068453
Q_Learning [223/300]: mean_loss=0.07780478149652481
Q_Learning [224/300]: mean_loss=0.0325621603988111
Q_Learning [225/300]: mean_loss=0.014352764817886055
Q_Learning [226/300]: mean_loss=0.010026139905676246
Q_Learning [227/300]: mean_loss=0.02701192256063223
Q_Learning [228/300]: mean_loss=0.10387047939002514
Q_Learning [229/300]: mean_loss=0.09035975951701403
Q_Learning [230/300]: mean_loss=0.012902536313049495
Q_Learning [231/300]: mean_loss=0.023530657636001706
Q_Learning [232/300]: mean_loss=0.014185465406626463
Q_Learning [233/300]: mean_loss=0.013198726112022996
Q_Learning [234/300]: mean_loss=0.06742752902209759
Q_Learning [235/300]: mean_loss=0.02032006182707846
Q_Learning [236/300]: mean_loss=0.01887163962237537
Q_Learning [237/300]: mean_loss=0.02026451611891389
Q_Learning [238/300]: mean_loss=0.03129729232750833
Q_Learning [239/300]: mean_loss=0.02585566695779562
Q_Learning [240/300]: mean_loss=0.01962413382716477
Q_Learning [241/300]: mean_loss=0.031041596550494432
Q_Learning [242/300]: mean_loss=0.01656209328211844
Q_Learning [243/300]: mean_loss=0.019862559624016285
Q_Learning [244/300]: mean_loss=0.01587703009136021
Q_Learning [245/300]: mean_loss=0.014826732454821467
Q_Learning [246/300]: mean_loss=0.022496439050883055
Q_Learning [247/300]: mean_loss=0.03343129949644208
Q_Learning [248/300]: mean_loss=0.02188418060541153
Q_Learning [249/300]: mean_loss=0.024735886370763183
Q_Learning [250/300]: mean_loss=0.01594859967008233
Q_Learning [251/300]: mean_loss=0.007885186118073761
Q_Learning [252/300]: mean_loss=0.026145205600187182
Q_Learning [253/300]: mean_loss=0.0075667822966352105
Q_Learning [254/300]: mean_loss=0.003777644509682432
Q_Learning [255/300]: mean_loss=0.017903226427733898
Q_Learning [256/300]: mean_loss=0.033164181280881166
Q_Learning [257/300]: mean_loss=0.06357297208160162
Q_Learning [258/300]: mean_loss=0.10680619720369577
Q_Learning [259/300]: mean_loss=0.08898567128926516
Q_Learning [260/300]: mean_loss=0.04664819082245231
Q_Learning [261/300]: mean_loss=0.012561394483782351
Q_Learning [262/300]: mean_loss=0.011959340539760888
Q_Learning [263/300]: mean_loss=0.12833973858505487
Q_Learning [264/300]: mean_loss=0.06618683785200119
Q_Learning [265/300]: mean_loss=0.04446292435750365
Q_Learning [266/300]: mean_loss=0.027588059660047293
Q_Learning [267/300]: mean_loss=0.040557550732046366
Q_Learning [268/300]: mean_loss=0.027573154773563147
Q_Learning [269/300]: mean_loss=0.028074705507606268
Q_Learning [270/300]: mean_loss=0.016120340209454298
Q_Learning [271/300]: mean_loss=0.02446353156119585
Q_Learning [272/300]: mean_loss=0.010927775467280298
Q_Learning [273/300]: mean_loss=0.010713114868849516
Q_Learning [274/300]: mean_loss=0.08870079554617405
Q_Learning [275/300]: mean_loss=0.05799455940723419
Q_Learning [276/300]: mean_loss=0.03945754235610366
Q_Learning [277/300]: mean_loss=0.022396337473765016
Q_Learning [278/300]: mean_loss=0.04023824259638786
Q_Learning [279/300]: mean_loss=0.04334188811480999
Q_Learning [280/300]: mean_loss=0.02670092135667801
Q_Learning [281/300]: mean_loss=0.18430104851722717
Q_Learning [282/300]: mean_loss=0.158487344160676
Q_Learning [283/300]: mean_loss=0.11283648107200861
Q_Learning [284/300]: mean_loss=0.033504603896290064
Q_Learning [285/300]: mean_loss=0.035308219492435455
Q_Learning [286/300]: mean_loss=0.042984812054783106
Q_Learning [287/300]: mean_loss=0.04561829101294279
Q_Learning [288/300]: mean_loss=0.01478592783678323
Q_Learning [289/300]: mean_loss=0.029510913882404566
Q_Learning [290/300]: mean_loss=0.012135219760239124
Q_Learning [291/300]: mean_loss=0.10414674319326878
Q_Learning [292/300]: mean_loss=0.025229043094441295
Q_Learning [293/300]: mean_loss=0.010042436653748155
Q_Learning [294/300]: mean_loss=0.005194538040086627
Q_Learning [295/300]: mean_loss=0.03344368562102318
Q_Learning [296/300]: mean_loss=0.01020329212769866
Q_Learning [297/300]: mean_loss=0.026950020343065262
Q_Learning [298/300]: mean_loss=0.00985189329367131
Q_Learning [299/300]: mean_loss=0.01416964246891439
Q_Learning [300/300]: mean_loss=0.015938651165924966
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-1.6893525  -0.11095417]
[2, 0, 1, 0, 0, 1, 1, 2, 1, 1, 1, 0, 0, 1, 2, 1, 0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1, 0, 1, 2, 1, 1, 0, 2, 0, 1, 0, 2, 0, 2, 1, 2, 0, 2, 0, 1, 0, 2, 0, 0, 1, 2, 2, 1, 0, 0, 2, 2, 2, 1, 2, 0, 2, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 0, 2, 1, 2, 2, 0, 0, 1, 2, 1, 0, 1, 2, 2, 0, 1, 1, 2, 2, 1, 2, 1, 2, 0, 2, 1, 0, 1, 2, 2, 2, 1, 1, 2, 1, 2, 0, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 1, 0, 0, 2, 2, 1, 2, 0, 1, 2, 1, 2, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 2, 2, 0, 1, 0, 0, 2, 0, 1, 2, 2, 2, 1, 2, 1, 0, 0, 2, 0, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 0, 2, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 1, 0, 1, 2, 0, 0, 2, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 0, 2, 1, 1, 0, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 1, 2, 2, 1, 2, 0, 2, 1, 1, 2, 1, 2, 0, 1, 2]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Centroids: [[-0.32831863, -0.23329586], [-0.21771704, -0.62598616], [-0.88612556, -0.83343166]]
Centroids: [[-0.48228326, -0.56770796], [2.5397887, -2.4607751]]
Contingency Matrix: 
[[ 92   0]
 [108   1]
 [ 99   0]]
[[92, 0], [108, 1], [99, 0]]
[[92, 0, 0], [108, 1, 0], [99, 0, 0]]
[0, 1, 2]
[[-1, 0, 0], [-1, -1, -1], [-1, 0, 0]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 0]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 0, 0: 1, 2: 2}
New Contingency Matrix: 
[[  0  92   0]
 [  1 108   0]
 [  0  99   0]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [0, 108, 0], Sum: 108
All_Elements: [0, 92, 0, 1, 108, 0, 0, 99, 0], Sum: 300
Accuracy: 0.36
