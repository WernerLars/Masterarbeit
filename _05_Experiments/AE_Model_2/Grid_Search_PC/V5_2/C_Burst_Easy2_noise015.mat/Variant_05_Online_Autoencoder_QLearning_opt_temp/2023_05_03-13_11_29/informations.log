Experiment_path: Experiment_07
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: AE_Model_2/Grid_Search_PC//V5_2/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_05_03-13_11_29
Punishment_Coefficient: 1.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000015D423D6748>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.2006339505314827
Online_Training [2/700]: mean_loss=0.2430319171398878
Online_Training [3/700]: mean_loss=0.22050213254988194
Online_Training [4/700]: mean_loss=0.08446377236396074
Online_Training [5/700]: mean_loss=0.25137187726795673
Online_Training [6/700]: mean_loss=0.10796177014708519
Online_Training [7/700]: mean_loss=0.11403135862201452
Online_Training [8/700]: mean_loss=0.07530721183866262
Online_Training [9/700]: mean_loss=0.12204575445502996
Online_Training [10/700]: mean_loss=0.15029273927211761
Online_Training [11/700]: mean_loss=0.06494785845279694
Online_Training [12/700]: mean_loss=0.07111447770148516
Online_Training [13/700]: mean_loss=0.08543363772332668
Online_Training [14/700]: mean_loss=0.0352630908600986
Online_Training [15/700]: mean_loss=0.04451932059600949
Online_Training [16/700]: mean_loss=0.12520800530910492
Online_Training [17/700]: mean_loss=0.09295208565890789
Online_Training [18/700]: mean_loss=0.0564671796746552
Online_Training [19/700]: mean_loss=0.026302488055080175
Online_Training [20/700]: mean_loss=0.14758675545454025
Online_Training [21/700]: mean_loss=0.12977823242545128
Online_Training [22/700]: mean_loss=0.019443512661382556
Online_Training [23/700]: mean_loss=0.018300584517419338
Online_Training [24/700]: mean_loss=0.07178271654993296
Online_Training [25/700]: mean_loss=0.03866708232089877
Online_Training [26/700]: mean_loss=0.04723857855424285
Online_Training [27/700]: mean_loss=0.10611386317759752
Online_Training [28/700]: mean_loss=0.035896089393645525
Online_Training [29/700]: mean_loss=0.04460737854242325
Online_Training [30/700]: mean_loss=0.03173204930499196
Online_Training [31/700]: mean_loss=0.028062039287760854
Online_Training [32/700]: mean_loss=0.04436734225600958
Online_Training [33/700]: mean_loss=0.023949507158249617
Online_Training [34/700]: mean_loss=0.14377667382359505
Online_Training [35/700]: mean_loss=0.05411825329065323
Online_Training [36/700]: mean_loss=0.08588493801653385
Online_Training [37/700]: mean_loss=0.05232199653983116
Online_Training [38/700]: mean_loss=0.040948871057480574
Online_Training [39/700]: mean_loss=0.11715704295784235
Online_Training [40/700]: mean_loss=0.033325752476230264
Online_Training [41/700]: mean_loss=0.031153156189247966
Online_Training [42/700]: mean_loss=0.0577699551358819
Online_Training [43/700]: mean_loss=0.11939004436135292
Online_Training [44/700]: mean_loss=0.15081367641687393
Online_Training [45/700]: mean_loss=0.06321040214970708
Online_Training [46/700]: mean_loss=0.03800788428634405
Online_Training [47/700]: mean_loss=0.08822763618081808
Online_Training [48/700]: mean_loss=0.07015220634639263
Online_Training [49/700]: mean_loss=0.09023109171539545
Online_Training [50/700]: mean_loss=0.1199053218588233
Online_Training [51/700]: mean_loss=0.026291385293006897
Online_Training [52/700]: mean_loss=0.16657978668808937
Online_Training [53/700]: mean_loss=0.02095453324727714
Online_Training [54/700]: mean_loss=0.08665870502591133
Online_Training [55/700]: mean_loss=0.03816726943477988
Online_Training [56/700]: mean_loss=0.04069593036547303
Online_Training [57/700]: mean_loss=0.06534491712227464
Online_Training [58/700]: mean_loss=0.3484125882387161
Online_Training [59/700]: mean_loss=0.07024162588641047
Online_Training [60/700]: mean_loss=0.06856631208211184
Online_Training [61/700]: mean_loss=0.05523296119645238
Online_Training [62/700]: mean_loss=0.08747024228796363
Online_Training [63/700]: mean_loss=0.06703915633261204
Online_Training [64/700]: mean_loss=0.00816499680513516
Online_Training [65/700]: mean_loss=0.06413964787498116
Online_Training [66/700]: mean_loss=0.04327953141182661
Online_Training [67/700]: mean_loss=0.061305887065827847
Online_Training [68/700]: mean_loss=0.0730448691174388
Online_Training [69/700]: mean_loss=0.17818692326545715
Online_Training [70/700]: mean_loss=0.03714572498574853
Online_Training [71/700]: mean_loss=0.07513544801622629
Online_Training [72/700]: mean_loss=0.07723300904035568
Online_Training [73/700]: mean_loss=0.04133720276877284
Online_Training [74/700]: mean_loss=0.04172035586088896
Online_Training [75/700]: mean_loss=0.030572673538699746
Online_Training [76/700]: mean_loss=0.04238187009468675
Online_Training [77/700]: mean_loss=0.04193710698746145
Online_Training [78/700]: mean_loss=0.06769988685846329
Online_Training [79/700]: mean_loss=0.04319629538804293
Online_Training [80/700]: mean_loss=0.035978137981146574
Online_Training [81/700]: mean_loss=0.014137008460238576
Online_Training [82/700]: mean_loss=0.029106634203344584
Online_Training [83/700]: mean_loss=0.10961493477225304
Online_Training [84/700]: mean_loss=0.03134161210618913
Online_Training [85/700]: mean_loss=0.023666636552661657
Online_Training [86/700]: mean_loss=0.05738385906443
Online_Training [87/700]: mean_loss=0.013945995247922838
Online_Training [88/700]: mean_loss=0.03137581027112901
Online_Training [89/700]: mean_loss=0.04651913931593299
Online_Training [90/700]: mean_loss=0.02241769223473966
Online_Training [91/700]: mean_loss=0.03718185983598232
Online_Training [92/700]: mean_loss=0.04715253412723541
Online_Training [93/700]: mean_loss=0.058585465885698795
Online_Training [94/700]: mean_loss=0.056631291285157204
Online_Training [95/700]: mean_loss=0.06617959029972553
Online_Training [96/700]: mean_loss=0.020651123370043933
Online_Training [97/700]: mean_loss=0.0560779832303524
Online_Training [98/700]: mean_loss=0.04428124940022826
Online_Training [99/700]: mean_loss=0.01881395443342626
Online_Training [100/700]: mean_loss=0.04375685704872012
Online_Training [101/700]: mean_loss=0.031521196477115154
Online_Training [102/700]: mean_loss=0.058606951497495174
Online_Training [103/700]: mean_loss=0.04588177427649498
Online_Training [104/700]: mean_loss=0.05606377124786377
Online_Training [105/700]: mean_loss=0.03824298968538642
Online_Training [106/700]: mean_loss=0.01496502012014389
Online_Training [107/700]: mean_loss=0.017027721041813493
Online_Training [108/700]: mean_loss=0.031226832885295153
Online_Training [109/700]: mean_loss=0.03681512945331633
Online_Training [110/700]: mean_loss=0.03113732673227787
Online_Training [111/700]: mean_loss=0.029751094989478588
Online_Training [112/700]: mean_loss=0.15565561316907406
Online_Training [113/700]: mean_loss=0.026922553777694702
Online_Training [114/700]: mean_loss=0.05732702696695924
Online_Training [115/700]: mean_loss=0.04295912757515907
Online_Training [116/700]: mean_loss=0.028974503744393587
Online_Training [117/700]: mean_loss=0.05432074470445514
Online_Training [118/700]: mean_loss=0.056795123498886824
Online_Training [119/700]: mean_loss=0.12788630090653896
Online_Training [120/700]: mean_loss=0.06395474309101701
Online_Training [121/700]: mean_loss=0.06745206750929356
Online_Training [122/700]: mean_loss=0.07385201565921307
Online_Training [123/700]: mean_loss=0.035073064267635345
Online_Training [124/700]: mean_loss=0.013005473301745951
Online_Training [125/700]: mean_loss=0.08400718914344907
Online_Training [126/700]: mean_loss=0.039744215086102486
Online_Training [127/700]: mean_loss=0.0693319933488965
Online_Training [128/700]: mean_loss=0.02797252801246941
Online_Training [129/700]: mean_loss=0.03271903400309384
Online_Training [130/700]: mean_loss=0.020516570657491684
Online_Training [131/700]: mean_loss=0.027882908936589956
Online_Training [132/700]: mean_loss=0.018296118592843413
Online_Training [133/700]: mean_loss=0.02529704663902521
Online_Training [134/700]: mean_loss=0.025064500281587243
Online_Training [135/700]: mean_loss=0.10897853318601847
Online_Training [136/700]: mean_loss=0.022181940963491797
Online_Training [137/700]: mean_loss=0.02677396940998733
Online_Training [138/700]: mean_loss=0.011712275561876595
Online_Training [139/700]: mean_loss=0.020239447010681033
Online_Training [140/700]: mean_loss=0.03317991178482771
Online_Training [141/700]: mean_loss=0.030773463426157832
Online_Training [142/700]: mean_loss=0.013160407543182373
Online_Training [143/700]: mean_loss=0.028075278969481587
Online_Training [144/700]: mean_loss=0.014512298861518502
Online_Training [145/700]: mean_loss=0.06288888864219189
Online_Training [146/700]: mean_loss=0.021489011589437723
Online_Training [147/700]: mean_loss=0.016469066846184433
Online_Training [148/700]: mean_loss=0.051110494416207075
Online_Training [149/700]: mean_loss=0.09652089048177004
Online_Training [150/700]: mean_loss=0.11653646174818277
Online_Training [151/700]: mean_loss=0.022119836416095495
Online_Training [152/700]: mean_loss=0.019971338333562016
Online_Training [153/700]: mean_loss=0.05183590669184923
Online_Training [154/700]: mean_loss=0.038561627734452486
Online_Training [155/700]: mean_loss=0.013934488641098142
Online_Training [156/700]: mean_loss=0.020498201483860612
Online_Training [157/700]: mean_loss=0.14889876265078783
Online_Training [158/700]: mean_loss=0.013430431310553104
Online_Training [159/700]: mean_loss=0.018320608651265502
Online_Training [160/700]: mean_loss=0.036105782724916935
Online_Training [161/700]: mean_loss=0.033204405568540096
Online_Training [162/700]: mean_loss=0.015688073355704546
Online_Training [163/700]: mean_loss=0.04933762131258845
Online_Training [164/700]: mean_loss=0.014591657323762774
Online_Training [165/700]: mean_loss=0.010413410607725382
Online_Training [166/700]: mean_loss=0.02153017884120345
Online_Training [167/700]: mean_loss=0.03955838456749916
Online_Training [168/700]: mean_loss=0.04579492565244436
Online_Training [169/700]: mean_loss=0.05121366959065199
Online_Training [170/700]: mean_loss=0.18074725568294525
Online_Training [171/700]: mean_loss=0.020672898273915052
Online_Training [172/700]: mean_loss=0.016595662687905133
Online_Training [173/700]: mean_loss=0.02635489613749087
Online_Training [174/700]: mean_loss=0.013711231877095997
Online_Training [175/700]: mean_loss=0.012496649869717658
Online_Training [176/700]: mean_loss=0.0062939790659584105
Online_Training [177/700]: mean_loss=0.036527652060613036
Online_Training [178/700]: mean_loss=0.03487574029713869
Online_Training [179/700]: mean_loss=0.024289379362016916
Online_Training [180/700]: mean_loss=0.03565683378838003
Online_Training [181/700]: mean_loss=0.03773608151823282
Online_Training [182/700]: mean_loss=0.021283756708726287
Online_Training [183/700]: mean_loss=0.01409360091201961
Online_Training [184/700]: mean_loss=0.008574437350034714
Online_Training [185/700]: mean_loss=0.036075526382774115
Online_Training [186/700]: mean_loss=0.0344013930298388
Online_Training [187/700]: mean_loss=0.026932145236060023
Online_Training [188/700]: mean_loss=0.025777998380362988
Online_Training [189/700]: mean_loss=0.05469953361898661
Online_Training [190/700]: mean_loss=0.023901014123111963
Online_Training [191/700]: mean_loss=0.15187152661383152
Online_Training [192/700]: mean_loss=0.021969560300931334
Online_Training [193/700]: mean_loss=0.0242291996255517
Online_Training [194/700]: mean_loss=0.021388118620961905
Online_Training [195/700]: mean_loss=0.0234365938231349
Online_Training [196/700]: mean_loss=0.014048067037947476
Online_Training [197/700]: mean_loss=0.04716943670064211
Online_Training [198/700]: mean_loss=0.015883205691352487
Online_Training [199/700]: mean_loss=0.08217114489525557
Online_Training [200/700]: mean_loss=0.018270117812789977
Online_Training [201/700]: mean_loss=0.03445654036477208
Online_Training [202/700]: mean_loss=0.019443725934252143
Online_Training [203/700]: mean_loss=0.010627388255670667
Online_Training [204/700]: mean_loss=0.01923739700578153
Online_Training [205/700]: mean_loss=0.0710673313587904
Online_Training [206/700]: mean_loss=0.018716043676249683
Online_Training [207/700]: mean_loss=0.049809171352535486
Online_Training [208/700]: mean_loss=0.045632341876626015
Online_Training [209/700]: mean_loss=0.04798362636938691
Online_Training [210/700]: mean_loss=0.02611483889631927
Online_Training [211/700]: mean_loss=0.018470288021489978
Online_Training [212/700]: mean_loss=0.09271610248833895
Online_Training [213/700]: mean_loss=0.08247792162001133
Online_Training [214/700]: mean_loss=0.021624871995300055
Online_Training [215/700]: mean_loss=0.02961090300232172
Online_Training [216/700]: mean_loss=0.054740657564252615
Online_Training [217/700]: mean_loss=0.013616817421279848
Online_Training [218/700]: mean_loss=0.008721047779545188
Online_Training [219/700]: mean_loss=0.053996832109987736
Online_Training [220/700]: mean_loss=0.012692464515566826
Online_Training [221/700]: mean_loss=0.031368950149044394
Online_Training [222/700]: mean_loss=0.023417797638103366
Online_Training [223/700]: mean_loss=0.031245161779224873
Online_Training [224/700]: mean_loss=0.006692674709483981
Online_Training [225/700]: mean_loss=0.02119963150471449
Online_Training [226/700]: mean_loss=0.018405392300337553
Online_Training [227/700]: mean_loss=0.009404577082023025
Online_Training [228/700]: mean_loss=0.037183700827881694
Online_Training [229/700]: mean_loss=0.05196100287139416
Online_Training [230/700]: mean_loss=0.01645104947965592
Online_Training [231/700]: mean_loss=0.025091601070016623
Online_Training [232/700]: mean_loss=0.020277239615097642
Online_Training [233/700]: mean_loss=0.02735265577211976
Online_Training [234/700]: mean_loss=0.025038850959390402
Online_Training [235/700]: mean_loss=0.06882391963154078
Online_Training [236/700]: mean_loss=0.04993595788255334
Online_Training [237/700]: mean_loss=0.03349197958596051
Online_Training [238/700]: mean_loss=0.09738982748240232
Online_Training [239/700]: mean_loss=0.22969739511609077
Online_Training [240/700]: mean_loss=0.07791665568947792
Online_Training [241/700]: mean_loss=0.042448027059435844
Online_Training [242/700]: mean_loss=0.03546882001683116
Online_Training [243/700]: mean_loss=0.04043419286608696
Online_Training [244/700]: mean_loss=0.041086018551141024
Online_Training [245/700]: mean_loss=0.05826086364686489
Online_Training [246/700]: mean_loss=0.026851337403059006
Online_Training [247/700]: mean_loss=0.011403331998735666
Online_Training [248/700]: mean_loss=0.05863264761865139
Online_Training [249/700]: mean_loss=0.05208519147709012
Online_Training [250/700]: mean_loss=0.015628131572157145
Online_Training [251/700]: mean_loss=0.020789144560694695
Online_Training [252/700]: mean_loss=0.015322895022109151
Online_Training [253/700]: mean_loss=0.0130675412947312
Online_Training [254/700]: mean_loss=0.02053826511837542
Online_Training [255/700]: mean_loss=0.0455809086561203
Online_Training [256/700]: mean_loss=0.019824121613055468
Online_Training [257/700]: mean_loss=0.029654108453541994
Online_Training [258/700]: mean_loss=0.01252309198025614
Online_Training [259/700]: mean_loss=0.00988991349004209
Online_Training [260/700]: mean_loss=0.019256274681538343
Online_Training [261/700]: mean_loss=0.021794989705085754
Online_Training [262/700]: mean_loss=0.03076478629373014
Online_Training [263/700]: mean_loss=0.01656468107830733
Online_Training [264/700]: mean_loss=0.04489274136722088
Online_Training [265/700]: mean_loss=0.019230927107855678
Online_Training [266/700]: mean_loss=0.011998748290352523
Online_Training [267/700]: mean_loss=0.0136406309902668
Online_Training [268/700]: mean_loss=0.008618883788585663
Online_Training [269/700]: mean_loss=0.031586474273353815
Online_Training [270/700]: mean_loss=0.01703294867184013
Online_Training [271/700]: mean_loss=0.019151558401063085
Online_Training [272/700]: mean_loss=0.007192717806901783
Online_Training [273/700]: mean_loss=0.01441699406132102
Online_Training [274/700]: mean_loss=0.029931313591077924
Online_Training [275/700]: mean_loss=0.010413801181130111
Online_Training [276/700]: mean_loss=0.018217624397948384
Online_Training [277/700]: mean_loss=0.07867702934890985
Online_Training [278/700]: mean_loss=0.025452018715441227
Online_Training [279/700]: mean_loss=0.024804947432130575
Online_Training [280/700]: mean_loss=0.03425543592311442
Online_Training [281/700]: mean_loss=0.03581477305851877
Online_Training [282/700]: mean_loss=0.024642087053507566
Online_Training [283/700]: mean_loss=0.019410347566008568
Online_Training [284/700]: mean_loss=0.033821118995547295
Online_Training [285/700]: mean_loss=0.027920314809307456
Online_Training [286/700]: mean_loss=0.00828343944158405
Online_Training [287/700]: mean_loss=0.010976861929520965
Online_Training [288/700]: mean_loss=0.014739537262357771
Online_Training [289/700]: mean_loss=0.03626002324745059
Online_Training [290/700]: mean_loss=0.008597983280196786
Online_Training [291/700]: mean_loss=0.013560950988903642
Online_Training [292/700]: mean_loss=0.006929626455530524
Online_Training [293/700]: mean_loss=0.021183595759794116
Online_Training [294/700]: mean_loss=0.031478629913181067
Online_Training [295/700]: mean_loss=0.03454837156459689
Online_Training [296/700]: mean_loss=0.038725089048966765
Online_Training [297/700]: mean_loss=0.019843329908326268
Online_Training [298/700]: mean_loss=0.030470542376860976
Online_Training [299/700]: mean_loss=0.034540430177003145
Online_Training [300/700]: mean_loss=0.04836683114990592
Online_Training [301/700]: mean_loss=0.012237887247465551
Online_Training [302/700]: mean_loss=0.034667156636714935
Online_Training [303/700]: mean_loss=0.019073216011747718
Online_Training [304/700]: mean_loss=0.016767793335020542
Online_Training [305/700]: mean_loss=0.07128413300961256
Online_Training [306/700]: mean_loss=0.04978406196460128
Online_Training [307/700]: mean_loss=0.07465941458940506
Online_Training [308/700]: mean_loss=0.02855702326633036
Online_Training [309/700]: mean_loss=0.008213043911382556
Online_Training [310/700]: mean_loss=0.03840002464130521
Online_Training [311/700]: mean_loss=0.016012632404454052
Online_Training [312/700]: mean_loss=0.057311630342155695
Online_Training [313/700]: mean_loss=0.019922382663935423
Online_Training [314/700]: mean_loss=0.02337448438629508
Online_Training [315/700]: mean_loss=0.020840009674429893
Online_Training [316/700]: mean_loss=0.016292160958983004
Online_Training [317/700]: mean_loss=0.008169505163095891
Online_Training [318/700]: mean_loss=0.03207181324250996
Online_Training [319/700]: mean_loss=0.03191594663076103
Online_Training [320/700]: mean_loss=0.015242060529999435
Online_Training [321/700]: mean_loss=0.02027836791239679
Online_Training [322/700]: mean_loss=0.03614993835799396
Online_Training [323/700]: mean_loss=0.01897867873776704
Online_Training [324/700]: mean_loss=0.012715371791273355
Online_Training [325/700]: mean_loss=0.025245616678148508
Online_Training [326/700]: mean_loss=0.032833201345056295
Online_Training [327/700]: mean_loss=0.021565336268395185
Online_Training [328/700]: mean_loss=0.04171277256682515
Online_Training [329/700]: mean_loss=0.013222610461525619
Online_Training [330/700]: mean_loss=0.028171367943286896
Online_Training [331/700]: mean_loss=0.01992854429408908
Online_Training [332/700]: mean_loss=0.016736342571675777
Online_Training [333/700]: mean_loss=0.01038559339940548
Online_Training [334/700]: mean_loss=0.010247958125546575
Online_Training [335/700]: mean_loss=0.05842525837942958
Online_Training [336/700]: mean_loss=0.07092934148386121
Online_Training [337/700]: mean_loss=0.11318463832139969
Online_Training [338/700]: mean_loss=0.04677751986309886
Online_Training [339/700]: mean_loss=0.018752343603409827
Online_Training [340/700]: mean_loss=0.010015086038038135
Online_Training [341/700]: mean_loss=0.04581927740946412
Online_Training [342/700]: mean_loss=0.055348715744912624
Online_Training [343/700]: mean_loss=0.02247669594362378
Online_Training [344/700]: mean_loss=0.021471987711265683
Online_Training [345/700]: mean_loss=0.045395541936159134
Online_Training [346/700]: mean_loss=0.0152915904764086
Online_Training [347/700]: mean_loss=0.1348602343350649
Online_Training [348/700]: mean_loss=0.01719713828060776
Online_Training [349/700]: mean_loss=0.02454314287751913
Online_Training [350/700]: mean_loss=0.009865578031167388
Online_Training [351/700]: mean_loss=0.009349581494461745
Online_Training [352/700]: mean_loss=0.008833411033265293
Online_Training [353/700]: mean_loss=0.04506024904549122
Online_Training [354/700]: mean_loss=0.011521025327965617
Online_Training [355/700]: mean_loss=0.014723692322149873
Online_Training [356/700]: mean_loss=0.015995066612958908
Online_Training [357/700]: mean_loss=0.07866469863802195
Online_Training [358/700]: mean_loss=0.07248931331560016
Online_Training [359/700]: mean_loss=0.07947715744376183
Online_Training [360/700]: mean_loss=0.024632014567032456
Online_Training [361/700]: mean_loss=0.02603527018800378
Online_Training [362/700]: mean_loss=0.06141331885010004
Online_Training [363/700]: mean_loss=0.021563360234722495
Online_Training [364/700]: mean_loss=0.007948702666908503
Online_Training [365/700]: mean_loss=0.019652680028229952
Online_Training [366/700]: mean_loss=0.021804104559123516
Online_Training [367/700]: mean_loss=0.026066334918141365
Online_Training [368/700]: mean_loss=0.030912321293726563
Online_Training [369/700]: mean_loss=0.02424847730435431
Online_Training [370/700]: mean_loss=0.038666429463773966
Online_Training [371/700]: mean_loss=0.024495195131748915
Online_Training [372/700]: mean_loss=0.031306104036048055
Online_Training [373/700]: mean_loss=0.03185334149748087
Online_Training [374/700]: mean_loss=0.016833579633384943
Online_Training [375/700]: mean_loss=0.020594476722180843
Online_Training [376/700]: mean_loss=0.008229942119214684
Online_Training [377/700]: mean_loss=0.017691563349217176
Online_Training [378/700]: mean_loss=0.02364970534108579
Online_Training [379/700]: mean_loss=0.032296649646013975
Online_Training [380/700]: mean_loss=0.011777176870964468
Online_Training [381/700]: mean_loss=0.016757577657699585
Online_Training [382/700]: mean_loss=0.010196463204920292
Online_Training [383/700]: mean_loss=0.008280908747110516
Online_Training [384/700]: mean_loss=0.16533945687115192
Online_Training [385/700]: mean_loss=0.01137860061135143
Online_Training [386/700]: mean_loss=0.02303780592046678
Online_Training [387/700]: mean_loss=0.020675958832725883
Online_Training [388/700]: mean_loss=0.012620416935533285
Online_Training [389/700]: mean_loss=0.01084037497639656
Online_Training [390/700]: mean_loss=0.040658928686752915
Online_Training [391/700]: mean_loss=0.008218170201871544
Online_Training [392/700]: mean_loss=0.02567436988465488
Online_Training [393/700]: mean_loss=0.023184045450761914
Online_Training [394/700]: mean_loss=0.02480362239293754
Online_Training [395/700]: mean_loss=0.006495853245723993
Online_Training [396/700]: mean_loss=0.02317663561552763
Online_Training [397/700]: mean_loss=0.016167062101885676
Online_Training [398/700]: mean_loss=0.028702530777081847
Online_Training [399/700]: mean_loss=0.030301616061478853
Online_Training [400/700]: mean_loss=0.03138337144628167
Online_Training [401/700]: mean_loss=0.032512353267520666
Online_Training [402/700]: mean_loss=0.012254217290319502
Online_Training [403/700]: mean_loss=0.017969743232242763
Online_Training [404/700]: mean_loss=0.04368922067806125
Online_Training [405/700]: mean_loss=0.06444068672135472
Online_Training [406/700]: mean_loss=0.010512512759305537
Online_Training [407/700]: mean_loss=0.03781323553994298
Online_Training [408/700]: mean_loss=0.014898414956405759
Online_Training [409/700]: mean_loss=0.005765466601587832
Online_Training [410/700]: mean_loss=0.02385592903010547
Online_Training [411/700]: mean_loss=0.01619440282229334
Online_Training [412/700]: mean_loss=0.09587250556796789
Online_Training [413/700]: mean_loss=0.030263822060078382
Online_Training [414/700]: mean_loss=0.017536666011437774
Online_Training [415/700]: mean_loss=0.023872279562056065
Online_Training [416/700]: mean_loss=0.014395370380952954
Online_Training [417/700]: mean_loss=0.06020122533664107
Online_Training [418/700]: mean_loss=0.009818913298659027
Online_Training [419/700]: mean_loss=0.011942837154492736
Online_Training [420/700]: mean_loss=0.05235030967742205
Online_Training [421/700]: mean_loss=0.034348211949691176
Online_Training [422/700]: mean_loss=0.0255940742790699
Online_Training [423/700]: mean_loss=0.03636699775233865
Online_Training [424/700]: mean_loss=0.05805473169311881
Online_Training [425/700]: mean_loss=0.025901774177327752
Online_Training [426/700]: mean_loss=0.00755808298708871
Online_Training [427/700]: mean_loss=0.019524455070495605
Online_Training [428/700]: mean_loss=0.026678069727495313
Online_Training [429/700]: mean_loss=0.011961770826019347
Online_Training [430/700]: mean_loss=0.009669671184383333
Online_Training [431/700]: mean_loss=0.014663270325399935
Online_Training [432/700]: mean_loss=0.0611586831510067
Online_Training [433/700]: mean_loss=0.012941173859871924
Online_Training [434/700]: mean_loss=0.015898175654001534
Online_Training [435/700]: mean_loss=0.015095130074769258
Online_Training [436/700]: mean_loss=0.0457842918112874
Online_Training [437/700]: mean_loss=0.014881179318763316
Online_Training [438/700]: mean_loss=0.17123498395085335
Online_Training [439/700]: mean_loss=0.09650569874793291
Online_Training [440/700]: mean_loss=0.06615108205005527
Online_Training [441/700]: mean_loss=0.07715641520917416
Online_Training [442/700]: mean_loss=0.0298036674503237
Online_Training [443/700]: mean_loss=0.013800396234728396
Online_Training [444/700]: mean_loss=0.027591199381276965
Online_Training [445/700]: mean_loss=0.023907808121293783
Online_Training [446/700]: mean_loss=0.03760184533894062
Online_Training [447/700]: mean_loss=0.012546238489449024
Online_Training [448/700]: mean_loss=0.018716297578066587
Online_Training [449/700]: mean_loss=0.0175811582012102
Online_Training [450/700]: mean_loss=0.01680662133730948
Online_Training [451/700]: mean_loss=0.04693156015127897
Online_Training [452/700]: mean_loss=0.03591817012056708
Online_Training [453/700]: mean_loss=0.0633877501823008
Online_Training [454/700]: mean_loss=0.03817654447630048
Online_Training [455/700]: mean_loss=0.040419446770101786
Online_Training [456/700]: mean_loss=0.011273013078607619
Online_Training [457/700]: mean_loss=0.010743756894953549
Online_Training [458/700]: mean_loss=0.029689738992601633
Online_Training [459/700]: mean_loss=0.015531162731349468
Online_Training [460/700]: mean_loss=0.025399042759090662
Online_Training [461/700]: mean_loss=0.036080937599763274
Online_Training [462/700]: mean_loss=0.021127690095454454
Online_Training [463/700]: mean_loss=0.016197712160646915
Online_Training [464/700]: mean_loss=0.018374509178102016
Online_Training [465/700]: mean_loss=0.028766489354893565
Online_Training [466/700]: mean_loss=0.029143638676032424
Online_Training [467/700]: mean_loss=0.037067943485453725
Online_Training [468/700]: mean_loss=0.019371702801436186
Online_Training [469/700]: mean_loss=0.01964595355093479
Online_Training [470/700]: mean_loss=0.0456715552136302
Online_Training [471/700]: mean_loss=0.02456012391485274
Online_Training [472/700]: mean_loss=0.023468369152396917
Online_Training [473/700]: mean_loss=0.009367590304464102
Online_Training [474/700]: mean_loss=0.014378560706973076
Online_Training [475/700]: mean_loss=0.02256170567125082
Online_Training [476/700]: mean_loss=0.22526196017861366
Online_Training [477/700]: mean_loss=0.14953097980469465
Online_Training [478/700]: mean_loss=0.04489532392472029
Online_Training [479/700]: mean_loss=0.007839499274268746
Online_Training [480/700]: mean_loss=0.01203490688931197
Online_Training [481/700]: mean_loss=0.024136333027854562
Online_Training [482/700]: mean_loss=0.02557475888170302
Online_Training [483/700]: mean_loss=0.015820595435798168
Online_Training [484/700]: mean_loss=0.02528212359175086
Online_Training [485/700]: mean_loss=0.013902633101679385
Online_Training [486/700]: mean_loss=0.019652401097118855
Online_Training [487/700]: mean_loss=0.03419206105172634
Online_Training [488/700]: mean_loss=0.017154689878225327
Online_Training [489/700]: mean_loss=0.01834896020591259
Online_Training [490/700]: mean_loss=0.024168494157493114
Online_Training [491/700]: mean_loss=0.035129600670188665
Online_Training [492/700]: mean_loss=0.016538168536499143
Online_Training [493/700]: mean_loss=0.022579673561267555
Online_Training [494/700]: mean_loss=0.043513497803360224
Online_Training [495/700]: mean_loss=0.013049975503236055
Online_Training [496/700]: mean_loss=0.04352844087406993
Online_Training [497/700]: mean_loss=0.02342106564901769
Online_Training [498/700]: mean_loss=0.018559301039204
Online_Training [499/700]: mean_loss=0.020334392553195357
Online_Training [500/700]: mean_loss=0.014267448452301323
Online_Training [501/700]: mean_loss=0.014941148809157312
Online_Training [502/700]: mean_loss=0.04210554948076606
Online_Training [503/700]: mean_loss=0.017825532471761107
Online_Training [504/700]: mean_loss=0.030089057283475995
Online_Training [505/700]: mean_loss=0.018659179797396064
Online_Training [506/700]: mean_loss=0.11973440274596214
Online_Training [507/700]: mean_loss=0.14992337487637997
Online_Training [508/700]: mean_loss=0.0319198053330183
Online_Training [509/700]: mean_loss=0.014044351992197335
Online_Training [510/700]: mean_loss=0.03855600534006953
Online_Training [511/700]: mean_loss=0.025257103145122528
Online_Training [512/700]: mean_loss=0.016418756800703704
Online_Training [513/700]: mean_loss=0.01803501311223954
Online_Training [514/700]: mean_loss=0.032239408465102315
Online_Training [515/700]: mean_loss=0.022270738845691085
Online_Training [516/700]: mean_loss=0.019443289609625936
Online_Training [517/700]: mean_loss=0.02511546853929758
Online_Training [518/700]: mean_loss=0.0329891515430063
Online_Training [519/700]: mean_loss=0.008390424656681716
Online_Training [520/700]: mean_loss=0.029301192378625274
Online_Training [521/700]: mean_loss=0.036152391927316785
Online_Training [522/700]: mean_loss=0.007977207947988063
Online_Training [523/700]: mean_loss=0.019956494215875864
Online_Training [524/700]: mean_loss=0.07127265073359013
Online_Training [525/700]: mean_loss=0.0239043734036386
Online_Training [526/700]: mean_loss=0.01275685615837574
Online_Training [527/700]: mean_loss=0.01584385079331696
Online_Training [528/700]: mean_loss=0.03470273385755718
Online_Training [529/700]: mean_loss=0.026344087440520525
Online_Training [530/700]: mean_loss=0.026923812925815582
Online_Training [531/700]: mean_loss=0.05733030615374446
Online_Training [532/700]: mean_loss=0.02268185466527939
Online_Training [533/700]: mean_loss=0.02522684819996357
Online_Training [534/700]: mean_loss=0.020067542558535933
Online_Training [535/700]: mean_loss=0.018212063005194068
Online_Training [536/700]: mean_loss=0.09234048426151276
Online_Training [537/700]: mean_loss=0.04572001798078418
Online_Training [538/700]: mean_loss=0.008783194120042026
Online_Training [539/700]: mean_loss=0.009818901075050235
Online_Training [540/700]: mean_loss=0.02431130106560886
Online_Training [541/700]: mean_loss=0.09103010967373848
Online_Training [542/700]: mean_loss=0.00679084233706817
Online_Training [543/700]: mean_loss=0.020963520277291536
Online_Training [544/700]: mean_loss=0.01820499263703823
Online_Training [545/700]: mean_loss=0.04195699281990528
Online_Training [546/700]: mean_loss=0.012087835348211229
Online_Training [547/700]: mean_loss=0.018514705821871758
Online_Training [548/700]: mean_loss=0.015460855327546597
Online_Training [549/700]: mean_loss=0.006042980763595551
Online_Training [550/700]: mean_loss=0.047369839157909155
Online_Training [551/700]: mean_loss=0.03966829879209399
Online_Training [552/700]: mean_loss=0.04893995728343725
Online_Training [553/700]: mean_loss=0.04102405719459057
Online_Training [554/700]: mean_loss=0.010994142154231668
Online_Training [555/700]: mean_loss=0.022047516191378236
Online_Training [556/700]: mean_loss=0.014250759617425501
Online_Training [557/700]: mean_loss=0.016727789654396474
Online_Training [558/700]: mean_loss=0.00962999276816845
Online_Training [559/700]: mean_loss=0.004784304794156924
Online_Training [560/700]: mean_loss=0.012103948276489973
Online_Training [561/700]: mean_loss=0.02312379819341004
Online_Training [562/700]: mean_loss=0.036383059807121754
Online_Training [563/700]: mean_loss=0.013122018659487367
Online_Training [564/700]: mean_loss=0.011616196716204286
Online_Training [565/700]: mean_loss=0.0338966129347682
Online_Training [566/700]: mean_loss=0.020000049378722906
Online_Training [567/700]: mean_loss=0.0126888332888484
Online_Training [568/700]: mean_loss=0.02437893976457417
Online_Training [569/700]: mean_loss=0.028340335236862302
Online_Training [570/700]: mean_loss=0.007767635688651353
Online_Training [571/700]: mean_loss=0.03594773937948048
Online_Training [572/700]: mean_loss=0.01813624450005591
Online_Training [573/700]: mean_loss=0.02561450796201825
Online_Training [574/700]: mean_loss=0.04746899055317044
Online_Training [575/700]: mean_loss=0.0654241000302136
Online_Training [576/700]: mean_loss=0.012453083647415042
Online_Training [577/700]: mean_loss=0.02183155226521194
Online_Training [578/700]: mean_loss=0.010037142666988075
Online_Training [579/700]: mean_loss=0.01479129632934928
Online_Training [580/700]: mean_loss=0.021451445762068033
Online_Training [581/700]: mean_loss=0.025781606091186404
Online_Training [582/700]: mean_loss=0.02886779303662479
Online_Training [583/700]: mean_loss=0.004286953306291252
Online_Training [584/700]: mean_loss=0.038069669622927904
Online_Training [585/700]: mean_loss=0.02061846642754972
Online_Training [586/700]: mean_loss=0.07369357906281948
Online_Training [587/700]: mean_loss=0.03325045062229037
Online_Training [588/700]: mean_loss=0.014836710877716541
Online_Training [589/700]: mean_loss=0.026958643924444914
Online_Training [590/700]: mean_loss=0.010853404819499701
Online_Training [591/700]: mean_loss=0.019234650069847703
Online_Training [592/700]: mean_loss=0.016939245397225022
Online_Training [593/700]: mean_loss=0.042400187347084284
Online_Training [594/700]: mean_loss=0.03737987158820033
Online_Training [595/700]: mean_loss=0.02749161748215556
Online_Training [596/700]: mean_loss=0.014912684331648052
Online_Training [597/700]: mean_loss=0.008074126555584371
Online_Training [598/700]: mean_loss=0.023744852980598807
Online_Training [599/700]: mean_loss=0.020813387352973223
Online_Training [600/700]: mean_loss=0.01222517853602767
Online_Training [601/700]: mean_loss=0.03322510584257543
Online_Training [602/700]: mean_loss=0.008929887088015676
Online_Training [603/700]: mean_loss=0.006108469562605023
Online_Training [604/700]: mean_loss=0.01757215545512736
Online_Training [605/700]: mean_loss=0.015010452596470714
Online_Training [606/700]: mean_loss=0.005032020679209381
Online_Training [607/700]: mean_loss=0.007293274044059217
Online_Training [608/700]: mean_loss=0.017684894148260355
Online_Training [609/700]: mean_loss=0.012965511181391776
Online_Training [610/700]: mean_loss=0.016279065748676658
Online_Training [611/700]: mean_loss=0.011522731627337635
Online_Training [612/700]: mean_loss=0.13883110880851746
Online_Training [613/700]: mean_loss=0.055418639443814754
Online_Training [614/700]: mean_loss=0.01473005278967321
Online_Training [615/700]: mean_loss=0.013967954088002443
Online_Training [616/700]: mean_loss=0.03216726239770651
Online_Training [617/700]: mean_loss=0.005059949879068881
Online_Training [618/700]: mean_loss=0.02420929353684187
Online_Training [619/700]: mean_loss=0.01963983243331313
Online_Training [620/700]: mean_loss=0.08019677083939314
Online_Training [621/700]: mean_loss=0.012936442042700946
Online_Training [622/700]: mean_loss=0.048246505204588175
Online_Training [623/700]: mean_loss=0.058664624113589525
Online_Training [624/700]: mean_loss=0.016825232654809952
Online_Training [625/700]: mean_loss=0.01011518610175699
Online_Training [626/700]: mean_loss=0.030701070558279753
Online_Training [627/700]: mean_loss=0.016839981311932206
Online_Training [628/700]: mean_loss=0.010598503518849611
Online_Training [629/700]: mean_loss=0.0695390272885561
Online_Training [630/700]: mean_loss=0.040393128991127014
Online_Training [631/700]: mean_loss=0.013944230857305229
Online_Training [632/700]: mean_loss=0.022839516401290894
Online_Training [633/700]: mean_loss=0.01751042460091412
Online_Training [634/700]: mean_loss=0.023192349122837186
Online_Training [635/700]: mean_loss=0.019908284884877503
Online_Training [636/700]: mean_loss=0.013295963872224092
Online_Training [637/700]: mean_loss=0.01713695377111435
Online_Training [638/700]: mean_loss=0.043628083541989326
Online_Training [639/700]: mean_loss=0.021902151638641953
Online_Training [640/700]: mean_loss=0.010565232019871473
Online_Training [641/700]: mean_loss=0.012553744367323816
Online_Training [642/700]: mean_loss=0.018021653639152646
Online_Training [643/700]: mean_loss=0.009084536111913621
Online_Training [644/700]: mean_loss=0.0352538051083684
Online_Training [645/700]: mean_loss=0.012874464388005435
Online_Training [646/700]: mean_loss=0.062337796203792095
Online_Training [647/700]: mean_loss=0.007922956137917936
Online_Training [648/700]: mean_loss=0.01566815993282944
Online_Training [649/700]: mean_loss=0.012340824236162007
Online_Training [650/700]: mean_loss=0.01517464267089963
Online_Training [651/700]: mean_loss=0.009916507522575557
Online_Training [652/700]: mean_loss=0.009672542742919177
Online_Training [653/700]: mean_loss=0.0683098086155951
Online_Training [654/700]: mean_loss=0.015635977615602314
Online_Training [655/700]: mean_loss=0.014382185647264123
Online_Training [656/700]: mean_loss=0.01491621055174619
Online_Training [657/700]: mean_loss=0.015712599910330027
Online_Training [658/700]: mean_loss=0.01681220973841846
Online_Training [659/700]: mean_loss=0.023751912638545036
Online_Training [660/700]: mean_loss=0.013645574916154146
Online_Training [661/700]: mean_loss=0.03980251681059599
Online_Training [662/700]: mean_loss=0.028052154695615172
Online_Training [663/700]: mean_loss=0.019878373248502612
Online_Training [664/700]: mean_loss=0.0053910272545181215
Online_Training [665/700]: mean_loss=0.04209883138537407
Online_Training [666/700]: mean_loss=0.012040366185829043
Online_Training [667/700]: mean_loss=0.006906386755872518
Online_Training [668/700]: mean_loss=0.023573510814458132
Online_Training [669/700]: mean_loss=0.011158869485370815
Online_Training [670/700]: mean_loss=0.01331512862816453
Online_Training [671/700]: mean_loss=0.012085660244338214
Online_Training [672/700]: mean_loss=0.016327479854226112
Online_Training [673/700]: mean_loss=0.01148550002835691
Online_Training [674/700]: mean_loss=0.013734648237004876
Online_Training [675/700]: mean_loss=0.012027852237224579
Online_Training [676/700]: mean_loss=0.032089164946228266
Online_Training [677/700]: mean_loss=0.05315656401216984
Online_Training [678/700]: mean_loss=0.01798175391741097
Online_Training [679/700]: mean_loss=0.014765712316147983
Online_Training [680/700]: mean_loss=0.03397663962095976
Online_Training [681/700]: mean_loss=0.017622158979065716
Online_Training [682/700]: mean_loss=0.006815123721025884
Online_Training [683/700]: mean_loss=0.01015615975484252
Online_Training [684/700]: mean_loss=0.01485579158179462
Online_Training [685/700]: mean_loss=0.030855220975354314
Online_Training [686/700]: mean_loss=0.013870096066966653
Online_Training [687/700]: mean_loss=0.007639829011168331
Online_Training [688/700]: mean_loss=0.06359522417187691
Online_Training [689/700]: mean_loss=0.01889454131014645
Online_Training [690/700]: mean_loss=0.014157692901790142
Online_Training [691/700]: mean_loss=0.028518338920548558
Online_Training [692/700]: mean_loss=0.026490194955840707
Online_Training [693/700]: mean_loss=0.012309339828789234
Online_Training [694/700]: mean_loss=0.029781935503706336
Online_Training [695/700]: mean_loss=0.017221919493749738
Online_Training [696/700]: mean_loss=0.04464234784245491
Online_Training [697/700]: mean_loss=0.012314479448832572
Online_Training [698/700]: mean_loss=0.021371352137066424
Online_Training [699/700]: mean_loss=0.1244714641943574
Online_Training [700/700]: mean_loss=0.02102431596722454
Q_Learning [1/300]: mean_loss=0.2006339505314827
Q_Learning [2/300]: mean_loss=0.2430319171398878
Q_Learning [3/300]: mean_loss=0.22050213254988194
Q_Learning [4/300]: mean_loss=0.08446377236396074
Q_Learning [5/300]: mean_loss=0.25137187726795673
Q_Learning [6/300]: mean_loss=0.10796177014708519
Q_Learning [7/300]: mean_loss=0.11403135862201452
Q_Learning [8/300]: mean_loss=0.07530721183866262
Q_Learning [9/300]: mean_loss=0.12204575445502996
Q_Learning [10/300]: mean_loss=0.15029273927211761
Q_Learning [11/300]: mean_loss=0.06494785845279694
Q_Learning [12/300]: mean_loss=0.07111447770148516
Q_Learning [13/300]: mean_loss=0.08543363772332668
Q_Learning [14/300]: mean_loss=0.0352630908600986
Q_Learning [15/300]: mean_loss=0.04451932059600949
Q_Learning [16/300]: mean_loss=0.12520800530910492
Q_Learning [17/300]: mean_loss=0.09295208565890789
Q_Learning [18/300]: mean_loss=0.0564671796746552
Q_Learning [19/300]: mean_loss=0.026302488055080175
Q_Learning [20/300]: mean_loss=0.14758675545454025
Q_Learning [21/300]: mean_loss=0.12977823242545128
Q_Learning [22/300]: mean_loss=0.019443512661382556
Q_Learning [23/300]: mean_loss=0.018300584517419338
Q_Learning [24/300]: mean_loss=0.07178271654993296
Q_Learning [25/300]: mean_loss=0.03866708232089877
Q_Learning [26/300]: mean_loss=0.04723857855424285
Q_Learning [27/300]: mean_loss=0.10611386317759752
Q_Learning [28/300]: mean_loss=0.035896089393645525
Q_Learning [29/300]: mean_loss=0.04460737854242325
Q_Learning [30/300]: mean_loss=0.03173204930499196
Q_Learning [31/300]: mean_loss=0.028062039287760854
Q_Learning [32/300]: mean_loss=0.04436734225600958
Q_Learning [33/300]: mean_loss=0.023949507158249617
Q_Learning [34/300]: mean_loss=0.14377667382359505
Q_Learning [35/300]: mean_loss=0.05411825329065323
Q_Learning [36/300]: mean_loss=0.08588493801653385
Q_Learning [37/300]: mean_loss=0.05232199653983116
Q_Learning [38/300]: mean_loss=0.040948871057480574
Q_Learning [39/300]: mean_loss=0.11715704295784235
Q_Learning [40/300]: mean_loss=0.033325752476230264
Q_Learning [41/300]: mean_loss=0.031153156189247966
Q_Learning [42/300]: mean_loss=0.0577699551358819
Q_Learning [43/300]: mean_loss=0.11939004436135292
Q_Learning [44/300]: mean_loss=0.15081367641687393
Q_Learning [45/300]: mean_loss=0.06321040214970708
Q_Learning [46/300]: mean_loss=0.03800788428634405
Q_Learning [47/300]: mean_loss=0.08822763618081808
Q_Learning [48/300]: mean_loss=0.07015220634639263
Q_Learning [49/300]: mean_loss=0.09023109171539545
Q_Learning [50/300]: mean_loss=0.1199053218588233
Q_Learning [51/300]: mean_loss=0.026291385293006897
Q_Learning [52/300]: mean_loss=0.16657978668808937
Q_Learning [53/300]: mean_loss=0.02095453324727714
Q_Learning [54/300]: mean_loss=0.08665870502591133
Q_Learning [55/300]: mean_loss=0.03816726943477988
Q_Learning [56/300]: mean_loss=0.04069593036547303
Q_Learning [57/300]: mean_loss=0.06534491712227464
Q_Learning [58/300]: mean_loss=0.3484125882387161
Q_Learning [59/300]: mean_loss=0.07024162588641047
Q_Learning [60/300]: mean_loss=0.06856631208211184
Q_Learning [61/300]: mean_loss=0.05523296119645238
Q_Learning [62/300]: mean_loss=0.08747024228796363
Q_Learning [63/300]: mean_loss=0.06703915633261204
Q_Learning [64/300]: mean_loss=0.00816499680513516
Q_Learning [65/300]: mean_loss=0.06413964787498116
Q_Learning [66/300]: mean_loss=0.04327953141182661
Q_Learning [67/300]: mean_loss=0.061305887065827847
Q_Learning [68/300]: mean_loss=0.0730448691174388
Q_Learning [69/300]: mean_loss=0.17818692326545715
Q_Learning [70/300]: mean_loss=0.03714572498574853
Q_Learning [71/300]: mean_loss=0.07513544801622629
Q_Learning [72/300]: mean_loss=0.07723300904035568
Q_Learning [73/300]: mean_loss=0.04133720276877284
Q_Learning [74/300]: mean_loss=0.04172035586088896
Q_Learning [75/300]: mean_loss=0.030572673538699746
Q_Learning [76/300]: mean_loss=0.04238187009468675
Q_Learning [77/300]: mean_loss=0.04193710698746145
Q_Learning [78/300]: mean_loss=0.06769988685846329
Q_Learning [79/300]: mean_loss=0.04319629538804293
Q_Learning [80/300]: mean_loss=0.035978137981146574
Q_Learning [81/300]: mean_loss=0.014137008460238576
Q_Learning [82/300]: mean_loss=0.029106634203344584
Q_Learning [83/300]: mean_loss=0.10961493477225304
Q_Learning [84/300]: mean_loss=0.03134161210618913
Q_Learning [85/300]: mean_loss=0.023666636552661657
Q_Learning [86/300]: mean_loss=0.05738385906443
Q_Learning [87/300]: mean_loss=0.013945995247922838
Q_Learning [88/300]: mean_loss=0.03137581027112901
Q_Learning [89/300]: mean_loss=0.04651913931593299
Q_Learning [90/300]: mean_loss=0.02241769223473966
Q_Learning [91/300]: mean_loss=0.03718185983598232
Q_Learning [92/300]: mean_loss=0.04715253412723541
Q_Learning [93/300]: mean_loss=0.058585465885698795
Q_Learning [94/300]: mean_loss=0.056631291285157204
Q_Learning [95/300]: mean_loss=0.06617959029972553
Q_Learning [96/300]: mean_loss=0.020651123370043933
Q_Learning [97/300]: mean_loss=0.0560779832303524
Q_Learning [98/300]: mean_loss=0.04428124940022826
Q_Learning [99/300]: mean_loss=0.01881395443342626
Q_Learning [100/300]: mean_loss=0.04375685704872012
Q_Learning [101/300]: mean_loss=0.031521196477115154
Q_Learning [102/300]: mean_loss=0.058606951497495174
Q_Learning [103/300]: mean_loss=0.04588177427649498
Q_Learning [104/300]: mean_loss=0.05606377124786377
Q_Learning [105/300]: mean_loss=0.03824298968538642
Q_Learning [106/300]: mean_loss=0.01496502012014389
Q_Learning [107/300]: mean_loss=0.017027721041813493
Q_Learning [108/300]: mean_loss=0.031226832885295153
Q_Learning [109/300]: mean_loss=0.03681512945331633
Q_Learning [110/300]: mean_loss=0.03113732673227787
Q_Learning [111/300]: mean_loss=0.029751094989478588
Q_Learning [112/300]: mean_loss=0.15565561316907406
Q_Learning [113/300]: mean_loss=0.026922553777694702
Q_Learning [114/300]: mean_loss=0.05732702696695924
Q_Learning [115/300]: mean_loss=0.04295912757515907
Q_Learning [116/300]: mean_loss=0.028974503744393587
Q_Learning [117/300]: mean_loss=0.05432074470445514
Q_Learning [118/300]: mean_loss=0.056795123498886824
Q_Learning [119/300]: mean_loss=0.12788630090653896
Q_Learning [120/300]: mean_loss=0.06395474309101701
Q_Learning [121/300]: mean_loss=0.06745206750929356
Q_Learning [122/300]: mean_loss=0.07385201565921307
Q_Learning [123/300]: mean_loss=0.035073064267635345
Q_Learning [124/300]: mean_loss=0.013005473301745951
Q_Learning [125/300]: mean_loss=0.08400718914344907
Q_Learning [126/300]: mean_loss=0.039744215086102486
Q_Learning [127/300]: mean_loss=0.0693319933488965
Q_Learning [128/300]: mean_loss=0.02797252801246941
Q_Learning [129/300]: mean_loss=0.03271903400309384
Q_Learning [130/300]: mean_loss=0.020516570657491684
Q_Learning [131/300]: mean_loss=0.027882908936589956
Q_Learning [132/300]: mean_loss=0.018296118592843413
Q_Learning [133/300]: mean_loss=0.02529704663902521
Q_Learning [134/300]: mean_loss=0.025064500281587243
Q_Learning [135/300]: mean_loss=0.10897853318601847
Q_Learning [136/300]: mean_loss=0.022181940963491797
Q_Learning [137/300]: mean_loss=0.02677396940998733
Q_Learning [138/300]: mean_loss=0.011712275561876595
Q_Learning [139/300]: mean_loss=0.020239447010681033
Q_Learning [140/300]: mean_loss=0.03317991178482771
Q_Learning [141/300]: mean_loss=0.030773463426157832
Q_Learning [142/300]: mean_loss=0.013160407543182373
Q_Learning [143/300]: mean_loss=0.028075278969481587
Q_Learning [144/300]: mean_loss=0.014512298861518502
Q_Learning [145/300]: mean_loss=0.06288888864219189
Q_Learning [146/300]: mean_loss=0.021489011589437723
Q_Learning [147/300]: mean_loss=0.016469066846184433
Q_Learning [148/300]: mean_loss=0.051110494416207075
Q_Learning [149/300]: mean_loss=0.09652089048177004
Q_Learning [150/300]: mean_loss=0.11653646174818277
Q_Learning [151/300]: mean_loss=0.022119836416095495
Q_Learning [152/300]: mean_loss=0.019971338333562016
Q_Learning [153/300]: mean_loss=0.05183590669184923
Q_Learning [154/300]: mean_loss=0.038561627734452486
Q_Learning [155/300]: mean_loss=0.013934488641098142
Q_Learning [156/300]: mean_loss=0.020498201483860612
Q_Learning [157/300]: mean_loss=0.14889876265078783
Q_Learning [158/300]: mean_loss=0.013430431310553104
Q_Learning [159/300]: mean_loss=0.018320608651265502
Q_Learning [160/300]: mean_loss=0.036105782724916935
Q_Learning [161/300]: mean_loss=0.033204405568540096
Q_Learning [162/300]: mean_loss=0.015688073355704546
Q_Learning [163/300]: mean_loss=0.04933762131258845
Q_Learning [164/300]: mean_loss=0.014591657323762774
Q_Learning [165/300]: mean_loss=0.010413410607725382
Q_Learning [166/300]: mean_loss=0.02153017884120345
Q_Learning [167/300]: mean_loss=0.03955838456749916
Q_Learning [168/300]: mean_loss=0.04579492565244436
Q_Learning [169/300]: mean_loss=0.05121366959065199
Q_Learning [170/300]: mean_loss=0.18074725568294525
Q_Learning [171/300]: mean_loss=0.020672898273915052
Q_Learning [172/300]: mean_loss=0.016595662687905133
Q_Learning [173/300]: mean_loss=0.02635489613749087
Q_Learning [174/300]: mean_loss=0.013711231877095997
Q_Learning [175/300]: mean_loss=0.012496649869717658
Q_Learning [176/300]: mean_loss=0.0062939790659584105
Q_Learning [177/300]: mean_loss=0.036527652060613036
Q_Learning [178/300]: mean_loss=0.03487574029713869
Q_Learning [179/300]: mean_loss=0.024289379362016916
Q_Learning [180/300]: mean_loss=0.03565683378838003
Q_Learning [181/300]: mean_loss=0.03773608151823282
Q_Learning [182/300]: mean_loss=0.021283756708726287
Q_Learning [183/300]: mean_loss=0.01409360091201961
Q_Learning [184/300]: mean_loss=0.008574437350034714
Q_Learning [185/300]: mean_loss=0.036075526382774115
Q_Learning [186/300]: mean_loss=0.0344013930298388
Q_Learning [187/300]: mean_loss=0.026932145236060023
Q_Learning [188/300]: mean_loss=0.025777998380362988
Q_Learning [189/300]: mean_loss=0.05469953361898661
Q_Learning [190/300]: mean_loss=0.023901014123111963
Q_Learning [191/300]: mean_loss=0.15187152661383152
Q_Learning [192/300]: mean_loss=0.021969560300931334
Q_Learning [193/300]: mean_loss=0.0242291996255517
Q_Learning [194/300]: mean_loss=0.021388118620961905
Q_Learning [195/300]: mean_loss=0.0234365938231349
Q_Learning [196/300]: mean_loss=0.014048067037947476
Q_Learning [197/300]: mean_loss=0.04716943670064211
Q_Learning [198/300]: mean_loss=0.015883205691352487
Q_Learning [199/300]: mean_loss=0.08217114489525557
Q_Learning [200/300]: mean_loss=0.018270117812789977
Q_Learning [201/300]: mean_loss=0.03445654036477208
Q_Learning [202/300]: mean_loss=0.019443725934252143
Q_Learning [203/300]: mean_loss=0.010627388255670667
Q_Learning [204/300]: mean_loss=0.01923739700578153
Q_Learning [205/300]: mean_loss=0.0710673313587904
Q_Learning [206/300]: mean_loss=0.018716043676249683
Q_Learning [207/300]: mean_loss=0.049809171352535486
Q_Learning [208/300]: mean_loss=0.045632341876626015
Q_Learning [209/300]: mean_loss=0.04798362636938691
Q_Learning [210/300]: mean_loss=0.02611483889631927
Q_Learning [211/300]: mean_loss=0.018470288021489978
Q_Learning [212/300]: mean_loss=0.09271610248833895
Q_Learning [213/300]: mean_loss=0.08247792162001133
Q_Learning [214/300]: mean_loss=0.021624871995300055
Q_Learning [215/300]: mean_loss=0.02961090300232172
Q_Learning [216/300]: mean_loss=0.054740657564252615
Q_Learning [217/300]: mean_loss=0.013616817421279848
Q_Learning [218/300]: mean_loss=0.008721047779545188
Q_Learning [219/300]: mean_loss=0.053996832109987736
Q_Learning [220/300]: mean_loss=0.012692464515566826
Q_Learning [221/300]: mean_loss=0.031368950149044394
Q_Learning [222/300]: mean_loss=0.023417797638103366
Q_Learning [223/300]: mean_loss=0.031245161779224873
Q_Learning [224/300]: mean_loss=0.006692674709483981
Q_Learning [225/300]: mean_loss=0.02119963150471449
Q_Learning [226/300]: mean_loss=0.018405392300337553
Q_Learning [227/300]: mean_loss=0.009404577082023025
Q_Learning [228/300]: mean_loss=0.037183700827881694
Q_Learning [229/300]: mean_loss=0.05196100287139416
Q_Learning [230/300]: mean_loss=0.01645104947965592
Q_Learning [231/300]: mean_loss=0.025091601070016623
Q_Learning [232/300]: mean_loss=0.020277239615097642
Q_Learning [233/300]: mean_loss=0.02735265577211976
Q_Learning [234/300]: mean_loss=0.025038850959390402
Q_Learning [235/300]: mean_loss=0.06882391963154078
Q_Learning [236/300]: mean_loss=0.04993595788255334
Q_Learning [237/300]: mean_loss=0.03349197958596051
Q_Learning [238/300]: mean_loss=0.09738982748240232
Q_Learning [239/300]: mean_loss=0.22969739511609077
Q_Learning [240/300]: mean_loss=0.07791665568947792
Q_Learning [241/300]: mean_loss=0.042448027059435844
Q_Learning [242/300]: mean_loss=0.03546882001683116
Q_Learning [243/300]: mean_loss=0.04043419286608696
Q_Learning [244/300]: mean_loss=0.041086018551141024
Q_Learning [245/300]: mean_loss=0.05826086364686489
Q_Learning [246/300]: mean_loss=0.026851337403059006
Q_Learning [247/300]: mean_loss=0.011403331998735666
Q_Learning [248/300]: mean_loss=0.05863264761865139
Q_Learning [249/300]: mean_loss=0.05208519147709012
Q_Learning [250/300]: mean_loss=0.015628131572157145
Q_Learning [251/300]: mean_loss=0.020789144560694695
Q_Learning [252/300]: mean_loss=0.015322895022109151
Q_Learning [253/300]: mean_loss=0.0130675412947312
Q_Learning [254/300]: mean_loss=0.02053826511837542
Q_Learning [255/300]: mean_loss=0.0455809086561203
Q_Learning [256/300]: mean_loss=0.019824121613055468
Q_Learning [257/300]: mean_loss=0.029654108453541994
Q_Learning [258/300]: mean_loss=0.01252309198025614
Q_Learning [259/300]: mean_loss=0.00988991349004209
Q_Learning [260/300]: mean_loss=0.019256274681538343
Q_Learning [261/300]: mean_loss=0.021794989705085754
Q_Learning [262/300]: mean_loss=0.03076478629373014
Q_Learning [263/300]: mean_loss=0.01656468107830733
Q_Learning [264/300]: mean_loss=0.04489274136722088
Q_Learning [265/300]: mean_loss=0.019230927107855678
Q_Learning [266/300]: mean_loss=0.011998748290352523
Q_Learning [267/300]: mean_loss=0.0136406309902668
Q_Learning [268/300]: mean_loss=0.008618883788585663
Q_Learning [269/300]: mean_loss=0.031586474273353815
Q_Learning [270/300]: mean_loss=0.01703294867184013
Q_Learning [271/300]: mean_loss=0.019151558401063085
Q_Learning [272/300]: mean_loss=0.007192717806901783
Q_Learning [273/300]: mean_loss=0.01441699406132102
Q_Learning [274/300]: mean_loss=0.029931313591077924
Q_Learning [275/300]: mean_loss=0.010413801181130111
Q_Learning [276/300]: mean_loss=0.018217624397948384
Q_Learning [277/300]: mean_loss=0.07867702934890985
Q_Learning [278/300]: mean_loss=0.025452018715441227
Q_Learning [279/300]: mean_loss=0.024804947432130575
Q_Learning [280/300]: mean_loss=0.03425543592311442
Q_Learning [281/300]: mean_loss=0.03581477305851877
Q_Learning [282/300]: mean_loss=0.024642087053507566
Q_Learning [283/300]: mean_loss=0.019410347566008568
Q_Learning [284/300]: mean_loss=0.033821118995547295
Q_Learning [285/300]: mean_loss=0.027920314809307456
Q_Learning [286/300]: mean_loss=0.00828343944158405
Q_Learning [287/300]: mean_loss=0.010976861929520965
Q_Learning [288/300]: mean_loss=0.014739537262357771
Q_Learning [289/300]: mean_loss=0.03626002324745059
Q_Learning [290/300]: mean_loss=0.008597983280196786
Q_Learning [291/300]: mean_loss=0.013560950988903642
Q_Learning [292/300]: mean_loss=0.006929626455530524
Q_Learning [293/300]: mean_loss=0.021183595759794116
Q_Learning [294/300]: mean_loss=0.031478629913181067
Q_Learning [295/300]: mean_loss=0.03454837156459689
Q_Learning [296/300]: mean_loss=0.038725089048966765
Q_Learning [297/300]: mean_loss=0.019843329908326268
Q_Learning [298/300]: mean_loss=0.030470542376860976
Q_Learning [299/300]: mean_loss=0.034540430177003145
Q_Learning [300/300]: mean_loss=0.04836683114990592
Number of Samples after Autoencoder testing: 300
First Spike after testing: [2.2660425  0.01936641]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]
Centroids: [[-1.2234377, -0.7352896], [-0.27594686, -0.60387176], [1.6515039, -0.064165756]]
Centroids: [[-0.6970418, -0.6461515], [1.6732842, -0.08022451]]
Contingency Matrix: 
[[103   0]
 [100   0]
 [  6  91]]
[[103, 0], [100, 0], [6, 91]]
[[103, 0, 0], [100, 0, 0], [6, 91, 0]]
[0, 1, 2]
[[-1, -1, -1], [-1, 0, 0], [-1, 91, 0]]
[[-1, -1, -1], [-1, -1, 0], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 2: 1, 1: 2}
New Contingency Matrix: 
[[103   0   0]
 [100   0   0]
 [  6   0  91]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [103, 0, 91], Sum: 194
All_Elements: [103, 0, 0, 100, 0, 0, 6, 0, 91], Sum: 300
Accuracy: 0.6466666666666666
