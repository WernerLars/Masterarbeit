Experiment_path: AE_Model_2/Epochs//V5/Experiment_05
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise030.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise030.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning
Visualisation_Path: AE_Model_2/Epochs//V5/Experiment_05/C_Easy1_noise030.mat/Variant_05_Online_Autoencoder_QLearning/2023_04_25-15_48_21
Punishment_Coefficient: 1.4
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001B8D9B3FB70>
Sampling rate: 24000.0
Raw: [0.08699461 0.08768749 0.09047398 ... 0.00793535 0.04192906 0.07540523]
Times: [    109     286     672 ... 1438732 1439041 1439176]
Cluster: [3 2 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3475
First aligned Spike Frame: [ 0.24838055  0.3968745   0.4994273   0.56717131  0.62437383  0.6710342
  0.6751285   0.62114176  0.54776115  0.51498001  0.55727438  0.67535688
  0.8518956   1.0665341   1.2479893   1.28963743  1.15621047  0.92299039
  0.68934948  0.49064578  0.29688022  0.08718391 -0.09567419 -0.18884929
 -0.19110403 -0.16315565 -0.16207475 -0.19314602 -0.21851792 -0.21534689
 -0.19320808 -0.18259624 -0.20407859 -0.25441706 -0.31051347 -0.35274265
 -0.36843999 -0.35552317 -0.31821193 -0.2558418  -0.17609511 -0.11324907
 -0.10743416 -0.17666352 -0.28550824 -0.38347104 -0.44318272]
Cluster 0, Occurrences: 1162
Cluster 1, Occurrences: 1164
Cluster 2, Occurrences: 1149
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.28705790638923645
Online_Training [2/700]: mean_loss=0.23429281413555145
Online_Training [3/700]: mean_loss=0.4310628652572632
Online_Training [4/700]: mean_loss=0.15026846677064895
Online_Training [5/700]: mean_loss=0.258857387304306
Online_Training [6/700]: mean_loss=0.08188102841377258
Online_Training [7/700]: mean_loss=0.21522069871425628
Online_Training [8/700]: mean_loss=0.4264796018600464
Online_Training [9/700]: mean_loss=0.46843132078647615
Online_Training [10/700]: mean_loss=0.29297262728214263
Online_Training [11/700]: mean_loss=0.28322927057743075
Online_Training [12/700]: mean_loss=0.1408783733844757
Online_Training [13/700]: mean_loss=0.08539737537503242
Online_Training [14/700]: mean_loss=0.10338188111782073
Online_Training [15/700]: mean_loss=0.42784484326839445
Online_Training [16/700]: mean_loss=0.6608021855354309
Online_Training [17/700]: mean_loss=0.11653931066393852
Online_Training [18/700]: mean_loss=0.20271925181150435
Online_Training [19/700]: mean_loss=0.23014650046825408
Online_Training [20/700]: mean_loss=0.1651903435587883
Online_Training [21/700]: mean_loss=0.1431584522128105
Online_Training [22/700]: mean_loss=0.16522215604782103
Online_Training [23/700]: mean_loss=0.13056000769138337
Online_Training [24/700]: mean_loss=0.4766215145587921
Online_Training [25/700]: mean_loss=0.040755543112754825
Online_Training [26/700]: mean_loss=0.17167846113443375
Online_Training [27/700]: mean_loss=0.15462722033262252
Online_Training [28/700]: mean_loss=0.19699510484933852
Online_Training [29/700]: mean_loss=0.2049272671341896
Online_Training [30/700]: mean_loss=0.09236317574977874
Online_Training [31/700]: mean_loss=0.2321217969059944
Online_Training [32/700]: mean_loss=0.14851194024085998
Online_Training [33/700]: mean_loss=0.17329802364110947
Online_Training [34/700]: mean_loss=0.4726553350687027
Online_Training [35/700]: mean_loss=0.08679161593317986
Online_Training [36/700]: mean_loss=0.5213029593229294
Online_Training [37/700]: mean_loss=0.15590245351195336
Online_Training [38/700]: mean_loss=0.11566685512661934
Online_Training [39/700]: mean_loss=0.09029745683073997
Online_Training [40/700]: mean_loss=0.11213870272040367
Online_Training [41/700]: mean_loss=0.16751200705766678
Online_Training [42/700]: mean_loss=0.09340783283114433
Online_Training [43/700]: mean_loss=0.13566914573311806
Online_Training [44/700]: mean_loss=0.08739412054419518
Online_Training [45/700]: mean_loss=0.07514116391539574
Online_Training [46/700]: mean_loss=0.10927115976810456
Online_Training [47/700]: mean_loss=0.17829367518424988
Online_Training [48/700]: mean_loss=0.10220412164926529
Online_Training [49/700]: mean_loss=0.0836325854063034
Online_Training [50/700]: mean_loss=0.12405351921916008
Online_Training [51/700]: mean_loss=0.27924312353134156
Online_Training [52/700]: mean_loss=0.11117267981171608
Online_Training [53/700]: mean_loss=0.10677081868052482
Online_Training [54/700]: mean_loss=0.05752448253333568
Online_Training [55/700]: mean_loss=0.03127853199839592
Online_Training [56/700]: mean_loss=0.09421180412173272
Online_Training [57/700]: mean_loss=0.10681564435362816
Online_Training [58/700]: mean_loss=0.14340721666812897
Online_Training [59/700]: mean_loss=0.18484744280576706
Online_Training [60/700]: mean_loss=0.08638592138886451
Online_Training [61/700]: mean_loss=0.08999848887324333
Online_Training [62/700]: mean_loss=0.1245715081691742
Online_Training [63/700]: mean_loss=0.07427931018173695
Online_Training [64/700]: mean_loss=0.10341188386082649
Online_Training [65/700]: mean_loss=0.08746499568223953
Online_Training [66/700]: mean_loss=0.21175429373979568
Online_Training [67/700]: mean_loss=0.06817220374941826
Online_Training [68/700]: mean_loss=0.03539837338030338
Online_Training [69/700]: mean_loss=0.07944546788930892
Online_Training [70/700]: mean_loss=0.13000918179750443
Online_Training [71/700]: mean_loss=0.03295964170247316
Online_Training [72/700]: mean_loss=0.17451851218938827
Online_Training [73/700]: mean_loss=0.019133369065821172
Online_Training [74/700]: mean_loss=0.03714594654738903
Online_Training [75/700]: mean_loss=0.017163181211799383
Online_Training [76/700]: mean_loss=0.12878075018525123
Online_Training [77/700]: mean_loss=0.2575551465153694
Online_Training [78/700]: mean_loss=0.09699322283267975
Online_Training [79/700]: mean_loss=0.0422926502302289
Online_Training [80/700]: mean_loss=0.08783797174692154
Online_Training [81/700]: mean_loss=0.08812721967697143
Online_Training [82/700]: mean_loss=0.2452595427632332
Online_Training [83/700]: mean_loss=0.12532646358013153
Online_Training [84/700]: mean_loss=0.05999679937958717
Online_Training [85/700]: mean_loss=0.03166054580360651
Online_Training [86/700]: mean_loss=0.10969609022140503
Online_Training [87/700]: mean_loss=0.02409503199160099
Online_Training [88/700]: mean_loss=0.10860183760523796
Online_Training [89/700]: mean_loss=0.10246794074773788
Online_Training [90/700]: mean_loss=0.03542795516550541
Online_Training [91/700]: mean_loss=0.14518764466047288
Online_Training [92/700]: mean_loss=0.09257345795631408
Online_Training [93/700]: mean_loss=0.06464568823575974
Online_Training [94/700]: mean_loss=0.059874605387449265
Online_Training [95/700]: mean_loss=0.11274615749716758
Online_Training [96/700]: mean_loss=0.04803636223077774
Online_Training [97/700]: mean_loss=0.010225625988096
Online_Training [98/700]: mean_loss=0.03334914688020944
Online_Training [99/700]: mean_loss=0.10779822766780853
Online_Training [100/700]: mean_loss=0.24856334626674653
Online_Training [101/700]: mean_loss=0.07291218787431716
Online_Training [102/700]: mean_loss=0.05712820366024971
Online_Training [103/700]: mean_loss=0.07050235345959663
Online_Training [104/700]: mean_loss=0.04843847416341305
Online_Training [105/700]: mean_loss=0.012686435971409083
Online_Training [106/700]: mean_loss=0.03995827697217465
Online_Training [107/700]: mean_loss=0.09356340318918228
Online_Training [108/700]: mean_loss=0.09948931857943535
Online_Training [109/700]: mean_loss=0.05541982315480709
Online_Training [110/700]: mean_loss=0.08372295573353768
Online_Training [111/700]: mean_loss=0.10047023147344589
Online_Training [112/700]: mean_loss=0.06387651264667511
Online_Training [113/700]: mean_loss=0.023015179485082627
Online_Training [114/700]: mean_loss=0.11895512789487839
Online_Training [115/700]: mean_loss=0.08807937130331993
Online_Training [116/700]: mean_loss=0.05885145850479603
Online_Training [117/700]: mean_loss=0.05964108034968376
Online_Training [118/700]: mean_loss=0.18036764711141587
Online_Training [119/700]: mean_loss=0.07856015115976334
Online_Training [120/700]: mean_loss=0.1066332146525383
Online_Training [121/700]: mean_loss=0.0631931871175766
Online_Training [122/700]: mean_loss=0.07786019258201123
Online_Training [123/700]: mean_loss=0.176313117146492
Online_Training [124/700]: mean_loss=0.1008409582078457
Online_Training [125/700]: mean_loss=0.060876605287194255
Online_Training [126/700]: mean_loss=0.05741135105490684
Online_Training [127/700]: mean_loss=0.08869916349649429
Online_Training [128/700]: mean_loss=0.08538642898201942
Online_Training [129/700]: mean_loss=0.031189608573913574
Online_Training [130/700]: mean_loss=0.05271840170025825
Online_Training [131/700]: mean_loss=0.16147485822439195
Online_Training [132/700]: mean_loss=0.04847554191946983
Online_Training [133/700]: mean_loss=0.03646416813135147
Online_Training [134/700]: mean_loss=0.04914363510906696
Online_Training [135/700]: mean_loss=0.016688454151153564
Online_Training [136/700]: mean_loss=0.04499635323882103
Online_Training [137/700]: mean_loss=0.14752712100744247
Online_Training [138/700]: mean_loss=0.058733544498682025
Online_Training [139/700]: mean_loss=0.03284578565508127
Online_Training [140/700]: mean_loss=0.05345554240047932
Online_Training [141/700]: mean_loss=0.12664584517478944
Online_Training [142/700]: mean_loss=0.037098197638988493
Online_Training [143/700]: mean_loss=0.12254300564527512
Online_Training [144/700]: mean_loss=0.0498883530497551
Online_Training [145/700]: mean_loss=0.04271148219704628
Online_Training [146/700]: mean_loss=0.03797015473246575
Online_Training [147/700]: mean_loss=0.2620524227619171
Online_Training [148/700]: mean_loss=0.04476087391376495
Online_Training [149/700]: mean_loss=0.05168439485132694
Online_Training [150/700]: mean_loss=0.02462731208652258
Online_Training [151/700]: mean_loss=0.060422340780496596
Online_Training [152/700]: mean_loss=0.08533433005213738
Online_Training [153/700]: mean_loss=0.046665767952799794
Online_Training [154/700]: mean_loss=0.09097447618842125
Online_Training [155/700]: mean_loss=0.043129916116595265
Online_Training [156/700]: mean_loss=0.05792535543441772
Online_Training [157/700]: mean_loss=0.037225603312253955
Online_Training [158/700]: mean_loss=0.04845998212695122
Online_Training [159/700]: mean_loss=0.04559186212718487
Online_Training [160/700]: mean_loss=0.1176605187356472
Online_Training [161/700]: mean_loss=0.11734609380364418
Online_Training [162/700]: mean_loss=0.10445455759763718
Online_Training [163/700]: mean_loss=0.04189389944076538
Online_Training [164/700]: mean_loss=0.1421840876340866
Online_Training [165/700]: mean_loss=0.012336295377463103
Online_Training [166/700]: mean_loss=0.083747149258852
Online_Training [167/700]: mean_loss=0.031196317449212075
Online_Training [168/700]: mean_loss=0.07194152027368546
Online_Training [169/700]: mean_loss=0.08137505650520324
Online_Training [170/700]: mean_loss=0.04566665552556515
Online_Training [171/700]: mean_loss=0.03533114697784186
Online_Training [172/700]: mean_loss=0.052070395275950435
Online_Training [173/700]: mean_loss=0.1160135693848133
Online_Training [174/700]: mean_loss=0.05343723371624946
Online_Training [175/700]: mean_loss=0.029212974570691587
Online_Training [176/700]: mean_loss=0.18615984469652175
Online_Training [177/700]: mean_loss=0.28221818059682846
Online_Training [178/700]: mean_loss=0.19458647668361664
Online_Training [179/700]: mean_loss=0.05635502710938454
Online_Training [180/700]: mean_loss=0.10087664574384689
Online_Training [181/700]: mean_loss=0.030836029537022115
Online_Training [182/700]: mean_loss=0.031742893159389496
Online_Training [183/700]: mean_loss=0.16290070563554765
Online_Training [184/700]: mean_loss=0.1193511076271534
Online_Training [185/700]: mean_loss=0.16245786100625992
Online_Training [186/700]: mean_loss=0.03273564931005239
Online_Training [187/700]: mean_loss=0.046906839683651926
Online_Training [188/700]: mean_loss=0.05026575848460198
Online_Training [189/700]: mean_loss=0.036938658356666564
Online_Training [190/700]: mean_loss=0.021852175891399383
Online_Training [191/700]: mean_loss=0.1790362536907196
Online_Training [192/700]: mean_loss=0.1226228006184101
Online_Training [193/700]: mean_loss=0.03537029549479485
Online_Training [194/700]: mean_loss=0.2573941215872765
Online_Training [195/700]: mean_loss=0.0738940455019474
Online_Training [196/700]: mean_loss=0.0497774388641119
Online_Training [197/700]: mean_loss=0.026845987886190414
Online_Training [198/700]: mean_loss=0.03644447065889835
Online_Training [199/700]: mean_loss=0.059556054323911665
Online_Training [200/700]: mean_loss=0.1894555866718292
Online_Training [201/700]: mean_loss=0.09206049740314484
Online_Training [202/700]: mean_loss=0.034799225814640525
Online_Training [203/700]: mean_loss=0.0551430843770504
Online_Training [204/700]: mean_loss=0.05261827893555164
Online_Training [205/700]: mean_loss=0.04301556274294853
Online_Training [206/700]: mean_loss=0.07485110312700272
Online_Training [207/700]: mean_loss=0.300501161813736
Online_Training [208/700]: mean_loss=0.12682522162795068
Online_Training [209/700]: mean_loss=0.03753936272114515
Online_Training [210/700]: mean_loss=0.032789711467921735
Online_Training [211/700]: mean_loss=0.05795769281685352
Online_Training [212/700]: mean_loss=0.04004511497914791
Online_Training [213/700]: mean_loss=0.09325771555304527
Online_Training [214/700]: mean_loss=0.3812623232603073
Online_Training [215/700]: mean_loss=0.8188330411911011
Online_Training [216/700]: mean_loss=0.10356885716319084
Online_Training [217/700]: mean_loss=0.10401779636740685
Online_Training [218/700]: mean_loss=0.08942952305078507
Online_Training [219/700]: mean_loss=0.04100620336830616
Online_Training [220/700]: mean_loss=0.051487136632204056
Online_Training [221/700]: mean_loss=0.1078782968223095
Online_Training [222/700]: mean_loss=0.21173031330108644
Online_Training [223/700]: mean_loss=0.05829248800873756
Online_Training [224/700]: mean_loss=0.07149548083543777
Online_Training [225/700]: mean_loss=0.045378347113728526
Online_Training [226/700]: mean_loss=0.1743738315999508
Online_Training [227/700]: mean_loss=0.06193506233394146
Online_Training [228/700]: mean_loss=0.0703377053141594
Online_Training [229/700]: mean_loss=0.06859092563390731
Online_Training [230/700]: mean_loss=0.04457194693386555
Online_Training [231/700]: mean_loss=0.060658881813287734
Online_Training [232/700]: mean_loss=0.049123425781726834
Online_Training [233/700]: mean_loss=0.036020517162978646
Online_Training [234/700]: mean_loss=0.10631861910223961
Online_Training [235/700]: mean_loss=0.043747027218341825
Online_Training [236/700]: mean_loss=0.10289189219474792
Online_Training [237/700]: mean_loss=0.07616182565689086
Online_Training [238/700]: mean_loss=0.021856762655079364
Online_Training [239/700]: mean_loss=0.05860121101140976
Online_Training [240/700]: mean_loss=0.06410612910985947
Online_Training [241/700]: mean_loss=0.03656022399663925
Online_Training [242/700]: mean_loss=0.07393323555588723
Online_Training [243/700]: mean_loss=0.12614039108157157
Online_Training [244/700]: mean_loss=0.04451058097183704
Online_Training [245/700]: mean_loss=0.03478415478020906
Online_Training [246/700]: mean_loss=0.079678463190794
Online_Training [247/700]: mean_loss=0.10093822702765465
Online_Training [248/700]: mean_loss=0.22673070132732392
Online_Training [249/700]: mean_loss=0.10776095986366271
Online_Training [250/700]: mean_loss=0.05712195560336113
Online_Training [251/700]: mean_loss=0.123479825258255
Online_Training [252/700]: mean_loss=0.06910974830389023
Online_Training [253/700]: mean_loss=0.02770509887486696
Online_Training [254/700]: mean_loss=0.15699026733636856
Online_Training [255/700]: mean_loss=0.11073360741138458
Online_Training [256/700]: mean_loss=0.08292911127209664
Online_Training [257/700]: mean_loss=0.17158723324537278
Online_Training [258/700]: mean_loss=0.027460511587560178
Online_Training [259/700]: mean_loss=0.031489724107086656
Online_Training [260/700]: mean_loss=0.0552719559520483
Online_Training [261/700]: mean_loss=0.03348103798925876
Online_Training [262/700]: mean_loss=0.1018970899283886
Online_Training [263/700]: mean_loss=0.03540905714035034
Online_Training [264/700]: mean_loss=0.10467120930552483
Online_Training [265/700]: mean_loss=0.039701126515865326
Online_Training [266/700]: mean_loss=0.042267865315079686
Online_Training [267/700]: mean_loss=0.019729405455291272
Online_Training [268/700]: mean_loss=0.07800914347171783
Online_Training [269/700]: mean_loss=0.042102069780230525
Online_Training [270/700]: mean_loss=0.045736484602093695
Online_Training [271/700]: mean_loss=0.026636766828596593
Online_Training [272/700]: mean_loss=0.24321686774492263
Online_Training [273/700]: mean_loss=0.07051834017038346
Online_Training [274/700]: mean_loss=0.03560610506683588
Online_Training [275/700]: mean_loss=0.12246556952595711
Online_Training [276/700]: mean_loss=0.15516892969608306
Online_Training [277/700]: mean_loss=0.10431071519851684
Online_Training [278/700]: mean_loss=0.22367385774850845
Online_Training [279/700]: mean_loss=0.06296636015176774
Online_Training [280/700]: mean_loss=0.0713334009051323
Online_Training [281/700]: mean_loss=0.03344770520925522
Online_Training [282/700]: mean_loss=0.14931403547525407
Online_Training [283/700]: mean_loss=0.03411407470703125
Online_Training [284/700]: mean_loss=0.05366107188165188
Online_Training [285/700]: mean_loss=0.0641901757568121
Online_Training [286/700]: mean_loss=0.04749153032898903
Online_Training [287/700]: mean_loss=0.07584479600191116
Online_Training [288/700]: mean_loss=0.034531790390610696
Online_Training [289/700]: mean_loss=0.08773375228047371
Online_Training [290/700]: mean_loss=0.08946769386529922
Online_Training [291/700]: mean_loss=0.039330709353089334
Online_Training [292/700]: mean_loss=0.028509153798222543
Online_Training [293/700]: mean_loss=0.12611715123057365
Online_Training [294/700]: mean_loss=0.060585209727287294
Online_Training [295/700]: mean_loss=0.02327011004090309
Online_Training [296/700]: mean_loss=0.07104689292609692
Online_Training [297/700]: mean_loss=0.29294023513793943
Online_Training [298/700]: mean_loss=0.13124167844653128
Online_Training [299/700]: mean_loss=0.09653054475784302
Online_Training [300/700]: mean_loss=0.043707411363720895
Online_Training [301/700]: mean_loss=0.20700282752513885
Online_Training [302/700]: mean_loss=0.26792651116847993
Online_Training [303/700]: mean_loss=0.07751534804701805
Online_Training [304/700]: mean_loss=0.17224484086036682
Online_Training [305/700]: mean_loss=0.1960533156991005
Online_Training [306/700]: mean_loss=0.26315515786409377
Online_Training [307/700]: mean_loss=0.13119025081396102
Online_Training [308/700]: mean_loss=0.13331775665283202
Online_Training [309/700]: mean_loss=0.12117042392492294
Online_Training [310/700]: mean_loss=0.20513934940099715
Online_Training [311/700]: mean_loss=0.03717347458004951
Online_Training [312/700]: mean_loss=0.014320135395973922
Online_Training [313/700]: mean_loss=0.08732507973909379
Online_Training [314/700]: mean_loss=0.22460003942251205
Online_Training [315/700]: mean_loss=0.4944242060184479
Online_Training [316/700]: mean_loss=0.06294496171176434
Online_Training [317/700]: mean_loss=0.07912464588880538
Online_Training [318/700]: mean_loss=0.03314879592508078
Online_Training [319/700]: mean_loss=0.07742308378219605
Online_Training [320/700]: mean_loss=0.06528955064713955
Online_Training [321/700]: mean_loss=0.2682617217302322
Online_Training [322/700]: mean_loss=0.18904806971549987
Online_Training [323/700]: mean_loss=0.05843546688556671
Online_Training [324/700]: mean_loss=0.054990268871188165
Online_Training [325/700]: mean_loss=0.11564371958374978
Online_Training [326/700]: mean_loss=0.1157008096575737
Online_Training [327/700]: mean_loss=0.06805409416556359
Online_Training [328/700]: mean_loss=0.044462548568844795
Online_Training [329/700]: mean_loss=0.3390862464904785
Online_Training [330/700]: mean_loss=0.07894089445471764
Online_Training [331/700]: mean_loss=0.13983756452798843
Online_Training [332/700]: mean_loss=0.03331978265196085
Online_Training [333/700]: mean_loss=0.14504275619983673
Online_Training [334/700]: mean_loss=0.0790917344391346
Online_Training [335/700]: mean_loss=0.12370794489979745
Online_Training [336/700]: mean_loss=0.037505725398659706
Online_Training [337/700]: mean_loss=0.07777923345565796
Online_Training [338/700]: mean_loss=0.06307767741382123
Online_Training [339/700]: mean_loss=0.056849877908825876
Online_Training [340/700]: mean_loss=0.05357201173901558
Online_Training [341/700]: mean_loss=0.029141006618738176
Online_Training [342/700]: mean_loss=0.05503587126731872
Online_Training [343/700]: mean_loss=0.04477931931614876
Online_Training [344/700]: mean_loss=0.054663379490375516
Online_Training [345/700]: mean_loss=0.04245416149497032
Online_Training [346/700]: mean_loss=0.17377844005823134
Online_Training [347/700]: mean_loss=0.0545286625623703
Online_Training [348/700]: mean_loss=0.1424945265054703
Online_Training [349/700]: mean_loss=0.0737888641655445
Online_Training [350/700]: mean_loss=0.052503740042448045
Online_Training [351/700]: mean_loss=0.2110460415482521
Online_Training [352/700]: mean_loss=0.010114915017038584
Online_Training [353/700]: mean_loss=0.04009392969310284
Online_Training [354/700]: mean_loss=0.10461573526263238
Online_Training [355/700]: mean_loss=0.08902113810181618
Online_Training [356/700]: mean_loss=0.031795700639486314
Online_Training [357/700]: mean_loss=0.021854088827967643
Online_Training [358/700]: mean_loss=0.06853313818573951
Online_Training [359/700]: mean_loss=0.1185084454715252
Online_Training [360/700]: mean_loss=0.08409500792622567
Online_Training [361/700]: mean_loss=0.038884108886122704
Online_Training [362/700]: mean_loss=0.021383001655340194
Online_Training [363/700]: mean_loss=0.042857710272073746
Online_Training [364/700]: mean_loss=0.12504150345921516
Online_Training [365/700]: mean_loss=0.052703969180583954
Online_Training [366/700]: mean_loss=0.08821430578827857
Online_Training [367/700]: mean_loss=0.03322985842823982
Online_Training [368/700]: mean_loss=0.08453739657998086
Online_Training [369/700]: mean_loss=0.039541518315672874
Online_Training [370/700]: mean_loss=0.04302590861916542
Online_Training [371/700]: mean_loss=0.22654679417610168
Online_Training [372/700]: mean_loss=0.09290686994791031
Online_Training [373/700]: mean_loss=0.030155513994395734
Online_Training [374/700]: mean_loss=0.28686816394329073
Online_Training [375/700]: mean_loss=0.04720164425671101
Online_Training [376/700]: mean_loss=0.06796426884829998
Online_Training [377/700]: mean_loss=0.061302787810564044
Online_Training [378/700]: mean_loss=0.015404626540839673
Online_Training [379/700]: mean_loss=0.19287720024585725
Online_Training [380/700]: mean_loss=0.10044307485222817
Online_Training [381/700]: mean_loss=0.16833660155534744
Online_Training [382/700]: mean_loss=0.05161056891083717
Online_Training [383/700]: mean_loss=0.08334285169839858
Online_Training [384/700]: mean_loss=0.11195505633950234
Online_Training [385/700]: mean_loss=0.1329390175640583
Online_Training [386/700]: mean_loss=0.043827960267663
Online_Training [387/700]: mean_loss=0.05597442500293255
Online_Training [388/700]: mean_loss=0.056502405926585196
Online_Training [389/700]: mean_loss=0.05564861670136452
Online_Training [390/700]: mean_loss=0.03818008229136467
Online_Training [391/700]: mean_loss=0.05029391124844551
Online_Training [392/700]: mean_loss=0.07477586008608342
Online_Training [393/700]: mean_loss=0.11797191798686982
Online_Training [394/700]: mean_loss=0.0548189714550972
Online_Training [395/700]: mean_loss=0.09670277312397957
Online_Training [396/700]: mean_loss=0.09438033401966095
Online_Training [397/700]: mean_loss=0.07428059950470925
Online_Training [398/700]: mean_loss=0.11545153260231018
Online_Training [399/700]: mean_loss=0.08385981246829033
Online_Training [400/700]: mean_loss=0.04305254742503166
Online_Training [401/700]: mean_loss=0.10641147494316101
Online_Training [402/700]: mean_loss=0.07118400186300278
Online_Training [403/700]: mean_loss=0.05064674839377403
Online_Training [404/700]: mean_loss=0.07651537880301476
Online_Training [405/700]: mean_loss=0.25361073613166807
Online_Training [406/700]: mean_loss=0.09030110239982606
Online_Training [407/700]: mean_loss=0.08980986103415489
Online_Training [408/700]: mean_loss=0.14389650225639344
Online_Training [409/700]: mean_loss=0.02725297901779413
Online_Training [410/700]: mean_loss=0.0843513198196888
Online_Training [411/700]: mean_loss=0.09516513869166374
Online_Training [412/700]: mean_loss=0.12474509477615356
Online_Training [413/700]: mean_loss=0.10723099559545517
Online_Training [414/700]: mean_loss=0.05969580747187138
Online_Training [415/700]: mean_loss=0.07824266999959946
Online_Training [416/700]: mean_loss=0.17355760037899018
Online_Training [417/700]: mean_loss=0.12819794416427613
Online_Training [418/700]: mean_loss=0.14888863563537597
Online_Training [419/700]: mean_loss=0.09470811188220978
Online_Training [420/700]: mean_loss=0.023332615196704865
Online_Training [421/700]: mean_loss=0.035394894517958166
Online_Training [422/700]: mean_loss=0.21124470680952073
Online_Training [423/700]: mean_loss=0.20798633843660355
Online_Training [424/700]: mean_loss=0.1263839177787304
Online_Training [425/700]: mean_loss=0.173261858522892
Online_Training [426/700]: mean_loss=0.2354804739356041
Online_Training [427/700]: mean_loss=0.035050684586167336
Online_Training [428/700]: mean_loss=0.03792666494846344
Online_Training [429/700]: mean_loss=0.050155118107795715
Online_Training [430/700]: mean_loss=0.08516291156411171
Online_Training [431/700]: mean_loss=0.023341834917664527
Online_Training [432/700]: mean_loss=0.03733538947999478
Online_Training [433/700]: mean_loss=0.08708103075623512
Online_Training [434/700]: mean_loss=0.05570404902100563
Online_Training [435/700]: mean_loss=0.15682997256517411
Online_Training [436/700]: mean_loss=0.20261160880327225
Online_Training [437/700]: mean_loss=0.06492392681539058
Online_Training [438/700]: mean_loss=0.07624665126204491
Online_Training [439/700]: mean_loss=0.10196907967329025
Online_Training [440/700]: mean_loss=0.28605264127254487
Online_Training [441/700]: mean_loss=0.07070792466402054
Online_Training [442/700]: mean_loss=0.04620090313255787
Online_Training [443/700]: mean_loss=0.06957432031631469
Online_Training [444/700]: mean_loss=0.03622817490249872
Online_Training [445/700]: mean_loss=0.02161973174661398
Online_Training [446/700]: mean_loss=0.07901902124285698
Online_Training [447/700]: mean_loss=0.13900584131479263
Online_Training [448/700]: mean_loss=0.03533274829387665
Online_Training [449/700]: mean_loss=0.0248004462569952
Online_Training [450/700]: mean_loss=0.048918575420975684
Online_Training [451/700]: mean_loss=0.08866510987281799
Online_Training [452/700]: mean_loss=0.1408828854560852
Online_Training [453/700]: mean_loss=0.06626119799911975
Online_Training [454/700]: mean_loss=0.05557243786752224
Online_Training [455/700]: mean_loss=0.06812376938760281
Online_Training [456/700]: mean_loss=0.0448773767799139
Online_Training [457/700]: mean_loss=0.07878558784723282
Online_Training [458/700]: mean_loss=0.018717289529740812
Online_Training [459/700]: mean_loss=0.10865878760814666
Online_Training [460/700]: mean_loss=0.07971058562397956
Online_Training [461/700]: mean_loss=0.24571426957845688
Online_Training [462/700]: mean_loss=0.02239038925617933
Online_Training [463/700]: mean_loss=0.05342422910034657
Online_Training [464/700]: mean_loss=0.23279390335083008
Online_Training [465/700]: mean_loss=0.04541932791471481
Online_Training [466/700]: mean_loss=0.052279474958777425
Online_Training [467/700]: mean_loss=0.0493515208363533
Online_Training [468/700]: mean_loss=0.058055320754647255
Online_Training [469/700]: mean_loss=0.05033550746738911
Online_Training [470/700]: mean_loss=0.026761547662317753
Online_Training [471/700]: mean_loss=0.09533571377396584
Online_Training [472/700]: mean_loss=0.0479271974414587
Online_Training [473/700]: mean_loss=0.13776324987411498
Online_Training [474/700]: mean_loss=0.1896197408437729
Online_Training [475/700]: mean_loss=0.03859800845384598
Online_Training [476/700]: mean_loss=0.04546557925641537
Online_Training [477/700]: mean_loss=0.031588931940495966
Online_Training [478/700]: mean_loss=0.08930025771260261
Online_Training [479/700]: mean_loss=0.2523964375257492
Online_Training [480/700]: mean_loss=0.034743616729974745
Online_Training [481/700]: mean_loss=0.0685386810451746
Online_Training [482/700]: mean_loss=0.025592480413615705
Online_Training [483/700]: mean_loss=0.06122785769402981
Online_Training [484/700]: mean_loss=0.058074630051851275
Online_Training [485/700]: mean_loss=0.12218576595187187
Online_Training [486/700]: mean_loss=0.08600622266530991
Online_Training [487/700]: mean_loss=0.02025436293333769
Online_Training [488/700]: mean_loss=0.16994415819644929
Online_Training [489/700]: mean_loss=0.18713976740837096
Online_Training [490/700]: mean_loss=0.05710660666227341
Online_Training [491/700]: mean_loss=0.05339184999465942
Online_Training [492/700]: mean_loss=0.07753870710730552
Online_Training [493/700]: mean_loss=0.0387001559138298
Online_Training [494/700]: mean_loss=0.023995873145759107
Online_Training [495/700]: mean_loss=0.0773088924586773
Online_Training [496/700]: mean_loss=0.0853909581899643
Online_Training [497/700]: mean_loss=0.12714042365550995
Online_Training [498/700]: mean_loss=0.03658286333084106
Online_Training [499/700]: mean_loss=0.06692286729812622
Online_Training [500/700]: mean_loss=0.1352677047252655
Online_Training [501/700]: mean_loss=0.04007655084133148
Online_Training [502/700]: mean_loss=0.07063825726509095
Online_Training [503/700]: mean_loss=0.0636594545096159
Online_Training [504/700]: mean_loss=0.07793262153863907
Online_Training [505/700]: mean_loss=0.034961409866809845
Online_Training [506/700]: mean_loss=0.06295860782265664
Online_Training [507/700]: mean_loss=0.08776027709245682
Online_Training [508/700]: mean_loss=0.19324386417865752
Online_Training [509/700]: mean_loss=0.034623493626713756
Online_Training [510/700]: mean_loss=0.04453710801899433
Online_Training [511/700]: mean_loss=0.0646508801728487
Online_Training [512/700]: mean_loss=0.05787704698741436
Online_Training [513/700]: mean_loss=0.03385848663747311
Online_Training [514/700]: mean_loss=0.09960658475756645
Online_Training [515/700]: mean_loss=0.07949803695082665
Online_Training [516/700]: mean_loss=0.05827102027833462
Online_Training [517/700]: mean_loss=0.0311329560354352
Online_Training [518/700]: mean_loss=0.31434581279754636
Online_Training [519/700]: mean_loss=0.2460273250937462
Online_Training [520/700]: mean_loss=0.04748764894902706
Online_Training [521/700]: mean_loss=0.050376979261636735
Online_Training [522/700]: mean_loss=0.04679027199745178
Online_Training [523/700]: mean_loss=0.09170682206749917
Online_Training [524/700]: mean_loss=0.03249198812991381
Online_Training [525/700]: mean_loss=0.04918505810201168
Online_Training [526/700]: mean_loss=0.04343632720410824
Online_Training [527/700]: mean_loss=0.029520410113036633
Online_Training [528/700]: mean_loss=0.057246534153819084
Online_Training [529/700]: mean_loss=0.11655640751123428
Online_Training [530/700]: mean_loss=0.20754640996456147
Online_Training [531/700]: mean_loss=0.09175542294979096
Online_Training [532/700]: mean_loss=0.17724550217390062
Online_Training [533/700]: mean_loss=0.05583486407995224
Online_Training [534/700]: mean_loss=0.04076785370707512
Online_Training [535/700]: mean_loss=0.14265901297330857
Online_Training [536/700]: mean_loss=0.09704997763037682
Online_Training [537/700]: mean_loss=0.05332847312092781
Online_Training [538/700]: mean_loss=0.2290456026792526
Online_Training [539/700]: mean_loss=0.055270991101861
Online_Training [540/700]: mean_loss=0.025603397749364376
Online_Training [541/700]: mean_loss=0.0365505401045084
Online_Training [542/700]: mean_loss=0.2030128911137581
Online_Training [543/700]: mean_loss=0.06415067687630653
Online_Training [544/700]: mean_loss=0.05872619934380054
Online_Training [545/700]: mean_loss=0.06873755380511284
Online_Training [546/700]: mean_loss=0.033147731237113474
Online_Training [547/700]: mean_loss=0.02787899039685726
Online_Training [548/700]: mean_loss=0.1291374869644642
Online_Training [549/700]: mean_loss=0.02719064336270094
Online_Training [550/700]: mean_loss=0.1040963388979435
Online_Training [551/700]: mean_loss=0.09542134404182434
Online_Training [552/700]: mean_loss=0.06345917023718357
Online_Training [553/700]: mean_loss=0.02538625057786703
Online_Training [554/700]: mean_loss=0.10041820332407951
Online_Training [555/700]: mean_loss=0.11864554435014725
Online_Training [556/700]: mean_loss=0.03605773076415062
Online_Training [557/700]: mean_loss=0.044047793745994566
Online_Training [558/700]: mean_loss=0.03529959172010422
Online_Training [559/700]: mean_loss=0.015714038629084826
Online_Training [560/700]: mean_loss=0.08248383402824402
Online_Training [561/700]: mean_loss=0.12015745490789413
Online_Training [562/700]: mean_loss=0.10688248425722122
Online_Training [563/700]: mean_loss=0.021435924619436265
Online_Training [564/700]: mean_loss=0.01663080919533968
Online_Training [565/700]: mean_loss=0.11895573660731315
Online_Training [566/700]: mean_loss=0.3919999301433563
Online_Training [567/700]: mean_loss=0.09555265605449677
Online_Training [568/700]: mean_loss=0.04272955395281315
Online_Training [569/700]: mean_loss=0.054369742050766945
Online_Training [570/700]: mean_loss=0.09678007438778877
Online_Training [571/700]: mean_loss=0.02108535300940275
Online_Training [572/700]: mean_loss=0.04802862294018269
Online_Training [573/700]: mean_loss=0.0364331666380167
Online_Training [574/700]: mean_loss=0.05381837673485279
Online_Training [575/700]: mean_loss=0.08495368212461471
Online_Training [576/700]: mean_loss=0.05453781224787235
Online_Training [577/700]: mean_loss=0.03266193084418774
Online_Training [578/700]: mean_loss=0.08450538143515587
Online_Training [579/700]: mean_loss=0.03073278348892927
Online_Training [580/700]: mean_loss=0.04155430942773819
Online_Training [581/700]: mean_loss=0.048653874173760416
Online_Training [582/700]: mean_loss=0.010722849052399397
Online_Training [583/700]: mean_loss=0.008251296170055867
Online_Training [584/700]: mean_loss=0.0551743421703577
Online_Training [585/700]: mean_loss=0.023378048837184907
Online_Training [586/700]: mean_loss=0.02626920659095049
Online_Training [587/700]: mean_loss=0.04366798214614391
Online_Training [588/700]: mean_loss=0.08525271043181419
Online_Training [589/700]: mean_loss=0.08165308982133865
Online_Training [590/700]: mean_loss=0.11244504824280739
Online_Training [591/700]: mean_loss=0.08230261728167534
Online_Training [592/700]: mean_loss=0.017940888553857802
Online_Training [593/700]: mean_loss=0.4074292629957199
Online_Training [594/700]: mean_loss=0.42134890556335447
Online_Training [595/700]: mean_loss=0.044422519952058794
Online_Training [596/700]: mean_loss=0.17956943362951278
Online_Training [597/700]: mean_loss=0.026504417695105077
Online_Training [598/700]: mean_loss=0.22362979948520662
Online_Training [599/700]: mean_loss=0.108266282081604
Online_Training [600/700]: mean_loss=0.09833230152726173
Online_Training [601/700]: mean_loss=0.02933304812759161
Online_Training [602/700]: mean_loss=0.1153037652373314
Online_Training [603/700]: mean_loss=0.025607792474329472
Online_Training [604/700]: mean_loss=0.0504966638982296
Online_Training [605/700]: mean_loss=0.13046121448278428
Online_Training [606/700]: mean_loss=0.07546375989913941
Online_Training [607/700]: mean_loss=0.061814078316092494
Online_Training [608/700]: mean_loss=0.28218148201704024
Online_Training [609/700]: mean_loss=0.026569107733666896
Online_Training [610/700]: mean_loss=0.16887827664613725
Online_Training [611/700]: mean_loss=0.03819792382419109
Online_Training [612/700]: mean_loss=0.014194109570235014
Online_Training [613/700]: mean_loss=0.09330144748091698
Online_Training [614/700]: mean_loss=0.024821037612855434
Online_Training [615/700]: mean_loss=0.1231783539056778
Online_Training [616/700]: mean_loss=0.04990449510514736
Online_Training [617/700]: mean_loss=0.06847535558044911
Online_Training [618/700]: mean_loss=0.04190147817134857
Online_Training [619/700]: mean_loss=0.0700680162757635
Online_Training [620/700]: mean_loss=0.032806144841015336
Online_Training [621/700]: mean_loss=0.07515703178942204
Online_Training [622/700]: mean_loss=0.12822623625397683
Online_Training [623/700]: mean_loss=0.013440378289669753
Online_Training [624/700]: mean_loss=0.08566751256585121
Online_Training [625/700]: mean_loss=0.09275395944714546
Online_Training [626/700]: mean_loss=0.1744976446032524
Online_Training [627/700]: mean_loss=0.02470021080225706
Online_Training [628/700]: mean_loss=0.04926868937909603
Online_Training [629/700]: mean_loss=0.07727999091148377
Online_Training [630/700]: mean_loss=0.04767074324190616
Online_Training [631/700]: mean_loss=0.03767646364867687
Online_Training [632/700]: mean_loss=0.05606302544474602
Online_Training [633/700]: mean_loss=0.08212648704648018
Online_Training [634/700]: mean_loss=0.05876148268580437
Online_Training [635/700]: mean_loss=0.05570586659014225
Online_Training [636/700]: mean_loss=0.06748536825180054
Online_Training [637/700]: mean_loss=0.09376649186015129
Online_Training [638/700]: mean_loss=0.14491163343191146
Online_Training [639/700]: mean_loss=0.11386701315641404
Online_Training [640/700]: mean_loss=0.0919108361005783
Online_Training [641/700]: mean_loss=0.05827879868447781
Online_Training [642/700]: mean_loss=0.06840005069971085
Online_Training [643/700]: mean_loss=0.04586522802710533
Online_Training [644/700]: mean_loss=0.06339676901698113
Online_Training [645/700]: mean_loss=0.11450630873441696
Online_Training [646/700]: mean_loss=0.0411154642701149
Online_Training [647/700]: mean_loss=0.018344400636851787
Online_Training [648/700]: mean_loss=0.10868241637945175
Online_Training [649/700]: mean_loss=0.046962884813547136
Online_Training [650/700]: mean_loss=0.025058602169156074
Online_Training [651/700]: mean_loss=0.04199775904417038
Online_Training [652/700]: mean_loss=0.06437865197658539
Online_Training [653/700]: mean_loss=0.019851147942245007
Online_Training [654/700]: mean_loss=0.09445891678333282
Online_Training [655/700]: mean_loss=0.0415848646312952
Online_Training [656/700]: mean_loss=0.05513610802590847
Online_Training [657/700]: mean_loss=0.17365287244319916
Online_Training [658/700]: mean_loss=0.0685275785624981
Online_Training [659/700]: mean_loss=0.03894516136497259
Online_Training [660/700]: mean_loss=0.09367823228240013
Online_Training [661/700]: mean_loss=0.09152796939015388
Online_Training [662/700]: mean_loss=0.3576187640428543
Online_Training [663/700]: mean_loss=0.2496634230017662
Online_Training [664/700]: mean_loss=0.18893626034259797
Online_Training [665/700]: mean_loss=0.08229751139879227
Online_Training [666/700]: mean_loss=0.0946047380566597
Online_Training [667/700]: mean_loss=0.10982254222035408
Online_Training [668/700]: mean_loss=0.20900358855724335
Online_Training [669/700]: mean_loss=0.04885418936610222
Online_Training [670/700]: mean_loss=0.038396310061216354
Online_Training [671/700]: mean_loss=0.05053447373211384
Online_Training [672/700]: mean_loss=0.09352248013019562
Online_Training [673/700]: mean_loss=0.06663247346878051
Online_Training [674/700]: mean_loss=0.09608213603496552
Online_Training [675/700]: mean_loss=0.054559675604105
Online_Training [676/700]: mean_loss=0.22271517813205718
Online_Training [677/700]: mean_loss=0.04007825404405594
Online_Training [678/700]: mean_loss=0.022169294022023677
Online_Training [679/700]: mean_loss=0.07765185832977295
Online_Training [680/700]: mean_loss=0.06968971341848373
Online_Training [681/700]: mean_loss=0.02227972708642483
Online_Training [682/700]: mean_loss=0.08678373694419861
Online_Training [683/700]: mean_loss=0.16075988113880157
Online_Training [684/700]: mean_loss=0.05373765081167221
Online_Training [685/700]: mean_loss=0.0550224419683218
Online_Training [686/700]: mean_loss=0.18344079256057738
Online_Training [687/700]: mean_loss=0.03827904053032398
Online_Training [688/700]: mean_loss=0.054446570202708246
Online_Training [689/700]: mean_loss=0.022133023478090763
Online_Training [690/700]: mean_loss=0.08468927443027496
Online_Training [691/700]: mean_loss=0.019841619394719602
Online_Training [692/700]: mean_loss=0.0862993061542511
Online_Training [693/700]: mean_loss=0.13835613578557968
Online_Training [694/700]: mean_loss=0.06253347955644131
Online_Training [695/700]: mean_loss=0.07546457722783088
Online_Training [696/700]: mean_loss=0.04592840373516083
Online_Training [697/700]: mean_loss=0.08405897840857506
Online_Training [698/700]: mean_loss=0.16353071480989456
Online_Training [699/700]: mean_loss=0.019215104542672633
Online_Training [700/700]: mean_loss=0.14160891473293305
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 1.3345913 -1.3136714]
[1, 1, 0, 2, 2, 1, 2, 0, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 1, 2, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 2, 0, 0, 0, 0, 2, 1, 2, 1, 2, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 1, 0, 2, 0, 0, 0, 2, 1, 1, 2, 2, 0, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 2, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 0, 0, 2, 2, 2, 1, 1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 1, 2, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 2, 2, 0, 0, 2, 1, 0, 0, 2, 1, 2, 0, 0, 2, 2, 2, 1, 0, 1, 1, 1, 0, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 1, 0, 1, 2, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 1, 2, 0, 2, 2, 0, 2, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 2, 0, 1, 2, 1, 2, 2, 1, 1, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 1, 0, 0, 2, 1, 0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 1, 0, 1, 2, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 1, 2, 0, 0]
[0, 0, 1, 2, 1, 0, 2, 1, 2, 0, 0, 1, 0, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 0, 2, 0, 2, 0, 2, 1, 1, 2, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 1, 1, 1, 1, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 1, 2, 1, 1, 1, 2, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 2, 2, 2, 3, 2, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 2, 4, 0, 2, 2, 1, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 0, 0, 3, 2, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 3, 1, 2, 0, 2, 1, 3, 0, 2, 2, 0, 1, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 1, 0, 2, 2, 2, 3, 1, 1, 3, 0, 0, 1, 0, 0, 3, 1, 3, 0, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 1, 2, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 4, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 0, 2, 2, 0, 5, 2, 2, 1, 0, 1, 2, 1, 5, 1, 2, 1, 0, 1, 2, 2, 2, 5, 2, 1, 2, 3, 1, 2, 2, 0, 0, 1, 1, 2, 0, 3, 0, 1, 0, 1, 1, 0, 2, 1, 0, 0, 3, 4, 5, 2, 1, 0, 1, 1, 1, 2, 0, 1, 1, 2, 1, 0, 2, 3, 1]
Centroids: [[-1.6857575, 0.4963146], [0.89763427, -1.2475101], [0.08817637, 2.8816745]]
Centroids: [[0.9512211, -1.2228633], [-1.4891472, 0.5855691], [-0.014255165, 3.0037868], [-2.7860525, -0.48192713], [-1.0721234, -3.1664612], [2.395849, 1.7463444]]
Contingency Matrix: 
[[ 1 92  4 12  0  0]
 [84  2  0  0  3  1]
 [ 1  5 92  0  0  3]]
[[1, 92, 4, 12, 0, 0], [84, 2, 0, 0, 3, 1], [1, 5, 92, 0, 0, 3]]
[[1, 92, 4, 12, 0, 0], [84, 2, 0, 0, 3, 1], [1, 5, 92, 0, 0, 3]]
[0, 1, 2, 3, 4, 5]
[[-1, -1, -1, -1, -1, -1], [84, -1, 0, 0, 3, 1], [1, -1, 92, 0, 0, 3]]
[[-1, -1, -1, -1, -1, -1], [84, -1, -1, 0, 3, 1], [-1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 1, 2: 2, 1: 0}
New Contingency Matrix: 
[[92  1  4 12  0  0]
 [ 2 84  0  0  3  1]
 [ 5  1 92  0  0  3]]
New Clustered Label Sequence: [1, 0, 2, 3, 4, 5]
Diagonal_Elements: [92, 84, 92], Sum: 268
All_Elements: [92, 1, 4, 12, 0, 0, 2, 84, 0, 0, 3, 1, 5, 1, 92, 0, 0, 3], Sum: 300
Accuracy: 0.8933333333333333
