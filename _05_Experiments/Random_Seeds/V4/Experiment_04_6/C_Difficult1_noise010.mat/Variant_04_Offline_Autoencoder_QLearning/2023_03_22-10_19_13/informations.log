Experiment_path: Random_Seeds//V4/Experiment_04_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_04_Offline_Autoencoder_QLearning
Visualisation_Path: Random_Seeds//V4/Experiment_04_6/C_Difficult1_noise010.mat/Variant_04_Offline_Autoencoder_QLearning/2023_03_22-10_19_13
Punishment_Coefficient: 0.32
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000233BAD47B00>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
Train Index: 3103
x_train: 3103
y_train: 3103
x_test: 345
y_test: 345
<torch.utils.data.dataloader.DataLoader object at 0x00000233C58D0438>
<torch.utils.data.dataloader.DataLoader object at 0x00000233C58D04A8>
Epoch 1
-------------------------------
loss: 0.177522  [    0/ 3103]
loss: 0.102406  [  100/ 3103]
loss: 0.037106  [  200/ 3103]
loss: 0.045194  [  300/ 3103]
loss: 0.021923  [  400/ 3103]
loss: 0.015375  [  500/ 3103]
loss: 0.023693  [  600/ 3103]
loss: 0.011297  [  700/ 3103]
loss: 0.015329  [  800/ 3103]
loss: 0.037695  [  900/ 3103]
loss: 0.090042  [ 1000/ 3103]
loss: 0.014938  [ 1100/ 3103]
loss: 0.017431  [ 1200/ 3103]
loss: 0.130453  [ 1300/ 3103]
loss: 0.013467  [ 1400/ 3103]
loss: 0.037516  [ 1500/ 3103]
loss: 0.029762  [ 1600/ 3103]
loss: 0.020533  [ 1700/ 3103]
loss: 0.017830  [ 1800/ 3103]
loss: 0.023313  [ 1900/ 3103]
loss: 0.010719  [ 2000/ 3103]
loss: 0.006054  [ 2100/ 3103]
loss: 0.016238  [ 2200/ 3103]
loss: 0.008459  [ 2300/ 3103]
loss: 0.023558  [ 2400/ 3103]
loss: 0.012703  [ 2500/ 3103]
loss: 0.012158  [ 2600/ 3103]
loss: 0.012952  [ 2700/ 3103]
loss: 0.008299  [ 2800/ 3103]
loss: 0.008193  [ 2900/ 3103]
loss: 0.004634  [ 3000/ 3103]
loss: 0.013493  [ 3100/ 3103]
Epoch 2
-------------------------------
loss: 0.016673  [    0/ 3103]
loss: 0.005509  [  100/ 3103]
loss: 0.002329  [  200/ 3103]
loss: 0.016987  [  300/ 3103]
loss: 0.008783  [  400/ 3103]
loss: 0.007800  [  500/ 3103]
loss: 0.010414  [  600/ 3103]
loss: 0.008051  [  700/ 3103]
loss: 0.007156  [  800/ 3103]
loss: 0.015064  [  900/ 3103]
loss: 0.084205  [ 1000/ 3103]
loss: 0.014498  [ 1100/ 3103]
loss: 0.008767  [ 1200/ 3103]
loss: 0.120847  [ 1300/ 3103]
loss: 0.006971  [ 1400/ 3103]
loss: 0.025431  [ 1500/ 3103]
loss: 0.009519  [ 1600/ 3103]
loss: 0.010417  [ 1700/ 3103]
loss: 0.008756  [ 1800/ 3103]
loss: 0.018864  [ 1900/ 3103]
loss: 0.008187  [ 2000/ 3103]
loss: 0.002626  [ 2100/ 3103]
loss: 0.004799  [ 2200/ 3103]
loss: 0.006160  [ 2300/ 3103]
loss: 0.007821  [ 2400/ 3103]
loss: 0.009649  [ 2500/ 3103]
loss: 0.011202  [ 2600/ 3103]
loss: 0.010139  [ 2700/ 3103]
loss: 0.006416  [ 2800/ 3103]
loss: 0.002872  [ 2900/ 3103]
loss: 0.004073  [ 3000/ 3103]
loss: 0.011241  [ 3100/ 3103]
Epoch 3
-------------------------------
loss: 0.016172  [    0/ 3103]
loss: 0.006722  [  100/ 3103]
loss: 0.001580  [  200/ 3103]
loss: 0.006769  [  300/ 3103]
loss: 0.008145  [  400/ 3103]
loss: 0.011130  [  500/ 3103]
loss: 0.007462  [  600/ 3103]
loss: 0.007740  [  700/ 3103]
loss: 0.004368  [  800/ 3103]
loss: 0.007010  [  900/ 3103]
loss: 0.086204  [ 1000/ 3103]
loss: 0.014565  [ 1100/ 3103]
loss: 0.008482  [ 1200/ 3103]
loss: 0.124299  [ 1300/ 3103]
loss: 0.006360  [ 1400/ 3103]
loss: 0.022565  [ 1500/ 3103]
loss: 0.004994  [ 1600/ 3103]
loss: 0.010248  [ 1700/ 3103]
loss: 0.007660  [ 1800/ 3103]
loss: 0.018806  [ 1900/ 3103]
loss: 0.007730  [ 2000/ 3103]
loss: 0.002862  [ 2100/ 3103]
loss: 0.005074  [ 2200/ 3103]
loss: 0.005866  [ 2300/ 3103]
loss: 0.008135  [ 2400/ 3103]
loss: 0.008930  [ 2500/ 3103]
loss: 0.011830  [ 2600/ 3103]
loss: 0.009619  [ 2700/ 3103]
loss: 0.006504  [ 2800/ 3103]
loss: 0.002637  [ 2900/ 3103]
loss: 0.003830  [ 3000/ 3103]
loss: 0.012128  [ 3100/ 3103]
Epoch 4
-------------------------------
loss: 0.016556  [    0/ 3103]
loss: 0.006905  [  100/ 3103]
loss: 0.001509  [  200/ 3103]
loss: 0.005022  [  300/ 3103]
loss: 0.007789  [  400/ 3103]
loss: 0.012134  [  500/ 3103]
loss: 0.007271  [  600/ 3103]
loss: 0.007711  [  700/ 3103]
loss: 0.003980  [  800/ 3103]
loss: 0.006047  [  900/ 3103]
loss: 0.085487  [ 1000/ 3103]
loss: 0.014611  [ 1100/ 3103]
loss: 0.008519  [ 1200/ 3103]
loss: 0.124977  [ 1300/ 3103]
loss: 0.006435  [ 1400/ 3103]
loss: 0.021366  [ 1500/ 3103]
loss: 0.004191  [ 1600/ 3103]
loss: 0.010646  [ 1700/ 3103]
loss: 0.007656  [ 1800/ 3103]
loss: 0.018359  [ 1900/ 3103]
loss: 0.007674  [ 2000/ 3103]
loss: 0.003029  [ 2100/ 3103]
loss: 0.005176  [ 2200/ 3103]
loss: 0.005768  [ 2300/ 3103]
loss: 0.008078  [ 2400/ 3103]
loss: 0.008720  [ 2500/ 3103]
loss: 0.012073  [ 2600/ 3103]
loss: 0.009454  [ 2700/ 3103]
loss: 0.006634  [ 2800/ 3103]
loss: 0.002578  [ 2900/ 3103]
loss: 0.003769  [ 3000/ 3103]
loss: 0.012582  [ 3100/ 3103]
Epoch 5
-------------------------------
loss: 0.016749  [    0/ 3103]
loss: 0.006871  [  100/ 3103]
loss: 0.001578  [  200/ 3103]
loss: 0.004279  [  300/ 3103]
loss: 0.007474  [  400/ 3103]
loss: 0.012467  [  500/ 3103]
loss: 0.007124  [  600/ 3103]
loss: 0.007705  [  700/ 3103]
loss: 0.003856  [  800/ 3103]
loss: 0.005774  [  900/ 3103]
loss: 0.084750  [ 1000/ 3103]
loss: 0.014684  [ 1100/ 3103]
loss: 0.008521  [ 1200/ 3103]
loss: 0.125437  [ 1300/ 3103]
loss: 0.006514  [ 1400/ 3103]
loss: 0.020558  [ 1500/ 3103]
loss: 0.003941  [ 1600/ 3103]
loss: 0.011057  [ 1700/ 3103]
loss: 0.007807  [ 1800/ 3103]
loss: 0.017813  [ 1900/ 3103]
loss: 0.007737  [ 2000/ 3103]
loss: 0.003149  [ 2100/ 3103]
loss: 0.005186  [ 2200/ 3103]
loss: 0.005767  [ 2300/ 3103]
loss: 0.007957  [ 2400/ 3103]
loss: 0.008536  [ 2500/ 3103]
loss: 0.012213  [ 2600/ 3103]
loss: 0.009441  [ 2700/ 3103]
loss: 0.006745  [ 2800/ 3103]
loss: 0.002560  [ 2900/ 3103]
loss: 0.003773  [ 3000/ 3103]
loss: 0.012902  [ 3100/ 3103]
Epoch 6
-------------------------------
loss: 0.016902  [    0/ 3103]
loss: 0.006893  [  100/ 3103]
loss: 0.001713  [  200/ 3103]
loss: 0.003886  [  300/ 3103]
loss: 0.007422  [  400/ 3103]
loss: 0.012644  [  500/ 3103]
loss: 0.007001  [  600/ 3103]
loss: 0.007674  [  700/ 3103]
loss: 0.003772  [  800/ 3103]
loss: 0.005686  [  900/ 3103]
loss: 0.087121  [ 1000/ 3103]
loss: 0.014717  [ 1100/ 3103]
loss: 0.008476  [ 1200/ 3103]
loss: 0.125438  [ 1300/ 3103]
loss: 0.006596  [ 1400/ 3103]
loss: 0.020019  [ 1500/ 3103]
loss: 0.003798  [ 1600/ 3103]
loss: 0.011414  [ 1700/ 3103]
loss: 0.007850  [ 1800/ 3103]
loss: 0.018178  [ 1900/ 3103]
loss: 0.007864  [ 2000/ 3103]
loss: 0.003222  [ 2100/ 3103]
loss: 0.005235  [ 2200/ 3103]
loss: 0.005803  [ 2300/ 3103]
loss: 0.007918  [ 2400/ 3103]
loss: 0.008410  [ 2500/ 3103]
loss: 0.012301  [ 2600/ 3103]
loss: 0.009438  [ 2700/ 3103]
loss: 0.006798  [ 2800/ 3103]
loss: 0.002526  [ 2900/ 3103]
loss: 0.003732  [ 3000/ 3103]
loss: 0.013149  [ 3100/ 3103]
Epoch 7
-------------------------------
loss: 0.016980  [    0/ 3103]
loss: 0.006906  [  100/ 3103]
loss: 0.001743  [  200/ 3103]
loss: 0.003661  [  300/ 3103]
loss: 0.007335  [  400/ 3103]
loss: 0.012762  [  500/ 3103]
loss: 0.006888  [  600/ 3103]
loss: 0.007675  [  700/ 3103]
loss: 0.003721  [  800/ 3103]
loss: 0.005583  [  900/ 3103]
loss: 0.084493  [ 1000/ 3103]
loss: 0.014740  [ 1100/ 3103]
loss: 0.008487  [ 1200/ 3103]
loss: 0.125513  [ 1300/ 3103]
loss: 0.006628  [ 1400/ 3103]
loss: 0.019837  [ 1500/ 3103]
loss: 0.003843  [ 1600/ 3103]
loss: 0.011498  [ 1700/ 3103]
loss: 0.007869  [ 1800/ 3103]
loss: 0.017837  [ 1900/ 3103]
loss: 0.007833  [ 2000/ 3103]
loss: 0.003247  [ 2100/ 3103]
loss: 0.005214  [ 2200/ 3103]
loss: 0.005796  [ 2300/ 3103]
loss: 0.007912  [ 2400/ 3103]
loss: 0.008366  [ 2500/ 3103]
loss: 0.012307  [ 2600/ 3103]
loss: 0.009434  [ 2700/ 3103]
loss: 0.006846  [ 2800/ 3103]
loss: 0.002518  [ 2900/ 3103]
loss: 0.003733  [ 3000/ 3103]
loss: 0.013219  [ 3100/ 3103]
Epoch 8
-------------------------------
loss: 0.016995  [    0/ 3103]
loss: 0.006870  [  100/ 3103]
loss: 0.001784  [  200/ 3103]
loss: 0.003601  [  300/ 3103]
loss: 0.007374  [  400/ 3103]
loss: 0.012794  [  500/ 3103]
loss: 0.006855  [  600/ 3103]
loss: 0.007650  [  700/ 3103]
loss: 0.003687  [  800/ 3103]
loss: 0.005536  [  900/ 3103]
loss: 0.084450  [ 1000/ 3103]
loss: 0.014762  [ 1100/ 3103]
loss: 0.008456  [ 1200/ 3103]
loss: 0.125234  [ 1300/ 3103]
loss: 0.006641  [ 1400/ 3103]
loss: 0.019701  [ 1500/ 3103]
loss: 0.003856  [ 1600/ 3103]
loss: 0.011565  [ 1700/ 3103]
loss: 0.007855  [ 1800/ 3103]
loss: 0.017777  [ 1900/ 3103]
loss: 0.007850  [ 2000/ 3103]
loss: 0.003273  [ 2100/ 3103]
loss: 0.005202  [ 2200/ 3103]
loss: 0.005809  [ 2300/ 3103]
loss: 0.007918  [ 2400/ 3103]
loss: 0.008322  [ 2500/ 3103]
loss: 0.012326  [ 2600/ 3103]
loss: 0.009469  [ 2700/ 3103]
loss: 0.006871  [ 2800/ 3103]
loss: 0.002513  [ 2900/ 3103]
loss: 0.003715  [ 3000/ 3103]
loss: 0.013314  [ 3100/ 3103]
Number of Clusters: 3
Q_Learning:     1/  345]
Q_Learning:     2/  345]
Q_Learning:     3/  345]
Q_Learning:     4/  345]
Q_Learning:     5/  345]
Q_Learning:     6/  345]
Q_Learning:     7/  345]
Q_Learning:     8/  345]
Q_Learning:     9/  345]
Q_Learning:    10/  345]
Q_Learning:    11/  345]
Q_Learning:    12/  345]
Q_Learning:    13/  345]
Q_Learning:    14/  345]
Q_Learning:    15/  345]
Q_Learning:    16/  345]
Q_Learning:    17/  345]
Q_Learning:    18/  345]
Q_Learning:    19/  345]
Q_Learning:    20/  345]
Q_Learning:    21/  345]
Q_Learning:    22/  345]
Q_Learning:    23/  345]
Q_Learning:    24/  345]
Q_Learning:    25/  345]
Q_Learning:    26/  345]
Q_Learning:    27/  345]
Q_Learning:    28/  345]
Q_Learning:    29/  345]
Q_Learning:    30/  345]
Q_Learning:    31/  345]
Q_Learning:    32/  345]
Q_Learning:    33/  345]
Q_Learning:    34/  345]
Q_Learning:    35/  345]
Q_Learning:    36/  345]
Q_Learning:    37/  345]
Q_Learning:    38/  345]
Q_Learning:    39/  345]
Q_Learning:    40/  345]
Q_Learning:    41/  345]
Q_Learning:    42/  345]
Q_Learning:    43/  345]
Q_Learning:    44/  345]
Q_Learning:    45/  345]
Q_Learning:    46/  345]
Q_Learning:    47/  345]
Q_Learning:    48/  345]
Q_Learning:    49/  345]
Q_Learning:    50/  345]
Q_Learning:    51/  345]
Q_Learning:    52/  345]
Q_Learning:    53/  345]
Q_Learning:    54/  345]
Q_Learning:    55/  345]
Q_Learning:    56/  345]
Q_Learning:    57/  345]
Q_Learning:    58/  345]
Q_Learning:    59/  345]
Q_Learning:    60/  345]
Q_Learning:    61/  345]
Q_Learning:    62/  345]
Q_Learning:    63/  345]
Q_Learning:    64/  345]
Q_Learning:    65/  345]
Q_Learning:    66/  345]
Q_Learning:    67/  345]
Q_Learning:    68/  345]
Q_Learning:    69/  345]
Q_Learning:    70/  345]
Q_Learning:    71/  345]
Q_Learning:    72/  345]
Q_Learning:    73/  345]
Q_Learning:    74/  345]
Q_Learning:    75/  345]
Q_Learning:    76/  345]
Q_Learning:    77/  345]
Q_Learning:    78/  345]
Q_Learning:    79/  345]
Q_Learning:    80/  345]
Q_Learning:    81/  345]
Q_Learning:    82/  345]
Q_Learning:    83/  345]
Q_Learning:    84/  345]
Q_Learning:    85/  345]
Q_Learning:    86/  345]
Q_Learning:    87/  345]
Q_Learning:    88/  345]
Q_Learning:    89/  345]
Q_Learning:    90/  345]
Q_Learning:    91/  345]
Q_Learning:    92/  345]
Q_Learning:    93/  345]
Q_Learning:    94/  345]
Q_Learning:    95/  345]
Q_Learning:    96/  345]
Q_Learning:    97/  345]
Q_Learning:    98/  345]
Q_Learning:    99/  345]
Q_Learning:   100/  345]
Q_Learning:   101/  345]
Q_Learning:   102/  345]
Q_Learning:   103/  345]
Q_Learning:   104/  345]
Q_Learning:   105/  345]
Q_Learning:   106/  345]
Q_Learning:   107/  345]
Q_Learning:   108/  345]
Q_Learning:   109/  345]
Q_Learning:   110/  345]
Q_Learning:   111/  345]
Q_Learning:   112/  345]
Q_Learning:   113/  345]
Q_Learning:   114/  345]
Q_Learning:   115/  345]
Q_Learning:   116/  345]
Q_Learning:   117/  345]
Q_Learning:   118/  345]
Q_Learning:   119/  345]
Q_Learning:   120/  345]
Q_Learning:   121/  345]
Q_Learning:   122/  345]
Q_Learning:   123/  345]
Q_Learning:   124/  345]
Q_Learning:   125/  345]
Q_Learning:   126/  345]
Q_Learning:   127/  345]
Q_Learning:   128/  345]
Q_Learning:   129/  345]
Q_Learning:   130/  345]
Q_Learning:   131/  345]
Q_Learning:   132/  345]
Q_Learning:   133/  345]
Q_Learning:   134/  345]
Q_Learning:   135/  345]
Q_Learning:   136/  345]
Q_Learning:   137/  345]
Q_Learning:   138/  345]
Q_Learning:   139/  345]
Q_Learning:   140/  345]
Q_Learning:   141/  345]
Q_Learning:   142/  345]
Q_Learning:   143/  345]
Q_Learning:   144/  345]
Q_Learning:   145/  345]
Q_Learning:   146/  345]
Q_Learning:   147/  345]
Q_Learning:   148/  345]
Q_Learning:   149/  345]
Q_Learning:   150/  345]
Q_Learning:   151/  345]
Q_Learning:   152/  345]
Q_Learning:   153/  345]
Q_Learning:   154/  345]
Q_Learning:   155/  345]
Q_Learning:   156/  345]
Q_Learning:   157/  345]
Q_Learning:   158/  345]
Q_Learning:   159/  345]
Q_Learning:   160/  345]
Q_Learning:   161/  345]
Q_Learning:   162/  345]
Q_Learning:   163/  345]
Q_Learning:   164/  345]
Q_Learning:   165/  345]
Q_Learning:   166/  345]
Q_Learning:   167/  345]
Q_Learning:   168/  345]
Q_Learning:   169/  345]
Q_Learning:   170/  345]
Q_Learning:   171/  345]
Q_Learning:   172/  345]
Q_Learning:   173/  345]
Q_Learning:   174/  345]
Q_Learning:   175/  345]
Q_Learning:   176/  345]
Q_Learning:   177/  345]
Q_Learning:   178/  345]
Q_Learning:   179/  345]
Q_Learning:   180/  345]
Q_Learning:   181/  345]
Q_Learning:   182/  345]
Q_Learning:   183/  345]
Q_Learning:   184/  345]
Q_Learning:   185/  345]
Q_Learning:   186/  345]
Q_Learning:   187/  345]
Q_Learning:   188/  345]
Q_Learning:   189/  345]
Q_Learning:   190/  345]
Q_Learning:   191/  345]
Q_Learning:   192/  345]
Q_Learning:   193/  345]
Q_Learning:   194/  345]
Q_Learning:   195/  345]
Q_Learning:   196/  345]
Q_Learning:   197/  345]
Q_Learning:   198/  345]
Q_Learning:   199/  345]
Q_Learning:   200/  345]
Q_Learning:   201/  345]
Q_Learning:   202/  345]
Q_Learning:   203/  345]
Q_Learning:   204/  345]
Q_Learning:   205/  345]
Q_Learning:   206/  345]
Q_Learning:   207/  345]
Q_Learning:   208/  345]
Q_Learning:   209/  345]
Q_Learning:   210/  345]
Q_Learning:   211/  345]
Q_Learning:   212/  345]
Q_Learning:   213/  345]
Q_Learning:   214/  345]
Q_Learning:   215/  345]
Q_Learning:   216/  345]
Q_Learning:   217/  345]
Q_Learning:   218/  345]
Q_Learning:   219/  345]
Q_Learning:   220/  345]
Q_Learning:   221/  345]
Q_Learning:   222/  345]
Q_Learning:   223/  345]
Q_Learning:   224/  345]
Q_Learning:   225/  345]
Q_Learning:   226/  345]
Q_Learning:   227/  345]
Q_Learning:   228/  345]
Q_Learning:   229/  345]
Q_Learning:   230/  345]
Q_Learning:   231/  345]
Q_Learning:   232/  345]
Q_Learning:   233/  345]
Q_Learning:   234/  345]
Q_Learning:   235/  345]
Q_Learning:   236/  345]
Q_Learning:   237/  345]
Q_Learning:   238/  345]
Q_Learning:   239/  345]
Q_Learning:   240/  345]
Q_Learning:   241/  345]
Q_Learning:   242/  345]
Q_Learning:   243/  345]
Q_Learning:   244/  345]
Q_Learning:   245/  345]
Q_Learning:   246/  345]
Q_Learning:   247/  345]
Q_Learning:   248/  345]
Q_Learning:   249/  345]
Q_Learning:   250/  345]
Q_Learning:   251/  345]
Q_Learning:   252/  345]
Q_Learning:   253/  345]
Q_Learning:   254/  345]
Q_Learning:   255/  345]
Q_Learning:   256/  345]
Q_Learning:   257/  345]
Q_Learning:   258/  345]
Q_Learning:   259/  345]
Q_Learning:   260/  345]
Q_Learning:   261/  345]
Q_Learning:   262/  345]
Q_Learning:   263/  345]
Q_Learning:   264/  345]
Q_Learning:   265/  345]
Q_Learning:   266/  345]
Q_Learning:   267/  345]
Q_Learning:   268/  345]
Q_Learning:   269/  345]
Q_Learning:   270/  345]
Q_Learning:   271/  345]
Q_Learning:   272/  345]
Q_Learning:   273/  345]
Q_Learning:   274/  345]
Q_Learning:   275/  345]
Q_Learning:   276/  345]
Q_Learning:   277/  345]
Q_Learning:   278/  345]
Q_Learning:   279/  345]
Q_Learning:   280/  345]
Q_Learning:   281/  345]
Q_Learning:   282/  345]
Q_Learning:   283/  345]
Q_Learning:   284/  345]
Q_Learning:   285/  345]
Q_Learning:   286/  345]
Q_Learning:   287/  345]
Q_Learning:   288/  345]
Q_Learning:   289/  345]
Q_Learning:   290/  345]
Q_Learning:   291/  345]
Q_Learning:   292/  345]
Q_Learning:   293/  345]
Q_Learning:   294/  345]
Q_Learning:   295/  345]
Q_Learning:   296/  345]
Q_Learning:   297/  345]
Q_Learning:   298/  345]
Q_Learning:   299/  345]
Q_Learning:   300/  345]
Q_Learning:   301/  345]
Q_Learning:   302/  345]
Q_Learning:   303/  345]
Q_Learning:   304/  345]
Q_Learning:   305/  345]
Q_Learning:   306/  345]
Q_Learning:   307/  345]
Q_Learning:   308/  345]
Q_Learning:   309/  345]
Q_Learning:   310/  345]
Q_Learning:   311/  345]
Q_Learning:   312/  345]
Q_Learning:   313/  345]
Q_Learning:   314/  345]
Q_Learning:   315/  345]
Q_Learning:   316/  345]
Q_Learning:   317/  345]
Q_Learning:   318/  345]
Q_Learning:   319/  345]
Q_Learning:   320/  345]
Q_Learning:   321/  345]
Q_Learning:   322/  345]
Q_Learning:   323/  345]
Q_Learning:   324/  345]
Q_Learning:   325/  345]
Q_Learning:   326/  345]
Q_Learning:   327/  345]
Q_Learning:   328/  345]
Q_Learning:   329/  345]
Q_Learning:   330/  345]
Q_Learning:   331/  345]
Q_Learning:   332/  345]
Q_Learning:   333/  345]
Q_Learning:   334/  345]
Q_Learning:   335/  345]
Q_Learning:   336/  345]
Q_Learning:   337/  345]
Q_Learning:   338/  345]
Q_Learning:   339/  345]
Q_Learning:   340/  345]
Q_Learning:   341/  345]
Q_Learning:   342/  345]
Q_Learning:   343/  345]
Q_Learning:   344/  345]
Q_Learning:   345/  345]
Number of Samples after Autoencoder testing: 345
First Spike after testing: [ 0.66232216 -2.4221187 ]
[0, 0, 1, 0, 1, 0, 0, 1, 2, 2, 1, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0, 2, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 2, 1, 0, 1, 0, 2, 1, 0, 2, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 0, 2, 1, 0, 1, 2, 1, 0, 2, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 1, 2, 0, 2, 2, 1, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 1, 1, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 2, 2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2]
[0, 1, 2, 3, 4, 5, 6, 2, 7, 4, 8, 9, 0, 10, 11, 4, 12, 13, 10, 6, 1, 2, 8, 14, 11, 7, 2, 6, 10, 8, 3, 1, 4, 15, 3, 6, 6, 6, 16, 17, 8, 18, 2, 12, 1, 19, 11, 20, 10, 5, 2, 12, 18, 11, 5, 2, 18, 21, 21, 12, 0, 17, 22, 2, 3, 21, 23, 20, 4, 3, 18, 15, 17, 10, 23, 24, 0, 25, 2, 17, 26, 3, 3, 4, 27, 5, 23, 1, 23, 11, 6, 20, 27, 21, 20, 2, 21, 19, 10, 3, 16, 16, 23, 4, 2, 2, 20, 16, 1, 17, 2, 25, 16, 10, 16, 14, 12, 17, 11, 28, 6, 17, 7, 17, 22, 21, 19, 6, 7, 18, 8, 18, 20, 24, 24, 2, 23, 17, 7, 8, 17, 27, 1, 21, 29, 3, 28, 14, 29, 19, 11, 1, 17, 3, 18, 5, 2, 28, 4, 29, 12, 4, 10, 7, 3, 2, 30, 31, 3, 2, 16, 23, 5, 17, 4, 31, 8, 26, 32, 18, 5, 18, 3, 33, 17, 20, 25, 31, 25, 22, 18, 2, 5, 6, 2, 3, 23, 8, 4, 29, 4, 8, 3, 26, 4, 31, 1, 12, 6, 21, 11, 7, 4, 31, 23, 11, 2, 7, 21, 21, 16, 2, 34, 34, 21, 20, 12, 3, 8, 25, 2, 31, 21, 5, 14, 18, 27, 4, 3, 8, 2, 20, 22, 35, 1, 31, 6, 3, 21, 0, 36, 7, 32, 10, 22, 20, 7, 14, 0, 27, 28, 35, 12, 22, 1, 29, 19, 20, 35, 21, 17, 28, 0, 12, 23, 1, 18, 5, 28, 37, 7, 17, 28, 38, 28, 18, 17, 23, 21, 2, 16, 8, 1, 31, 5, 32, 1, 1, 29, 16, 33, 3, 5, 17, 3, 11, 11, 8, 5, 12, 0, 20, 8, 25, 27, 14, 2, 14, 3, 27, 32, 6, 4, 2, 16, 39, 40, 11, 26, 27, 26, 18, 2, 13, 36, 33, 6, 33, 1, 1, 14, 23, 32, 1, 31]
Centroids: [[-0.859869, -5.4700813], [-1.9271106, -6.052051], [-3.4857514, -11.447647]]
Centroids: [[0.47268927, -2.1328738], [-0.82845944, -5.311897], [-1.6592592, -5.5101542], [-0.46705237, -4.447659], [-2.1116223, -6.6909804], [-0.10447112, -3.2710435], [-1.1947857, -6.5355935], [-4.2248273, -13.190872], [-2.751604, -7.8110285], [0.9631397, -0.26080063], [-4.532935, -14.545787], [-3.148571, -11.166764], [-3.0102563, -9.245855], [-1.9738178, -8.884926], [-1.4092188, -7.2992115], [-2.1879463, -10.241129], [-1.3341864, -3.8616278], [-2.1526942, -7.551179], [-3.1187232, -10.162135], [-4.262846, -13.752739], [-3.5307329, -11.158969], [-1.365663, -4.7464128], [-3.8058674, -11.675235], [-1.0457381, -5.8269534], [-1.3572625, -5.5979934], [-2.6560786, -9.629167], [-1.8806732, -8.087019], [-2.7163613, -8.59701], [-3.4224353, -11.874715], [-0.7892327, -3.0389626], [-0.35988492, -1.2405908], [-3.9120762, -12.604832], [-2.1595812, -6.137935], [-2.3601542, -9.274223], [-5.1268563, -16.800303], [0.6916997, -1.3603592], [-2.320532, -7.0173683], [0.20133509, -0.19464809], [-2.7526531, -7.0266676], [-4.914469, -15.330892], [-3.110076, -13.368018]]
Contingency Matrix: 
[[ 7 17  2 20  0 13 14  0  0  1  0  0  0  2  8  1  0  5  0  0  0  1  0 12
   1  1  4  1  0  1  0  0  0  1  1  3  0  0  0  0  1]
 [ 1  1 25  1 15  0  0  0 14  0  0  2  4  0  0  0 11  8  2  0  0 14  1  0
   1  0  0  5  0  5  1  0  5  0  0  0  1  1  1  0  0]
 [ 0  0  0  0  1  0  0 11  0  0  9 10  7  0  0  1  0  4 12  5 12  0  5  0
   1  5  1  2  8  0  0  9  0  3  1  0  1  0  0  1  0]]
[[7, 17, -1, 20, 0, 13, 14, 0, 0, 1, 0, 0, 0, 2, 8, 1, 0, 5, 0, 0, 0, 1, 0, 12, 1, 1, 4, 1, 0, 1, 0, 0, 0, 1, 1, 3, 0, 0, 0, 0, 1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 0, -1, 0, 1, 0, 0, 11, 0, 0, 9, 10, 7, 0, 0, 1, 0, 4, 12, 5, 12, 0, 5, 0, 1, 5, 1, 2, 8, 0, 0, 9, 0, 3, 1, 0, 1, 0, 0, 1, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 0, -1, -1, 1, 0, 0, 11, 0, 0, 9, 10, 7, 0, 0, 1, 0, 4, 12, 5, 12, 0, 5, 0, 1, 5, 1, 2, 8, 0, 0, 9, 0, 3, 1, 0, 1, 0, 0, 1, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 2, 0: 3, 2: 18}
New Contingency Matrix: 
[[20  2  0  7 17  0 13 14  0  0  1  0  0  0  2  8  1  0  5  0  0  1  0 12
   1  1  4  1  0  1  0  0  0  1  1  3  0  0  0  0  1]
 [ 1 25  2  1  1 15  0  0  0 14  0  0  2  4  0  0  0 11  8  0  0 14  1  0
   1  0  0  5  0  5  1  0  5  0  0  0  1  1  1  0  0]
 [ 0  0 12  0  0  1  0  0 11  0  0  9 10  7  0  0  1  0  4  5 12  0  5  0
   1  5  1  2  8  0  0  9  0  3  1  0  1  0  0  1  0]]
New Clustered Label Sequence: [3, 2, 18, 0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]
Diagonal_Elements: [20, 25, 12], Sum: 57
All_Elements: [20, 2, 0, 7, 17, 0, 13, 14, 0, 0, 1, 0, 0, 0, 2, 8, 1, 0, 5, 0, 0, 1, 0, 12, 1, 1, 4, 1, 0, 1, 0, 0, 0, 1, 1, 3, 0, 0, 0, 0, 1, 1, 25, 2, 1, 1, 15, 0, 0, 0, 14, 0, 0, 2, 4, 0, 0, 0, 11, 8, 0, 0, 14, 1, 0, 1, 0, 0, 5, 0, 5, 1, 0, 5, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 12, 0, 0, 1, 0, 0, 11, 0, 0, 9, 10, 7, 0, 0, 1, 0, 4, 5, 12, 0, 5, 0, 1, 5, 1, 2, 8, 0, 0, 9, 0, 3, 1, 0, 1, 0, 0, 1, 0], Sum: 345
Accuracy: 0.16521739130434782
Done!
