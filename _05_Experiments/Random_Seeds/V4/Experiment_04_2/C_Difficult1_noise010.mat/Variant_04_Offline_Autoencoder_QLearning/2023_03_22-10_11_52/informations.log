Experiment_path: Random_Seeds//V4/Experiment_04_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_04_Offline_Autoencoder_QLearning
Visualisation_Path: Random_Seeds//V4/Experiment_04_2/C_Difficult1_noise010.mat/Variant_04_Offline_Autoencoder_QLearning/2023_03_22-10_11_52
Punishment_Coefficient: 0.32
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001C4BDF40550>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
Train Index: 3103
x_train: 3103
y_train: 3103
x_test: 345
y_test: 345
<torch.utils.data.dataloader.DataLoader object at 0x000001C4C8879630>
<torch.utils.data.dataloader.DataLoader object at 0x000001C4C2BDC828>
Epoch 1
-------------------------------
loss: 0.191293  [    0/ 3103]
loss: 0.026029  [  100/ 3103]
loss: 0.019727  [  200/ 3103]
loss: 0.034551  [  300/ 3103]
loss: 0.015941  [  400/ 3103]
loss: 0.015645  [  500/ 3103]
loss: 0.013683  [  600/ 3103]
loss: 0.010349  [  700/ 3103]
loss: 0.007773  [  800/ 3103]
loss: 0.020939  [  900/ 3103]
loss: 0.085716  [ 1000/ 3103]
loss: 0.012226  [ 1100/ 3103]
loss: 0.011164  [ 1200/ 3103]
loss: 0.124888  [ 1300/ 3103]
loss: 0.008839  [ 1400/ 3103]
loss: 0.016806  [ 1500/ 3103]
loss: 0.008540  [ 1600/ 3103]
loss: 0.013758  [ 1700/ 3103]
loss: 0.007907  [ 1800/ 3103]
loss: 0.016979  [ 1900/ 3103]
loss: 0.007885  [ 2000/ 3103]
loss: 0.003626  [ 2100/ 3103]
loss: 0.007522  [ 2200/ 3103]
loss: 0.006333  [ 2300/ 3103]
loss: 0.009996  [ 2400/ 3103]
loss: 0.007360  [ 2500/ 3103]
loss: 0.012602  [ 2600/ 3103]
loss: 0.008507  [ 2700/ 3103]
loss: 0.006764  [ 2800/ 3103]
loss: 0.002616  [ 2900/ 3103]
loss: 0.004497  [ 3000/ 3103]
loss: 0.014901  [ 3100/ 3103]
Epoch 2
-------------------------------
loss: 0.020612  [    0/ 3103]
loss: 0.008872  [  100/ 3103]
loss: 0.001900  [  200/ 3103]
loss: 0.002352  [  300/ 3103]
loss: 0.006172  [  400/ 3103]
loss: 0.013963  [  500/ 3103]
loss: 0.005834  [  600/ 3103]
loss: 0.008269  [  700/ 3103]
loss: 0.003626  [  800/ 3103]
loss: 0.007102  [  900/ 3103]
loss: 0.084127  [ 1000/ 3103]
loss: 0.014800  [ 1100/ 3103]
loss: 0.009095  [ 1200/ 3103]
loss: 0.125287  [ 1300/ 3103]
loss: 0.006879  [ 1400/ 3103]
loss: 0.019811  [ 1500/ 3103]
loss: 0.004470  [ 1600/ 3103]
loss: 0.012180  [ 1700/ 3103]
loss: 0.006801  [ 1800/ 3103]
loss: 0.016961  [ 1900/ 3103]
loss: 0.008342  [ 2000/ 3103]
loss: 0.003360  [ 2100/ 3103]
loss: 0.005737  [ 2200/ 3103]
loss: 0.005844  [ 2300/ 3103]
loss: 0.008083  [ 2400/ 3103]
loss: 0.008095  [ 2500/ 3103]
loss: 0.012756  [ 2600/ 3103]
loss: 0.008998  [ 2700/ 3103]
loss: 0.006307  [ 2800/ 3103]
loss: 0.002857  [ 2900/ 3103]
loss: 0.004221  [ 3000/ 3103]
loss: 0.013121  [ 3100/ 3103]
Epoch 3
-------------------------------
loss: 0.019229  [    0/ 3103]
loss: 0.008052  [  100/ 3103]
loss: 0.002737  [  200/ 3103]
loss: 0.003320  [  300/ 3103]
loss: 0.006808  [  400/ 3103]
loss: 0.013211  [  500/ 3103]
loss: 0.006458  [  600/ 3103]
loss: 0.007956  [  700/ 3103]
loss: 0.003649  [  800/ 3103]
loss: 0.006198  [  900/ 3103]
loss: 0.084171  [ 1000/ 3103]
loss: 0.014986  [ 1100/ 3103]
loss: 0.008672  [ 1200/ 3103]
loss: 0.125341  [ 1300/ 3103]
loss: 0.006642  [ 1400/ 3103]
loss: 0.020789  [ 1500/ 3103]
loss: 0.004113  [ 1600/ 3103]
loss: 0.011990  [ 1700/ 3103]
loss: 0.006985  [ 1800/ 3103]
loss: 0.016981  [ 1900/ 3103]
loss: 0.008383  [ 2000/ 3103]
loss: 0.003243  [ 2100/ 3103]
loss: 0.005539  [ 2200/ 3103]
loss: 0.005705  [ 2300/ 3103]
loss: 0.007641  [ 2400/ 3103]
loss: 0.008208  [ 2500/ 3103]
loss: 0.012541  [ 2600/ 3103]
loss: 0.009477  [ 2700/ 3103]
loss: 0.006169  [ 2800/ 3103]
loss: 0.002737  [ 2900/ 3103]
loss: 0.004094  [ 3000/ 3103]
loss: 0.012712  [ 3100/ 3103]
Epoch 4
-------------------------------
loss: 0.020471  [    0/ 3103]
loss: 0.008141  [  100/ 3103]
loss: 0.003632  [  200/ 3103]
loss: 0.003481  [  300/ 3103]
loss: 0.007125  [  400/ 3103]
loss: 0.012593  [  500/ 3103]
loss: 0.006553  [  600/ 3103]
loss: 0.008202  [  700/ 3103]
loss: 0.003794  [  800/ 3103]
loss: 0.005341  [  900/ 3103]
loss: 0.084350  [ 1000/ 3103]
loss: 0.015388  [ 1100/ 3103]
loss: 0.008243  [ 1200/ 3103]
loss: 0.124716  [ 1300/ 3103]
loss: 0.006630  [ 1400/ 3103]
loss: 0.020789  [ 1500/ 3103]
loss: 0.004169  [ 1600/ 3103]
loss: 0.011926  [ 1700/ 3103]
loss: 0.006998  [ 1800/ 3103]
loss: 0.017166  [ 1900/ 3103]
loss: 0.008417  [ 2000/ 3103]
loss: 0.003131  [ 2100/ 3103]
loss: 0.005240  [ 2200/ 3103]
loss: 0.005919  [ 2300/ 3103]
loss: 0.007720  [ 2400/ 3103]
loss: 0.008488  [ 2500/ 3103]
loss: 0.012511  [ 2600/ 3103]
loss: 0.009353  [ 2700/ 3103]
loss: 0.006428  [ 2800/ 3103]
loss: 0.002564  [ 2900/ 3103]
loss: 0.004068  [ 3000/ 3103]
loss: 0.012581  [ 3100/ 3103]
Epoch 5
-------------------------------
loss: 0.019191  [    0/ 3103]
loss: 0.007717  [  100/ 3103]
loss: 0.004483  [  200/ 3103]
loss: 0.003682  [  300/ 3103]
loss: 0.005408  [  400/ 3103]
loss: 0.012429  [  500/ 3103]
loss: 0.006551  [  600/ 3103]
loss: 0.007937  [  700/ 3103]
loss: 0.003998  [  800/ 3103]
loss: 0.005559  [  900/ 3103]
loss: 0.084505  [ 1000/ 3103]
loss: 0.015050  [ 1100/ 3103]
loss: 0.007719  [ 1200/ 3103]
loss: 0.124429  [ 1300/ 3103]
loss: 0.006541  [ 1400/ 3103]
loss: 0.021235  [ 1500/ 3103]
loss: 0.003990  [ 1600/ 3103]
loss: 0.011898  [ 1700/ 3103]
loss: 0.007272  [ 1800/ 3103]
loss: 0.017519  [ 1900/ 3103]
loss: 0.008249  [ 2000/ 3103]
loss: 0.003064  [ 2100/ 3103]
loss: 0.005060  [ 2200/ 3103]
loss: 0.005785  [ 2300/ 3103]
loss: 0.007224  [ 2400/ 3103]
loss: 0.008633  [ 2500/ 3103]
loss: 0.012649  [ 2600/ 3103]
loss: 0.009229  [ 2700/ 3103]
loss: 0.006945  [ 2800/ 3103]
loss: 0.002293  [ 2900/ 3103]
loss: 0.004215  [ 3000/ 3103]
loss: 0.012501  [ 3100/ 3103]
Epoch 6
-------------------------------
loss: 0.018594  [    0/ 3103]
loss: 0.007240  [  100/ 3103]
loss: 0.005429  [  200/ 3103]
loss: 0.004419  [  300/ 3103]
loss: 0.005041  [  400/ 3103]
loss: 0.012263  [  500/ 3103]
loss: 0.006596  [  600/ 3103]
loss: 0.007607  [  700/ 3103]
loss: 0.004178  [  800/ 3103]
loss: 0.005748  [  900/ 3103]
loss: 0.085549  [ 1000/ 3103]
loss: 0.014848  [ 1100/ 3103]
loss: 0.007318  [ 1200/ 3103]
loss: 0.124350  [ 1300/ 3103]
loss: 0.006548  [ 1400/ 3103]
loss: 0.020874  [ 1500/ 3103]
loss: 0.003928  [ 1600/ 3103]
loss: 0.011941  [ 1700/ 3103]
loss: 0.007562  [ 1800/ 3103]
loss: 0.017713  [ 1900/ 3103]
loss: 0.008018  [ 2000/ 3103]
loss: 0.002956  [ 2100/ 3103]
loss: 0.004972  [ 2200/ 3103]
loss: 0.005891  [ 2300/ 3103]
loss: 0.006805  [ 2400/ 3103]
loss: 0.008598  [ 2500/ 3103]
loss: 0.012806  [ 2600/ 3103]
loss: 0.009050  [ 2700/ 3103]
loss: 0.007129  [ 2800/ 3103]
loss: 0.002224  [ 2900/ 3103]
loss: 0.004387  [ 3000/ 3103]
loss: 0.012726  [ 3100/ 3103]
Epoch 7
-------------------------------
loss: 0.018742  [    0/ 3103]
loss: 0.007165  [  100/ 3103]
loss: 0.006202  [  200/ 3103]
loss: 0.005195  [  300/ 3103]
loss: 0.004334  [  400/ 3103]
loss: 0.012474  [  500/ 3103]
loss: 0.006589  [  600/ 3103]
loss: 0.007383  [  700/ 3103]
loss: 0.004317  [  800/ 3103]
loss: 0.005867  [  900/ 3103]
loss: 0.085449  [ 1000/ 3103]
loss: 0.014563  [ 1100/ 3103]
loss: 0.007116  [ 1200/ 3103]
loss: 0.124369  [ 1300/ 3103]
loss: 0.006387  [ 1400/ 3103]
loss: 0.020560  [ 1500/ 3103]
loss: 0.003821  [ 1600/ 3103]
loss: 0.011621  [ 1700/ 3103]
loss: 0.007830  [ 1800/ 3103]
loss: 0.017975  [ 1900/ 3103]
loss: 0.007762  [ 2000/ 3103]
loss: 0.002892  [ 2100/ 3103]
loss: 0.004939  [ 2200/ 3103]
loss: 0.006086  [ 2300/ 3103]
loss: 0.006451  [ 2400/ 3103]
loss: 0.008554  [ 2500/ 3103]
loss: 0.012624  [ 2600/ 3103]
loss: 0.008670  [ 2700/ 3103]
loss: 0.007245  [ 2800/ 3103]
loss: 0.002270  [ 2900/ 3103]
loss: 0.004458  [ 3000/ 3103]
loss: 0.012757  [ 3100/ 3103]
Epoch 8
-------------------------------
loss: 0.018934  [    0/ 3103]
loss: 0.007054  [  100/ 3103]
loss: 0.006479  [  200/ 3103]
loss: 0.005406  [  300/ 3103]
loss: 0.003737  [  400/ 3103]
loss: 0.012710  [  500/ 3103]
loss: 0.006588  [  600/ 3103]
loss: 0.007298  [  700/ 3103]
loss: 0.004948  [  800/ 3103]
loss: 0.005882  [  900/ 3103]
loss: 0.086023  [ 1000/ 3103]
loss: 0.014657  [ 1100/ 3103]
loss: 0.006848  [ 1200/ 3103]
loss: 0.124213  [ 1300/ 3103]
loss: 0.006347  [ 1400/ 3103]
loss: 0.020338  [ 1500/ 3103]
loss: 0.003847  [ 1600/ 3103]
loss: 0.011561  [ 1700/ 3103]
loss: 0.008122  [ 1800/ 3103]
loss: 0.018137  [ 1900/ 3103]
loss: 0.007688  [ 2000/ 3103]
loss: 0.002866  [ 2100/ 3103]
loss: 0.004979  [ 2200/ 3103]
loss: 0.006471  [ 2300/ 3103]
loss: 0.005553  [ 2400/ 3103]
loss: 0.008559  [ 2500/ 3103]
loss: 0.012601  [ 2600/ 3103]
loss: 0.007960  [ 2700/ 3103]
loss: 0.007082  [ 2800/ 3103]
loss: 0.002124  [ 2900/ 3103]
loss: 0.004426  [ 3000/ 3103]
loss: 0.012692  [ 3100/ 3103]
Number of Clusters: 3
Q_Learning:     1/  345]
Q_Learning:     2/  345]
Q_Learning:     3/  345]
Q_Learning:     4/  345]
Q_Learning:     5/  345]
Q_Learning:     6/  345]
Q_Learning:     7/  345]
Q_Learning:     8/  345]
Q_Learning:     9/  345]
Q_Learning:    10/  345]
Q_Learning:    11/  345]
Q_Learning:    12/  345]
Q_Learning:    13/  345]
Q_Learning:    14/  345]
Q_Learning:    15/  345]
Q_Learning:    16/  345]
Q_Learning:    17/  345]
Q_Learning:    18/  345]
Q_Learning:    19/  345]
Q_Learning:    20/  345]
Q_Learning:    21/  345]
Q_Learning:    22/  345]
Q_Learning:    23/  345]
Q_Learning:    24/  345]
Q_Learning:    25/  345]
Q_Learning:    26/  345]
Q_Learning:    27/  345]
Q_Learning:    28/  345]
Q_Learning:    29/  345]
Q_Learning:    30/  345]
Q_Learning:    31/  345]
Q_Learning:    32/  345]
Q_Learning:    33/  345]
Q_Learning:    34/  345]
Q_Learning:    35/  345]
Q_Learning:    36/  345]
Q_Learning:    37/  345]
Q_Learning:    38/  345]
Q_Learning:    39/  345]
Q_Learning:    40/  345]
Q_Learning:    41/  345]
Q_Learning:    42/  345]
Q_Learning:    43/  345]
Q_Learning:    44/  345]
Q_Learning:    45/  345]
Q_Learning:    46/  345]
Q_Learning:    47/  345]
Q_Learning:    48/  345]
Q_Learning:    49/  345]
Q_Learning:    50/  345]
Q_Learning:    51/  345]
Q_Learning:    52/  345]
Q_Learning:    53/  345]
Q_Learning:    54/  345]
Q_Learning:    55/  345]
Q_Learning:    56/  345]
Q_Learning:    57/  345]
Q_Learning:    58/  345]
Q_Learning:    59/  345]
Q_Learning:    60/  345]
Q_Learning:    61/  345]
Q_Learning:    62/  345]
Q_Learning:    63/  345]
Q_Learning:    64/  345]
Q_Learning:    65/  345]
Q_Learning:    66/  345]
Q_Learning:    67/  345]
Q_Learning:    68/  345]
Q_Learning:    69/  345]
Q_Learning:    70/  345]
Q_Learning:    71/  345]
Q_Learning:    72/  345]
Q_Learning:    73/  345]
Q_Learning:    74/  345]
Q_Learning:    75/  345]
Q_Learning:    76/  345]
Q_Learning:    77/  345]
Q_Learning:    78/  345]
Q_Learning:    79/  345]
Q_Learning:    80/  345]
Q_Learning:    81/  345]
Q_Learning:    82/  345]
Q_Learning:    83/  345]
Q_Learning:    84/  345]
Q_Learning:    85/  345]
Q_Learning:    86/  345]
Q_Learning:    87/  345]
Q_Learning:    88/  345]
Q_Learning:    89/  345]
Q_Learning:    90/  345]
Q_Learning:    91/  345]
Q_Learning:    92/  345]
Q_Learning:    93/  345]
Q_Learning:    94/  345]
Q_Learning:    95/  345]
Q_Learning:    96/  345]
Q_Learning:    97/  345]
Q_Learning:    98/  345]
Q_Learning:    99/  345]
Q_Learning:   100/  345]
Q_Learning:   101/  345]
Q_Learning:   102/  345]
Q_Learning:   103/  345]
Q_Learning:   104/  345]
Q_Learning:   105/  345]
Q_Learning:   106/  345]
Q_Learning:   107/  345]
Q_Learning:   108/  345]
Q_Learning:   109/  345]
Q_Learning:   110/  345]
Q_Learning:   111/  345]
Q_Learning:   112/  345]
Q_Learning:   113/  345]
Q_Learning:   114/  345]
Q_Learning:   115/  345]
Q_Learning:   116/  345]
Q_Learning:   117/  345]
Q_Learning:   118/  345]
Q_Learning:   119/  345]
Q_Learning:   120/  345]
Q_Learning:   121/  345]
Q_Learning:   122/  345]
Q_Learning:   123/  345]
Q_Learning:   124/  345]
Q_Learning:   125/  345]
Q_Learning:   126/  345]
Q_Learning:   127/  345]
Q_Learning:   128/  345]
Q_Learning:   129/  345]
Q_Learning:   130/  345]
Q_Learning:   131/  345]
Q_Learning:   132/  345]
Q_Learning:   133/  345]
Q_Learning:   134/  345]
Q_Learning:   135/  345]
Q_Learning:   136/  345]
Q_Learning:   137/  345]
Q_Learning:   138/  345]
Q_Learning:   139/  345]
Q_Learning:   140/  345]
Q_Learning:   141/  345]
Q_Learning:   142/  345]
Q_Learning:   143/  345]
Q_Learning:   144/  345]
Q_Learning:   145/  345]
Q_Learning:   146/  345]
Q_Learning:   147/  345]
Q_Learning:   148/  345]
Q_Learning:   149/  345]
Q_Learning:   150/  345]
Q_Learning:   151/  345]
Q_Learning:   152/  345]
Q_Learning:   153/  345]
Q_Learning:   154/  345]
Q_Learning:   155/  345]
Q_Learning:   156/  345]
Q_Learning:   157/  345]
Q_Learning:   158/  345]
Q_Learning:   159/  345]
Q_Learning:   160/  345]
Q_Learning:   161/  345]
Q_Learning:   162/  345]
Q_Learning:   163/  345]
Q_Learning:   164/  345]
Q_Learning:   165/  345]
Q_Learning:   166/  345]
Q_Learning:   167/  345]
Q_Learning:   168/  345]
Q_Learning:   169/  345]
Q_Learning:   170/  345]
Q_Learning:   171/  345]
Q_Learning:   172/  345]
Q_Learning:   173/  345]
Q_Learning:   174/  345]
Q_Learning:   175/  345]
Q_Learning:   176/  345]
Q_Learning:   177/  345]
Q_Learning:   178/  345]
Q_Learning:   179/  345]
Q_Learning:   180/  345]
Q_Learning:   181/  345]
Q_Learning:   182/  345]
Q_Learning:   183/  345]
Q_Learning:   184/  345]
Q_Learning:   185/  345]
Q_Learning:   186/  345]
Q_Learning:   187/  345]
Q_Learning:   188/  345]
Q_Learning:   189/  345]
Q_Learning:   190/  345]
Q_Learning:   191/  345]
Q_Learning:   192/  345]
Q_Learning:   193/  345]
Q_Learning:   194/  345]
Q_Learning:   195/  345]
Q_Learning:   196/  345]
Q_Learning:   197/  345]
Q_Learning:   198/  345]
Q_Learning:   199/  345]
Q_Learning:   200/  345]
Q_Learning:   201/  345]
Q_Learning:   202/  345]
Q_Learning:   203/  345]
Q_Learning:   204/  345]
Q_Learning:   205/  345]
Q_Learning:   206/  345]
Q_Learning:   207/  345]
Q_Learning:   208/  345]
Q_Learning:   209/  345]
Q_Learning:   210/  345]
Q_Learning:   211/  345]
Q_Learning:   212/  345]
Q_Learning:   213/  345]
Q_Learning:   214/  345]
Q_Learning:   215/  345]
Q_Learning:   216/  345]
Q_Learning:   217/  345]
Q_Learning:   218/  345]
Q_Learning:   219/  345]
Q_Learning:   220/  345]
Q_Learning:   221/  345]
Q_Learning:   222/  345]
Q_Learning:   223/  345]
Q_Learning:   224/  345]
Q_Learning:   225/  345]
Q_Learning:   226/  345]
Q_Learning:   227/  345]
Q_Learning:   228/  345]
Q_Learning:   229/  345]
Q_Learning:   230/  345]
Q_Learning:   231/  345]
Q_Learning:   232/  345]
Q_Learning:   233/  345]
Q_Learning:   234/  345]
Q_Learning:   235/  345]
Q_Learning:   236/  345]
Q_Learning:   237/  345]
Q_Learning:   238/  345]
Q_Learning:   239/  345]
Q_Learning:   240/  345]
Q_Learning:   241/  345]
Q_Learning:   242/  345]
Q_Learning:   243/  345]
Q_Learning:   244/  345]
Q_Learning:   245/  345]
Q_Learning:   246/  345]
Q_Learning:   247/  345]
Q_Learning:   248/  345]
Q_Learning:   249/  345]
Q_Learning:   250/  345]
Q_Learning:   251/  345]
Q_Learning:   252/  345]
Q_Learning:   253/  345]
Q_Learning:   254/  345]
Q_Learning:   255/  345]
Q_Learning:   256/  345]
Q_Learning:   257/  345]
Q_Learning:   258/  345]
Q_Learning:   259/  345]
Q_Learning:   260/  345]
Q_Learning:   261/  345]
Q_Learning:   262/  345]
Q_Learning:   263/  345]
Q_Learning:   264/  345]
Q_Learning:   265/  345]
Q_Learning:   266/  345]
Q_Learning:   267/  345]
Q_Learning:   268/  345]
Q_Learning:   269/  345]
Q_Learning:   270/  345]
Q_Learning:   271/  345]
Q_Learning:   272/  345]
Q_Learning:   273/  345]
Q_Learning:   274/  345]
Q_Learning:   275/  345]
Q_Learning:   276/  345]
Q_Learning:   277/  345]
Q_Learning:   278/  345]
Q_Learning:   279/  345]
Q_Learning:   280/  345]
Q_Learning:   281/  345]
Q_Learning:   282/  345]
Q_Learning:   283/  345]
Q_Learning:   284/  345]
Q_Learning:   285/  345]
Q_Learning:   286/  345]
Q_Learning:   287/  345]
Q_Learning:   288/  345]
Q_Learning:   289/  345]
Q_Learning:   290/  345]
Q_Learning:   291/  345]
Q_Learning:   292/  345]
Q_Learning:   293/  345]
Q_Learning:   294/  345]
Q_Learning:   295/  345]
Q_Learning:   296/  345]
Q_Learning:   297/  345]
Q_Learning:   298/  345]
Q_Learning:   299/  345]
Q_Learning:   300/  345]
Q_Learning:   301/  345]
Q_Learning:   302/  345]
Q_Learning:   303/  345]
Q_Learning:   304/  345]
Q_Learning:   305/  345]
Q_Learning:   306/  345]
Q_Learning:   307/  345]
Q_Learning:   308/  345]
Q_Learning:   309/  345]
Q_Learning:   310/  345]
Q_Learning:   311/  345]
Q_Learning:   312/  345]
Q_Learning:   313/  345]
Q_Learning:   314/  345]
Q_Learning:   315/  345]
Q_Learning:   316/  345]
Q_Learning:   317/  345]
Q_Learning:   318/  345]
Q_Learning:   319/  345]
Q_Learning:   320/  345]
Q_Learning:   321/  345]
Q_Learning:   322/  345]
Q_Learning:   323/  345]
Q_Learning:   324/  345]
Q_Learning:   325/  345]
Q_Learning:   326/  345]
Q_Learning:   327/  345]
Q_Learning:   328/  345]
Q_Learning:   329/  345]
Q_Learning:   330/  345]
Q_Learning:   331/  345]
Q_Learning:   332/  345]
Q_Learning:   333/  345]
Q_Learning:   334/  345]
Q_Learning:   335/  345]
Q_Learning:   336/  345]
Q_Learning:   337/  345]
Q_Learning:   338/  345]
Q_Learning:   339/  345]
Q_Learning:   340/  345]
Q_Learning:   341/  345]
Q_Learning:   342/  345]
Q_Learning:   343/  345]
Q_Learning:   344/  345]
Q_Learning:   345/  345]
Number of Samples after Autoencoder testing: 345
First Spike after testing: [-0.3191767  1.2076316]
[0, 0, 1, 0, 1, 0, 0, 1, 2, 2, 1, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0, 2, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 2, 1, 0, 1, 0, 2, 1, 0, 2, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 0, 2, 1, 0, 1, 2, 1, 0, 2, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 1, 2, 0, 2, 2, 1, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 1, 1, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 2, 2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2]
[0, 0, 1, 0, 1, 0, 0, 1, 2, 1, 1, 3, 3, 2, 2, 1, 1, 2, 2, 0, 0, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 0, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 3, 1, 2, 1, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 0, 1, 3, 2, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 0, 1, 2, 1, 2, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 1, 2, 3, 2, 1, 1, 1, 2, 1, 0, 2, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 1, 0, 2, 0, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1, 2, 0, 1, 1, 0, 3, 1, 1, 2, 1, 0, 1, 1, 3, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 3, 0, 2, 1, 1, 0, 1, 1, 2, 2, 3, 0, 2, 0, 1, 1, 3, 1, 2, 1, 2, 2, 2, 2, 0, 3, 1, 2, 3, 2, 2, 0, 1, 2, 2, 3, 1, 0, 2, 3, 1, 1, 0, 2, 0, 2, 1, 2, 1, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 2, 3, 1, 0, 1, 1, 1, 2, 0, 3, 1, 0, 2, 2, 1, 0, 2, 3, 2, 1, 2, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 2, 4, 2, 0, 1, 0, 2, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2]
Centroids: [[-0.4914031, 0.8464875], [-0.4274255, 0.35046652], [-1.033556, 0.5385041]]
Centroids: [[-0.5127532, 0.8327349], [-0.44184774, 0.3527952], [-1.0723586, 0.5831906], [-0.13251556, 1.0326352], [-1.4173143, 1.3058956]]
Contingency Matrix: 
[[ 83  10   7  16   1]
 [  1 113   4   1   0]
 [  1  13  95   0   0]]
[[83, -1, 7, 16, 1], [-1, -1, -1, -1, -1], [1, -1, 95, 0, 0]]
[[83, -1, -1, 16, 1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1]]
Match_Labels: {1: 1, 2: 2, 0: 0}
New Contingency Matrix: 
[[ 83  10   7  16   1]
 [  1 113   4   1   0]
 [  1  13  95   0   0]]
New Clustered Label Sequence: [0, 1, 2, 3, 4]
Diagonal_Elements: [83, 113, 95], Sum: 291
All_Elements: [83, 10, 7, 16, 1, 1, 113, 4, 1, 0, 1, 13, 95, 0, 0], Sum: 345
Accuracy: 0.8434782608695652
Done!
