Experiment_path: Random_Seeds//V4/Experiment_04_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_04_Offline_Autoencoder_QLearning
Visualisation_Path: Random_Seeds//V4/Experiment_04_8/C_Difficult1_noise010.mat/Variant_04_Offline_Autoencoder_QLearning/2023_03_22-10_09_34
Punishment_Coefficient: 0.32
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001BA63A44BA8>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
Train Index: 3103
x_train: 3103
y_train: 3103
x_test: 345
y_test: 345
<torch.utils.data.dataloader.DataLoader object at 0x000001BA61EDFDD8>
<torch.utils.data.dataloader.DataLoader object at 0x000001BA6A6CC4A8>
Epoch 1
-------------------------------
loss: 0.175502  [    0/ 3103]
loss: 0.063345  [  100/ 3103]
loss: 0.028824  [  200/ 3103]
loss: 0.035303  [  300/ 3103]
loss: 0.019417  [  400/ 3103]
loss: 0.015117  [  500/ 3103]
loss: 0.022457  [  600/ 3103]
loss: 0.010533  [  700/ 3103]
loss: 0.015204  [  800/ 3103]
loss: 0.031908  [  900/ 3103]
loss: 0.091443  [ 1000/ 3103]
loss: 0.013861  [ 1100/ 3103]
loss: 0.010983  [ 1200/ 3103]
loss: 0.130192  [ 1300/ 3103]
loss: 0.009899  [ 1400/ 3103]
loss: 0.031803  [ 1500/ 3103]
loss: 0.021512  [ 1600/ 3103]
loss: 0.010796  [ 1700/ 3103]
loss: 0.008897  [ 1800/ 3103]
loss: 0.017788  [ 1900/ 3103]
loss: 0.007198  [ 2000/ 3103]
loss: 0.004139  [ 2100/ 3103]
loss: 0.011066  [ 2200/ 3103]
loss: 0.006385  [ 2300/ 3103]
loss: 0.021235  [ 2400/ 3103]
loss: 0.009960  [ 2500/ 3103]
loss: 0.010871  [ 2600/ 3103]
loss: 0.011645  [ 2700/ 3103]
loss: 0.006357  [ 2800/ 3103]
loss: 0.007675  [ 2900/ 3103]
loss: 0.004063  [ 3000/ 3103]
loss: 0.007965  [ 3100/ 3103]
Epoch 2
-------------------------------
loss: 0.017250  [    0/ 3103]
loss: 0.007712  [  100/ 3103]
loss: 0.003664  [  200/ 3103]
loss: 0.009102  [  300/ 3103]
loss: 0.011995  [  400/ 3103]
loss: 0.013604  [  500/ 3103]
loss: 0.008627  [  600/ 3103]
loss: 0.007768  [  700/ 3103]
loss: 0.005055  [  800/ 3103]
loss: 0.005778  [  900/ 3103]
loss: 0.091906  [ 1000/ 3103]
loss: 0.014469  [ 1100/ 3103]
loss: 0.008612  [ 1200/ 3103]
loss: 0.127162  [ 1300/ 3103]
loss: 0.006152  [ 1400/ 3103]
loss: 0.023003  [ 1500/ 3103]
loss: 0.004018  [ 1600/ 3103]
loss: 0.010199  [ 1700/ 3103]
loss: 0.006574  [ 1800/ 3103]
loss: 0.017559  [ 1900/ 3103]
loss: 0.008290  [ 2000/ 3103]
loss: 0.003222  [ 2100/ 3103]
loss: 0.005131  [ 2200/ 3103]
loss: 0.005622  [ 2300/ 3103]
loss: 0.007852  [ 2400/ 3103]
loss: 0.008338  [ 2500/ 3103]
loss: 0.012629  [ 2600/ 3103]
loss: 0.009565  [ 2700/ 3103]
loss: 0.006406  [ 2800/ 3103]
loss: 0.002684  [ 2900/ 3103]
loss: 0.003966  [ 3000/ 3103]
loss: 0.012469  [ 3100/ 3103]
Epoch 3
-------------------------------
loss: 0.017755  [    0/ 3103]
loss: 0.007332  [  100/ 3103]
loss: 0.002321  [  200/ 3103]
loss: 0.004682  [  300/ 3103]
loss: 0.007233  [  400/ 3103]
loss: 0.013336  [  500/ 3103]
loss: 0.006699  [  600/ 3103]
loss: 0.007630  [  700/ 3103]
loss: 0.004125  [  800/ 3103]
loss: 0.005299  [  900/ 3103]
loss: 0.085381  [ 1000/ 3103]
loss: 0.014680  [ 1100/ 3103]
loss: 0.008550  [ 1200/ 3103]
loss: 0.125611  [ 1300/ 3103]
loss: 0.006292  [ 1400/ 3103]
loss: 0.022032  [ 1500/ 3103]
loss: 0.004022  [ 1600/ 3103]
loss: 0.010671  [ 1700/ 3103]
loss: 0.006987  [ 1800/ 3103]
loss: 0.017782  [ 1900/ 3103]
loss: 0.008108  [ 2000/ 3103]
loss: 0.003321  [ 2100/ 3103]
loss: 0.005411  [ 2200/ 3103]
loss: 0.005832  [ 2300/ 3103]
loss: 0.007490  [ 2400/ 3103]
loss: 0.008100  [ 2500/ 3103]
loss: 0.012760  [ 2600/ 3103]
loss: 0.009347  [ 2700/ 3103]
loss: 0.007103  [ 2800/ 3103]
loss: 0.002294  [ 2900/ 3103]
loss: 0.004002  [ 3000/ 3103]
loss: 0.013388  [ 3100/ 3103]
Epoch 4
-------------------------------
loss: 0.016893  [    0/ 3103]
loss: 0.007058  [  100/ 3103]
loss: 0.002796  [  200/ 3103]
loss: 0.004618  [  300/ 3103]
loss: 0.004857  [  400/ 3103]
loss: 0.013411  [  500/ 3103]
loss: 0.006567  [  600/ 3103]
loss: 0.007294  [  700/ 3103]
loss: 0.004239  [  800/ 3103]
loss: 0.005310  [  900/ 3103]
loss: 0.084765  [ 1000/ 3103]
loss: 0.013778  [ 1100/ 3103]
loss: 0.007765  [ 1200/ 3103]
loss: 0.125845  [ 1300/ 3103]
loss: 0.006120  [ 1400/ 3103]
loss: 0.022530  [ 1500/ 3103]
loss: 0.004008  [ 1600/ 3103]
loss: 0.010251  [ 1700/ 3103]
loss: 0.007040  [ 1800/ 3103]
loss: 0.017832  [ 1900/ 3103]
loss: 0.007478  [ 2000/ 3103]
loss: 0.003318  [ 2100/ 3103]
loss: 0.005143  [ 2200/ 3103]
loss: 0.006313  [ 2300/ 3103]
loss: 0.009123  [ 2400/ 3103]
loss: 0.007974  [ 2500/ 3103]
loss: 0.013062  [ 2600/ 3103]
loss: 0.009025  [ 2700/ 3103]
loss: 0.008132  [ 2800/ 3103]
loss: 0.002025  [ 2900/ 3103]
loss: 0.004088  [ 3000/ 3103]
loss: 0.012579  [ 3100/ 3103]
Epoch 5
-------------------------------
loss: 0.014435  [    0/ 3103]
loss: 0.006628  [  100/ 3103]
loss: 0.003076  [  200/ 3103]
loss: 0.005512  [  300/ 3103]
loss: 0.004527  [  400/ 3103]
loss: 0.013350  [  500/ 3103]
loss: 0.006892  [  600/ 3103]
loss: 0.006327  [  700/ 3103]
loss: 0.004557  [  800/ 3103]
loss: 0.005401  [  900/ 3103]
loss: 0.083598  [ 1000/ 3103]
loss: 0.012578  [ 1100/ 3103]
loss: 0.007318  [ 1200/ 3103]
loss: 0.126694  [ 1300/ 3103]
loss: 0.005799  [ 1400/ 3103]
loss: 0.022818  [ 1500/ 3103]
loss: 0.003835  [ 1600/ 3103]
loss: 0.009214  [ 1700/ 3103]
loss: 0.007154  [ 1800/ 3103]
loss: 0.018039  [ 1900/ 3103]
loss: 0.006743  [ 2000/ 3103]
loss: 0.003252  [ 2100/ 3103]
loss: 0.004954  [ 2200/ 3103]
loss: 0.006135  [ 2300/ 3103]
loss: 0.009586  [ 2400/ 3103]
loss: 0.007778  [ 2500/ 3103]
loss: 0.013273  [ 2600/ 3103]
loss: 0.008663  [ 2700/ 3103]
loss: 0.008357  [ 2800/ 3103]
loss: 0.002062  [ 2900/ 3103]
loss: 0.004270  [ 3000/ 3103]
loss: 0.012518  [ 3100/ 3103]
Epoch 6
-------------------------------
loss: 0.014146  [    0/ 3103]
loss: 0.006163  [  100/ 3103]
loss: 0.003551  [  200/ 3103]
loss: 0.006343  [  300/ 3103]
loss: 0.005071  [  400/ 3103]
loss: 0.013438  [  500/ 3103]
loss: 0.007217  [  600/ 3103]
loss: 0.005566  [  700/ 3103]
loss: 0.004479  [  800/ 3103]
loss: 0.005691  [  900/ 3103]
loss: 0.083493  [ 1000/ 3103]
loss: 0.012037  [ 1100/ 3103]
loss: 0.007101  [ 1200/ 3103]
loss: 0.126841  [ 1300/ 3103]
loss: 0.005815  [ 1400/ 3103]
loss: 0.022273  [ 1500/ 3103]
loss: 0.004005  [ 1600/ 3103]
loss: 0.008691  [ 1700/ 3103]
loss: 0.007061  [ 1800/ 3103]
loss: 0.018202  [ 1900/ 3103]
loss: 0.006539  [ 2000/ 3103]
loss: 0.003206  [ 2100/ 3103]
loss: 0.004789  [ 2200/ 3103]
loss: 0.006179  [ 2300/ 3103]
loss: 0.009582  [ 2400/ 3103]
loss: 0.007535  [ 2500/ 3103]
loss: 0.013222  [ 2600/ 3103]
loss: 0.008257  [ 2700/ 3103]
loss: 0.008541  [ 2800/ 3103]
loss: 0.002110  [ 2900/ 3103]
loss: 0.004830  [ 3000/ 3103]
loss: 0.012996  [ 3100/ 3103]
Epoch 7
-------------------------------
loss: 0.013308  [    0/ 3103]
loss: 0.005861  [  100/ 3103]
loss: 0.003603  [  200/ 3103]
loss: 0.007007  [  300/ 3103]
loss: 0.004667  [  400/ 3103]
loss: 0.013504  [  500/ 3103]
loss: 0.007374  [  600/ 3103]
loss: 0.005302  [  700/ 3103]
loss: 0.004640  [  800/ 3103]
loss: 0.005849  [  900/ 3103]
loss: 0.083002  [ 1000/ 3103]
loss: 0.011667  [ 1100/ 3103]
loss: 0.006980  [ 1200/ 3103]
loss: 0.126660  [ 1300/ 3103]
loss: 0.005717  [ 1400/ 3103]
loss: 0.022206  [ 1500/ 3103]
loss: 0.004256  [ 1600/ 3103]
loss: 0.008390  [ 1700/ 3103]
loss: 0.007146  [ 1800/ 3103]
loss: 0.018824  [ 1900/ 3103]
loss: 0.006358  [ 2000/ 3103]
loss: 0.003154  [ 2100/ 3103]
loss: 0.004739  [ 2200/ 3103]
loss: 0.006220  [ 2300/ 3103]
loss: 0.009693  [ 2400/ 3103]
loss: 0.007414  [ 2500/ 3103]
loss: 0.013172  [ 2600/ 3103]
loss: 0.008018  [ 2700/ 3103]
loss: 0.008349  [ 2800/ 3103]
loss: 0.001980  [ 2900/ 3103]
loss: 0.004856  [ 3000/ 3103]
loss: 0.012644  [ 3100/ 3103]
Epoch 8
-------------------------------
loss: 0.012523  [    0/ 3103]
loss: 0.005498  [  100/ 3103]
loss: 0.004064  [  200/ 3103]
loss: 0.007175  [  300/ 3103]
loss: 0.004592  [  400/ 3103]
loss: 0.013320  [  500/ 3103]
loss: 0.007548  [  600/ 3103]
loss: 0.005299  [  700/ 3103]
loss: 0.004965  [  800/ 3103]
loss: 0.005446  [  900/ 3103]
loss: 0.082178  [ 1000/ 3103]
loss: 0.011386  [ 1100/ 3103]
loss: 0.006970  [ 1200/ 3103]
loss: 0.126479  [ 1300/ 3103]
loss: 0.005720  [ 1400/ 3103]
loss: 0.021800  [ 1500/ 3103]
loss: 0.004892  [ 1600/ 3103]
loss: 0.009033  [ 1700/ 3103]
loss: 0.007221  [ 1800/ 3103]
loss: 0.019080  [ 1900/ 3103]
loss: 0.006299  [ 2000/ 3103]
loss: 0.003048  [ 2100/ 3103]
loss: 0.004589  [ 2200/ 3103]
loss: 0.006151  [ 2300/ 3103]
loss: 0.009827  [ 2400/ 3103]
loss: 0.007239  [ 2500/ 3103]
loss: 0.012885  [ 2600/ 3103]
loss: 0.007952  [ 2700/ 3103]
loss: 0.008416  [ 2800/ 3103]
loss: 0.001884  [ 2900/ 3103]
loss: 0.004935  [ 3000/ 3103]
loss: 0.012325  [ 3100/ 3103]
Number of Clusters: 3
Q_Learning:     1/  345]
Q_Learning:     2/  345]
Q_Learning:     3/  345]
Q_Learning:     4/  345]
Q_Learning:     5/  345]
Q_Learning:     6/  345]
Q_Learning:     7/  345]
Q_Learning:     8/  345]
Q_Learning:     9/  345]
Q_Learning:    10/  345]
Q_Learning:    11/  345]
Q_Learning:    12/  345]
Q_Learning:    13/  345]
Q_Learning:    14/  345]
Q_Learning:    15/  345]
Q_Learning:    16/  345]
Q_Learning:    17/  345]
Q_Learning:    18/  345]
Q_Learning:    19/  345]
Q_Learning:    20/  345]
Q_Learning:    21/  345]
Q_Learning:    22/  345]
Q_Learning:    23/  345]
Q_Learning:    24/  345]
Q_Learning:    25/  345]
Q_Learning:    26/  345]
Q_Learning:    27/  345]
Q_Learning:    28/  345]
Q_Learning:    29/  345]
Q_Learning:    30/  345]
Q_Learning:    31/  345]
Q_Learning:    32/  345]
Q_Learning:    33/  345]
Q_Learning:    34/  345]
Q_Learning:    35/  345]
Q_Learning:    36/  345]
Q_Learning:    37/  345]
Q_Learning:    38/  345]
Q_Learning:    39/  345]
Q_Learning:    40/  345]
Q_Learning:    41/  345]
Q_Learning:    42/  345]
Q_Learning:    43/  345]
Q_Learning:    44/  345]
Q_Learning:    45/  345]
Q_Learning:    46/  345]
Q_Learning:    47/  345]
Q_Learning:    48/  345]
Q_Learning:    49/  345]
Q_Learning:    50/  345]
Q_Learning:    51/  345]
Q_Learning:    52/  345]
Q_Learning:    53/  345]
Q_Learning:    54/  345]
Q_Learning:    55/  345]
Q_Learning:    56/  345]
Q_Learning:    57/  345]
Q_Learning:    58/  345]
Q_Learning:    59/  345]
Q_Learning:    60/  345]
Q_Learning:    61/  345]
Q_Learning:    62/  345]
Q_Learning:    63/  345]
Q_Learning:    64/  345]
Q_Learning:    65/  345]
Q_Learning:    66/  345]
Q_Learning:    67/  345]
Q_Learning:    68/  345]
Q_Learning:    69/  345]
Q_Learning:    70/  345]
Q_Learning:    71/  345]
Q_Learning:    72/  345]
Q_Learning:    73/  345]
Q_Learning:    74/  345]
Q_Learning:    75/  345]
Q_Learning:    76/  345]
Q_Learning:    77/  345]
Q_Learning:    78/  345]
Q_Learning:    79/  345]
Q_Learning:    80/  345]
Q_Learning:    81/  345]
Q_Learning:    82/  345]
Q_Learning:    83/  345]
Q_Learning:    84/  345]
Q_Learning:    85/  345]
Q_Learning:    86/  345]
Q_Learning:    87/  345]
Q_Learning:    88/  345]
Q_Learning:    89/  345]
Q_Learning:    90/  345]
Q_Learning:    91/  345]
Q_Learning:    92/  345]
Q_Learning:    93/  345]
Q_Learning:    94/  345]
Q_Learning:    95/  345]
Q_Learning:    96/  345]
Q_Learning:    97/  345]
Q_Learning:    98/  345]
Q_Learning:    99/  345]
Q_Learning:   100/  345]
Q_Learning:   101/  345]
Q_Learning:   102/  345]
Q_Learning:   103/  345]
Q_Learning:   104/  345]
Q_Learning:   105/  345]
Q_Learning:   106/  345]
Q_Learning:   107/  345]
Q_Learning:   108/  345]
Q_Learning:   109/  345]
Q_Learning:   110/  345]
Q_Learning:   111/  345]
Q_Learning:   112/  345]
Q_Learning:   113/  345]
Q_Learning:   114/  345]
Q_Learning:   115/  345]
Q_Learning:   116/  345]
Q_Learning:   117/  345]
Q_Learning:   118/  345]
Q_Learning:   119/  345]
Q_Learning:   120/  345]
Q_Learning:   121/  345]
Q_Learning:   122/  345]
Q_Learning:   123/  345]
Q_Learning:   124/  345]
Q_Learning:   125/  345]
Q_Learning:   126/  345]
Q_Learning:   127/  345]
Q_Learning:   128/  345]
Q_Learning:   129/  345]
Q_Learning:   130/  345]
Q_Learning:   131/  345]
Q_Learning:   132/  345]
Q_Learning:   133/  345]
Q_Learning:   134/  345]
Q_Learning:   135/  345]
Q_Learning:   136/  345]
Q_Learning:   137/  345]
Q_Learning:   138/  345]
Q_Learning:   139/  345]
Q_Learning:   140/  345]
Q_Learning:   141/  345]
Q_Learning:   142/  345]
Q_Learning:   143/  345]
Q_Learning:   144/  345]
Q_Learning:   145/  345]
Q_Learning:   146/  345]
Q_Learning:   147/  345]
Q_Learning:   148/  345]
Q_Learning:   149/  345]
Q_Learning:   150/  345]
Q_Learning:   151/  345]
Q_Learning:   152/  345]
Q_Learning:   153/  345]
Q_Learning:   154/  345]
Q_Learning:   155/  345]
Q_Learning:   156/  345]
Q_Learning:   157/  345]
Q_Learning:   158/  345]
Q_Learning:   159/  345]
Q_Learning:   160/  345]
Q_Learning:   161/  345]
Q_Learning:   162/  345]
Q_Learning:   163/  345]
Q_Learning:   164/  345]
Q_Learning:   165/  345]
Q_Learning:   166/  345]
Q_Learning:   167/  345]
Q_Learning:   168/  345]
Q_Learning:   169/  345]
Q_Learning:   170/  345]
Q_Learning:   171/  345]
Q_Learning:   172/  345]
Q_Learning:   173/  345]
Q_Learning:   174/  345]
Q_Learning:   175/  345]
Q_Learning:   176/  345]
Q_Learning:   177/  345]
Q_Learning:   178/  345]
Q_Learning:   179/  345]
Q_Learning:   180/  345]
Q_Learning:   181/  345]
Q_Learning:   182/  345]
Q_Learning:   183/  345]
Q_Learning:   184/  345]
Q_Learning:   185/  345]
Q_Learning:   186/  345]
Q_Learning:   187/  345]
Q_Learning:   188/  345]
Q_Learning:   189/  345]
Q_Learning:   190/  345]
Q_Learning:   191/  345]
Q_Learning:   192/  345]
Q_Learning:   193/  345]
Q_Learning:   194/  345]
Q_Learning:   195/  345]
Q_Learning:   196/  345]
Q_Learning:   197/  345]
Q_Learning:   198/  345]
Q_Learning:   199/  345]
Q_Learning:   200/  345]
Q_Learning:   201/  345]
Q_Learning:   202/  345]
Q_Learning:   203/  345]
Q_Learning:   204/  345]
Q_Learning:   205/  345]
Q_Learning:   206/  345]
Q_Learning:   207/  345]
Q_Learning:   208/  345]
Q_Learning:   209/  345]
Q_Learning:   210/  345]
Q_Learning:   211/  345]
Q_Learning:   212/  345]
Q_Learning:   213/  345]
Q_Learning:   214/  345]
Q_Learning:   215/  345]
Q_Learning:   216/  345]
Q_Learning:   217/  345]
Q_Learning:   218/  345]
Q_Learning:   219/  345]
Q_Learning:   220/  345]
Q_Learning:   221/  345]
Q_Learning:   222/  345]
Q_Learning:   223/  345]
Q_Learning:   224/  345]
Q_Learning:   225/  345]
Q_Learning:   226/  345]
Q_Learning:   227/  345]
Q_Learning:   228/  345]
Q_Learning:   229/  345]
Q_Learning:   230/  345]
Q_Learning:   231/  345]
Q_Learning:   232/  345]
Q_Learning:   233/  345]
Q_Learning:   234/  345]
Q_Learning:   235/  345]
Q_Learning:   236/  345]
Q_Learning:   237/  345]
Q_Learning:   238/  345]
Q_Learning:   239/  345]
Q_Learning:   240/  345]
Q_Learning:   241/  345]
Q_Learning:   242/  345]
Q_Learning:   243/  345]
Q_Learning:   244/  345]
Q_Learning:   245/  345]
Q_Learning:   246/  345]
Q_Learning:   247/  345]
Q_Learning:   248/  345]
Q_Learning:   249/  345]
Q_Learning:   250/  345]
Q_Learning:   251/  345]
Q_Learning:   252/  345]
Q_Learning:   253/  345]
Q_Learning:   254/  345]
Q_Learning:   255/  345]
Q_Learning:   256/  345]
Q_Learning:   257/  345]
Q_Learning:   258/  345]
Q_Learning:   259/  345]
Q_Learning:   260/  345]
Q_Learning:   261/  345]
Q_Learning:   262/  345]
Q_Learning:   263/  345]
Q_Learning:   264/  345]
Q_Learning:   265/  345]
Q_Learning:   266/  345]
Q_Learning:   267/  345]
Q_Learning:   268/  345]
Q_Learning:   269/  345]
Q_Learning:   270/  345]
Q_Learning:   271/  345]
Q_Learning:   272/  345]
Q_Learning:   273/  345]
Q_Learning:   274/  345]
Q_Learning:   275/  345]
Q_Learning:   276/  345]
Q_Learning:   277/  345]
Q_Learning:   278/  345]
Q_Learning:   279/  345]
Q_Learning:   280/  345]
Q_Learning:   281/  345]
Q_Learning:   282/  345]
Q_Learning:   283/  345]
Q_Learning:   284/  345]
Q_Learning:   285/  345]
Q_Learning:   286/  345]
Q_Learning:   287/  345]
Q_Learning:   288/  345]
Q_Learning:   289/  345]
Q_Learning:   290/  345]
Q_Learning:   291/  345]
Q_Learning:   292/  345]
Q_Learning:   293/  345]
Q_Learning:   294/  345]
Q_Learning:   295/  345]
Q_Learning:   296/  345]
Q_Learning:   297/  345]
Q_Learning:   298/  345]
Q_Learning:   299/  345]
Q_Learning:   300/  345]
Q_Learning:   301/  345]
Q_Learning:   302/  345]
Q_Learning:   303/  345]
Q_Learning:   304/  345]
Q_Learning:   305/  345]
Q_Learning:   306/  345]
Q_Learning:   307/  345]
Q_Learning:   308/  345]
Q_Learning:   309/  345]
Q_Learning:   310/  345]
Q_Learning:   311/  345]
Q_Learning:   312/  345]
Q_Learning:   313/  345]
Q_Learning:   314/  345]
Q_Learning:   315/  345]
Q_Learning:   316/  345]
Q_Learning:   317/  345]
Q_Learning:   318/  345]
Q_Learning:   319/  345]
Q_Learning:   320/  345]
Q_Learning:   321/  345]
Q_Learning:   322/  345]
Q_Learning:   323/  345]
Q_Learning:   324/  345]
Q_Learning:   325/  345]
Q_Learning:   326/  345]
Q_Learning:   327/  345]
Q_Learning:   328/  345]
Q_Learning:   329/  345]
Q_Learning:   330/  345]
Q_Learning:   331/  345]
Q_Learning:   332/  345]
Q_Learning:   333/  345]
Q_Learning:   334/  345]
Q_Learning:   335/  345]
Q_Learning:   336/  345]
Q_Learning:   337/  345]
Q_Learning:   338/  345]
Q_Learning:   339/  345]
Q_Learning:   340/  345]
Q_Learning:   341/  345]
Q_Learning:   342/  345]
Q_Learning:   343/  345]
Q_Learning:   344/  345]
Q_Learning:   345/  345]
Number of Samples after Autoencoder testing: 345
First Spike after testing: [1.4250228 1.3494582]
[0, 0, 1, 0, 1, 0, 0, 1, 2, 2, 1, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0, 2, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 2, 1, 0, 1, 0, 2, 1, 0, 2, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 0, 2, 1, 0, 1, 2, 1, 0, 2, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 1, 2, 0, 2, 2, 1, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 1, 1, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 2, 2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2]
[0, 1, 2, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 4, 5, 2, 2, 5, 3, 1, 1, 2, 6, 7, 3, 3, 1, 7, 4, 2, 7, 7, 2, 4, 1, 0, 0, 0, 2, 2, 2, 3, 2, 2, 7, 4, 8, 2, 4, 1, 1, 3, 3, 3, 1, 2, 3, 2, 2, 3, 0, 1, 2, 2, 1, 2, 7, 3, 2, 1, 3, 5, 1, 4, 0, 2, 7, 7, 2, 7, 7, 1, 7, 2, 3, 1, 1, 1, 1, 9, 7, 3, 2, 2, 3, 2, 2, 3, 3, 1, 2, 6, 1, 2, 2, 6, 3, 6, 7, 1, 2, 3, 6, 3, 2, 7, 2, 2, 3, 9, 1, 2, 3, 3, 3, 2, 9, 7, 3, 3, 2, 3, 3, 1, 3, 2, 1, 2, 3, 2, 1, 3, 1, 6, 6, 1, 3, 1, 2, 3, 3, 7, 3, 7, 3, 1, 2, 9, 2, 6, 3, 2, 3, 9, 7, 2, 6, 9, 0, 2, 6, 0, 1, 2, 2, 9, 6, 7, 2, 2, 1, 3, 1, 9, 2, 3, 3, 9, 3, 4, 3, 2, 7, 7, 6, 1, 1, 2, 2, 6, 2, 2, 1, 3, 2, 3, 1, 2, 7, 6, 9, 3, 2, 9, 7, 3, 6, 9, 1, 1, 6, 2, 9, 9, 2, 3, 2, 7, 6, 3, 2, 3, 6, 1, 1, 3, 2, 6, 1, 2, 6, 3, 3, 7, 1, 4, 7, 2, 6, 1, 6, 3, 2, 4, 3, 3, 4, 0, 0, 2, 4, 1, 3, 3, 1, 1, 9, 3, 1, 2, 1, 9, 1, 2, 1, 1, 3, 1, 3, 6, 3, 2, 9, 6, 9, 3, 2, 1, 6, 2, 2, 6, 1, 3, 0, 6, 7, 1, 2, 6, 7, 0, 1, 1, 1, 3, 3, 2, 1, 3, 2, 3, 2, 3, 2, 7, 2, 1, 1, 3, 2, 1, 2, 2, 6, 9, 10, 4, 7, 6, 7, 9, 1, 9, 3, 3, 1, 3, 7, 7, 7, 1, 6, 1, 3]
Centroids: [[0.49754947, 0.3739982], [-0.45524508, -0.3833118], [0.53747386, -0.2678013]]
Centroids: [[1.300399, 0.98597115], [0.0961829, 0.16366322], [-0.42016044, -0.39919415], [0.35679185, -0.3525857], [1.520071, 0.20745163], [2.8783996, 1.4372612], [-0.86248153, -0.538541], [0.75754106, 0.48525447], [2.253541, 0.8827697], [0.8511153, -0.16699888], [3.4785664, 1.5435677]]
Contingency Matrix: 
[[12 65  1  2  0  2  0 32  0  2  1]
 [ 0  3 79  2  1  1 31  1  1  0  0]
 [ 0  3  5 70 11  0  0  1  0 19  0]]
[[12, 65, -1, 2, 0, 2, 0, 32, 0, 2, 1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 3, -1, 70, 11, 0, 0, 1, 0, 19, 0]]
[[12, 65, -1, -1, 0, 2, 0, 32, 0, 2, 1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 2, 2: 3, 0: 1}
New Contingency Matrix: 
[[65  1  2 12  0  2  0 32  0  2  1]
 [ 3 79  2  0  1  1 31  1  1  0  0]
 [ 3  5 70  0 11  0  0  1  0 19  0]]
New Clustered Label Sequence: [1, 2, 3, 0, 4, 5, 6, 7, 8, 9, 10]
Diagonal_Elements: [65, 79, 70], Sum: 214
All_Elements: [65, 1, 2, 12, 0, 2, 0, 32, 0, 2, 1, 3, 79, 2, 0, 1, 1, 31, 1, 1, 0, 0, 3, 5, 70, 0, 11, 0, 0, 1, 0, 19, 0], Sum: 345
Accuracy: 0.6202898550724638
Done!
