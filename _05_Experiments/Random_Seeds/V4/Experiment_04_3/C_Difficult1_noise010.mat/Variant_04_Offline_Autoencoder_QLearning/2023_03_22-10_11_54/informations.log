Experiment_path: Random_Seeds//V4/Experiment_04_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_04_Offline_Autoencoder_QLearning
Visualisation_Path: Random_Seeds//V4/Experiment_04_3/C_Difficult1_noise010.mat/Variant_04_Offline_Autoencoder_QLearning/2023_03_22-10_11_54
Punishment_Coefficient: 0.32
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E38F7D5208>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
Train Index: 3103
x_train: 3103
y_train: 3103
x_test: 345
y_test: 345
<torch.utils.data.dataloader.DataLoader object at 0x000001E3969E9128>
<torch.utils.data.dataloader.DataLoader object at 0x000001E38DFBD390>
Epoch 1
-------------------------------
loss: 0.235271  [    0/ 3103]
loss: 0.061189  [  100/ 3103]
loss: 0.027590  [  200/ 3103]
loss: 0.034985  [  300/ 3103]
loss: 0.022766  [  400/ 3103]
loss: 0.014265  [  500/ 3103]
loss: 0.023259  [  600/ 3103]
loss: 0.011000  [  700/ 3103]
loss: 0.016009  [  800/ 3103]
loss: 0.025902  [  900/ 3103]
loss: 0.087431  [ 1000/ 3103]
loss: 0.014354  [ 1100/ 3103]
loss: 0.010802  [ 1200/ 3103]
loss: 0.129761  [ 1300/ 3103]
loss: 0.009501  [ 1400/ 3103]
loss: 0.026990  [ 1500/ 3103]
loss: 0.019881  [ 1600/ 3103]
loss: 0.014791  [ 1700/ 3103]
loss: 0.010393  [ 1800/ 3103]
loss: 0.015994  [ 1900/ 3103]
loss: 0.008445  [ 2000/ 3103]
loss: 0.004784  [ 2100/ 3103]
loss: 0.013171  [ 2200/ 3103]
loss: 0.007947  [ 2300/ 3103]
loss: 0.022975  [ 2400/ 3103]
loss: 0.007416  [ 2500/ 3103]
loss: 0.011682  [ 2600/ 3103]
loss: 0.014917  [ 2700/ 3103]
loss: 0.007690  [ 2800/ 3103]
loss: 0.009954  [ 2900/ 3103]
loss: 0.004080  [ 3000/ 3103]
loss: 0.016184  [ 3100/ 3103]
Epoch 2
-------------------------------
loss: 0.016554  [    0/ 3103]
loss: 0.008386  [  100/ 3103]
loss: 0.003784  [  200/ 3103]
loss: 0.008312  [  300/ 3103]
loss: 0.013137  [  400/ 3103]
loss: 0.013842  [  500/ 3103]
loss: 0.008660  [  600/ 3103]
loss: 0.009454  [  700/ 3103]
loss: 0.005831  [  800/ 3103]
loss: 0.010739  [  900/ 3103]
loss: 0.083802  [ 1000/ 3103]
loss: 0.010958  [ 1100/ 3103]
loss: 0.011028  [ 1200/ 3103]
loss: 0.129682  [ 1300/ 3103]
loss: 0.008219  [ 1400/ 3103]
loss: 0.012282  [ 1500/ 3103]
loss: 0.008764  [ 1600/ 3103]
loss: 0.012506  [ 1700/ 3103]
loss: 0.007977  [ 1800/ 3103]
loss: 0.017949  [ 1900/ 3103]
loss: 0.007207  [ 2000/ 3103]
loss: 0.004096  [ 2100/ 3103]
loss: 0.010414  [ 2200/ 3103]
loss: 0.006485  [ 2300/ 3103]
loss: 0.014386  [ 2400/ 3103]
loss: 0.006527  [ 2500/ 3103]
loss: 0.012704  [ 2600/ 3103]
loss: 0.007762  [ 2700/ 3103]
loss: 0.007586  [ 2800/ 3103]
loss: 0.002929  [ 2900/ 3103]
loss: 0.004216  [ 3000/ 3103]
loss: 0.017373  [ 3100/ 3103]
Epoch 3
-------------------------------
loss: 0.019961  [    0/ 3103]
loss: 0.008503  [  100/ 3103]
loss: 0.001453  [  200/ 3103]
loss: 0.002191  [  300/ 3103]
loss: 0.005422  [  400/ 3103]
loss: 0.014744  [  500/ 3103]
loss: 0.005474  [  600/ 3103]
loss: 0.008824  [  700/ 3103]
loss: 0.003746  [  800/ 3103]
loss: 0.006887  [  900/ 3103]
loss: 0.083383  [ 1000/ 3103]
loss: 0.014494  [ 1100/ 3103]
loss: 0.009615  [ 1200/ 3103]
loss: 0.125799  [ 1300/ 3103]
loss: 0.007017  [ 1400/ 3103]
loss: 0.018253  [ 1500/ 3103]
loss: 0.004507  [ 1600/ 3103]
loss: 0.012024  [ 1700/ 3103]
loss: 0.006944  [ 1800/ 3103]
loss: 0.018253  [ 1900/ 3103]
loss: 0.008026  [ 2000/ 3103]
loss: 0.003609  [ 2100/ 3103]
loss: 0.006347  [ 2200/ 3103]
loss: 0.005888  [ 2300/ 3103]
loss: 0.009100  [ 2400/ 3103]
loss: 0.007627  [ 2500/ 3103]
loss: 0.012789  [ 2600/ 3103]
loss: 0.008317  [ 2700/ 3103]
loss: 0.006990  [ 2800/ 3103]
loss: 0.002486  [ 2900/ 3103]
loss: 0.003997  [ 3000/ 3103]
loss: 0.014829  [ 3100/ 3103]
Epoch 4
-------------------------------
loss: 0.018859  [    0/ 3103]
loss: 0.007787  [  100/ 3103]
loss: 0.001803  [  200/ 3103]
loss: 0.003548  [  300/ 3103]
loss: 0.006515  [  400/ 3103]
loss: 0.013848  [  500/ 3103]
loss: 0.006098  [  600/ 3103]
loss: 0.008161  [  700/ 3103]
loss: 0.003797  [  800/ 3103]
loss: 0.006403  [  900/ 3103]
loss: 0.084868  [ 1000/ 3103]
loss: 0.014890  [ 1100/ 3103]
loss: 0.008920  [ 1200/ 3103]
loss: 0.125914  [ 1300/ 3103]
loss: 0.006630  [ 1400/ 3103]
loss: 0.020438  [ 1500/ 3103]
loss: 0.004034  [ 1600/ 3103]
loss: 0.011499  [ 1700/ 3103]
loss: 0.006857  [ 1800/ 3103]
loss: 0.018043  [ 1900/ 3103]
loss: 0.008179  [ 2000/ 3103]
loss: 0.003421  [ 2100/ 3103]
loss: 0.005511  [ 2200/ 3103]
loss: 0.005771  [ 2300/ 3103]
loss: 0.008383  [ 2400/ 3103]
loss: 0.007959  [ 2500/ 3103]
loss: 0.012745  [ 2600/ 3103]
loss: 0.008776  [ 2700/ 3103]
loss: 0.006765  [ 2800/ 3103]
loss: 0.002535  [ 2900/ 3103]
loss: 0.003912  [ 3000/ 3103]
loss: 0.013785  [ 3100/ 3103]
Epoch 5
-------------------------------
loss: 0.018201  [    0/ 3103]
loss: 0.007493  [  100/ 3103]
loss: 0.003351  [  200/ 3103]
loss: 0.003845  [  300/ 3103]
loss: 0.006925  [  400/ 3103]
loss: 0.013199  [  500/ 3103]
loss: 0.006332  [  600/ 3103]
loss: 0.008083  [  700/ 3103]
loss: 0.003974  [  800/ 3103]
loss: 0.005852  [  900/ 3103]
loss: 0.085109  [ 1000/ 3103]
loss: 0.014999  [ 1100/ 3103]
loss: 0.008490  [ 1200/ 3103]
loss: 0.125518  [ 1300/ 3103]
loss: 0.006499  [ 1400/ 3103]
loss: 0.020702  [ 1500/ 3103]
loss: 0.004556  [ 1600/ 3103]
loss: 0.011787  [ 1700/ 3103]
loss: 0.006886  [ 1800/ 3103]
loss: 0.018185  [ 1900/ 3103]
loss: 0.008245  [ 2000/ 3103]
loss: 0.003034  [ 2100/ 3103]
loss: 0.005340  [ 2200/ 3103]
loss: 0.005642  [ 2300/ 3103]
loss: 0.007913  [ 2400/ 3103]
loss: 0.008454  [ 2500/ 3103]
loss: 0.012095  [ 2600/ 3103]
loss: 0.009273  [ 2700/ 3103]
loss: 0.006464  [ 2800/ 3103]
loss: 0.002296  [ 2900/ 3103]
loss: 0.003879  [ 3000/ 3103]
loss: 0.012997  [ 3100/ 3103]
Epoch 6
-------------------------------
loss: 0.018415  [    0/ 3103]
loss: 0.007817  [  100/ 3103]
loss: 0.004438  [  200/ 3103]
loss: 0.003825  [  300/ 3103]
loss: 0.006518  [  400/ 3103]
loss: 0.012511  [  500/ 3103]
loss: 0.006460  [  600/ 3103]
loss: 0.008538  [  700/ 3103]
loss: 0.004361  [  800/ 3103]
loss: 0.006072  [  900/ 3103]
loss: 0.085231  [ 1000/ 3103]
loss: 0.015395  [ 1100/ 3103]
loss: 0.007864  [ 1200/ 3103]
loss: 0.124736  [ 1300/ 3103]
loss: 0.006618  [ 1400/ 3103]
loss: 0.020464  [ 1500/ 3103]
loss: 0.004507  [ 1600/ 3103]
loss: 0.012084  [ 1700/ 3103]
loss: 0.006747  [ 1800/ 3103]
loss: 0.018345  [ 1900/ 3103]
loss: 0.008066  [ 2000/ 3103]
loss: 0.003133  [ 2100/ 3103]
loss: 0.004988  [ 2200/ 3103]
loss: 0.005554  [ 2300/ 3103]
loss: 0.006657  [ 2400/ 3103]
loss: 0.008579  [ 2500/ 3103]
loss: 0.012220  [ 2600/ 3103]
loss: 0.009975  [ 2700/ 3103]
loss: 0.006120  [ 2800/ 3103]
loss: 0.002287  [ 2900/ 3103]
loss: 0.003882  [ 3000/ 3103]
loss: 0.012672  [ 3100/ 3103]
Epoch 7
-------------------------------
loss: 0.018945  [    0/ 3103]
loss: 0.008408  [  100/ 3103]
loss: 0.004739  [  200/ 3103]
loss: 0.003827  [  300/ 3103]
loss: 0.005713  [  400/ 3103]
loss: 0.012272  [  500/ 3103]
loss: 0.006607  [  600/ 3103]
loss: 0.008367  [  700/ 3103]
loss: 0.004541  [  800/ 3103]
loss: 0.006562  [  900/ 3103]
loss: 0.084985  [ 1000/ 3103]
loss: 0.015505  [ 1100/ 3103]
loss: 0.006655  [ 1200/ 3103]
loss: 0.124417  [ 1300/ 3103]
loss: 0.006699  [ 1400/ 3103]
loss: 0.020094  [ 1500/ 3103]
loss: 0.004386  [ 1600/ 3103]
loss: 0.011925  [ 1700/ 3103]
loss: 0.006771  [ 1800/ 3103]
loss: 0.018104  [ 1900/ 3103]
loss: 0.007948  [ 2000/ 3103]
loss: 0.002604  [ 2100/ 3103]
loss: 0.004898  [ 2200/ 3103]
loss: 0.005711  [ 2300/ 3103]
loss: 0.005451  [ 2400/ 3103]
loss: 0.008613  [ 2500/ 3103]
loss: 0.012032  [ 2600/ 3103]
loss: 0.008679  [ 2700/ 3103]
loss: 0.006026  [ 2800/ 3103]
loss: 0.002212  [ 2900/ 3103]
loss: 0.003941  [ 3000/ 3103]
loss: 0.012586  [ 3100/ 3103]
Epoch 8
-------------------------------
loss: 0.019780  [    0/ 3103]
loss: 0.007922  [  100/ 3103]
loss: 0.004781  [  200/ 3103]
loss: 0.004743  [  300/ 3103]
loss: 0.003814  [  400/ 3103]
loss: 0.012227  [  500/ 3103]
loss: 0.006838  [  600/ 3103]
loss: 0.007751  [  700/ 3103]
loss: 0.004582  [  800/ 3103]
loss: 0.006802  [  900/ 3103]
loss: 0.085553  [ 1000/ 3103]
loss: 0.015825  [ 1100/ 3103]
loss: 0.005716  [ 1200/ 3103]
loss: 0.124718  [ 1300/ 3103]
loss: 0.006157  [ 1400/ 3103]
loss: 0.020494  [ 1500/ 3103]
loss: 0.004039  [ 1600/ 3103]
loss: 0.010351  [ 1700/ 3103]
loss: 0.006694  [ 1800/ 3103]
loss: 0.018545  [ 1900/ 3103]
loss: 0.007903  [ 2000/ 3103]
loss: 0.002099  [ 2100/ 3103]
loss: 0.004422  [ 2200/ 3103]
loss: 0.006250  [ 2300/ 3103]
loss: 0.005280  [ 2400/ 3103]
loss: 0.009443  [ 2500/ 3103]
loss: 0.011239  [ 2600/ 3103]
loss: 0.008228  [ 2700/ 3103]
loss: 0.005738  [ 2800/ 3103]
loss: 0.002169  [ 2900/ 3103]
loss: 0.003935  [ 3000/ 3103]
loss: 0.013056  [ 3100/ 3103]
Number of Clusters: 3
Q_Learning:     1/  345]
Q_Learning:     2/  345]
Q_Learning:     3/  345]
Q_Learning:     4/  345]
Q_Learning:     5/  345]
Q_Learning:     6/  345]
Q_Learning:     7/  345]
Q_Learning:     8/  345]
Q_Learning:     9/  345]
Q_Learning:    10/  345]
Q_Learning:    11/  345]
Q_Learning:    12/  345]
Q_Learning:    13/  345]
Q_Learning:    14/  345]
Q_Learning:    15/  345]
Q_Learning:    16/  345]
Q_Learning:    17/  345]
Q_Learning:    18/  345]
Q_Learning:    19/  345]
Q_Learning:    20/  345]
Q_Learning:    21/  345]
Q_Learning:    22/  345]
Q_Learning:    23/  345]
Q_Learning:    24/  345]
Q_Learning:    25/  345]
Q_Learning:    26/  345]
Q_Learning:    27/  345]
Q_Learning:    28/  345]
Q_Learning:    29/  345]
Q_Learning:    30/  345]
Q_Learning:    31/  345]
Q_Learning:    32/  345]
Q_Learning:    33/  345]
Q_Learning:    34/  345]
Q_Learning:    35/  345]
Q_Learning:    36/  345]
Q_Learning:    37/  345]
Q_Learning:    38/  345]
Q_Learning:    39/  345]
Q_Learning:    40/  345]
Q_Learning:    41/  345]
Q_Learning:    42/  345]
Q_Learning:    43/  345]
Q_Learning:    44/  345]
Q_Learning:    45/  345]
Q_Learning:    46/  345]
Q_Learning:    47/  345]
Q_Learning:    48/  345]
Q_Learning:    49/  345]
Q_Learning:    50/  345]
Q_Learning:    51/  345]
Q_Learning:    52/  345]
Q_Learning:    53/  345]
Q_Learning:    54/  345]
Q_Learning:    55/  345]
Q_Learning:    56/  345]
Q_Learning:    57/  345]
Q_Learning:    58/  345]
Q_Learning:    59/  345]
Q_Learning:    60/  345]
Q_Learning:    61/  345]
Q_Learning:    62/  345]
Q_Learning:    63/  345]
Q_Learning:    64/  345]
Q_Learning:    65/  345]
Q_Learning:    66/  345]
Q_Learning:    67/  345]
Q_Learning:    68/  345]
Q_Learning:    69/  345]
Q_Learning:    70/  345]
Q_Learning:    71/  345]
Q_Learning:    72/  345]
Q_Learning:    73/  345]
Q_Learning:    74/  345]
Q_Learning:    75/  345]
Q_Learning:    76/  345]
Q_Learning:    77/  345]
Q_Learning:    78/  345]
Q_Learning:    79/  345]
Q_Learning:    80/  345]
Q_Learning:    81/  345]
Q_Learning:    82/  345]
Q_Learning:    83/  345]
Q_Learning:    84/  345]
Q_Learning:    85/  345]
Q_Learning:    86/  345]
Q_Learning:    87/  345]
Q_Learning:    88/  345]
Q_Learning:    89/  345]
Q_Learning:    90/  345]
Q_Learning:    91/  345]
Q_Learning:    92/  345]
Q_Learning:    93/  345]
Q_Learning:    94/  345]
Q_Learning:    95/  345]
Q_Learning:    96/  345]
Q_Learning:    97/  345]
Q_Learning:    98/  345]
Q_Learning:    99/  345]
Q_Learning:   100/  345]
Q_Learning:   101/  345]
Q_Learning:   102/  345]
Q_Learning:   103/  345]
Q_Learning:   104/  345]
Q_Learning:   105/  345]
Q_Learning:   106/  345]
Q_Learning:   107/  345]
Q_Learning:   108/  345]
Q_Learning:   109/  345]
Q_Learning:   110/  345]
Q_Learning:   111/  345]
Q_Learning:   112/  345]
Q_Learning:   113/  345]
Q_Learning:   114/  345]
Q_Learning:   115/  345]
Q_Learning:   116/  345]
Q_Learning:   117/  345]
Q_Learning:   118/  345]
Q_Learning:   119/  345]
Q_Learning:   120/  345]
Q_Learning:   121/  345]
Q_Learning:   122/  345]
Q_Learning:   123/  345]
Q_Learning:   124/  345]
Q_Learning:   125/  345]
Q_Learning:   126/  345]
Q_Learning:   127/  345]
Q_Learning:   128/  345]
Q_Learning:   129/  345]
Q_Learning:   130/  345]
Q_Learning:   131/  345]
Q_Learning:   132/  345]
Q_Learning:   133/  345]
Q_Learning:   134/  345]
Q_Learning:   135/  345]
Q_Learning:   136/  345]
Q_Learning:   137/  345]
Q_Learning:   138/  345]
Q_Learning:   139/  345]
Q_Learning:   140/  345]
Q_Learning:   141/  345]
Q_Learning:   142/  345]
Q_Learning:   143/  345]
Q_Learning:   144/  345]
Q_Learning:   145/  345]
Q_Learning:   146/  345]
Q_Learning:   147/  345]
Q_Learning:   148/  345]
Q_Learning:   149/  345]
Q_Learning:   150/  345]
Q_Learning:   151/  345]
Q_Learning:   152/  345]
Q_Learning:   153/  345]
Q_Learning:   154/  345]
Q_Learning:   155/  345]
Q_Learning:   156/  345]
Q_Learning:   157/  345]
Q_Learning:   158/  345]
Q_Learning:   159/  345]
Q_Learning:   160/  345]
Q_Learning:   161/  345]
Q_Learning:   162/  345]
Q_Learning:   163/  345]
Q_Learning:   164/  345]
Q_Learning:   165/  345]
Q_Learning:   166/  345]
Q_Learning:   167/  345]
Q_Learning:   168/  345]
Q_Learning:   169/  345]
Q_Learning:   170/  345]
Q_Learning:   171/  345]
Q_Learning:   172/  345]
Q_Learning:   173/  345]
Q_Learning:   174/  345]
Q_Learning:   175/  345]
Q_Learning:   176/  345]
Q_Learning:   177/  345]
Q_Learning:   178/  345]
Q_Learning:   179/  345]
Q_Learning:   180/  345]
Q_Learning:   181/  345]
Q_Learning:   182/  345]
Q_Learning:   183/  345]
Q_Learning:   184/  345]
Q_Learning:   185/  345]
Q_Learning:   186/  345]
Q_Learning:   187/  345]
Q_Learning:   188/  345]
Q_Learning:   189/  345]
Q_Learning:   190/  345]
Q_Learning:   191/  345]
Q_Learning:   192/  345]
Q_Learning:   193/  345]
Q_Learning:   194/  345]
Q_Learning:   195/  345]
Q_Learning:   196/  345]
Q_Learning:   197/  345]
Q_Learning:   198/  345]
Q_Learning:   199/  345]
Q_Learning:   200/  345]
Q_Learning:   201/  345]
Q_Learning:   202/  345]
Q_Learning:   203/  345]
Q_Learning:   204/  345]
Q_Learning:   205/  345]
Q_Learning:   206/  345]
Q_Learning:   207/  345]
Q_Learning:   208/  345]
Q_Learning:   209/  345]
Q_Learning:   210/  345]
Q_Learning:   211/  345]
Q_Learning:   212/  345]
Q_Learning:   213/  345]
Q_Learning:   214/  345]
Q_Learning:   215/  345]
Q_Learning:   216/  345]
Q_Learning:   217/  345]
Q_Learning:   218/  345]
Q_Learning:   219/  345]
Q_Learning:   220/  345]
Q_Learning:   221/  345]
Q_Learning:   222/  345]
Q_Learning:   223/  345]
Q_Learning:   224/  345]
Q_Learning:   225/  345]
Q_Learning:   226/  345]
Q_Learning:   227/  345]
Q_Learning:   228/  345]
Q_Learning:   229/  345]
Q_Learning:   230/  345]
Q_Learning:   231/  345]
Q_Learning:   232/  345]
Q_Learning:   233/  345]
Q_Learning:   234/  345]
Q_Learning:   235/  345]
Q_Learning:   236/  345]
Q_Learning:   237/  345]
Q_Learning:   238/  345]
Q_Learning:   239/  345]
Q_Learning:   240/  345]
Q_Learning:   241/  345]
Q_Learning:   242/  345]
Q_Learning:   243/  345]
Q_Learning:   244/  345]
Q_Learning:   245/  345]
Q_Learning:   246/  345]
Q_Learning:   247/  345]
Q_Learning:   248/  345]
Q_Learning:   249/  345]
Q_Learning:   250/  345]
Q_Learning:   251/  345]
Q_Learning:   252/  345]
Q_Learning:   253/  345]
Q_Learning:   254/  345]
Q_Learning:   255/  345]
Q_Learning:   256/  345]
Q_Learning:   257/  345]
Q_Learning:   258/  345]
Q_Learning:   259/  345]
Q_Learning:   260/  345]
Q_Learning:   261/  345]
Q_Learning:   262/  345]
Q_Learning:   263/  345]
Q_Learning:   264/  345]
Q_Learning:   265/  345]
Q_Learning:   266/  345]
Q_Learning:   267/  345]
Q_Learning:   268/  345]
Q_Learning:   269/  345]
Q_Learning:   270/  345]
Q_Learning:   271/  345]
Q_Learning:   272/  345]
Q_Learning:   273/  345]
Q_Learning:   274/  345]
Q_Learning:   275/  345]
Q_Learning:   276/  345]
Q_Learning:   277/  345]
Q_Learning:   278/  345]
Q_Learning:   279/  345]
Q_Learning:   280/  345]
Q_Learning:   281/  345]
Q_Learning:   282/  345]
Q_Learning:   283/  345]
Q_Learning:   284/  345]
Q_Learning:   285/  345]
Q_Learning:   286/  345]
Q_Learning:   287/  345]
Q_Learning:   288/  345]
Q_Learning:   289/  345]
Q_Learning:   290/  345]
Q_Learning:   291/  345]
Q_Learning:   292/  345]
Q_Learning:   293/  345]
Q_Learning:   294/  345]
Q_Learning:   295/  345]
Q_Learning:   296/  345]
Q_Learning:   297/  345]
Q_Learning:   298/  345]
Q_Learning:   299/  345]
Q_Learning:   300/  345]
Q_Learning:   301/  345]
Q_Learning:   302/  345]
Q_Learning:   303/  345]
Q_Learning:   304/  345]
Q_Learning:   305/  345]
Q_Learning:   306/  345]
Q_Learning:   307/  345]
Q_Learning:   308/  345]
Q_Learning:   309/  345]
Q_Learning:   310/  345]
Q_Learning:   311/  345]
Q_Learning:   312/  345]
Q_Learning:   313/  345]
Q_Learning:   314/  345]
Q_Learning:   315/  345]
Q_Learning:   316/  345]
Q_Learning:   317/  345]
Q_Learning:   318/  345]
Q_Learning:   319/  345]
Q_Learning:   320/  345]
Q_Learning:   321/  345]
Q_Learning:   322/  345]
Q_Learning:   323/  345]
Q_Learning:   324/  345]
Q_Learning:   325/  345]
Q_Learning:   326/  345]
Q_Learning:   327/  345]
Q_Learning:   328/  345]
Q_Learning:   329/  345]
Q_Learning:   330/  345]
Q_Learning:   331/  345]
Q_Learning:   332/  345]
Q_Learning:   333/  345]
Q_Learning:   334/  345]
Q_Learning:   335/  345]
Q_Learning:   336/  345]
Q_Learning:   337/  345]
Q_Learning:   338/  345]
Q_Learning:   339/  345]
Q_Learning:   340/  345]
Q_Learning:   341/  345]
Q_Learning:   342/  345]
Q_Learning:   343/  345]
Q_Learning:   344/  345]
Q_Learning:   345/  345]
Number of Samples after Autoencoder testing: 345
First Spike after testing: [ 0.3848445 -0.3991664]
[0, 0, 1, 0, 1, 0, 0, 1, 2, 2, 1, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0, 2, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 2, 1, 0, 1, 0, 2, 1, 0, 2, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 0, 2, 1, 0, 1, 2, 1, 0, 2, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 1, 2, 0, 2, 2, 1, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 1, 1, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 1, 2, 1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 2, 2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2]
[0, 0, 1, 0, 1, 0, 0, 1, 2, 1, 1, 0, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 4, 3, 2, 2, 0, 0, 2, 1, 0, 0, 1, 3, 0, 3, 0, 3, 1, 1, 1, 2, 4, 1, 0, 2, 3, 4, 2, 0, 0, 1, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 2, 3, 0, 2, 3, 0, 0, 3, 1, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, 3, 3, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1, 4, 0, 1, 1, 4, 2, 1, 0, 1, 1, 2, 1, 2, 1, 3, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 3, 2, 1, 4, 1, 2, 0, 2, 1, 0, 1, 2, 1, 0, 2, 0, 4, 4, 0, 2, 0, 1, 2, 2, 0, 1, 0, 2, 0, 1, 3, 1, 1, 1, 1, 2, 2, 0, 1, 5, 2, 3, 1, 4, 3, 0, 1, 1, 2, 4, 3, 4, 1, 0, 2, 0, 3, 1, 2, 3, 2, 2, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 4, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 0, 4, 1, 6, 6, 1, 2, 1, 0, 4, 2, 1, 2, 4, 0, 0, 2, 4, 4, 0, 1, 1, 2, 2, 0, 0, 3, 3, 0, 1, 0, 5, 2, 1, 7, 2, 2, 7, 3, 0, 1, 7, 0, 1, 2, 0, 0, 2, 2, 0, 1, 0, 7, 0, 1, 0, 0, 2, 0, 2, 5, 2, 1, 2, 4, 7, 2, 1, 0, 1, 1, 1, 4, 0, 2, 0, 4, 0, 0, 1, 4, 3, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 2, 1, 7, 1, 3, 1, 0, 0, 2, 1, 0, 1, 1, 4, 6, 8, 7, 3, 4, 3, 1, 1, 3, 2, 7, 0, 2, 0, 0, 3, 0, 4, 0, 2]
Centroids: [[0.15578073, -0.2353709], [-0.49330434, 0.39493254], [-0.70147514, -0.25420693]]
Centroids: [[0.18630193, -0.13767502], [-0.50329816, 0.31002367], [-0.7485606, -0.26929167], [-0.027998636, -0.5541261], [-0.7849893, 0.69627494], [-0.1678621, 0.99220604], [-1.0945494, -0.659488], [-0.4465087, -0.5396619], [-0.15924819, -1.2382842]]
Contingency Matrix: 
[[91  1  0 23  0  0  1  0  1]
 [ 6 84  2  2 22  3  0  0  0]
 [ 1 15 75  6  2  0  2  8  0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 84, 2, 2, 22, 3, 0, 0, 0], [-1, 15, 75, 6, 2, 0, 2, 8, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 75, 6, 2, 0, 2, 8, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[91  1  0 23  0  0  1  0  1]
 [ 6 84  2  2 22  3  0  0  0]
 [ 1 15 75  6  2  0  2  8  0]]
New Clustered Label Sequence: [0, 1, 2, 3, 4, 5, 6, 7, 8]
Diagonal_Elements: [91, 84, 75], Sum: 250
All_Elements: [91, 1, 0, 23, 0, 0, 1, 0, 1, 6, 84, 2, 2, 22, 3, 0, 0, 0, 1, 15, 75, 6, 2, 0, 2, 8, 0], Sum: 345
Accuracy: 0.7246376811594203
Done!
