Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Easy1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_42_38
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E739D0A048>
Sampling rate: 24000.0
Raw: [ 0.01223885  0.0148803   0.02156532 ... -0.02666729 -0.01215068
  0.01031338]
Times: [   1012    1333    1523 ... 1438660 1438690 1439287]
Cluster: [1 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3522
First aligned Spike Frame: [-0.12579972 -0.1620207  -0.18573939 -0.18961714 -0.17315203 -0.1396561
 -0.09426159 -0.04496221  0.00734136  0.05943689  0.09448878  0.07601101
  0.00811529  0.09446653  0.55421698  1.03008495  0.90195967  0.23116337
 -0.37857386 -0.59030761 -0.52695739 -0.40967661 -0.32471334 -0.26000903
 -0.19839489 -0.13975054 -0.09692457 -0.08223204 -0.09147337 -0.10695261
 -0.11338461 -0.10883018 -0.09915766 -0.08637804 -0.06514771 -0.03537735
 -0.00695045  0.01307529  0.02539335  0.03607991  0.04814655  0.05257424
  0.04538721  0.03512231  0.03354714  0.04141478  0.0511991 ]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1134
Cluster 2, Occurrences: 1237
<torch.utils.data.dataloader.DataLoader object at 0x000001E7328FBE10>
Epoch 1
-------------------------------
loss: 0.148136  [    0/ 3522]
loss: 0.266723  [  100/ 3522]
loss: 0.112647  [  200/ 3522]
loss: 0.064491  [  300/ 3522]
loss: 0.092889  [  400/ 3522]
loss: 0.085820  [  500/ 3522]
loss: 0.170572  [  600/ 3522]
loss: 0.017617  [  700/ 3522]
loss: 0.014861  [  800/ 3522]
loss: 0.007482  [  900/ 3522]
loss: 0.006038  [ 1000/ 3522]
loss: 0.005063  [ 1100/ 3522]
loss: 0.089169  [ 1200/ 3522]
loss: 0.017092  [ 1300/ 3522]
loss: 0.003909  [ 1400/ 3522]
loss: 0.004479  [ 1500/ 3522]
loss: 0.010423  [ 1600/ 3522]
loss: 0.009619  [ 1700/ 3522]
loss: 0.010067  [ 1800/ 3522]
loss: 0.015894  [ 1900/ 3522]
loss: 0.011438  [ 2000/ 3522]
loss: 0.014322  [ 2100/ 3522]
loss: 0.004849  [ 2200/ 3522]
loss: 0.005979  [ 2300/ 3522]
loss: 0.006525  [ 2400/ 3522]
loss: 0.004889  [ 2500/ 3522]
loss: 0.074376  [ 2600/ 3522]
loss: 0.010739  [ 2700/ 3522]
loss: 0.003469  [ 2800/ 3522]
loss: 0.004492  [ 2900/ 3522]
loss: 0.007466  [ 3000/ 3522]
loss: 0.006653  [ 3100/ 3522]
loss: 0.013954  [ 3200/ 3522]
loss: 0.008626  [ 3300/ 3522]
loss: 0.009615  [ 3400/ 3522]
loss: 0.007930  [ 3500/ 3522]
Epoch 2
-------------------------------
loss: 0.011056  [    0/ 3522]
loss: 0.007526  [  100/ 3522]
loss: 0.005458  [  200/ 3522]
loss: 0.041972  [  300/ 3522]
loss: 0.008753  [  400/ 3522]
loss: 0.009052  [  500/ 3522]
loss: 0.111790  [  600/ 3522]
loss: 0.015362  [  700/ 3522]
loss: 0.013507  [  800/ 3522]
loss: 0.004670  [  900/ 3522]
loss: 0.004431  [ 1000/ 3522]
loss: 0.004477  [ 1100/ 3522]
loss: 0.090932  [ 1200/ 3522]
loss: 0.015525  [ 1300/ 3522]
loss: 0.003187  [ 1400/ 3522]
loss: 0.003444  [ 1500/ 3522]
loss: 0.010009  [ 1600/ 3522]
loss: 0.008622  [ 1700/ 3522]
loss: 0.010414  [ 1800/ 3522]
loss: 0.014516  [ 1900/ 3522]
loss: 0.011515  [ 2000/ 3522]
loss: 0.013053  [ 2100/ 3522]
loss: 0.004979  [ 2200/ 3522]
loss: 0.005823  [ 2300/ 3522]
loss: 0.006356  [ 2400/ 3522]
loss: 0.004607  [ 2500/ 3522]
loss: 0.069818  [ 2600/ 3522]
loss: 0.009298  [ 2700/ 3522]
loss: 0.004390  [ 2800/ 3522]
loss: 0.004518  [ 2900/ 3522]
loss: 0.006932  [ 3000/ 3522]
loss: 0.006083  [ 3100/ 3522]
loss: 0.014326  [ 3200/ 3522]
loss: 0.008243  [ 3300/ 3522]
loss: 0.010437  [ 3400/ 3522]
loss: 0.006379  [ 3500/ 3522]
Epoch 3
-------------------------------
loss: 0.011292  [    0/ 3522]
loss: 0.007263  [  100/ 3522]
loss: 0.004827  [  200/ 3522]
loss: 0.034356  [  300/ 3522]
loss: 0.008418  [  400/ 3522]
loss: 0.008323  [  500/ 3522]
loss: 0.111472  [  600/ 3522]
loss: 0.015159  [  700/ 3522]
loss: 0.012909  [  800/ 3522]
loss: 0.003804  [  900/ 3522]
loss: 0.003758  [ 1000/ 3522]
loss: 0.004575  [ 1100/ 3522]
loss: 0.089565  [ 1200/ 3522]
loss: 0.014324  [ 1300/ 3522]
loss: 0.003648  [ 1400/ 3522]
loss: 0.003395  [ 1500/ 3522]
loss: 0.009699  [ 1600/ 3522]
loss: 0.009067  [ 1700/ 3522]
loss: 0.010852  [ 1800/ 3522]
loss: 0.013353  [ 1900/ 3522]
loss: 0.011472  [ 2000/ 3522]
loss: 0.010502  [ 2100/ 3522]
loss: 0.004932  [ 2200/ 3522]
loss: 0.005630  [ 2300/ 3522]
loss: 0.004236  [ 2400/ 3522]
loss: 0.004573  [ 2500/ 3522]
loss: 0.071962  [ 2600/ 3522]
loss: 0.008316  [ 2700/ 3522]
loss: 0.005017  [ 2800/ 3522]
loss: 0.004614  [ 2900/ 3522]
loss: 0.007750  [ 3000/ 3522]
loss: 0.005458  [ 3100/ 3522]
loss: 0.013425  [ 3200/ 3522]
loss: 0.008600  [ 3300/ 3522]
loss: 0.010709  [ 3400/ 3522]
loss: 0.005732  [ 3500/ 3522]
Epoch 4
-------------------------------
loss: 0.010545  [    0/ 3522]
loss: 0.006963  [  100/ 3522]
loss: 0.003981  [  200/ 3522]
loss: 0.021535  [  300/ 3522]
loss: 0.007595  [  400/ 3522]
loss: 0.008518  [  500/ 3522]
loss: 0.117765  [  600/ 3522]
loss: 0.014513  [  700/ 3522]
loss: 0.011777  [  800/ 3522]
loss: 0.003689  [  900/ 3522]
loss: 0.003233  [ 1000/ 3522]
loss: 0.004839  [ 1100/ 3522]
loss: 0.088636  [ 1200/ 3522]
loss: 0.013283  [ 1300/ 3522]
loss: 0.003835  [ 1400/ 3522]
loss: 0.003221  [ 1500/ 3522]
loss: 0.009729  [ 1600/ 3522]
loss: 0.009671  [ 1700/ 3522]
loss: 0.011650  [ 1800/ 3522]
loss: 0.011359  [ 1900/ 3522]
loss: 0.011168  [ 2000/ 3522]
loss: 0.007650  [ 2100/ 3522]
loss: 0.004625  [ 2200/ 3522]
loss: 0.005865  [ 2300/ 3522]
loss: 0.003494  [ 2400/ 3522]
loss: 0.004212  [ 2500/ 3522]
loss: 0.073359  [ 2600/ 3522]
loss: 0.008072  [ 2700/ 3522]
loss: 0.004747  [ 2800/ 3522]
loss: 0.004678  [ 2900/ 3522]
loss: 0.009297  [ 3000/ 3522]
loss: 0.005034  [ 3100/ 3522]
loss: 0.011938  [ 3200/ 3522]
loss: 0.009447  [ 3300/ 3522]
loss: 0.010700  [ 3400/ 3522]
loss: 0.006143  [ 3500/ 3522]
Epoch 5
-------------------------------
loss: 0.009201  [    0/ 3522]
loss: 0.007148  [  100/ 3522]
loss: 0.003441  [  200/ 3522]
loss: 0.014414  [  300/ 3522]
loss: 0.006957  [  400/ 3522]
loss: 0.008822  [  500/ 3522]
loss: 0.119403  [  600/ 3522]
loss: 0.014227  [  700/ 3522]
loss: 0.010802  [  800/ 3522]
loss: 0.003793  [  900/ 3522]
loss: 0.003100  [ 1000/ 3522]
loss: 0.004310  [ 1100/ 3522]
loss: 0.089928  [ 1200/ 3522]
loss: 0.013354  [ 1300/ 3522]
loss: 0.003540  [ 1400/ 3522]
loss: 0.002780  [ 1500/ 3522]
loss: 0.009889  [ 1600/ 3522]
loss: 0.009830  [ 1700/ 3522]
loss: 0.011778  [ 1800/ 3522]
loss: 0.011210  [ 1900/ 3522]
loss: 0.010753  [ 2000/ 3522]
loss: 0.007231  [ 2100/ 3522]
loss: 0.004152  [ 2200/ 3522]
loss: 0.005288  [ 2300/ 3522]
loss: 0.003379  [ 2400/ 3522]
loss: 0.003643  [ 2500/ 3522]
loss: 0.074077  [ 2600/ 3522]
loss: 0.007979  [ 2700/ 3522]
loss: 0.004559  [ 2800/ 3522]
loss: 0.004741  [ 2900/ 3522]
loss: 0.008685  [ 3000/ 3522]
loss: 0.005145  [ 3100/ 3522]
loss: 0.011017  [ 3200/ 3522]
loss: 0.009410  [ 3300/ 3522]
loss: 0.010592  [ 3400/ 3522]
loss: 0.006174  [ 3500/ 3522]
Epoch 6
-------------------------------
loss: 0.008148  [    0/ 3522]
loss: 0.007486  [  100/ 3522]
loss: 0.003433  [  200/ 3522]
loss: 0.012465  [  300/ 3522]
loss: 0.006898  [  400/ 3522]
loss: 0.008972  [  500/ 3522]
loss: 0.118736  [  600/ 3522]
loss: 0.013895  [  700/ 3522]
loss: 0.009980  [  800/ 3522]
loss: 0.004254  [  900/ 3522]
loss: 0.003134  [ 1000/ 3522]
loss: 0.003922  [ 1100/ 3522]
loss: 0.091747  [ 1200/ 3522]
loss: 0.013587  [ 1300/ 3522]
loss: 0.003326  [ 1400/ 3522]
loss: 0.002595  [ 1500/ 3522]
loss: 0.010010  [ 1600/ 3522]
loss: 0.010117  [ 1700/ 3522]
loss: 0.012021  [ 1800/ 3522]
loss: 0.011494  [ 1900/ 3522]
loss: 0.010300  [ 2000/ 3522]
loss: 0.007145  [ 2100/ 3522]
loss: 0.003689  [ 2200/ 3522]
loss: 0.005130  [ 2300/ 3522]
loss: 0.003129  [ 2400/ 3522]
loss: 0.003282  [ 2500/ 3522]
loss: 0.073959  [ 2600/ 3522]
loss: 0.007779  [ 2700/ 3522]
loss: 0.004611  [ 2800/ 3522]
loss: 0.004648  [ 2900/ 3522]
loss: 0.008253  [ 3000/ 3522]
loss: 0.004716  [ 3100/ 3522]
loss: 0.011144  [ 3200/ 3522]
loss: 0.009043  [ 3300/ 3522]
loss: 0.010347  [ 3400/ 3522]
loss: 0.006112  [ 3500/ 3522]
Epoch 7
-------------------------------
loss: 0.007454  [    0/ 3522]
loss: 0.007746  [  100/ 3522]
loss: 0.003478  [  200/ 3522]
loss: 0.011455  [  300/ 3522]
loss: 0.006976  [  400/ 3522]
loss: 0.009074  [  500/ 3522]
loss: 0.117378  [  600/ 3522]
loss: 0.013580  [  700/ 3522]
loss: 0.009400  [  800/ 3522]
loss: 0.004819  [  900/ 3522]
loss: 0.003148  [ 1000/ 3522]
loss: 0.003688  [ 1100/ 3522]
loss: 0.093821  [ 1200/ 3522]
loss: 0.013629  [ 1300/ 3522]
loss: 0.002953  [ 1400/ 3522]
loss: 0.002403  [ 1500/ 3522]
loss: 0.010032  [ 1600/ 3522]
loss: 0.009381  [ 1700/ 3522]
loss: 0.012182  [ 1800/ 3522]
loss: 0.011549  [ 1900/ 3522]
loss: 0.010040  [ 2000/ 3522]
loss: 0.007056  [ 2100/ 3522]
loss: 0.003423  [ 2200/ 3522]
loss: 0.005113  [ 2300/ 3522]
loss: 0.003172  [ 2400/ 3522]
loss: 0.002980  [ 2500/ 3522]
loss: 0.073826  [ 2600/ 3522]
loss: 0.007472  [ 2700/ 3522]
loss: 0.003916  [ 2800/ 3522]
loss: 0.004608  [ 2900/ 3522]
loss: 0.007889  [ 3000/ 3522]
loss: 0.004161  [ 3100/ 3522]
loss: 0.009764  [ 3200/ 3522]
loss: 0.008974  [ 3300/ 3522]
loss: 0.010282  [ 3400/ 3522]
loss: 0.006266  [ 3500/ 3522]
Epoch 8
-------------------------------
loss: 0.007131  [    0/ 3522]
loss: 0.008540  [  100/ 3522]
loss: 0.003616  [  200/ 3522]
loss: 0.011034  [  300/ 3522]
loss: 0.007084  [  400/ 3522]
loss: 0.009191  [  500/ 3522]
loss: 0.116199  [  600/ 3522]
loss: 0.013320  [  700/ 3522]
loss: 0.009001  [  800/ 3522]
loss: 0.005318  [  900/ 3522]
loss: 0.003208  [ 1000/ 3522]
loss: 0.003529  [ 1100/ 3522]
loss: 0.100097  [ 1200/ 3522]
loss: 0.013582  [ 1300/ 3522]
loss: 0.002896  [ 1400/ 3522]
loss: 0.002233  [ 1500/ 3522]
loss: 0.010006  [ 1600/ 3522]
loss: 0.009622  [ 1700/ 3522]
loss: 0.012220  [ 1800/ 3522]
loss: 0.011572  [ 1900/ 3522]
loss: 0.009858  [ 2000/ 3522]
loss: 0.006980  [ 2100/ 3522]
loss: 0.003183  [ 2200/ 3522]
loss: 0.005701  [ 2300/ 3522]
loss: 0.002991  [ 2400/ 3522]
loss: 0.002830  [ 2500/ 3522]
loss: 0.074081  [ 2600/ 3522]
loss: 0.007149  [ 2700/ 3522]
loss: 0.003756  [ 2800/ 3522]
loss: 0.004600  [ 2900/ 3522]
loss: 0.007531  [ 3000/ 3522]
loss: 0.004118  [ 3100/ 3522]
loss: 0.009274  [ 3200/ 3522]
loss: 0.008944  [ 3300/ 3522]
loss: 0.010264  [ 3400/ 3522]
loss: 0.006146  [ 3500/ 3522]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3522
First Spike after testing: [-0.86665636 -0.77602   ]
[0 2 2 ... 2 0 2]
[2 1 1 ... 1 2 1]
Cluster 0 Occurrences: 1151; KMEANS: 1123
Cluster 1 Occurrences: 1134; KMEANS: 1250
Cluster 2 Occurrences: 1237; KMEANS: 1149
Centroids: [[-0.9372729, -0.923615], [0.5132964, 2.2416334], [1.2502592, -1.0415641]]
Centroids: [[0.5220638, 2.2704165], [1.2471046, -1.0381956], [-0.9532733, -0.92377424]]
Contingency Matrix: 
[[   0    9 1142]
 [1120    8    6]
 [   3 1233    1]]
[[0, -1, 1142], [1120, -1, 6], [-1, -1, -1]]
[[-1, -1, -1], [1120, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[1142    0    9]
 [   6 1120    8]
 [   1    3 1233]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1142, 1120, 1233], Sum: 3495
All_Elements: [1142, 0, 9, 6, 1120, 8, 1, 3, 1233], Sum: 3522
Accuracy: 0.9923339011925043
Done!
