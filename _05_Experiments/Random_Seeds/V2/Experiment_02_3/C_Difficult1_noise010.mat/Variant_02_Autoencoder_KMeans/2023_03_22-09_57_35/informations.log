Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Difficult1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_57_35
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E739D0A048>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
<torch.utils.data.dataloader.DataLoader object at 0x000001E795D00C88>
Epoch 1
-------------------------------
loss: 0.235271  [    0/ 3448]
loss: 0.061189  [  100/ 3448]
loss: 0.027590  [  200/ 3448]
loss: 0.034985  [  300/ 3448]
loss: 0.022766  [  400/ 3448]
loss: 0.014265  [  500/ 3448]
loss: 0.023259  [  600/ 3448]
loss: 0.011000  [  700/ 3448]
loss: 0.016009  [  800/ 3448]
loss: 0.025902  [  900/ 3448]
loss: 0.087431  [ 1000/ 3448]
loss: 0.014354  [ 1100/ 3448]
loss: 0.010802  [ 1200/ 3448]
loss: 0.129761  [ 1300/ 3448]
loss: 0.009501  [ 1400/ 3448]
loss: 0.026990  [ 1500/ 3448]
loss: 0.019881  [ 1600/ 3448]
loss: 0.014791  [ 1700/ 3448]
loss: 0.010393  [ 1800/ 3448]
loss: 0.015994  [ 1900/ 3448]
loss: 0.008445  [ 2000/ 3448]
loss: 0.004784  [ 2100/ 3448]
loss: 0.013171  [ 2200/ 3448]
loss: 0.007947  [ 2300/ 3448]
loss: 0.022975  [ 2400/ 3448]
loss: 0.007416  [ 2500/ 3448]
loss: 0.011682  [ 2600/ 3448]
loss: 0.014917  [ 2700/ 3448]
loss: 0.007690  [ 2800/ 3448]
loss: 0.009954  [ 2900/ 3448]
loss: 0.004080  [ 3000/ 3448]
loss: 0.016184  [ 3100/ 3448]
loss: 0.009757  [ 3200/ 3448]
loss: 0.013114  [ 3300/ 3448]
loss: 0.007085  [ 3400/ 3448]
Epoch 2
-------------------------------
loss: 0.019271  [    0/ 3448]
loss: 0.008587  [  100/ 3448]
loss: 0.002905  [  200/ 3448]
loss: 0.006038  [  300/ 3448]
loss: 0.010566  [  400/ 3448]
loss: 0.014572  [  500/ 3448]
loss: 0.007318  [  600/ 3448]
loss: 0.009466  [  700/ 3448]
loss: 0.005139  [  800/ 3448]
loss: 0.009692  [  900/ 3448]
loss: 0.082781  [ 1000/ 3448]
loss: 0.011716  [ 1100/ 3448]
loss: 0.010990  [ 1200/ 3448]
loss: 0.128947  [ 1300/ 3448]
loss: 0.007975  [ 1400/ 3448]
loss: 0.012798  [ 1500/ 3448]
loss: 0.007414  [ 1600/ 3448]
loss: 0.012492  [ 1700/ 3448]
loss: 0.007548  [ 1800/ 3448]
loss: 0.018076  [ 1900/ 3448]
loss: 0.007454  [ 2000/ 3448]
loss: 0.003991  [ 2100/ 3448]
loss: 0.009388  [ 2200/ 3448]
loss: 0.006337  [ 2300/ 3448]
loss: 0.013073  [ 2400/ 3448]
loss: 0.006723  [ 2500/ 3448]
loss: 0.012747  [ 2600/ 3448]
loss: 0.007652  [ 2700/ 3448]
loss: 0.007491  [ 2800/ 3448]
loss: 0.002777  [ 2900/ 3448]
loss: 0.004192  [ 3000/ 3448]
loss: 0.017059  [ 3100/ 3448]
loss: 0.011179  [ 3200/ 3448]
loss: 0.010374  [ 3300/ 3448]
loss: 0.006592  [ 3400/ 3448]
Epoch 3
-------------------------------
loss: 0.021535  [    0/ 3448]
loss: 0.008392  [  100/ 3448]
loss: 0.001396  [  200/ 3448]
loss: 0.002797  [  300/ 3448]
loss: 0.005635  [  400/ 3448]
loss: 0.014395  [  500/ 3448]
loss: 0.005576  [  600/ 3448]
loss: 0.008631  [  700/ 3448]
loss: 0.003667  [  800/ 3448]
loss: 0.006602  [  900/ 3448]
loss: 0.083734  [ 1000/ 3448]
loss: 0.014832  [ 1100/ 3448]
loss: 0.009522  [ 1200/ 3448]
loss: 0.125848  [ 1300/ 3448]
loss: 0.006841  [ 1400/ 3448]
loss: 0.019031  [ 1500/ 3448]
loss: 0.004280  [ 1600/ 3448]
loss: 0.011858  [ 1700/ 3448]
loss: 0.006827  [ 1800/ 3448]
loss: 0.018541  [ 1900/ 3448]
loss: 0.008116  [ 2000/ 3448]
loss: 0.003551  [ 2100/ 3448]
loss: 0.006090  [ 2200/ 3448]
loss: 0.005828  [ 2300/ 3448]
loss: 0.008824  [ 2400/ 3448]
loss: 0.007741  [ 2500/ 3448]
loss: 0.012775  [ 2600/ 3448]
loss: 0.008418  [ 2700/ 3448]
loss: 0.006921  [ 2800/ 3448]
loss: 0.002501  [ 2900/ 3448]
loss: 0.003970  [ 3000/ 3448]
loss: 0.014524  [ 3100/ 3448]
loss: 0.012641  [ 3200/ 3448]
loss: 0.010823  [ 3300/ 3448]
loss: 0.006768  [ 3400/ 3448]
Epoch 4
-------------------------------
loss: 0.020470  [    0/ 3448]
loss: 0.007705  [  100/ 3448]
loss: 0.001713  [  200/ 3448]
loss: 0.003806  [  300/ 3448]
loss: 0.006830  [  400/ 3448]
loss: 0.013670  [  500/ 3448]
loss: 0.006220  [  600/ 3448]
loss: 0.008071  [  700/ 3448]
loss: 0.003789  [  800/ 3448]
loss: 0.006346  [  900/ 3448]
loss: 0.084708  [ 1000/ 3448]
loss: 0.015017  [ 1100/ 3448]
loss: 0.008933  [ 1200/ 3448]
loss: 0.125980  [ 1300/ 3448]
loss: 0.006528  [ 1400/ 3448]
loss: 0.020723  [ 1500/ 3448]
loss: 0.003954  [ 1600/ 3448]
loss: 0.011401  [ 1700/ 3448]
loss: 0.006804  [ 1800/ 3448]
loss: 0.018299  [ 1900/ 3448]
loss: 0.008194  [ 2000/ 3448]
loss: 0.003401  [ 2100/ 3448]
loss: 0.005436  [ 2200/ 3448]
loss: 0.005769  [ 2300/ 3448]
loss: 0.008364  [ 2400/ 3448]
loss: 0.008016  [ 2500/ 3448]
loss: 0.012723  [ 2600/ 3448]
loss: 0.008843  [ 2700/ 3448]
loss: 0.006736  [ 2800/ 3448]
loss: 0.002527  [ 2900/ 3448]
loss: 0.003891  [ 3000/ 3448]
loss: 0.013698  [ 3100/ 3448]
loss: 0.012855  [ 3200/ 3448]
loss: 0.011032  [ 3300/ 3448]
loss: 0.006988  [ 3400/ 3448]
Epoch 5
-------------------------------
loss: 0.020106  [    0/ 3448]
loss: 0.007440  [  100/ 3448]
loss: 0.003127  [  200/ 3448]
loss: 0.004752  [  300/ 3448]
loss: 0.007039  [  400/ 3448]
loss: 0.013291  [  500/ 3448]
loss: 0.006402  [  600/ 3448]
loss: 0.008102  [  700/ 3448]
loss: 0.004065  [  800/ 3448]
loss: 0.005568  [  900/ 3448]
loss: 0.085137  [ 1000/ 3448]
loss: 0.015088  [ 1100/ 3448]
loss: 0.008753  [ 1200/ 3448]
loss: 0.125646  [ 1300/ 3448]
loss: 0.006466  [ 1400/ 3448]
loss: 0.020633  [ 1500/ 3448]
loss: 0.005204  [ 1600/ 3448]
loss: 0.011634  [ 1700/ 3448]
loss: 0.006919  [ 1800/ 3448]
loss: 0.018329  [ 1900/ 3448]
loss: 0.008233  [ 2000/ 3448]
loss: 0.003165  [ 2100/ 3448]
loss: 0.005342  [ 2200/ 3448]
loss: 0.005699  [ 2300/ 3448]
loss: 0.007493  [ 2400/ 3448]
loss: 0.008295  [ 2500/ 3448]
loss: 0.012264  [ 2600/ 3448]
loss: 0.009299  [ 2700/ 3448]
loss: 0.006347  [ 2800/ 3448]
loss: 0.002293  [ 2900/ 3448]
loss: 0.003880  [ 3000/ 3448]
loss: 0.012976  [ 3100/ 3448]
loss: 0.012788  [ 3200/ 3448]
loss: 0.010992  [ 3300/ 3448]
loss: 0.007039  [ 3400/ 3448]
Epoch 6
-------------------------------
loss: 0.020357  [    0/ 3448]
loss: 0.007609  [  100/ 3448]
loss: 0.004039  [  200/ 3448]
loss: 0.004184  [  300/ 3448]
loss: 0.006679  [  400/ 3448]
loss: 0.012773  [  500/ 3448]
loss: 0.006440  [  600/ 3448]
loss: 0.008317  [  700/ 3448]
loss: 0.004400  [  800/ 3448]
loss: 0.005806  [  900/ 3448]
loss: 0.085479  [ 1000/ 3448]
loss: 0.015359  [ 1100/ 3448]
loss: 0.008169  [ 1200/ 3448]
loss: 0.124960  [ 1300/ 3448]
loss: 0.006600  [ 1400/ 3448]
loss: 0.020466  [ 1500/ 3448]
loss: 0.005315  [ 1600/ 3448]
loss: 0.012017  [ 1700/ 3448]
loss: 0.006921  [ 1800/ 3448]
loss: 0.018154  [ 1900/ 3448]
loss: 0.008031  [ 2000/ 3448]
loss: 0.003133  [ 2100/ 3448]
loss: 0.005087  [ 2200/ 3448]
loss: 0.005661  [ 2300/ 3448]
loss: 0.006658  [ 2400/ 3448]
loss: 0.008452  [ 2500/ 3448]
loss: 0.012293  [ 2600/ 3448]
loss: 0.009469  [ 2700/ 3448]
loss: 0.006218  [ 2800/ 3448]
loss: 0.002274  [ 2900/ 3448]
loss: 0.003911  [ 3000/ 3448]
loss: 0.012872  [ 3100/ 3448]
loss: 0.012696  [ 3200/ 3448]
loss: 0.011070  [ 3300/ 3448]
loss: 0.006827  [ 3400/ 3448]
Epoch 7
-------------------------------
loss: 0.020539  [    0/ 3448]
loss: 0.007774  [  100/ 3448]
loss: 0.004157  [  200/ 3448]
loss: 0.004040  [  300/ 3448]
loss: 0.004494  [  400/ 3448]
loss: 0.012665  [  500/ 3448]
loss: 0.006590  [  600/ 3448]
loss: 0.007854  [  700/ 3448]
loss: 0.004657  [  800/ 3448]
loss: 0.006399  [  900/ 3448]
loss: 0.085570  [ 1000/ 3448]
loss: 0.015510  [ 1100/ 3448]
loss: 0.006750  [ 1200/ 3448]
loss: 0.124529  [ 1300/ 3448]
loss: 0.006698  [ 1400/ 3448]
loss: 0.019931  [ 1500/ 3448]
loss: 0.004706  [ 1600/ 3448]
loss: 0.011901  [ 1700/ 3448]
loss: 0.006760  [ 1800/ 3448]
loss: 0.018224  [ 1900/ 3448]
loss: 0.007970  [ 2000/ 3448]
loss: 0.002772  [ 2100/ 3448]
loss: 0.004846  [ 2200/ 3448]
loss: 0.005798  [ 2300/ 3448]
loss: 0.006516  [ 2400/ 3448]
loss: 0.008891  [ 2500/ 3448]
loss: 0.012092  [ 2600/ 3448]
loss: 0.008378  [ 2700/ 3448]
loss: 0.006111  [ 2800/ 3448]
loss: 0.002142  [ 2900/ 3448]
loss: 0.003937  [ 3000/ 3448]
loss: 0.012614  [ 3100/ 3448]
loss: 0.012068  [ 3200/ 3448]
loss: 0.011377  [ 3300/ 3448]
loss: 0.006311  [ 3400/ 3448]
Epoch 8
-------------------------------
loss: 0.021064  [    0/ 3448]
loss: 0.007502  [  100/ 3448]
loss: 0.004018  [  200/ 3448]
loss: 0.004959  [  300/ 3448]
loss: 0.003385  [  400/ 3448]
loss: 0.012563  [  500/ 3448]
loss: 0.007034  [  600/ 3448]
loss: 0.007181  [  700/ 3448]
loss: 0.004676  [  800/ 3448]
loss: 0.006532  [  900/ 3448]
loss: 0.085742  [ 1000/ 3448]
loss: 0.015893  [ 1100/ 3448]
loss: 0.005802  [ 1200/ 3448]
loss: 0.124631  [ 1300/ 3448]
loss: 0.006201  [ 1400/ 3448]
loss: 0.020228  [ 1500/ 3448]
loss: 0.004528  [ 1600/ 3448]
loss: 0.010263  [ 1700/ 3448]
loss: 0.006736  [ 1800/ 3448]
loss: 0.018490  [ 1900/ 3448]
loss: 0.007879  [ 2000/ 3448]
loss: 0.002245  [ 2100/ 3448]
loss: 0.004473  [ 2200/ 3448]
loss: 0.006354  [ 2300/ 3448]
loss: 0.005992  [ 2400/ 3448]
loss: 0.009597  [ 2500/ 3448]
loss: 0.011100  [ 2600/ 3448]
loss: 0.008230  [ 2700/ 3448]
loss: 0.006006  [ 2800/ 3448]
loss: 0.002129  [ 2900/ 3448]
loss: 0.003949  [ 3000/ 3448]
loss: 0.013141  [ 3100/ 3448]
loss: 0.011100  [ 3200/ 3448]
loss: 0.011233  [ 3300/ 3448]
loss: 0.005770  [ 3400/ 3448]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3448
First Spike after testing: [-0.32460093 -0.26525065]
[2 2 2 ... 1 0 2]
[0 0 0 ... 1 2 0]
Cluster 0 Occurrences: 1164; KMEANS: 1036
Cluster 1 Occurrences: 1155; KMEANS: 1145
Cluster 2 Occurrences: 1129; KMEANS: 1267
Centroids: [[0.09453549, -0.16498245], [-0.55492675, 0.42604795], [-0.67210555, -0.25108284]]
Centroids: [[-0.64827186, -0.30864796], [-0.6382232, 0.47560522], [0.088924065, -0.16435312]]
Contingency Matrix: 
[[  27   14 1123]
 [  74  998   83]
 [ 935  133   61]]
[[-1, -1, -1], [74, 998, -1], [935, 133, -1]]
[[-1, -1, -1], [-1, -1, -1], [935, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 1: 1, 2: 0}
New Contingency Matrix: 
[[1123   14   27]
 [  83  998   74]
 [  61  133  935]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1123, 998, 935], Sum: 3056
All_Elements: [1123, 14, 27, 83, 998, 74, 61, 133, 935], Sum: 3448
Accuracy: 0.8863109048723898
Done!
