Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Difficult2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_02_18
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E73AAA8CC0>
Sampling rate: 24000.0
Raw: [ 0.02085333  0.02043967  0.02052644 ... -0.02218732 -0.02150573
 -0.01811243]
Times: [   1583    1934    2430 ... 1439313 1439656 1439854]
Cluster: [3 3 3 ... 2 2 1]
Number of different clusters:  3
Number of Spikes: 3364
First aligned Spike Frame: [-0.05170878 -0.0548761  -0.06029554 -0.06053219 -0.04807119 -0.02780025
 -0.01550543 -0.01702494 -0.02945104 -0.04493807 -0.07056858 -0.07003585
  0.07629654  0.43081562  0.80470191  0.96319627  0.89198123  0.73643948
  0.58987232  0.46714337  0.36345495  0.2828462   0.22743292  0.182731
  0.13931053  0.09524506  0.05136602  0.01367166 -0.01393093 -0.03985679
 -0.07387102 -0.11218435 -0.1444455  -0.16672578 -0.17809238 -0.18020802
 -0.17953732 -0.18246903 -0.18617363 -0.18205375 -0.17299738 -0.16958427
 -0.17248955 -0.17516876 -0.1727246  -0.16696514 -0.15993314]
Cluster 0, Occurrences: 1120
Cluster 1, Occurrences: 1109
Cluster 2, Occurrences: 1135
<torch.utils.data.dataloader.DataLoader object at 0x000001E795D00DA0>
Epoch 1
-------------------------------
loss: 0.183194  [    0/ 3364]
loss: 0.084301  [  100/ 3364]
loss: 0.028994  [  200/ 3364]
loss: 0.013937  [  300/ 3364]
loss: 0.002628  [  400/ 3364]
loss: 0.036695  [  500/ 3364]
loss: 0.007732  [  600/ 3364]
loss: 0.010399  [  700/ 3364]
loss: 0.004321  [  800/ 3364]
loss: 0.015513  [  900/ 3364]
loss: 0.014472  [ 1000/ 3364]
loss: 0.004178  [ 1100/ 3364]
loss: 0.010083  [ 1200/ 3364]
loss: 0.006776  [ 1300/ 3364]
loss: 0.085166  [ 1400/ 3364]
loss: 0.004764  [ 1500/ 3364]
loss: 0.006501  [ 1600/ 3364]
loss: 0.006879  [ 1700/ 3364]
loss: 0.003060  [ 1800/ 3364]
loss: 0.004925  [ 1900/ 3364]
loss: 0.005216  [ 2000/ 3364]
loss: 0.007381  [ 2100/ 3364]
loss: 0.004073  [ 2200/ 3364]
loss: 0.008589  [ 2300/ 3364]
loss: 0.002214  [ 2400/ 3364]
loss: 0.003973  [ 2500/ 3364]
loss: 0.003601  [ 2600/ 3364]
loss: 0.004692  [ 2700/ 3364]
loss: 0.003852  [ 2800/ 3364]
loss: 0.002883  [ 2900/ 3364]
loss: 0.005721  [ 3000/ 3364]
loss: 0.006442  [ 3100/ 3364]
loss: 0.001922  [ 3200/ 3364]
loss: 0.001131  [ 3300/ 3364]
Epoch 2
-------------------------------
loss: 0.001610  [    0/ 3364]
loss: 0.002493  [  100/ 3364]
loss: 0.005478  [  200/ 3364]
loss: 0.001324  [  300/ 3364]
loss: 0.000887  [  400/ 3364]
loss: 0.030900  [  500/ 3364]
loss: 0.004101  [  600/ 3364]
loss: 0.005259  [  700/ 3364]
loss: 0.002782  [  800/ 3364]
loss: 0.003587  [  900/ 3364]
loss: 0.003405  [ 1000/ 3364]
loss: 0.003606  [ 1100/ 3364]
loss: 0.002233  [ 1200/ 3364]
loss: 0.005216  [ 1300/ 3364]
loss: 0.084855  [ 1400/ 3364]
loss: 0.002719  [ 1500/ 3364]
loss: 0.006027  [ 1600/ 3364]
loss: 0.002776  [ 1700/ 3364]
loss: 0.001630  [ 1800/ 3364]
loss: 0.003570  [ 1900/ 3364]
loss: 0.002221  [ 2000/ 3364]
loss: 0.004070  [ 2100/ 3364]
loss: 0.004124  [ 2200/ 3364]
loss: 0.006473  [ 2300/ 3364]
loss: 0.000960  [ 2400/ 3364]
loss: 0.002368  [ 2500/ 3364]
loss: 0.001883  [ 2600/ 3364]
loss: 0.003673  [ 2700/ 3364]
loss: 0.004046  [ 2800/ 3364]
loss: 0.001847  [ 2900/ 3364]
loss: 0.003815  [ 3000/ 3364]
loss: 0.006171  [ 3100/ 3364]
loss: 0.001794  [ 3200/ 3364]
loss: 0.001347  [ 3300/ 3364]
Epoch 3
-------------------------------
loss: 0.001607  [    0/ 3364]
loss: 0.002406  [  100/ 3364]
loss: 0.005166  [  200/ 3364]
loss: 0.000845  [  300/ 3364]
loss: 0.000712  [  400/ 3364]
loss: 0.032226  [  500/ 3364]
loss: 0.004048  [  600/ 3364]
loss: 0.005272  [  700/ 3364]
loss: 0.002966  [  800/ 3364]
loss: 0.003513  [  900/ 3364]
loss: 0.002846  [ 1000/ 3364]
loss: 0.003725  [ 1100/ 3364]
loss: 0.002064  [ 1200/ 3364]
loss: 0.005366  [ 1300/ 3364]
loss: 0.084831  [ 1400/ 3364]
loss: 0.002576  [ 1500/ 3364]
loss: 0.005890  [ 1600/ 3364]
loss: 0.002668  [ 1700/ 3364]
loss: 0.001474  [ 1800/ 3364]
loss: 0.003502  [ 1900/ 3364]
loss: 0.002211  [ 2000/ 3364]
loss: 0.003780  [ 2100/ 3364]
loss: 0.004309  [ 2200/ 3364]
loss: 0.006248  [ 2300/ 3364]
loss: 0.000913  [ 2400/ 3364]
loss: 0.002171  [ 2500/ 3364]
loss: 0.001710  [ 2600/ 3364]
loss: 0.003736  [ 2700/ 3364]
loss: 0.004190  [ 2800/ 3364]
loss: 0.001934  [ 2900/ 3364]
loss: 0.003512  [ 3000/ 3364]
loss: 0.005747  [ 3100/ 3364]
loss: 0.001810  [ 3200/ 3364]
loss: 0.001763  [ 3300/ 3364]
Epoch 4
-------------------------------
loss: 0.001605  [    0/ 3364]
loss: 0.002428  [  100/ 3364]
loss: 0.004977  [  200/ 3364]
loss: 0.000944  [  300/ 3364]
loss: 0.000910  [  400/ 3364]
loss: 0.035574  [  500/ 3364]
loss: 0.004128  [  600/ 3364]
loss: 0.004965  [  700/ 3364]
loss: 0.002902  [  800/ 3364]
loss: 0.003704  [  900/ 3364]
loss: 0.002908  [ 1000/ 3364]
loss: 0.003591  [ 1100/ 3364]
loss: 0.002080  [ 1200/ 3364]
loss: 0.005787  [ 1300/ 3364]
loss: 0.083396  [ 1400/ 3364]
loss: 0.002744  [ 1500/ 3364]
loss: 0.005879  [ 1600/ 3364]
loss: 0.002680  [ 1700/ 3364]
loss: 0.001481  [ 1800/ 3364]
loss: 0.003483  [ 1900/ 3364]
loss: 0.002128  [ 2000/ 3364]
loss: 0.003684  [ 2100/ 3364]
loss: 0.004481  [ 2200/ 3364]
loss: 0.006056  [ 2300/ 3364]
loss: 0.001201  [ 2400/ 3364]
loss: 0.001936  [ 2500/ 3364]
loss: 0.001534  [ 2600/ 3364]
loss: 0.003547  [ 2700/ 3364]
loss: 0.004041  [ 2800/ 3364]
loss: 0.001948  [ 2900/ 3364]
loss: 0.003050  [ 3000/ 3364]
loss: 0.005502  [ 3100/ 3364]
loss: 0.001720  [ 3200/ 3364]
loss: 0.001611  [ 3300/ 3364]
Epoch 5
-------------------------------
loss: 0.001685  [    0/ 3364]
loss: 0.002451  [  100/ 3364]
loss: 0.004583  [  200/ 3364]
loss: 0.000756  [  300/ 3364]
loss: 0.000948  [  400/ 3364]
loss: 0.035556  [  500/ 3364]
loss: 0.004315  [  600/ 3364]
loss: 0.004770  [  700/ 3364]
loss: 0.002900  [  800/ 3364]
loss: 0.003361  [  900/ 3364]
loss: 0.002600  [ 1000/ 3364]
loss: 0.003953  [ 1100/ 3364]
loss: 0.002180  [ 1200/ 3364]
loss: 0.005993  [ 1300/ 3364]
loss: 0.083007  [ 1400/ 3364]
loss: 0.002756  [ 1500/ 3364]
loss: 0.005777  [ 1600/ 3364]
loss: 0.002657  [ 1700/ 3364]
loss: 0.001454  [ 1800/ 3364]
loss: 0.003473  [ 1900/ 3364]
loss: 0.002172  [ 2000/ 3364]
loss: 0.003552  [ 2100/ 3364]
loss: 0.004165  [ 2200/ 3364]
loss: 0.005665  [ 2300/ 3364]
loss: 0.001540  [ 2400/ 3364]
loss: 0.002268  [ 2500/ 3364]
loss: 0.001615  [ 2600/ 3364]
loss: 0.003346  [ 2700/ 3364]
loss: 0.003758  [ 2800/ 3364]
loss: 0.001869  [ 2900/ 3364]
loss: 0.003549  [ 3000/ 3364]
loss: 0.005313  [ 3100/ 3364]
loss: 0.001617  [ 3200/ 3364]
loss: 0.002455  [ 3300/ 3364]
Epoch 6
-------------------------------
loss: 0.001536  [    0/ 3364]
loss: 0.002427  [  100/ 3364]
loss: 0.004584  [  200/ 3364]
loss: 0.000603  [  300/ 3364]
loss: 0.000957  [  400/ 3364]
loss: 0.034542  [  500/ 3364]
loss: 0.004406  [  600/ 3364]
loss: 0.005520  [  700/ 3364]
loss: 0.002826  [  800/ 3364]
loss: 0.002222  [  900/ 3364]
loss: 0.002438  [ 1000/ 3364]
loss: 0.004322  [ 1100/ 3364]
loss: 0.002185  [ 1200/ 3364]
loss: 0.005461  [ 1300/ 3364]
loss: 0.083592  [ 1400/ 3364]
loss: 0.002737  [ 1500/ 3364]
loss: 0.005374  [ 1600/ 3364]
loss: 0.002722  [ 1700/ 3364]
loss: 0.001300  [ 1800/ 3364]
loss: 0.003476  [ 1900/ 3364]
loss: 0.002439  [ 2000/ 3364]
loss: 0.003727  [ 2100/ 3364]
loss: 0.004092  [ 2200/ 3364]
loss: 0.005429  [ 2300/ 3364]
loss: 0.001116  [ 2400/ 3364]
loss: 0.002448  [ 2500/ 3364]
loss: 0.001655  [ 2600/ 3364]
loss: 0.003250  [ 2700/ 3364]
loss: 0.003864  [ 2800/ 3364]
loss: 0.001793  [ 2900/ 3364]
loss: 0.003641  [ 3000/ 3364]
loss: 0.005192  [ 3100/ 3364]
loss: 0.001483  [ 3200/ 3364]
loss: 0.001996  [ 3300/ 3364]
Epoch 7
-------------------------------
loss: 0.001525  [    0/ 3364]
loss: 0.002262  [  100/ 3364]
loss: 0.004497  [  200/ 3364]
loss: 0.000727  [  300/ 3364]
loss: 0.001088  [  400/ 3364]
loss: 0.033082  [  500/ 3364]
loss: 0.004267  [  600/ 3364]
loss: 0.007687  [  700/ 3364]
loss: 0.002785  [  800/ 3364]
loss: 0.002192  [  900/ 3364]
loss: 0.002405  [ 1000/ 3364]
loss: 0.004016  [ 1100/ 3364]
loss: 0.002191  [ 1200/ 3364]
loss: 0.004682  [ 1300/ 3364]
loss: 0.085142  [ 1400/ 3364]
loss: 0.002662  [ 1500/ 3364]
loss: 0.005153  [ 1600/ 3364]
loss: 0.002850  [ 1700/ 3364]
loss: 0.001305  [ 1800/ 3364]
loss: 0.003495  [ 1900/ 3364]
loss: 0.002456  [ 2000/ 3364]
loss: 0.003888  [ 2100/ 3364]
loss: 0.003922  [ 2200/ 3364]
loss: 0.005054  [ 2300/ 3364]
loss: 0.000983  [ 2400/ 3364]
loss: 0.002535  [ 2500/ 3364]
loss: 0.001695  [ 2600/ 3364]
loss: 0.003205  [ 2700/ 3364]
loss: 0.003695  [ 2800/ 3364]
loss: 0.001737  [ 2900/ 3364]
loss: 0.003632  [ 3000/ 3364]
loss: 0.005183  [ 3100/ 3364]
loss: 0.001355  [ 3200/ 3364]
loss: 0.001372  [ 3300/ 3364]
Epoch 8
-------------------------------
loss: 0.001603  [    0/ 3364]
loss: 0.002003  [  100/ 3364]
loss: 0.004531  [  200/ 3364]
loss: 0.000760  [  300/ 3364]
loss: 0.000988  [  400/ 3364]
loss: 0.031943  [  500/ 3364]
loss: 0.004229  [  600/ 3364]
loss: 0.007483  [  700/ 3364]
loss: 0.002939  [  800/ 3364]
loss: 0.002348  [  900/ 3364]
loss: 0.002398  [ 1000/ 3364]
loss: 0.003913  [ 1100/ 3364]
loss: 0.002163  [ 1200/ 3364]
loss: 0.003433  [ 1300/ 3364]
loss: 0.084985  [ 1400/ 3364]
loss: 0.002613  [ 1500/ 3364]
loss: 0.004729  [ 1600/ 3364]
loss: 0.003006  [ 1700/ 3364]
loss: 0.001231  [ 1800/ 3364]
loss: 0.003491  [ 1900/ 3364]
loss: 0.002478  [ 2000/ 3364]
loss: 0.003978  [ 2100/ 3364]
loss: 0.003836  [ 2200/ 3364]
loss: 0.004980  [ 2300/ 3364]
loss: 0.000926  [ 2400/ 3364]
loss: 0.002544  [ 2500/ 3364]
loss: 0.001780  [ 2600/ 3364]
loss: 0.003061  [ 2700/ 3364]
loss: 0.003942  [ 2800/ 3364]
loss: 0.001679  [ 2900/ 3364]
loss: 0.003752  [ 3000/ 3364]
loss: 0.005204  [ 3100/ 3364]
loss: 0.001286  [ 3200/ 3364]
loss: 0.001701  [ 3300/ 3364]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3364
First Spike after testing: [-0.75291795 -0.5853568 ]
[2 2 2 ... 1 1 0]
[0 0 0 ... 1 1 2]
Cluster 0 Occurrences: 1120; KMEANS: 1108
Cluster 1 Occurrences: 1109; KMEANS: 1118
Cluster 2 Occurrences: 1135; KMEANS: 1138
Centroids: [[-2.277801, -0.050995123], [0.73500335, -0.6465688], [-0.8394512, -0.5490626]]
Centroids: [[-0.7993509, -0.55149287], [0.73847055, -0.6472], [-2.3099515, -0.05511571]]
Contingency Matrix: 
[[   9    3 1108]
 [   6 1102    1]
 [1093   13   29]]
[[-1, -1, -1], [6, 1102, -1], [1093, 13, -1]]
[[-1, -1, -1], [-1, -1, -1], [1093, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 1: 1, 2: 0}
New Contingency Matrix: 
[[1108    3    9]
 [   1 1102    6]
 [  29   13 1093]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1108, 1102, 1093], Sum: 3303
All_Elements: [1108, 3, 9, 1, 1102, 6, 29, 13, 1093], Sum: 3364
Accuracy: 0.9818668252080857
Done!
