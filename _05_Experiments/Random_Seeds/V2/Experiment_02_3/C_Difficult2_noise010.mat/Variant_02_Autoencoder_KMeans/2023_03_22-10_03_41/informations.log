Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_03_41
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E78753FFD0>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x000001E795D00240>
Epoch 1
-------------------------------
loss: 0.207918  [    0/ 3462]
loss: 0.123661  [  100/ 3462]
loss: 0.039593  [  200/ 3462]
loss: 0.018706  [  300/ 3462]
loss: 0.018922  [  400/ 3462]
loss: 0.016624  [  500/ 3462]
loss: 0.019635  [  600/ 3462]
loss: 0.030940  [  700/ 3462]
loss: 0.012035  [  800/ 3462]
loss: 0.014638  [  900/ 3462]
loss: 0.013662  [ 1000/ 3462]
loss: 0.058003  [ 1100/ 3462]
loss: 0.014547  [ 1200/ 3462]
loss: 0.005583  [ 1300/ 3462]
loss: 0.007852  [ 1400/ 3462]
loss: 0.012727  [ 1500/ 3462]
loss: 0.007408  [ 1600/ 3462]
loss: 0.006290  [ 1700/ 3462]
loss: 0.012770  [ 1800/ 3462]
loss: 0.007901  [ 1900/ 3462]
loss: 0.010940  [ 2000/ 3462]
loss: 0.070482  [ 2100/ 3462]
loss: 0.002194  [ 2200/ 3462]
loss: 0.005018  [ 2300/ 3462]
loss: 0.011431  [ 2400/ 3462]
loss: 0.007610  [ 2500/ 3462]
loss: 0.012104  [ 2600/ 3462]
loss: 0.006407  [ 2700/ 3462]
loss: 0.005272  [ 2800/ 3462]
loss: 0.014349  [ 2900/ 3462]
loss: 0.110990  [ 3000/ 3462]
loss: 0.006024  [ 3100/ 3462]
loss: 0.009005  [ 3200/ 3462]
loss: 0.129581  [ 3300/ 3462]
loss: 0.011261  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.001729  [    0/ 3462]
loss: 0.012595  [  100/ 3462]
loss: 0.010687  [  200/ 3462]
loss: 0.016773  [  300/ 3462]
loss: 0.012290  [  400/ 3462]
loss: 0.007675  [  500/ 3462]
loss: 0.006606  [  600/ 3462]
loss: 0.021263  [  700/ 3462]
loss: 0.009478  [  800/ 3462]
loss: 0.013979  [  900/ 3462]
loss: 0.009455  [ 1000/ 3462]
loss: 0.033037  [ 1100/ 3462]
loss: 0.011581  [ 1200/ 3462]
loss: 0.002290  [ 1300/ 3462]
loss: 0.006746  [ 1400/ 3462]
loss: 0.013953  [ 1500/ 3462]
loss: 0.005575  [ 1600/ 3462]
loss: 0.005008  [ 1700/ 3462]
loss: 0.007206  [ 1800/ 3462]
loss: 0.005922  [ 1900/ 3462]
loss: 0.009013  [ 2000/ 3462]
loss: 0.064825  [ 2100/ 3462]
loss: 0.002466  [ 2200/ 3462]
loss: 0.004273  [ 2300/ 3462]
loss: 0.012274  [ 2400/ 3462]
loss: 0.005295  [ 2500/ 3462]
loss: 0.007396  [ 2600/ 3462]
loss: 0.005876  [ 2700/ 3462]
loss: 0.004486  [ 2800/ 3462]
loss: 0.013804  [ 2900/ 3462]
loss: 0.105960  [ 3000/ 3462]
loss: 0.005148  [ 3100/ 3462]
loss: 0.009287  [ 3200/ 3462]
loss: 0.120069  [ 3300/ 3462]
loss: 0.010708  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.001551  [    0/ 3462]
loss: 0.012786  [  100/ 3462]
loss: 0.005977  [  200/ 3462]
loss: 0.016827  [  300/ 3462]
loss: 0.012772  [  400/ 3462]
loss: 0.005611  [  500/ 3462]
loss: 0.005892  [  600/ 3462]
loss: 0.021080  [  700/ 3462]
loss: 0.008556  [  800/ 3462]
loss: 0.014231  [  900/ 3462]
loss: 0.006621  [ 1000/ 3462]
loss: 0.034037  [ 1100/ 3462]
loss: 0.009250  [ 1200/ 3462]
loss: 0.001947  [ 1300/ 3462]
loss: 0.003859  [ 1400/ 3462]
loss: 0.013587  [ 1500/ 3462]
loss: 0.003576  [ 1600/ 3462]
loss: 0.004691  [ 1700/ 3462]
loss: 0.004453  [ 1800/ 3462]
loss: 0.004520  [ 1900/ 3462]
loss: 0.007567  [ 2000/ 3462]
loss: 0.063603  [ 2100/ 3462]
loss: 0.002165  [ 2200/ 3462]
loss: 0.005080  [ 2300/ 3462]
loss: 0.011884  [ 2400/ 3462]
loss: 0.003621  [ 2500/ 3462]
loss: 0.006244  [ 2600/ 3462]
loss: 0.005599  [ 2700/ 3462]
loss: 0.004376  [ 2800/ 3462]
loss: 0.013146  [ 2900/ 3462]
loss: 0.103498  [ 3000/ 3462]
loss: 0.004916  [ 3100/ 3462]
loss: 0.009082  [ 3200/ 3462]
loss: 0.107272  [ 3300/ 3462]
loss: 0.010446  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.001535  [    0/ 3462]
loss: 0.012801  [  100/ 3462]
loss: 0.003835  [  200/ 3462]
loss: 0.016816  [  300/ 3462]
loss: 0.013135  [  400/ 3462]
loss: 0.003593  [  500/ 3462]
loss: 0.005265  [  600/ 3462]
loss: 0.020873  [  700/ 3462]
loss: 0.007781  [  800/ 3462]
loss: 0.013543  [  900/ 3462]
loss: 0.005642  [ 1000/ 3462]
loss: 0.035907  [ 1100/ 3462]
loss: 0.008568  [ 1200/ 3462]
loss: 0.001882  [ 1300/ 3462]
loss: 0.002645  [ 1400/ 3462]
loss: 0.013160  [ 1500/ 3462]
loss: 0.002948  [ 1600/ 3462]
loss: 0.004512  [ 1700/ 3462]
loss: 0.004336  [ 1800/ 3462]
loss: 0.003719  [ 1900/ 3462]
loss: 0.006872  [ 2000/ 3462]
loss: 0.063950  [ 2100/ 3462]
loss: 0.002017  [ 2200/ 3462]
loss: 0.005769  [ 2300/ 3462]
loss: 0.011825  [ 2400/ 3462]
loss: 0.001905  [ 2500/ 3462]
loss: 0.005956  [ 2600/ 3462]
loss: 0.005653  [ 2700/ 3462]
loss: 0.003920  [ 2800/ 3462]
loss: 0.012751  [ 2900/ 3462]
loss: 0.103143  [ 3000/ 3462]
loss: 0.005019  [ 3100/ 3462]
loss: 0.008825  [ 3200/ 3462]
loss: 0.100100  [ 3300/ 3462]
loss: 0.010425  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.001545  [    0/ 3462]
loss: 0.012654  [  100/ 3462]
loss: 0.003133  [  200/ 3462]
loss: 0.016956  [  300/ 3462]
loss: 0.013268  [  400/ 3462]
loss: 0.003250  [  500/ 3462]
loss: 0.004934  [  600/ 3462]
loss: 0.020775  [  700/ 3462]
loss: 0.006287  [  800/ 3462]
loss: 0.013447  [  900/ 3462]
loss: 0.005450  [ 1000/ 3462]
loss: 0.036340  [ 1100/ 3462]
loss: 0.008795  [ 1200/ 3462]
loss: 0.001908  [ 1300/ 3462]
loss: 0.002209  [ 1400/ 3462]
loss: 0.012986  [ 1500/ 3462]
loss: 0.002758  [ 1600/ 3462]
loss: 0.004379  [ 1700/ 3462]
loss: 0.004616  [ 1800/ 3462]
loss: 0.002912  [ 1900/ 3462]
loss: 0.006248  [ 2000/ 3462]
loss: 0.064438  [ 2100/ 3462]
loss: 0.001980  [ 2200/ 3462]
loss: 0.006158  [ 2300/ 3462]
loss: 0.011970  [ 2400/ 3462]
loss: 0.001648  [ 2500/ 3462]
loss: 0.005920  [ 2600/ 3462]
loss: 0.005707  [ 2700/ 3462]
loss: 0.002607  [ 2800/ 3462]
loss: 0.012642  [ 2900/ 3462]
loss: 0.102980  [ 3000/ 3462]
loss: 0.005047  [ 3100/ 3462]
loss: 0.008603  [ 3200/ 3462]
loss: 0.098649  [ 3300/ 3462]
loss: 0.010742  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.001516  [    0/ 3462]
loss: 0.012755  [  100/ 3462]
loss: 0.002865  [  200/ 3462]
loss: 0.017086  [  300/ 3462]
loss: 0.012544  [  400/ 3462]
loss: 0.002926  [  500/ 3462]
loss: 0.004792  [  600/ 3462]
loss: 0.020695  [  700/ 3462]
loss: 0.003987  [  800/ 3462]
loss: 0.013370  [  900/ 3462]
loss: 0.005382  [ 1000/ 3462]
loss: 0.036384  [ 1100/ 3462]
loss: 0.009391  [ 1200/ 3462]
loss: 0.001880  [ 1300/ 3462]
loss: 0.002097  [ 1400/ 3462]
loss: 0.012897  [ 1500/ 3462]
loss: 0.002726  [ 1600/ 3462]
loss: 0.004381  [ 1700/ 3462]
loss: 0.004865  [ 1800/ 3462]
loss: 0.002758  [ 1900/ 3462]
loss: 0.006329  [ 2000/ 3462]
loss: 0.064582  [ 2100/ 3462]
loss: 0.001976  [ 2200/ 3462]
loss: 0.006309  [ 2300/ 3462]
loss: 0.011669  [ 2400/ 3462]
loss: 0.001217  [ 2500/ 3462]
loss: 0.005900  [ 2600/ 3462]
loss: 0.005651  [ 2700/ 3462]
loss: 0.002126  [ 2800/ 3462]
loss: 0.012310  [ 2900/ 3462]
loss: 0.102856  [ 3000/ 3462]
loss: 0.005140  [ 3100/ 3462]
loss: 0.008535  [ 3200/ 3462]
loss: 0.105712  [ 3300/ 3462]
loss: 0.010802  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.001519  [    0/ 3462]
loss: 0.012790  [  100/ 3462]
loss: 0.003033  [  200/ 3462]
loss: 0.016955  [  300/ 3462]
loss: 0.011796  [  400/ 3462]
loss: 0.003078  [  500/ 3462]
loss: 0.004597  [  600/ 3462]
loss: 0.020692  [  700/ 3462]
loss: 0.002647  [  800/ 3462]
loss: 0.013615  [  900/ 3462]
loss: 0.005145  [ 1000/ 3462]
loss: 0.036708  [ 1100/ 3462]
loss: 0.009726  [ 1200/ 3462]
loss: 0.001872  [ 1300/ 3462]
loss: 0.002076  [ 1400/ 3462]
loss: 0.012729  [ 1500/ 3462]
loss: 0.002706  [ 1600/ 3462]
loss: 0.004343  [ 1700/ 3462]
loss: 0.004971  [ 1800/ 3462]
loss: 0.002993  [ 1900/ 3462]
loss: 0.006270  [ 2000/ 3462]
loss: 0.064368  [ 2100/ 3462]
loss: 0.001988  [ 2200/ 3462]
loss: 0.006342  [ 2300/ 3462]
loss: 0.011450  [ 2400/ 3462]
loss: 0.001079  [ 2500/ 3462]
loss: 0.005914  [ 2600/ 3462]
loss: 0.005634  [ 2700/ 3462]
loss: 0.002021  [ 2800/ 3462]
loss: 0.012021  [ 2900/ 3462]
loss: 0.103079  [ 3000/ 3462]
loss: 0.005209  [ 3100/ 3462]
loss: 0.008437  [ 3200/ 3462]
loss: 0.106644  [ 3300/ 3462]
loss: 0.010950  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.001513  [    0/ 3462]
loss: 0.012834  [  100/ 3462]
loss: 0.003045  [  200/ 3462]
loss: 0.016778  [  300/ 3462]
loss: 0.011510  [  400/ 3462]
loss: 0.002928  [  500/ 3462]
loss: 0.004472  [  600/ 3462]
loss: 0.020598  [  700/ 3462]
loss: 0.002129  [  800/ 3462]
loss: 0.013982  [  900/ 3462]
loss: 0.005189  [ 1000/ 3462]
loss: 0.036967  [ 1100/ 3462]
loss: 0.010050  [ 1200/ 3462]
loss: 0.001876  [ 1300/ 3462]
loss: 0.002055  [ 1400/ 3462]
loss: 0.012641  [ 1500/ 3462]
loss: 0.002758  [ 1600/ 3462]
loss: 0.004418  [ 1700/ 3462]
loss: 0.004936  [ 1800/ 3462]
loss: 0.003580  [ 1900/ 3462]
loss: 0.006249  [ 2000/ 3462]
loss: 0.064459  [ 2100/ 3462]
loss: 0.001977  [ 2200/ 3462]
loss: 0.006258  [ 2300/ 3462]
loss: 0.011395  [ 2400/ 3462]
loss: 0.001115  [ 2500/ 3462]
loss: 0.005871  [ 2600/ 3462]
loss: 0.005617  [ 2700/ 3462]
loss: 0.001971  [ 2800/ 3462]
loss: 0.011797  [ 2900/ 3462]
loss: 0.103042  [ 3000/ 3462]
loss: 0.005133  [ 3100/ 3462]
loss: 0.008436  [ 3200/ 3462]
loss: 0.112718  [ 3300/ 3462]
loss: 0.011036  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [-1.3547548  0.5590156]
[0 2 2 ... 0 1 2]
[0 2 2 ... 0 1 2]
Cluster 0 Occurrences: 1187; KMEANS: 1188
Cluster 1 Occurrences: 1136; KMEANS: 1138
Cluster 2 Occurrences: 1139; KMEANS: 1136
Centroids: [[-1.4006374, 0.47124863], [0.9438801, -0.53921336], [-0.4694745, 0.42717272]]
Centroids: [[-1.4315215, 0.50001353], [0.95177877, -0.53814644], [-0.44675797, 0.397685]]
Contingency Matrix: 
[[1131    1   55]
 [   2 1129    5]
 [  55    8 1076]]
[[-1, -1, -1], [-1, 1129, 5], [-1, 8, 1076]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 1076]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[1131    1   55]
 [   2 1129    5]
 [  55    8 1076]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1131, 1129, 1076], Sum: 3336
All_Elements: [1131, 1, 55, 2, 1129, 5, 55, 8, 1076], Sum: 3462
Accuracy: 0.9636048526863085
Done!
