Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Easy1_noise035.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_48_50
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E732955048>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
<torch.utils.data.dataloader.DataLoader object at 0x000001E7328FBE10>
Epoch 1
-------------------------------
loss: 0.286505  [    0/ 3534]
loss: 0.312713  [  100/ 3534]
loss: 0.134939  [  200/ 3534]
loss: 0.190492  [  300/ 3534]
loss: 0.141445  [  400/ 3534]
loss: 0.080555  [  500/ 3534]
loss: 0.162396  [  600/ 3534]
loss: 0.073685  [  700/ 3534]
loss: 0.118759  [  800/ 3534]
loss: 0.058042  [  900/ 3534]
loss: 0.102226  [ 1000/ 3534]
loss: 0.031730  [ 1100/ 3534]
loss: 0.108115  [ 1200/ 3534]
loss: 0.105625  [ 1300/ 3534]
loss: 0.030282  [ 1400/ 3534]
loss: 0.158606  [ 1500/ 3534]
loss: 0.164117  [ 1600/ 3534]
loss: 0.035975  [ 1700/ 3534]
loss: 0.403135  [ 1800/ 3534]
loss: 0.080026  [ 1900/ 3534]
loss: 0.068114  [ 2000/ 3534]
loss: 0.035038  [ 2100/ 3534]
loss: 0.043491  [ 2200/ 3534]
loss: 0.117066  [ 2300/ 3534]
loss: 0.083767  [ 2400/ 3534]
loss: 0.084716  [ 2500/ 3534]
loss: 0.094431  [ 2600/ 3534]
loss: 0.030270  [ 2700/ 3534]
loss: 0.164850  [ 2800/ 3534]
loss: 0.161043  [ 2900/ 3534]
loss: 0.323412  [ 3000/ 3534]
loss: 0.064555  [ 3100/ 3534]
loss: 0.127820  [ 3200/ 3534]
loss: 0.044651  [ 3300/ 3534]
loss: 0.079670  [ 3400/ 3534]
loss: 0.076258  [ 3500/ 3534]
Epoch 2
-------------------------------
loss: 0.125111  [    0/ 3534]
loss: 0.071506  [  100/ 3534]
loss: 0.024633  [  200/ 3534]
loss: 0.143984  [  300/ 3534]
loss: 0.124660  [  400/ 3534]
loss: 0.021660  [  500/ 3534]
loss: 0.026534  [  600/ 3534]
loss: 0.050243  [  700/ 3534]
loss: 0.045478  [  800/ 3534]
loss: 0.038666  [  900/ 3534]
loss: 0.026714  [ 1000/ 3534]
loss: 0.027397  [ 1100/ 3534]
loss: 0.019568  [ 1200/ 3534]
loss: 0.079690  [ 1300/ 3534]
loss: 0.025171  [ 1400/ 3534]
loss: 0.068406  [ 1500/ 3534]
loss: 0.140580  [ 1600/ 3534]
loss: 0.043116  [ 1700/ 3534]
loss: 0.092088  [ 1800/ 3534]
loss: 0.035239  [ 1900/ 3534]
loss: 0.027624  [ 2000/ 3534]
loss: 0.036342  [ 2100/ 3534]
loss: 0.033675  [ 2200/ 3534]
loss: 0.139999  [ 2300/ 3534]
loss: 0.070142  [ 2400/ 3534]
loss: 0.092190  [ 2500/ 3534]
loss: 0.074879  [ 2600/ 3534]
loss: 0.031491  [ 2700/ 3534]
loss: 0.140061  [ 2800/ 3534]
loss: 0.044048  [ 2900/ 3534]
loss: 0.316134  [ 3000/ 3534]
loss: 0.053266  [ 3100/ 3534]
loss: 0.126990  [ 3200/ 3534]
loss: 0.051645  [ 3300/ 3534]
loss: 0.045373  [ 3400/ 3534]
loss: 0.070872  [ 3500/ 3534]
Epoch 3
-------------------------------
loss: 0.126090  [    0/ 3534]
loss: 0.037960  [  100/ 3534]
loss: 0.028832  [  200/ 3534]
loss: 0.110203  [  300/ 3534]
loss: 0.177733  [  400/ 3534]
loss: 0.031750  [  500/ 3534]
loss: 0.024627  [  600/ 3534]
loss: 0.072271  [  700/ 3534]
loss: 0.035684  [  800/ 3534]
loss: 0.031341  [  900/ 3534]
loss: 0.042475  [ 1000/ 3534]
loss: 0.026746  [ 1100/ 3534]
loss: 0.015006  [ 1200/ 3534]
loss: 0.056985  [ 1300/ 3534]
loss: 0.019206  [ 1400/ 3534]
loss: 0.041276  [ 1500/ 3534]
loss: 0.143880  [ 1600/ 3534]
loss: 0.051843  [ 1700/ 3534]
loss: 0.054688  [ 1800/ 3534]
loss: 0.034265  [ 1900/ 3534]
loss: 0.029635  [ 2000/ 3534]
loss: 0.035413  [ 2100/ 3534]
loss: 0.033061  [ 2200/ 3534]
loss: 0.133301  [ 2300/ 3534]
loss: 0.062930  [ 2400/ 3534]
loss: 0.096523  [ 2500/ 3534]
loss: 0.081912  [ 2600/ 3534]
loss: 0.029553  [ 2700/ 3534]
loss: 0.126853  [ 2800/ 3534]
loss: 0.037398  [ 2900/ 3534]
loss: 0.265348  [ 3000/ 3534]
loss: 0.050213  [ 3100/ 3534]
loss: 0.127416  [ 3200/ 3534]
loss: 0.067912  [ 3300/ 3534]
loss: 0.041865  [ 3400/ 3534]
loss: 0.070825  [ 3500/ 3534]
Epoch 4
-------------------------------
loss: 0.126131  [    0/ 3534]
loss: 0.025455  [  100/ 3534]
loss: 0.028575  [  200/ 3534]
loss: 0.108622  [  300/ 3534]
loss: 0.203067  [  400/ 3534]
loss: 0.030641  [  500/ 3534]
loss: 0.026977  [  600/ 3534]
loss: 0.076329  [  700/ 3534]
loss: 0.034983  [  800/ 3534]
loss: 0.029804  [  900/ 3534]
loss: 0.033388  [ 1000/ 3534]
loss: 0.025091  [ 1100/ 3534]
loss: 0.016548  [ 1200/ 3534]
loss: 0.051982  [ 1300/ 3534]
loss: 0.018357  [ 1400/ 3534]
loss: 0.038060  [ 1500/ 3534]
loss: 0.145452  [ 1600/ 3534]
loss: 0.051760  [ 1700/ 3534]
loss: 0.056149  [ 1800/ 3534]
loss: 0.035739  [ 1900/ 3534]
loss: 0.029567  [ 2000/ 3534]
loss: 0.033325  [ 2100/ 3534]
loss: 0.031709  [ 2200/ 3534]
loss: 0.130709  [ 2300/ 3534]
loss: 0.060482  [ 2400/ 3534]
loss: 0.096809  [ 2500/ 3534]
loss: 0.079517  [ 2600/ 3534]
loss: 0.029234  [ 2700/ 3534]
loss: 0.113959  [ 2800/ 3534]
loss: 0.035608  [ 2900/ 3534]
loss: 0.228156  [ 3000/ 3534]
loss: 0.050198  [ 3100/ 3534]
loss: 0.130082  [ 3200/ 3534]
loss: 0.077075  [ 3300/ 3534]
loss: 0.041593  [ 3400/ 3534]
loss: 0.070825  [ 3500/ 3534]
Epoch 5
-------------------------------
loss: 0.126159  [    0/ 3534]
loss: 0.022638  [  100/ 3534]
loss: 0.026841  [  200/ 3534]
loss: 0.104546  [  300/ 3534]
loss: 0.227313  [  400/ 3534]
loss: 0.030392  [  500/ 3534]
loss: 0.029781  [  600/ 3534]
loss: 0.079084  [  700/ 3534]
loss: 0.035128  [  800/ 3534]
loss: 0.030193  [  900/ 3534]
loss: 0.027991  [ 1000/ 3534]
loss: 0.023895  [ 1100/ 3534]
loss: 0.017189  [ 1200/ 3534]
loss: 0.050516  [ 1300/ 3534]
loss: 0.016091  [ 1400/ 3534]
loss: 0.039400  [ 1500/ 3534]
loss: 0.146985  [ 1600/ 3534]
loss: 0.052884  [ 1700/ 3534]
loss: 0.056521  [ 1800/ 3534]
loss: 0.034973  [ 1900/ 3534]
loss: 0.029065  [ 2000/ 3534]
loss: 0.032764  [ 2100/ 3534]
loss: 0.032556  [ 2200/ 3534]
loss: 0.129498  [ 2300/ 3534]
loss: 0.058755  [ 2400/ 3534]
loss: 0.097494  [ 2500/ 3534]
loss: 0.077180  [ 2600/ 3534]
loss: 0.029156  [ 2700/ 3534]
loss: 0.105570  [ 2800/ 3534]
loss: 0.035811  [ 2900/ 3534]
loss: 0.207518  [ 3000/ 3534]
loss: 0.050518  [ 3100/ 3534]
loss: 0.131354  [ 3200/ 3534]
loss: 0.083871  [ 3300/ 3534]
loss: 0.041717  [ 3400/ 3534]
loss: 0.070881  [ 3500/ 3534]
Epoch 6
-------------------------------
loss: 0.125550  [    0/ 3534]
loss: 0.024095  [  100/ 3534]
loss: 0.026547  [  200/ 3534]
loss: 0.101008  [  300/ 3534]
loss: 0.244238  [  400/ 3534]
loss: 0.026732  [  500/ 3534]
loss: 0.031193  [  600/ 3534]
loss: 0.081364  [  700/ 3534]
loss: 0.036074  [  800/ 3534]
loss: 0.030664  [  900/ 3534]
loss: 0.027832  [ 1000/ 3534]
loss: 0.023537  [ 1100/ 3534]
loss: 0.017996  [ 1200/ 3534]
loss: 0.052963  [ 1300/ 3534]
loss: 0.015378  [ 1400/ 3534]
loss: 0.040126  [ 1500/ 3534]
loss: 0.145721  [ 1600/ 3534]
loss: 0.054436  [ 1700/ 3534]
loss: 0.055413  [ 1800/ 3534]
loss: 0.035106  [ 1900/ 3534]
loss: 0.028002  [ 2000/ 3534]
loss: 0.032380  [ 2100/ 3534]
loss: 0.032877  [ 2200/ 3534]
loss: 0.127178  [ 2300/ 3534]
loss: 0.056633  [ 2400/ 3534]
loss: 0.098090  [ 2500/ 3534]
loss: 0.076172  [ 2600/ 3534]
loss: 0.029261  [ 2700/ 3534]
loss: 0.102531  [ 2800/ 3534]
loss: 0.037642  [ 2900/ 3534]
loss: 0.198728  [ 3000/ 3534]
loss: 0.051110  [ 3100/ 3534]
loss: 0.131161  [ 3200/ 3534]
loss: 0.091802  [ 3300/ 3534]
loss: 0.041744  [ 3400/ 3534]
loss: 0.070903  [ 3500/ 3534]
Epoch 7
-------------------------------
loss: 0.124847  [    0/ 3534]
loss: 0.028015  [  100/ 3534]
loss: 0.026529  [  200/ 3534]
loss: 0.101295  [  300/ 3534]
loss: 0.252255  [  400/ 3534]
loss: 0.027490  [  500/ 3534]
loss: 0.031055  [  600/ 3534]
loss: 0.084764  [  700/ 3534]
loss: 0.036860  [  800/ 3534]
loss: 0.029954  [  900/ 3534]
loss: 0.027050  [ 1000/ 3534]
loss: 0.022886  [ 1100/ 3534]
loss: 0.019083  [ 1200/ 3534]
loss: 0.050220  [ 1300/ 3534]
loss: 0.013860  [ 1400/ 3534]
loss: 0.039161  [ 1500/ 3534]
loss: 0.144367  [ 1600/ 3534]
loss: 0.054776  [ 1700/ 3534]
loss: 0.053384  [ 1800/ 3534]
loss: 0.034596  [ 1900/ 3534]
loss: 0.027272  [ 2000/ 3534]
loss: 0.031853  [ 2100/ 3534]
loss: 0.032479  [ 2200/ 3534]
loss: 0.125605  [ 2300/ 3534]
loss: 0.054652  [ 2400/ 3534]
loss: 0.097709  [ 2500/ 3534]
loss: 0.074240  [ 2600/ 3534]
loss: 0.029422  [ 2700/ 3534]
loss: 0.099359  [ 2800/ 3534]
loss: 0.037135  [ 2900/ 3534]
loss: 0.188217  [ 3000/ 3534]
loss: 0.051851  [ 3100/ 3534]
loss: 0.130976  [ 3200/ 3534]
loss: 0.093046  [ 3300/ 3534]
loss: 0.041562  [ 3400/ 3534]
loss: 0.071020  [ 3500/ 3534]
Epoch 8
-------------------------------
loss: 0.123949  [    0/ 3534]
loss: 0.034152  [  100/ 3534]
loss: 0.026794  [  200/ 3534]
loss: 0.100429  [  300/ 3534]
loss: 0.259163  [  400/ 3534]
loss: 0.025533  [  500/ 3534]
loss: 0.030768  [  600/ 3534]
loss: 0.086412  [  700/ 3534]
loss: 0.037777  [  800/ 3534]
loss: 0.029668  [  900/ 3534]
loss: 0.028179  [ 1000/ 3534]
loss: 0.022640  [ 1100/ 3534]
loss: 0.020209  [ 1200/ 3534]
loss: 0.050835  [ 1300/ 3534]
loss: 0.015770  [ 1400/ 3534]
loss: 0.037486  [ 1500/ 3534]
loss: 0.143864  [ 1600/ 3534]
loss: 0.054843  [ 1700/ 3534]
loss: 0.051183  [ 1800/ 3534]
loss: 0.032947  [ 1900/ 3534]
loss: 0.026848  [ 2000/ 3534]
loss: 0.031622  [ 2100/ 3534]
loss: 0.030777  [ 2200/ 3534]
loss: 0.125977  [ 2300/ 3534]
loss: 0.053023  [ 2400/ 3534]
loss: 0.096144  [ 2500/ 3534]
loss: 0.072006  [ 2600/ 3534]
loss: 0.029559  [ 2700/ 3534]
loss: 0.093428  [ 2800/ 3534]
loss: 0.037394  [ 2900/ 3534]
loss: 0.182501  [ 3000/ 3534]
loss: 0.051738  [ 3100/ 3534]
loss: 0.130758  [ 3200/ 3534]
loss: 0.092061  [ 3300/ 3534]
loss: 0.041396  [ 3400/ 3534]
loss: 0.071095  [ 3500/ 3534]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3534
First Spike after testing: [ 0.03070172 -1.3449936 ]
[0 1 2 ... 2 2 1]
[2 1 0 ... 0 2 2]
Cluster 0 Occurrences: 1208; KMEANS: 1175
Cluster 1 Occurrences: 1137; KMEANS: 1110
Cluster 2 Occurrences: 1189; KMEANS: 1249
Centroids: [[-0.16564797, -1.2581578], [0.023100257, 3.4955027], [1.7690003, -0.80364233]]
Centroids: [[1.8173218, -0.8757828], [0.050760824, 3.5941062], [-0.20992301, -1.1700655]]
Contingency Matrix: 
[[  60    0 1148]
 [   8 1089   40]
 [1107   21   61]]
[[-1, -1, -1], [8, 1089, -1], [1107, 21, -1]]
[[-1, -1, -1], [-1, 1089, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 2: 0, 1: 1}
New Contingency Matrix: 
[[1148    0   60]
 [  40 1089    8]
 [  61   21 1107]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1148, 1089, 1107], Sum: 3344
All_Elements: [1148, 0, 60, 40, 1089, 8, 61, 21, 1107], Sum: 3534
Accuracy: 0.946236559139785
Done!
