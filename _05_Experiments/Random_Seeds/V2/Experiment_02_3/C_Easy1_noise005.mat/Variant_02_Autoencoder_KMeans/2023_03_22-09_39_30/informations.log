Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_39_30
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E7328FBE10>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x000001E732042518>
Epoch 1
-------------------------------
loss: 0.133774  [    0/ 3514]
loss: 0.276803  [  100/ 3514]
loss: 0.109785  [  200/ 3514]
loss: 0.032730  [  300/ 3514]
loss: 0.092240  [  400/ 3514]
loss: 0.053115  [  500/ 3514]
loss: 0.042341  [  600/ 3514]
loss: 0.019832  [  700/ 3514]
loss: 0.001774  [  800/ 3514]
loss: 0.005223  [  900/ 3514]
loss: 0.006712  [ 1000/ 3514]
loss: 0.094736  [ 1100/ 3514]
loss: 0.003109  [ 1200/ 3514]
loss: 0.001916  [ 1300/ 3514]
loss: 0.073064  [ 1400/ 3514]
loss: 0.001951  [ 1500/ 3514]
loss: 0.007309  [ 1600/ 3514]
loss: 0.005931  [ 1700/ 3514]
loss: 0.246320  [ 1800/ 3514]
loss: 0.007954  [ 1900/ 3514]
loss: 0.002668  [ 2000/ 3514]
loss: 0.005589  [ 2100/ 3514]
loss: 0.000799  [ 2200/ 3514]
loss: 0.002694  [ 2300/ 3514]
loss: 0.002216  [ 2400/ 3514]
loss: 0.007882  [ 2500/ 3514]
loss: 0.004051  [ 2600/ 3514]
loss: 0.004600  [ 2700/ 3514]
loss: 0.007474  [ 2800/ 3514]
loss: 0.002261  [ 2900/ 3514]
loss: 0.008387  [ 3000/ 3514]
loss: 0.001309  [ 3100/ 3514]
loss: 0.001567  [ 3200/ 3514]
loss: 0.004900  [ 3300/ 3514]
loss: 0.006823  [ 3400/ 3514]
loss: 0.003655  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.007023  [    0/ 3514]
loss: 0.002389  [  100/ 3514]
loss: 0.006730  [  200/ 3514]
loss: 0.003835  [  300/ 3514]
loss: 0.004697  [  400/ 3514]
loss: 0.005109  [  500/ 3514]
loss: 0.008868  [  600/ 3514]
loss: 0.002298  [  700/ 3514]
loss: 0.001451  [  800/ 3514]
loss: 0.004279  [  900/ 3514]
loss: 0.006282  [ 1000/ 3514]
loss: 0.090014  [ 1100/ 3514]
loss: 0.002841  [ 1200/ 3514]
loss: 0.001752  [ 1300/ 3514]
loss: 0.067431  [ 1400/ 3514]
loss: 0.000869  [ 1500/ 3514]
loss: 0.005762  [ 1600/ 3514]
loss: 0.005524  [ 1700/ 3514]
loss: 0.215362  [ 1800/ 3514]
loss: 0.006921  [ 1900/ 3514]
loss: 0.001553  [ 2000/ 3514]
loss: 0.005334  [ 2100/ 3514]
loss: 0.000659  [ 2200/ 3514]
loss: 0.001552  [ 2300/ 3514]
loss: 0.002048  [ 2400/ 3514]
loss: 0.007610  [ 2500/ 3514]
loss: 0.004106  [ 2600/ 3514]
loss: 0.002981  [ 2700/ 3514]
loss: 0.007362  [ 2800/ 3514]
loss: 0.001869  [ 2900/ 3514]
loss: 0.006473  [ 3000/ 3514]
loss: 0.001186  [ 3100/ 3514]
loss: 0.001715  [ 3200/ 3514]
loss: 0.005995  [ 3300/ 3514]
loss: 0.005952  [ 3400/ 3514]
loss: 0.003546  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.005857  [    0/ 3514]
loss: 0.001725  [  100/ 3514]
loss: 0.006767  [  200/ 3514]
loss: 0.003896  [  300/ 3514]
loss: 0.004587  [  400/ 3514]
loss: 0.003976  [  500/ 3514]
loss: 0.008172  [  600/ 3514]
loss: 0.002315  [  700/ 3514]
loss: 0.001359  [  800/ 3514]
loss: 0.004263  [  900/ 3514]
loss: 0.006416  [ 1000/ 3514]
loss: 0.090070  [ 1100/ 3514]
loss: 0.002604  [ 1200/ 3514]
loss: 0.001691  [ 1300/ 3514]
loss: 0.068383  [ 1400/ 3514]
loss: 0.000793  [ 1500/ 3514]
loss: 0.005162  [ 1600/ 3514]
loss: 0.005403  [ 1700/ 3514]
loss: 0.208694  [ 1800/ 3514]
loss: 0.006208  [ 1900/ 3514]
loss: 0.001170  [ 2000/ 3514]
loss: 0.005191  [ 2100/ 3514]
loss: 0.000635  [ 2200/ 3514]
loss: 0.001383  [ 2300/ 3514]
loss: 0.001844  [ 2400/ 3514]
loss: 0.007257  [ 2500/ 3514]
loss: 0.003976  [ 2600/ 3514]
loss: 0.002642  [ 2700/ 3514]
loss: 0.007295  [ 2800/ 3514]
loss: 0.002018  [ 2900/ 3514]
loss: 0.004298  [ 3000/ 3514]
loss: 0.001461  [ 3100/ 3514]
loss: 0.001808  [ 3200/ 3514]
loss: 0.006476  [ 3300/ 3514]
loss: 0.005647  [ 3400/ 3514]
loss: 0.003313  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.004737  [    0/ 3514]
loss: 0.001468  [  100/ 3514]
loss: 0.006525  [  200/ 3514]
loss: 0.003970  [  300/ 3514]
loss: 0.004284  [  400/ 3514]
loss: 0.003454  [  500/ 3514]
loss: 0.006338  [  600/ 3514]
loss: 0.002756  [  700/ 3514]
loss: 0.001295  [  800/ 3514]
loss: 0.004112  [  900/ 3514]
loss: 0.006210  [ 1000/ 3514]
loss: 0.090343  [ 1100/ 3514]
loss: 0.002525  [ 1200/ 3514]
loss: 0.001381  [ 1300/ 3514]
loss: 0.070410  [ 1400/ 3514]
loss: 0.000690  [ 1500/ 3514]
loss: 0.004807  [ 1600/ 3514]
loss: 0.005273  [ 1700/ 3514]
loss: 0.203613  [ 1800/ 3514]
loss: 0.005079  [ 1900/ 3514]
loss: 0.001090  [ 2000/ 3514]
loss: 0.005445  [ 2100/ 3514]
loss: 0.000630  [ 2200/ 3514]
loss: 0.001532  [ 2300/ 3514]
loss: 0.001787  [ 2400/ 3514]
loss: 0.007051  [ 2500/ 3514]
loss: 0.003624  [ 2600/ 3514]
loss: 0.002413  [ 2700/ 3514]
loss: 0.007236  [ 2800/ 3514]
loss: 0.002182  [ 2900/ 3514]
loss: 0.002705  [ 3000/ 3514]
loss: 0.001567  [ 3100/ 3514]
loss: 0.001793  [ 3200/ 3514]
loss: 0.005598  [ 3300/ 3514]
loss: 0.005820  [ 3400/ 3514]
loss: 0.002640  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.003949  [    0/ 3514]
loss: 0.001377  [  100/ 3514]
loss: 0.006686  [  200/ 3514]
loss: 0.003957  [  300/ 3514]
loss: 0.004189  [  400/ 3514]
loss: 0.003269  [  500/ 3514]
loss: 0.005403  [  600/ 3514]
loss: 0.002707  [  700/ 3514]
loss: 0.001247  [  800/ 3514]
loss: 0.004001  [  900/ 3514]
loss: 0.005826  [ 1000/ 3514]
loss: 0.090444  [ 1100/ 3514]
loss: 0.002386  [ 1200/ 3514]
loss: 0.001341  [ 1300/ 3514]
loss: 0.069384  [ 1400/ 3514]
loss: 0.000764  [ 1500/ 3514]
loss: 0.004998  [ 1600/ 3514]
loss: 0.005483  [ 1700/ 3514]
loss: 0.194467  [ 1800/ 3514]
loss: 0.004234  [ 1900/ 3514]
loss: 0.000854  [ 2000/ 3514]
loss: 0.005191  [ 2100/ 3514]
loss: 0.000615  [ 2200/ 3514]
loss: 0.001634  [ 2300/ 3514]
loss: 0.001795  [ 2400/ 3514]
loss: 0.006712  [ 2500/ 3514]
loss: 0.003297  [ 2600/ 3514]
loss: 0.002379  [ 2700/ 3514]
loss: 0.007305  [ 2800/ 3514]
loss: 0.001885  [ 2900/ 3514]
loss: 0.002758  [ 3000/ 3514]
loss: 0.001300  [ 3100/ 3514]
loss: 0.001693  [ 3200/ 3514]
loss: 0.004658  [ 3300/ 3514]
loss: 0.005376  [ 3400/ 3514]
loss: 0.002497  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.004126  [    0/ 3514]
loss: 0.001253  [  100/ 3514]
loss: 0.006757  [  200/ 3514]
loss: 0.003721  [  300/ 3514]
loss: 0.004268  [  400/ 3514]
loss: 0.003268  [  500/ 3514]
loss: 0.005289  [  600/ 3514]
loss: 0.003094  [  700/ 3514]
loss: 0.001272  [  800/ 3514]
loss: 0.004062  [  900/ 3514]
loss: 0.005823  [ 1000/ 3514]
loss: 0.090274  [ 1100/ 3514]
loss: 0.002131  [ 1200/ 3514]
loss: 0.001355  [ 1300/ 3514]
loss: 0.070356  [ 1400/ 3514]
loss: 0.000400  [ 1500/ 3514]
loss: 0.005012  [ 1600/ 3514]
loss: 0.005494  [ 1700/ 3514]
loss: 0.187079  [ 1800/ 3514]
loss: 0.004498  [ 1900/ 3514]
loss: 0.000744  [ 2000/ 3514]
loss: 0.004929  [ 2100/ 3514]
loss: 0.000652  [ 2200/ 3514]
loss: 0.001757  [ 2300/ 3514]
loss: 0.001695  [ 2400/ 3514]
loss: 0.006822  [ 2500/ 3514]
loss: 0.003259  [ 2600/ 3514]
loss: 0.003003  [ 2700/ 3514]
loss: 0.007404  [ 2800/ 3514]
loss: 0.001695  [ 2900/ 3514]
loss: 0.002819  [ 3000/ 3514]
loss: 0.001695  [ 3100/ 3514]
loss: 0.001641  [ 3200/ 3514]
loss: 0.004780  [ 3300/ 3514]
loss: 0.006416  [ 3400/ 3514]
loss: 0.002443  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.004385  [    0/ 3514]
loss: 0.001047  [  100/ 3514]
loss: 0.006792  [  200/ 3514]
loss: 0.003550  [  300/ 3514]
loss: 0.004164  [  400/ 3514]
loss: 0.003311  [  500/ 3514]
loss: 0.004978  [  600/ 3514]
loss: 0.003309  [  700/ 3514]
loss: 0.001336  [  800/ 3514]
loss: 0.004172  [  900/ 3514]
loss: 0.005794  [ 1000/ 3514]
loss: 0.089702  [ 1100/ 3514]
loss: 0.001933  [ 1200/ 3514]
loss: 0.001356  [ 1300/ 3514]
loss: 0.071138  [ 1400/ 3514]
loss: 0.000380  [ 1500/ 3514]
loss: 0.005084  [ 1600/ 3514]
loss: 0.005409  [ 1700/ 3514]
loss: 0.180312  [ 1800/ 3514]
loss: 0.004089  [ 1900/ 3514]
loss: 0.000768  [ 2000/ 3514]
loss: 0.004972  [ 2100/ 3514]
loss: 0.000663  [ 2200/ 3514]
loss: 0.001885  [ 2300/ 3514]
loss: 0.001779  [ 2400/ 3514]
loss: 0.006812  [ 2500/ 3514]
loss: 0.003354  [ 2600/ 3514]
loss: 0.003219  [ 2700/ 3514]
loss: 0.007135  [ 2800/ 3514]
loss: 0.001907  [ 2900/ 3514]
loss: 0.002735  [ 3000/ 3514]
loss: 0.001432  [ 3100/ 3514]
loss: 0.001659  [ 3200/ 3514]
loss: 0.004790  [ 3300/ 3514]
loss: 0.005932  [ 3400/ 3514]
loss: 0.002487  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.005468  [    0/ 3514]
loss: 0.000873  [  100/ 3514]
loss: 0.006875  [  200/ 3514]
loss: 0.003401  [  300/ 3514]
loss: 0.004152  [  400/ 3514]
loss: 0.003512  [  500/ 3514]
loss: 0.004792  [  600/ 3514]
loss: 0.003374  [  700/ 3514]
loss: 0.001415  [  800/ 3514]
loss: 0.004238  [  900/ 3514]
loss: 0.005725  [ 1000/ 3514]
loss: 0.090716  [ 1100/ 3514]
loss: 0.001913  [ 1200/ 3514]
loss: 0.001353  [ 1300/ 3514]
loss: 0.071520  [ 1400/ 3514]
loss: 0.000432  [ 1500/ 3514]
loss: 0.005221  [ 1600/ 3514]
loss: 0.005482  [ 1700/ 3514]
loss: 0.171640  [ 1800/ 3514]
loss: 0.003738  [ 1900/ 3514]
loss: 0.001164  [ 2000/ 3514]
loss: 0.004944  [ 2100/ 3514]
loss: 0.000620  [ 2200/ 3514]
loss: 0.001758  [ 2300/ 3514]
loss: 0.002012  [ 2400/ 3514]
loss: 0.007080  [ 2500/ 3514]
loss: 0.003261  [ 2600/ 3514]
loss: 0.003968  [ 2700/ 3514]
loss: 0.006888  [ 2800/ 3514]
loss: 0.001897  [ 2900/ 3514]
loss: 0.002665  [ 3000/ 3514]
loss: 0.001281  [ 3100/ 3514]
loss: 0.001742  [ 3200/ 3514]
loss: 0.005046  [ 3300/ 3514]
loss: 0.005474  [ 3400/ 3514]
loss: 0.002487  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [0.48842645 1.8802531 ]
[1 0 2 ... 1 0 1]
[1 2 0 ... 1 2 1]
Cluster 0 Occurrences: 1165; KMEANS: 1212
Cluster 1 Occurrences: 1157; KMEANS: 1141
Cluster 2 Occurrences: 1192; KMEANS: 1161
Centroids: [[-0.96921617, -1.233775], [0.36844826, 2.1545236], [1.1829646, -1.1829753]]
Centroids: [[1.1778042, -1.1803025], [0.3688903, 2.1881094], [-0.98290366, -1.2237526]]
Contingency Matrix: 
[[  11    0 1154]
 [  12 1138    7]
 [1189    3    0]]
[[-1, 0, 1154], [-1, 1138, 7], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1138, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1154    0   11]
 [   7 1138   12]
 [   0    3 1189]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1154, 1138, 1189], Sum: 3481
All_Elements: [1154, 0, 11, 7, 1138, 12, 0, 3, 1189], Sum: 3514
Accuracy: 0.9906089926010244
Done!
