Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_56_18
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E73134ADD8>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x000001E733637198>
Epoch 1
-------------------------------
loss: 0.229874  [    0/ 3383]
loss: 0.054983  [  100/ 3383]
loss: 0.017852  [  200/ 3383]
loss: 0.010669  [  300/ 3383]
loss: 0.007223  [  400/ 3383]
loss: 0.011093  [  500/ 3383]
loss: 0.012505  [  600/ 3383]
loss: 0.017861  [  700/ 3383]
loss: 0.009578  [  800/ 3383]
loss: 0.015038  [  900/ 3383]
loss: 0.113112  [ 1000/ 3383]
loss: 0.058618  [ 1100/ 3383]
loss: 0.029440  [ 1200/ 3383]
loss: 0.014888  [ 1300/ 3383]
loss: 0.007105  [ 1400/ 3383]
loss: 0.015764  [ 1500/ 3383]
loss: 0.010514  [ 1600/ 3383]
loss: 0.002018  [ 1700/ 3383]
loss: 0.012158  [ 1800/ 3383]
loss: 0.015700  [ 1900/ 3383]
loss: 0.010260  [ 2000/ 3383]
loss: 0.004332  [ 2100/ 3383]
loss: 0.010076  [ 2200/ 3383]
loss: 0.004811  [ 2300/ 3383]
loss: 0.004068  [ 2400/ 3383]
loss: 0.029220  [ 2500/ 3383]
loss: 0.007630  [ 2600/ 3383]
loss: 0.002780  [ 2700/ 3383]
loss: 0.005752  [ 2800/ 3383]
loss: 0.005233  [ 2900/ 3383]
loss: 0.004787  [ 3000/ 3383]
loss: 0.005361  [ 3100/ 3383]
loss: 0.066280  [ 3200/ 3383]
loss: 0.002330  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.003945  [    0/ 3383]
loss: 0.006239  [  100/ 3383]
loss: 0.005918  [  200/ 3383]
loss: 0.002593  [  300/ 3383]
loss: 0.002913  [  400/ 3383]
loss: 0.004928  [  500/ 3383]
loss: 0.001329  [  600/ 3383]
loss: 0.003235  [  700/ 3383]
loss: 0.007405  [  800/ 3383]
loss: 0.001883  [  900/ 3383]
loss: 0.090967  [ 1000/ 3383]
loss: 0.057799  [ 1100/ 3383]
loss: 0.023136  [ 1200/ 3383]
loss: 0.009260  [ 1300/ 3383]
loss: 0.004035  [ 1400/ 3383]
loss: 0.015003  [ 1500/ 3383]
loss: 0.002548  [ 1600/ 3383]
loss: 0.001567  [ 1700/ 3383]
loss: 0.012193  [ 1800/ 3383]
loss: 0.014553  [ 1900/ 3383]
loss: 0.002836  [ 2000/ 3383]
loss: 0.003553  [ 2100/ 3383]
loss: 0.008941  [ 2200/ 3383]
loss: 0.001455  [ 2300/ 3383]
loss: 0.004145  [ 2400/ 3383]
loss: 0.029369  [ 2500/ 3383]
loss: 0.001354  [ 2600/ 3383]
loss: 0.003406  [ 2700/ 3383]
loss: 0.006253  [ 2800/ 3383]
loss: 0.005640  [ 2900/ 3383]
loss: 0.003890  [ 3000/ 3383]
loss: 0.004487  [ 3100/ 3383]
loss: 0.064761  [ 3200/ 3383]
loss: 0.002423  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.003929  [    0/ 3383]
loss: 0.005943  [  100/ 3383]
loss: 0.006037  [  200/ 3383]
loss: 0.002349  [  300/ 3383]
loss: 0.003056  [  400/ 3383]
loss: 0.004809  [  500/ 3383]
loss: 0.001081  [  600/ 3383]
loss: 0.002369  [  700/ 3383]
loss: 0.007374  [  800/ 3383]
loss: 0.001514  [  900/ 3383]
loss: 0.090774  [ 1000/ 3383]
loss: 0.057687  [ 1100/ 3383]
loss: 0.022743  [ 1200/ 3383]
loss: 0.009321  [ 1300/ 3383]
loss: 0.004086  [ 1400/ 3383]
loss: 0.014998  [ 1500/ 3383]
loss: 0.002502  [ 1600/ 3383]
loss: 0.001566  [ 1700/ 3383]
loss: 0.012058  [ 1800/ 3383]
loss: 0.014422  [ 1900/ 3383]
loss: 0.002966  [ 2000/ 3383]
loss: 0.003473  [ 2100/ 3383]
loss: 0.008790  [ 2200/ 3383]
loss: 0.001494  [ 2300/ 3383]
loss: 0.004065  [ 2400/ 3383]
loss: 0.028663  [ 2500/ 3383]
loss: 0.001253  [ 2600/ 3383]
loss: 0.003156  [ 2700/ 3383]
loss: 0.006271  [ 2800/ 3383]
loss: 0.005714  [ 2900/ 3383]
loss: 0.003844  [ 3000/ 3383]
loss: 0.004491  [ 3100/ 3383]
loss: 0.065049  [ 3200/ 3383]
loss: 0.002470  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.003873  [    0/ 3383]
loss: 0.005839  [  100/ 3383]
loss: 0.005882  [  200/ 3383]
loss: 0.002398  [  300/ 3383]
loss: 0.002954  [  400/ 3383]
loss: 0.004695  [  500/ 3383]
loss: 0.001066  [  600/ 3383]
loss: 0.002475  [  700/ 3383]
loss: 0.007386  [  800/ 3383]
loss: 0.001533  [  900/ 3383]
loss: 0.091076  [ 1000/ 3383]
loss: 0.057728  [ 1100/ 3383]
loss: 0.022797  [ 1200/ 3383]
loss: 0.009331  [ 1300/ 3383]
loss: 0.004071  [ 1400/ 3383]
loss: 0.015011  [ 1500/ 3383]
loss: 0.002488  [ 1600/ 3383]
loss: 0.001562  [ 1700/ 3383]
loss: 0.011859  [ 1800/ 3383]
loss: 0.014407  [ 1900/ 3383]
loss: 0.002954  [ 2000/ 3383]
loss: 0.003466  [ 2100/ 3383]
loss: 0.008727  [ 2200/ 3383]
loss: 0.001515  [ 2300/ 3383]
loss: 0.004096  [ 2400/ 3383]
loss: 0.028714  [ 2500/ 3383]
loss: 0.001221  [ 2600/ 3383]
loss: 0.003188  [ 2700/ 3383]
loss: 0.006284  [ 2800/ 3383]
loss: 0.005758  [ 2900/ 3383]
loss: 0.003753  [ 3000/ 3383]
loss: 0.004505  [ 3100/ 3383]
loss: 0.064949  [ 3200/ 3383]
loss: 0.002462  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.003904  [    0/ 3383]
loss: 0.005861  [  100/ 3383]
loss: 0.005780  [  200/ 3383]
loss: 0.002351  [  300/ 3383]
loss: 0.002980  [  400/ 3383]
loss: 0.004674  [  500/ 3383]
loss: 0.001087  [  600/ 3383]
loss: 0.002351  [  700/ 3383]
loss: 0.007373  [  800/ 3383]
loss: 0.001500  [  900/ 3383]
loss: 0.090895  [ 1000/ 3383]
loss: 0.057754  [ 1100/ 3383]
loss: 0.022893  [ 1200/ 3383]
loss: 0.009348  [ 1300/ 3383]
loss: 0.004082  [ 1400/ 3383]
loss: 0.015043  [ 1500/ 3383]
loss: 0.002510  [ 1600/ 3383]
loss: 0.001570  [ 1700/ 3383]
loss: 0.011798  [ 1800/ 3383]
loss: 0.014428  [ 1900/ 3383]
loss: 0.002937  [ 2000/ 3383]
loss: 0.003461  [ 2100/ 3383]
loss: 0.008692  [ 2200/ 3383]
loss: 0.001558  [ 2300/ 3383]
loss: 0.004025  [ 2400/ 3383]
loss: 0.026789  [ 2500/ 3383]
loss: 0.001377  [ 2600/ 3383]
loss: 0.003096  [ 2700/ 3383]
loss: 0.006353  [ 2800/ 3383]
loss: 0.005754  [ 2900/ 3383]
loss: 0.003827  [ 3000/ 3383]
loss: 0.004537  [ 3100/ 3383]
loss: 0.064874  [ 3200/ 3383]
loss: 0.002475  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.003831  [    0/ 3383]
loss: 0.005856  [  100/ 3383]
loss: 0.005745  [  200/ 3383]
loss: 0.002405  [  300/ 3383]
loss: 0.002989  [  400/ 3383]
loss: 0.004671  [  500/ 3383]
loss: 0.001110  [  600/ 3383]
loss: 0.002221  [  700/ 3383]
loss: 0.007374  [  800/ 3383]
loss: 0.001503  [  900/ 3383]
loss: 0.090926  [ 1000/ 3383]
loss: 0.057738  [ 1100/ 3383]
loss: 0.022940  [ 1200/ 3383]
loss: 0.009335  [ 1300/ 3383]
loss: 0.004105  [ 1400/ 3383]
loss: 0.015032  [ 1500/ 3383]
loss: 0.002496  [ 1600/ 3383]
loss: 0.001577  [ 1700/ 3383]
loss: 0.011838  [ 1800/ 3383]
loss: 0.014380  [ 1900/ 3383]
loss: 0.002970  [ 2000/ 3383]
loss: 0.003437  [ 2100/ 3383]
loss: 0.008651  [ 2200/ 3383]
loss: 0.001594  [ 2300/ 3383]
loss: 0.003954  [ 2400/ 3383]
loss: 0.027507  [ 2500/ 3383]
loss: 0.001172  [ 2600/ 3383]
loss: 0.003012  [ 2700/ 3383]
loss: 0.006256  [ 2800/ 3383]
loss: 0.005732  [ 2900/ 3383]
loss: 0.003843  [ 3000/ 3383]
loss: 0.004536  [ 3100/ 3383]
loss: 0.065005  [ 3200/ 3383]
loss: 0.002486  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.003850  [    0/ 3383]
loss: 0.005821  [  100/ 3383]
loss: 0.005650  [  200/ 3383]
loss: 0.002455  [  300/ 3383]
loss: 0.002910  [  400/ 3383]
loss: 0.004661  [  500/ 3383]
loss: 0.001089  [  600/ 3383]
loss: 0.002341  [  700/ 3383]
loss: 0.007377  [  800/ 3383]
loss: 0.001540  [  900/ 3383]
loss: 0.091269  [ 1000/ 3383]
loss: 0.057764  [ 1100/ 3383]
loss: 0.023001  [ 1200/ 3383]
loss: 0.009334  [ 1300/ 3383]
loss: 0.004113  [ 1400/ 3383]
loss: 0.015030  [ 1500/ 3383]
loss: 0.002520  [ 1600/ 3383]
loss: 0.001559  [ 1700/ 3383]
loss: 0.011696  [ 1800/ 3383]
loss: 0.014311  [ 1900/ 3383]
loss: 0.002873  [ 2000/ 3383]
loss: 0.003431  [ 2100/ 3383]
loss: 0.008618  [ 2200/ 3383]
loss: 0.001593  [ 2300/ 3383]
loss: 0.003843  [ 2400/ 3383]
loss: 0.027769  [ 2500/ 3383]
loss: 0.001228  [ 2600/ 3383]
loss: 0.003019  [ 2700/ 3383]
loss: 0.006246  [ 2800/ 3383]
loss: 0.005754  [ 2900/ 3383]
loss: 0.003780  [ 3000/ 3383]
loss: 0.004501  [ 3100/ 3383]
loss: 0.065294  [ 3200/ 3383]
loss: 0.002509  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.003953  [    0/ 3383]
loss: 0.005902  [  100/ 3383]
loss: 0.005577  [  200/ 3383]
loss: 0.002524  [  300/ 3383]
loss: 0.002861  [  400/ 3383]
loss: 0.004652  [  500/ 3383]
loss: 0.001161  [  600/ 3383]
loss: 0.002131  [  700/ 3383]
loss: 0.007207  [  800/ 3383]
loss: 0.001530  [  900/ 3383]
loss: 0.091334  [ 1000/ 3383]
loss: 0.057632  [ 1100/ 3383]
loss: 0.023032  [ 1200/ 3383]
loss: 0.009352  [ 1300/ 3383]
loss: 0.003893  [ 1400/ 3383]
loss: 0.015124  [ 1500/ 3383]
loss: 0.002580  [ 1600/ 3383]
loss: 0.001535  [ 1700/ 3383]
loss: 0.011244  [ 1800/ 3383]
loss: 0.014187  [ 1900/ 3383]
loss: 0.002859  [ 2000/ 3383]
loss: 0.003447  [ 2100/ 3383]
loss: 0.008720  [ 2200/ 3383]
loss: 0.001702  [ 2300/ 3383]
loss: 0.003725  [ 2400/ 3383]
loss: 0.027124  [ 2500/ 3383]
loss: 0.001325  [ 2600/ 3383]
loss: 0.002617  [ 2700/ 3383]
loss: 0.006224  [ 2800/ 3383]
loss: 0.005814  [ 2900/ 3383]
loss: 0.003983  [ 3000/ 3383]
loss: 0.004553  [ 3100/ 3383]
loss: 0.064501  [ 3200/ 3383]
loss: 0.002434  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [-1.5528396   0.64979565]
[2 1 2 ... 0 1 2]
[0 2 0 ... 1 2 0]
Cluster 0 Occurrences: 1115; KMEANS: 1239
Cluster 1 Occurrences: 1113; KMEANS: 1069
Cluster 2 Occurrences: 1155; KMEANS: 1075
Centroids: [[-0.6214026, 0.20016436], [-0.6069743, 0.79325163], [-1.6852007, 0.8739813]]
Centroids: [[-1.6904297, 0.87962115], [-0.58146554, 0.1778571], [-0.5570271, 0.7772473]]
Contingency Matrix: 
[[  35 1064   16]
 [  52    4 1057]
 [1152    1    2]]
[[-1, 1064, 16], [-1, 4, 1057], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1057], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1064   16   35]
 [   4 1057   52]
 [   1    2 1152]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1064, 1057, 1152], Sum: 3273
All_Elements: [1064, 16, 35, 4, 1057, 52, 1, 2, 1152], Sum: 3383
Accuracy: 0.9674844812296778
Done!
