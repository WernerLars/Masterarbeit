Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_53_50
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E74337C668>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x000001E733637198>
Epoch 1
-------------------------------
loss: 0.269845  [    0/ 3411]
loss: 0.158745  [  100/ 3411]
loss: 0.158723  [  200/ 3411]
loss: 0.019979  [  300/ 3411]
loss: 0.035818  [  400/ 3411]
loss: 0.032178  [  500/ 3411]
loss: 0.013263  [  600/ 3411]
loss: 0.029458  [  700/ 3411]
loss: 0.026973  [  800/ 3411]
loss: 0.038906  [  900/ 3411]
loss: 0.003977  [ 1000/ 3411]
loss: 0.059293  [ 1100/ 3411]
loss: 0.020445  [ 1200/ 3411]
loss: 0.021120  [ 1300/ 3411]
loss: 0.021546  [ 1400/ 3411]
loss: 0.063374  [ 1500/ 3411]
loss: 0.034702  [ 1600/ 3411]
loss: 0.034576  [ 1700/ 3411]
loss: 0.020192  [ 1800/ 3411]
loss: 0.005376  [ 1900/ 3411]
loss: 0.023422  [ 2000/ 3411]
loss: 0.006378  [ 2100/ 3411]
loss: 0.007376  [ 2200/ 3411]
loss: 0.091785  [ 2300/ 3411]
loss: 0.012737  [ 2400/ 3411]
loss: 0.012401  [ 2500/ 3411]
loss: 0.006558  [ 2600/ 3411]
loss: 0.010477  [ 2700/ 3411]
loss: 0.024640  [ 2800/ 3411]
loss: 0.016289  [ 2900/ 3411]
loss: 0.012788  [ 3000/ 3411]
loss: 0.005578  [ 3100/ 3411]
loss: 0.020433  [ 3200/ 3411]
loss: 0.013207  [ 3300/ 3411]
loss: 0.008217  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.013708  [    0/ 3411]
loss: 0.010365  [  100/ 3411]
loss: 0.012527  [  200/ 3411]
loss: 0.015419  [  300/ 3411]
loss: 0.039396  [  400/ 3411]
loss: 0.012483  [  500/ 3411]
loss: 0.002831  [  600/ 3411]
loss: 0.004839  [  700/ 3411]
loss: 0.024078  [  800/ 3411]
loss: 0.016293  [  900/ 3411]
loss: 0.003781  [ 1000/ 3411]
loss: 0.009821  [ 1100/ 3411]
loss: 0.018123  [ 1200/ 3411]
loss: 0.011321  [ 1300/ 3411]
loss: 0.017751  [ 1400/ 3411]
loss: 0.060543  [ 1500/ 3411]
loss: 0.017356  [ 1600/ 3411]
loss: 0.019765  [ 1700/ 3411]
loss: 0.016692  [ 1800/ 3411]
loss: 0.005512  [ 1900/ 3411]
loss: 0.029385  [ 2000/ 3411]
loss: 0.005831  [ 2100/ 3411]
loss: 0.007390  [ 2200/ 3411]
loss: 0.134360  [ 2300/ 3411]
loss: 0.015123  [ 2400/ 3411]
loss: 0.008163  [ 2500/ 3411]
loss: 0.007266  [ 2600/ 3411]
loss: 0.009132  [ 2700/ 3411]
loss: 0.024879  [ 2800/ 3411]
loss: 0.014325  [ 2900/ 3411]
loss: 0.011564  [ 3000/ 3411]
loss: 0.005706  [ 3100/ 3411]
loss: 0.022596  [ 3200/ 3411]
loss: 0.013946  [ 3300/ 3411]
loss: 0.007319  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.017893  [    0/ 3411]
loss: 0.012827  [  100/ 3411]
loss: 0.012844  [  200/ 3411]
loss: 0.013524  [  300/ 3411]
loss: 0.036935  [  400/ 3411]
loss: 0.011127  [  500/ 3411]
loss: 0.003231  [  600/ 3411]
loss: 0.004302  [  700/ 3411]
loss: 0.022118  [  800/ 3411]
loss: 0.016192  [  900/ 3411]
loss: 0.003737  [ 1000/ 3411]
loss: 0.008818  [ 1100/ 3411]
loss: 0.019005  [ 1200/ 3411]
loss: 0.011664  [ 1300/ 3411]
loss: 0.018465  [ 1400/ 3411]
loss: 0.061535  [ 1500/ 3411]
loss: 0.019060  [ 1600/ 3411]
loss: 0.018298  [ 1700/ 3411]
loss: 0.014131  [ 1800/ 3411]
loss: 0.005903  [ 1900/ 3411]
loss: 0.032156  [ 2000/ 3411]
loss: 0.006237  [ 2100/ 3411]
loss: 0.007560  [ 2200/ 3411]
loss: 0.143394  [ 2300/ 3411]
loss: 0.016363  [ 2400/ 3411]
loss: 0.007405  [ 2500/ 3411]
loss: 0.006701  [ 2600/ 3411]
loss: 0.008614  [ 2700/ 3411]
loss: 0.025452  [ 2800/ 3411]
loss: 0.013193  [ 2900/ 3411]
loss: 0.011109  [ 3000/ 3411]
loss: 0.005766  [ 3100/ 3411]
loss: 0.022122  [ 3200/ 3411]
loss: 0.014111  [ 3300/ 3411]
loss: 0.006284  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.018798  [    0/ 3411]
loss: 0.013666  [  100/ 3411]
loss: 0.013929  [  200/ 3411]
loss: 0.013021  [  300/ 3411]
loss: 0.035511  [  400/ 3411]
loss: 0.010601  [  500/ 3411]
loss: 0.003243  [  600/ 3411]
loss: 0.003530  [  700/ 3411]
loss: 0.021044  [  800/ 3411]
loss: 0.016177  [  900/ 3411]
loss: 0.003745  [ 1000/ 3411]
loss: 0.008677  [ 1100/ 3411]
loss: 0.019078  [ 1200/ 3411]
loss: 0.011520  [ 1300/ 3411]
loss: 0.019092  [ 1400/ 3411]
loss: 0.063955  [ 1500/ 3411]
loss: 0.019873  [ 1600/ 3411]
loss: 0.017228  [ 1700/ 3411]
loss: 0.012390  [ 1800/ 3411]
loss: 0.006167  [ 1900/ 3411]
loss: 0.033163  [ 2000/ 3411]
loss: 0.006671  [ 2100/ 3411]
loss: 0.007716  [ 2200/ 3411]
loss: 0.146557  [ 2300/ 3411]
loss: 0.016777  [ 2400/ 3411]
loss: 0.007072  [ 2500/ 3411]
loss: 0.006429  [ 2600/ 3411]
loss: 0.008304  [ 2700/ 3411]
loss: 0.025685  [ 2800/ 3411]
loss: 0.012841  [ 2900/ 3411]
loss: 0.011087  [ 3000/ 3411]
loss: 0.005934  [ 3100/ 3411]
loss: 0.022043  [ 3200/ 3411]
loss: 0.013991  [ 3300/ 3411]
loss: 0.005636  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.018782  [    0/ 3411]
loss: 0.013899  [  100/ 3411]
loss: 0.014760  [  200/ 3411]
loss: 0.012761  [  300/ 3411]
loss: 0.034692  [  400/ 3411]
loss: 0.010171  [  500/ 3411]
loss: 0.003227  [  600/ 3411]
loss: 0.003322  [  700/ 3411]
loss: 0.020565  [  800/ 3411]
loss: 0.016256  [  900/ 3411]
loss: 0.003750  [ 1000/ 3411]
loss: 0.008466  [ 1100/ 3411]
loss: 0.019222  [ 1200/ 3411]
loss: 0.011483  [ 1300/ 3411]
loss: 0.019463  [ 1400/ 3411]
loss: 0.066656  [ 1500/ 3411]
loss: 0.020322  [ 1600/ 3411]
loss: 0.016239  [ 1700/ 3411]
loss: 0.011624  [ 1800/ 3411]
loss: 0.006189  [ 1900/ 3411]
loss: 0.033628  [ 2000/ 3411]
loss: 0.006538  [ 2100/ 3411]
loss: 0.007876  [ 2200/ 3411]
loss: 0.148243  [ 2300/ 3411]
loss: 0.016943  [ 2400/ 3411]
loss: 0.006880  [ 2500/ 3411]
loss: 0.006297  [ 2600/ 3411]
loss: 0.008017  [ 2700/ 3411]
loss: 0.025831  [ 2800/ 3411]
loss: 0.012358  [ 2900/ 3411]
loss: 0.010670  [ 3000/ 3411]
loss: 0.005895  [ 3100/ 3411]
loss: 0.021843  [ 3200/ 3411]
loss: 0.013824  [ 3300/ 3411]
loss: 0.005321  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.018569  [    0/ 3411]
loss: 0.014019  [  100/ 3411]
loss: 0.015338  [  200/ 3411]
loss: 0.012676  [  300/ 3411]
loss: 0.034160  [  400/ 3411]
loss: 0.009996  [  500/ 3411]
loss: 0.003251  [  600/ 3411]
loss: 0.003220  [  700/ 3411]
loss: 0.020091  [  800/ 3411]
loss: 0.016250  [  900/ 3411]
loss: 0.003748  [ 1000/ 3411]
loss: 0.008357  [ 1100/ 3411]
loss: 0.019301  [ 1200/ 3411]
loss: 0.011536  [ 1300/ 3411]
loss: 0.019709  [ 1400/ 3411]
loss: 0.068360  [ 1500/ 3411]
loss: 0.020938  [ 1600/ 3411]
loss: 0.015596  [ 1700/ 3411]
loss: 0.011269  [ 1800/ 3411]
loss: 0.006254  [ 1900/ 3411]
loss: 0.033870  [ 2000/ 3411]
loss: 0.006393  [ 2100/ 3411]
loss: 0.008007  [ 2200/ 3411]
loss: 0.149254  [ 2300/ 3411]
loss: 0.016901  [ 2400/ 3411]
loss: 0.006768  [ 2500/ 3411]
loss: 0.006305  [ 2600/ 3411]
loss: 0.007834  [ 2700/ 3411]
loss: 0.025958  [ 2800/ 3411]
loss: 0.011898  [ 2900/ 3411]
loss: 0.010604  [ 3000/ 3411]
loss: 0.005853  [ 3100/ 3411]
loss: 0.021805  [ 3200/ 3411]
loss: 0.013664  [ 3300/ 3411]
loss: 0.005101  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.018318  [    0/ 3411]
loss: 0.014136  [  100/ 3411]
loss: 0.015922  [  200/ 3411]
loss: 0.012631  [  300/ 3411]
loss: 0.033606  [  400/ 3411]
loss: 0.009763  [  500/ 3411]
loss: 0.003261  [  600/ 3411]
loss: 0.003318  [  700/ 3411]
loss: 0.019922  [  800/ 3411]
loss: 0.016462  [  900/ 3411]
loss: 0.003748  [ 1000/ 3411]
loss: 0.008249  [ 1100/ 3411]
loss: 0.019397  [ 1200/ 3411]
loss: 0.011642  [ 1300/ 3411]
loss: 0.019639  [ 1400/ 3411]
loss: 0.069953  [ 1500/ 3411]
loss: 0.021413  [ 1600/ 3411]
loss: 0.014968  [ 1700/ 3411]
loss: 0.011183  [ 1800/ 3411]
loss: 0.006279  [ 1900/ 3411]
loss: 0.033981  [ 2000/ 3411]
loss: 0.006394  [ 2100/ 3411]
loss: 0.008087  [ 2200/ 3411]
loss: 0.149669  [ 2300/ 3411]
loss: 0.017250  [ 2400/ 3411]
loss: 0.006755  [ 2500/ 3411]
loss: 0.006373  [ 2600/ 3411]
loss: 0.007700  [ 2700/ 3411]
loss: 0.026042  [ 2800/ 3411]
loss: 0.011474  [ 2900/ 3411]
loss: 0.010480  [ 3000/ 3411]
loss: 0.006031  [ 3100/ 3411]
loss: 0.022030  [ 3200/ 3411]
loss: 0.013534  [ 3300/ 3411]
loss: 0.004910  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.018340  [    0/ 3411]
loss: 0.014198  [  100/ 3411]
loss: 0.016214  [  200/ 3411]
loss: 0.012524  [  300/ 3411]
loss: 0.033157  [  400/ 3411]
loss: 0.009515  [  500/ 3411]
loss: 0.003291  [  600/ 3411]
loss: 0.003379  [  700/ 3411]
loss: 0.019726  [  800/ 3411]
loss: 0.016753  [  900/ 3411]
loss: 0.003767  [ 1000/ 3411]
loss: 0.007975  [ 1100/ 3411]
loss: 0.019529  [ 1200/ 3411]
loss: 0.011821  [ 1300/ 3411]
loss: 0.019784  [ 1400/ 3411]
loss: 0.071594  [ 1500/ 3411]
loss: 0.021554  [ 1600/ 3411]
loss: 0.014420  [ 1700/ 3411]
loss: 0.011251  [ 1800/ 3411]
loss: 0.006285  [ 1900/ 3411]
loss: 0.033970  [ 2000/ 3411]
loss: 0.005864  [ 2100/ 3411]
loss: 0.008216  [ 2200/ 3411]
loss: 0.150220  [ 2300/ 3411]
loss: 0.017327  [ 2400/ 3411]
loss: 0.006726  [ 2500/ 3411]
loss: 0.006385  [ 2600/ 3411]
loss: 0.007586  [ 2700/ 3411]
loss: 0.026257  [ 2800/ 3411]
loss: 0.011203  [ 2900/ 3411]
loss: 0.010537  [ 3000/ 3411]
loss: 0.005656  [ 3100/ 3411]
loss: 0.022152  [ 3200/ 3411]
loss: 0.013474  [ 3300/ 3411]
loss: 0.004695  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [ 1.1158645 -0.9202168]
[0 2 0 ... 1 1 2]
[1 2 1 ... 1 1 0]
Cluster 0 Occurrences: 1181; KMEANS: 554
Cluster 1 Occurrences: 1098; KMEANS: 2281
Cluster 2 Occurrences: 1132; KMEANS: 576
Centroids: [[1.1949501, -0.76764333], [0.71039265, -0.43680584], [-2.176585, 0.4256637]]
Centroids: [[-2.642999, 0.5883561], [0.961502, -0.60923815], [-1.738909, 0.2766921]]
Contingency Matrix: 
[[   0 1180    1]
 [   0 1096    2]
 [ 554    5  573]]
[[-1, -1, -1], [0, -1, 2], [554, -1, 573]]
[[-1, -1, -1], [0, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 1, 2: 2, 1: 0}
New Contingency Matrix: 
[[1180    0    1]
 [1096    0    2]
 [   5  554  573]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [1180, 0, 573], Sum: 1753
All_Elements: [1180, 0, 1, 1096, 0, 2, 5, 554, 573], Sum: 3411
Accuracy: 0.5139255350337144
Done!
