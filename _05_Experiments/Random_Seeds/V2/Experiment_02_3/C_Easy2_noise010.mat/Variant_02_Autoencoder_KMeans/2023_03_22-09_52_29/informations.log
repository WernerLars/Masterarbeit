Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Easy2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_52_29
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E785E4D550>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
<torch.utils.data.dataloader.DataLoader object at 0x000001E733637160>
Epoch 1
-------------------------------
loss: 0.224554  [    0/ 3520]
loss: 0.088354  [  100/ 3520]
loss: 0.194174  [  200/ 3520]
loss: 0.015221  [  300/ 3520]
loss: 0.116042  [  400/ 3520]
loss: 0.146831  [  500/ 3520]
loss: 0.013873  [  600/ 3520]
loss: 0.009325  [  700/ 3520]
loss: 0.007206  [  800/ 3520]
loss: 0.011263  [  900/ 3520]
loss: 0.004912  [ 1000/ 3520]
loss: 0.011355  [ 1100/ 3520]
loss: 0.016371  [ 1200/ 3520]
loss: 0.031455  [ 1300/ 3520]
loss: 0.013564  [ 1400/ 3520]
loss: 0.003184  [ 1500/ 3520]
loss: 0.004478  [ 1600/ 3520]
loss: 0.003764  [ 1700/ 3520]
loss: 0.122717  [ 1800/ 3520]
loss: 0.007679  [ 1900/ 3520]
loss: 0.014659  [ 2000/ 3520]
loss: 0.007884  [ 2100/ 3520]
loss: 0.008960  [ 2200/ 3520]
loss: 0.085341  [ 2300/ 3520]
loss: 0.008288  [ 2400/ 3520]
loss: 0.007230  [ 2500/ 3520]
loss: 0.013811  [ 2600/ 3520]
loss: 0.002707  [ 2700/ 3520]
loss: 0.014281  [ 2800/ 3520]
loss: 0.007715  [ 2900/ 3520]
loss: 0.012482  [ 3000/ 3520]
loss: 0.023700  [ 3100/ 3520]
loss: 0.005471  [ 3200/ 3520]
loss: 0.002885  [ 3300/ 3520]
loss: 0.004124  [ 3400/ 3520]
loss: 0.011526  [ 3500/ 3520]
Epoch 2
-------------------------------
loss: 0.006170  [    0/ 3520]
loss: 0.003171  [  100/ 3520]
loss: 0.193224  [  200/ 3520]
loss: 0.004160  [  300/ 3520]
loss: 0.075960  [  400/ 3520]
loss: 0.120443  [  500/ 3520]
loss: 0.005650  [  600/ 3520]
loss: 0.005120  [  700/ 3520]
loss: 0.004327  [  800/ 3520]
loss: 0.006507  [  900/ 3520]
loss: 0.003157  [ 1000/ 3520]
loss: 0.008513  [ 1100/ 3520]
loss: 0.004127  [ 1200/ 3520]
loss: 0.012193  [ 1300/ 3520]
loss: 0.012934  [ 1400/ 3520]
loss: 0.001814  [ 1500/ 3520]
loss: 0.005493  [ 1600/ 3520]
loss: 0.003915  [ 1700/ 3520]
loss: 0.120104  [ 1800/ 3520]
loss: 0.008284  [ 1900/ 3520]
loss: 0.008826  [ 2000/ 3520]
loss: 0.006799  [ 2100/ 3520]
loss: 0.009437  [ 2200/ 3520]
loss: 0.071903  [ 2300/ 3520]
loss: 0.006648  [ 2400/ 3520]
loss: 0.009036  [ 2500/ 3520]
loss: 0.013924  [ 2600/ 3520]
loss: 0.002597  [ 2700/ 3520]
loss: 0.009460  [ 2800/ 3520]
loss: 0.003523  [ 2900/ 3520]
loss: 0.012097  [ 3000/ 3520]
loss: 0.019052  [ 3100/ 3520]
loss: 0.005503  [ 3200/ 3520]
loss: 0.001348  [ 3300/ 3520]
loss: 0.004680  [ 3400/ 3520]
loss: 0.009248  [ 3500/ 3520]
Epoch 3
-------------------------------
loss: 0.002397  [    0/ 3520]
loss: 0.004000  [  100/ 3520]
loss: 0.202275  [  200/ 3520]
loss: 0.005147  [  300/ 3520]
loss: 0.068333  [  400/ 3520]
loss: 0.094922  [  500/ 3520]
loss: 0.005848  [  600/ 3520]
loss: 0.005433  [  700/ 3520]
loss: 0.003472  [  800/ 3520]
loss: 0.004099  [  900/ 3520]
loss: 0.003191  [ 1000/ 3520]
loss: 0.007990  [ 1100/ 3520]
loss: 0.006597  [ 1200/ 3520]
loss: 0.006921  [ 1300/ 3520]
loss: 0.012421  [ 1400/ 3520]
loss: 0.001999  [ 1500/ 3520]
loss: 0.005469  [ 1600/ 3520]
loss: 0.003870  [ 1700/ 3520]
loss: 0.116672  [ 1800/ 3520]
loss: 0.008226  [ 1900/ 3520]
loss: 0.007936  [ 2000/ 3520]
loss: 0.006663  [ 2100/ 3520]
loss: 0.009388  [ 2200/ 3520]
loss: 0.065897  [ 2300/ 3520]
loss: 0.005176  [ 2400/ 3520]
loss: 0.009449  [ 2500/ 3520]
loss: 0.014280  [ 2600/ 3520]
loss: 0.002493  [ 2700/ 3520]
loss: 0.012046  [ 2800/ 3520]
loss: 0.002486  [ 2900/ 3520]
loss: 0.012588  [ 3000/ 3520]
loss: 0.016622  [ 3100/ 3520]
loss: 0.005581  [ 3200/ 3520]
loss: 0.001058  [ 3300/ 3520]
loss: 0.005710  [ 3400/ 3520]
loss: 0.008850  [ 3500/ 3520]
Epoch 4
-------------------------------
loss: 0.004041  [    0/ 3520]
loss: 0.003934  [  100/ 3520]
loss: 0.180763  [  200/ 3520]
loss: 0.005513  [  300/ 3520]
loss: 0.052161  [  400/ 3520]
loss: 0.081774  [  500/ 3520]
loss: 0.006115  [  600/ 3520]
loss: 0.006253  [  700/ 3520]
loss: 0.004105  [  800/ 3520]
loss: 0.002867  [  900/ 3520]
loss: 0.003302  [ 1000/ 3520]
loss: 0.008077  [ 1100/ 3520]
loss: 0.008121  [ 1200/ 3520]
loss: 0.003280  [ 1300/ 3520]
loss: 0.011248  [ 1400/ 3520]
loss: 0.001961  [ 1500/ 3520]
loss: 0.005253  [ 1600/ 3520]
loss: 0.004037  [ 1700/ 3520]
loss: 0.112492  [ 1800/ 3520]
loss: 0.008133  [ 1900/ 3520]
loss: 0.007556  [ 2000/ 3520]
loss: 0.006838  [ 2100/ 3520]
loss: 0.008957  [ 2200/ 3520]
loss: 0.060965  [ 2300/ 3520]
loss: 0.004522  [ 2400/ 3520]
loss: 0.009538  [ 2500/ 3520]
loss: 0.014038  [ 2600/ 3520]
loss: 0.002593  [ 2700/ 3520]
loss: 0.013143  [ 2800/ 3520]
loss: 0.002301  [ 2900/ 3520]
loss: 0.012337  [ 3000/ 3520]
loss: 0.014165  [ 3100/ 3520]
loss: 0.005723  [ 3200/ 3520]
loss: 0.000869  [ 3300/ 3520]
loss: 0.007091  [ 3400/ 3520]
loss: 0.009034  [ 3500/ 3520]
Epoch 5
-------------------------------
loss: 0.006496  [    0/ 3520]
loss: 0.003546  [  100/ 3520]
loss: 0.150346  [  200/ 3520]
loss: 0.005560  [  300/ 3520]
loss: 0.040842  [  400/ 3520]
loss: 0.074638  [  500/ 3520]
loss: 0.006004  [  600/ 3520]
loss: 0.006891  [  700/ 3520]
loss: 0.004699  [  800/ 3520]
loss: 0.002275  [  900/ 3520]
loss: 0.003672  [ 1000/ 3520]
loss: 0.008030  [ 1100/ 3520]
loss: 0.009569  [ 1200/ 3520]
loss: 0.001890  [ 1300/ 3520]
loss: 0.009769  [ 1400/ 3520]
loss: 0.002256  [ 1500/ 3520]
loss: 0.005278  [ 1600/ 3520]
loss: 0.003385  [ 1700/ 3520]
loss: 0.100741  [ 1800/ 3520]
loss: 0.007917  [ 1900/ 3520]
loss: 0.005541  [ 2000/ 3520]
loss: 0.007041  [ 2100/ 3520]
loss: 0.008659  [ 2200/ 3520]
loss: 0.054209  [ 2300/ 3520]
loss: 0.003945  [ 2400/ 3520]
loss: 0.009692  [ 2500/ 3520]
loss: 0.012954  [ 2600/ 3520]
loss: 0.002663  [ 2700/ 3520]
loss: 0.014672  [ 2800/ 3520]
loss: 0.002506  [ 2900/ 3520]
loss: 0.011880  [ 3000/ 3520]
loss: 0.013470  [ 3100/ 3520]
loss: 0.005847  [ 3200/ 3520]
loss: 0.000978  [ 3300/ 3520]
loss: 0.008079  [ 3400/ 3520]
loss: 0.009209  [ 3500/ 3520]
Epoch 6
-------------------------------
loss: 0.008458  [    0/ 3520]
loss: 0.002655  [  100/ 3520]
loss: 0.135349  [  200/ 3520]
loss: 0.005383  [  300/ 3520]
loss: 0.036229  [  400/ 3520]
loss: 0.070267  [  500/ 3520]
loss: 0.006199  [  600/ 3520]
loss: 0.007339  [  700/ 3520]
loss: 0.005158  [  800/ 3520]
loss: 0.002217  [  900/ 3520]
loss: 0.004023  [ 1000/ 3520]
loss: 0.008133  [ 1100/ 3520]
loss: 0.010922  [ 1200/ 3520]
loss: 0.002309  [ 1300/ 3520]
loss: 0.008630  [ 1400/ 3520]
loss: 0.002066  [ 1500/ 3520]
loss: 0.005056  [ 1600/ 3520]
loss: 0.003114  [ 1700/ 3520]
loss: 0.098741  [ 1800/ 3520]
loss: 0.007820  [ 1900/ 3520]
loss: 0.004056  [ 2000/ 3520]
loss: 0.006920  [ 2100/ 3520]
loss: 0.008692  [ 2200/ 3520]
loss: 0.053096  [ 2300/ 3520]
loss: 0.003939  [ 2400/ 3520]
loss: 0.009847  [ 2500/ 3520]
loss: 0.010664  [ 2600/ 3520]
loss: 0.002642  [ 2700/ 3520]
loss: 0.015527  [ 2800/ 3520]
loss: 0.002912  [ 2900/ 3520]
loss: 0.011341  [ 3000/ 3520]
loss: 0.012493  [ 3100/ 3520]
loss: 0.006058  [ 3200/ 3520]
loss: 0.001019  [ 3300/ 3520]
loss: 0.008670  [ 3400/ 3520]
loss: 0.009434  [ 3500/ 3520]
Epoch 7
-------------------------------
loss: 0.009976  [    0/ 3520]
loss: 0.002528  [  100/ 3520]
loss: 0.117210  [  200/ 3520]
loss: 0.005115  [  300/ 3520]
loss: 0.033603  [  400/ 3520]
loss: 0.068711  [  500/ 3520]
loss: 0.006365  [  600/ 3520]
loss: 0.007775  [  700/ 3520]
loss: 0.005290  [  800/ 3520]
loss: 0.002168  [  900/ 3520]
loss: 0.004280  [ 1000/ 3520]
loss: 0.008389  [ 1100/ 3520]
loss: 0.011541  [ 1200/ 3520]
loss: 0.002877  [ 1300/ 3520]
loss: 0.007931  [ 1400/ 3520]
loss: 0.002089  [ 1500/ 3520]
loss: 0.004747  [ 1600/ 3520]
loss: 0.003062  [ 1700/ 3520]
loss: 0.097034  [ 1800/ 3520]
loss: 0.007650  [ 1900/ 3520]
loss: 0.003420  [ 2000/ 3520]
loss: 0.006841  [ 2100/ 3520]
loss: 0.008400  [ 2200/ 3520]
loss: 0.050441  [ 2300/ 3520]
loss: 0.003949  [ 2400/ 3520]
loss: 0.009710  [ 2500/ 3520]
loss: 0.009290  [ 2600/ 3520]
loss: 0.002707  [ 2700/ 3520]
loss: 0.015858  [ 2800/ 3520]
loss: 0.003004  [ 2900/ 3520]
loss: 0.010644  [ 3000/ 3520]
loss: 0.012270  [ 3100/ 3520]
loss: 0.006363  [ 3200/ 3520]
loss: 0.001000  [ 3300/ 3520]
loss: 0.009791  [ 3400/ 3520]
loss: 0.010032  [ 3500/ 3520]
Epoch 8
-------------------------------
loss: 0.011473  [    0/ 3520]
loss: 0.001823  [  100/ 3520]
loss: 0.098210  [  200/ 3520]
loss: 0.004948  [  300/ 3520]
loss: 0.030181  [  400/ 3520]
loss: 0.060724  [  500/ 3520]
loss: 0.006080  [  600/ 3520]
loss: 0.007965  [  700/ 3520]
loss: 0.005021  [  800/ 3520]
loss: 0.002333  [  900/ 3520]
loss: 0.004321  [ 1000/ 3520]
loss: 0.008305  [ 1100/ 3520]
loss: 0.012516  [ 1200/ 3520]
loss: 0.003587  [ 1300/ 3520]
loss: 0.007419  [ 1400/ 3520]
loss: 0.002202  [ 1500/ 3520]
loss: 0.004643  [ 1600/ 3520]
loss: 0.003105  [ 1700/ 3520]
loss: 0.095963  [ 1800/ 3520]
loss: 0.007632  [ 1900/ 3520]
loss: 0.002913  [ 2000/ 3520]
loss: 0.007036  [ 2100/ 3520]
loss: 0.007907  [ 2200/ 3520]
loss: 0.043903  [ 2300/ 3520]
loss: 0.003654  [ 2400/ 3520]
loss: 0.009748  [ 2500/ 3520]
loss: 0.008389  [ 2600/ 3520]
loss: 0.002837  [ 2700/ 3520]
loss: 0.016000  [ 2800/ 3520]
loss: 0.003108  [ 2900/ 3520]
loss: 0.010249  [ 3000/ 3520]
loss: 0.010945  [ 3100/ 3520]
loss: 0.006346  [ 3200/ 3520]
loss: 0.001071  [ 3300/ 3520]
loss: 0.010637  [ 3400/ 3520]
loss: 0.010049  [ 3500/ 3520]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3520
First Spike after testing: [ 1.1849602 -0.883424 ]
[0 1 2 ... 0 1 2]
[2 1 0 ... 2 1 0]
Cluster 0 Occurrences: 1160; KMEANS: 1209
Cluster 1 Occurrences: 1146; KMEANS: 1107
Cluster 2 Occurrences: 1214; KMEANS: 1204
Centroids: [[1.6024264, -0.7706013], [0.73969597, -0.27921018], [-1.5953381, 0.42789376]]
Centroids: [[-1.6013464, 0.43374157], [0.68942887, -0.27445593], [1.6134516, -0.7599503]]
Contingency Matrix: 
[[   0   12 1148]
 [   0 1091   55]
 [1209    4    1]]
[[-1, 12, 1148], [-1, 1091, 55], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1091, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1148   12    0]
 [  55 1091    0]
 [   1    4 1209]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1148, 1091, 1209], Sum: 3448
All_Elements: [1148, 12, 0, 55, 1091, 0, 1, 4, 1209], Sum: 3520
Accuracy: 0.9795454545454545
Done!
