Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Easy2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_51_12
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E732955198>
Sampling rate: 24000.0
Raw: [ 0.11862069  0.1123084   0.10401825 ... -0.10219323 -0.10268373
 -0.08956559]
Times: [    346     799    1005 ... 1436867 1437273 1437800]
Cluster: [3 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3410
First aligned Spike Frame: [ 2.05661766e-03  8.27536867e-03  1.66427268e-02  2.31246655e-02
  2.28936935e-02  1.99169368e-02  2.25281834e-02  3.37605443e-02
  4.94182133e-02  6.24484568e-02  8.42111946e-02  1.71357846e-01
  3.88441746e-01  6.99052305e-01  9.59509287e-01  1.03608873e+00
  9.29169963e-01  7.55567481e-01  6.10726415e-01  5.06818519e-01
  4.23878029e-01  3.55610047e-01  3.01970228e-01  2.53702042e-01
  1.98274486e-01  1.32802904e-01  6.40690121e-02  7.96454927e-04
 -5.66201776e-02 -1.11669131e-01 -1.62581026e-01 -2.01746625e-01
 -2.23071447e-01 -2.29516190e-01 -2.30160694e-01 -2.27148529e-01
 -2.18080531e-01 -2.04276810e-01 -1.90750996e-01 -1.81098693e-01
 -1.72421418e-01 -1.61640218e-01 -1.48460304e-01 -1.32332846e-01
 -1.13338953e-01 -9.43725979e-02 -7.56249106e-02]
Cluster 0, Occurrences: 1130
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1167
<torch.utils.data.dataloader.DataLoader object at 0x000001E7328FB588>
Epoch 1
-------------------------------
loss: 0.214226  [    0/ 3410]
loss: 0.118638  [  100/ 3410]
loss: 0.030728  [  200/ 3410]
loss: 0.027333  [  300/ 3410]
loss: 0.005372  [  400/ 3410]
loss: 0.003669  [  500/ 3410]
loss: 0.001338  [  600/ 3410]
loss: 0.004720  [  700/ 3410]
loss: 0.006606  [  800/ 3410]
loss: 0.005119  [  900/ 3410]
loss: 0.012310  [ 1000/ 3410]
loss: 0.003259  [ 1100/ 3410]
loss: 0.004133  [ 1200/ 3410]
loss: 0.006504  [ 1300/ 3410]
loss: 0.001778  [ 1400/ 3410]
loss: 0.001874  [ 1500/ 3410]
loss: 0.001968  [ 1600/ 3410]
loss: 0.005655  [ 1700/ 3410]
loss: 0.009252  [ 1800/ 3410]
loss: 0.001448  [ 1900/ 3410]
loss: 0.054459  [ 2000/ 3410]
loss: 0.003445  [ 2100/ 3410]
loss: 0.024322  [ 2200/ 3410]
loss: 0.003670  [ 2300/ 3410]
loss: 0.004268  [ 2400/ 3410]
loss: 0.119776  [ 2500/ 3410]
loss: 0.008500  [ 2600/ 3410]
loss: 0.004032  [ 2700/ 3410]
loss: 0.000869  [ 2800/ 3410]
loss: 0.007427  [ 2900/ 3410]
loss: 0.002573  [ 3000/ 3410]
loss: 0.001057  [ 3100/ 3410]
loss: 0.003501  [ 3200/ 3410]
loss: 0.001745  [ 3300/ 3410]
loss: 0.001334  [ 3400/ 3410]
Epoch 2
-------------------------------
loss: 0.000511  [    0/ 3410]
loss: 0.003577  [  100/ 3410]
loss: 0.005535  [  200/ 3410]
loss: 0.003358  [  300/ 3410]
loss: 0.002549  [  400/ 3410]
loss: 0.003381  [  500/ 3410]
loss: 0.001153  [  600/ 3410]
loss: 0.005119  [  700/ 3410]
loss: 0.003526  [  800/ 3410]
loss: 0.001874  [  900/ 3410]
loss: 0.006457  [ 1000/ 3410]
loss: 0.003392  [ 1100/ 3410]
loss: 0.003498  [ 1200/ 3410]
loss: 0.005764  [ 1300/ 3410]
loss: 0.001594  [ 1400/ 3410]
loss: 0.001888  [ 1500/ 3410]
loss: 0.001784  [ 1600/ 3410]
loss: 0.004715  [ 1700/ 3410]
loss: 0.008883  [ 1800/ 3410]
loss: 0.001215  [ 1900/ 3410]
loss: 0.055752  [ 2000/ 3410]
loss: 0.002860  [ 2100/ 3410]
loss: 0.022741  [ 2200/ 3410]
loss: 0.003101  [ 2300/ 3410]
loss: 0.003318  [ 2400/ 3410]
loss: 0.116695  [ 2500/ 3410]
loss: 0.009352  [ 2600/ 3410]
loss: 0.003868  [ 2700/ 3410]
loss: 0.000669  [ 2800/ 3410]
loss: 0.006987  [ 2900/ 3410]
loss: 0.002519  [ 3000/ 3410]
loss: 0.000879  [ 3100/ 3410]
loss: 0.002596  [ 3200/ 3410]
loss: 0.001582  [ 3300/ 3410]
loss: 0.000934  [ 3400/ 3410]
Epoch 3
-------------------------------
loss: 0.000300  [    0/ 3410]
loss: 0.003510  [  100/ 3410]
loss: 0.004866  [  200/ 3410]
loss: 0.002615  [  300/ 3410]
loss: 0.002387  [  400/ 3410]
loss: 0.002507  [  500/ 3410]
loss: 0.001381  [  600/ 3410]
loss: 0.004707  [  700/ 3410]
loss: 0.002809  [  800/ 3410]
loss: 0.001631  [  900/ 3410]
loss: 0.007153  [ 1000/ 3410]
loss: 0.003220  [ 1100/ 3410]
loss: 0.002897  [ 1200/ 3410]
loss: 0.005711  [ 1300/ 3410]
loss: 0.001952  [ 1400/ 3410]
loss: 0.001884  [ 1500/ 3410]
loss: 0.001865  [ 1600/ 3410]
loss: 0.004395  [ 1700/ 3410]
loss: 0.008697  [ 1800/ 3410]
loss: 0.001204  [ 1900/ 3410]
loss: 0.054493  [ 2000/ 3410]
loss: 0.002682  [ 2100/ 3410]
loss: 0.024280  [ 2200/ 3410]
loss: 0.002593  [ 2300/ 3410]
loss: 0.003039  [ 2400/ 3410]
loss: 0.115271  [ 2500/ 3410]
loss: 0.007865  [ 2600/ 3410]
loss: 0.003803  [ 2700/ 3410]
loss: 0.000815  [ 2800/ 3410]
loss: 0.007196  [ 2900/ 3410]
loss: 0.002408  [ 3000/ 3410]
loss: 0.000917  [ 3100/ 3410]
loss: 0.002267  [ 3200/ 3410]
loss: 0.001529  [ 3300/ 3410]
loss: 0.000706  [ 3400/ 3410]
Epoch 4
-------------------------------
loss: 0.000414  [    0/ 3410]
loss: 0.003126  [  100/ 3410]
loss: 0.004521  [  200/ 3410]
loss: 0.002155  [  300/ 3410]
loss: 0.002298  [  400/ 3410]
loss: 0.002483  [  500/ 3410]
loss: 0.001538  [  600/ 3410]
loss: 0.005095  [  700/ 3410]
loss: 0.002619  [  800/ 3410]
loss: 0.001685  [  900/ 3410]
loss: 0.007170  [ 1000/ 3410]
loss: 0.003206  [ 1100/ 3410]
loss: 0.002691  [ 1200/ 3410]
loss: 0.005656  [ 1300/ 3410]
loss: 0.001576  [ 1400/ 3410]
loss: 0.002015  [ 1500/ 3410]
loss: 0.001861  [ 1600/ 3410]
loss: 0.004529  [ 1700/ 3410]
loss: 0.007984  [ 1800/ 3410]
loss: 0.001217  [ 1900/ 3410]
loss: 0.051708  [ 2000/ 3410]
loss: 0.002782  [ 2100/ 3410]
loss: 0.025850  [ 2200/ 3410]
loss: 0.002251  [ 2300/ 3410]
loss: 0.002782  [ 2400/ 3410]
loss: 0.114057  [ 2500/ 3410]
loss: 0.007207  [ 2600/ 3410]
loss: 0.003918  [ 2700/ 3410]
loss: 0.000761  [ 2800/ 3410]
loss: 0.007166  [ 2900/ 3410]
loss: 0.002293  [ 3000/ 3410]
loss: 0.000928  [ 3100/ 3410]
loss: 0.001780  [ 3200/ 3410]
loss: 0.001510  [ 3300/ 3410]
loss: 0.000590  [ 3400/ 3410]
Epoch 5
-------------------------------
loss: 0.000480  [    0/ 3410]
loss: 0.002805  [  100/ 3410]
loss: 0.004453  [  200/ 3410]
loss: 0.002003  [  300/ 3410]
loss: 0.002300  [  400/ 3410]
loss: 0.002472  [  500/ 3410]
loss: 0.001525  [  600/ 3410]
loss: 0.005152  [  700/ 3410]
loss: 0.002758  [  800/ 3410]
loss: 0.001806  [  900/ 3410]
loss: 0.007023  [ 1000/ 3410]
loss: 0.003186  [ 1100/ 3410]
loss: 0.002482  [ 1200/ 3410]
loss: 0.005738  [ 1300/ 3410]
loss: 0.001311  [ 1400/ 3410]
loss: 0.001927  [ 1500/ 3410]
loss: 0.001850  [ 1600/ 3410]
loss: 0.005070  [ 1700/ 3410]
loss: 0.008241  [ 1800/ 3410]
loss: 0.001213  [ 1900/ 3410]
loss: 0.048783  [ 2000/ 3410]
loss: 0.002914  [ 2100/ 3410]
loss: 0.027170  [ 2200/ 3410]
loss: 0.002063  [ 2300/ 3410]
loss: 0.002590  [ 2400/ 3410]
loss: 0.116631  [ 2500/ 3410]
loss: 0.005661  [ 2600/ 3410]
loss: 0.003951  [ 2700/ 3410]
loss: 0.000754  [ 2800/ 3410]
loss: 0.007054  [ 2900/ 3410]
loss: 0.002363  [ 3000/ 3410]
loss: 0.000934  [ 3100/ 3410]
loss: 0.001716  [ 3200/ 3410]
loss: 0.001544  [ 3300/ 3410]
loss: 0.000599  [ 3400/ 3410]
Epoch 6
-------------------------------
loss: 0.000400  [    0/ 3410]
loss: 0.002243  [  100/ 3410]
loss: 0.004416  [  200/ 3410]
loss: 0.002008  [  300/ 3410]
loss: 0.002351  [  400/ 3410]
loss: 0.002586  [  500/ 3410]
loss: 0.001505  [  600/ 3410]
loss: 0.005187  [  700/ 3410]
loss: 0.002861  [  800/ 3410]
loss: 0.001936  [  900/ 3410]
loss: 0.006810  [ 1000/ 3410]
loss: 0.003236  [ 1100/ 3410]
loss: 0.002276  [ 1200/ 3410]
loss: 0.005917  [ 1300/ 3410]
loss: 0.001184  [ 1400/ 3410]
loss: 0.002121  [ 1500/ 3410]
loss: 0.001835  [ 1600/ 3410]
loss: 0.004641  [ 1700/ 3410]
loss: 0.009012  [ 1800/ 3410]
loss: 0.001264  [ 1900/ 3410]
loss: 0.045509  [ 2000/ 3410]
loss: 0.003050  [ 2100/ 3410]
loss: 0.028369  [ 2200/ 3410]
loss: 0.002046  [ 2300/ 3410]
loss: 0.002582  [ 2400/ 3410]
loss: 0.112526  [ 2500/ 3410]
loss: 0.005312  [ 2600/ 3410]
loss: 0.003918  [ 2700/ 3410]
loss: 0.000783  [ 2800/ 3410]
loss: 0.006981  [ 2900/ 3410]
loss: 0.002382  [ 3000/ 3410]
loss: 0.000938  [ 3100/ 3410]
loss: 0.001767  [ 3200/ 3410]
loss: 0.001397  [ 3300/ 3410]
loss: 0.000499  [ 3400/ 3410]
Epoch 7
-------------------------------
loss: 0.000465  [    0/ 3410]
loss: 0.002188  [  100/ 3410]
loss: 0.004320  [  200/ 3410]
loss: 0.001920  [  300/ 3410]
loss: 0.002300  [  400/ 3410]
loss: 0.002559  [  500/ 3410]
loss: 0.001515  [  600/ 3410]
loss: 0.004955  [  700/ 3410]
loss: 0.003234  [  800/ 3410]
loss: 0.001988  [  900/ 3410]
loss: 0.006655  [ 1000/ 3410]
loss: 0.003205  [ 1100/ 3410]
loss: 0.002104  [ 1200/ 3410]
loss: 0.005807  [ 1300/ 3410]
loss: 0.001094  [ 1400/ 3410]
loss: 0.002113  [ 1500/ 3410]
loss: 0.001529  [ 1600/ 3410]
loss: 0.004519  [ 1700/ 3410]
loss: 0.008224  [ 1800/ 3410]
loss: 0.001228  [ 1900/ 3410]
loss: 0.043145  [ 2000/ 3410]
loss: 0.003045  [ 2100/ 3410]
loss: 0.028431  [ 2200/ 3410]
loss: 0.001947  [ 2300/ 3410]
loss: 0.002621  [ 2400/ 3410]
loss: 0.110236  [ 2500/ 3410]
loss: 0.004742  [ 2600/ 3410]
loss: 0.004025  [ 2700/ 3410]
loss: 0.000792  [ 2800/ 3410]
loss: 0.007028  [ 2900/ 3410]
loss: 0.002307  [ 3000/ 3410]
loss: 0.000931  [ 3100/ 3410]
loss: 0.002079  [ 3200/ 3410]
loss: 0.001398  [ 3300/ 3410]
loss: 0.000518  [ 3400/ 3410]
Epoch 8
-------------------------------
loss: 0.000566  [    0/ 3410]
loss: 0.001965  [  100/ 3410]
loss: 0.004289  [  200/ 3410]
loss: 0.001848  [  300/ 3410]
loss: 0.002281  [  400/ 3410]
loss: 0.002361  [  500/ 3410]
loss: 0.001461  [  600/ 3410]
loss: 0.004703  [  700/ 3410]
loss: 0.003538  [  800/ 3410]
loss: 0.002017  [  900/ 3410]
loss: 0.006781  [ 1000/ 3410]
loss: 0.003117  [ 1100/ 3410]
loss: 0.002202  [ 1200/ 3410]
loss: 0.005808  [ 1300/ 3410]
loss: 0.001003  [ 1400/ 3410]
loss: 0.002048  [ 1500/ 3410]
loss: 0.001582  [ 1600/ 3410]
loss: 0.004173  [ 1700/ 3410]
loss: 0.007588  [ 1800/ 3410]
loss: 0.001187  [ 1900/ 3410]
loss: 0.042127  [ 2000/ 3410]
loss: 0.003065  [ 2100/ 3410]
loss: 0.028529  [ 2200/ 3410]
loss: 0.001952  [ 2300/ 3410]
loss: 0.002772  [ 2400/ 3410]
loss: 0.110599  [ 2500/ 3410]
loss: 0.004530  [ 2600/ 3410]
loss: 0.004092  [ 2700/ 3410]
loss: 0.000723  [ 2800/ 3410]
loss: 0.007113  [ 2900/ 3410]
loss: 0.002186  [ 3000/ 3410]
loss: 0.000917  [ 3100/ 3410]
loss: 0.001748  [ 3200/ 3410]
loss: 0.001397  [ 3300/ 3410]
loss: 0.000558  [ 3400/ 3410]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3410
First Spike after testing: [-1.8289294  -0.35891423]
[2 2 2 ... 2 0 2]
[1 1 1 ... 1 2 1]
Cluster 0 Occurrences: 1130; KMEANS: 1086
Cluster 1 Occurrences: 1113; KMEANS: 1174
Cluster 2 Occurrences: 1167; KMEANS: 1150
Centroids: [[1.3802648, -0.39866063], [0.579912, -0.4304644], [-1.6925164, -0.3720271]]
Centroids: [[0.55539185, -0.42597473], [-1.6878262, -0.37838095], [1.3985453, -0.39732277]]
Contingency Matrix: 
[[  14    1 1115]
 [1071    7   35]
 [   1 1166    0]]
[[14, -1, 1115], [1071, -1, 35], [-1, -1, -1]]
[[-1, -1, -1], [1071, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[1115   14    1]
 [  35 1071    7]
 [   0    1 1166]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1115, 1071, 1166], Sum: 3352
All_Elements: [1115, 14, 1, 35, 1071, 7, 0, 1, 1166], Sum: 3410
Accuracy: 0.9829912023460411
Done!
