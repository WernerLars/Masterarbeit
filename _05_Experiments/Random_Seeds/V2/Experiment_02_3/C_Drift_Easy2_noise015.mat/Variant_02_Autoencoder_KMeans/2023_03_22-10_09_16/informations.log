Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Drift_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_09_16
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E796A9E908>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
<torch.utils.data.dataloader.DataLoader object at 0x000001E795FE4E48>
Epoch 1
-------------------------------
loss: 0.205488  [    0/ 3444]
loss: 0.085372  [  100/ 3444]
loss: 0.038250  [  200/ 3444]
loss: 0.016133  [  300/ 3444]
loss: 0.026566  [  400/ 3444]
loss: 0.033686  [  500/ 3444]
loss: 0.067610  [  600/ 3444]
loss: 0.024903  [  700/ 3444]
loss: 0.008487  [  800/ 3444]
loss: 0.021847  [  900/ 3444]
loss: 0.009946  [ 1000/ 3444]
loss: 0.018175  [ 1100/ 3444]
loss: 0.016605  [ 1200/ 3444]
loss: 0.048938  [ 1300/ 3444]
loss: 0.117716  [ 1400/ 3444]
loss: 0.017261  [ 1500/ 3444]
loss: 0.012381  [ 1600/ 3444]
loss: 0.014137  [ 1700/ 3444]
loss: 0.016604  [ 1800/ 3444]
loss: 0.017206  [ 1900/ 3444]
loss: 0.015340  [ 2000/ 3444]
loss: 0.019808  [ 2100/ 3444]
loss: 0.025678  [ 2200/ 3444]
loss: 0.020525  [ 2300/ 3444]
loss: 0.005731  [ 2400/ 3444]
loss: 0.010444  [ 2500/ 3444]
loss: 0.011325  [ 2600/ 3444]
loss: 0.013838  [ 2700/ 3444]
loss: 0.013251  [ 2800/ 3444]
loss: 0.011182  [ 2900/ 3444]
loss: 0.011807  [ 3000/ 3444]
loss: 0.092541  [ 3100/ 3444]
loss: 0.088830  [ 3200/ 3444]
loss: 0.008738  [ 3300/ 3444]
loss: 0.030568  [ 3400/ 3444]
Epoch 2
-------------------------------
loss: 0.018662  [    0/ 3444]
loss: 0.010571  [  100/ 3444]
loss: 0.006679  [  200/ 3444]
loss: 0.016439  [  300/ 3444]
loss: 0.013363  [  400/ 3444]
loss: 0.009831  [  500/ 3444]
loss: 0.032788  [  600/ 3444]
loss: 0.026828  [  700/ 3444]
loss: 0.006643  [  800/ 3444]
loss: 0.016701  [  900/ 3444]
loss: 0.009800  [ 1000/ 3444]
loss: 0.011745  [ 1100/ 3444]
loss: 0.003121  [ 1200/ 3444]
loss: 0.020136  [ 1300/ 3444]
loss: 0.111135  [ 1400/ 3444]
loss: 0.006858  [ 1500/ 3444]
loss: 0.009471  [ 1600/ 3444]
loss: 0.006721  [ 1700/ 3444]
loss: 0.016076  [ 1800/ 3444]
loss: 0.009146  [ 1900/ 3444]
loss: 0.010187  [ 2000/ 3444]
loss: 0.016955  [ 2100/ 3444]
loss: 0.018821  [ 2200/ 3444]
loss: 0.012412  [ 2300/ 3444]
loss: 0.005717  [ 2400/ 3444]
loss: 0.005251  [ 2500/ 3444]
loss: 0.006217  [ 2600/ 3444]
loss: 0.005295  [ 2700/ 3444]
loss: 0.015637  [ 2800/ 3444]
loss: 0.011290  [ 2900/ 3444]
loss: 0.010921  [ 3000/ 3444]
loss: 0.043568  [ 3100/ 3444]
loss: 0.097170  [ 3200/ 3444]
loss: 0.007288  [ 3300/ 3444]
loss: 0.026760  [ 3400/ 3444]
Epoch 3
-------------------------------
loss: 0.017458  [    0/ 3444]
loss: 0.009022  [  100/ 3444]
loss: 0.006242  [  200/ 3444]
loss: 0.015670  [  300/ 3444]
loss: 0.011520  [  400/ 3444]
loss: 0.008332  [  500/ 3444]
loss: 0.024901  [  600/ 3444]
loss: 0.026585  [  700/ 3444]
loss: 0.006915  [  800/ 3444]
loss: 0.018053  [  900/ 3444]
loss: 0.009739  [ 1000/ 3444]
loss: 0.010972  [ 1100/ 3444]
loss: 0.003658  [ 1200/ 3444]
loss: 0.015974  [ 1300/ 3444]
loss: 0.111460  [ 1400/ 3444]
loss: 0.007575  [ 1500/ 3444]
loss: 0.008863  [ 1600/ 3444]
loss: 0.006575  [ 1700/ 3444]
loss: 0.016337  [ 1800/ 3444]
loss: 0.008860  [ 1900/ 3444]
loss: 0.008319  [ 2000/ 3444]
loss: 0.016628  [ 2100/ 3444]
loss: 0.017848  [ 2200/ 3444]
loss: 0.012043  [ 2300/ 3444]
loss: 0.005235  [ 2400/ 3444]
loss: 0.004489  [ 2500/ 3444]
loss: 0.005934  [ 2600/ 3444]
loss: 0.005387  [ 2700/ 3444]
loss: 0.015935  [ 2800/ 3444]
loss: 0.011713  [ 2900/ 3444]
loss: 0.010445  [ 3000/ 3444]
loss: 0.032903  [ 3100/ 3444]
loss: 0.098704  [ 3200/ 3444]
loss: 0.006637  [ 3300/ 3444]
loss: 0.026016  [ 3400/ 3444]
Epoch 4
-------------------------------
loss: 0.017281  [    0/ 3444]
loss: 0.008944  [  100/ 3444]
loss: 0.006037  [  200/ 3444]
loss: 0.015367  [  300/ 3444]
loss: 0.010753  [  400/ 3444]
loss: 0.008498  [  500/ 3444]
loss: 0.022592  [  600/ 3444]
loss: 0.026102  [  700/ 3444]
loss: 0.006975  [  800/ 3444]
loss: 0.018179  [  900/ 3444]
loss: 0.009804  [ 1000/ 3444]
loss: 0.010656  [ 1100/ 3444]
loss: 0.003754  [ 1200/ 3444]
loss: 0.015250  [ 1300/ 3444]
loss: 0.112382  [ 1400/ 3444]
loss: 0.007456  [ 1500/ 3444]
loss: 0.008707  [ 1600/ 3444]
loss: 0.006657  [ 1700/ 3444]
loss: 0.016666  [ 1800/ 3444]
loss: 0.008692  [ 1900/ 3444]
loss: 0.007564  [ 2000/ 3444]
loss: 0.016393  [ 2100/ 3444]
loss: 0.017608  [ 2200/ 3444]
loss: 0.011771  [ 2300/ 3444]
loss: 0.004865  [ 2400/ 3444]
loss: 0.004021  [ 2500/ 3444]
loss: 0.005761  [ 2600/ 3444]
loss: 0.005912  [ 2700/ 3444]
loss: 0.015944  [ 2800/ 3444]
loss: 0.011771  [ 2900/ 3444]
loss: 0.010541  [ 3000/ 3444]
loss: 0.028383  [ 3100/ 3444]
loss: 0.100042  [ 3200/ 3444]
loss: 0.006363  [ 3300/ 3444]
loss: 0.025769  [ 3400/ 3444]
Epoch 5
-------------------------------
loss: 0.017190  [    0/ 3444]
loss: 0.009310  [  100/ 3444]
loss: 0.005875  [  200/ 3444]
loss: 0.015228  [  300/ 3444]
loss: 0.010499  [  400/ 3444]
loss: 0.008716  [  500/ 3444]
loss: 0.018857  [  600/ 3444]
loss: 0.025540  [  700/ 3444]
loss: 0.007036  [  800/ 3444]
loss: 0.017980  [  900/ 3444]
loss: 0.010488  [ 1000/ 3444]
loss: 0.010630  [ 1100/ 3444]
loss: 0.003868  [ 1200/ 3444]
loss: 0.019307  [ 1300/ 3444]
loss: 0.114547  [ 1400/ 3444]
loss: 0.007197  [ 1500/ 3444]
loss: 0.007921  [ 1600/ 3444]
loss: 0.006904  [ 1700/ 3444]
loss: 0.017286  [ 1800/ 3444]
loss: 0.008632  [ 1900/ 3444]
loss: 0.004564  [ 2000/ 3444]
loss: 0.016069  [ 2100/ 3444]
loss: 0.018135  [ 2200/ 3444]
loss: 0.011329  [ 2300/ 3444]
loss: 0.005795  [ 2400/ 3444]
loss: 0.003553  [ 2500/ 3444]
loss: 0.005401  [ 2600/ 3444]
loss: 0.005798  [ 2700/ 3444]
loss: 0.016251  [ 2800/ 3444]
loss: 0.011917  [ 2900/ 3444]
loss: 0.010249  [ 3000/ 3444]
loss: 0.023321  [ 3100/ 3444]
loss: 0.103324  [ 3200/ 3444]
loss: 0.006338  [ 3300/ 3444]
loss: 0.025613  [ 3400/ 3444]
Epoch 6
-------------------------------
loss: 0.018745  [    0/ 3444]
loss: 0.009630  [  100/ 3444]
loss: 0.005632  [  200/ 3444]
loss: 0.015342  [  300/ 3444]
loss: 0.010561  [  400/ 3444]
loss: 0.008680  [  500/ 3444]
loss: 0.015550  [  600/ 3444]
loss: 0.025620  [  700/ 3444]
loss: 0.007129  [  800/ 3444]
loss: 0.017986  [  900/ 3444]
loss: 0.010365  [ 1000/ 3444]
loss: 0.010192  [ 1100/ 3444]
loss: 0.003325  [ 1200/ 3444]
loss: 0.017226  [ 1300/ 3444]
loss: 0.115301  [ 1400/ 3444]
loss: 0.007042  [ 1500/ 3444]
loss: 0.007942  [ 1600/ 3444]
loss: 0.007204  [ 1700/ 3444]
loss: 0.017676  [ 1800/ 3444]
loss: 0.008460  [ 1900/ 3444]
loss: 0.004293  [ 2000/ 3444]
loss: 0.016085  [ 2100/ 3444]
loss: 0.018640  [ 2200/ 3444]
loss: 0.011194  [ 2300/ 3444]
loss: 0.005980  [ 2400/ 3444]
loss: 0.003484  [ 2500/ 3444]
loss: 0.005409  [ 2600/ 3444]
loss: 0.005466  [ 2700/ 3444]
loss: 0.016209  [ 2800/ 3444]
loss: 0.011967  [ 2900/ 3444]
loss: 0.010459  [ 3000/ 3444]
loss: 0.020577  [ 3100/ 3444]
loss: 0.104918  [ 3200/ 3444]
loss: 0.006402  [ 3300/ 3444]
loss: 0.025733  [ 3400/ 3444]
Epoch 7
-------------------------------
loss: 0.017916  [    0/ 3444]
loss: 0.009673  [  100/ 3444]
loss: 0.005503  [  200/ 3444]
loss: 0.015427  [  300/ 3444]
loss: 0.010283  [  400/ 3444]
loss: 0.008402  [  500/ 3444]
loss: 0.014891  [  600/ 3444]
loss: 0.025335  [  700/ 3444]
loss: 0.007449  [  800/ 3444]
loss: 0.018021  [  900/ 3444]
loss: 0.010383  [ 1000/ 3444]
loss: 0.009861  [ 1100/ 3444]
loss: 0.003081  [ 1200/ 3444]
loss: 0.016205  [ 1300/ 3444]
loss: 0.115551  [ 1400/ 3444]
loss: 0.007228  [ 1500/ 3444]
loss: 0.008168  [ 1600/ 3444]
loss: 0.007469  [ 1700/ 3444]
loss: 0.018095  [ 1800/ 3444]
loss: 0.008283  [ 1900/ 3444]
loss: 0.004169  [ 2000/ 3444]
loss: 0.015902  [ 2100/ 3444]
loss: 0.019017  [ 2200/ 3444]
loss: 0.011031  [ 2300/ 3444]
loss: 0.006242  [ 2400/ 3444]
loss: 0.003511  [ 2500/ 3444]
loss: 0.005470  [ 2600/ 3444]
loss: 0.005420  [ 2700/ 3444]
loss: 0.016121  [ 2800/ 3444]
loss: 0.011822  [ 2900/ 3444]
loss: 0.010682  [ 3000/ 3444]
loss: 0.020120  [ 3100/ 3444]
loss: 0.105731  [ 3200/ 3444]
loss: 0.006452  [ 3300/ 3444]
loss: 0.025923  [ 3400/ 3444]
Epoch 8
-------------------------------
loss: 0.017041  [    0/ 3444]
loss: 0.010120  [  100/ 3444]
loss: 0.005533  [  200/ 3444]
loss: 0.015408  [  300/ 3444]
loss: 0.009930  [  400/ 3444]
loss: 0.008386  [  500/ 3444]
loss: 0.014403  [  600/ 3444]
loss: 0.025387  [  700/ 3444]
loss: 0.007860  [  800/ 3444]
loss: 0.017975  [  900/ 3444]
loss: 0.010438  [ 1000/ 3444]
loss: 0.009592  [ 1100/ 3444]
loss: 0.002965  [ 1200/ 3444]
loss: 0.015405  [ 1300/ 3444]
loss: 0.115951  [ 1400/ 3444]
loss: 0.007241  [ 1500/ 3444]
loss: 0.008186  [ 1600/ 3444]
loss: 0.007512  [ 1700/ 3444]
loss: 0.018164  [ 1800/ 3444]
loss: 0.008272  [ 1900/ 3444]
loss: 0.004074  [ 2000/ 3444]
loss: 0.015742  [ 2100/ 3444]
loss: 0.019199  [ 2200/ 3444]
loss: 0.010875  [ 2300/ 3444]
loss: 0.006553  [ 2400/ 3444]
loss: 0.003617  [ 2500/ 3444]
loss: 0.005519  [ 2600/ 3444]
loss: 0.005206  [ 2700/ 3444]
loss: 0.016138  [ 2800/ 3444]
loss: 0.011775  [ 2900/ 3444]
loss: 0.010852  [ 3000/ 3444]
loss: 0.019587  [ 3100/ 3444]
loss: 0.105963  [ 3200/ 3444]
loss: 0.006430  [ 3300/ 3444]
loss: 0.026094  [ 3400/ 3444]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3444
First Spike after testing: [-2.6971176  1.0350893]
[2 2 0 ... 0 2 0]
[0 0 1 ... 1 0 1]
Cluster 0 Occurrences: 1142; KMEANS: 580
Cluster 1 Occurrences: 1180; KMEANS: 2328
Cluster 2 Occurrences: 1122; KMEANS: 536
Centroids: [[1.0788071, -0.70451546], [0.34590262, -0.5784916], [-2.708518, 0.91190773]]
Centroids: [[-3.2655344, 1.2436612], [0.7042324, -0.64099926], [-2.1347716, 0.57258683]]
Contingency Matrix: 
[[   0 1142    0]
 [   0 1178    2]
 [ 580    8  534]]
[[0, -1, 0], [-1, -1, -1], [580, -1, 534]]
[[-1, -1, 0], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 2: 0, 0: 2}
New Contingency Matrix: 
[[   0 1142    0]
 [   2 1178    0]
 [ 534    8  580]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [0, 1178, 580], Sum: 1758
All_Elements: [0, 1142, 0, 2, 1178, 0, 534, 8, 580], Sum: 3444
Accuracy: 0.5104529616724739
Done!
