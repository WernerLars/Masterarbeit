Experiment_path: Random_Seeds//V2/Experiment_02_3
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_3/C_Difficult1_noise020.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_00_53
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E788019588>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
<torch.utils.data.dataloader.DataLoader object at 0x000001E795D00240>
Epoch 1
-------------------------------
loss: 0.223049  [    0/ 3414]
loss: 0.109133  [  100/ 3414]
loss: 0.034256  [  200/ 3414]
loss: 0.043428  [  300/ 3414]
loss: 0.054322  [  400/ 3414]
loss: 0.070937  [  500/ 3414]
loss: 0.040941  [  600/ 3414]
loss: 0.049904  [  700/ 3414]
loss: 0.079594  [  800/ 3414]
loss: 0.074525  [  900/ 3414]
loss: 0.027092  [ 1000/ 3414]
loss: 0.020370  [ 1100/ 3414]
loss: 0.029915  [ 1200/ 3414]
loss: 0.030177  [ 1300/ 3414]
loss: 0.019282  [ 1400/ 3414]
loss: 0.029747  [ 1500/ 3414]
loss: 0.016110  [ 1600/ 3414]
loss: 0.015318  [ 1700/ 3414]
loss: 0.029049  [ 1800/ 3414]
loss: 0.022157  [ 1900/ 3414]
loss: 0.038505  [ 2000/ 3414]
loss: 0.026844  [ 2100/ 3414]
loss: 0.040399  [ 2200/ 3414]
loss: 0.036910  [ 2300/ 3414]
loss: 0.008973  [ 2400/ 3414]
loss: 0.156122  [ 2500/ 3414]
loss: 0.025437  [ 2600/ 3414]
loss: 0.014104  [ 2700/ 3414]
loss: 0.009825  [ 2800/ 3414]
loss: 0.036885  [ 2900/ 3414]
loss: 0.040031  [ 3000/ 3414]
loss: 0.030750  [ 3100/ 3414]
loss: 0.022372  [ 3200/ 3414]
loss: 0.011620  [ 3300/ 3414]
loss: 0.025884  [ 3400/ 3414]
Epoch 2
-------------------------------
loss: 0.042428  [    0/ 3414]
loss: 0.029440  [  100/ 3414]
loss: 0.008285  [  200/ 3414]
loss: 0.048164  [  300/ 3414]
loss: 0.016159  [  400/ 3414]
loss: 0.045482  [  500/ 3414]
loss: 0.031283  [  600/ 3414]
loss: 0.030045  [  700/ 3414]
loss: 0.052179  [  800/ 3414]
loss: 0.019770  [  900/ 3414]
loss: 0.016557  [ 1000/ 3414]
loss: 0.022846  [ 1100/ 3414]
loss: 0.006451  [ 1200/ 3414]
loss: 0.032765  [ 1300/ 3414]
loss: 0.018524  [ 1400/ 3414]
loss: 0.027994  [ 1500/ 3414]
loss: 0.011740  [ 1600/ 3414]
loss: 0.010870  [ 1700/ 3414]
loss: 0.029481  [ 1800/ 3414]
loss: 0.019975  [ 1900/ 3414]
loss: 0.034662  [ 2000/ 3414]
loss: 0.031406  [ 2100/ 3414]
loss: 0.039409  [ 2200/ 3414]
loss: 0.034391  [ 2300/ 3414]
loss: 0.008463  [ 2400/ 3414]
loss: 0.158848  [ 2500/ 3414]
loss: 0.024733  [ 2600/ 3414]
loss: 0.013889  [ 2700/ 3414]
loss: 0.011311  [ 2800/ 3414]
loss: 0.039662  [ 2900/ 3414]
loss: 0.043658  [ 3000/ 3414]
loss: 0.033346  [ 3100/ 3414]
loss: 0.021264  [ 3200/ 3414]
loss: 0.011996  [ 3300/ 3414]
loss: 0.025225  [ 3400/ 3414]
Epoch 3
-------------------------------
loss: 0.041866  [    0/ 3414]
loss: 0.029668  [  100/ 3414]
loss: 0.008437  [  200/ 3414]
loss: 0.048517  [  300/ 3414]
loss: 0.014618  [  400/ 3414]
loss: 0.045008  [  500/ 3414]
loss: 0.029138  [  600/ 3414]
loss: 0.033552  [  700/ 3414]
loss: 0.052061  [  800/ 3414]
loss: 0.020390  [  900/ 3414]
loss: 0.016341  [ 1000/ 3414]
loss: 0.022860  [ 1100/ 3414]
loss: 0.006291  [ 1200/ 3414]
loss: 0.032595  [ 1300/ 3414]
loss: 0.018468  [ 1400/ 3414]
loss: 0.027743  [ 1500/ 3414]
loss: 0.011171  [ 1600/ 3414]
loss: 0.010396  [ 1700/ 3414]
loss: 0.029623  [ 1800/ 3414]
loss: 0.020316  [ 1900/ 3414]
loss: 0.033785  [ 2000/ 3414]
loss: 0.031877  [ 2100/ 3414]
loss: 0.038989  [ 2200/ 3414]
loss: 0.034767  [ 2300/ 3414]
loss: 0.008418  [ 2400/ 3414]
loss: 0.160490  [ 2500/ 3414]
loss: 0.024407  [ 2600/ 3414]
loss: 0.013792  [ 2700/ 3414]
loss: 0.011497  [ 2800/ 3414]
loss: 0.040182  [ 2900/ 3414]
loss: 0.044318  [ 3000/ 3414]
loss: 0.033823  [ 3100/ 3414]
loss: 0.020900  [ 3200/ 3414]
loss: 0.011976  [ 3300/ 3414]
loss: 0.025190  [ 3400/ 3414]
Epoch 4
-------------------------------
loss: 0.043302  [    0/ 3414]
loss: 0.029730  [  100/ 3414]
loss: 0.008382  [  200/ 3414]
loss: 0.048398  [  300/ 3414]
loss: 0.014749  [  400/ 3414]
loss: 0.044832  [  500/ 3414]
loss: 0.028859  [  600/ 3414]
loss: 0.034268  [  700/ 3414]
loss: 0.051819  [  800/ 3414]
loss: 0.021054  [  900/ 3414]
loss: 0.016251  [ 1000/ 3414]
loss: 0.022559  [ 1100/ 3414]
loss: 0.006203  [ 1200/ 3414]
loss: 0.032574  [ 1300/ 3414]
loss: 0.018450  [ 1400/ 3414]
loss: 0.027468  [ 1500/ 3414]
loss: 0.011090  [ 1600/ 3414]
loss: 0.010266  [ 1700/ 3414]
loss: 0.029380  [ 1800/ 3414]
loss: 0.020168  [ 1900/ 3414]
loss: 0.033665  [ 2000/ 3414]
loss: 0.031969  [ 2100/ 3414]
loss: 0.038434  [ 2200/ 3414]
loss: 0.035144  [ 2300/ 3414]
loss: 0.008340  [ 2400/ 3414]
loss: 0.161659  [ 2500/ 3414]
loss: 0.024464  [ 2600/ 3414]
loss: 0.013710  [ 2700/ 3414]
loss: 0.011331  [ 2800/ 3414]
loss: 0.040093  [ 2900/ 3414]
loss: 0.044898  [ 3000/ 3414]
loss: 0.033866  [ 3100/ 3414]
loss: 0.021132  [ 3200/ 3414]
loss: 0.011883  [ 3300/ 3414]
loss: 0.025177  [ 3400/ 3414]
Epoch 5
-------------------------------
loss: 0.045666  [    0/ 3414]
loss: 0.029835  [  100/ 3414]
loss: 0.008322  [  200/ 3414]
loss: 0.048458  [  300/ 3414]
loss: 0.014803  [  400/ 3414]
loss: 0.044833  [  500/ 3414]
loss: 0.029046  [  600/ 3414]
loss: 0.034294  [  700/ 3414]
loss: 0.051747  [  800/ 3414]
loss: 0.021614  [  900/ 3414]
loss: 0.016231  [ 1000/ 3414]
loss: 0.022376  [ 1100/ 3414]
loss: 0.006214  [ 1200/ 3414]
loss: 0.032624  [ 1300/ 3414]
loss: 0.018488  [ 1400/ 3414]
loss: 0.027266  [ 1500/ 3414]
loss: 0.011113  [ 1600/ 3414]
loss: 0.010316  [ 1700/ 3414]
loss: 0.029045  [ 1800/ 3414]
loss: 0.019961  [ 1900/ 3414]
loss: 0.033942  [ 2000/ 3414]
loss: 0.031905  [ 2100/ 3414]
loss: 0.037378  [ 2200/ 3414]
loss: 0.035258  [ 2300/ 3414]
loss: 0.008236  [ 2400/ 3414]
loss: 0.161937  [ 2500/ 3414]
loss: 0.024301  [ 2600/ 3414]
loss: 0.013657  [ 2700/ 3414]
loss: 0.011127  [ 2800/ 3414]
loss: 0.040435  [ 2900/ 3414]
loss: 0.045020  [ 3000/ 3414]
loss: 0.033204  [ 3100/ 3414]
loss: 0.021369  [ 3200/ 3414]
loss: 0.011691  [ 3300/ 3414]
loss: 0.025108  [ 3400/ 3414]
Epoch 6
-------------------------------
loss: 0.051227  [    0/ 3414]
loss: 0.030037  [  100/ 3414]
loss: 0.008236  [  200/ 3414]
loss: 0.048638  [  300/ 3414]
loss: 0.015098  [  400/ 3414]
loss: 0.045043  [  500/ 3414]
loss: 0.029362  [  600/ 3414]
loss: 0.033972  [  700/ 3414]
loss: 0.051209  [  800/ 3414]
loss: 0.022019  [  900/ 3414]
loss: 0.016259  [ 1000/ 3414]
loss: 0.022119  [ 1100/ 3414]
loss: 0.006584  [ 1200/ 3414]
loss: 0.032662  [ 1300/ 3414]
loss: 0.018536  [ 1400/ 3414]
loss: 0.027076  [ 1500/ 3414]
loss: 0.011155  [ 1600/ 3414]
loss: 0.010541  [ 1700/ 3414]
loss: 0.028782  [ 1800/ 3414]
loss: 0.019814  [ 1900/ 3414]
loss: 0.034500  [ 2000/ 3414]
loss: 0.031751  [ 2100/ 3414]
loss: 0.036218  [ 2200/ 3414]
loss: 0.034793  [ 2300/ 3414]
loss: 0.008155  [ 2400/ 3414]
loss: 0.162608  [ 2500/ 3414]
loss: 0.024170  [ 2600/ 3414]
loss: 0.013346  [ 2700/ 3414]
loss: 0.011311  [ 2800/ 3414]
loss: 0.040819  [ 2900/ 3414]
loss: 0.045482  [ 3000/ 3414]
loss: 0.032546  [ 3100/ 3414]
loss: 0.021327  [ 3200/ 3414]
loss: 0.011597  [ 3300/ 3414]
loss: 0.025072  [ 3400/ 3414]
Epoch 7
-------------------------------
loss: 0.060580  [    0/ 3414]
loss: 0.030211  [  100/ 3414]
loss: 0.008221  [  200/ 3414]
loss: 0.049005  [  300/ 3414]
loss: 0.014977  [  400/ 3414]
loss: 0.045462  [  500/ 3414]
loss: 0.029682  [  600/ 3414]
loss: 0.032922  [  700/ 3414]
loss: 0.050382  [  800/ 3414]
loss: 0.022557  [  900/ 3414]
loss: 0.016641  [ 1000/ 3414]
loss: 0.022163  [ 1100/ 3414]
loss: 0.006901  [ 1200/ 3414]
loss: 0.032174  [ 1300/ 3414]
loss: 0.018740  [ 1400/ 3414]
loss: 0.026816  [ 1500/ 3414]
loss: 0.011052  [ 1600/ 3414]
loss: 0.010792  [ 1700/ 3414]
loss: 0.028517  [ 1800/ 3414]
loss: 0.019539  [ 1900/ 3414]
loss: 0.035993  [ 2000/ 3414]
loss: 0.033162  [ 2100/ 3414]
loss: 0.034687  [ 2200/ 3414]
loss: 0.035618  [ 2300/ 3414]
loss: 0.008183  [ 2400/ 3414]
loss: 0.159974  [ 2500/ 3414]
loss: 0.024136  [ 2600/ 3414]
loss: 0.013056  [ 2700/ 3414]
loss: 0.010970  [ 2800/ 3414]
loss: 0.040609  [ 2900/ 3414]
loss: 0.048679  [ 3000/ 3414]
loss: 0.030751  [ 3100/ 3414]
loss: 0.021524  [ 3200/ 3414]
loss: 0.011385  [ 3300/ 3414]
loss: 0.024903  [ 3400/ 3414]
Epoch 8
-------------------------------
loss: 0.067769  [    0/ 3414]
loss: 0.030477  [  100/ 3414]
loss: 0.008200  [  200/ 3414]
loss: 0.049068  [  300/ 3414]
loss: 0.015671  [  400/ 3414]
loss: 0.043819  [  500/ 3414]
loss: 0.031099  [  600/ 3414]
loss: 0.031164  [  700/ 3414]
loss: 0.048530  [  800/ 3414]
loss: 0.022287  [  900/ 3414]
loss: 0.017332  [ 1000/ 3414]
loss: 0.022194  [ 1100/ 3414]
loss: 0.007012  [ 1200/ 3414]
loss: 0.032093  [ 1300/ 3414]
loss: 0.018909  [ 1400/ 3414]
loss: 0.026818  [ 1500/ 3414]
loss: 0.010897  [ 1600/ 3414]
loss: 0.011788  [ 1700/ 3414]
loss: 0.028331  [ 1800/ 3414]
loss: 0.019416  [ 1900/ 3414]
loss: 0.035273  [ 2000/ 3414]
loss: 0.036761  [ 2100/ 3414]
loss: 0.035233  [ 2200/ 3414]
loss: 0.035415  [ 2300/ 3414]
loss: 0.008186  [ 2400/ 3414]
loss: 0.158911  [ 2500/ 3414]
loss: 0.024511  [ 2600/ 3414]
loss: 0.011907  [ 2700/ 3414]
loss: 0.012319  [ 2800/ 3414]
loss: 0.041188  [ 2900/ 3414]
loss: 0.051910  [ 3000/ 3414]
loss: 0.028842  [ 3100/ 3414]
loss: 0.021813  [ 3200/ 3414]
loss: 0.011148  [ 3300/ 3414]
loss: 0.024507  [ 3400/ 3414]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3414
First Spike after testing: [0.35777515 0.03687974]
[1 1 0 ... 0 0 2]
[0 0 2 ... 1 0 2]
Cluster 0 Occurrences: 1136; KMEANS: 1164
Cluster 1 Occurrences: 1099; KMEANS: 1197
Cluster 2 Occurrences: 1179; KMEANS: 1053
Centroids: [[-0.30522376, -0.1467228], [-0.39174306, 0.056096032], [-1.0734133, -0.09573527]]
Centroids: [[-0.1976766, 0.31072146], [-0.36689004, -0.44995096], [-1.3044169, -0.038924906]]
Contingency Matrix: 
[[458 558 120]
 [548 381 170]
 [158 258 763]]
[[458, 558, -1], [548, 381, -1], [-1, -1, -1]]
[[-1, -1, -1], [548, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 1, 1: 0}
New Contingency Matrix: 
[[558 458 120]
 [381 548 170]
 [258 158 763]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [558, 548, 763], Sum: 1869
All_Elements: [558, 458, 120, 381, 548, 170, 258, 158, 763], Sum: 3414
Accuracy: 0.5474516695957821
Done!
