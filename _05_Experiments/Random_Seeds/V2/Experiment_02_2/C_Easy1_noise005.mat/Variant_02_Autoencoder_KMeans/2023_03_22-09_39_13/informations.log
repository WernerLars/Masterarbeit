Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_39_13
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA03BDDBE0>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x000001FA03C24EF0>
Epoch 1
-------------------------------
loss: 0.166760  [    0/ 3514]
loss: 0.119801  [  100/ 3514]
loss: 0.037186  [  200/ 3514]
loss: 0.053958  [  300/ 3514]
loss: 0.007372  [  400/ 3514]
loss: 0.006755  [  500/ 3514]
loss: 0.008966  [  600/ 3514]
loss: 0.003252  [  700/ 3514]
loss: 0.001735  [  800/ 3514]
loss: 0.004186  [  900/ 3514]
loss: 0.005689  [ 1000/ 3514]
loss: 0.092860  [ 1100/ 3514]
loss: 0.002623  [ 1200/ 3514]
loss: 0.002131  [ 1300/ 3514]
loss: 0.086867  [ 1400/ 3514]
loss: 0.000715  [ 1500/ 3514]
loss: 0.006650  [ 1600/ 3514]
loss: 0.005325  [ 1700/ 3514]
loss: 0.233512  [ 1800/ 3514]
loss: 0.006832  [ 1900/ 3514]
loss: 0.002949  [ 2000/ 3514]
loss: 0.005351  [ 2100/ 3514]
loss: 0.000881  [ 2200/ 3514]
loss: 0.001737  [ 2300/ 3514]
loss: 0.002337  [ 2400/ 3514]
loss: 0.007148  [ 2500/ 3514]
loss: 0.003861  [ 2600/ 3514]
loss: 0.004966  [ 2700/ 3514]
loss: 0.007121  [ 2800/ 3514]
loss: 0.002360  [ 2900/ 3514]
loss: 0.005557  [ 3000/ 3514]
loss: 0.001705  [ 3100/ 3514]
loss: 0.001803  [ 3200/ 3514]
loss: 0.008390  [ 3300/ 3514]
loss: 0.007197  [ 3400/ 3514]
loss: 0.003560  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.004425  [    0/ 3514]
loss: 0.002987  [  100/ 3514]
loss: 0.007118  [  200/ 3514]
loss: 0.003852  [  300/ 3514]
loss: 0.004031  [  400/ 3514]
loss: 0.004706  [  500/ 3514]
loss: 0.007962  [  600/ 3514]
loss: 0.002983  [  700/ 3514]
loss: 0.001541  [  800/ 3514]
loss: 0.003952  [  900/ 3514]
loss: 0.006013  [ 1000/ 3514]
loss: 0.092296  [ 1100/ 3514]
loss: 0.002823  [ 1200/ 3514]
loss: 0.001924  [ 1300/ 3514]
loss: 0.082827  [ 1400/ 3514]
loss: 0.000497  [ 1500/ 3514]
loss: 0.007410  [ 1600/ 3514]
loss: 0.005434  [ 1700/ 3514]
loss: 0.232483  [ 1800/ 3514]
loss: 0.004673  [ 1900/ 3514]
loss: 0.001858  [ 2000/ 3514]
loss: 0.005530  [ 2100/ 3514]
loss: 0.000649  [ 2200/ 3514]
loss: 0.001317  [ 2300/ 3514]
loss: 0.002004  [ 2400/ 3514]
loss: 0.006607  [ 2500/ 3514]
loss: 0.004246  [ 2600/ 3514]
loss: 0.003365  [ 2700/ 3514]
loss: 0.007148  [ 2800/ 3514]
loss: 0.002006  [ 2900/ 3514]
loss: 0.004287  [ 3000/ 3514]
loss: 0.001674  [ 3100/ 3514]
loss: 0.001921  [ 3200/ 3514]
loss: 0.006473  [ 3300/ 3514]
loss: 0.005634  [ 3400/ 3514]
loss: 0.002968  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.003457  [    0/ 3514]
loss: 0.002145  [  100/ 3514]
loss: 0.006757  [  200/ 3514]
loss: 0.003759  [  300/ 3514]
loss: 0.004082  [  400/ 3514]
loss: 0.003692  [  500/ 3514]
loss: 0.006541  [  600/ 3514]
loss: 0.002939  [  700/ 3514]
loss: 0.001610  [  800/ 3514]
loss: 0.003815  [  900/ 3514]
loss: 0.006230  [ 1000/ 3514]
loss: 0.091147  [ 1100/ 3514]
loss: 0.002470  [ 1200/ 3514]
loss: 0.002027  [ 1300/ 3514]
loss: 0.070585  [ 1400/ 3514]
loss: 0.000667  [ 1500/ 3514]
loss: 0.008694  [ 1600/ 3514]
loss: 0.006207  [ 1700/ 3514]
loss: 0.245237  [ 1800/ 3514]
loss: 0.004460  [ 1900/ 3514]
loss: 0.001199  [ 2000/ 3514]
loss: 0.005407  [ 2100/ 3514]
loss: 0.000647  [ 2200/ 3514]
loss: 0.001538  [ 2300/ 3514]
loss: 0.002056  [ 2400/ 3514]
loss: 0.005954  [ 2500/ 3514]
loss: 0.004289  [ 2600/ 3514]
loss: 0.002411  [ 2700/ 3514]
loss: 0.007021  [ 2800/ 3514]
loss: 0.001620  [ 2900/ 3514]
loss: 0.003302  [ 3000/ 3514]
loss: 0.002032  [ 3100/ 3514]
loss: 0.001990  [ 3200/ 3514]
loss: 0.005948  [ 3300/ 3514]
loss: 0.005163  [ 3400/ 3514]
loss: 0.002730  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.004241  [    0/ 3514]
loss: 0.001768  [  100/ 3514]
loss: 0.006841  [  200/ 3514]
loss: 0.003771  [  300/ 3514]
loss: 0.004158  [  400/ 3514]
loss: 0.003574  [  500/ 3514]
loss: 0.006237  [  600/ 3514]
loss: 0.002966  [  700/ 3514]
loss: 0.001509  [  800/ 3514]
loss: 0.003872  [  900/ 3514]
loss: 0.006122  [ 1000/ 3514]
loss: 0.091438  [ 1100/ 3514]
loss: 0.002222  [ 1200/ 3514]
loss: 0.002074  [ 1300/ 3514]
loss: 0.066528  [ 1400/ 3514]
loss: 0.000671  [ 1500/ 3514]
loss: 0.008459  [ 1600/ 3514]
loss: 0.006401  [ 1700/ 3514]
loss: 0.236512  [ 1800/ 3514]
loss: 0.004184  [ 1900/ 3514]
loss: 0.000960  [ 2000/ 3514]
loss: 0.005245  [ 2100/ 3514]
loss: 0.000596  [ 2200/ 3514]
loss: 0.001603  [ 2300/ 3514]
loss: 0.001891  [ 2400/ 3514]
loss: 0.005854  [ 2500/ 3514]
loss: 0.004503  [ 2600/ 3514]
loss: 0.002118  [ 2700/ 3514]
loss: 0.006947  [ 2800/ 3514]
loss: 0.001674  [ 2900/ 3514]
loss: 0.002874  [ 3000/ 3514]
loss: 0.001445  [ 3100/ 3514]
loss: 0.001912  [ 3200/ 3514]
loss: 0.005819  [ 3300/ 3514]
loss: 0.004993  [ 3400/ 3514]
loss: 0.002689  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.004578  [    0/ 3514]
loss: 0.001526  [  100/ 3514]
loss: 0.006744  [  200/ 3514]
loss: 0.003876  [  300/ 3514]
loss: 0.004190  [  400/ 3514]
loss: 0.003548  [  500/ 3514]
loss: 0.006017  [  600/ 3514]
loss: 0.003126  [  700/ 3514]
loss: 0.001563  [  800/ 3514]
loss: 0.003768  [  900/ 3514]
loss: 0.006247  [ 1000/ 3514]
loss: 0.091822  [ 1100/ 3514]
loss: 0.001918  [ 1200/ 3514]
loss: 0.002304  [ 1300/ 3514]
loss: 0.065233  [ 1400/ 3514]
loss: 0.000534  [ 1500/ 3514]
loss: 0.008460  [ 1600/ 3514]
loss: 0.006834  [ 1700/ 3514]
loss: 0.229695  [ 1800/ 3514]
loss: 0.003816  [ 1900/ 3514]
loss: 0.000906  [ 2000/ 3514]
loss: 0.005111  [ 2100/ 3514]
loss: 0.000645  [ 2200/ 3514]
loss: 0.001897  [ 2300/ 3514]
loss: 0.001822  [ 2400/ 3514]
loss: 0.005515  [ 2500/ 3514]
loss: 0.004504  [ 2600/ 3514]
loss: 0.002015  [ 2700/ 3514]
loss: 0.006863  [ 2800/ 3514]
loss: 0.001426  [ 2900/ 3514]
loss: 0.002518  [ 3000/ 3514]
loss: 0.001205  [ 3100/ 3514]
loss: 0.001856  [ 3200/ 3514]
loss: 0.005664  [ 3300/ 3514]
loss: 0.004895  [ 3400/ 3514]
loss: 0.002698  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.004535  [    0/ 3514]
loss: 0.001356  [  100/ 3514]
loss: 0.006910  [  200/ 3514]
loss: 0.003938  [  300/ 3514]
loss: 0.004111  [  400/ 3514]
loss: 0.003544  [  500/ 3514]
loss: 0.005748  [  600/ 3514]
loss: 0.003139  [  700/ 3514]
loss: 0.001459  [  800/ 3514]
loss: 0.003835  [  900/ 3514]
loss: 0.006010  [ 1000/ 3514]
loss: 0.092743  [ 1100/ 3514]
loss: 0.001597  [ 1200/ 3514]
loss: 0.002386  [ 1300/ 3514]
loss: 0.064676  [ 1400/ 3514]
loss: 0.000471  [ 1500/ 3514]
loss: 0.008690  [ 1600/ 3514]
loss: 0.006995  [ 1700/ 3514]
loss: 0.221136  [ 1800/ 3514]
loss: 0.004050  [ 1900/ 3514]
loss: 0.000892  [ 2000/ 3514]
loss: 0.005302  [ 2100/ 3514]
loss: 0.000574  [ 2200/ 3514]
loss: 0.001851  [ 2300/ 3514]
loss: 0.001813  [ 2400/ 3514]
loss: 0.005444  [ 2500/ 3514]
loss: 0.004536  [ 2600/ 3514]
loss: 0.002042  [ 2700/ 3514]
loss: 0.006856  [ 2800/ 3514]
loss: 0.001358  [ 2900/ 3514]
loss: 0.002397  [ 3000/ 3514]
loss: 0.001010  [ 3100/ 3514]
loss: 0.001850  [ 3200/ 3514]
loss: 0.006535  [ 3300/ 3514]
loss: 0.004956  [ 3400/ 3514]
loss: 0.002938  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.005052  [    0/ 3514]
loss: 0.001275  [  100/ 3514]
loss: 0.007134  [  200/ 3514]
loss: 0.003916  [  300/ 3514]
loss: 0.004257  [  400/ 3514]
loss: 0.003658  [  500/ 3514]
loss: 0.005445  [  600/ 3514]
loss: 0.002984  [  700/ 3514]
loss: 0.001498  [  800/ 3514]
loss: 0.003849  [  900/ 3514]
loss: 0.005792  [ 1000/ 3514]
loss: 0.093354  [ 1100/ 3514]
loss: 0.001381  [ 1200/ 3514]
loss: 0.002396  [ 1300/ 3514]
loss: 0.063948  [ 1400/ 3514]
loss: 0.000450  [ 1500/ 3514]
loss: 0.008450  [ 1600/ 3514]
loss: 0.006837  [ 1700/ 3514]
loss: 0.216058  [ 1800/ 3514]
loss: 0.004257  [ 1900/ 3514]
loss: 0.000865  [ 2000/ 3514]
loss: 0.005438  [ 2100/ 3514]
loss: 0.000595  [ 2200/ 3514]
loss: 0.001660  [ 2300/ 3514]
loss: 0.001764  [ 2400/ 3514]
loss: 0.005522  [ 2500/ 3514]
loss: 0.004525  [ 2600/ 3514]
loss: 0.002021  [ 2700/ 3514]
loss: 0.006905  [ 2800/ 3514]
loss: 0.001323  [ 2900/ 3514]
loss: 0.002274  [ 3000/ 3514]
loss: 0.001050  [ 3100/ 3514]
loss: 0.001837  [ 3200/ 3514]
loss: 0.006932  [ 3300/ 3514]
loss: 0.004925  [ 3400/ 3514]
loss: 0.003176  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.005179  [    0/ 3514]
loss: 0.001171  [  100/ 3514]
loss: 0.007139  [  200/ 3514]
loss: 0.003895  [  300/ 3514]
loss: 0.004243  [  400/ 3514]
loss: 0.003653  [  500/ 3514]
loss: 0.005230  [  600/ 3514]
loss: 0.002781  [  700/ 3514]
loss: 0.001463  [  800/ 3514]
loss: 0.003870  [  900/ 3514]
loss: 0.005747  [ 1000/ 3514]
loss: 0.093150  [ 1100/ 3514]
loss: 0.001232  [ 1200/ 3514]
loss: 0.002382  [ 1300/ 3514]
loss: 0.064128  [ 1400/ 3514]
loss: 0.000427  [ 1500/ 3514]
loss: 0.008298  [ 1600/ 3514]
loss: 0.006601  [ 1700/ 3514]
loss: 0.211261  [ 1800/ 3514]
loss: 0.004459  [ 1900/ 3514]
loss: 0.000828  [ 2000/ 3514]
loss: 0.005388  [ 2100/ 3514]
loss: 0.000609  [ 2200/ 3514]
loss: 0.001584  [ 2300/ 3514]
loss: 0.001790  [ 2400/ 3514]
loss: 0.005494  [ 2500/ 3514]
loss: 0.004561  [ 2600/ 3514]
loss: 0.001921  [ 2700/ 3514]
loss: 0.006930  [ 2800/ 3514]
loss: 0.001643  [ 2900/ 3514]
loss: 0.002178  [ 3000/ 3514]
loss: 0.001041  [ 3100/ 3514]
loss: 0.001794  [ 3200/ 3514]
loss: 0.006925  [ 3300/ 3514]
loss: 0.004965  [ 3400/ 3514]
loss: 0.002632  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [0.89675164 0.35522816]
[1 0 2 ... 1 0 1]
[1 2 0 ... 1 2 1]
Cluster 0 Occurrences: 1165; KMEANS: 1211
Cluster 1 Occurrences: 1157; KMEANS: 1137
Cluster 2 Occurrences: 1192; KMEANS: 1166
Centroids: [[-1.2695749, 0.69918954], [0.909289, 0.41312245], [-0.3118741, -1.0535637]]
Centroids: [[-0.29363132, -1.050724], [0.9183752, 0.4250411], [-1.2756143, 0.70827234]]
Contingency Matrix: 
[[   9    2 1154]
 [  14 1135    8]
 [1188    0    4]]
[[-1, 2, 1154], [-1, 1135, 8], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1135, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1154    2    9]
 [   8 1135   14]
 [   4    0 1188]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1154, 1135, 1188], Sum: 3477
All_Elements: [1154, 2, 9, 8, 1135, 14, 4, 0, 1188], Sum: 3514
Accuracy: 0.9894706886738759
Done!
