Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Easy2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_51_27
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA098B49B0>
Sampling rate: 24000.0
Raw: [ 0.11862069  0.1123084   0.10401825 ... -0.10219323 -0.10268373
 -0.08956559]
Times: [    346     799    1005 ... 1436867 1437273 1437800]
Cluster: [3 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3410
First aligned Spike Frame: [ 2.05661766e-03  8.27536867e-03  1.66427268e-02  2.31246655e-02
  2.28936935e-02  1.99169368e-02  2.25281834e-02  3.37605443e-02
  4.94182133e-02  6.24484568e-02  8.42111946e-02  1.71357846e-01
  3.88441746e-01  6.99052305e-01  9.59509287e-01  1.03608873e+00
  9.29169963e-01  7.55567481e-01  6.10726415e-01  5.06818519e-01
  4.23878029e-01  3.55610047e-01  3.01970228e-01  2.53702042e-01
  1.98274486e-01  1.32802904e-01  6.40690121e-02  7.96454927e-04
 -5.66201776e-02 -1.11669131e-01 -1.62581026e-01 -2.01746625e-01
 -2.23071447e-01 -2.29516190e-01 -2.30160694e-01 -2.27148529e-01
 -2.18080531e-01 -2.04276810e-01 -1.90750996e-01 -1.81098693e-01
 -1.72421418e-01 -1.61640218e-01 -1.48460304e-01 -1.32332846e-01
 -1.13338953e-01 -9.43725979e-02 -7.56249106e-02]
Cluster 0, Occurrences: 1130
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1167
<torch.utils.data.dataloader.DataLoader object at 0x000001FA03C24898>
Epoch 1
-------------------------------
loss: 0.196191  [    0/ 3410]
loss: 0.072056  [  100/ 3410]
loss: 0.013991  [  200/ 3410]
loss: 0.012189  [  300/ 3410]
loss: 0.004302  [  400/ 3410]
loss: 0.003191  [  500/ 3410]
loss: 0.001243  [  600/ 3410]
loss: 0.004890  [  700/ 3410]
loss: 0.008573  [  800/ 3410]
loss: 0.006753  [  900/ 3410]
loss: 0.011561  [ 1000/ 3410]
loss: 0.002789  [ 1100/ 3410]
loss: 0.003630  [ 1200/ 3410]
loss: 0.006228  [ 1300/ 3410]
loss: 0.001827  [ 1400/ 3410]
loss: 0.001978  [ 1500/ 3410]
loss: 0.001453  [ 1600/ 3410]
loss: 0.005045  [ 1700/ 3410]
loss: 0.006708  [ 1800/ 3410]
loss: 0.001073  [ 1900/ 3410]
loss: 0.053557  [ 2000/ 3410]
loss: 0.002915  [ 2100/ 3410]
loss: 0.028656  [ 2200/ 3410]
loss: 0.003152  [ 2300/ 3410]
loss: 0.003782  [ 2400/ 3410]
loss: 0.121296  [ 2500/ 3410]
loss: 0.007248  [ 2600/ 3410]
loss: 0.003694  [ 2700/ 3410]
loss: 0.001174  [ 2800/ 3410]
loss: 0.007202  [ 2900/ 3410]
loss: 0.002367  [ 3000/ 3410]
loss: 0.000894  [ 3100/ 3410]
loss: 0.006457  [ 3200/ 3410]
loss: 0.001800  [ 3300/ 3410]
loss: 0.001498  [ 3400/ 3410]
Epoch 2
-------------------------------
loss: 0.000605  [    0/ 3410]
loss: 0.002866  [  100/ 3410]
loss: 0.004480  [  200/ 3410]
loss: 0.004129  [  300/ 3410]
loss: 0.002174  [  400/ 3410]
loss: 0.002870  [  500/ 3410]
loss: 0.001063  [  600/ 3410]
loss: 0.005700  [  700/ 3410]
loss: 0.005400  [  800/ 3410]
loss: 0.002350  [  900/ 3410]
loss: 0.006275  [ 1000/ 3410]
loss: 0.002943  [ 1100/ 3410]
loss: 0.003679  [ 1200/ 3410]
loss: 0.005547  [ 1300/ 3410]
loss: 0.001593  [ 1400/ 3410]
loss: 0.001610  [ 1500/ 3410]
loss: 0.001451  [ 1600/ 3410]
loss: 0.004688  [ 1700/ 3410]
loss: 0.006216  [ 1800/ 3410]
loss: 0.001029  [ 1900/ 3410]
loss: 0.045319  [ 2000/ 3410]
loss: 0.002925  [ 2100/ 3410]
loss: 0.028909  [ 2200/ 3410]
loss: 0.002821  [ 2300/ 3410]
loss: 0.003264  [ 2400/ 3410]
loss: 0.119617  [ 2500/ 3410]
loss: 0.008387  [ 2600/ 3410]
loss: 0.003380  [ 2700/ 3410]
loss: 0.000813  [ 2800/ 3410]
loss: 0.006652  [ 2900/ 3410]
loss: 0.002328  [ 3000/ 3410]
loss: 0.000803  [ 3100/ 3410]
loss: 0.005345  [ 3200/ 3410]
loss: 0.001644  [ 3300/ 3410]
loss: 0.001537  [ 3400/ 3410]
Epoch 3
-------------------------------
loss: 0.000704  [    0/ 3410]
loss: 0.002658  [  100/ 3410]
loss: 0.004378  [  200/ 3410]
loss: 0.004173  [  300/ 3410]
loss: 0.002268  [  400/ 3410]
loss: 0.002449  [  500/ 3410]
loss: 0.001065  [  600/ 3410]
loss: 0.005419  [  700/ 3410]
loss: 0.005050  [  800/ 3410]
loss: 0.002455  [  900/ 3410]
loss: 0.006002  [ 1000/ 3410]
loss: 0.003056  [ 1100/ 3410]
loss: 0.003481  [ 1200/ 3410]
loss: 0.005615  [ 1300/ 3410]
loss: 0.001454  [ 1400/ 3410]
loss: 0.001508  [ 1500/ 3410]
loss: 0.001505  [ 1600/ 3410]
loss: 0.004602  [ 1700/ 3410]
loss: 0.005469  [ 1800/ 3410]
loss: 0.001107  [ 1900/ 3410]
loss: 0.037288  [ 2000/ 3410]
loss: 0.003102  [ 2100/ 3410]
loss: 0.028991  [ 2200/ 3410]
loss: 0.002782  [ 2300/ 3410]
loss: 0.002953  [ 2400/ 3410]
loss: 0.119021  [ 2500/ 3410]
loss: 0.008656  [ 2600/ 3410]
loss: 0.003140  [ 2700/ 3410]
loss: 0.000666  [ 2800/ 3410]
loss: 0.006296  [ 2900/ 3410]
loss: 0.002396  [ 3000/ 3410]
loss: 0.000822  [ 3100/ 3410]
loss: 0.004225  [ 3200/ 3410]
loss: 0.001622  [ 3300/ 3410]
loss: 0.001597  [ 3400/ 3410]
Epoch 4
-------------------------------
loss: 0.000714  [    0/ 3410]
loss: 0.002569  [  100/ 3410]
loss: 0.004516  [  200/ 3410]
loss: 0.003958  [  300/ 3410]
loss: 0.002300  [  400/ 3410]
loss: 0.002387  [  500/ 3410]
loss: 0.001097  [  600/ 3410]
loss: 0.005083  [  700/ 3410]
loss: 0.004435  [  800/ 3410]
loss: 0.002531  [  900/ 3410]
loss: 0.005346  [ 1000/ 3410]
loss: 0.003267  [ 1100/ 3410]
loss: 0.003413  [ 1200/ 3410]
loss: 0.005898  [ 1300/ 3410]
loss: 0.001326  [ 1400/ 3410]
loss: 0.001455  [ 1500/ 3410]
loss: 0.001620  [ 1600/ 3410]
loss: 0.004330  [ 1700/ 3410]
loss: 0.005081  [ 1800/ 3410]
loss: 0.001184  [ 1900/ 3410]
loss: 0.033642  [ 2000/ 3410]
loss: 0.003342  [ 2100/ 3410]
loss: 0.028711  [ 2200/ 3410]
loss: 0.002745  [ 2300/ 3410]
loss: 0.002894  [ 2400/ 3410]
loss: 0.117230  [ 2500/ 3410]
loss: 0.008436  [ 2600/ 3410]
loss: 0.003125  [ 2700/ 3410]
loss: 0.000652  [ 2800/ 3410]
loss: 0.005811  [ 2900/ 3410]
loss: 0.001970  [ 3000/ 3410]
loss: 0.000853  [ 3100/ 3410]
loss: 0.003627  [ 3200/ 3410]
loss: 0.001713  [ 3300/ 3410]
loss: 0.001234  [ 3400/ 3410]
Epoch 5
-------------------------------
loss: 0.000631  [    0/ 3410]
loss: 0.002712  [  100/ 3410]
loss: 0.004455  [  200/ 3410]
loss: 0.003485  [  300/ 3410]
loss: 0.002350  [  400/ 3410]
loss: 0.002582  [  500/ 3410]
loss: 0.001168  [  600/ 3410]
loss: 0.005015  [  700/ 3410]
loss: 0.004058  [  800/ 3410]
loss: 0.002578  [  900/ 3410]
loss: 0.004842  [ 1000/ 3410]
loss: 0.003494  [ 1100/ 3410]
loss: 0.003186  [ 1200/ 3410]
loss: 0.005769  [ 1300/ 3410]
loss: 0.001212  [ 1400/ 3410]
loss: 0.001423  [ 1500/ 3410]
loss: 0.001739  [ 1600/ 3410]
loss: 0.004146  [ 1700/ 3410]
loss: 0.005035  [ 1800/ 3410]
loss: 0.001174  [ 1900/ 3410]
loss: 0.030630  [ 2000/ 3410]
loss: 0.003535  [ 2100/ 3410]
loss: 0.028489  [ 2200/ 3410]
loss: 0.002672  [ 2300/ 3410]
loss: 0.002981  [ 2400/ 3410]
loss: 0.115168  [ 2500/ 3410]
loss: 0.008747  [ 2600/ 3410]
loss: 0.003136  [ 2700/ 3410]
loss: 0.000578  [ 2800/ 3410]
loss: 0.005610  [ 2900/ 3410]
loss: 0.002297  [ 3000/ 3410]
loss: 0.000922  [ 3100/ 3410]
loss: 0.003110  [ 3200/ 3410]
loss: 0.001861  [ 3300/ 3410]
loss: 0.000898  [ 3400/ 3410]
Epoch 6
-------------------------------
loss: 0.000586  [    0/ 3410]
loss: 0.002858  [  100/ 3410]
loss: 0.004529  [  200/ 3410]
loss: 0.002988  [  300/ 3410]
loss: 0.002326  [  400/ 3410]
loss: 0.002920  [  500/ 3410]
loss: 0.001189  [  600/ 3410]
loss: 0.004804  [  700/ 3410]
loss: 0.004183  [  800/ 3410]
loss: 0.002490  [  900/ 3410]
loss: 0.004629  [ 1000/ 3410]
loss: 0.003542  [ 1100/ 3410]
loss: 0.002981  [ 1200/ 3410]
loss: 0.005668  [ 1300/ 3410]
loss: 0.001150  [ 1400/ 3410]
loss: 0.001422  [ 1500/ 3410]
loss: 0.001782  [ 1600/ 3410]
loss: 0.004363  [ 1700/ 3410]
loss: 0.004769  [ 1800/ 3410]
loss: 0.001209  [ 1900/ 3410]
loss: 0.029464  [ 2000/ 3410]
loss: 0.003548  [ 2100/ 3410]
loss: 0.028316  [ 2200/ 3410]
loss: 0.002716  [ 2300/ 3410]
loss: 0.003051  [ 2400/ 3410]
loss: 0.115959  [ 2500/ 3410]
loss: 0.008370  [ 2600/ 3410]
loss: 0.003287  [ 2700/ 3410]
loss: 0.000567  [ 2800/ 3410]
loss: 0.005486  [ 2900/ 3410]
loss: 0.002276  [ 3000/ 3410]
loss: 0.000965  [ 3100/ 3410]
loss: 0.002655  [ 3200/ 3410]
loss: 0.001887  [ 3300/ 3410]
loss: 0.000811  [ 3400/ 3410]
Epoch 7
-------------------------------
loss: 0.000557  [    0/ 3410]
loss: 0.002851  [  100/ 3410]
loss: 0.004633  [  200/ 3410]
loss: 0.002894  [  300/ 3410]
loss: 0.002351  [  400/ 3410]
loss: 0.002920  [  500/ 3410]
loss: 0.001222  [  600/ 3410]
loss: 0.004439  [  700/ 3410]
loss: 0.004050  [  800/ 3410]
loss: 0.002552  [  900/ 3410]
loss: 0.004626  [ 1000/ 3410]
loss: 0.003625  [ 1100/ 3410]
loss: 0.002804  [ 1200/ 3410]
loss: 0.005724  [ 1300/ 3410]
loss: 0.001092  [ 1400/ 3410]
loss: 0.001396  [ 1500/ 3410]
loss: 0.001714  [ 1600/ 3410]
loss: 0.004346  [ 1700/ 3410]
loss: 0.004631  [ 1800/ 3410]
loss: 0.001182  [ 1900/ 3410]
loss: 0.027932  [ 2000/ 3410]
loss: 0.003464  [ 2100/ 3410]
loss: 0.027999  [ 2200/ 3410]
loss: 0.002779  [ 2300/ 3410]
loss: 0.003117  [ 2400/ 3410]
loss: 0.112862  [ 2500/ 3410]
loss: 0.007992  [ 2600/ 3410]
loss: 0.003448  [ 2700/ 3410]
loss: 0.000596  [ 2800/ 3410]
loss: 0.005470  [ 2900/ 3410]
loss: 0.002237  [ 3000/ 3410]
loss: 0.000967  [ 3100/ 3410]
loss: 0.002706  [ 3200/ 3410]
loss: 0.001973  [ 3300/ 3410]
loss: 0.000690  [ 3400/ 3410]
Epoch 8
-------------------------------
loss: 0.000512  [    0/ 3410]
loss: 0.003261  [  100/ 3410]
loss: 0.004602  [  200/ 3410]
loss: 0.002934  [  300/ 3410]
loss: 0.002120  [  400/ 3410]
loss: 0.003567  [  500/ 3410]
loss: 0.001270  [  600/ 3410]
loss: 0.004092  [  700/ 3410]
loss: 0.004051  [  800/ 3410]
loss: 0.002516  [  900/ 3410]
loss: 0.004156  [ 1000/ 3410]
loss: 0.003355  [ 1100/ 3410]
loss: 0.002630  [ 1200/ 3410]
loss: 0.005578  [ 1300/ 3410]
loss: 0.001031  [ 1400/ 3410]
loss: 0.001288  [ 1500/ 3410]
loss: 0.001670  [ 1600/ 3410]
loss: 0.004357  [ 1700/ 3410]
loss: 0.004502  [ 1800/ 3410]
loss: 0.001178  [ 1900/ 3410]
loss: 0.025180  [ 2000/ 3410]
loss: 0.003340  [ 2100/ 3410]
loss: 0.027462  [ 2200/ 3410]
loss: 0.002883  [ 2300/ 3410]
loss: 0.003100  [ 2400/ 3410]
loss: 0.117289  [ 2500/ 3410]
loss: 0.008513  [ 2600/ 3410]
loss: 0.003566  [ 2700/ 3410]
loss: 0.000596  [ 2800/ 3410]
loss: 0.005215  [ 2900/ 3410]
loss: 0.002242  [ 3000/ 3410]
loss: 0.000948  [ 3100/ 3410]
loss: 0.002619  [ 3200/ 3410]
loss: 0.001985  [ 3300/ 3410]
loss: 0.000719  [ 3400/ 3410]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3410
First Spike after testing: [-0.76286787 -0.726663  ]
[2 2 2 ... 2 0 2]
[0 0 0 ... 0 1 0]
Cluster 0 Occurrences: 1130; KMEANS: 1163
Cluster 1 Occurrences: 1113; KMEANS: 1153
Cluster 2 Occurrences: 1167; KMEANS: 1094
Centroids: [[0.3009291, 1.5917692], [0.9822725, 0.67514724], [-0.79904306, -0.62662894]]
Centroids: [[-0.8059129, -0.6271044], [0.28215957, 1.6118623], [1.0171688, 0.6304453]]
Contingency Matrix: 
[[   0 1109   21]
 [   1   44 1068]
 [1162    0    5]]
[[-1, 1109, 21], [-1, 44, 1068], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1068], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1109   21    0]
 [  44 1068    1]
 [   0    5 1162]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1109, 1068, 1162], Sum: 3339
All_Elements: [1109, 21, 0, 44, 1068, 1, 0, 5, 1162], Sum: 3410
Accuracy: 0.9791788856304985
Done!
