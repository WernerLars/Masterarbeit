Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Drift_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_09_23
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA85B730B8>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
<torch.utils.data.dataloader.DataLoader object at 0x000001FA95895860>
Epoch 1
-------------------------------
loss: 0.173984  [    0/ 3444]
loss: 0.052178  [  100/ 3444]
loss: 0.011012  [  200/ 3444]
loss: 0.018799  [  300/ 3444]
loss: 0.026812  [  400/ 3444]
loss: 0.032601  [  500/ 3444]
loss: 0.065458  [  600/ 3444]
loss: 0.025088  [  700/ 3444]
loss: 0.007841  [  800/ 3444]
loss: 0.036787  [  900/ 3444]
loss: 0.010152  [ 1000/ 3444]
loss: 0.019004  [ 1100/ 3444]
loss: 0.018041  [ 1200/ 3444]
loss: 0.051946  [ 1300/ 3444]
loss: 0.110606  [ 1400/ 3444]
loss: 0.011292  [ 1500/ 3444]
loss: 0.010821  [ 1600/ 3444]
loss: 0.010776  [ 1700/ 3444]
loss: 0.019479  [ 1800/ 3444]
loss: 0.013184  [ 1900/ 3444]
loss: 0.010146  [ 2000/ 3444]
loss: 0.013420  [ 2100/ 3444]
loss: 0.021084  [ 2200/ 3444]
loss: 0.009796  [ 2300/ 3444]
loss: 0.007351  [ 2400/ 3444]
loss: 0.004136  [ 2500/ 3444]
loss: 0.008522  [ 2600/ 3444]
loss: 0.013683  [ 2700/ 3444]
loss: 0.014373  [ 2800/ 3444]
loss: 0.011856  [ 2900/ 3444]
loss: 0.006704  [ 3000/ 3444]
loss: 0.084746  [ 3100/ 3444]
loss: 0.142302  [ 3200/ 3444]
loss: 0.008429  [ 3300/ 3444]
loss: 0.028861  [ 3400/ 3444]
Epoch 2
-------------------------------
loss: 0.017704  [    0/ 3444]
loss: 0.016169  [  100/ 3444]
loss: 0.010310  [  200/ 3444]
loss: 0.017243  [  300/ 3444]
loss: 0.013406  [  400/ 3444]
loss: 0.023212  [  500/ 3444]
loss: 0.021852  [  600/ 3444]
loss: 0.023510  [  700/ 3444]
loss: 0.006961  [  800/ 3444]
loss: 0.019913  [  900/ 3444]
loss: 0.009987  [ 1000/ 3444]
loss: 0.010179  [ 1100/ 3444]
loss: 0.007773  [ 1200/ 3444]
loss: 0.034245  [ 1300/ 3444]
loss: 0.115511  [ 1400/ 3444]
loss: 0.012425  [ 1500/ 3444]
loss: 0.011458  [ 1600/ 3444]
loss: 0.009930  [ 1700/ 3444]
loss: 0.016836  [ 1800/ 3444]
loss: 0.010818  [ 1900/ 3444]
loss: 0.005008  [ 2000/ 3444]
loss: 0.016112  [ 2100/ 3444]
loss: 0.020701  [ 2200/ 3444]
loss: 0.009547  [ 2300/ 3444]
loss: 0.011811  [ 2400/ 3444]
loss: 0.002897  [ 2500/ 3444]
loss: 0.003399  [ 2600/ 3444]
loss: 0.006307  [ 2700/ 3444]
loss: 0.014049  [ 2800/ 3444]
loss: 0.010656  [ 2900/ 3444]
loss: 0.007128  [ 3000/ 3444]
loss: 0.052338  [ 3100/ 3444]
loss: 0.114354  [ 3200/ 3444]
loss: 0.007280  [ 3300/ 3444]
loss: 0.029452  [ 3400/ 3444]
Epoch 3
-------------------------------
loss: 0.014648  [    0/ 3444]
loss: 0.016727  [  100/ 3444]
loss: 0.010247  [  200/ 3444]
loss: 0.016407  [  300/ 3444]
loss: 0.012893  [  400/ 3444]
loss: 0.019494  [  500/ 3444]
loss: 0.013842  [  600/ 3444]
loss: 0.024000  [  700/ 3444]
loss: 0.006976  [  800/ 3444]
loss: 0.019985  [  900/ 3444]
loss: 0.010846  [ 1000/ 3444]
loss: 0.008575  [ 1100/ 3444]
loss: 0.003641  [ 1200/ 3444]
loss: 0.026979  [ 1300/ 3444]
loss: 0.116401  [ 1400/ 3444]
loss: 0.010566  [ 1500/ 3444]
loss: 0.011257  [ 1600/ 3444]
loss: 0.008028  [ 1700/ 3444]
loss: 0.015420  [ 1800/ 3444]
loss: 0.010340  [ 1900/ 3444]
loss: 0.002706  [ 2000/ 3444]
loss: 0.016743  [ 2100/ 3444]
loss: 0.020325  [ 2200/ 3444]
loss: 0.009845  [ 2300/ 3444]
loss: 0.010884  [ 2400/ 3444]
loss: 0.002947  [ 2500/ 3444]
loss: 0.003173  [ 2600/ 3444]
loss: 0.003683  [ 2700/ 3444]
loss: 0.014282  [ 2800/ 3444]
loss: 0.010594  [ 2900/ 3444]
loss: 0.007378  [ 3000/ 3444]
loss: 0.038494  [ 3100/ 3444]
loss: 0.106463  [ 3200/ 3444]
loss: 0.006905  [ 3300/ 3444]
loss: 0.029049  [ 3400/ 3444]
Epoch 4
-------------------------------
loss: 0.013576  [    0/ 3444]
loss: 0.016612  [  100/ 3444]
loss: 0.009922  [  200/ 3444]
loss: 0.016281  [  300/ 3444]
loss: 0.012398  [  400/ 3444]
loss: 0.017059  [  500/ 3444]
loss: 0.010737  [  600/ 3444]
loss: 0.024941  [  700/ 3444]
loss: 0.007268  [  800/ 3444]
loss: 0.019940  [  900/ 3444]
loss: 0.011702  [ 1000/ 3444]
loss: 0.008536  [ 1100/ 3444]
loss: 0.003308  [ 1200/ 3444]
loss: 0.025499  [ 1300/ 3444]
loss: 0.115422  [ 1400/ 3444]
loss: 0.009515  [ 1500/ 3444]
loss: 0.010598  [ 1600/ 3444]
loss: 0.007820  [ 1700/ 3444]
loss: 0.015774  [ 1800/ 3444]
loss: 0.010159  [ 1900/ 3444]
loss: 0.002179  [ 2000/ 3444]
loss: 0.017029  [ 2100/ 3444]
loss: 0.020394  [ 2200/ 3444]
loss: 0.009797  [ 2300/ 3444]
loss: 0.011046  [ 2400/ 3444]
loss: 0.003153  [ 2500/ 3444]
loss: 0.003201  [ 2600/ 3444]
loss: 0.002930  [ 2700/ 3444]
loss: 0.014101  [ 2800/ 3444]
loss: 0.010804  [ 2900/ 3444]
loss: 0.007275  [ 3000/ 3444]
loss: 0.032965  [ 3100/ 3444]
loss: 0.102460  [ 3200/ 3444]
loss: 0.006684  [ 3300/ 3444]
loss: 0.028483  [ 3400/ 3444]
Epoch 5
-------------------------------
loss: 0.013676  [    0/ 3444]
loss: 0.016454  [  100/ 3444]
loss: 0.009657  [  200/ 3444]
loss: 0.016427  [  300/ 3444]
loss: 0.011649  [  400/ 3444]
loss: 0.015915  [  500/ 3444]
loss: 0.010188  [  600/ 3444]
loss: 0.025418  [  700/ 3444]
loss: 0.007517  [  800/ 3444]
loss: 0.019308  [  900/ 3444]
loss: 0.011755  [ 1000/ 3444]
loss: 0.008120  [ 1100/ 3444]
loss: 0.002642  [ 1200/ 3444]
loss: 0.022469  [ 1300/ 3444]
loss: 0.115308  [ 1400/ 3444]
loss: 0.008788  [ 1500/ 3444]
loss: 0.009768  [ 1600/ 3444]
loss: 0.007881  [ 1700/ 3444]
loss: 0.016396  [ 1800/ 3444]
loss: 0.010264  [ 1900/ 3444]
loss: 0.002116  [ 2000/ 3444]
loss: 0.017033  [ 2100/ 3444]
loss: 0.020466  [ 2200/ 3444]
loss: 0.009974  [ 2300/ 3444]
loss: 0.010755  [ 2400/ 3444]
loss: 0.003214  [ 2500/ 3444]
loss: 0.003249  [ 2600/ 3444]
loss: 0.002888  [ 2700/ 3444]
loss: 0.014105  [ 2800/ 3444]
loss: 0.011141  [ 2900/ 3444]
loss: 0.007469  [ 3000/ 3444]
loss: 0.029148  [ 3100/ 3444]
loss: 0.101311  [ 3200/ 3444]
loss: 0.006618  [ 3300/ 3444]
loss: 0.028263  [ 3400/ 3444]
Epoch 6
-------------------------------
loss: 0.013998  [    0/ 3444]
loss: 0.016011  [  100/ 3444]
loss: 0.009356  [  200/ 3444]
loss: 0.016768  [  300/ 3444]
loss: 0.011386  [  400/ 3444]
loss: 0.014627  [  500/ 3444]
loss: 0.011100  [  600/ 3444]
loss: 0.026083  [  700/ 3444]
loss: 0.007740  [  800/ 3444]
loss: 0.018153  [  900/ 3444]
loss: 0.011501  [ 1000/ 3444]
loss: 0.008367  [ 1100/ 3444]
loss: 0.002408  [ 1200/ 3444]
loss: 0.021503  [ 1300/ 3444]
loss: 0.114452  [ 1400/ 3444]
loss: 0.008001  [ 1500/ 3444]
loss: 0.009529  [ 1600/ 3444]
loss: 0.008106  [ 1700/ 3444]
loss: 0.017388  [ 1800/ 3444]
loss: 0.009921  [ 1900/ 3444]
loss: 0.002253  [ 2000/ 3444]
loss: 0.016427  [ 2100/ 3444]
loss: 0.020384  [ 2200/ 3444]
loss: 0.010148  [ 2300/ 3444]
loss: 0.010460  [ 2400/ 3444]
loss: 0.003140  [ 2500/ 3444]
loss: 0.003260  [ 2600/ 3444]
loss: 0.003441  [ 2700/ 3444]
loss: 0.013981  [ 2800/ 3444]
loss: 0.011426  [ 2900/ 3444]
loss: 0.007936  [ 3000/ 3444]
loss: 0.027490  [ 3100/ 3444]
loss: 0.101372  [ 3200/ 3444]
loss: 0.006543  [ 3300/ 3444]
loss: 0.028280  [ 3400/ 3444]
Epoch 7
-------------------------------
loss: 0.014454  [    0/ 3444]
loss: 0.015578  [  100/ 3444]
loss: 0.009093  [  200/ 3444]
loss: 0.016624  [  300/ 3444]
loss: 0.010613  [  400/ 3444]
loss: 0.013502  [  500/ 3444]
loss: 0.009836  [  600/ 3444]
loss: 0.026669  [  700/ 3444]
loss: 0.007905  [  800/ 3444]
loss: 0.017400  [  900/ 3444]
loss: 0.011378  [ 1000/ 3444]
loss: 0.008420  [ 1100/ 3444]
loss: 0.002317  [ 1200/ 3444]
loss: 0.021714  [ 1300/ 3444]
loss: 0.113799  [ 1400/ 3444]
loss: 0.007603  [ 1500/ 3444]
loss: 0.009422  [ 1600/ 3444]
loss: 0.008191  [ 1700/ 3444]
loss: 0.018206  [ 1800/ 3444]
loss: 0.010078  [ 1900/ 3444]
loss: 0.002227  [ 2000/ 3444]
loss: 0.016186  [ 2100/ 3444]
loss: 0.020182  [ 2200/ 3444]
loss: 0.010390  [ 2300/ 3444]
loss: 0.009606  [ 2400/ 3444]
loss: 0.003208  [ 2500/ 3444]
loss: 0.003369  [ 2600/ 3444]
loss: 0.004003  [ 2700/ 3444]
loss: 0.014059  [ 2800/ 3444]
loss: 0.011597  [ 2900/ 3444]
loss: 0.008200  [ 3000/ 3444]
loss: 0.024275  [ 3100/ 3444]
loss: 0.101578  [ 3200/ 3444]
loss: 0.006603  [ 3300/ 3444]
loss: 0.028051  [ 3400/ 3444]
Epoch 8
-------------------------------
loss: 0.014586  [    0/ 3444]
loss: 0.015094  [  100/ 3444]
loss: 0.008821  [  200/ 3444]
loss: 0.016251  [  300/ 3444]
loss: 0.009763  [  400/ 3444]
loss: 0.012942  [  500/ 3444]
loss: 0.009936  [  600/ 3444]
loss: 0.026912  [  700/ 3444]
loss: 0.007734  [  800/ 3444]
loss: 0.017100  [  900/ 3444]
loss: 0.011639  [ 1000/ 3444]
loss: 0.008470  [ 1100/ 3444]
loss: 0.002457  [ 1200/ 3444]
loss: 0.022778  [ 1300/ 3444]
loss: 0.113742  [ 1400/ 3444]
loss: 0.007459  [ 1500/ 3444]
loss: 0.009105  [ 1600/ 3444]
loss: 0.008148  [ 1700/ 3444]
loss: 0.018779  [ 1800/ 3444]
loss: 0.009734  [ 1900/ 3444]
loss: 0.002284  [ 2000/ 3444]
loss: 0.016007  [ 2100/ 3444]
loss: 0.019944  [ 2200/ 3444]
loss: 0.010379  [ 2300/ 3444]
loss: 0.008843  [ 2400/ 3444]
loss: 0.003332  [ 2500/ 3444]
loss: 0.003536  [ 2600/ 3444]
loss: 0.004514  [ 2700/ 3444]
loss: 0.013988  [ 2800/ 3444]
loss: 0.012035  [ 2900/ 3444]
loss: 0.008360  [ 3000/ 3444]
loss: 0.026482  [ 3100/ 3444]
loss: 0.102679  [ 3200/ 3444]
loss: 0.006635  [ 3300/ 3444]
loss: 0.027912  [ 3400/ 3444]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3444
First Spike after testing: [-0.23492825 -0.74059904]
[2 2 0 ... 0 2 0]
[0 0 2 ... 2 0 2]
Cluster 0 Occurrences: 1142; KMEANS: 1118
Cluster 1 Occurrences: 1180; KMEANS: 1195
Cluster 2 Occurrences: 1122; KMEANS: 1131
Centroids: [[0.08332771, 1.1812868], [0.8287676, 1.1589713], [-0.34482723, -0.7963944]]
Centroids: [[-0.34805942, -0.80644834], [0.8505846, 1.1856973], [0.052070532, 1.1562884]]
Contingency Matrix: 
[[   1   65 1076]
 [   2 1127   51]
 [1115    3    4]]
[[1, -1, 1076], [-1, -1, -1], [1115, -1, 4]]
[[-1, -1, 1076], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 2: 0, 0: 2}
New Contingency Matrix: 
[[1076   65    1]
 [  51 1127    2]
 [   4    3 1115]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1076, 1127, 1115], Sum: 3318
All_Elements: [1076, 65, 1, 51, 1127, 2, 4, 3, 1115], Sum: 3444
Accuracy: 0.9634146341463414
Done!
