Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Difficult1_noise020.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_01_01
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA0E55BA90>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
<torch.utils.data.dataloader.DataLoader object at 0x000001FA85B730F0>
Epoch 1
-------------------------------
loss: 0.189320  [    0/ 3414]
loss: 0.056216  [  100/ 3414]
loss: 0.018226  [  200/ 3414]
loss: 0.046502  [  300/ 3414]
loss: 0.042511  [  400/ 3414]
loss: 0.048456  [  500/ 3414]
loss: 0.033100  [  600/ 3414]
loss: 0.034784  [  700/ 3414]
loss: 0.056522  [  800/ 3414]
loss: 0.034777  [  900/ 3414]
loss: 0.017770  [ 1000/ 3414]
loss: 0.022659  [ 1100/ 3414]
loss: 0.010166  [ 1200/ 3414]
loss: 0.032315  [ 1300/ 3414]
loss: 0.017486  [ 1400/ 3414]
loss: 0.029036  [ 1500/ 3414]
loss: 0.011416  [ 1600/ 3414]
loss: 0.010689  [ 1700/ 3414]
loss: 0.031740  [ 1800/ 3414]
loss: 0.020563  [ 1900/ 3414]
loss: 0.034902  [ 2000/ 3414]
loss: 0.033015  [ 2100/ 3414]
loss: 0.039839  [ 2200/ 3414]
loss: 0.033608  [ 2300/ 3414]
loss: 0.009579  [ 2400/ 3414]
loss: 0.161577  [ 2500/ 3414]
loss: 0.027065  [ 2600/ 3414]
loss: 0.014107  [ 2700/ 3414]
loss: 0.012724  [ 2800/ 3414]
loss: 0.040952  [ 2900/ 3414]
loss: 0.045288  [ 3000/ 3414]
loss: 0.035201  [ 3100/ 3414]
loss: 0.020088  [ 3200/ 3414]
loss: 0.012721  [ 3300/ 3414]
loss: 0.025407  [ 3400/ 3414]
Epoch 2
-------------------------------
loss: 0.045727  [    0/ 3414]
loss: 0.029233  [  100/ 3414]
loss: 0.008252  [  200/ 3414]
loss: 0.049978  [  300/ 3414]
loss: 0.014796  [  400/ 3414]
loss: 0.044695  [  500/ 3414]
loss: 0.027571  [  600/ 3414]
loss: 0.033814  [  700/ 3414]
loss: 0.052276  [  800/ 3414]
loss: 0.020529  [  900/ 3414]
loss: 0.016458  [ 1000/ 3414]
loss: 0.023364  [ 1100/ 3414]
loss: 0.006135  [ 1200/ 3414]
loss: 0.032899  [ 1300/ 3414]
loss: 0.018051  [ 1400/ 3414]
loss: 0.028640  [ 1500/ 3414]
loss: 0.011003  [ 1600/ 3414]
loss: 0.010117  [ 1700/ 3414]
loss: 0.030856  [ 1800/ 3414]
loss: 0.021083  [ 1900/ 3414]
loss: 0.034633  [ 2000/ 3414]
loss: 0.033915  [ 2100/ 3414]
loss: 0.040134  [ 2200/ 3414]
loss: 0.034489  [ 2300/ 3414]
loss: 0.009212  [ 2400/ 3414]
loss: 0.156909  [ 2500/ 3414]
loss: 0.025389  [ 2600/ 3414]
loss: 0.013717  [ 2700/ 3414]
loss: 0.012800  [ 2800/ 3414]
loss: 0.042492  [ 2900/ 3414]
loss: 0.045522  [ 3000/ 3414]
loss: 0.035183  [ 3100/ 3414]
loss: 0.020549  [ 3200/ 3414]
loss: 0.012543  [ 3300/ 3414]
loss: 0.025073  [ 3400/ 3414]
Epoch 3
-------------------------------
loss: 0.043774  [    0/ 3414]
loss: 0.029607  [  100/ 3414]
loss: 0.008298  [  200/ 3414]
loss: 0.049930  [  300/ 3414]
loss: 0.015048  [  400/ 3414]
loss: 0.044508  [  500/ 3414]
loss: 0.027701  [  600/ 3414]
loss: 0.033903  [  700/ 3414]
loss: 0.051559  [  800/ 3414]
loss: 0.021785  [  900/ 3414]
loss: 0.016467  [ 1000/ 3414]
loss: 0.023156  [ 1100/ 3414]
loss: 0.006371  [ 1200/ 3414]
loss: 0.032880  [ 1300/ 3414]
loss: 0.018219  [ 1400/ 3414]
loss: 0.028045  [ 1500/ 3414]
loss: 0.010735  [ 1600/ 3414]
loss: 0.010017  [ 1700/ 3414]
loss: 0.030238  [ 1800/ 3414]
loss: 0.020720  [ 1900/ 3414]
loss: 0.034638  [ 2000/ 3414]
loss: 0.033563  [ 2100/ 3414]
loss: 0.040944  [ 2200/ 3414]
loss: 0.035361  [ 2300/ 3414]
loss: 0.008679  [ 2400/ 3414]
loss: 0.156695  [ 2500/ 3414]
loss: 0.024425  [ 2600/ 3414]
loss: 0.013391  [ 2700/ 3414]
loss: 0.013005  [ 2800/ 3414]
loss: 0.042856  [ 2900/ 3414]
loss: 0.045644  [ 3000/ 3414]
loss: 0.035315  [ 3100/ 3414]
loss: 0.020613  [ 3200/ 3414]
loss: 0.012436  [ 3300/ 3414]
loss: 0.024953  [ 3400/ 3414]
Epoch 4
-------------------------------
loss: 0.044543  [    0/ 3414]
loss: 0.029724  [  100/ 3414]
loss: 0.008430  [  200/ 3414]
loss: 0.049631  [  300/ 3414]
loss: 0.014969  [  400/ 3414]
loss: 0.044219  [  500/ 3414]
loss: 0.027815  [  600/ 3414]
loss: 0.034216  [  700/ 3414]
loss: 0.051088  [  800/ 3414]
loss: 0.022346  [  900/ 3414]
loss: 0.016332  [ 1000/ 3414]
loss: 0.022934  [ 1100/ 3414]
loss: 0.006601  [ 1200/ 3414]
loss: 0.032964  [ 1300/ 3414]
loss: 0.018402  [ 1400/ 3414]
loss: 0.027462  [ 1500/ 3414]
loss: 0.010460  [ 1600/ 3414]
loss: 0.009826  [ 1700/ 3414]
loss: 0.029766  [ 1800/ 3414]
loss: 0.020404  [ 1900/ 3414]
loss: 0.034680  [ 2000/ 3414]
loss: 0.033456  [ 2100/ 3414]
loss: 0.041577  [ 2200/ 3414]
loss: 0.035712  [ 2300/ 3414]
loss: 0.008582  [ 2400/ 3414]
loss: 0.158068  [ 2500/ 3414]
loss: 0.024208  [ 2600/ 3414]
loss: 0.013540  [ 2700/ 3414]
loss: 0.013017  [ 2800/ 3414]
loss: 0.043500  [ 2900/ 3414]
loss: 0.045505  [ 3000/ 3414]
loss: 0.035335  [ 3100/ 3414]
loss: 0.020707  [ 3200/ 3414]
loss: 0.012254  [ 3300/ 3414]
loss: 0.024491  [ 3400/ 3414]
Epoch 5
-------------------------------
loss: 0.044149  [    0/ 3414]
loss: 0.030131  [  100/ 3414]
loss: 0.008357  [  200/ 3414]
loss: 0.049719  [  300/ 3414]
loss: 0.014942  [  400/ 3414]
loss: 0.043953  [  500/ 3414]
loss: 0.027799  [  600/ 3414]
loss: 0.034170  [  700/ 3414]
loss: 0.050755  [  800/ 3414]
loss: 0.023048  [  900/ 3414]
loss: 0.016242  [ 1000/ 3414]
loss: 0.022884  [ 1100/ 3414]
loss: 0.006439  [ 1200/ 3414]
loss: 0.033549  [ 1300/ 3414]
loss: 0.018545  [ 1400/ 3414]
loss: 0.026757  [ 1500/ 3414]
loss: 0.009960  [ 1600/ 3414]
loss: 0.009571  [ 1700/ 3414]
loss: 0.029403  [ 1800/ 3414]
loss: 0.020288  [ 1900/ 3414]
loss: 0.034660  [ 2000/ 3414]
loss: 0.033718  [ 2100/ 3414]
loss: 0.040607  [ 2200/ 3414]
loss: 0.036606  [ 2300/ 3414]
loss: 0.008454  [ 2400/ 3414]
loss: 0.158354  [ 2500/ 3414]
loss: 0.023046  [ 2600/ 3414]
loss: 0.013262  [ 2700/ 3414]
loss: 0.013280  [ 2800/ 3414]
loss: 0.043169  [ 2900/ 3414]
loss: 0.045632  [ 3000/ 3414]
loss: 0.035473  [ 3100/ 3414]
loss: 0.020503  [ 3200/ 3414]
loss: 0.012215  [ 3300/ 3414]
loss: 0.024314  [ 3400/ 3414]
Epoch 6
-------------------------------
loss: 0.044940  [    0/ 3414]
loss: 0.030294  [  100/ 3414]
loss: 0.008292  [  200/ 3414]
loss: 0.049310  [  300/ 3414]
loss: 0.014947  [  400/ 3414]
loss: 0.043845  [  500/ 3414]
loss: 0.027828  [  600/ 3414]
loss: 0.034429  [  700/ 3414]
loss: 0.050847  [  800/ 3414]
loss: 0.023767  [  900/ 3414]
loss: 0.016160  [ 1000/ 3414]
loss: 0.022503  [ 1100/ 3414]
loss: 0.006365  [ 1200/ 3414]
loss: 0.032932  [ 1300/ 3414]
loss: 0.018687  [ 1400/ 3414]
loss: 0.026487  [ 1500/ 3414]
loss: 0.009709  [ 1600/ 3414]
loss: 0.009240  [ 1700/ 3414]
loss: 0.029171  [ 1800/ 3414]
loss: 0.020270  [ 1900/ 3414]
loss: 0.034280  [ 2000/ 3414]
loss: 0.033899  [ 2100/ 3414]
loss: 0.040826  [ 2200/ 3414]
loss: 0.037290  [ 2300/ 3414]
loss: 0.008585  [ 2400/ 3414]
loss: 0.158817  [ 2500/ 3414]
loss: 0.022167  [ 2600/ 3414]
loss: 0.013235  [ 2700/ 3414]
loss: 0.013709  [ 2800/ 3414]
loss: 0.043250  [ 2900/ 3414]
loss: 0.045915  [ 3000/ 3414]
loss: 0.035785  [ 3100/ 3414]
loss: 0.020359  [ 3200/ 3414]
loss: 0.012095  [ 3300/ 3414]
loss: 0.024253  [ 3400/ 3414]
Epoch 7
-------------------------------
loss: 0.046221  [    0/ 3414]
loss: 0.030802  [  100/ 3414]
loss: 0.008302  [  200/ 3414]
loss: 0.049233  [  300/ 3414]
loss: 0.015150  [  400/ 3414]
loss: 0.043566  [  500/ 3414]
loss: 0.027712  [  600/ 3414]
loss: 0.034558  [  700/ 3414]
loss: 0.051025  [  800/ 3414]
loss: 0.024756  [  900/ 3414]
loss: 0.015805  [ 1000/ 3414]
loss: 0.022353  [ 1100/ 3414]
loss: 0.006590  [ 1200/ 3414]
loss: 0.032216  [ 1300/ 3414]
loss: 0.018686  [ 1400/ 3414]
loss: 0.026207  [ 1500/ 3414]
loss: 0.009594  [ 1600/ 3414]
loss: 0.009083  [ 1700/ 3414]
loss: 0.029155  [ 1800/ 3414]
loss: 0.020027  [ 1900/ 3414]
loss: 0.034195  [ 2000/ 3414]
loss: 0.034077  [ 2100/ 3414]
loss: 0.041326  [ 2200/ 3414]
loss: 0.037986  [ 2300/ 3414]
loss: 0.008441  [ 2400/ 3414]
loss: 0.157103  [ 2500/ 3414]
loss: 0.021522  [ 2600/ 3414]
loss: 0.012872  [ 2700/ 3414]
loss: 0.014343  [ 2800/ 3414]
loss: 0.043128  [ 2900/ 3414]
loss: 0.045794  [ 3000/ 3414]
loss: 0.035812  [ 3100/ 3414]
loss: 0.020691  [ 3200/ 3414]
loss: 0.011989  [ 3300/ 3414]
loss: 0.024637  [ 3400/ 3414]
Epoch 8
-------------------------------
loss: 0.043534  [    0/ 3414]
loss: 0.030476  [  100/ 3414]
loss: 0.008370  [  200/ 3414]
loss: 0.049108  [  300/ 3414]
loss: 0.015454  [  400/ 3414]
loss: 0.043554  [  500/ 3414]
loss: 0.027574  [  600/ 3414]
loss: 0.034661  [  700/ 3414]
loss: 0.051303  [  800/ 3414]
loss: 0.024358  [  900/ 3414]
loss: 0.015472  [ 1000/ 3414]
loss: 0.021968  [ 1100/ 3414]
loss: 0.007085  [ 1200/ 3414]
loss: 0.031745  [ 1300/ 3414]
loss: 0.018788  [ 1400/ 3414]
loss: 0.026040  [ 1500/ 3414]
loss: 0.009483  [ 1600/ 3414]
loss: 0.011385  [ 1700/ 3414]
loss: 0.028854  [ 1800/ 3414]
loss: 0.020605  [ 1900/ 3414]
loss: 0.032938  [ 2000/ 3414]
loss: 0.035213  [ 2100/ 3414]
loss: 0.042055  [ 2200/ 3414]
loss: 0.039842  [ 2300/ 3414]
loss: 0.008396  [ 2400/ 3414]
loss: 0.154097  [ 2500/ 3414]
loss: 0.019518  [ 2600/ 3414]
loss: 0.012701  [ 2700/ 3414]
loss: 0.015706  [ 2800/ 3414]
loss: 0.043258  [ 2900/ 3414]
loss: 0.045452  [ 3000/ 3414]
loss: 0.040309  [ 3100/ 3414]
loss: 0.021574  [ 3200/ 3414]
loss: 0.012251  [ 3300/ 3414]
loss: 0.024848  [ 3400/ 3414]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3414
First Spike after testing: [0.33753327 1.3168594 ]
[1 1 0 ... 0 0 2]
[0 1 2 ... 0 0 2]
Cluster 0 Occurrences: 1136; KMEANS: 1136
Cluster 1 Occurrences: 1099; KMEANS: 1119
Cluster 2 Occurrences: 1179; KMEANS: 1159
Centroids: [[-0.33664322, 0.47300467], [-0.35154667, 0.34748074], [-0.772015, 0.3725921]]
Centroids: [[-0.34303546, 0.6696186], [-0.24384291, 0.14541566], [-0.8769918, 0.3754045]]
Contingency Matrix: 
[[623 368 145]
 [340 554 205]
 [173 197 809]]
[[623, 368, -1], [340, 554, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, 554, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 0, 1: 1}
New Contingency Matrix: 
[[623 368 145]
 [340 554 205]
 [173 197 809]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [623, 554, 809], Sum: 1986
All_Elements: [623, 368, 145, 340, 554, 205, 173, 197, 809], Sum: 3414
Accuracy: 0.5817223198594025
Done!
