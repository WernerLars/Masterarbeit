Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_54_02
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA032AD400>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x000001FA03BDDA20>
Epoch 1
-------------------------------
loss: 0.307536  [    0/ 3411]
loss: 0.111497  [  100/ 3411]
loss: 0.057577  [  200/ 3411]
loss: 0.016675  [  300/ 3411]
loss: 0.041365  [  400/ 3411]
loss: 0.030722  [  500/ 3411]
loss: 0.014808  [  600/ 3411]
loss: 0.023143  [  700/ 3411]
loss: 0.029670  [  800/ 3411]
loss: 0.039218  [  900/ 3411]
loss: 0.004678  [ 1000/ 3411]
loss: 0.058547  [ 1100/ 3411]
loss: 0.023190  [ 1200/ 3411]
loss: 0.018998  [ 1300/ 3411]
loss: 0.022757  [ 1400/ 3411]
loss: 0.054021  [ 1500/ 3411]
loss: 0.040604  [ 1600/ 3411]
loss: 0.039866  [ 1700/ 3411]
loss: 0.018287  [ 1800/ 3411]
loss: 0.004214  [ 1900/ 3411]
loss: 0.036469  [ 2000/ 3411]
loss: 0.010323  [ 2100/ 3411]
loss: 0.007572  [ 2200/ 3411]
loss: 0.154564  [ 2300/ 3411]
loss: 0.013391  [ 2400/ 3411]
loss: 0.009679  [ 2500/ 3411]
loss: 0.016937  [ 2600/ 3411]
loss: 0.010016  [ 2700/ 3411]
loss: 0.037634  [ 2800/ 3411]
loss: 0.011524  [ 2900/ 3411]
loss: 0.013403  [ 3000/ 3411]
loss: 0.005943  [ 3100/ 3411]
loss: 0.018251  [ 3200/ 3411]
loss: 0.017544  [ 3300/ 3411]
loss: 0.008397  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.020861  [    0/ 3411]
loss: 0.014581  [  100/ 3411]
loss: 0.015741  [  200/ 3411]
loss: 0.012031  [  300/ 3411]
loss: 0.043392  [  400/ 3411]
loss: 0.012450  [  500/ 3411]
loss: 0.005310  [  600/ 3411]
loss: 0.011107  [  700/ 3411]
loss: 0.011266  [  800/ 3411]
loss: 0.018603  [  900/ 3411]
loss: 0.003515  [ 1000/ 3411]
loss: 0.036402  [ 1100/ 3411]
loss: 0.018165  [ 1200/ 3411]
loss: 0.010688  [ 1300/ 3411]
loss: 0.023439  [ 1400/ 3411]
loss: 0.053866  [ 1500/ 3411]
loss: 0.034377  [ 1600/ 3411]
loss: 0.031953  [ 1700/ 3411]
loss: 0.014482  [ 1800/ 3411]
loss: 0.005101  [ 1900/ 3411]
loss: 0.035383  [ 2000/ 3411]
loss: 0.009764  [ 2100/ 3411]
loss: 0.007127  [ 2200/ 3411]
loss: 0.149795  [ 2300/ 3411]
loss: 0.013965  [ 2400/ 3411]
loss: 0.003982  [ 2500/ 3411]
loss: 0.011860  [ 2600/ 3411]
loss: 0.008283  [ 2700/ 3411]
loss: 0.033982  [ 2800/ 3411]
loss: 0.008046  [ 2900/ 3411]
loss: 0.012586  [ 3000/ 3411]
loss: 0.005524  [ 3100/ 3411]
loss: 0.018737  [ 3200/ 3411]
loss: 0.016828  [ 3300/ 3411]
loss: 0.008032  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.021006  [    0/ 3411]
loss: 0.014445  [  100/ 3411]
loss: 0.016829  [  200/ 3411]
loss: 0.011433  [  300/ 3411]
loss: 0.035202  [  400/ 3411]
loss: 0.010184  [  500/ 3411]
loss: 0.004387  [  600/ 3411]
loss: 0.007714  [  700/ 3411]
loss: 0.012506  [  800/ 3411]
loss: 0.020678  [  900/ 3411]
loss: 0.003493  [ 1000/ 3411]
loss: 0.024026  [ 1100/ 3411]
loss: 0.018004  [ 1200/ 3411]
loss: 0.012644  [ 1300/ 3411]
loss: 0.023250  [ 1400/ 3411]
loss: 0.057872  [ 1500/ 3411]
loss: 0.032519  [ 1600/ 3411]
loss: 0.025721  [ 1700/ 3411]
loss: 0.014896  [ 1800/ 3411]
loss: 0.005147  [ 1900/ 3411]
loss: 0.035363  [ 2000/ 3411]
loss: 0.009865  [ 2100/ 3411]
loss: 0.007493  [ 2200/ 3411]
loss: 0.156060  [ 2300/ 3411]
loss: 0.016732  [ 2400/ 3411]
loss: 0.004168  [ 2500/ 3411]
loss: 0.010452  [ 2600/ 3411]
loss: 0.007531  [ 2700/ 3411]
loss: 0.030467  [ 2800/ 3411]
loss: 0.008217  [ 2900/ 3411]
loss: 0.011606  [ 3000/ 3411]
loss: 0.005173  [ 3100/ 3411]
loss: 0.019730  [ 3200/ 3411]
loss: 0.015199  [ 3300/ 3411]
loss: 0.008535  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.021041  [    0/ 3411]
loss: 0.014615  [  100/ 3411]
loss: 0.016473  [  200/ 3411]
loss: 0.012026  [  300/ 3411]
loss: 0.032315  [  400/ 3411]
loss: 0.010186  [  500/ 3411]
loss: 0.003510  [  600/ 3411]
loss: 0.008555  [  700/ 3411]
loss: 0.015622  [  800/ 3411]
loss: 0.019411  [  900/ 3411]
loss: 0.003593  [ 1000/ 3411]
loss: 0.016664  [ 1100/ 3411]
loss: 0.018246  [ 1200/ 3411]
loss: 0.013116  [ 1300/ 3411]
loss: 0.021919  [ 1400/ 3411]
loss: 0.059976  [ 1500/ 3411]
loss: 0.029047  [ 1600/ 3411]
loss: 0.021689  [ 1700/ 3411]
loss: 0.015548  [ 1800/ 3411]
loss: 0.005170  [ 1900/ 3411]
loss: 0.035143  [ 2000/ 3411]
loss: 0.009575  [ 2100/ 3411]
loss: 0.007606  [ 2200/ 3411]
loss: 0.156450  [ 2300/ 3411]
loss: 0.017431  [ 2400/ 3411]
loss: 0.005714  [ 2500/ 3411]
loss: 0.009243  [ 2600/ 3411]
loss: 0.007475  [ 2700/ 3411]
loss: 0.028652  [ 2800/ 3411]
loss: 0.008794  [ 2900/ 3411]
loss: 0.010371  [ 3000/ 3411]
loss: 0.005100  [ 3100/ 3411]
loss: 0.019258  [ 3200/ 3411]
loss: 0.014393  [ 3300/ 3411]
loss: 0.008470  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.020998  [    0/ 3411]
loss: 0.014352  [  100/ 3411]
loss: 0.016284  [  200/ 3411]
loss: 0.012305  [  300/ 3411]
loss: 0.032084  [  400/ 3411]
loss: 0.010425  [  500/ 3411]
loss: 0.003095  [  600/ 3411]
loss: 0.008962  [  700/ 3411]
loss: 0.017597  [  800/ 3411]
loss: 0.018479  [  900/ 3411]
loss: 0.003708  [ 1000/ 3411]
loss: 0.012771  [ 1100/ 3411]
loss: 0.018545  [ 1200/ 3411]
loss: 0.012384  [ 1300/ 3411]
loss: 0.020601  [ 1400/ 3411]
loss: 0.063879  [ 1500/ 3411]
loss: 0.026141  [ 1600/ 3411]
loss: 0.017899  [ 1700/ 3411]
loss: 0.015292  [ 1800/ 3411]
loss: 0.005666  [ 1900/ 3411]
loss: 0.033314  [ 2000/ 3411]
loss: 0.008767  [ 2100/ 3411]
loss: 0.007432  [ 2200/ 3411]
loss: 0.155240  [ 2300/ 3411]
loss: 0.017470  [ 2400/ 3411]
loss: 0.006932  [ 2500/ 3411]
loss: 0.007858  [ 2600/ 3411]
loss: 0.007329  [ 2700/ 3411]
loss: 0.027254  [ 2800/ 3411]
loss: 0.009721  [ 2900/ 3411]
loss: 0.010370  [ 3000/ 3411]
loss: 0.005125  [ 3100/ 3411]
loss: 0.017181  [ 3200/ 3411]
loss: 0.013527  [ 3300/ 3411]
loss: 0.007885  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.019923  [    0/ 3411]
loss: 0.014469  [  100/ 3411]
loss: 0.015767  [  200/ 3411]
loss: 0.012418  [  300/ 3411]
loss: 0.032149  [  400/ 3411]
loss: 0.009823  [  500/ 3411]
loss: 0.002869  [  600/ 3411]
loss: 0.009963  [  700/ 3411]
loss: 0.019148  [  800/ 3411]
loss: 0.017214  [  900/ 3411]
loss: 0.003912  [ 1000/ 3411]
loss: 0.010365  [ 1100/ 3411]
loss: 0.018628  [ 1200/ 3411]
loss: 0.012496  [ 1300/ 3411]
loss: 0.018961  [ 1400/ 3411]
loss: 0.067457  [ 1500/ 3411]
loss: 0.024441  [ 1600/ 3411]
loss: 0.016076  [ 1700/ 3411]
loss: 0.014638  [ 1800/ 3411]
loss: 0.005898  [ 1900/ 3411]
loss: 0.030828  [ 2000/ 3411]
loss: 0.007937  [ 2100/ 3411]
loss: 0.007599  [ 2200/ 3411]
loss: 0.153997  [ 2300/ 3411]
loss: 0.017104  [ 2400/ 3411]
loss: 0.007711  [ 2500/ 3411]
loss: 0.007264  [ 2600/ 3411]
loss: 0.006993  [ 2700/ 3411]
loss: 0.026143  [ 2800/ 3411]
loss: 0.010195  [ 2900/ 3411]
loss: 0.010628  [ 3000/ 3411]
loss: 0.005663  [ 3100/ 3411]
loss: 0.015051  [ 3200/ 3411]
loss: 0.013055  [ 3300/ 3411]
loss: 0.007576  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.019569  [    0/ 3411]
loss: 0.014854  [  100/ 3411]
loss: 0.015994  [  200/ 3411]
loss: 0.012639  [  300/ 3411]
loss: 0.031689  [  400/ 3411]
loss: 0.009256  [  500/ 3411]
loss: 0.002880  [  600/ 3411]
loss: 0.009853  [  700/ 3411]
loss: 0.020730  [  800/ 3411]
loss: 0.016805  [  900/ 3411]
loss: 0.004229  [ 1000/ 3411]
loss: 0.008510  [ 1100/ 3411]
loss: 0.018909  [ 1200/ 3411]
loss: 0.013100  [ 1300/ 3411]
loss: 0.017396  [ 1400/ 3411]
loss: 0.070354  [ 1500/ 3411]
loss: 0.023136  [ 1600/ 3411]
loss: 0.014864  [ 1700/ 3411]
loss: 0.013897  [ 1800/ 3411]
loss: 0.006237  [ 1900/ 3411]
loss: 0.028843  [ 2000/ 3411]
loss: 0.007526  [ 2100/ 3411]
loss: 0.007922  [ 2200/ 3411]
loss: 0.151969  [ 2300/ 3411]
loss: 0.016763  [ 2400/ 3411]
loss: 0.008275  [ 2500/ 3411]
loss: 0.006968  [ 2600/ 3411]
loss: 0.006566  [ 2700/ 3411]
loss: 0.024796  [ 2800/ 3411]
loss: 0.010271  [ 2900/ 3411]
loss: 0.011011  [ 3000/ 3411]
loss: 0.005906  [ 3100/ 3411]
loss: 0.012630  [ 3200/ 3411]
loss: 0.012456  [ 3300/ 3411]
loss: 0.007209  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.020987  [    0/ 3411]
loss: 0.014405  [  100/ 3411]
loss: 0.016725  [  200/ 3411]
loss: 0.012048  [  300/ 3411]
loss: 0.031282  [  400/ 3411]
loss: 0.008709  [  500/ 3411]
loss: 0.002811  [  600/ 3411]
loss: 0.008323  [  700/ 3411]
loss: 0.021680  [  800/ 3411]
loss: 0.016452  [  900/ 3411]
loss: 0.004164  [ 1000/ 3411]
loss: 0.008081  [ 1100/ 3411]
loss: 0.018860  [ 1200/ 3411]
loss: 0.013789  [ 1300/ 3411]
loss: 0.015821  [ 1400/ 3411]
loss: 0.072200  [ 1500/ 3411]
loss: 0.022556  [ 1600/ 3411]
loss: 0.014669  [ 1700/ 3411]
loss: 0.013385  [ 1800/ 3411]
loss: 0.006103  [ 1900/ 3411]
loss: 0.026264  [ 2000/ 3411]
loss: 0.007083  [ 2100/ 3411]
loss: 0.008102  [ 2200/ 3411]
loss: 0.152041  [ 2300/ 3411]
loss: 0.015867  [ 2400/ 3411]
loss: 0.008996  [ 2500/ 3411]
loss: 0.007025  [ 2600/ 3411]
loss: 0.006012  [ 2700/ 3411]
loss: 0.023958  [ 2800/ 3411]
loss: 0.010723  [ 2900/ 3411]
loss: 0.011205  [ 3000/ 3411]
loss: 0.005837  [ 3100/ 3411]
loss: 0.011996  [ 3200/ 3411]
loss: 0.012090  [ 3300/ 3411]
loss: 0.006920  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [0.09346624 1.7224456 ]
[0 2 0 ... 1 1 2]
[2 0 1 ... 1 1 0]
Cluster 0 Occurrences: 1181; KMEANS: 1128
Cluster 1 Occurrences: 1098; KMEANS: 960
Cluster 2 Occurrences: 1132; KMEANS: 1323
Centroids: [[-0.11086372, 1.5340948], [0.7875623, 0.93096036], [0.08871748, -1.0816069]]
Centroids: [[0.09158806, -1.09072], [0.9339949, 0.9156138], [-0.12524933, 1.4821804]]
Contingency Matrix: 
[[   1   37 1143]
 [   3  922  173]
 [1124    1    7]]
[[-1, -1, -1], [3, 922, -1], [1124, 1, -1]]
[[-1, -1, -1], [-1, 922, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 2: 0, 1: 1}
New Contingency Matrix: 
[[1143   37    1]
 [ 173  922    3]
 [   7    1 1124]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1143, 922, 1124], Sum: 3189
All_Elements: [1143, 37, 1, 173, 922, 3, 7, 1, 1124], Sum: 3411
Accuracy: 0.9349164467897977
Done!
