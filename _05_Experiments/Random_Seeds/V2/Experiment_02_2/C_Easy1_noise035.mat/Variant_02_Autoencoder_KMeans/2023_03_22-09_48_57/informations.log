Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Easy1_noise035.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_48_57
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA03AC4940>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
<torch.utils.data.dataloader.DataLoader object at 0x000001FA03BDDF60>
Epoch 1
-------------------------------
loss: 0.281136  [    0/ 3534]
loss: 0.284183  [  100/ 3534]
loss: 0.094457  [  200/ 3534]
loss: 0.211648  [  300/ 3534]
loss: 0.162392  [  400/ 3534]
loss: 0.149443  [  500/ 3534]
loss: 0.066971  [  600/ 3534]
loss: 0.094645  [  700/ 3534]
loss: 0.044715  [  800/ 3534]
loss: 0.028511  [  900/ 3534]
loss: 0.055969  [ 1000/ 3534]
loss: 0.025987  [ 1100/ 3534]
loss: 0.033403  [ 1200/ 3534]
loss: 0.079143  [ 1300/ 3534]
loss: 0.019621  [ 1400/ 3534]
loss: 0.043179  [ 1500/ 3534]
loss: 0.153514  [ 1600/ 3534]
loss: 0.048999  [ 1700/ 3534]
loss: 0.096949  [ 1800/ 3534]
loss: 0.027489  [ 1900/ 3534]
loss: 0.031047  [ 2000/ 3534]
loss: 0.033015  [ 2100/ 3534]
loss: 0.037242  [ 2200/ 3534]
loss: 0.134146  [ 2300/ 3534]
loss: 0.082551  [ 2400/ 3534]
loss: 0.103848  [ 2500/ 3534]
loss: 0.068063  [ 2600/ 3534]
loss: 0.030572  [ 2700/ 3534]
loss: 0.134861  [ 2800/ 3534]
loss: 0.040022  [ 2900/ 3534]
loss: 0.150903  [ 3000/ 3534]
loss: 0.066929  [ 3100/ 3534]
loss: 0.123371  [ 3200/ 3534]
loss: 0.074631  [ 3300/ 3534]
loss: 0.047945  [ 3400/ 3534]
loss: 0.072731  [ 3500/ 3534]
Epoch 2
-------------------------------
loss: 0.128707  [    0/ 3534]
loss: 0.048892  [  100/ 3534]
loss: 0.026173  [  200/ 3534]
loss: 0.110740  [  300/ 3534]
loss: 0.179308  [  400/ 3534]
loss: 0.067612  [  500/ 3534]
loss: 0.079371  [  600/ 3534]
loss: 0.077400  [  700/ 3534]
loss: 0.039190  [  800/ 3534]
loss: 0.030022  [  900/ 3534]
loss: 0.049149  [ 1000/ 3534]
loss: 0.020089  [ 1100/ 3534]
loss: 0.037750  [ 1200/ 3534]
loss: 0.056183  [ 1300/ 3534]
loss: 0.014340  [ 1400/ 3534]
loss: 0.033284  [ 1500/ 3534]
loss: 0.151950  [ 1600/ 3534]
loss: 0.055870  [ 1700/ 3534]
loss: 0.045621  [ 1800/ 3534]
loss: 0.028619  [ 1900/ 3534]
loss: 0.030586  [ 2000/ 3534]
loss: 0.035854  [ 2100/ 3534]
loss: 0.039671  [ 2200/ 3534]
loss: 0.129905  [ 2300/ 3534]
loss: 0.067905  [ 2400/ 3534]
loss: 0.102570  [ 2500/ 3534]
loss: 0.065632  [ 2600/ 3534]
loss: 0.029042  [ 2700/ 3534]
loss: 0.126624  [ 2800/ 3534]
loss: 0.027892  [ 2900/ 3534]
loss: 0.157147  [ 3000/ 3534]
loss: 0.058760  [ 3100/ 3534]
loss: 0.126517  [ 3200/ 3534]
loss: 0.080895  [ 3300/ 3534]
loss: 0.048741  [ 3400/ 3534]
loss: 0.072210  [ 3500/ 3534]
Epoch 3
-------------------------------
loss: 0.127628  [    0/ 3534]
loss: 0.050409  [  100/ 3534]
loss: 0.024936  [  200/ 3534]
loss: 0.104340  [  300/ 3534]
loss: 0.196344  [  400/ 3534]
loss: 0.056498  [  500/ 3534]
loss: 0.082899  [  600/ 3534]
loss: 0.081040  [  700/ 3534]
loss: 0.039832  [  800/ 3534]
loss: 0.027124  [  900/ 3534]
loss: 0.044814  [ 1000/ 3534]
loss: 0.019767  [ 1100/ 3534]
loss: 0.039539  [ 1200/ 3534]
loss: 0.052310  [ 1300/ 3534]
loss: 0.014073  [ 1400/ 3534]
loss: 0.030344  [ 1500/ 3534]
loss: 0.151867  [ 1600/ 3534]
loss: 0.056750  [ 1700/ 3534]
loss: 0.039460  [ 1800/ 3534]
loss: 0.028612  [ 1900/ 3534]
loss: 0.028765  [ 2000/ 3534]
loss: 0.036096  [ 2100/ 3534]
loss: 0.038904  [ 2200/ 3534]
loss: 0.126831  [ 2300/ 3534]
loss: 0.069148  [ 2400/ 3534]
loss: 0.097615  [ 2500/ 3534]
loss: 0.063419  [ 2600/ 3534]
loss: 0.029690  [ 2700/ 3534]
loss: 0.119994  [ 2800/ 3534]
loss: 0.026206  [ 2900/ 3534]
loss: 0.158960  [ 3000/ 3534]
loss: 0.056491  [ 3100/ 3534]
loss: 0.128116  [ 3200/ 3534]
loss: 0.090817  [ 3300/ 3534]
loss: 0.047821  [ 3400/ 3534]
loss: 0.073369  [ 3500/ 3534]
Epoch 4
-------------------------------
loss: 0.126192  [    0/ 3534]
loss: 0.056111  [  100/ 3534]
loss: 0.023236  [  200/ 3534]
loss: 0.103621  [  300/ 3534]
loss: 0.206761  [  400/ 3534]
loss: 0.053405  [  500/ 3534]
loss: 0.081357  [  600/ 3534]
loss: 0.078951  [  700/ 3534]
loss: 0.040520  [  800/ 3534]
loss: 0.026576  [  900/ 3534]
loss: 0.040921  [ 1000/ 3534]
loss: 0.018907  [ 1100/ 3534]
loss: 0.038207  [ 1200/ 3534]
loss: 0.053311  [ 1300/ 3534]
loss: 0.013629  [ 1400/ 3534]
loss: 0.031300  [ 1500/ 3534]
loss: 0.154351  [ 1600/ 3534]
loss: 0.057869  [ 1700/ 3534]
loss: 0.037697  [ 1800/ 3534]
loss: 0.029299  [ 1900/ 3534]
loss: 0.027647  [ 2000/ 3534]
loss: 0.035919  [ 2100/ 3534]
loss: 0.038267  [ 2200/ 3534]
loss: 0.126486  [ 2300/ 3534]
loss: 0.070254  [ 2400/ 3534]
loss: 0.096834  [ 2500/ 3534]
loss: 0.061803  [ 2600/ 3534]
loss: 0.029699  [ 2700/ 3534]
loss: 0.113581  [ 2800/ 3534]
loss: 0.023841  [ 2900/ 3534]
loss: 0.158986  [ 3000/ 3534]
loss: 0.055002  [ 3100/ 3534]
loss: 0.129909  [ 3200/ 3534]
loss: 0.093553  [ 3300/ 3534]
loss: 0.046469  [ 3400/ 3534]
loss: 0.073641  [ 3500/ 3534]
Epoch 5
-------------------------------
loss: 0.125744  [    0/ 3534]
loss: 0.056470  [  100/ 3534]
loss: 0.023797  [  200/ 3534]
loss: 0.102016  [  300/ 3534]
loss: 0.213686  [  400/ 3534]
loss: 0.050858  [  500/ 3534]
loss: 0.080141  [  600/ 3534]
loss: 0.076880  [  700/ 3534]
loss: 0.040596  [  800/ 3534]
loss: 0.026340  [  900/ 3534]
loss: 0.038567  [ 1000/ 3534]
loss: 0.017005  [ 1100/ 3534]
loss: 0.041260  [ 1200/ 3534]
loss: 0.053420  [ 1300/ 3534]
loss: 0.013181  [ 1400/ 3534]
loss: 0.031448  [ 1500/ 3534]
loss: 0.158088  [ 1600/ 3534]
loss: 0.057743  [ 1700/ 3534]
loss: 0.037994  [ 1800/ 3534]
loss: 0.029904  [ 1900/ 3534]
loss: 0.026221  [ 2000/ 3534]
loss: 0.036006  [ 2100/ 3534]
loss: 0.038795  [ 2200/ 3534]
loss: 0.126496  [ 2300/ 3534]
loss: 0.070580  [ 2400/ 3534]
loss: 0.096585  [ 2500/ 3534]
loss: 0.061663  [ 2600/ 3534]
loss: 0.029417  [ 2700/ 3534]
loss: 0.113178  [ 2800/ 3534]
loss: 0.022989  [ 2900/ 3534]
loss: 0.160540  [ 3000/ 3534]
loss: 0.052983  [ 3100/ 3534]
loss: 0.129926  [ 3200/ 3534]
loss: 0.080924  [ 3300/ 3534]
loss: 0.045942  [ 3400/ 3534]
loss: 0.073254  [ 3500/ 3534]
Epoch 6
-------------------------------
loss: 0.124801  [    0/ 3534]
loss: 0.055339  [  100/ 3534]
loss: 0.024108  [  200/ 3534]
loss: 0.104294  [  300/ 3534]
loss: 0.210095  [  400/ 3534]
loss: 0.047605  [  500/ 3534]
loss: 0.077891  [  600/ 3534]
loss: 0.076333  [  700/ 3534]
loss: 0.041352  [  800/ 3534]
loss: 0.026474  [  900/ 3534]
loss: 0.036527  [ 1000/ 3534]
loss: 0.016498  [ 1100/ 3534]
loss: 0.040145  [ 1200/ 3534]
loss: 0.053837  [ 1300/ 3534]
loss: 0.013397  [ 1400/ 3534]
loss: 0.031976  [ 1500/ 3534]
loss: 0.158339  [ 1600/ 3534]
loss: 0.057135  [ 1700/ 3534]
loss: 0.038567  [ 1800/ 3534]
loss: 0.029421  [ 1900/ 3534]
loss: 0.026148  [ 2000/ 3534]
loss: 0.035910  [ 2100/ 3534]
loss: 0.038066  [ 2200/ 3534]
loss: 0.127331  [ 2300/ 3534]
loss: 0.072555  [ 2400/ 3534]
loss: 0.094583  [ 2500/ 3534]
loss: 0.062729  [ 2600/ 3534]
loss: 0.029316  [ 2700/ 3534]
loss: 0.113827  [ 2800/ 3534]
loss: 0.022973  [ 2900/ 3534]
loss: 0.166838  [ 3000/ 3534]
loss: 0.052519  [ 3100/ 3534]
loss: 0.129247  [ 3200/ 3534]
loss: 0.075479  [ 3300/ 3534]
loss: 0.045520  [ 3400/ 3534]
loss: 0.073636  [ 3500/ 3534]
Epoch 7
-------------------------------
loss: 0.124589  [    0/ 3534]
loss: 0.053548  [  100/ 3534]
loss: 0.025005  [  200/ 3534]
loss: 0.108727  [  300/ 3534]
loss: 0.209477  [  400/ 3534]
loss: 0.044051  [  500/ 3534]
loss: 0.075924  [  600/ 3534]
loss: 0.075139  [  700/ 3534]
loss: 0.041182  [  800/ 3534]
loss: 0.026282  [  900/ 3534]
loss: 0.034371  [ 1000/ 3534]
loss: 0.015909  [ 1100/ 3534]
loss: 0.036598  [ 1200/ 3534]
loss: 0.053841  [ 1300/ 3534]
loss: 0.013929  [ 1400/ 3534]
loss: 0.032332  [ 1500/ 3534]
loss: 0.157943  [ 1600/ 3534]
loss: 0.055885  [ 1700/ 3534]
loss: 0.039043  [ 1800/ 3534]
loss: 0.029944  [ 1900/ 3534]
loss: 0.025861  [ 2000/ 3534]
loss: 0.035534  [ 2100/ 3534]
loss: 0.037263  [ 2200/ 3534]
loss: 0.127194  [ 2300/ 3534]
loss: 0.070558  [ 2400/ 3534]
loss: 0.093565  [ 2500/ 3534]
loss: 0.063885  [ 2600/ 3534]
loss: 0.029020  [ 2700/ 3534]
loss: 0.116844  [ 2800/ 3534]
loss: 0.022754  [ 2900/ 3534]
loss: 0.170065  [ 3000/ 3534]
loss: 0.050726  [ 3100/ 3534]
loss: 0.130459  [ 3200/ 3534]
loss: 0.078381  [ 3300/ 3534]
loss: 0.045294  [ 3400/ 3534]
loss: 0.073236  [ 3500/ 3534]
Epoch 8
-------------------------------
loss: 0.123934  [    0/ 3534]
loss: 0.053117  [  100/ 3534]
loss: 0.024577  [  200/ 3534]
loss: 0.109712  [  300/ 3534]
loss: 0.213769  [  400/ 3534]
loss: 0.041956  [  500/ 3534]
loss: 0.075210  [  600/ 3534]
loss: 0.076039  [  700/ 3534]
loss: 0.041140  [  800/ 3534]
loss: 0.027218  [  900/ 3534]
loss: 0.033261  [ 1000/ 3534]
loss: 0.015850  [ 1100/ 3534]
loss: 0.033170  [ 1200/ 3534]
loss: 0.055574  [ 1300/ 3534]
loss: 0.014130  [ 1400/ 3534]
loss: 0.032844  [ 1500/ 3534]
loss: 0.157886  [ 1600/ 3534]
loss: 0.054235  [ 1700/ 3534]
loss: 0.039253  [ 1800/ 3534]
loss: 0.030108  [ 1900/ 3534]
loss: 0.025527  [ 2000/ 3534]
loss: 0.035207  [ 2100/ 3534]
loss: 0.036683  [ 2200/ 3534]
loss: 0.127099  [ 2300/ 3534]
loss: 0.066662  [ 2400/ 3534]
loss: 0.093108  [ 2500/ 3534]
loss: 0.064232  [ 2600/ 3534]
loss: 0.028885  [ 2700/ 3534]
loss: 0.115228  [ 2800/ 3534]
loss: 0.022750  [ 2900/ 3534]
loss: 0.177008  [ 3000/ 3534]
loss: 0.048029  [ 3100/ 3534]
loss: 0.132437  [ 3200/ 3534]
loss: 0.076911  [ 3300/ 3534]
loss: 0.045234  [ 3400/ 3534]
loss: 0.072848  [ 3500/ 3534]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3534
First Spike after testing: [-1.1099718  0.323764 ]
[0 1 2 ... 2 2 1]
[1 0 2 ... 2 1 0]
Cluster 0 Occurrences: 1208; KMEANS: 1167
Cluster 1 Occurrences: 1137; KMEANS: 1258
Cluster 2 Occurrences: 1189; KMEANS: 1109
Centroids: [[-0.8786646, 0.3285475], [1.4974868, 1.2974772], [-0.25664452, -1.3065861]]
Centroids: [[1.5162078, 1.259883], [-0.98480105, 0.3107939], [-0.17535576, -1.3910514]]
Contingency Matrix: 
[[   1 1123   84]
 [1125    6    6]
 [  41  129 1019]]
[[-1, 1123, 84], [-1, -1, -1], [-1, 129, 1019]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 1019]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 0, 0: 1, 2: 2}
New Contingency Matrix: 
[[1123    1   84]
 [   6 1125    6]
 [ 129   41 1019]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [1123, 1125, 1019], Sum: 3267
All_Elements: [1123, 1, 84, 6, 1125, 6, 129, 41, 1019], Sum: 3534
Accuracy: 0.9244482173174873
Done!
