Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_03_53
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA87E855F8>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x000001FA94049940>
Epoch 1
-------------------------------
loss: 0.167063  [    0/ 3462]
loss: 0.071214  [  100/ 3462]
loss: 0.030095  [  200/ 3462]
loss: 0.015121  [  300/ 3462]
loss: 0.010740  [  400/ 3462]
loss: 0.008354  [  500/ 3462]
loss: 0.014558  [  600/ 3462]
loss: 0.021609  [  700/ 3462]
loss: 0.010347  [  800/ 3462]
loss: 0.012204  [  900/ 3462]
loss: 0.014660  [ 1000/ 3462]
loss: 0.065678  [ 1100/ 3462]
loss: 0.009962  [ 1200/ 3462]
loss: 0.008062  [ 1300/ 3462]
loss: 0.012796  [ 1400/ 3462]
loss: 0.006193  [ 1500/ 3462]
loss: 0.007722  [ 1600/ 3462]
loss: 0.006304  [ 1700/ 3462]
loss: 0.012196  [ 1800/ 3462]
loss: 0.006861  [ 1900/ 3462]
loss: 0.012230  [ 2000/ 3462]
loss: 0.052016  [ 2100/ 3462]
loss: 0.007636  [ 2200/ 3462]
loss: 0.006950  [ 2300/ 3462]
loss: 0.013453  [ 2400/ 3462]
loss: 0.006054  [ 2500/ 3462]
loss: 0.019926  [ 2600/ 3462]
loss: 0.008599  [ 2700/ 3462]
loss: 0.008371  [ 2800/ 3462]
loss: 0.011839  [ 2900/ 3462]
loss: 0.114000  [ 3000/ 3462]
loss: 0.006517  [ 3100/ 3462]
loss: 0.007908  [ 3200/ 3462]
loss: 0.132941  [ 3300/ 3462]
loss: 0.011909  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.002571  [    0/ 3462]
loss: 0.013268  [  100/ 3462]
loss: 0.012427  [  200/ 3462]
loss: 0.008743  [  300/ 3462]
loss: 0.010159  [  400/ 3462]
loss: 0.008547  [  500/ 3462]
loss: 0.005359  [  600/ 3462]
loss: 0.014845  [  700/ 3462]
loss: 0.008251  [  800/ 3462]
loss: 0.015354  [  900/ 3462]
loss: 0.008993  [ 1000/ 3462]
loss: 0.047796  [ 1100/ 3462]
loss: 0.010728  [ 1200/ 3462]
loss: 0.004491  [ 1300/ 3462]
loss: 0.005592  [ 1400/ 3462]
loss: 0.006118  [ 1500/ 3462]
loss: 0.008319  [ 1600/ 3462]
loss: 0.007212  [ 1700/ 3462]
loss: 0.016705  [ 1800/ 3462]
loss: 0.008085  [ 1900/ 3462]
loss: 0.010702  [ 2000/ 3462]
loss: 0.050475  [ 2100/ 3462]
loss: 0.001717  [ 2200/ 3462]
loss: 0.007549  [ 2300/ 3462]
loss: 0.011890  [ 2400/ 3462]
loss: 0.005781  [ 2500/ 3462]
loss: 0.015829  [ 2600/ 3462]
loss: 0.007334  [ 2700/ 3462]
loss: 0.004622  [ 2800/ 3462]
loss: 0.014247  [ 2900/ 3462]
loss: 0.113321  [ 3000/ 3462]
loss: 0.005616  [ 3100/ 3462]
loss: 0.007733  [ 3200/ 3462]
loss: 0.135133  [ 3300/ 3462]
loss: 0.010705  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.001659  [    0/ 3462]
loss: 0.012506  [  100/ 3462]
loss: 0.011795  [  200/ 3462]
loss: 0.007080  [  300/ 3462]
loss: 0.008651  [  400/ 3462]
loss: 0.008483  [  500/ 3462]
loss: 0.003264  [  600/ 3462]
loss: 0.016709  [  700/ 3462]
loss: 0.008244  [  800/ 3462]
loss: 0.015385  [  900/ 3462]
loss: 0.009145  [ 1000/ 3462]
loss: 0.043650  [ 1100/ 3462]
loss: 0.011630  [ 1200/ 3462]
loss: 0.004119  [ 1300/ 3462]
loss: 0.005022  [ 1400/ 3462]
loss: 0.006084  [ 1500/ 3462]
loss: 0.007728  [ 1600/ 3462]
loss: 0.005749  [ 1700/ 3462]
loss: 0.016475  [ 1800/ 3462]
loss: 0.008424  [ 1900/ 3462]
loss: 0.009229  [ 2000/ 3462]
loss: 0.048228  [ 2100/ 3462]
loss: 0.001991  [ 2200/ 3462]
loss: 0.007439  [ 2300/ 3462]
loss: 0.011758  [ 2400/ 3462]
loss: 0.005944  [ 2500/ 3462]
loss: 0.014817  [ 2600/ 3462]
loss: 0.006752  [ 2700/ 3462]
loss: 0.004203  [ 2800/ 3462]
loss: 0.014795  [ 2900/ 3462]
loss: 0.112766  [ 3000/ 3462]
loss: 0.006563  [ 3100/ 3462]
loss: 0.008246  [ 3200/ 3462]
loss: 0.137344  [ 3300/ 3462]
loss: 0.011060  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.001568  [    0/ 3462]
loss: 0.012690  [  100/ 3462]
loss: 0.011049  [  200/ 3462]
loss: 0.007386  [  300/ 3462]
loss: 0.008523  [  400/ 3462]
loss: 0.007932  [  500/ 3462]
loss: 0.001752  [  600/ 3462]
loss: 0.017069  [  700/ 3462]
loss: 0.008515  [  800/ 3462]
loss: 0.015482  [  900/ 3462]
loss: 0.008934  [ 1000/ 3462]
loss: 0.042706  [ 1100/ 3462]
loss: 0.011945  [ 1200/ 3462]
loss: 0.004110  [ 1300/ 3462]
loss: 0.004338  [ 1400/ 3462]
loss: 0.007074  [ 1500/ 3462]
loss: 0.007045  [ 1600/ 3462]
loss: 0.006067  [ 1700/ 3462]
loss: 0.015502  [ 1800/ 3462]
loss: 0.008332  [ 1900/ 3462]
loss: 0.007219  [ 2000/ 3462]
loss: 0.049191  [ 2100/ 3462]
loss: 0.002085  [ 2200/ 3462]
loss: 0.007470  [ 2300/ 3462]
loss: 0.011723  [ 2400/ 3462]
loss: 0.006155  [ 2500/ 3462]
loss: 0.014085  [ 2600/ 3462]
loss: 0.006463  [ 2700/ 3462]
loss: 0.004205  [ 2800/ 3462]
loss: 0.014774  [ 2900/ 3462]
loss: 0.110934  [ 3000/ 3462]
loss: 0.006754  [ 3100/ 3462]
loss: 0.008481  [ 3200/ 3462]
loss: 0.139813  [ 3300/ 3462]
loss: 0.011656  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.001524  [    0/ 3462]
loss: 0.012654  [  100/ 3462]
loss: 0.009749  [  200/ 3462]
loss: 0.008793  [  300/ 3462]
loss: 0.008063  [  400/ 3462]
loss: 0.007148  [  500/ 3462]
loss: 0.001013  [  600/ 3462]
loss: 0.017535  [  700/ 3462]
loss: 0.008905  [  800/ 3462]
loss: 0.015885  [  900/ 3462]
loss: 0.008673  [ 1000/ 3462]
loss: 0.043056  [ 1100/ 3462]
loss: 0.011951  [ 1200/ 3462]
loss: 0.003858  [ 1300/ 3462]
loss: 0.003765  [ 1400/ 3462]
loss: 0.008410  [ 1500/ 3462]
loss: 0.006198  [ 1600/ 3462]
loss: 0.006268  [ 1700/ 3462]
loss: 0.014470  [ 1800/ 3462]
loss: 0.008127  [ 1900/ 3462]
loss: 0.005755  [ 2000/ 3462]
loss: 0.051864  [ 2100/ 3462]
loss: 0.002114  [ 2200/ 3462]
loss: 0.007317  [ 2300/ 3462]
loss: 0.011791  [ 2400/ 3462]
loss: 0.006295  [ 2500/ 3462]
loss: 0.012906  [ 2600/ 3462]
loss: 0.006290  [ 2700/ 3462]
loss: 0.004326  [ 2800/ 3462]
loss: 0.014490  [ 2900/ 3462]
loss: 0.109133  [ 3000/ 3462]
loss: 0.006675  [ 3100/ 3462]
loss: 0.008619  [ 3200/ 3462]
loss: 0.139458  [ 3300/ 3462]
loss: 0.012352  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.001517  [    0/ 3462]
loss: 0.012368  [  100/ 3462]
loss: 0.008168  [  200/ 3462]
loss: 0.010586  [  300/ 3462]
loss: 0.007917  [  400/ 3462]
loss: 0.006249  [  500/ 3462]
loss: 0.000865  [  600/ 3462]
loss: 0.017915  [  700/ 3462]
loss: 0.009289  [  800/ 3462]
loss: 0.016343  [  900/ 3462]
loss: 0.008301  [ 1000/ 3462]
loss: 0.044249  [ 1100/ 3462]
loss: 0.010862  [ 1200/ 3462]
loss: 0.003994  [ 1300/ 3462]
loss: 0.003105  [ 1400/ 3462]
loss: 0.009343  [ 1500/ 3462]
loss: 0.005068  [ 1600/ 3462]
loss: 0.006641  [ 1700/ 3462]
loss: 0.012648  [ 1800/ 3462]
loss: 0.007831  [ 1900/ 3462]
loss: 0.004770  [ 2000/ 3462]
loss: 0.054592  [ 2100/ 3462]
loss: 0.002028  [ 2200/ 3462]
loss: 0.007059  [ 2300/ 3462]
loss: 0.011830  [ 2400/ 3462]
loss: 0.006434  [ 2500/ 3462]
loss: 0.011849  [ 2600/ 3462]
loss: 0.006213  [ 2700/ 3462]
loss: 0.004648  [ 2800/ 3462]
loss: 0.013988  [ 2900/ 3462]
loss: 0.106639  [ 3000/ 3462]
loss: 0.006596  [ 3100/ 3462]
loss: 0.008655  [ 3200/ 3462]
loss: 0.137051  [ 3300/ 3462]
loss: 0.012847  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.001540  [    0/ 3462]
loss: 0.012156  [  100/ 3462]
loss: 0.007035  [  200/ 3462]
loss: 0.012286  [  300/ 3462]
loss: 0.008255  [  400/ 3462]
loss: 0.005410  [  500/ 3462]
loss: 0.001021  [  600/ 3462]
loss: 0.018101  [  700/ 3462]
loss: 0.009616  [  800/ 3462]
loss: 0.016685  [  900/ 3462]
loss: 0.007835  [ 1000/ 3462]
loss: 0.045570  [ 1100/ 3462]
loss: 0.010416  [ 1200/ 3462]
loss: 0.004021  [ 1300/ 3462]
loss: 0.002683  [ 1400/ 3462]
loss: 0.010062  [ 1500/ 3462]
loss: 0.004281  [ 1600/ 3462]
loss: 0.006595  [ 1700/ 3462]
loss: 0.011339  [ 1800/ 3462]
loss: 0.007337  [ 1900/ 3462]
loss: 0.004293  [ 2000/ 3462]
loss: 0.056861  [ 2100/ 3462]
loss: 0.001954  [ 2200/ 3462]
loss: 0.006791  [ 2300/ 3462]
loss: 0.011876  [ 2400/ 3462]
loss: 0.006450  [ 2500/ 3462]
loss: 0.010962  [ 2600/ 3462]
loss: 0.006122  [ 2700/ 3462]
loss: 0.004875  [ 2800/ 3462]
loss: 0.013379  [ 2900/ 3462]
loss: 0.104846  [ 3000/ 3462]
loss: 0.006403  [ 3100/ 3462]
loss: 0.008643  [ 3200/ 3462]
loss: 0.133521  [ 3300/ 3462]
loss: 0.013252  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.001586  [    0/ 3462]
loss: 0.011840  [  100/ 3462]
loss: 0.005520  [  200/ 3462]
loss: 0.013504  [  300/ 3462]
loss: 0.008631  [  400/ 3462]
loss: 0.004851  [  500/ 3462]
loss: 0.001382  [  600/ 3462]
loss: 0.018212  [  700/ 3462]
loss: 0.009869  [  800/ 3462]
loss: 0.016812  [  900/ 3462]
loss: 0.007367  [ 1000/ 3462]
loss: 0.045903  [ 1100/ 3462]
loss: 0.010575  [ 1200/ 3462]
loss: 0.003958  [ 1300/ 3462]
loss: 0.002386  [ 1400/ 3462]
loss: 0.010763  [ 1500/ 3462]
loss: 0.003607  [ 1600/ 3462]
loss: 0.006555  [ 1700/ 3462]
loss: 0.010337  [ 1800/ 3462]
loss: 0.006994  [ 1900/ 3462]
loss: 0.004021  [ 2000/ 3462]
loss: 0.058625  [ 2100/ 3462]
loss: 0.001893  [ 2200/ 3462]
loss: 0.006489  [ 2300/ 3462]
loss: 0.011935  [ 2400/ 3462]
loss: 0.006481  [ 2500/ 3462]
loss: 0.010218  [ 2600/ 3462]
loss: 0.005983  [ 2700/ 3462]
loss: 0.005100  [ 2800/ 3462]
loss: 0.012841  [ 2900/ 3462]
loss: 0.103573  [ 3000/ 3462]
loss: 0.006302  [ 3100/ 3462]
loss: 0.008498  [ 3200/ 3462]
loss: 0.129924  [ 3300/ 3462]
loss: 0.013490  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [ 0.3002825  -0.81208193]
[0 2 2 ... 0 1 2]
[0 2 2 ... 0 1 2]
Cluster 0 Occurrences: 1187; KMEANS: 1191
Cluster 1 Occurrences: 1136; KMEANS: 1141
Cluster 2 Occurrences: 1139; KMEANS: 1130
Centroids: [[0.4386096, -0.8831233], [-0.37735158, 1.0003908], [-0.13922562, -0.0069769556]]
Centroids: [[0.45397273, -0.90861267], [-0.38423005, 1.0048734], [-0.14946443, 0.014006303]]
Contingency Matrix: 
[[1157    5   25]
 [   2 1127    7]
 [  32    9 1098]]
[[-1, -1, -1], [-1, 1127, 7], [-1, 9, 1098]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 1098]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[1157    5   25]
 [   2 1127    7]
 [  32    9 1098]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1157, 1127, 1098], Sum: 3382
All_Elements: [1157, 5, 25, 2, 1127, 7, 32, 9, 1098], Sum: 3462
Accuracy: 0.976891969959561
Done!
