Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Easy1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_42_45
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA03BDD940>
Sampling rate: 24000.0
Raw: [ 0.01223885  0.0148803   0.02156532 ... -0.02666729 -0.01215068
  0.01031338]
Times: [   1012    1333    1523 ... 1438660 1438690 1439287]
Cluster: [1 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3522
First aligned Spike Frame: [-0.12579972 -0.1620207  -0.18573939 -0.18961714 -0.17315203 -0.1396561
 -0.09426159 -0.04496221  0.00734136  0.05943689  0.09448878  0.07601101
  0.00811529  0.09446653  0.55421698  1.03008495  0.90195967  0.23116337
 -0.37857386 -0.59030761 -0.52695739 -0.40967661 -0.32471334 -0.26000903
 -0.19839489 -0.13975054 -0.09692457 -0.08223204 -0.09147337 -0.10695261
 -0.11338461 -0.10883018 -0.09915766 -0.08637804 -0.06514771 -0.03537735
 -0.00695045  0.01307529  0.02539335  0.03607991  0.04814655  0.05257424
  0.04538721  0.03512231  0.03354714  0.04141478  0.0511991 ]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1134
Cluster 2, Occurrences: 1237
<torch.utils.data.dataloader.DataLoader object at 0x000001FA032AD400>
Epoch 1
-------------------------------
loss: 0.108981  [    0/ 3522]
loss: 0.162910  [  100/ 3522]
loss: 0.036510  [  200/ 3522]
loss: 0.048245  [  300/ 3522]
loss: 0.009610  [  400/ 3522]
loss: 0.009064  [  500/ 3522]
loss: 0.121202  [  600/ 3522]
loss: 0.019780  [  700/ 3522]
loss: 0.016221  [  800/ 3522]
loss: 0.007468  [  900/ 3522]
loss: 0.004983  [ 1000/ 3522]
loss: 0.004339  [ 1100/ 3522]
loss: 0.094359  [ 1200/ 3522]
loss: 0.017440  [ 1300/ 3522]
loss: 0.002649  [ 1400/ 3522]
loss: 0.003743  [ 1500/ 3522]
loss: 0.009611  [ 1600/ 3522]
loss: 0.008102  [ 1700/ 3522]
loss: 0.014249  [ 1800/ 3522]
loss: 0.013183  [ 1900/ 3522]
loss: 0.011759  [ 2000/ 3522]
loss: 0.012137  [ 2100/ 3522]
loss: 0.005308  [ 2200/ 3522]
loss: 0.006798  [ 2300/ 3522]
loss: 0.005790  [ 2400/ 3522]
loss: 0.004539  [ 2500/ 3522]
loss: 0.071301  [ 2600/ 3522]
loss: 0.007787  [ 2700/ 3522]
loss: 0.003284  [ 2800/ 3522]
loss: 0.004496  [ 2900/ 3522]
loss: 0.011056  [ 3000/ 3522]
loss: 0.006703  [ 3100/ 3522]
loss: 0.014103  [ 3200/ 3522]
loss: 0.010035  [ 3300/ 3522]
loss: 0.011499  [ 3400/ 3522]
loss: 0.005601  [ 3500/ 3522]
Epoch 2
-------------------------------
loss: 0.010981  [    0/ 3522]
loss: 0.008534  [  100/ 3522]
loss: 0.004455  [  200/ 3522]
loss: 0.045513  [  300/ 3522]
loss: 0.007175  [  400/ 3522]
loss: 0.010002  [  500/ 3522]
loss: 0.120239  [  600/ 3522]
loss: 0.014785  [  700/ 3522]
loss: 0.012065  [  800/ 3522]
loss: 0.007048  [  900/ 3522]
loss: 0.003575  [ 1000/ 3522]
loss: 0.004073  [ 1100/ 3522]
loss: 0.084459  [ 1200/ 3522]
loss: 0.015272  [ 1300/ 3522]
loss: 0.002885  [ 1400/ 3522]
loss: 0.003179  [ 1500/ 3522]
loss: 0.011094  [ 1600/ 3522]
loss: 0.006988  [ 1700/ 3522]
loss: 0.009891  [ 1800/ 3522]
loss: 0.010789  [ 1900/ 3522]
loss: 0.011354  [ 2000/ 3522]
loss: 0.008045  [ 2100/ 3522]
loss: 0.004394  [ 2200/ 3522]
loss: 0.007787  [ 2300/ 3522]
loss: 0.004931  [ 2400/ 3522]
loss: 0.004733  [ 2500/ 3522]
loss: 0.072116  [ 2600/ 3522]
loss: 0.006853  [ 2700/ 3522]
loss: 0.002353  [ 2800/ 3522]
loss: 0.004724  [ 2900/ 3522]
loss: 0.011205  [ 3000/ 3522]
loss: 0.004896  [ 3100/ 3522]
loss: 0.009924  [ 3200/ 3522]
loss: 0.010159  [ 3300/ 3522]
loss: 0.012469  [ 3400/ 3522]
loss: 0.006048  [ 3500/ 3522]
Epoch 3
-------------------------------
loss: 0.010919  [    0/ 3522]
loss: 0.008591  [  100/ 3522]
loss: 0.004706  [  200/ 3522]
loss: 0.033537  [  300/ 3522]
loss: 0.006323  [  400/ 3522]
loss: 0.009263  [  500/ 3522]
loss: 0.121900  [  600/ 3522]
loss: 0.014302  [  700/ 3522]
loss: 0.011010  [  800/ 3522]
loss: 0.006438  [  900/ 3522]
loss: 0.003616  [ 1000/ 3522]
loss: 0.004022  [ 1100/ 3522]
loss: 0.083109  [ 1200/ 3522]
loss: 0.014946  [ 1300/ 3522]
loss: 0.002724  [ 1400/ 3522]
loss: 0.003485  [ 1500/ 3522]
loss: 0.010530  [ 1600/ 3522]
loss: 0.007034  [ 1700/ 3522]
loss: 0.011374  [ 1800/ 3522]
loss: 0.011185  [ 1900/ 3522]
loss: 0.011280  [ 2000/ 3522]
loss: 0.007631  [ 2100/ 3522]
loss: 0.004624  [ 2200/ 3522]
loss: 0.006576  [ 2300/ 3522]
loss: 0.004796  [ 2400/ 3522]
loss: 0.004221  [ 2500/ 3522]
loss: 0.071338  [ 2600/ 3522]
loss: 0.006359  [ 2700/ 3522]
loss: 0.002488  [ 2800/ 3522]
loss: 0.004320  [ 2900/ 3522]
loss: 0.011948  [ 3000/ 3522]
loss: 0.003091  [ 3100/ 3522]
loss: 0.007742  [ 3200/ 3522]
loss: 0.010772  [ 3300/ 3522]
loss: 0.012189  [ 3400/ 3522]
loss: 0.005939  [ 3500/ 3522]
Epoch 4
-------------------------------
loss: 0.010599  [    0/ 3522]
loss: 0.008423  [  100/ 3522]
loss: 0.004694  [  200/ 3522]
loss: 0.026278  [  300/ 3522]
loss: 0.006879  [  400/ 3522]
loss: 0.008985  [  500/ 3522]
loss: 0.123447  [  600/ 3522]
loss: 0.013674  [  700/ 3522]
loss: 0.009869  [  800/ 3522]
loss: 0.006536  [  900/ 3522]
loss: 0.003782  [ 1000/ 3522]
loss: 0.003931  [ 1100/ 3522]
loss: 0.080075  [ 1200/ 3522]
loss: 0.015022  [ 1300/ 3522]
loss: 0.002675  [ 1400/ 3522]
loss: 0.003294  [ 1500/ 3522]
loss: 0.009994  [ 1600/ 3522]
loss: 0.006650  [ 1700/ 3522]
loss: 0.011306  [ 1800/ 3522]
loss: 0.011478  [ 1900/ 3522]
loss: 0.010990  [ 2000/ 3522]
loss: 0.007716  [ 2100/ 3522]
loss: 0.004350  [ 2200/ 3522]
loss: 0.006453  [ 2300/ 3522]
loss: 0.004655  [ 2400/ 3522]
loss: 0.003594  [ 2500/ 3522]
loss: 0.070861  [ 2600/ 3522]
loss: 0.006325  [ 2700/ 3522]
loss: 0.002340  [ 2800/ 3522]
loss: 0.004269  [ 2900/ 3522]
loss: 0.012518  [ 3000/ 3522]
loss: 0.003786  [ 3100/ 3522]
loss: 0.006712  [ 3200/ 3522]
loss: 0.011288  [ 3300/ 3522]
loss: 0.011507  [ 3400/ 3522]
loss: 0.005795  [ 3500/ 3522]
Epoch 5
-------------------------------
loss: 0.010029  [    0/ 3522]
loss: 0.008602  [  100/ 3522]
loss: 0.005342  [  200/ 3522]
loss: 0.022791  [  300/ 3522]
loss: 0.006500  [  400/ 3522]
loss: 0.009125  [  500/ 3522]
loss: 0.123169  [  600/ 3522]
loss: 0.013015  [  700/ 3522]
loss: 0.008856  [  800/ 3522]
loss: 0.006532  [  900/ 3522]
loss: 0.003918  [ 1000/ 3522]
loss: 0.003806  [ 1100/ 3522]
loss: 0.077419  [ 1200/ 3522]
loss: 0.014694  [ 1300/ 3522]
loss: 0.002660  [ 1400/ 3522]
loss: 0.003078  [ 1500/ 3522]
loss: 0.009855  [ 1600/ 3522]
loss: 0.007013  [ 1700/ 3522]
loss: 0.011079  [ 1800/ 3522]
loss: 0.011416  [ 1900/ 3522]
loss: 0.010681  [ 2000/ 3522]
loss: 0.007614  [ 2100/ 3522]
loss: 0.004150  [ 2200/ 3522]
loss: 0.006554  [ 2300/ 3522]
loss: 0.004586  [ 2400/ 3522]
loss: 0.003299  [ 2500/ 3522]
loss: 0.070337  [ 2600/ 3522]
loss: 0.006330  [ 2700/ 3522]
loss: 0.002241  [ 2800/ 3522]
loss: 0.004231  [ 2900/ 3522]
loss: 0.012605  [ 3000/ 3522]
loss: 0.002790  [ 3100/ 3522]
loss: 0.006087  [ 3200/ 3522]
loss: 0.010752  [ 3300/ 3522]
loss: 0.011540  [ 3400/ 3522]
loss: 0.005852  [ 3500/ 3522]
Epoch 6
-------------------------------
loss: 0.009779  [    0/ 3522]
loss: 0.008754  [  100/ 3522]
loss: 0.004912  [  200/ 3522]
loss: 0.022515  [  300/ 3522]
loss: 0.007078  [  400/ 3522]
loss: 0.008999  [  500/ 3522]
loss: 0.123511  [  600/ 3522]
loss: 0.012571  [  700/ 3522]
loss: 0.008282  [  800/ 3522]
loss: 0.006657  [  900/ 3522]
loss: 0.003964  [ 1000/ 3522]
loss: 0.003792  [ 1100/ 3522]
loss: 0.076019  [ 1200/ 3522]
loss: 0.014494  [ 1300/ 3522]
loss: 0.002682  [ 1400/ 3522]
loss: 0.002886  [ 1500/ 3522]
loss: 0.009776  [ 1600/ 3522]
loss: 0.006680  [ 1700/ 3522]
loss: 0.011399  [ 1800/ 3522]
loss: 0.011313  [ 1900/ 3522]
loss: 0.010552  [ 2000/ 3522]
loss: 0.007504  [ 2100/ 3522]
loss: 0.003889  [ 2200/ 3522]
loss: 0.006487  [ 2300/ 3522]
loss: 0.004593  [ 2400/ 3522]
loss: 0.003097  [ 2500/ 3522]
loss: 0.070022  [ 2600/ 3522]
loss: 0.006532  [ 2700/ 3522]
loss: 0.002168  [ 2800/ 3522]
loss: 0.004248  [ 2900/ 3522]
loss: 0.012137  [ 3000/ 3522]
loss: 0.002296  [ 3100/ 3522]
loss: 0.005626  [ 3200/ 3522]
loss: 0.010731  [ 3300/ 3522]
loss: 0.011687  [ 3400/ 3522]
loss: 0.005781  [ 3500/ 3522]
Epoch 7
-------------------------------
loss: 0.009063  [    0/ 3522]
loss: 0.008890  [  100/ 3522]
loss: 0.004391  [  200/ 3522]
loss: 0.022931  [  300/ 3522]
loss: 0.006872  [  400/ 3522]
loss: 0.008927  [  500/ 3522]
loss: 0.123401  [  600/ 3522]
loss: 0.012411  [  700/ 3522]
loss: 0.007811  [  800/ 3522]
loss: 0.006717  [  900/ 3522]
loss: 0.003967  [ 1000/ 3522]
loss: 0.003822  [ 1100/ 3522]
loss: 0.076329  [ 1200/ 3522]
loss: 0.014387  [ 1300/ 3522]
loss: 0.002883  [ 1400/ 3522]
loss: 0.002704  [ 1500/ 3522]
loss: 0.009675  [ 1600/ 3522]
loss: 0.005999  [ 1700/ 3522]
loss: 0.011288  [ 1800/ 3522]
loss: 0.011123  [ 1900/ 3522]
loss: 0.010481  [ 2000/ 3522]
loss: 0.007516  [ 2100/ 3522]
loss: 0.003871  [ 2200/ 3522]
loss: 0.007422  [ 2300/ 3522]
loss: 0.005091  [ 2400/ 3522]
loss: 0.002982  [ 2500/ 3522]
loss: 0.070191  [ 2600/ 3522]
loss: 0.006758  [ 2700/ 3522]
loss: 0.002098  [ 2800/ 3522]
loss: 0.004318  [ 2900/ 3522]
loss: 0.012377  [ 3000/ 3522]
loss: 0.002431  [ 3100/ 3522]
loss: 0.005851  [ 3200/ 3522]
loss: 0.010470  [ 3300/ 3522]
loss: 0.011537  [ 3400/ 3522]
loss: 0.005750  [ 3500/ 3522]
Epoch 8
-------------------------------
loss: 0.008943  [    0/ 3522]
loss: 0.008933  [  100/ 3522]
loss: 0.004715  [  200/ 3522]
loss: 0.022376  [  300/ 3522]
loss: 0.006619  [  400/ 3522]
loss: 0.009032  [  500/ 3522]
loss: 0.123271  [  600/ 3522]
loss: 0.012329  [  700/ 3522]
loss: 0.007758  [  800/ 3522]
loss: 0.006747  [  900/ 3522]
loss: 0.003912  [ 1000/ 3522]
loss: 0.003780  [ 1100/ 3522]
loss: 0.077464  [ 1200/ 3522]
loss: 0.014266  [ 1300/ 3522]
loss: 0.002765  [ 1400/ 3522]
loss: 0.002587  [ 1500/ 3522]
loss: 0.009586  [ 1600/ 3522]
loss: 0.006122  [ 1700/ 3522]
loss: 0.011238  [ 1800/ 3522]
loss: 0.011043  [ 1900/ 3522]
loss: 0.010515  [ 2000/ 3522]
loss: 0.007496  [ 2100/ 3522]
loss: 0.003855  [ 2200/ 3522]
loss: 0.007202  [ 2300/ 3522]
loss: 0.004789  [ 2400/ 3522]
loss: 0.002902  [ 2500/ 3522]
loss: 0.070187  [ 2600/ 3522]
loss: 0.006919  [ 2700/ 3522]
loss: 0.002009  [ 2800/ 3522]
loss: 0.004339  [ 2900/ 3522]
loss: 0.012395  [ 3000/ 3522]
loss: 0.002866  [ 3100/ 3522]
loss: 0.005419  [ 3200/ 3522]
loss: 0.010793  [ 3300/ 3522]
loss: 0.011780  [ 3400/ 3522]
loss: 0.005813  [ 3500/ 3522]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3522
First Spike after testing: [-1.0582068  0.6540649]
[0 2 2 ... 2 0 2]
[2 0 0 ... 0 2 0]
Cluster 0 Occurrences: 1151; KMEANS: 1257
Cluster 1 Occurrences: 1134; KMEANS: 1117
Cluster 2 Occurrences: 1237; KMEANS: 1148
Centroids: [[-1.2915956, 0.65086854], [0.77866006, 0.8243415], [-0.3659817, -1.2572939]]
Centroids: [[-0.34431937, -1.2549807], [0.7777906, 0.84808093], [-1.2999374, 0.66104937]]
Contingency Matrix: 
[[   9    3 1139]
 [  15 1114    5]
 [1233    0    4]]
[[-1, 3, 1139], [-1, 1114, 5], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1114, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1139    3    9]
 [   5 1114   15]
 [   4    0 1233]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1139, 1114, 1233], Sum: 3486
All_Elements: [1139, 3, 9, 5, 1114, 15, 4, 0, 1233], Sum: 3522
Accuracy: 0.989778534923339
Done!
