Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Difficult1_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_59_34
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA877E09E8>
Sampling rate: 24000.0
Raw: [ 0.04887081  0.02693095 -0.0154249  ... -0.09301659 -0.11629005
 -0.14613101]
Times: [    340     491     641 ... 1439047 1439065 1439816]
Cluster: [1 1 1 ... 3 2 2]
Number of different clusters:  3
Number of Spikes: 3472
First aligned Spike Frame: [ 0.12751554  0.12305882  0.10482977  0.09479529  0.10214978  0.11675932
  0.11777927  0.09307299  0.04670706 -0.00574343 -0.06143573 -0.14637617
 -0.20942665 -0.00208103  0.52241508  0.81651544  0.46446121 -0.19226425
 -0.60927882 -0.6713583  -0.57871227 -0.49011309 -0.4269388  -0.3668903
 -0.30523219 -0.24747124 -0.19738203 -0.15189972 -0.10449507 -0.05533325
 -0.01452429  0.01008816  0.02570853  0.04365027  0.06334113  0.07980397
  0.08484457  0.07688513  0.06142919  0.04320028  0.02240626  0.00477291
 -0.00393242 -0.00135684  0.00575182  0.0026944  -0.01541647]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1172
Cluster 2, Occurrences: 1141
<torch.utils.data.dataloader.DataLoader object at 0x000001FA85B730F0>
Epoch 1
-------------------------------
loss: 0.103343  [    0/ 3472]
loss: 0.054619  [  100/ 3472]
loss: 0.009219  [  200/ 3472]
loss: 0.018840  [  300/ 3472]
loss: 0.030480  [  400/ 3472]
loss: 0.016425  [  500/ 3472]
loss: 0.014348  [  600/ 3472]
loss: 0.004690  [  700/ 3472]
loss: 0.039315  [  800/ 3472]
loss: 0.027119  [  900/ 3472]
loss: 0.011048  [ 1000/ 3472]
loss: 0.023821  [ 1100/ 3472]
loss: 0.023739  [ 1200/ 3472]
loss: 0.011841  [ 1300/ 3472]
loss: 0.003621  [ 1400/ 3472]
loss: 0.047778  [ 1500/ 3472]
loss: 0.020980  [ 1600/ 3472]
loss: 0.010754  [ 1700/ 3472]
loss: 0.025320  [ 1800/ 3472]
loss: 0.143541  [ 1900/ 3472]
loss: 0.044802  [ 2000/ 3472]
loss: 0.013185  [ 2100/ 3472]
loss: 0.010685  [ 2200/ 3472]
loss: 0.005694  [ 2300/ 3472]
loss: 0.009725  [ 2400/ 3472]
loss: 0.012146  [ 2500/ 3472]
loss: 0.015218  [ 2600/ 3472]
loss: 0.010075  [ 2700/ 3472]
loss: 0.024550  [ 2800/ 3472]
loss: 0.030674  [ 2900/ 3472]
loss: 0.008614  [ 3000/ 3472]
loss: 0.021998  [ 3100/ 3472]
loss: 0.014479  [ 3200/ 3472]
loss: 0.009023  [ 3300/ 3472]
loss: 0.008877  [ 3400/ 3472]
Epoch 2
-------------------------------
loss: 0.009876  [    0/ 3472]
loss: 0.007806  [  100/ 3472]
loss: 0.010111  [  200/ 3472]
loss: 0.017310  [  300/ 3472]
loss: 0.006130  [  400/ 3472]
loss: 0.015938  [  500/ 3472]
loss: 0.012090  [  600/ 3472]
loss: 0.005308  [  700/ 3472]
loss: 0.036679  [  800/ 3472]
loss: 0.027393  [  900/ 3472]
loss: 0.009944  [ 1000/ 3472]
loss: 0.027202  [ 1100/ 3472]
loss: 0.024562  [ 1200/ 3472]
loss: 0.006333  [ 1300/ 3472]
loss: 0.003268  [ 1400/ 3472]
loss: 0.037972  [ 1500/ 3472]
loss: 0.018943  [ 1600/ 3472]
loss: 0.010994  [ 1700/ 3472]
loss: 0.028363  [ 1800/ 3472]
loss: 0.136956  [ 1900/ 3472]
loss: 0.048857  [ 2000/ 3472]
loss: 0.013830  [ 2100/ 3472]
loss: 0.010700  [ 2200/ 3472]
loss: 0.005488  [ 2300/ 3472]
loss: 0.009249  [ 2400/ 3472]
loss: 0.013078  [ 2500/ 3472]
loss: 0.013787  [ 2600/ 3472]
loss: 0.011240  [ 2700/ 3472]
loss: 0.025641  [ 2800/ 3472]
loss: 0.028887  [ 2900/ 3472]
loss: 0.009109  [ 3000/ 3472]
loss: 0.019774  [ 3100/ 3472]
loss: 0.014102  [ 3200/ 3472]
loss: 0.008518  [ 3300/ 3472]
loss: 0.009150  [ 3400/ 3472]
Epoch 3
-------------------------------
loss: 0.008431  [    0/ 3472]
loss: 0.007712  [  100/ 3472]
loss: 0.010303  [  200/ 3472]
loss: 0.017455  [  300/ 3472]
loss: 0.005710  [  400/ 3472]
loss: 0.015673  [  500/ 3472]
loss: 0.012645  [  600/ 3472]
loss: 0.005302  [  700/ 3472]
loss: 0.035746  [  800/ 3472]
loss: 0.027689  [  900/ 3472]
loss: 0.009336  [ 1000/ 3472]
loss: 0.027376  [ 1100/ 3472]
loss: 0.024144  [ 1200/ 3472]
loss: 0.005463  [ 1300/ 3472]
loss: 0.003023  [ 1400/ 3472]
loss: 0.034449  [ 1500/ 3472]
loss: 0.018190  [ 1600/ 3472]
loss: 0.011240  [ 1700/ 3472]
loss: 0.029202  [ 1800/ 3472]
loss: 0.135572  [ 1900/ 3472]
loss: 0.051006  [ 2000/ 3472]
loss: 0.013983  [ 2100/ 3472]
loss: 0.010875  [ 2200/ 3472]
loss: 0.005846  [ 2300/ 3472]
loss: 0.008840  [ 2400/ 3472]
loss: 0.014182  [ 2500/ 3472]
loss: 0.013128  [ 2600/ 3472]
loss: 0.012078  [ 2700/ 3472]
loss: 0.025326  [ 2800/ 3472]
loss: 0.027996  [ 2900/ 3472]
loss: 0.009320  [ 3000/ 3472]
loss: 0.018567  [ 3100/ 3472]
loss: 0.013661  [ 3200/ 3472]
loss: 0.008332  [ 3300/ 3472]
loss: 0.009610  [ 3400/ 3472]
Epoch 4
-------------------------------
loss: 0.007436  [    0/ 3472]
loss: 0.007546  [  100/ 3472]
loss: 0.010377  [  200/ 3472]
loss: 0.017585  [  300/ 3472]
loss: 0.005424  [  400/ 3472]
loss: 0.015484  [  500/ 3472]
loss: 0.012944  [  600/ 3472]
loss: 0.005567  [  700/ 3472]
loss: 0.035146  [  800/ 3472]
loss: 0.028098  [  900/ 3472]
loss: 0.008811  [ 1000/ 3472]
loss: 0.026887  [ 1100/ 3472]
loss: 0.023465  [ 1200/ 3472]
loss: 0.004710  [ 1300/ 3472]
loss: 0.003385  [ 1400/ 3472]
loss: 0.031260  [ 1500/ 3472]
loss: 0.017226  [ 1600/ 3472]
loss: 0.011378  [ 1700/ 3472]
loss: 0.029995  [ 1800/ 3472]
loss: 0.134885  [ 1900/ 3472]
loss: 0.052328  [ 2000/ 3472]
loss: 0.013870  [ 2100/ 3472]
loss: 0.011174  [ 2200/ 3472]
loss: 0.006177  [ 2300/ 3472]
loss: 0.008456  [ 2400/ 3472]
loss: 0.014523  [ 2500/ 3472]
loss: 0.012683  [ 2600/ 3472]
loss: 0.012751  [ 2700/ 3472]
loss: 0.022437  [ 2800/ 3472]
loss: 0.026990  [ 2900/ 3472]
loss: 0.009644  [ 3000/ 3472]
loss: 0.017241  [ 3100/ 3472]
loss: 0.013244  [ 3200/ 3472]
loss: 0.008440  [ 3300/ 3472]
loss: 0.009975  [ 3400/ 3472]
Epoch 5
-------------------------------
loss: 0.006641  [    0/ 3472]
loss: 0.007582  [  100/ 3472]
loss: 0.010411  [  200/ 3472]
loss: 0.017563  [  300/ 3472]
loss: 0.005007  [  400/ 3472]
loss: 0.015137  [  500/ 3472]
loss: 0.013902  [  600/ 3472]
loss: 0.005495  [  700/ 3472]
loss: 0.034748  [  800/ 3472]
loss: 0.028425  [  900/ 3472]
loss: 0.008270  [ 1000/ 3472]
loss: 0.025772  [ 1100/ 3472]
loss: 0.022483  [ 1200/ 3472]
loss: 0.004332  [ 1300/ 3472]
loss: 0.003810  [ 1400/ 3472]
loss: 0.027928  [ 1500/ 3472]
loss: 0.016322  [ 1600/ 3472]
loss: 0.011834  [ 1700/ 3472]
loss: 0.030234  [ 1800/ 3472]
loss: 0.135285  [ 1900/ 3472]
loss: 0.052827  [ 2000/ 3472]
loss: 0.013531  [ 2100/ 3472]
loss: 0.011705  [ 2200/ 3472]
loss: 0.006701  [ 2300/ 3472]
loss: 0.008343  [ 2400/ 3472]
loss: 0.015023  [ 2500/ 3472]
loss: 0.011545  [ 2600/ 3472]
loss: 0.013473  [ 2700/ 3472]
loss: 0.025516  [ 2800/ 3472]
loss: 0.028258  [ 2900/ 3472]
loss: 0.010567  [ 3000/ 3472]
loss: 0.015600  [ 3100/ 3472]
loss: 0.013069  [ 3200/ 3472]
loss: 0.007938  [ 3300/ 3472]
loss: 0.010443  [ 3400/ 3472]
Epoch 6
-------------------------------
loss: 0.005798  [    0/ 3472]
loss: 0.007319  [  100/ 3472]
loss: 0.010862  [  200/ 3472]
loss: 0.017630  [  300/ 3472]
loss: 0.004634  [  400/ 3472]
loss: 0.014952  [  500/ 3472]
loss: 0.014104  [  600/ 3472]
loss: 0.005045  [  700/ 3472]
loss: 0.034484  [  800/ 3472]
loss: 0.028112  [  900/ 3472]
loss: 0.008131  [ 1000/ 3472]
loss: 0.025349  [ 1100/ 3472]
loss: 0.021450  [ 1200/ 3472]
loss: 0.004285  [ 1300/ 3472]
loss: 0.003600  [ 1400/ 3472]
loss: 0.024588  [ 1500/ 3472]
loss: 0.015291  [ 1600/ 3472]
loss: 0.011725  [ 1700/ 3472]
loss: 0.028467  [ 1800/ 3472]
loss: 0.135749  [ 1900/ 3472]
loss: 0.053092  [ 2000/ 3472]
loss: 0.013383  [ 2100/ 3472]
loss: 0.011813  [ 2200/ 3472]
loss: 0.007436  [ 2300/ 3472]
loss: 0.008477  [ 2400/ 3472]
loss: 0.015305  [ 2500/ 3472]
loss: 0.010445  [ 2600/ 3472]
loss: 0.013904  [ 2700/ 3472]
loss: 0.024178  [ 2800/ 3472]
loss: 0.027744  [ 2900/ 3472]
loss: 0.011097  [ 3000/ 3472]
loss: 0.013974  [ 3100/ 3472]
loss: 0.012924  [ 3200/ 3472]
loss: 0.007581  [ 3300/ 3472]
loss: 0.010546  [ 3400/ 3472]
Epoch 7
-------------------------------
loss: 0.005458  [    0/ 3472]
loss: 0.007107  [  100/ 3472]
loss: 0.011021  [  200/ 3472]
loss: 0.017652  [  300/ 3472]
loss: 0.004519  [  400/ 3472]
loss: 0.014760  [  500/ 3472]
loss: 0.015161  [  600/ 3472]
loss: 0.004732  [  700/ 3472]
loss: 0.034194  [  800/ 3472]
loss: 0.027955  [  900/ 3472]
loss: 0.008075  [ 1000/ 3472]
loss: 0.024119  [ 1100/ 3472]
loss: 0.020237  [ 1200/ 3472]
loss: 0.004346  [ 1300/ 3472]
loss: 0.003282  [ 1400/ 3472]
loss: 0.020676  [ 1500/ 3472]
loss: 0.014177  [ 1600/ 3472]
loss: 0.012013  [ 1700/ 3472]
loss: 0.026486  [ 1800/ 3472]
loss: 0.137042  [ 1900/ 3472]
loss: 0.052814  [ 2000/ 3472]
loss: 0.012656  [ 2100/ 3472]
loss: 0.012060  [ 2200/ 3472]
loss: 0.008138  [ 2300/ 3472]
loss: 0.008443  [ 2400/ 3472]
loss: 0.015310  [ 2500/ 3472]
loss: 0.009599  [ 2600/ 3472]
loss: 0.014749  [ 2700/ 3472]
loss: 0.023095  [ 2800/ 3472]
loss: 0.027094  [ 2900/ 3472]
loss: 0.011285  [ 3000/ 3472]
loss: 0.012581  [ 3100/ 3472]
loss: 0.012701  [ 3200/ 3472]
loss: 0.007108  [ 3300/ 3472]
loss: 0.010386  [ 3400/ 3472]
Epoch 8
-------------------------------
loss: 0.005133  [    0/ 3472]
loss: 0.007129  [  100/ 3472]
loss: 0.011116  [  200/ 3472]
loss: 0.017601  [  300/ 3472]
loss: 0.004650  [  400/ 3472]
loss: 0.014709  [  500/ 3472]
loss: 0.015318  [  600/ 3472]
loss: 0.004094  [  700/ 3472]
loss: 0.033835  [  800/ 3472]
loss: 0.027893  [  900/ 3472]
loss: 0.008192  [ 1000/ 3472]
loss: 0.022967  [ 1100/ 3472]
loss: 0.019159  [ 1200/ 3472]
loss: 0.004442  [ 1300/ 3472]
loss: 0.003102  [ 1400/ 3472]
loss: 0.016386  [ 1500/ 3472]
loss: 0.013433  [ 1600/ 3472]
loss: 0.011669  [ 1700/ 3472]
loss: 0.023597  [ 1800/ 3472]
loss: 0.139004  [ 1900/ 3472]
loss: 0.052232  [ 2000/ 3472]
loss: 0.011932  [ 2100/ 3472]
loss: 0.012085  [ 2200/ 3472]
loss: 0.008190  [ 2300/ 3472]
loss: 0.008294  [ 2400/ 3472]
loss: 0.016143  [ 2500/ 3472]
loss: 0.009055  [ 2600/ 3472]
loss: 0.014788  [ 2700/ 3472]
loss: 0.021925  [ 2800/ 3472]
loss: 0.026551  [ 2900/ 3472]
loss: 0.011491  [ 3000/ 3472]
loss: 0.011458  [ 3100/ 3472]
loss: 0.012809  [ 3200/ 3472]
loss: 0.006695  [ 3300/ 3472]
loss: 0.010103  [ 3400/ 3472]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3472
First Spike after testing: [-0.05052368  0.8051976 ]
[0 0 0 ... 2 1 1]
[0 0 0 ... 2 0 1]
Cluster 0 Occurrences: 1159; KMEANS: 1247
Cluster 1 Occurrences: 1172; KMEANS: 1216
Cluster 2 Occurrences: 1141; KMEANS: 1009
Centroids: [[-0.27271265, 0.65553135], [-0.45591235, 0.100692734], [-0.9534576, 0.25213897]]
Centroids: [[-0.3327687, 0.73262835], [-0.3635936, 0.1499499], [-1.0715619, 0.06891647]]
Contingency Matrix: 
[[937 170  52]
 [ 71 906 195]
 [239 140 762]]
[[-1, -1, -1], [-1, 906, 195], [-1, 140, 762]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 762]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[937 170  52]
 [ 71 906 195]
 [239 140 762]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [937, 906, 762], Sum: 2605
All_Elements: [937, 170, 52, 71, 906, 195, 239, 140, 762], Sum: 3472
Accuracy: 0.7502880184331797
Done!
