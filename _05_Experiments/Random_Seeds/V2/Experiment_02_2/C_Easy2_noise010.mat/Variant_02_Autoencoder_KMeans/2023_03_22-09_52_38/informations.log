Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Easy2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_52_38
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA03ABC780>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
<torch.utils.data.dataloader.DataLoader object at 0x000001FA03BDD320>
Epoch 1
-------------------------------
loss: 0.269909  [    0/ 3520]
loss: 0.062750  [  100/ 3520]
loss: 0.198831  [  200/ 3520]
loss: 0.016082  [  300/ 3520]
loss: 0.107516  [  400/ 3520]
loss: 0.151556  [  500/ 3520]
loss: 0.016535  [  600/ 3520]
loss: 0.008903  [  700/ 3520]
loss: 0.007257  [  800/ 3520]
loss: 0.016597  [  900/ 3520]
loss: 0.003640  [ 1000/ 3520]
loss: 0.011795  [ 1100/ 3520]
loss: 0.011139  [ 1200/ 3520]
loss: 0.028465  [ 1300/ 3520]
loss: 0.011016  [ 1400/ 3520]
loss: 0.001623  [ 1500/ 3520]
loss: 0.003935  [ 1600/ 3520]
loss: 0.002476  [ 1700/ 3520]
loss: 0.079231  [ 1800/ 3520]
loss: 0.007976  [ 1900/ 3520]
loss: 0.013983  [ 2000/ 3520]
loss: 0.007618  [ 2100/ 3520]
loss: 0.007683  [ 2200/ 3520]
loss: 0.093263  [ 2300/ 3520]
loss: 0.005635  [ 2400/ 3520]
loss: 0.010145  [ 2500/ 3520]
loss: 0.010077  [ 2600/ 3520]
loss: 0.003589  [ 2700/ 3520]
loss: 0.016157  [ 2800/ 3520]
loss: 0.007000  [ 2900/ 3520]
loss: 0.012115  [ 3000/ 3520]
loss: 0.027472  [ 3100/ 3520]
loss: 0.005636  [ 3200/ 3520]
loss: 0.003668  [ 3300/ 3520]
loss: 0.007676  [ 3400/ 3520]
loss: 0.013423  [ 3500/ 3520]
Epoch 2
-------------------------------
loss: 0.014128  [    0/ 3520]
loss: 0.003493  [  100/ 3520]
loss: 0.158034  [  200/ 3520]
loss: 0.004752  [  300/ 3520]
loss: 0.112076  [  400/ 3520]
loss: 0.111996  [  500/ 3520]
loss: 0.006521  [  600/ 3520]
loss: 0.006898  [  700/ 3520]
loss: 0.007248  [  800/ 3520]
loss: 0.004940  [  900/ 3520]
loss: 0.003668  [ 1000/ 3520]
loss: 0.007929  [ 1100/ 3520]
loss: 0.010513  [ 1200/ 3520]
loss: 0.020942  [ 1300/ 3520]
loss: 0.012783  [ 1400/ 3520]
loss: 0.001067  [ 1500/ 3520]
loss: 0.003515  [ 1600/ 3520]
loss: 0.002355  [ 1700/ 3520]
loss: 0.074518  [ 1800/ 3520]
loss: 0.007713  [ 1900/ 3520]
loss: 0.011451  [ 2000/ 3520]
loss: 0.006937  [ 2100/ 3520]
loss: 0.006504  [ 2200/ 3520]
loss: 0.089335  [ 2300/ 3520]
loss: 0.004298  [ 2400/ 3520]
loss: 0.009722  [ 2500/ 3520]
loss: 0.010235  [ 2600/ 3520]
loss: 0.003389  [ 2700/ 3520]
loss: 0.015120  [ 2800/ 3520]
loss: 0.005147  [ 2900/ 3520]
loss: 0.011147  [ 3000/ 3520]
loss: 0.025905  [ 3100/ 3520]
loss: 0.005799  [ 3200/ 3520]
loss: 0.003949  [ 3300/ 3520]
loss: 0.008296  [ 3400/ 3520]
loss: 0.010828  [ 3500/ 3520]
Epoch 3
-------------------------------
loss: 0.011048  [    0/ 3520]
loss: 0.003843  [  100/ 3520]
loss: 0.136321  [  200/ 3520]
loss: 0.005258  [  300/ 3520]
loss: 0.115418  [  400/ 3520]
loss: 0.111801  [  500/ 3520]
loss: 0.006392  [  600/ 3520]
loss: 0.006353  [  700/ 3520]
loss: 0.006633  [  800/ 3520]
loss: 0.003205  [  900/ 3520]
loss: 0.003517  [ 1000/ 3520]
loss: 0.009246  [ 1100/ 3520]
loss: 0.010540  [ 1200/ 3520]
loss: 0.012193  [ 1300/ 3520]
loss: 0.011280  [ 1400/ 3520]
loss: 0.001446  [ 1500/ 3520]
loss: 0.003440  [ 1600/ 3520]
loss: 0.003157  [ 1700/ 3520]
loss: 0.083605  [ 1800/ 3520]
loss: 0.007723  [ 1900/ 3520]
loss: 0.010503  [ 2000/ 3520]
loss: 0.006817  [ 2100/ 3520]
loss: 0.006711  [ 2200/ 3520]
loss: 0.079943  [ 2300/ 3520]
loss: 0.004415  [ 2400/ 3520]
loss: 0.009724  [ 2500/ 3520]
loss: 0.010731  [ 2600/ 3520]
loss: 0.003375  [ 2700/ 3520]
loss: 0.014056  [ 2800/ 3520]
loss: 0.003894  [ 2900/ 3520]
loss: 0.011134  [ 3000/ 3520]
loss: 0.021743  [ 3100/ 3520]
loss: 0.006138  [ 3200/ 3520]
loss: 0.003961  [ 3300/ 3520]
loss: 0.008050  [ 3400/ 3520]
loss: 0.009278  [ 3500/ 3520]
Epoch 4
-------------------------------
loss: 0.009637  [    0/ 3520]
loss: 0.004080  [  100/ 3520]
loss: 0.119367  [  200/ 3520]
loss: 0.005025  [  300/ 3520]
loss: 0.112987  [  400/ 3520]
loss: 0.114915  [  500/ 3520]
loss: 0.006149  [  600/ 3520]
loss: 0.006390  [  700/ 3520]
loss: 0.005773  [  800/ 3520]
loss: 0.002359  [  900/ 3520]
loss: 0.003135  [ 1000/ 3520]
loss: 0.009231  [ 1100/ 3520]
loss: 0.010181  [ 1200/ 3520]
loss: 0.007724  [ 1300/ 3520]
loss: 0.009862  [ 1400/ 3520]
loss: 0.002126  [ 1500/ 3520]
loss: 0.003488  [ 1600/ 3520]
loss: 0.003449  [ 1700/ 3520]
loss: 0.093099  [ 1800/ 3520]
loss: 0.007687  [ 1900/ 3520]
loss: 0.010672  [ 2000/ 3520]
loss: 0.006908  [ 2100/ 3520]
loss: 0.005900  [ 2200/ 3520]
loss: 0.069001  [ 2300/ 3520]
loss: 0.005028  [ 2400/ 3520]
loss: 0.009022  [ 2500/ 3520]
loss: 0.009638  [ 2600/ 3520]
loss: 0.003167  [ 2700/ 3520]
loss: 0.014568  [ 2800/ 3520]
loss: 0.003447  [ 2900/ 3520]
loss: 0.011023  [ 3000/ 3520]
loss: 0.022442  [ 3100/ 3520]
loss: 0.005739  [ 3200/ 3520]
loss: 0.004148  [ 3300/ 3520]
loss: 0.008411  [ 3400/ 3520]
loss: 0.009389  [ 3500/ 3520]
Epoch 5
-------------------------------
loss: 0.009782  [    0/ 3520]
loss: 0.003523  [  100/ 3520]
loss: 0.104026  [  200/ 3520]
loss: 0.004594  [  300/ 3520]
loss: 0.097887  [  400/ 3520]
loss: 0.114516  [  500/ 3520]
loss: 0.005788  [  600/ 3520]
loss: 0.006465  [  700/ 3520]
loss: 0.005627  [  800/ 3520]
loss: 0.002023  [  900/ 3520]
loss: 0.003451  [ 1000/ 3520]
loss: 0.008888  [ 1100/ 3520]
loss: 0.009835  [ 1200/ 3520]
loss: 0.007222  [ 1300/ 3520]
loss: 0.008610  [ 1400/ 3520]
loss: 0.002524  [ 1500/ 3520]
loss: 0.003593  [ 1600/ 3520]
loss: 0.003690  [ 1700/ 3520]
loss: 0.099266  [ 1800/ 3520]
loss: 0.007483  [ 1900/ 3520]
loss: 0.010269  [ 2000/ 3520]
loss: 0.007083  [ 2100/ 3520]
loss: 0.005538  [ 2200/ 3520]
loss: 0.061441  [ 2300/ 3520]
loss: 0.005437  [ 2400/ 3520]
loss: 0.009033  [ 2500/ 3520]
loss: 0.009615  [ 2600/ 3520]
loss: 0.003110  [ 2700/ 3520]
loss: 0.014982  [ 2800/ 3520]
loss: 0.003055  [ 2900/ 3520]
loss: 0.011127  [ 3000/ 3520]
loss: 0.022066  [ 3100/ 3520]
loss: 0.005980  [ 3200/ 3520]
loss: 0.003860  [ 3300/ 3520]
loss: 0.008468  [ 3400/ 3520]
loss: 0.009621  [ 3500/ 3520]
Epoch 6
-------------------------------
loss: 0.010522  [    0/ 3520]
loss: 0.003096  [  100/ 3520]
loss: 0.092421  [  200/ 3520]
loss: 0.004442  [  300/ 3520]
loss: 0.094361  [  400/ 3520]
loss: 0.107965  [  500/ 3520]
loss: 0.005109  [  600/ 3520]
loss: 0.006328  [  700/ 3520]
loss: 0.005963  [  800/ 3520]
loss: 0.002112  [  900/ 3520]
loss: 0.003546  [ 1000/ 3520]
loss: 0.008971  [ 1100/ 3520]
loss: 0.010175  [ 1200/ 3520]
loss: 0.007007  [ 1300/ 3520]
loss: 0.007730  [ 1400/ 3520]
loss: 0.001743  [ 1500/ 3520]
loss: 0.003668  [ 1600/ 3520]
loss: 0.003732  [ 1700/ 3520]
loss: 0.100565  [ 1800/ 3520]
loss: 0.007567  [ 1900/ 3520]
loss: 0.010248  [ 2000/ 3520]
loss: 0.007126  [ 2100/ 3520]
loss: 0.005341  [ 2200/ 3520]
loss: 0.057721  [ 2300/ 3520]
loss: 0.005058  [ 2400/ 3520]
loss: 0.008987  [ 2500/ 3520]
loss: 0.010502  [ 2600/ 3520]
loss: 0.002942  [ 2700/ 3520]
loss: 0.014378  [ 2800/ 3520]
loss: 0.003119  [ 2900/ 3520]
loss: 0.011178  [ 3000/ 3520]
loss: 0.021451  [ 3100/ 3520]
loss: 0.006254  [ 3200/ 3520]
loss: 0.003587  [ 3300/ 3520]
loss: 0.009075  [ 3400/ 3520]
loss: 0.009825  [ 3500/ 3520]
Epoch 7
-------------------------------
loss: 0.010999  [    0/ 3520]
loss: 0.003025  [  100/ 3520]
loss: 0.085139  [  200/ 3520]
loss: 0.004783  [  300/ 3520]
loss: 0.090151  [  400/ 3520]
loss: 0.103901  [  500/ 3520]
loss: 0.004960  [  600/ 3520]
loss: 0.006094  [  700/ 3520]
loss: 0.006009  [  800/ 3520]
loss: 0.002338  [  900/ 3520]
loss: 0.003624  [ 1000/ 3520]
loss: 0.008512  [ 1100/ 3520]
loss: 0.010262  [ 1200/ 3520]
loss: 0.007340  [ 1300/ 3520]
loss: 0.007574  [ 1400/ 3520]
loss: 0.001833  [ 1500/ 3520]
loss: 0.003800  [ 1600/ 3520]
loss: 0.003719  [ 1700/ 3520]
loss: 0.098808  [ 1800/ 3520]
loss: 0.007394  [ 1900/ 3520]
loss: 0.010685  [ 2000/ 3520]
loss: 0.007092  [ 2100/ 3520]
loss: 0.005282  [ 2200/ 3520]
loss: 0.054289  [ 2300/ 3520]
loss: 0.004958  [ 2400/ 3520]
loss: 0.008916  [ 2500/ 3520]
loss: 0.010228  [ 2600/ 3520]
loss: 0.002928  [ 2700/ 3520]
loss: 0.014259  [ 2800/ 3520]
loss: 0.003208  [ 2900/ 3520]
loss: 0.010896  [ 3000/ 3520]
loss: 0.020378  [ 3100/ 3520]
loss: 0.006176  [ 3200/ 3520]
loss: 0.003118  [ 3300/ 3520]
loss: 0.009705  [ 3400/ 3520]
loss: 0.009966  [ 3500/ 3520]
Epoch 8
-------------------------------
loss: 0.011363  [    0/ 3520]
loss: 0.003001  [  100/ 3520]
loss: 0.085689  [  200/ 3520]
loss: 0.005131  [  300/ 3520]
loss: 0.092412  [  400/ 3520]
loss: 0.092402  [  500/ 3520]
loss: 0.004751  [  600/ 3520]
loss: 0.005997  [  700/ 3520]
loss: 0.006115  [  800/ 3520]
loss: 0.002291  [  900/ 3520]
loss: 0.003669  [ 1000/ 3520]
loss: 0.008120  [ 1100/ 3520]
loss: 0.010924  [ 1200/ 3520]
loss: 0.007820  [ 1300/ 3520]
loss: 0.007487  [ 1400/ 3520]
loss: 0.001793  [ 1500/ 3520]
loss: 0.003778  [ 1600/ 3520]
loss: 0.003704  [ 1700/ 3520]
loss: 0.098375  [ 1800/ 3520]
loss: 0.007335  [ 1900/ 3520]
loss: 0.009294  [ 2000/ 3520]
loss: 0.006984  [ 2100/ 3520]
loss: 0.005274  [ 2200/ 3520]
loss: 0.052314  [ 2300/ 3520]
loss: 0.005079  [ 2400/ 3520]
loss: 0.008207  [ 2500/ 3520]
loss: 0.010103  [ 2600/ 3520]
loss: 0.003003  [ 2700/ 3520]
loss: 0.014219  [ 2800/ 3520]
loss: 0.003081  [ 2900/ 3520]
loss: 0.010230  [ 3000/ 3520]
loss: 0.018980  [ 3100/ 3520]
loss: 0.006017  [ 3200/ 3520]
loss: 0.003187  [ 3300/ 3520]
loss: 0.009904  [ 3400/ 3520]
loss: 0.009898  [ 3500/ 3520]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3520
First Spike after testing: [0.45479137 1.4465498 ]
[0 1 2 ... 0 1 2]
[2 1 0 ... 2 1 0]
Cluster 0 Occurrences: 1160; KMEANS: 1213
Cluster 1 Occurrences: 1146; KMEANS: 1089
Cluster 2 Occurrences: 1214; KMEANS: 1218
Centroids: [[0.03355588, 1.6445117], [0.46531147, 0.74052536], [-0.5189797, -0.73141557]]
Centroids: [[-0.5236779, -0.73234844], [0.5748014, 0.7038421], [-0.03990738, 1.6339834]]
Contingency Matrix: 
[[   0   39 1121]
 [   3 1047   96]
 [1210    3    1]]
[[-1, 39, 1121], [-1, 1047, 96], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1047, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1121   39    0]
 [  96 1047    3]
 [   1    3 1210]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1121, 1047, 1210], Sum: 3378
All_Elements: [1121, 39, 0, 96, 1047, 3, 1, 3, 1210], Sum: 3520
Accuracy: 0.959659090909091
Done!
