Experiment_path: Random_Seeds//V2/Experiment_02_2
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_2/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_56_31
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001FA807D8FD0>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x000001FA03BDD198>
Epoch 1
-------------------------------
loss: 0.185120  [    0/ 3383]
loss: 0.030997  [  100/ 3383]
loss: 0.014936  [  200/ 3383]
loss: 0.008155  [  300/ 3383]
loss: 0.003603  [  400/ 3383]
loss: 0.008123  [  500/ 3383]
loss: 0.006160  [  600/ 3383]
loss: 0.011148  [  700/ 3383]
loss: 0.007739  [  800/ 3383]
loss: 0.003145  [  900/ 3383]
loss: 0.091831  [ 1000/ 3383]
loss: 0.057668  [ 1100/ 3383]
loss: 0.025090  [ 1200/ 3383]
loss: 0.008703  [ 1300/ 3383]
loss: 0.003434  [ 1400/ 3383]
loss: 0.015820  [ 1500/ 3383]
loss: 0.002345  [ 1600/ 3383]
loss: 0.001823  [ 1700/ 3383]
loss: 0.012485  [ 1800/ 3383]
loss: 0.015214  [ 1900/ 3383]
loss: 0.002403  [ 2000/ 3383]
loss: 0.003705  [ 2100/ 3383]
loss: 0.008792  [ 2200/ 3383]
loss: 0.001502  [ 2300/ 3383]
loss: 0.004333  [ 2400/ 3383]
loss: 0.028967  [ 2500/ 3383]
loss: 0.002165  [ 2600/ 3383]
loss: 0.003659  [ 2700/ 3383]
loss: 0.006428  [ 2800/ 3383]
loss: 0.005299  [ 2900/ 3383]
loss: 0.004228  [ 3000/ 3383]
loss: 0.004712  [ 3100/ 3383]
loss: 0.064566  [ 3200/ 3383]
loss: 0.002256  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.004202  [    0/ 3383]
loss: 0.005978  [  100/ 3383]
loss: 0.006004  [  200/ 3383]
loss: 0.002299  [  300/ 3383]
loss: 0.003085  [  400/ 3383]
loss: 0.004872  [  500/ 3383]
loss: 0.001060  [  600/ 3383]
loss: 0.002062  [  700/ 3383]
loss: 0.007508  [  800/ 3383]
loss: 0.001554  [  900/ 3383]
loss: 0.090215  [ 1000/ 3383]
loss: 0.057842  [ 1100/ 3383]
loss: 0.023215  [ 1200/ 3383]
loss: 0.009292  [ 1300/ 3383]
loss: 0.004142  [ 1400/ 3383]
loss: 0.014969  [ 1500/ 3383]
loss: 0.002635  [ 1600/ 3383]
loss: 0.001565  [ 1700/ 3383]
loss: 0.012290  [ 1800/ 3383]
loss: 0.014252  [ 1900/ 3383]
loss: 0.003027  [ 2000/ 3383]
loss: 0.003415  [ 2100/ 3383]
loss: 0.008791  [ 2200/ 3383]
loss: 0.001393  [ 2300/ 3383]
loss: 0.004317  [ 2400/ 3383]
loss: 0.027144  [ 2500/ 3383]
loss: 0.001651  [ 2600/ 3383]
loss: 0.003656  [ 2700/ 3383]
loss: 0.006488  [ 2800/ 3383]
loss: 0.005532  [ 2900/ 3383]
loss: 0.003958  [ 3000/ 3383]
loss: 0.004512  [ 3100/ 3383]
loss: 0.064430  [ 3200/ 3383]
loss: 0.002427  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.004058  [    0/ 3383]
loss: 0.005967  [  100/ 3383]
loss: 0.005891  [  200/ 3383]
loss: 0.002276  [  300/ 3383]
loss: 0.003076  [  400/ 3383]
loss: 0.004882  [  500/ 3383]
loss: 0.001080  [  600/ 3383]
loss: 0.002378  [  700/ 3383]
loss: 0.007415  [  800/ 3383]
loss: 0.001458  [  900/ 3383]
loss: 0.091033  [ 1000/ 3383]
loss: 0.057710  [ 1100/ 3383]
loss: 0.023138  [ 1200/ 3383]
loss: 0.009394  [ 1300/ 3383]
loss: 0.004103  [ 1400/ 3383]
loss: 0.014922  [ 1500/ 3383]
loss: 0.002558  [ 1600/ 3383]
loss: 0.001516  [ 1700/ 3383]
loss: 0.011655  [ 1800/ 3383]
loss: 0.013987  [ 1900/ 3383]
loss: 0.002852  [ 2000/ 3383]
loss: 0.003383  [ 2100/ 3383]
loss: 0.008825  [ 2200/ 3383]
loss: 0.001491  [ 2300/ 3383]
loss: 0.003735  [ 2400/ 3383]
loss: 0.026860  [ 2500/ 3383]
loss: 0.001561  [ 2600/ 3383]
loss: 0.002775  [ 2700/ 3383]
loss: 0.006455  [ 2800/ 3383]
loss: 0.005571  [ 2900/ 3383]
loss: 0.004763  [ 3000/ 3383]
loss: 0.004559  [ 3100/ 3383]
loss: 0.064271  [ 3200/ 3383]
loss: 0.002231  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.004120  [    0/ 3383]
loss: 0.005826  [  100/ 3383]
loss: 0.005910  [  200/ 3383]
loss: 0.002496  [  300/ 3383]
loss: 0.002949  [  400/ 3383]
loss: 0.004821  [  500/ 3383]
loss: 0.001227  [  600/ 3383]
loss: 0.002362  [  700/ 3383]
loss: 0.006619  [  800/ 3383]
loss: 0.001842  [  900/ 3383]
loss: 0.093546  [ 1000/ 3383]
loss: 0.057224  [ 1100/ 3383]
loss: 0.023880  [ 1200/ 3383]
loss: 0.009331  [ 1300/ 3383]
loss: 0.003821  [ 1400/ 3383]
loss: 0.014702  [ 1500/ 3383]
loss: 0.002447  [ 1600/ 3383]
loss: 0.001500  [ 1700/ 3383]
loss: 0.010464  [ 1800/ 3383]
loss: 0.013862  [ 1900/ 3383]
loss: 0.002839  [ 2000/ 3383]
loss: 0.003249  [ 2100/ 3383]
loss: 0.009055  [ 2200/ 3383]
loss: 0.001596  [ 2300/ 3383]
loss: 0.003463  [ 2400/ 3383]
loss: 0.026202  [ 2500/ 3383]
loss: 0.001434  [ 2600/ 3383]
loss: 0.002394  [ 2700/ 3383]
loss: 0.006304  [ 2800/ 3383]
loss: 0.005460  [ 2900/ 3383]
loss: 0.005410  [ 3000/ 3383]
loss: 0.004406  [ 3100/ 3383]
loss: 0.065070  [ 3200/ 3383]
loss: 0.002119  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.004108  [    0/ 3383]
loss: 0.005972  [  100/ 3383]
loss: 0.005957  [  200/ 3383]
loss: 0.002481  [  300/ 3383]
loss: 0.002617  [  400/ 3383]
loss: 0.004817  [  500/ 3383]
loss: 0.001191  [  600/ 3383]
loss: 0.002251  [  700/ 3383]
loss: 0.006075  [  800/ 3383]
loss: 0.002125  [  900/ 3383]
loss: 0.095634  [ 1000/ 3383]
loss: 0.057201  [ 1100/ 3383]
loss: 0.024713  [ 1200/ 3383]
loss: 0.009270  [ 1300/ 3383]
loss: 0.003846  [ 1400/ 3383]
loss: 0.014429  [ 1500/ 3383]
loss: 0.002360  [ 1600/ 3383]
loss: 0.001507  [ 1700/ 3383]
loss: 0.009329  [ 1800/ 3383]
loss: 0.013915  [ 1900/ 3383]
loss: 0.002668  [ 2000/ 3383]
loss: 0.003120  [ 2100/ 3383]
loss: 0.009046  [ 2200/ 3383]
loss: 0.001575  [ 2300/ 3383]
loss: 0.003231  [ 2400/ 3383]
loss: 0.026903  [ 2500/ 3383]
loss: 0.001478  [ 2600/ 3383]
loss: 0.002253  [ 2700/ 3383]
loss: 0.006152  [ 2800/ 3383]
loss: 0.005454  [ 2900/ 3383]
loss: 0.005837  [ 3000/ 3383]
loss: 0.004267  [ 3100/ 3383]
loss: 0.064932  [ 3200/ 3383]
loss: 0.002143  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.004026  [    0/ 3383]
loss: 0.006022  [  100/ 3383]
loss: 0.005803  [  200/ 3383]
loss: 0.002136  [  300/ 3383]
loss: 0.002442  [  400/ 3383]
loss: 0.004767  [  500/ 3383]
loss: 0.001192  [  600/ 3383]
loss: 0.002097  [  700/ 3383]
loss: 0.005540  [  800/ 3383]
loss: 0.001798  [  900/ 3383]
loss: 0.097315  [ 1000/ 3383]
loss: 0.057129  [ 1100/ 3383]
loss: 0.024583  [ 1200/ 3383]
loss: 0.009113  [ 1300/ 3383]
loss: 0.003647  [ 1400/ 3383]
loss: 0.014886  [ 1500/ 3383]
loss: 0.002160  [ 1600/ 3383]
loss: 0.001453  [ 1700/ 3383]
loss: 0.008340  [ 1800/ 3383]
loss: 0.013996  [ 1900/ 3383]
loss: 0.002501  [ 2000/ 3383]
loss: 0.002980  [ 2100/ 3383]
loss: 0.009042  [ 2200/ 3383]
loss: 0.001658  [ 2300/ 3383]
loss: 0.003139  [ 2400/ 3383]
loss: 0.026627  [ 2500/ 3383]
loss: 0.001296  [ 2600/ 3383]
loss: 0.001956  [ 2700/ 3383]
loss: 0.005909  [ 2800/ 3383]
loss: 0.005654  [ 2900/ 3383]
loss: 0.005867  [ 3000/ 3383]
loss: 0.004019  [ 3100/ 3383]
loss: 0.062729  [ 3200/ 3383]
loss: 0.002076  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.004321  [    0/ 3383]
loss: 0.006168  [  100/ 3383]
loss: 0.005591  [  200/ 3383]
loss: 0.002028  [  300/ 3383]
loss: 0.002357  [  400/ 3383]
loss: 0.004657  [  500/ 3383]
loss: 0.001256  [  600/ 3383]
loss: 0.001771  [  700/ 3383]
loss: 0.004953  [  800/ 3383]
loss: 0.001790  [  900/ 3383]
loss: 0.096852  [ 1000/ 3383]
loss: 0.057302  [ 1100/ 3383]
loss: 0.024695  [ 1200/ 3383]
loss: 0.008939  [ 1300/ 3383]
loss: 0.002857  [ 1400/ 3383]
loss: 0.014371  [ 1500/ 3383]
loss: 0.001950  [ 1600/ 3383]
loss: 0.001382  [ 1700/ 3383]
loss: 0.007284  [ 1800/ 3383]
loss: 0.014142  [ 1900/ 3383]
loss: 0.002386  [ 2000/ 3383]
loss: 0.003005  [ 2100/ 3383]
loss: 0.009109  [ 2200/ 3383]
loss: 0.001732  [ 2300/ 3383]
loss: 0.003116  [ 2400/ 3383]
loss: 0.028273  [ 2500/ 3383]
loss: 0.001194  [ 2600/ 3383]
loss: 0.002170  [ 2700/ 3383]
loss: 0.005784  [ 2800/ 3383]
loss: 0.005627  [ 2900/ 3383]
loss: 0.004882  [ 3000/ 3383]
loss: 0.003740  [ 3100/ 3383]
loss: 0.058982  [ 3200/ 3383]
loss: 0.002040  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.005125  [    0/ 3383]
loss: 0.006505  [  100/ 3383]
loss: 0.005458  [  200/ 3383]
loss: 0.001970  [  300/ 3383]
loss: 0.002317  [  400/ 3383]
loss: 0.004504  [  500/ 3383]
loss: 0.001249  [  600/ 3383]
loss: 0.001610  [  700/ 3383]
loss: 0.004162  [  800/ 3383]
loss: 0.001871  [  900/ 3383]
loss: 0.097091  [ 1000/ 3383]
loss: 0.057699  [ 1100/ 3383]
loss: 0.024501  [ 1200/ 3383]
loss: 0.008891  [ 1300/ 3383]
loss: 0.002196  [ 1400/ 3383]
loss: 0.013989  [ 1500/ 3383]
loss: 0.001672  [ 1600/ 3383]
loss: 0.001388  [ 1700/ 3383]
loss: 0.006461  [ 1800/ 3383]
loss: 0.014259  [ 1900/ 3383]
loss: 0.002260  [ 2000/ 3383]
loss: 0.003121  [ 2100/ 3383]
loss: 0.008989  [ 2200/ 3383]
loss: 0.001638  [ 2300/ 3383]
loss: 0.003264  [ 2400/ 3383]
loss: 0.028191  [ 2500/ 3383]
loss: 0.001068  [ 2600/ 3383]
loss: 0.002068  [ 2700/ 3383]
loss: 0.005619  [ 2800/ 3383]
loss: 0.005310  [ 2900/ 3383]
loss: 0.004253  [ 3000/ 3383]
loss: 0.003644  [ 3100/ 3383]
loss: 0.056229  [ 3200/ 3383]
loss: 0.002439  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [-1.0224609  0.3141045]
[2 1 2 ... 0 1 2]
[2 0 2 ... 1 0 2]
Cluster 0 Occurrences: 1115; KMEANS: 1093
Cluster 1 Occurrences: 1113; KMEANS: 1063
Cluster 2 Occurrences: 1155; KMEANS: 1227
Centroids: [[-0.39915043, 0.70419264], [-0.31440404, 0.0450853], [-1.0553273, 0.21796514]]
Centroids: [[-0.28433532, 0.0315305], [-0.37142742, 0.72008884], [-1.0662442, 0.23405634]]
Contingency Matrix: 
[[  15 1060   40]
 [1069    3   41]
 [   9    0 1146]]
[[15, 1060, -1], [1069, 3, -1], [-1, -1, -1]]
[[-1, 1060, -1], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 1: 0, 0: 1}
New Contingency Matrix: 
[[1060   15   40]
 [   3 1069   41]
 [   0    9 1146]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [1060, 1069, 1146], Sum: 3275
All_Elements: [1060, 15, 40, 3, 1069, 41, 0, 9, 1146], Sum: 3383
Accuracy: 0.9680756724800473
Done!
