Experiment_path: Random_Seeds//V2/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02/C_Difficult1_noise020.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_02_15
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002DBFEF18D68>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
<torch.utils.data.dataloader.DataLoader object at 0x000002DBE3E659B0>
Epoch 1
-------------------------------
loss: 0.191145  [    0/ 3414]
loss: 0.072759  [  100/ 3414]
loss: 0.018834  [  200/ 3414]
loss: 0.045917  [  300/ 3414]
loss: 0.034574  [  400/ 3414]
loss: 0.068111  [  500/ 3414]
loss: 0.037131  [  600/ 3414]
loss: 0.026685  [  700/ 3414]
loss: 0.074666  [  800/ 3414]
loss: 0.039164  [  900/ 3414]
loss: 0.024069  [ 1000/ 3414]
loss: 0.019478  [ 1100/ 3414]
loss: 0.016583  [ 1200/ 3414]
loss: 0.033773  [ 1300/ 3414]
loss: 0.018780  [ 1400/ 3414]
loss: 0.030400  [ 1500/ 3414]
loss: 0.012434  [ 1600/ 3414]
loss: 0.014381  [ 1700/ 3414]
loss: 0.031095  [ 1800/ 3414]
loss: 0.022260  [ 1900/ 3414]
loss: 0.036045  [ 2000/ 3414]
loss: 0.031082  [ 2100/ 3414]
loss: 0.040216  [ 2200/ 3414]
loss: 0.032720  [ 2300/ 3414]
loss: 0.009378  [ 2400/ 3414]
loss: 0.154969  [ 2500/ 3414]
loss: 0.027557  [ 2600/ 3414]
loss: 0.014374  [ 2700/ 3414]
loss: 0.010517  [ 2800/ 3414]
loss: 0.035320  [ 2900/ 3414]
loss: 0.044742  [ 3000/ 3414]
loss: 0.032330  [ 3100/ 3414]
loss: 0.021758  [ 3200/ 3414]
loss: 0.012790  [ 3300/ 3414]
loss: 0.025242  [ 3400/ 3414]
Epoch 2
-------------------------------
loss: 0.045826  [    0/ 3414]
loss: 0.029093  [  100/ 3414]
loss: 0.008525  [  200/ 3414]
loss: 0.050327  [  300/ 3414]
loss: 0.014768  [  400/ 3414]
loss: 0.045410  [  500/ 3414]
loss: 0.029464  [  600/ 3414]
loss: 0.031730  [  700/ 3414]
loss: 0.053177  [  800/ 3414]
loss: 0.019383  [  900/ 3414]
loss: 0.015826  [ 1000/ 3414]
loss: 0.024041  [ 1100/ 3414]
loss: 0.006267  [ 1200/ 3414]
loss: 0.032534  [ 1300/ 3414]
loss: 0.017777  [ 1400/ 3414]
loss: 0.029114  [ 1500/ 3414]
loss: 0.011431  [ 1600/ 3414]
loss: 0.010782  [ 1700/ 3414]
loss: 0.031031  [ 1800/ 3414]
loss: 0.021049  [ 1900/ 3414]
loss: 0.034321  [ 2000/ 3414]
loss: 0.032916  [ 2100/ 3414]
loss: 0.040310  [ 2200/ 3414]
loss: 0.033496  [ 2300/ 3414]
loss: 0.008741  [ 2400/ 3414]
loss: 0.157364  [ 2500/ 3414]
loss: 0.026157  [ 2600/ 3414]
loss: 0.014467  [ 2700/ 3414]
loss: 0.012041  [ 2800/ 3414]
loss: 0.040652  [ 2900/ 3414]
loss: 0.046013  [ 3000/ 3414]
loss: 0.034520  [ 3100/ 3414]
loss: 0.021356  [ 3200/ 3414]
loss: 0.012748  [ 3300/ 3414]
loss: 0.025221  [ 3400/ 3414]
Epoch 3
-------------------------------
loss: 0.043942  [    0/ 3414]
loss: 0.029309  [  100/ 3414]
loss: 0.008496  [  200/ 3414]
loss: 0.049039  [  300/ 3414]
loss: 0.014126  [  400/ 3414]
loss: 0.044587  [  500/ 3414]
loss: 0.028489  [  600/ 3414]
loss: 0.034178  [  700/ 3414]
loss: 0.051538  [  800/ 3414]
loss: 0.020120  [  900/ 3414]
loss: 0.015818  [ 1000/ 3414]
loss: 0.023336  [ 1100/ 3414]
loss: 0.006448  [ 1200/ 3414]
loss: 0.032334  [ 1300/ 3414]
loss: 0.018015  [ 1400/ 3414]
loss: 0.028247  [ 1500/ 3414]
loss: 0.010743  [ 1600/ 3414]
loss: 0.010095  [ 1700/ 3414]
loss: 0.030534  [ 1800/ 3414]
loss: 0.021128  [ 1900/ 3414]
loss: 0.033511  [ 2000/ 3414]
loss: 0.033302  [ 2100/ 3414]
loss: 0.040203  [ 2200/ 3414]
loss: 0.034806  [ 2300/ 3414]
loss: 0.008664  [ 2400/ 3414]
loss: 0.158036  [ 2500/ 3414]
loss: 0.025517  [ 2600/ 3414]
loss: 0.013991  [ 2700/ 3414]
loss: 0.012527  [ 2800/ 3414]
loss: 0.041952  [ 2900/ 3414]
loss: 0.046172  [ 3000/ 3414]
loss: 0.035052  [ 3100/ 3414]
loss: 0.021292  [ 3200/ 3414]
loss: 0.012566  [ 3300/ 3414]
loss: 0.024815  [ 3400/ 3414]
Epoch 4
-------------------------------
loss: 0.039136  [    0/ 3414]
loss: 0.029478  [  100/ 3414]
loss: 0.008574  [  200/ 3414]
loss: 0.048574  [  300/ 3414]
loss: 0.014001  [  400/ 3414]
loss: 0.044118  [  500/ 3414]
loss: 0.028432  [  600/ 3414]
loss: 0.034924  [  700/ 3414]
loss: 0.051032  [  800/ 3414]
loss: 0.020857  [  900/ 3414]
loss: 0.015754  [ 1000/ 3414]
loss: 0.022400  [ 1100/ 3414]
loss: 0.006783  [ 1200/ 3414]
loss: 0.032471  [ 1300/ 3414]
loss: 0.018296  [ 1400/ 3414]
loss: 0.027372  [ 1500/ 3414]
loss: 0.010182  [ 1600/ 3414]
loss: 0.009600  [ 1700/ 3414]
loss: 0.029989  [ 1800/ 3414]
loss: 0.021228  [ 1900/ 3414]
loss: 0.033025  [ 2000/ 3414]
loss: 0.033193  [ 2100/ 3414]
loss: 0.040268  [ 2200/ 3414]
loss: 0.036071  [ 2300/ 3414]
loss: 0.008483  [ 2400/ 3414]
loss: 0.157747  [ 2500/ 3414]
loss: 0.024109  [ 2600/ 3414]
loss: 0.014058  [ 2700/ 3414]
loss: 0.013001  [ 2800/ 3414]
loss: 0.043099  [ 2900/ 3414]
loss: 0.045794  [ 3000/ 3414]
loss: 0.035792  [ 3100/ 3414]
loss: 0.020155  [ 3200/ 3414]
loss: 0.012458  [ 3300/ 3414]
loss: 0.024847  [ 3400/ 3414]
Epoch 5
-------------------------------
loss: 0.027010  [    0/ 3414]
loss: 0.029624  [  100/ 3414]
loss: 0.008513  [  200/ 3414]
loss: 0.048025  [  300/ 3414]
loss: 0.014289  [  400/ 3414]
loss: 0.043913  [  500/ 3414]
loss: 0.028088  [  600/ 3414]
loss: 0.036010  [  700/ 3414]
loss: 0.050772  [  800/ 3414]
loss: 0.021847  [  900/ 3414]
loss: 0.015482  [ 1000/ 3414]
loss: 0.021450  [ 1100/ 3414]
loss: 0.007295  [ 1200/ 3414]
loss: 0.032472  [ 1300/ 3414]
loss: 0.018588  [ 1400/ 3414]
loss: 0.026969  [ 1500/ 3414]
loss: 0.010090  [ 1600/ 3414]
loss: 0.008990  [ 1700/ 3414]
loss: 0.029746  [ 1800/ 3414]
loss: 0.021371  [ 1900/ 3414]
loss: 0.032463  [ 2000/ 3414]
loss: 0.033504  [ 2100/ 3414]
loss: 0.040822  [ 2200/ 3414]
loss: 0.037183  [ 2300/ 3414]
loss: 0.008436  [ 2400/ 3414]
loss: 0.156279  [ 2500/ 3414]
loss: 0.021585  [ 2600/ 3414]
loss: 0.013933  [ 2700/ 3414]
loss: 0.013975  [ 2800/ 3414]
loss: 0.043554  [ 2900/ 3414]
loss: 0.045276  [ 3000/ 3414]
loss: 0.039273  [ 3100/ 3414]
loss: 0.021086  [ 3200/ 3414]
loss: 0.012688  [ 3300/ 3414]
loss: 0.024820  [ 3400/ 3414]
Epoch 6
-------------------------------
loss: 0.018627  [    0/ 3414]
loss: 0.029502  [  100/ 3414]
loss: 0.008737  [  200/ 3414]
loss: 0.048425  [  300/ 3414]
loss: 0.014616  [  400/ 3414]
loss: 0.043058  [  500/ 3414]
loss: 0.027440  [  600/ 3414]
loss: 0.037215  [  700/ 3414]
loss: 0.049955  [  800/ 3414]
loss: 0.023120  [  900/ 3414]
loss: 0.015142  [ 1000/ 3414]
loss: 0.020597  [ 1100/ 3414]
loss: 0.007595  [ 1200/ 3414]
loss: 0.032406  [ 1300/ 3414]
loss: 0.018741  [ 1400/ 3414]
loss: 0.026744  [ 1500/ 3414]
loss: 0.010143  [ 1600/ 3414]
loss: 0.008449  [ 1700/ 3414]
loss: 0.029523  [ 1800/ 3414]
loss: 0.021378  [ 1900/ 3414]
loss: 0.031420  [ 2000/ 3414]
loss: 0.034228  [ 2100/ 3414]
loss: 0.041605  [ 2200/ 3414]
loss: 0.039117  [ 2300/ 3414]
loss: 0.008401  [ 2400/ 3414]
loss: 0.153846  [ 2500/ 3414]
loss: 0.018684  [ 2600/ 3414]
loss: 0.013891  [ 2700/ 3414]
loss: 0.015912  [ 2800/ 3414]
loss: 0.044329  [ 2900/ 3414]
loss: 0.046072  [ 3000/ 3414]
loss: 0.040829  [ 3100/ 3414]
loss: 0.021283  [ 3200/ 3414]
loss: 0.012883  [ 3300/ 3414]
loss: 0.025107  [ 3400/ 3414]
Epoch 7
-------------------------------
loss: 0.017946  [    0/ 3414]
loss: 0.029462  [  100/ 3414]
loss: 0.009012  [  200/ 3414]
loss: 0.048198  [  300/ 3414]
loss: 0.015288  [  400/ 3414]
loss: 0.042205  [  500/ 3414]
loss: 0.026226  [  600/ 3414]
loss: 0.038691  [  700/ 3414]
loss: 0.049453  [  800/ 3414]
loss: 0.023973  [  900/ 3414]
loss: 0.014881  [ 1000/ 3414]
loss: 0.020127  [ 1100/ 3414]
loss: 0.007684  [ 1200/ 3414]
loss: 0.032007  [ 1300/ 3414]
loss: 0.018915  [ 1400/ 3414]
loss: 0.026350  [ 1500/ 3414]
loss: 0.009730  [ 1600/ 3414]
loss: 0.008731  [ 1700/ 3414]
loss: 0.029255  [ 1800/ 3414]
loss: 0.021243  [ 1900/ 3414]
loss: 0.031521  [ 2000/ 3414]
loss: 0.034280  [ 2100/ 3414]
loss: 0.043137  [ 2200/ 3414]
loss: 0.042253  [ 2300/ 3414]
loss: 0.008930  [ 2400/ 3414]
loss: 0.150308  [ 2500/ 3414]
loss: 0.016470  [ 2600/ 3414]
loss: 0.013598  [ 2700/ 3414]
loss: 0.017306  [ 2800/ 3414]
loss: 0.045150  [ 2900/ 3414]
loss: 0.045682  [ 3000/ 3414]
loss: 0.035770  [ 3100/ 3414]
loss: 0.021913  [ 3200/ 3414]
loss: 0.013301  [ 3300/ 3414]
loss: 0.025240  [ 3400/ 3414]
Epoch 8
-------------------------------
loss: 0.018792  [    0/ 3414]
loss: 0.029152  [  100/ 3414]
loss: 0.009155  [  200/ 3414]
loss: 0.048260  [  300/ 3414]
loss: 0.015820  [  400/ 3414]
loss: 0.041521  [  500/ 3414]
loss: 0.025547  [  600/ 3414]
loss: 0.039486  [  700/ 3414]
loss: 0.049360  [  800/ 3414]
loss: 0.024638  [  900/ 3414]
loss: 0.014615  [ 1000/ 3414]
loss: 0.019697  [ 1100/ 3414]
loss: 0.007897  [ 1200/ 3414]
loss: 0.031791  [ 1300/ 3414]
loss: 0.018997  [ 1400/ 3414]
loss: 0.026169  [ 1500/ 3414]
loss: 0.009427  [ 1600/ 3414]
loss: 0.009949  [ 1700/ 3414]
loss: 0.029008  [ 1800/ 3414]
loss: 0.021100  [ 1900/ 3414]
loss: 0.031797  [ 2000/ 3414]
loss: 0.034663  [ 2100/ 3414]
loss: 0.043532  [ 2200/ 3414]
loss: 0.043534  [ 2300/ 3414]
loss: 0.009440  [ 2400/ 3414]
loss: 0.147677  [ 2500/ 3414]
loss: 0.014942  [ 2600/ 3414]
loss: 0.013432  [ 2700/ 3414]
loss: 0.018710  [ 2800/ 3414]
loss: 0.045133  [ 2900/ 3414]
loss: 0.045436  [ 3000/ 3414]
loss: 0.034304  [ 3100/ 3414]
loss: 0.022268  [ 3200/ 3414]
loss: 0.013578  [ 3300/ 3414]
loss: 0.025347  [ 3400/ 3414]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3414
First Spike after testing: [-0.11032537 -0.8930275 ]
[1 1 0 ... 0 0 2]
[2 0 1 ... 2 2 1]
Cluster 0 Occurrences: 1136; KMEANS: 1129
Cluster 1 Occurrences: 1099; KMEANS: 978
Cluster 2 Occurrences: 1179; KMEANS: 1307
Centroids: [[0.22221787, 0.00020017338], [0.20626861, 0.17409319], [0.5517407, 0.26588127]]
Centroids: [[0.09189299, 0.39827088], [0.6721774, 0.2897761], [0.28193903, -0.17445984]]
Contingency Matrix: 
[[304 115 717]
 [576 154 369]
 [249 709 221]]
[[-1, -1, -1], [576, 154, -1], [249, 709, -1]]
[[-1, -1, -1], [576, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 2: 1, 1: 0}
New Contingency Matrix: 
[[717 304 115]
 [369 576 154]
 [221 249 709]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [717, 576, 709], Sum: 2002
All_Elements: [717, 304, 115, 369, 576, 154, 221, 249, 709], Sum: 3414
Accuracy: 0.5864089045108377
Done!
