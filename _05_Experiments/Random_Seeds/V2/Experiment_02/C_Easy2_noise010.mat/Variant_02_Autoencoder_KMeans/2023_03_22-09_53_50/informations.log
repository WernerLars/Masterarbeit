Experiment_path: Random_Seeds//V2/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02/C_Easy2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_53_50
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002DBEE06C128>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
<torch.utils.data.dataloader.DataLoader object at 0x000002DBE3E65710>
Epoch 1
-------------------------------
loss: 0.185553  [    0/ 3520]
loss: 0.074183  [  100/ 3520]
loss: 0.186407  [  200/ 3520]
loss: 0.016598  [  300/ 3520]
loss: 0.069319  [  400/ 3520]
loss: 0.130866  [  500/ 3520]
loss: 0.015050  [  600/ 3520]
loss: 0.009485  [  700/ 3520]
loss: 0.007256  [  800/ 3520]
loss: 0.018553  [  900/ 3520]
loss: 0.004506  [ 1000/ 3520]
loss: 0.023285  [ 1100/ 3520]
loss: 0.019412  [ 1200/ 3520]
loss: 0.031529  [ 1300/ 3520]
loss: 0.011215  [ 1400/ 3520]
loss: 0.004558  [ 1500/ 3520]
loss: 0.003872  [ 1600/ 3520]
loss: 0.002914  [ 1700/ 3520]
loss: 0.087157  [ 1800/ 3520]
loss: 0.007971  [ 1900/ 3520]
loss: 0.014584  [ 2000/ 3520]
loss: 0.006604  [ 2100/ 3520]
loss: 0.007427  [ 2200/ 3520]
loss: 0.051903  [ 2300/ 3520]
loss: 0.008235  [ 2400/ 3520]
loss: 0.008167  [ 2500/ 3520]
loss: 0.013278  [ 2600/ 3520]
loss: 0.002970  [ 2700/ 3520]
loss: 0.015073  [ 2800/ 3520]
loss: 0.005285  [ 2900/ 3520]
loss: 0.012532  [ 3000/ 3520]
loss: 0.007475  [ 3100/ 3520]
loss: 0.005220  [ 3200/ 3520]
loss: 0.003947  [ 3300/ 3520]
loss: 0.006151  [ 3400/ 3520]
loss: 0.012596  [ 3500/ 3520]
Epoch 2
-------------------------------
loss: 0.013699  [    0/ 3520]
loss: 0.004057  [  100/ 3520]
loss: 0.107507  [  200/ 3520]
loss: 0.004311  [  300/ 3520]
loss: 0.041145  [  400/ 3520]
loss: 0.062743  [  500/ 3520]
loss: 0.005221  [  600/ 3520]
loss: 0.008212  [  700/ 3520]
loss: 0.007226  [  800/ 3520]
loss: 0.003354  [  900/ 3520]
loss: 0.003374  [ 1000/ 3520]
loss: 0.008434  [ 1100/ 3520]
loss: 0.009006  [ 1200/ 3520]
loss: 0.009842  [ 1300/ 3520]
loss: 0.004049  [ 1400/ 3520]
loss: 0.001674  [ 1500/ 3520]
loss: 0.003017  [ 1600/ 3520]
loss: 0.004620  [ 1700/ 3520]
loss: 0.102373  [ 1800/ 3520]
loss: 0.006894  [ 1900/ 3520]
loss: 0.013840  [ 2000/ 3520]
loss: 0.007126  [ 2100/ 3520]
loss: 0.006191  [ 2200/ 3520]
loss: 0.051155  [ 2300/ 3520]
loss: 0.008314  [ 2400/ 3520]
loss: 0.009054  [ 2500/ 3520]
loss: 0.012023  [ 2600/ 3520]
loss: 0.003062  [ 2700/ 3520]
loss: 0.014726  [ 2800/ 3520]
loss: 0.004377  [ 2900/ 3520]
loss: 0.011733  [ 3000/ 3520]
loss: 0.002989  [ 3100/ 3520]
loss: 0.005442  [ 3200/ 3520]
loss: 0.003648  [ 3300/ 3520]
loss: 0.006629  [ 3400/ 3520]
loss: 0.012076  [ 3500/ 3520]
Epoch 3
-------------------------------
loss: 0.014118  [    0/ 3520]
loss: 0.003695  [  100/ 3520]
loss: 0.087282  [  200/ 3520]
loss: 0.003883  [  300/ 3520]
loss: 0.047021  [  400/ 3520]
loss: 0.056910  [  500/ 3520]
loss: 0.005035  [  600/ 3520]
loss: 0.008405  [  700/ 3520]
loss: 0.006984  [  800/ 3520]
loss: 0.002925  [  900/ 3520]
loss: 0.003552  [ 1000/ 3520]
loss: 0.008511  [ 1100/ 3520]
loss: 0.008407  [ 1200/ 3520]
loss: 0.009373  [ 1300/ 3520]
loss: 0.003793  [ 1400/ 3520]
loss: 0.001561  [ 1500/ 3520]
loss: 0.002756  [ 1600/ 3520]
loss: 0.004236  [ 1700/ 3520]
loss: 0.106264  [ 1800/ 3520]
loss: 0.006472  [ 1900/ 3520]
loss: 0.013664  [ 2000/ 3520]
loss: 0.007054  [ 2100/ 3520]
loss: 0.005802  [ 2200/ 3520]
loss: 0.055054  [ 2300/ 3520]
loss: 0.008936  [ 2400/ 3520]
loss: 0.009240  [ 2500/ 3520]
loss: 0.011691  [ 2600/ 3520]
loss: 0.003193  [ 2700/ 3520]
loss: 0.014738  [ 2800/ 3520]
loss: 0.004186  [ 2900/ 3520]
loss: 0.011361  [ 3000/ 3520]
loss: 0.002434  [ 3100/ 3520]
loss: 0.005440  [ 3200/ 3520]
loss: 0.003414  [ 3300/ 3520]
loss: 0.007092  [ 3400/ 3520]
loss: 0.012013  [ 3500/ 3520]
Epoch 4
-------------------------------
loss: 0.014247  [    0/ 3520]
loss: 0.003412  [  100/ 3520]
loss: 0.077709  [  200/ 3520]
loss: 0.003617  [  300/ 3520]
loss: 0.050274  [  400/ 3520]
loss: 0.058232  [  500/ 3520]
loss: 0.004859  [  600/ 3520]
loss: 0.008403  [  700/ 3520]
loss: 0.006814  [  800/ 3520]
loss: 0.002795  [  900/ 3520]
loss: 0.003644  [ 1000/ 3520]
loss: 0.008485  [ 1100/ 3520]
loss: 0.008274  [ 1200/ 3520]
loss: 0.008784  [ 1300/ 3520]
loss: 0.003837  [ 1400/ 3520]
loss: 0.001546  [ 1500/ 3520]
loss: 0.002640  [ 1600/ 3520]
loss: 0.004104  [ 1700/ 3520]
loss: 0.107927  [ 1800/ 3520]
loss: 0.006304  [ 1900/ 3520]
loss: 0.013484  [ 2000/ 3520]
loss: 0.006813  [ 2100/ 3520]
loss: 0.005775  [ 2200/ 3520]
loss: 0.056875  [ 2300/ 3520]
loss: 0.008781  [ 2400/ 3520]
loss: 0.009133  [ 2500/ 3520]
loss: 0.011827  [ 2600/ 3520]
loss: 0.003274  [ 2700/ 3520]
loss: 0.014356  [ 2800/ 3520]
loss: 0.003940  [ 2900/ 3520]
loss: 0.011201  [ 3000/ 3520]
loss: 0.002300  [ 3100/ 3520]
loss: 0.005525  [ 3200/ 3520]
loss: 0.003317  [ 3300/ 3520]
loss: 0.007187  [ 3400/ 3520]
loss: 0.011590  [ 3500/ 3520]
Epoch 5
-------------------------------
loss: 0.013458  [    0/ 3520]
loss: 0.003276  [  100/ 3520]
loss: 0.072038  [  200/ 3520]
loss: 0.003706  [  300/ 3520]
loss: 0.051242  [  400/ 3520]
loss: 0.058327  [  500/ 3520]
loss: 0.004891  [  600/ 3520]
loss: 0.008389  [  700/ 3520]
loss: 0.006549  [  800/ 3520]
loss: 0.002572  [  900/ 3520]
loss: 0.003772  [ 1000/ 3520]
loss: 0.008325  [ 1100/ 3520]
loss: 0.007996  [ 1200/ 3520]
loss: 0.005886  [ 1300/ 3520]
loss: 0.004069  [ 1400/ 3520]
loss: 0.001700  [ 1500/ 3520]
loss: 0.002135  [ 1600/ 3520]
loss: 0.003916  [ 1700/ 3520]
loss: 0.109388  [ 1800/ 3520]
loss: 0.006333  [ 1900/ 3520]
loss: 0.014781  [ 2000/ 3520]
loss: 0.006404  [ 2100/ 3520]
loss: 0.005251  [ 2200/ 3520]
loss: 0.056428  [ 2300/ 3520]
loss: 0.009353  [ 2400/ 3520]
loss: 0.009003  [ 2500/ 3520]
loss: 0.012110  [ 2600/ 3520]
loss: 0.003319  [ 2700/ 3520]
loss: 0.013552  [ 2800/ 3520]
loss: 0.003384  [ 2900/ 3520]
loss: 0.011084  [ 3000/ 3520]
loss: 0.002369  [ 3100/ 3520]
loss: 0.005607  [ 3200/ 3520]
loss: 0.002937  [ 3300/ 3520]
loss: 0.007993  [ 3400/ 3520]
loss: 0.009848  [ 3500/ 3520]
Epoch 6
-------------------------------
loss: 0.011944  [    0/ 3520]
loss: 0.002971  [  100/ 3520]
loss: 0.072963  [  200/ 3520]
loss: 0.004190  [  300/ 3520]
loss: 0.051560  [  400/ 3520]
loss: 0.058849  [  500/ 3520]
loss: 0.005105  [  600/ 3520]
loss: 0.008578  [  700/ 3520]
loss: 0.005927  [  800/ 3520]
loss: 0.002356  [  900/ 3520]
loss: 0.003897  [ 1000/ 3520]
loss: 0.008274  [ 1100/ 3520]
loss: 0.008496  [ 1200/ 3520]
loss: 0.002435  [ 1300/ 3520]
loss: 0.004653  [ 1400/ 3520]
loss: 0.001994  [ 1500/ 3520]
loss: 0.001975  [ 1600/ 3520]
loss: 0.003796  [ 1700/ 3520]
loss: 0.111184  [ 1800/ 3520]
loss: 0.006432  [ 1900/ 3520]
loss: 0.014865  [ 2000/ 3520]
loss: 0.005766  [ 2100/ 3520]
loss: 0.005045  [ 2200/ 3520]
loss: 0.055599  [ 2300/ 3520]
loss: 0.009385  [ 2400/ 3520]
loss: 0.009305  [ 2500/ 3520]
loss: 0.012291  [ 2600/ 3520]
loss: 0.003218  [ 2700/ 3520]
loss: 0.012883  [ 2800/ 3520]
loss: 0.002793  [ 2900/ 3520]
loss: 0.010401  [ 3000/ 3520]
loss: 0.003299  [ 3100/ 3520]
loss: 0.005646  [ 3200/ 3520]
loss: 0.002602  [ 3300/ 3520]
loss: 0.008463  [ 3400/ 3520]
loss: 0.008820  [ 3500/ 3520]
Epoch 7
-------------------------------
loss: 0.011740  [    0/ 3520]
loss: 0.002433  [  100/ 3520]
loss: 0.070635  [  200/ 3520]
loss: 0.004200  [  300/ 3520]
loss: 0.052351  [  400/ 3520]
loss: 0.060768  [  500/ 3520]
loss: 0.004682  [  600/ 3520]
loss: 0.008933  [  700/ 3520]
loss: 0.005653  [  800/ 3520]
loss: 0.002777  [  900/ 3520]
loss: 0.003799  [ 1000/ 3520]
loss: 0.008270  [ 1100/ 3520]
loss: 0.007970  [ 1200/ 3520]
loss: 0.002160  [ 1300/ 3520]
loss: 0.005020  [ 1400/ 3520]
loss: 0.003406  [ 1500/ 3520]
loss: 0.001982  [ 1600/ 3520]
loss: 0.003710  [ 1700/ 3520]
loss: 0.112305  [ 1800/ 3520]
loss: 0.006607  [ 1900/ 3520]
loss: 0.015524  [ 2000/ 3520]
loss: 0.005611  [ 2100/ 3520]
loss: 0.005421  [ 2200/ 3520]
loss: 0.056035  [ 2300/ 3520]
loss: 0.009222  [ 2400/ 3520]
loss: 0.009295  [ 2500/ 3520]
loss: 0.011338  [ 2600/ 3520]
loss: 0.003118  [ 2700/ 3520]
loss: 0.012763  [ 2800/ 3520]
loss: 0.003066  [ 2900/ 3520]
loss: 0.009523  [ 3000/ 3520]
loss: 0.005095  [ 3100/ 3520]
loss: 0.005612  [ 3200/ 3520]
loss: 0.002268  [ 3300/ 3520]
loss: 0.010570  [ 3400/ 3520]
loss: 0.008550  [ 3500/ 3520]
Epoch 8
-------------------------------
loss: 0.011671  [    0/ 3520]
loss: 0.002202  [  100/ 3520]
loss: 0.058442  [  200/ 3520]
loss: 0.004062  [  300/ 3520]
loss: 0.054561  [  400/ 3520]
loss: 0.066116  [  500/ 3520]
loss: 0.003874  [  600/ 3520]
loss: 0.008558  [  700/ 3520]
loss: 0.004993  [  800/ 3520]
loss: 0.002961  [  900/ 3520]
loss: 0.003800  [ 1000/ 3520]
loss: 0.008185  [ 1100/ 3520]
loss: 0.008275  [ 1200/ 3520]
loss: 0.003648  [ 1300/ 3520]
loss: 0.004871  [ 1400/ 3520]
loss: 0.003429  [ 1500/ 3520]
loss: 0.002108  [ 1600/ 3520]
loss: 0.003982  [ 1700/ 3520]
loss: 0.112197  [ 1800/ 3520]
loss: 0.006991  [ 1900/ 3520]
loss: 0.016020  [ 2000/ 3520]
loss: 0.005511  [ 2100/ 3520]
loss: 0.005583  [ 2200/ 3520]
loss: 0.057447  [ 2300/ 3520]
loss: 0.008449  [ 2400/ 3520]
loss: 0.009818  [ 2500/ 3520]
loss: 0.010804  [ 2600/ 3520]
loss: 0.003165  [ 2700/ 3520]
loss: 0.012814  [ 2800/ 3520]
loss: 0.003245  [ 2900/ 3520]
loss: 0.009597  [ 3000/ 3520]
loss: 0.006876  [ 3100/ 3520]
loss: 0.005717  [ 3200/ 3520]
loss: 0.001783  [ 3300/ 3520]
loss: 0.010863  [ 3400/ 3520]
loss: 0.008146  [ 3500/ 3520]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3520
First Spike after testing: [ 0.8306853 -0.5931082]
[0 1 2 ... 0 1 2]
[0 2 1 ... 0 2 1]
Cluster 0 Occurrences: 1160; KMEANS: 1211
Cluster 1 Occurrences: 1146; KMEANS: 1209
Cluster 2 Occurrences: 1214; KMEANS: 1100
Centroids: [[0.8248823, -0.79288286], [0.33585048, -0.3103964], [-0.4327424, 1.4789227]]
Centroids: [[0.8202596, -0.7979565], [-0.43677646, 1.4836675], [0.31920666, -0.27952272]]
Contingency Matrix: 
[[1158    0    2]
 [  52    0 1094]
 [   1 1209    4]]
[[1158, -1, 2], [52, -1, 1094], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1094], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 0, 1: 2}
New Contingency Matrix: 
[[1158    2    0]
 [  52 1094    0]
 [   1    4 1209]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [1158, 1094, 1209], Sum: 3461
All_Elements: [1158, 2, 0, 52, 1094, 0, 1, 4, 1209], Sum: 3520
Accuracy: 0.9832386363636364
Done!
