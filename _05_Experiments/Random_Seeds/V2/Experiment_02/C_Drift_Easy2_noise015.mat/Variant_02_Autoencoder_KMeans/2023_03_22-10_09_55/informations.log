Experiment_path: Random_Seeds//V2/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02/C_Drift_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_09_55
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002DC04628BE0>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
<torch.utils.data.dataloader.DataLoader object at 0x000002DC09AB5C50>
Epoch 1
-------------------------------
loss: 0.154733  [    0/ 3444]
loss: 0.075896  [  100/ 3444]
loss: 0.019867  [  200/ 3444]
loss: 0.018046  [  300/ 3444]
loss: 0.023605  [  400/ 3444]
loss: 0.027944  [  500/ 3444]
loss: 0.058341  [  600/ 3444]
loss: 0.025191  [  700/ 3444]
loss: 0.008081  [  800/ 3444]
loss: 0.025664  [  900/ 3444]
loss: 0.010257  [ 1000/ 3444]
loss: 0.015979  [ 1100/ 3444]
loss: 0.010103  [ 1200/ 3444]
loss: 0.036764  [ 1300/ 3444]
loss: 0.122329  [ 1400/ 3444]
loss: 0.006733  [ 1500/ 3444]
loss: 0.011515  [ 1600/ 3444]
loss: 0.010220  [ 1700/ 3444]
loss: 0.018781  [ 1800/ 3444]
loss: 0.009879  [ 1900/ 3444]
loss: 0.015144  [ 2000/ 3444]
loss: 0.020608  [ 2100/ 3444]
loss: 0.024995  [ 2200/ 3444]
loss: 0.014763  [ 2300/ 3444]
loss: 0.007162  [ 2400/ 3444]
loss: 0.006342  [ 2500/ 3444]
loss: 0.005009  [ 2600/ 3444]
loss: 0.004709  [ 2700/ 3444]
loss: 0.015483  [ 2800/ 3444]
loss: 0.010380  [ 2900/ 3444]
loss: 0.013303  [ 3000/ 3444]
loss: 0.100764  [ 3100/ 3444]
loss: 0.112007  [ 3200/ 3444]
loss: 0.009475  [ 3300/ 3444]
loss: 0.029528  [ 3400/ 3444]
Epoch 2
-------------------------------
loss: 0.016643  [    0/ 3444]
loss: 0.012306  [  100/ 3444]
loss: 0.006836  [  200/ 3444]
loss: 0.017633  [  300/ 3444]
loss: 0.012653  [  400/ 3444]
loss: 0.008931  [  500/ 3444]
loss: 0.042474  [  600/ 3444]
loss: 0.026805  [  700/ 3444]
loss: 0.006995  [  800/ 3444]
loss: 0.019190  [  900/ 3444]
loss: 0.009758  [ 1000/ 3444]
loss: 0.011054  [ 1100/ 3444]
loss: 0.003568  [ 1200/ 3444]
loss: 0.020129  [ 1300/ 3444]
loss: 0.111421  [ 1400/ 3444]
loss: 0.007752  [ 1500/ 3444]
loss: 0.011175  [ 1600/ 3444]
loss: 0.007660  [ 1700/ 3444]
loss: 0.017436  [ 1800/ 3444]
loss: 0.008354  [ 1900/ 3444]
loss: 0.013619  [ 2000/ 3444]
loss: 0.016427  [ 2100/ 3444]
loss: 0.019427  [ 2200/ 3444]
loss: 0.011630  [ 2300/ 3444]
loss: 0.006696  [ 2400/ 3444]
loss: 0.004769  [ 2500/ 3444]
loss: 0.005438  [ 2600/ 3444]
loss: 0.005749  [ 2700/ 3444]
loss: 0.015894  [ 2800/ 3444]
loss: 0.010451  [ 2900/ 3444]
loss: 0.010639  [ 3000/ 3444]
loss: 0.060395  [ 3100/ 3444]
loss: 0.106246  [ 3200/ 3444]
loss: 0.007481  [ 3300/ 3444]
loss: 0.026237  [ 3400/ 3444]
Epoch 3
-------------------------------
loss: 0.015783  [    0/ 3444]
loss: 0.010793  [  100/ 3444]
loss: 0.005540  [  200/ 3444]
loss: 0.016963  [  300/ 3444]
loss: 0.010541  [  400/ 3444]
loss: 0.008647  [  500/ 3444]
loss: 0.036214  [  600/ 3444]
loss: 0.025132  [  700/ 3444]
loss: 0.007383  [  800/ 3444]
loss: 0.019848  [  900/ 3444]
loss: 0.009839  [ 1000/ 3444]
loss: 0.010508  [ 1100/ 3444]
loss: 0.002862  [ 1200/ 3444]
loss: 0.014828  [ 1300/ 3444]
loss: 0.111805  [ 1400/ 3444]
loss: 0.008252  [ 1500/ 3444]
loss: 0.010567  [ 1600/ 3444]
loss: 0.007106  [ 1700/ 3444]
loss: 0.017061  [ 1800/ 3444]
loss: 0.008723  [ 1900/ 3444]
loss: 0.012060  [ 2000/ 3444]
loss: 0.015908  [ 2100/ 3444]
loss: 0.017831  [ 2200/ 3444]
loss: 0.011538  [ 2300/ 3444]
loss: 0.006060  [ 2400/ 3444]
loss: 0.004830  [ 2500/ 3444]
loss: 0.005186  [ 2600/ 3444]
loss: 0.007105  [ 2700/ 3444]
loss: 0.015981  [ 2800/ 3444]
loss: 0.011159  [ 2900/ 3444]
loss: 0.009918  [ 3000/ 3444]
loss: 0.043285  [ 3100/ 3444]
loss: 0.103095  [ 3200/ 3444]
loss: 0.007003  [ 3300/ 3444]
loss: 0.025200  [ 3400/ 3444]
Epoch 4
-------------------------------
loss: 0.015771  [    0/ 3444]
loss: 0.011239  [  100/ 3444]
loss: 0.005963  [  200/ 3444]
loss: 0.016914  [  300/ 3444]
loss: 0.010272  [  400/ 3444]
loss: 0.008218  [  500/ 3444]
loss: 0.032974  [  600/ 3444]
loss: 0.024200  [  700/ 3444]
loss: 0.007380  [  800/ 3444]
loss: 0.020433  [  900/ 3444]
loss: 0.009802  [ 1000/ 3444]
loss: 0.010768  [ 1100/ 3444]
loss: 0.003229  [ 1200/ 3444]
loss: 0.013670  [ 1300/ 3444]
loss: 0.112216  [ 1400/ 3444]
loss: 0.008498  [ 1500/ 3444]
loss: 0.010308  [ 1600/ 3444]
loss: 0.007062  [ 1700/ 3444]
loss: 0.017067  [ 1800/ 3444]
loss: 0.009007  [ 1900/ 3444]
loss: 0.011216  [ 2000/ 3444]
loss: 0.015950  [ 2100/ 3444]
loss: 0.017267  [ 2200/ 3444]
loss: 0.011227  [ 2300/ 3444]
loss: 0.005891  [ 2400/ 3444]
loss: 0.004680  [ 2500/ 3444]
loss: 0.005048  [ 2600/ 3444]
loss: 0.006454  [ 2700/ 3444]
loss: 0.015722  [ 2800/ 3444]
loss: 0.011278  [ 2900/ 3444]
loss: 0.009722  [ 3000/ 3444]
loss: 0.034769  [ 3100/ 3444]
loss: 0.101424  [ 3200/ 3444]
loss: 0.006783  [ 3300/ 3444]
loss: 0.024679  [ 3400/ 3444]
Epoch 5
-------------------------------
loss: 0.015787  [    0/ 3444]
loss: 0.012563  [  100/ 3444]
loss: 0.006174  [  200/ 3444]
loss: 0.016933  [  300/ 3444]
loss: 0.010123  [  400/ 3444]
loss: 0.008405  [  500/ 3444]
loss: 0.031876  [  600/ 3444]
loss: 0.023861  [  700/ 3444]
loss: 0.007321  [  800/ 3444]
loss: 0.021126  [  900/ 3444]
loss: 0.009957  [ 1000/ 3444]
loss: 0.011279  [ 1100/ 3444]
loss: 0.003680  [ 1200/ 3444]
loss: 0.013556  [ 1300/ 3444]
loss: 0.112109  [ 1400/ 3444]
loss: 0.008885  [ 1500/ 3444]
loss: 0.010271  [ 1600/ 3444]
loss: 0.007194  [ 1700/ 3444]
loss: 0.017294  [ 1800/ 3444]
loss: 0.009164  [ 1900/ 3444]
loss: 0.010858  [ 2000/ 3444]
loss: 0.015834  [ 2100/ 3444]
loss: 0.016708  [ 2200/ 3444]
loss: 0.011318  [ 2300/ 3444]
loss: 0.005687  [ 2400/ 3444]
loss: 0.004466  [ 2500/ 3444]
loss: 0.004994  [ 2600/ 3444]
loss: 0.005658  [ 2700/ 3444]
loss: 0.015615  [ 2800/ 3444]
loss: 0.011325  [ 2900/ 3444]
loss: 0.009701  [ 3000/ 3444]
loss: 0.030100  [ 3100/ 3444]
loss: 0.100919  [ 3200/ 3444]
loss: 0.006831  [ 3300/ 3444]
loss: 0.024145  [ 3400/ 3444]
Epoch 6
-------------------------------
loss: 0.015999  [    0/ 3444]
loss: 0.011825  [  100/ 3444]
loss: 0.006069  [  200/ 3444]
loss: 0.016965  [  300/ 3444]
loss: 0.009941  [  400/ 3444]
loss: 0.008510  [  500/ 3444]
loss: 0.030411  [  600/ 3444]
loss: 0.023605  [  700/ 3444]
loss: 0.007411  [  800/ 3444]
loss: 0.021797  [  900/ 3444]
loss: 0.010017  [ 1000/ 3444]
loss: 0.011319  [ 1100/ 3444]
loss: 0.003984  [ 1200/ 3444]
loss: 0.013435  [ 1300/ 3444]
loss: 0.112291  [ 1400/ 3444]
loss: 0.009079  [ 1500/ 3444]
loss: 0.010096  [ 1600/ 3444]
loss: 0.007345  [ 1700/ 3444]
loss: 0.017370  [ 1800/ 3444]
loss: 0.009240  [ 1900/ 3444]
loss: 0.010373  [ 2000/ 3444]
loss: 0.015908  [ 2100/ 3444]
loss: 0.016558  [ 2200/ 3444]
loss: 0.011281  [ 2300/ 3444]
loss: 0.005646  [ 2400/ 3444]
loss: 0.004418  [ 2500/ 3444]
loss: 0.004882  [ 2600/ 3444]
loss: 0.005202  [ 2700/ 3444]
loss: 0.015501  [ 2800/ 3444]
loss: 0.011217  [ 2900/ 3444]
loss: 0.009377  [ 3000/ 3444]
loss: 0.027365  [ 3100/ 3444]
loss: 0.100960  [ 3200/ 3444]
loss: 0.006902  [ 3300/ 3444]
loss: 0.023811  [ 3400/ 3444]
Epoch 7
-------------------------------
loss: 0.015806  [    0/ 3444]
loss: 0.011323  [  100/ 3444]
loss: 0.005759  [  200/ 3444]
loss: 0.016777  [  300/ 3444]
loss: 0.009950  [  400/ 3444]
loss: 0.008579  [  500/ 3444]
loss: 0.029023  [  600/ 3444]
loss: 0.023339  [  700/ 3444]
loss: 0.007458  [  800/ 3444]
loss: 0.021406  [  900/ 3444]
loss: 0.010062  [ 1000/ 3444]
loss: 0.011343  [ 1100/ 3444]
loss: 0.004340  [ 1200/ 3444]
loss: 0.013683  [ 1300/ 3444]
loss: 0.112697  [ 1400/ 3444]
loss: 0.009373  [ 1500/ 3444]
loss: 0.010484  [ 1600/ 3444]
loss: 0.007410  [ 1700/ 3444]
loss: 0.017352  [ 1800/ 3444]
loss: 0.009242  [ 1900/ 3444]
loss: 0.010048  [ 2000/ 3444]
loss: 0.015980  [ 2100/ 3444]
loss: 0.016690  [ 2200/ 3444]
loss: 0.011377  [ 2300/ 3444]
loss: 0.005599  [ 2400/ 3444]
loss: 0.004375  [ 2500/ 3444]
loss: 0.004779  [ 2600/ 3444]
loss: 0.005200  [ 2700/ 3444]
loss: 0.015257  [ 2800/ 3444]
loss: 0.011047  [ 2900/ 3444]
loss: 0.009242  [ 3000/ 3444]
loss: 0.026281  [ 3100/ 3444]
loss: 0.101125  [ 3200/ 3444]
loss: 0.006947  [ 3300/ 3444]
loss: 0.023635  [ 3400/ 3444]
Epoch 8
-------------------------------
loss: 0.015647  [    0/ 3444]
loss: 0.011311  [  100/ 3444]
loss: 0.005507  [  200/ 3444]
loss: 0.016556  [  300/ 3444]
loss: 0.010134  [  400/ 3444]
loss: 0.008603  [  500/ 3444]
loss: 0.028260  [  600/ 3444]
loss: 0.024342  [  700/ 3444]
loss: 0.007785  [  800/ 3444]
loss: 0.020848  [  900/ 3444]
loss: 0.010109  [ 1000/ 3444]
loss: 0.011320  [ 1100/ 3444]
loss: 0.004759  [ 1200/ 3444]
loss: 0.013684  [ 1300/ 3444]
loss: 0.113276  [ 1400/ 3444]
loss: 0.009097  [ 1500/ 3444]
loss: 0.010574  [ 1600/ 3444]
loss: 0.007398  [ 1700/ 3444]
loss: 0.017525  [ 1800/ 3444]
loss: 0.009272  [ 1900/ 3444]
loss: 0.009377  [ 2000/ 3444]
loss: 0.016360  [ 2100/ 3444]
loss: 0.016739  [ 2200/ 3444]
loss: 0.011311  [ 2300/ 3444]
loss: 0.005474  [ 2400/ 3444]
loss: 0.004364  [ 2500/ 3444]
loss: 0.005010  [ 2600/ 3444]
loss: 0.005264  [ 2700/ 3444]
loss: 0.014849  [ 2800/ 3444]
loss: 0.010783  [ 2900/ 3444]
loss: 0.009280  [ 3000/ 3444]
loss: 0.026346  [ 3100/ 3444]
loss: 0.102027  [ 3200/ 3444]
loss: 0.006843  [ 3300/ 3444]
loss: 0.023506  [ 3400/ 3444]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3444
First Spike after testing: [-0.18190356  1.3651615 ]
[2 2 0 ... 0 2 0]
[1 1 0 ... 0 1 0]
Cluster 0 Occurrences: 1142; KMEANS: 1149
Cluster 1 Occurrences: 1180; KMEANS: 1116
Cluster 2 Occurrences: 1122; KMEANS: 1179
Centroids: [[0.470149, -0.9102627], [0.51904285, -0.33690035], [-0.0086815255, 1.2940141]]
Centroids: [[0.46786582, -0.9222499], [-0.013352242, 1.3003112], [0.5232938, -0.31947485]]
Contingency Matrix: 
[[1119    0   23]
 [  30    2 1148]
 [   0 1114    8]]
[[1119, 0, -1], [-1, -1, -1], [0, 1114, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, 1114, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 2, 0: 0, 2: 1}
New Contingency Matrix: 
[[1119   23    0]
 [  30 1148    2]
 [   0    8 1114]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [1119, 1148, 1114], Sum: 3381
All_Elements: [1119, 23, 0, 30, 1148, 2, 0, 8, 1114], Sum: 3444
Accuracy: 0.9817073170731707
Done!
