Experiment_path: Random_Seeds//V2/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02/C_Easy2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_52_29
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002DBE49E9470>
Sampling rate: 24000.0
Raw: [ 0.11862069  0.1123084   0.10401825 ... -0.10219323 -0.10268373
 -0.08956559]
Times: [    346     799    1005 ... 1436867 1437273 1437800]
Cluster: [3 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3410
First aligned Spike Frame: [ 2.05661766e-03  8.27536867e-03  1.66427268e-02  2.31246655e-02
  2.28936935e-02  1.99169368e-02  2.25281834e-02  3.37605443e-02
  4.94182133e-02  6.24484568e-02  8.42111946e-02  1.71357846e-01
  3.88441746e-01  6.99052305e-01  9.59509287e-01  1.03608873e+00
  9.29169963e-01  7.55567481e-01  6.10726415e-01  5.06818519e-01
  4.23878029e-01  3.55610047e-01  3.01970228e-01  2.53702042e-01
  1.98274486e-01  1.32802904e-01  6.40690121e-02  7.96454927e-04
 -5.66201776e-02 -1.11669131e-01 -1.62581026e-01 -2.01746625e-01
 -2.23071447e-01 -2.29516190e-01 -2.30160694e-01 -2.27148529e-01
 -2.18080531e-01 -2.04276810e-01 -1.90750996e-01 -1.81098693e-01
 -1.72421418e-01 -1.61640218e-01 -1.48460304e-01 -1.32332846e-01
 -1.13338953e-01 -9.43725979e-02 -7.56249106e-02]
Cluster 0, Occurrences: 1130
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1167
<torch.utils.data.dataloader.DataLoader object at 0x000002DBE3E1D358>
Epoch 1
-------------------------------
loss: 0.150037  [    0/ 3410]
loss: 0.073794  [  100/ 3410]
loss: 0.016035  [  200/ 3410]
loss: 0.010564  [  300/ 3410]
loss: 0.003815  [  400/ 3410]
loss: 0.003701  [  500/ 3410]
loss: 0.001264  [  600/ 3410]
loss: 0.004921  [  700/ 3410]
loss: 0.005292  [  800/ 3410]
loss: 0.007087  [  900/ 3410]
loss: 0.014195  [ 1000/ 3410]
loss: 0.002813  [ 1100/ 3410]
loss: 0.003161  [ 1200/ 3410]
loss: 0.006358  [ 1300/ 3410]
loss: 0.001539  [ 1400/ 3410]
loss: 0.002319  [ 1500/ 3410]
loss: 0.001491  [ 1600/ 3410]
loss: 0.006922  [ 1700/ 3410]
loss: 0.007924  [ 1800/ 3410]
loss: 0.001441  [ 1900/ 3410]
loss: 0.052964  [ 2000/ 3410]
loss: 0.003493  [ 2100/ 3410]
loss: 0.028145  [ 2200/ 3410]
loss: 0.002343  [ 2300/ 3410]
loss: 0.002323  [ 2400/ 3410]
loss: 0.095049  [ 2500/ 3410]
loss: 0.008178  [ 2600/ 3410]
loss: 0.003902  [ 2700/ 3410]
loss: 0.000920  [ 2800/ 3410]
loss: 0.006867  [ 2900/ 3410]
loss: 0.002415  [ 3000/ 3410]
loss: 0.001014  [ 3100/ 3410]
loss: 0.002214  [ 3200/ 3410]
loss: 0.001526  [ 3300/ 3410]
loss: 0.001476  [ 3400/ 3410]
Epoch 2
-------------------------------
loss: 0.000515  [    0/ 3410]
loss: 0.003665  [  100/ 3410]
loss: 0.005508  [  200/ 3410]
loss: 0.004216  [  300/ 3410]
loss: 0.002475  [  400/ 3410]
loss: 0.005302  [  500/ 3410]
loss: 0.001123  [  600/ 3410]
loss: 0.005412  [  700/ 3410]
loss: 0.004083  [  800/ 3410]
loss: 0.002440  [  900/ 3410]
loss: 0.005854  [ 1000/ 3410]
loss: 0.002777  [ 1100/ 3410]
loss: 0.002574  [ 1200/ 3410]
loss: 0.005058  [ 1300/ 3410]
loss: 0.001676  [ 1400/ 3410]
loss: 0.001460  [ 1500/ 3410]
loss: 0.001450  [ 1600/ 3410]
loss: 0.004624  [ 1700/ 3410]
loss: 0.008535  [ 1800/ 3410]
loss: 0.001271  [ 1900/ 3410]
loss: 0.054251  [ 2000/ 3410]
loss: 0.003271  [ 2100/ 3410]
loss: 0.026728  [ 2200/ 3410]
loss: 0.002042  [ 2300/ 3410]
loss: 0.001585  [ 2400/ 3410]
loss: 0.074478  [ 2500/ 3410]
loss: 0.006037  [ 2600/ 3410]
loss: 0.003933  [ 2700/ 3410]
loss: 0.000782  [ 2800/ 3410]
loss: 0.005982  [ 2900/ 3410]
loss: 0.002385  [ 3000/ 3410]
loss: 0.000917  [ 3100/ 3410]
loss: 0.001338  [ 3200/ 3410]
loss: 0.001422  [ 3300/ 3410]
loss: 0.001471  [ 3400/ 3410]
Epoch 3
-------------------------------
loss: 0.000414  [    0/ 3410]
loss: 0.003410  [  100/ 3410]
loss: 0.005110  [  200/ 3410]
loss: 0.003753  [  300/ 3410]
loss: 0.002309  [  400/ 3410]
loss: 0.005226  [  500/ 3410]
loss: 0.001132  [  600/ 3410]
loss: 0.005671  [  700/ 3410]
loss: 0.003861  [  800/ 3410]
loss: 0.002432  [  900/ 3410]
loss: 0.005220  [ 1000/ 3410]
loss: 0.002525  [ 1100/ 3410]
loss: 0.002287  [ 1200/ 3410]
loss: 0.005018  [ 1300/ 3410]
loss: 0.001673  [ 1400/ 3410]
loss: 0.001456  [ 1500/ 3410]
loss: 0.001450  [ 1600/ 3410]
loss: 0.004043  [ 1700/ 3410]
loss: 0.007366  [ 1800/ 3410]
loss: 0.001172  [ 1900/ 3410]
loss: 0.053559  [ 2000/ 3410]
loss: 0.003140  [ 2100/ 3410]
loss: 0.025893  [ 2200/ 3410]
loss: 0.002013  [ 2300/ 3410]
loss: 0.001444  [ 2400/ 3410]
loss: 0.070141  [ 2500/ 3410]
loss: 0.004866  [ 2600/ 3410]
loss: 0.003981  [ 2700/ 3410]
loss: 0.000752  [ 2800/ 3410]
loss: 0.005692  [ 2900/ 3410]
loss: 0.002306  [ 3000/ 3410]
loss: 0.000896  [ 3100/ 3410]
loss: 0.001615  [ 3200/ 3410]
loss: 0.001354  [ 3300/ 3410]
loss: 0.001527  [ 3400/ 3410]
Epoch 4
-------------------------------
loss: 0.000342  [    0/ 3410]
loss: 0.003228  [  100/ 3410]
loss: 0.004874  [  200/ 3410]
loss: 0.003846  [  300/ 3410]
loss: 0.002187  [  400/ 3410]
loss: 0.006039  [  500/ 3410]
loss: 0.001068  [  600/ 3410]
loss: 0.005406  [  700/ 3410]
loss: 0.003739  [  800/ 3410]
loss: 0.002447  [  900/ 3410]
loss: 0.005151  [ 1000/ 3410]
loss: 0.002396  [ 1100/ 3410]
loss: 0.002078  [ 1200/ 3410]
loss: 0.004560  [ 1300/ 3410]
loss: 0.001661  [ 1400/ 3410]
loss: 0.001438  [ 1500/ 3410]
loss: 0.001396  [ 1600/ 3410]
loss: 0.003562  [ 1700/ 3410]
loss: 0.007043  [ 1800/ 3410]
loss: 0.001147  [ 1900/ 3410]
loss: 0.053366  [ 2000/ 3410]
loss: 0.003254  [ 2100/ 3410]
loss: 0.025880  [ 2200/ 3410]
loss: 0.002062  [ 2300/ 3410]
loss: 0.001461  [ 2400/ 3410]
loss: 0.078127  [ 2500/ 3410]
loss: 0.004946  [ 2600/ 3410]
loss: 0.004098  [ 2700/ 3410]
loss: 0.000733  [ 2800/ 3410]
loss: 0.005602  [ 2900/ 3410]
loss: 0.002232  [ 3000/ 3410]
loss: 0.000860  [ 3100/ 3410]
loss: 0.001458  [ 3200/ 3410]
loss: 0.001357  [ 3300/ 3410]
loss: 0.001579  [ 3400/ 3410]
Epoch 5
-------------------------------
loss: 0.000315  [    0/ 3410]
loss: 0.003117  [  100/ 3410]
loss: 0.004906  [  200/ 3410]
loss: 0.003881  [  300/ 3410]
loss: 0.002107  [  400/ 3410]
loss: 0.004519  [  500/ 3410]
loss: 0.001064  [  600/ 3410]
loss: 0.005271  [  700/ 3410]
loss: 0.003872  [  800/ 3410]
loss: 0.002467  [  900/ 3410]
loss: 0.004756  [ 1000/ 3410]
loss: 0.002367  [ 1100/ 3410]
loss: 0.001953  [ 1200/ 3410]
loss: 0.004684  [ 1300/ 3410]
loss: 0.001623  [ 1400/ 3410]
loss: 0.001371  [ 1500/ 3410]
loss: 0.001397  [ 1600/ 3410]
loss: 0.003395  [ 1700/ 3410]
loss: 0.006645  [ 1800/ 3410]
loss: 0.001128  [ 1900/ 3410]
loss: 0.052244  [ 2000/ 3410]
loss: 0.003260  [ 2100/ 3410]
loss: 0.025968  [ 2200/ 3410]
loss: 0.002084  [ 2300/ 3410]
loss: 0.001564  [ 2400/ 3410]
loss: 0.081920  [ 2500/ 3410]
loss: 0.004613  [ 2600/ 3410]
loss: 0.004080  [ 2700/ 3410]
loss: 0.000686  [ 2800/ 3410]
loss: 0.005630  [ 2900/ 3410]
loss: 0.002203  [ 3000/ 3410]
loss: 0.000873  [ 3100/ 3410]
loss: 0.001354  [ 3200/ 3410]
loss: 0.001337  [ 3300/ 3410]
loss: 0.001527  [ 3400/ 3410]
Epoch 6
-------------------------------
loss: 0.000336  [    0/ 3410]
loss: 0.003062  [  100/ 3410]
loss: 0.004831  [  200/ 3410]
loss: 0.003938  [  300/ 3410]
loss: 0.002054  [  400/ 3410]
loss: 0.003183  [  500/ 3410]
loss: 0.001169  [  600/ 3410]
loss: 0.005063  [  700/ 3410]
loss: 0.004019  [  800/ 3410]
loss: 0.002437  [  900/ 3410]
loss: 0.004315  [ 1000/ 3410]
loss: 0.002424  [ 1100/ 3410]
loss: 0.001948  [ 1200/ 3410]
loss: 0.004770  [ 1300/ 3410]
loss: 0.001567  [ 1400/ 3410]
loss: 0.001347  [ 1500/ 3410]
loss: 0.001430  [ 1600/ 3410]
loss: 0.003189  [ 1700/ 3410]
loss: 0.005965  [ 1800/ 3410]
loss: 0.001114  [ 1900/ 3410]
loss: 0.052192  [ 2000/ 3410]
loss: 0.003231  [ 2100/ 3410]
loss: 0.026136  [ 2200/ 3410]
loss: 0.002150  [ 2300/ 3410]
loss: 0.001727  [ 2400/ 3410]
loss: 0.080391  [ 2500/ 3410]
loss: 0.003777  [ 2600/ 3410]
loss: 0.004066  [ 2700/ 3410]
loss: 0.000698  [ 2800/ 3410]
loss: 0.005572  [ 2900/ 3410]
loss: 0.002170  [ 3000/ 3410]
loss: 0.000886  [ 3100/ 3410]
loss: 0.001727  [ 3200/ 3410]
loss: 0.001324  [ 3300/ 3410]
loss: 0.001465  [ 3400/ 3410]
Epoch 7
-------------------------------
loss: 0.000331  [    0/ 3410]
loss: 0.003001  [  100/ 3410]
loss: 0.004741  [  200/ 3410]
loss: 0.004048  [  300/ 3410]
loss: 0.002023  [  400/ 3410]
loss: 0.002961  [  500/ 3410]
loss: 0.001226  [  600/ 3410]
loss: 0.004894  [  700/ 3410]
loss: 0.004128  [  800/ 3410]
loss: 0.002384  [  900/ 3410]
loss: 0.003927  [ 1000/ 3410]
loss: 0.002579  [ 1100/ 3410]
loss: 0.001919  [ 1200/ 3410]
loss: 0.004874  [ 1300/ 3410]
loss: 0.001778  [ 1400/ 3410]
loss: 0.001301  [ 1500/ 3410]
loss: 0.001440  [ 1600/ 3410]
loss: 0.003115  [ 1700/ 3410]
loss: 0.005954  [ 1800/ 3410]
loss: 0.001105  [ 1900/ 3410]
loss: 0.052476  [ 2000/ 3410]
loss: 0.003144  [ 2100/ 3410]
loss: 0.026381  [ 2200/ 3410]
loss: 0.002299  [ 2300/ 3410]
loss: 0.001892  [ 2400/ 3410]
loss: 0.067818  [ 2500/ 3410]
loss: 0.003530  [ 2600/ 3410]
loss: 0.004089  [ 2700/ 3410]
loss: 0.000680  [ 2800/ 3410]
loss: 0.005373  [ 2900/ 3410]
loss: 0.002050  [ 3000/ 3410]
loss: 0.000874  [ 3100/ 3410]
loss: 0.001651  [ 3200/ 3410]
loss: 0.001385  [ 3300/ 3410]
loss: 0.001429  [ 3400/ 3410]
Epoch 8
-------------------------------
loss: 0.000335  [    0/ 3410]
loss: 0.002865  [  100/ 3410]
loss: 0.004617  [  200/ 3410]
loss: 0.004099  [  300/ 3410]
loss: 0.002018  [  400/ 3410]
loss: 0.002843  [  500/ 3410]
loss: 0.001205  [  600/ 3410]
loss: 0.004814  [  700/ 3410]
loss: 0.004265  [  800/ 3410]
loss: 0.002416  [  900/ 3410]
loss: 0.003667  [ 1000/ 3410]
loss: 0.002694  [ 1100/ 3410]
loss: 0.001986  [ 1200/ 3410]
loss: 0.005232  [ 1300/ 3410]
loss: 0.001716  [ 1400/ 3410]
loss: 0.001415  [ 1500/ 3410]
loss: 0.001380  [ 1600/ 3410]
loss: 0.003189  [ 1700/ 3410]
loss: 0.005865  [ 1800/ 3410]
loss: 0.001069  [ 1900/ 3410]
loss: 0.052445  [ 2000/ 3410]
loss: 0.003131  [ 2100/ 3410]
loss: 0.026709  [ 2200/ 3410]
loss: 0.002411  [ 2300/ 3410]
loss: 0.002064  [ 2400/ 3410]
loss: 0.067055  [ 2500/ 3410]
loss: 0.003744  [ 2600/ 3410]
loss: 0.004042  [ 2700/ 3410]
loss: 0.000684  [ 2800/ 3410]
loss: 0.005277  [ 2900/ 3410]
loss: 0.001938  [ 3000/ 3410]
loss: 0.000911  [ 3100/ 3410]
loss: 0.002096  [ 3200/ 3410]
loss: 0.001419  [ 3300/ 3410]
loss: 0.001415  [ 3400/ 3410]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3410
First Spike after testing: [0.00229262 0.9521933 ]
[2 2 2 ... 2 0 2]
[1 1 1 ... 1 0 1]
Cluster 0 Occurrences: 1130; KMEANS: 1159
Cluster 1 Occurrences: 1113; KMEANS: 1162
Cluster 2 Occurrences: 1167; KMEANS: 1089
Centroids: [[0.7632528, -1.4516817], [0.8300118, -0.55434257], [-0.021094711, 0.88029265]]
Centroids: [[0.75455284, -1.4719605], [-0.027587095, 0.8822366], [0.8440686, -0.5043515]]
Contingency Matrix: 
[[1112    0   18]
 [  47    1 1065]
 [   0 1161    6]]
[[1112, -1, 18], [47, -1, 1065], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1065], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 0, 1: 2}
New Contingency Matrix: 
[[1112   18    0]
 [  47 1065    1]
 [   0    6 1161]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [1112, 1065, 1161], Sum: 3338
All_Elements: [1112, 18, 0, 47, 1065, 1, 0, 6, 1161], Sum: 3410
Accuracy: 0.9788856304985337
Done!
