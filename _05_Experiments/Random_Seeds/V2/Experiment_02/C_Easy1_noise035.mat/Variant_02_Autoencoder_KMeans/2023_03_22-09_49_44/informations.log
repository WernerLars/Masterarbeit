Experiment_path: Random_Seeds//V2/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02/C_Easy1_noise035.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_49_44
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002DBE49E9470>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
<torch.utils.data.dataloader.DataLoader object at 0x000002DBE3E65128>
Epoch 1
-------------------------------
loss: 0.232332  [    0/ 3534]
loss: 0.304195  [  100/ 3534]
loss: 0.080518  [  200/ 3534]
loss: 0.183201  [  300/ 3534]
loss: 0.162349  [  400/ 3534]
loss: 0.159785  [  500/ 3534]
loss: 0.053240  [  600/ 3534]
loss: 0.067245  [  700/ 3534]
loss: 0.113509  [  800/ 3534]
loss: 0.037542  [  900/ 3534]
loss: 0.120996  [ 1000/ 3534]
loss: 0.023100  [ 1100/ 3534]
loss: 0.064931  [ 1200/ 3534]
loss: 0.053264  [ 1300/ 3534]
loss: 0.009476  [ 1400/ 3534]
loss: 0.047893  [ 1500/ 3534]
loss: 0.156637  [ 1600/ 3534]
loss: 0.045740  [ 1700/ 3534]
loss: 0.207402  [ 1800/ 3534]
loss: 0.061397  [ 1900/ 3534]
loss: 0.072585  [ 2000/ 3534]
loss: 0.032410  [ 2100/ 3534]
loss: 0.038537  [ 2200/ 3534]
loss: 0.117821  [ 2300/ 3534]
loss: 0.069053  [ 2400/ 3534]
loss: 0.096374  [ 2500/ 3534]
loss: 0.055220  [ 2600/ 3534]
loss: 0.046698  [ 2700/ 3534]
loss: 0.057229  [ 2800/ 3534]
loss: 0.042500  [ 2900/ 3534]
loss: 0.171324  [ 3000/ 3534]
loss: 0.062808  [ 3100/ 3534]
loss: 0.122341  [ 3200/ 3534]
loss: 0.211386  [ 3300/ 3534]
loss: 0.043889  [ 3400/ 3534]
loss: 0.069554  [ 3500/ 3534]
Epoch 2
-------------------------------
loss: 0.132246  [    0/ 3534]
loss: 0.057140  [  100/ 3534]
loss: 0.029989  [  200/ 3534]
loss: 0.109336  [  300/ 3534]
loss: 0.207958  [  400/ 3534]
loss: 0.070098  [  500/ 3534]
loss: 0.093146  [  600/ 3534]
loss: 0.071589  [  700/ 3534]
loss: 0.040841  [  800/ 3534]
loss: 0.029213  [  900/ 3534]
loss: 0.052590  [ 1000/ 3534]
loss: 0.024230  [ 1100/ 3534]
loss: 0.043325  [ 1200/ 3534]
loss: 0.054278  [ 1300/ 3534]
loss: 0.009600  [ 1400/ 3534]
loss: 0.026369  [ 1500/ 3534]
loss: 0.164921  [ 1600/ 3534]
loss: 0.061290  [ 1700/ 3534]
loss: 0.079888  [ 1800/ 3534]
loss: 0.035572  [ 1900/ 3534]
loss: 0.037907  [ 2000/ 3534]
loss: 0.035437  [ 2100/ 3534]
loss: 0.051433  [ 2200/ 3534]
loss: 0.117906  [ 2300/ 3534]
loss: 0.058860  [ 2400/ 3534]
loss: 0.093964  [ 2500/ 3534]
loss: 0.054708  [ 2600/ 3534]
loss: 0.035048  [ 2700/ 3534]
loss: 0.053293  [ 2800/ 3534]
loss: 0.022243  [ 2900/ 3534]
loss: 0.137985  [ 3000/ 3534]
loss: 0.052618  [ 3100/ 3534]
loss: 0.122412  [ 3200/ 3534]
loss: 0.153734  [ 3300/ 3534]
loss: 0.038958  [ 3400/ 3534]
loss: 0.069645  [ 3500/ 3534]
Epoch 3
-------------------------------
loss: 0.130259  [    0/ 3534]
loss: 0.054731  [  100/ 3534]
loss: 0.027811  [  200/ 3534]
loss: 0.114418  [  300/ 3534]
loss: 0.198932  [  400/ 3534]
loss: 0.055415  [  500/ 3534]
loss: 0.096062  [  600/ 3534]
loss: 0.071329  [  700/ 3534]
loss: 0.038922  [  800/ 3534]
loss: 0.031231  [  900/ 3534]
loss: 0.049553  [ 1000/ 3534]
loss: 0.024024  [ 1100/ 3534]
loss: 0.044665  [ 1200/ 3534]
loss: 0.054963  [ 1300/ 3534]
loss: 0.009036  [ 1400/ 3534]
loss: 0.026998  [ 1500/ 3534]
loss: 0.167344  [ 1600/ 3534]
loss: 0.060001  [ 1700/ 3534]
loss: 0.060981  [ 1800/ 3534]
loss: 0.032924  [ 1900/ 3534]
loss: 0.036063  [ 2000/ 3534]
loss: 0.035707  [ 2100/ 3534]
loss: 0.058537  [ 2200/ 3534]
loss: 0.121979  [ 2300/ 3534]
loss: 0.058187  [ 2400/ 3534]
loss: 0.093019  [ 2500/ 3534]
loss: 0.056318  [ 2600/ 3534]
loss: 0.035049  [ 2700/ 3534]
loss: 0.052305  [ 2800/ 3534]
loss: 0.019891  [ 2900/ 3534]
loss: 0.140032  [ 3000/ 3534]
loss: 0.050029  [ 3100/ 3534]
loss: 0.123775  [ 3200/ 3534]
loss: 0.143814  [ 3300/ 3534]
loss: 0.038613  [ 3400/ 3534]
loss: 0.069485  [ 3500/ 3534]
Epoch 4
-------------------------------
loss: 0.130245  [    0/ 3534]
loss: 0.056169  [  100/ 3534]
loss: 0.025137  [  200/ 3534]
loss: 0.118469  [  300/ 3534]
loss: 0.198462  [  400/ 3534]
loss: 0.050034  [  500/ 3534]
loss: 0.094827  [  600/ 3534]
loss: 0.072386  [  700/ 3534]
loss: 0.038940  [  800/ 3534]
loss: 0.031705  [  900/ 3534]
loss: 0.047854  [ 1000/ 3534]
loss: 0.023905  [ 1100/ 3534]
loss: 0.040086  [ 1200/ 3534]
loss: 0.056136  [ 1300/ 3534]
loss: 0.008067  [ 1400/ 3534]
loss: 0.027075  [ 1500/ 3534]
loss: 0.170104  [ 1600/ 3534]
loss: 0.057236  [ 1700/ 3534]
loss: 0.048223  [ 1800/ 3534]
loss: 0.032149  [ 1900/ 3534]
loss: 0.034405  [ 2000/ 3534]
loss: 0.035531  [ 2100/ 3534]
loss: 0.059566  [ 2200/ 3534]
loss: 0.124737  [ 2300/ 3534]
loss: 0.057818  [ 2400/ 3534]
loss: 0.091274  [ 2500/ 3534]
loss: 0.052187  [ 2600/ 3534]
loss: 0.034761  [ 2700/ 3534]
loss: 0.044847  [ 2800/ 3534]
loss: 0.023122  [ 2900/ 3534]
loss: 0.145624  [ 3000/ 3534]
loss: 0.048074  [ 3100/ 3534]
loss: 0.123817  [ 3200/ 3534]
loss: 0.145353  [ 3300/ 3534]
loss: 0.039644  [ 3400/ 3534]
loss: 0.069423  [ 3500/ 3534]
Epoch 5
-------------------------------
loss: 0.130214  [    0/ 3534]
loss: 0.053738  [  100/ 3534]
loss: 0.024276  [  200/ 3534]
loss: 0.122281  [  300/ 3534]
loss: 0.207189  [  400/ 3534]
loss: 0.045281  [  500/ 3534]
loss: 0.094159  [  600/ 3534]
loss: 0.071488  [  700/ 3534]
loss: 0.038757  [  800/ 3534]
loss: 0.032590  [  900/ 3534]
loss: 0.046270  [ 1000/ 3534]
loss: 0.023751  [ 1100/ 3534]
loss: 0.036252  [ 1200/ 3534]
loss: 0.057684  [ 1300/ 3534]
loss: 0.007532  [ 1400/ 3534]
loss: 0.027449  [ 1500/ 3534]
loss: 0.162243  [ 1600/ 3534]
loss: 0.055161  [ 1700/ 3534]
loss: 0.040198  [ 1800/ 3534]
loss: 0.031785  [ 1900/ 3534]
loss: 0.032765  [ 2000/ 3534]
loss: 0.035623  [ 2100/ 3534]
loss: 0.060086  [ 2200/ 3534]
loss: 0.128790  [ 2300/ 3534]
loss: 0.058135  [ 2400/ 3534]
loss: 0.090352  [ 2500/ 3534]
loss: 0.045158  [ 2600/ 3534]
loss: 0.034535  [ 2700/ 3534]
loss: 0.036991  [ 2800/ 3534]
loss: 0.020824  [ 2900/ 3534]
loss: 0.162952  [ 3000/ 3534]
loss: 0.048563  [ 3100/ 3534]
loss: 0.123458  [ 3200/ 3534]
loss: 0.154293  [ 3300/ 3534]
loss: 0.040787  [ 3400/ 3534]
loss: 0.068669  [ 3500/ 3534]
Epoch 6
-------------------------------
loss: 0.128817  [    0/ 3534]
loss: 0.048593  [  100/ 3534]
loss: 0.024696  [  200/ 3534]
loss: 0.126795  [  300/ 3534]
loss: 0.219587  [  400/ 3534]
loss: 0.041040  [  500/ 3534]
loss: 0.096807  [  600/ 3534]
loss: 0.071385  [  700/ 3534]
loss: 0.039443  [  800/ 3534]
loss: 0.033381  [  900/ 3534]
loss: 0.044861  [ 1000/ 3534]
loss: 0.023235  [ 1100/ 3534]
loss: 0.031641  [ 1200/ 3534]
loss: 0.058426  [ 1300/ 3534]
loss: 0.006945  [ 1400/ 3534]
loss: 0.027568  [ 1500/ 3534]
loss: 0.151845  [ 1600/ 3534]
loss: 0.053257  [ 1700/ 3534]
loss: 0.036142  [ 1800/ 3534]
loss: 0.031576  [ 1900/ 3534]
loss: 0.031876  [ 2000/ 3534]
loss: 0.035579  [ 2100/ 3534]
loss: 0.060136  [ 2200/ 3534]
loss: 0.125594  [ 2300/ 3534]
loss: 0.057103  [ 2400/ 3534]
loss: 0.092687  [ 2500/ 3534]
loss: 0.040497  [ 2600/ 3534]
loss: 0.034793  [ 2700/ 3534]
loss: 0.028064  [ 2800/ 3534]
loss: 0.021004  [ 2900/ 3534]
loss: 0.179789  [ 3000/ 3534]
loss: 0.049891  [ 3100/ 3534]
loss: 0.122943  [ 3200/ 3534]
loss: 0.170921  [ 3300/ 3534]
loss: 0.040899  [ 3400/ 3534]
loss: 0.067767  [ 3500/ 3534]
Epoch 7
-------------------------------
loss: 0.127826  [    0/ 3534]
loss: 0.052153  [  100/ 3534]
loss: 0.026457  [  200/ 3534]
loss: 0.125918  [  300/ 3534]
loss: 0.244603  [  400/ 3534]
loss: 0.037192  [  500/ 3534]
loss: 0.096695  [  600/ 3534]
loss: 0.073387  [  700/ 3534]
loss: 0.039416  [  800/ 3534]
loss: 0.034905  [  900/ 3534]
loss: 0.044581  [ 1000/ 3534]
loss: 0.022017  [ 1100/ 3534]
loss: 0.028211  [ 1200/ 3534]
loss: 0.058207  [ 1300/ 3534]
loss: 0.007289  [ 1400/ 3534]
loss: 0.026504  [ 1500/ 3534]
loss: 0.147373  [ 1600/ 3534]
loss: 0.051655  [ 1700/ 3534]
loss: 0.036667  [ 1800/ 3534]
loss: 0.031270  [ 1900/ 3534]
loss: 0.030578  [ 2000/ 3534]
loss: 0.035759  [ 2100/ 3534]
loss: 0.059426  [ 2200/ 3534]
loss: 0.124433  [ 2300/ 3534]
loss: 0.056249  [ 2400/ 3534]
loss: 0.096153  [ 2500/ 3534]
loss: 0.036296  [ 2600/ 3534]
loss: 0.034755  [ 2700/ 3534]
loss: 0.027827  [ 2800/ 3534]
loss: 0.020304  [ 2900/ 3534]
loss: 0.185059  [ 3000/ 3534]
loss: 0.050415  [ 3100/ 3534]
loss: 0.121807  [ 3200/ 3534]
loss: 0.183549  [ 3300/ 3534]
loss: 0.040445  [ 3400/ 3534]
loss: 0.067369  [ 3500/ 3534]
Epoch 8
-------------------------------
loss: 0.128921  [    0/ 3534]
loss: 0.057954  [  100/ 3534]
loss: 0.029298  [  200/ 3534]
loss: 0.125978  [  300/ 3534]
loss: 0.267262  [  400/ 3534]
loss: 0.033659  [  500/ 3534]
loss: 0.095248  [  600/ 3534]
loss: 0.075025  [  700/ 3534]
loss: 0.039001  [  800/ 3534]
loss: 0.034987  [  900/ 3534]
loss: 0.042311  [ 1000/ 3534]
loss: 0.021607  [ 1100/ 3534]
loss: 0.028140  [ 1200/ 3534]
loss: 0.058947  [ 1300/ 3534]
loss: 0.007520  [ 1400/ 3534]
loss: 0.026984  [ 1500/ 3534]
loss: 0.142960  [ 1600/ 3534]
loss: 0.050000  [ 1700/ 3534]
loss: 0.038815  [ 1800/ 3534]
loss: 0.030882  [ 1900/ 3534]
loss: 0.030560  [ 2000/ 3534]
loss: 0.036368  [ 2100/ 3534]
loss: 0.055517  [ 2200/ 3534]
loss: 0.123898  [ 2300/ 3534]
loss: 0.054639  [ 2400/ 3534]
loss: 0.102728  [ 2500/ 3534]
loss: 0.034241  [ 2600/ 3534]
loss: 0.036381  [ 2700/ 3534]
loss: 0.032722  [ 2800/ 3534]
loss: 0.019363  [ 2900/ 3534]
loss: 0.182507  [ 3000/ 3534]
loss: 0.051571  [ 3100/ 3534]
loss: 0.119675  [ 3200/ 3534]
loss: 0.167375  [ 3300/ 3534]
loss: 0.040603  [ 3400/ 3534]
loss: 0.068009  [ 3500/ 3534]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3534
First Spike after testing: [0.4174743 0.281539 ]
[0 1 2 ... 2 2 1]
[2 1 0 ... 2 0 1]
Cluster 0 Occurrences: 1208; KMEANS: 1151
Cluster 1 Occurrences: 1137; KMEANS: 1170
Cluster 2 Occurrences: 1189; KMEANS: 1213
Centroids: [[0.1550912, 0.29159904], [-0.11578118, -2.2360606], [0.22135125, 1.1335566]]
Centroids: [[0.29979256, 1.3216432], [-0.11984298, -2.2876322], [0.094022, 0.2580113]]
Contingency Matrix: 
[[  93    1 1114]
 [   4 1118   15]
 [1054   51   84]]
[[93, -1, 1114], [-1, -1, -1], [1054, -1, 84]]
[[-1, -1, -1], [-1, -1, -1], [1054, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 0: 2, 2: 0}
New Contingency Matrix: 
[[1114    1   93]
 [  15 1118    4]
 [  84   51 1054]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1114, 1118, 1054], Sum: 3286
All_Elements: [1114, 1, 93, 15, 1118, 4, 84, 51, 1054], Sum: 3534
Accuracy: 0.9298245614035088
Done!
