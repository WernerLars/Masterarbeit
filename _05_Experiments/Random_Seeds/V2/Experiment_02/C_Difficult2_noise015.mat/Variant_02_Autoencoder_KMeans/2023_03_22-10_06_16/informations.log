Experiment_path: Random_Seeds//V2/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02/C_Difficult2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_06_16
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002DC07EAC518>
Sampling rate: 24000.0
Raw: [-0.05565321 -0.04571496 -0.03115923 ...  0.1473638   0.13534729
  0.111692  ]
Times: [    418     529    1030 ... 1439028 1439080 1439623]
Cluster: [2 3 2 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3440
First aligned Spike Frame: [-0.17099344 -0.1945709  -0.20692804 -0.21224585 -0.21123273 -0.19839621
 -0.16928805 -0.13455314 -0.10755804 -0.09418858 -0.09168847 -0.09014646
 -0.07785681 -0.05220219 -0.010559    0.05141874  0.13325345  0.23429051
  0.3635645   0.52201137  0.68833941  0.84629252  0.96368446  0.9673675
  0.80566127  0.51814506  0.20703252 -0.04483802 -0.21878317 -0.33306068
 -0.39936966 -0.41844164 -0.40822894 -0.3999483  -0.40801198 -0.43204789
 -0.46902504 -0.51735316 -0.56113271 -0.57967205 -0.56696316 -0.53144438
 -0.47215401 -0.37953885 -0.25698053 -0.12693248 -0.00995817]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1185
<torch.utils.data.dataloader.DataLoader object at 0x000002DBE3E65D30>
Epoch 1
-------------------------------
loss: 0.168721  [    0/ 3440]
loss: 0.089342  [  100/ 3440]
loss: 0.015974  [  200/ 3440]
loss: 0.021356  [  300/ 3440]
loss: 0.056344  [  400/ 3440]
loss: 0.068908  [  500/ 3440]
loss: 0.074779  [  600/ 3440]
loss: 0.009263  [  700/ 3440]
loss: 0.019210  [  800/ 3440]
loss: 0.082853  [  900/ 3440]
loss: 0.009234  [ 1000/ 3440]
loss: 0.012327  [ 1100/ 3440]
loss: 0.007450  [ 1200/ 3440]
loss: 0.016407  [ 1300/ 3440]
loss: 0.029832  [ 1400/ 3440]
loss: 0.030148  [ 1500/ 3440]
loss: 0.008108  [ 1600/ 3440]
loss: 0.012132  [ 1700/ 3440]
loss: 0.018822  [ 1800/ 3440]
loss: 0.019677  [ 1900/ 3440]
loss: 0.030702  [ 2000/ 3440]
loss: 0.038801  [ 2100/ 3440]
loss: 0.007909  [ 2200/ 3440]
loss: 0.010702  [ 2300/ 3440]
loss: 0.016066  [ 2400/ 3440]
loss: 0.014581  [ 2500/ 3440]
loss: 0.013760  [ 2600/ 3440]
loss: 0.010817  [ 2700/ 3440]
loss: 0.021852  [ 2800/ 3440]
loss: 0.010885  [ 2900/ 3440]
loss: 0.005425  [ 3000/ 3440]
loss: 0.011733  [ 3100/ 3440]
loss: 0.015958  [ 3200/ 3440]
loss: 0.007762  [ 3300/ 3440]
loss: 0.011676  [ 3400/ 3440]
Epoch 2
-------------------------------
loss: 0.021752  [    0/ 3440]
loss: 0.015475  [  100/ 3440]
loss: 0.003547  [  200/ 3440]
loss: 0.008602  [  300/ 3440]
loss: 0.018976  [  400/ 3440]
loss: 0.077725  [  500/ 3440]
loss: 0.031114  [  600/ 3440]
loss: 0.009252  [  700/ 3440]
loss: 0.009594  [  800/ 3440]
loss: 0.084279  [  900/ 3440]
loss: 0.005446  [ 1000/ 3440]
loss: 0.012972  [ 1100/ 3440]
loss: 0.007312  [ 1200/ 3440]
loss: 0.012331  [ 1300/ 3440]
loss: 0.021217  [ 1400/ 3440]
loss: 0.028305  [ 1500/ 3440]
loss: 0.009521  [ 1600/ 3440]
loss: 0.011384  [ 1700/ 3440]
loss: 0.017403  [ 1800/ 3440]
loss: 0.020021  [ 1900/ 3440]
loss: 0.020453  [ 2000/ 3440]
loss: 0.030022  [ 2100/ 3440]
loss: 0.009952  [ 2200/ 3440]
loss: 0.010392  [ 2300/ 3440]
loss: 0.019434  [ 2400/ 3440]
loss: 0.010989  [ 2500/ 3440]
loss: 0.011367  [ 2600/ 3440]
loss: 0.010902  [ 2700/ 3440]
loss: 0.022018  [ 2800/ 3440]
loss: 0.012303  [ 2900/ 3440]
loss: 0.004722  [ 3000/ 3440]
loss: 0.011720  [ 3100/ 3440]
loss: 0.015041  [ 3200/ 3440]
loss: 0.006451  [ 3300/ 3440]
loss: 0.010029  [ 3400/ 3440]
Epoch 3
-------------------------------
loss: 0.022398  [    0/ 3440]
loss: 0.015198  [  100/ 3440]
loss: 0.003312  [  200/ 3440]
loss: 0.009204  [  300/ 3440]
loss: 0.019475  [  400/ 3440]
loss: 0.081410  [  500/ 3440]
loss: 0.026993  [  600/ 3440]
loss: 0.010510  [  700/ 3440]
loss: 0.008518  [  800/ 3440]
loss: 0.083443  [  900/ 3440]
loss: 0.004932  [ 1000/ 3440]
loss: 0.012938  [ 1100/ 3440]
loss: 0.007092  [ 1200/ 3440]
loss: 0.012640  [ 1300/ 3440]
loss: 0.019987  [ 1400/ 3440]
loss: 0.028480  [ 1500/ 3440]
loss: 0.008985  [ 1600/ 3440]
loss: 0.011474  [ 1700/ 3440]
loss: 0.017547  [ 1800/ 3440]
loss: 0.020315  [ 1900/ 3440]
loss: 0.018419  [ 2000/ 3440]
loss: 0.030108  [ 2100/ 3440]
loss: 0.009864  [ 2200/ 3440]
loss: 0.010217  [ 2300/ 3440]
loss: 0.019955  [ 2400/ 3440]
loss: 0.010180  [ 2500/ 3440]
loss: 0.011270  [ 2600/ 3440]
loss: 0.010887  [ 2700/ 3440]
loss: 0.022126  [ 2800/ 3440]
loss: 0.012595  [ 2900/ 3440]
loss: 0.004610  [ 3000/ 3440]
loss: 0.011659  [ 3100/ 3440]
loss: 0.014818  [ 3200/ 3440]
loss: 0.005839  [ 3300/ 3440]
loss: 0.009766  [ 3400/ 3440]
Epoch 4
-------------------------------
loss: 0.022444  [    0/ 3440]
loss: 0.015088  [  100/ 3440]
loss: 0.003221  [  200/ 3440]
loss: 0.009084  [  300/ 3440]
loss: 0.019543  [  400/ 3440]
loss: 0.083423  [  500/ 3440]
loss: 0.026096  [  600/ 3440]
loss: 0.010427  [  700/ 3440]
loss: 0.008238  [  800/ 3440]
loss: 0.083374  [  900/ 3440]
loss: 0.004775  [ 1000/ 3440]
loss: 0.013143  [ 1100/ 3440]
loss: 0.006994  [ 1200/ 3440]
loss: 0.012895  [ 1300/ 3440]
loss: 0.019594  [ 1400/ 3440]
loss: 0.028499  [ 1500/ 3440]
loss: 0.008656  [ 1600/ 3440]
loss: 0.011499  [ 1700/ 3440]
loss: 0.017595  [ 1800/ 3440]
loss: 0.020329  [ 1900/ 3440]
loss: 0.017146  [ 2000/ 3440]
loss: 0.030576  [ 2100/ 3440]
loss: 0.009588  [ 2200/ 3440]
loss: 0.010061  [ 2300/ 3440]
loss: 0.020329  [ 2400/ 3440]
loss: 0.009920  [ 2500/ 3440]
loss: 0.011332  [ 2600/ 3440]
loss: 0.010809  [ 2700/ 3440]
loss: 0.022328  [ 2800/ 3440]
loss: 0.012844  [ 2900/ 3440]
loss: 0.004558  [ 3000/ 3440]
loss: 0.011476  [ 3100/ 3440]
loss: 0.014541  [ 3200/ 3440]
loss: 0.005487  [ 3300/ 3440]
loss: 0.009614  [ 3400/ 3440]
Epoch 5
-------------------------------
loss: 0.022372  [    0/ 3440]
loss: 0.015051  [  100/ 3440]
loss: 0.003264  [  200/ 3440]
loss: 0.008984  [  300/ 3440]
loss: 0.019623  [  400/ 3440]
loss: 0.083562  [  500/ 3440]
loss: 0.025597  [  600/ 3440]
loss: 0.010282  [  700/ 3440]
loss: 0.008218  [  800/ 3440]
loss: 0.083486  [  900/ 3440]
loss: 0.004687  [ 1000/ 3440]
loss: 0.013264  [ 1100/ 3440]
loss: 0.006970  [ 1200/ 3440]
loss: 0.013131  [ 1300/ 3440]
loss: 0.019249  [ 1400/ 3440]
loss: 0.028559  [ 1500/ 3440]
loss: 0.008371  [ 1600/ 3440]
loss: 0.011491  [ 1700/ 3440]
loss: 0.017588  [ 1800/ 3440]
loss: 0.020488  [ 1900/ 3440]
loss: 0.016180  [ 2000/ 3440]
loss: 0.031032  [ 2100/ 3440]
loss: 0.009343  [ 2200/ 3440]
loss: 0.009971  [ 2300/ 3440]
loss: 0.020650  [ 2400/ 3440]
loss: 0.009964  [ 2500/ 3440]
loss: 0.011431  [ 2600/ 3440]
loss: 0.010744  [ 2700/ 3440]
loss: 0.022788  [ 2800/ 3440]
loss: 0.013012  [ 2900/ 3440]
loss: 0.004547  [ 3000/ 3440]
loss: 0.011435  [ 3100/ 3440]
loss: 0.014528  [ 3200/ 3440]
loss: 0.005237  [ 3300/ 3440]
loss: 0.009513  [ 3400/ 3440]
Epoch 6
-------------------------------
loss: 0.022136  [    0/ 3440]
loss: 0.015011  [  100/ 3440]
loss: 0.003235  [  200/ 3440]
loss: 0.008918  [  300/ 3440]
loss: 0.019773  [  400/ 3440]
loss: 0.084180  [  500/ 3440]
loss: 0.025033  [  600/ 3440]
loss: 0.010287  [  700/ 3440]
loss: 0.008269  [  800/ 3440]
loss: 0.083372  [  900/ 3440]
loss: 0.004635  [ 1000/ 3440]
loss: 0.013315  [ 1100/ 3440]
loss: 0.006961  [ 1200/ 3440]
loss: 0.013342  [ 1300/ 3440]
loss: 0.018630  [ 1400/ 3440]
loss: 0.028606  [ 1500/ 3440]
loss: 0.008082  [ 1600/ 3440]
loss: 0.011514  [ 1700/ 3440]
loss: 0.017689  [ 1800/ 3440]
loss: 0.020365  [ 1900/ 3440]
loss: 0.015455  [ 2000/ 3440]
loss: 0.031522  [ 2100/ 3440]
loss: 0.009137  [ 2200/ 3440]
loss: 0.009944  [ 2300/ 3440]
loss: 0.020749  [ 2400/ 3440]
loss: 0.009830  [ 2500/ 3440]
loss: 0.011459  [ 2600/ 3440]
loss: 0.010643  [ 2700/ 3440]
loss: 0.023295  [ 2800/ 3440]
loss: 0.013260  [ 2900/ 3440]
loss: 0.004538  [ 3000/ 3440]
loss: 0.011366  [ 3100/ 3440]
loss: 0.014417  [ 3200/ 3440]
loss: 0.005072  [ 3300/ 3440]
loss: 0.009395  [ 3400/ 3440]
Epoch 7
-------------------------------
loss: 0.021962  [    0/ 3440]
loss: 0.014934  [  100/ 3440]
loss: 0.003266  [  200/ 3440]
loss: 0.008785  [  300/ 3440]
loss: 0.019918  [  400/ 3440]
loss: 0.084323  [  500/ 3440]
loss: 0.024855  [  600/ 3440]
loss: 0.010244  [  700/ 3440]
loss: 0.008333  [  800/ 3440]
loss: 0.083193  [  900/ 3440]
loss: 0.004569  [ 1000/ 3440]
loss: 0.013329  [ 1100/ 3440]
loss: 0.006909  [ 1200/ 3440]
loss: 0.013541  [ 1300/ 3440]
loss: 0.018459  [ 1400/ 3440]
loss: 0.028613  [ 1500/ 3440]
loss: 0.007987  [ 1600/ 3440]
loss: 0.011513  [ 1700/ 3440]
loss: 0.017706  [ 1800/ 3440]
loss: 0.020437  [ 1900/ 3440]
loss: 0.014852  [ 2000/ 3440]
loss: 0.031443  [ 2100/ 3440]
loss: 0.008968  [ 2200/ 3440]
loss: 0.009934  [ 2300/ 3440]
loss: 0.020901  [ 2400/ 3440]
loss: 0.009899  [ 2500/ 3440]
loss: 0.011481  [ 2600/ 3440]
loss: 0.010598  [ 2700/ 3440]
loss: 0.023963  [ 2800/ 3440]
loss: 0.013480  [ 2900/ 3440]
loss: 0.004530  [ 3000/ 3440]
loss: 0.011246  [ 3100/ 3440]
loss: 0.014308  [ 3200/ 3440]
loss: 0.004938  [ 3300/ 3440]
loss: 0.009307  [ 3400/ 3440]
Epoch 8
-------------------------------
loss: 0.021958  [    0/ 3440]
loss: 0.014854  [  100/ 3440]
loss: 0.003242  [  200/ 3440]
loss: 0.008722  [  300/ 3440]
loss: 0.019896  [  400/ 3440]
loss: 0.084430  [  500/ 3440]
loss: 0.024745  [  600/ 3440]
loss: 0.010170  [  700/ 3440]
loss: 0.008296  [  800/ 3440]
loss: 0.082682  [  900/ 3440]
loss: 0.004580  [ 1000/ 3440]
loss: 0.013127  [ 1100/ 3440]
loss: 0.006789  [ 1200/ 3440]
loss: 0.013612  [ 1300/ 3440]
loss: 0.018133  [ 1400/ 3440]
loss: 0.028518  [ 1500/ 3440]
loss: 0.007907  [ 1600/ 3440]
loss: 0.011524  [ 1700/ 3440]
loss: 0.017739  [ 1800/ 3440]
loss: 0.020257  [ 1900/ 3440]
loss: 0.014309  [ 2000/ 3440]
loss: 0.031530  [ 2100/ 3440]
loss: 0.008918  [ 2200/ 3440]
loss: 0.010025  [ 2300/ 3440]
loss: 0.020982  [ 2400/ 3440]
loss: 0.010219  [ 2500/ 3440]
loss: 0.011439  [ 2600/ 3440]
loss: 0.010577  [ 2700/ 3440]
loss: 0.024239  [ 2800/ 3440]
loss: 0.013918  [ 2900/ 3440]
loss: 0.004580  [ 3000/ 3440]
loss: 0.011089  [ 3100/ 3440]
loss: 0.014428  [ 3200/ 3440]
loss: 0.004936  [ 3300/ 3440]
loss: 0.009263  [ 3400/ 3440]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3440
First Spike after testing: [-0.62647206 -0.9246826 ]
[1 2 1 ... 2 0 2]
[1 2 1 ... 2 0 2]
Cluster 0 Occurrences: 1142; KMEANS: 1180
Cluster 1 Occurrences: 1113; KMEANS: 1104
Cluster 2 Occurrences: 1185; KMEANS: 1156
Centroids: [[0.49503455, 0.45715278], [-0.75666916, -0.7887406], [-0.015605231, 0.21101335]]
Centroids: [[0.54521906, 0.42199597], [-0.775409, -0.80668217], [-0.07149002, 0.24815992]]
Contingency Matrix: 
[[1007    3  132]
 [  10 1096    7]
 [ 163    5 1017]]
[[1007, -1, 132], [-1, -1, -1], [163, -1, 1017]]
[[1007, -1, -1], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 2: 2, 0: 0}
New Contingency Matrix: 
[[1007    3  132]
 [  10 1096    7]
 [ 163    5 1017]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1007, 1096, 1017], Sum: 3120
All_Elements: [1007, 3, 132, 10, 1096, 7, 163, 5, 1017], Sum: 3440
Accuracy: 0.9069767441860465
Done!
