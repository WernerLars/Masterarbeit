Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Easy2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_52_29
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000171E0AD2278>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81B128>
Epoch 1
-------------------------------
loss: 0.221904  [    0/ 3520]
loss: 0.043865  [  100/ 3520]
loss: 0.168320  [  200/ 3520]
loss: 0.018356  [  300/ 3520]
loss: 0.133828  [  400/ 3520]
loss: 0.285156  [  500/ 3520]
loss: 0.020979  [  600/ 3520]
loss: 0.025825  [  700/ 3520]
loss: 0.007745  [  800/ 3520]
loss: 0.020299  [  900/ 3520]
loss: 0.005569  [ 1000/ 3520]
loss: 0.024420  [ 1100/ 3520]
loss: 0.021858  [ 1200/ 3520]
loss: 0.027194  [ 1300/ 3520]
loss: 0.023955  [ 1400/ 3520]
loss: 0.012733  [ 1500/ 3520]
loss: 0.002545  [ 1600/ 3520]
loss: 0.005145  [ 1700/ 3520]
loss: 0.076245  [ 1800/ 3520]
loss: 0.007082  [ 1900/ 3520]
loss: 0.013343  [ 2000/ 3520]
loss: 0.007205  [ 2100/ 3520]
loss: 0.003431  [ 2200/ 3520]
loss: 0.065981  [ 2300/ 3520]
loss: 0.008104  [ 2400/ 3520]
loss: 0.011156  [ 2500/ 3520]
loss: 0.009896  [ 2600/ 3520]
loss: 0.004405  [ 2700/ 3520]
loss: 0.019563  [ 2800/ 3520]
loss: 0.007434  [ 2900/ 3520]
loss: 0.011595  [ 3000/ 3520]
loss: 0.009788  [ 3100/ 3520]
loss: 0.005976  [ 3200/ 3520]
loss: 0.003649  [ 3300/ 3520]
loss: 0.006076  [ 3400/ 3520]
loss: 0.010081  [ 3500/ 3520]
Epoch 2
-------------------------------
loss: 0.013037  [    0/ 3520]
loss: 0.002435  [  100/ 3520]
loss: 0.174062  [  200/ 3520]
loss: 0.006542  [  300/ 3520]
loss: 0.081640  [  400/ 3520]
loss: 0.100230  [  500/ 3520]
loss: 0.007359  [  600/ 3520]
loss: 0.007742  [  700/ 3520]
loss: 0.004555  [  800/ 3520]
loss: 0.007242  [  900/ 3520]
loss: 0.004043  [ 1000/ 3520]
loss: 0.008237  [ 1100/ 3520]
loss: 0.008938  [ 1200/ 3520]
loss: 0.012759  [ 1300/ 3520]
loss: 0.014093  [ 1400/ 3520]
loss: 0.001664  [ 1500/ 3520]
loss: 0.001971  [ 1600/ 3520]
loss: 0.002835  [ 1700/ 3520]
loss: 0.105173  [ 1800/ 3520]
loss: 0.006902  [ 1900/ 3520]
loss: 0.012392  [ 2000/ 3520]
loss: 0.006614  [ 2100/ 3520]
loss: 0.003104  [ 2200/ 3520]
loss: 0.058716  [ 2300/ 3520]
loss: 0.008074  [ 2400/ 3520]
loss: 0.010494  [ 2500/ 3520]
loss: 0.009381  [ 2600/ 3520]
loss: 0.003588  [ 2700/ 3520]
loss: 0.017400  [ 2800/ 3520]
loss: 0.004308  [ 2900/ 3520]
loss: 0.012096  [ 3000/ 3520]
loss: 0.004857  [ 3100/ 3520]
loss: 0.005799  [ 3200/ 3520]
loss: 0.003985  [ 3300/ 3520]
loss: 0.006337  [ 3400/ 3520]
loss: 0.008754  [ 3500/ 3520]
Epoch 3
-------------------------------
loss: 0.010764  [    0/ 3520]
loss: 0.002324  [  100/ 3520]
loss: 0.162613  [  200/ 3520]
loss: 0.006100  [  300/ 3520]
loss: 0.072622  [  400/ 3520]
loss: 0.074107  [  500/ 3520]
loss: 0.006870  [  600/ 3520]
loss: 0.008591  [  700/ 3520]
loss: 0.003740  [  800/ 3520]
loss: 0.004801  [  900/ 3520]
loss: 0.004626  [ 1000/ 3520]
loss: 0.007955  [ 1100/ 3520]
loss: 0.009607  [ 1200/ 3520]
loss: 0.004860  [ 1300/ 3520]
loss: 0.012344  [ 1400/ 3520]
loss: 0.001639  [ 1500/ 3520]
loss: 0.002551  [ 1600/ 3520]
loss: 0.003728  [ 1700/ 3520]
loss: 0.126143  [ 1800/ 3520]
loss: 0.006546  [ 1900/ 3520]
loss: 0.011102  [ 2000/ 3520]
loss: 0.006626  [ 2100/ 3520]
loss: 0.004745  [ 2200/ 3520]
loss: 0.050696  [ 2300/ 3520]
loss: 0.009230  [ 2400/ 3520]
loss: 0.010622  [ 2500/ 3520]
loss: 0.009102  [ 2600/ 3520]
loss: 0.003037  [ 2700/ 3520]
loss: 0.015911  [ 2800/ 3520]
loss: 0.002531  [ 2900/ 3520]
loss: 0.012946  [ 3000/ 3520]
loss: 0.002675  [ 3100/ 3520]
loss: 0.006297  [ 3200/ 3520]
loss: 0.003739  [ 3300/ 3520]
loss: 0.006288  [ 3400/ 3520]
loss: 0.007533  [ 3500/ 3520]
Epoch 4
-------------------------------
loss: 0.009343  [    0/ 3520]
loss: 0.002238  [  100/ 3520]
loss: 0.148973  [  200/ 3520]
loss: 0.005598  [  300/ 3520]
loss: 0.063677  [  400/ 3520]
loss: 0.063973  [  500/ 3520]
loss: 0.006852  [  600/ 3520]
loss: 0.008979  [  700/ 3520]
loss: 0.003642  [  800/ 3520]
loss: 0.004252  [  900/ 3520]
loss: 0.004701  [ 1000/ 3520]
loss: 0.006919  [ 1100/ 3520]
loss: 0.009989  [ 1200/ 3520]
loss: 0.006790  [ 1300/ 3520]
loss: 0.012528  [ 1400/ 3520]
loss: 0.001589  [ 1500/ 3520]
loss: 0.002696  [ 1600/ 3520]
loss: 0.003881  [ 1700/ 3520]
loss: 0.120033  [ 1800/ 3520]
loss: 0.006194  [ 1900/ 3520]
loss: 0.010870  [ 2000/ 3520]
loss: 0.006638  [ 2100/ 3520]
loss: 0.005491  [ 2200/ 3520]
loss: 0.049384  [ 2300/ 3520]
loss: 0.009158  [ 2400/ 3520]
loss: 0.010284  [ 2500/ 3520]
loss: 0.009075  [ 2600/ 3520]
loss: 0.003040  [ 2700/ 3520]
loss: 0.016216  [ 2800/ 3520]
loss: 0.002461  [ 2900/ 3520]
loss: 0.012061  [ 3000/ 3520]
loss: 0.002154  [ 3100/ 3520]
loss: 0.006124  [ 3200/ 3520]
loss: 0.003833  [ 3300/ 3520]
loss: 0.006579  [ 3400/ 3520]
loss: 0.007662  [ 3500/ 3520]
Epoch 5
-------------------------------
loss: 0.008846  [    0/ 3520]
loss: 0.002083  [  100/ 3520]
loss: 0.137245  [  200/ 3520]
loss: 0.005305  [  300/ 3520]
loss: 0.059120  [  400/ 3520]
loss: 0.062156  [  500/ 3520]
loss: 0.006982  [  600/ 3520]
loss: 0.009077  [  700/ 3520]
loss: 0.003803  [  800/ 3520]
loss: 0.004105  [  900/ 3520]
loss: 0.004557  [ 1000/ 3520]
loss: 0.006832  [ 1100/ 3520]
loss: 0.008837  [ 1200/ 3520]
loss: 0.007226  [ 1300/ 3520]
loss: 0.012442  [ 1400/ 3520]
loss: 0.001816  [ 1500/ 3520]
loss: 0.002954  [ 1600/ 3520]
loss: 0.004038  [ 1700/ 3520]
loss: 0.112055  [ 1800/ 3520]
loss: 0.006161  [ 1900/ 3520]
loss: 0.010851  [ 2000/ 3520]
loss: 0.006817  [ 2100/ 3520]
loss: 0.005938  [ 2200/ 3520]
loss: 0.050592  [ 2300/ 3520]
loss: 0.009054  [ 2400/ 3520]
loss: 0.010088  [ 2500/ 3520]
loss: 0.008363  [ 2600/ 3520]
loss: 0.003040  [ 2700/ 3520]
loss: 0.015621  [ 2800/ 3520]
loss: 0.002616  [ 2900/ 3520]
loss: 0.011540  [ 3000/ 3520]
loss: 0.002056  [ 3100/ 3520]
loss: 0.005934  [ 3200/ 3520]
loss: 0.004027  [ 3300/ 3520]
loss: 0.007307  [ 3400/ 3520]
loss: 0.007223  [ 3500/ 3520]
Epoch 6
-------------------------------
loss: 0.008695  [    0/ 3520]
loss: 0.002384  [  100/ 3520]
loss: 0.128114  [  200/ 3520]
loss: 0.004840  [  300/ 3520]
loss: 0.054688  [  400/ 3520]
loss: 0.060890  [  500/ 3520]
loss: 0.006763  [  600/ 3520]
loss: 0.009242  [  700/ 3520]
loss: 0.003763  [  800/ 3520]
loss: 0.003943  [  900/ 3520]
loss: 0.004488  [ 1000/ 3520]
loss: 0.006843  [ 1100/ 3520]
loss: 0.008346  [ 1200/ 3520]
loss: 0.006632  [ 1300/ 3520]
loss: 0.011920  [ 1400/ 3520]
loss: 0.001929  [ 1500/ 3520]
loss: 0.003161  [ 1600/ 3520]
loss: 0.004093  [ 1700/ 3520]
loss: 0.102587  [ 1800/ 3520]
loss: 0.006117  [ 1900/ 3520]
loss: 0.010656  [ 2000/ 3520]
loss: 0.006685  [ 2100/ 3520]
loss: 0.006222  [ 2200/ 3520]
loss: 0.053859  [ 2300/ 3520]
loss: 0.009053  [ 2400/ 3520]
loss: 0.009973  [ 2500/ 3520]
loss: 0.007927  [ 2600/ 3520]
loss: 0.003008  [ 2700/ 3520]
loss: 0.015335  [ 2800/ 3520]
loss: 0.002584  [ 2900/ 3520]
loss: 0.012038  [ 3000/ 3520]
loss: 0.002284  [ 3100/ 3520]
loss: 0.005908  [ 3200/ 3520]
loss: 0.004122  [ 3300/ 3520]
loss: 0.008056  [ 3400/ 3520]
loss: 0.006796  [ 3500/ 3520]
Epoch 7
-------------------------------
loss: 0.008660  [    0/ 3520]
loss: 0.002063  [  100/ 3520]
loss: 0.116270  [  200/ 3520]
loss: 0.004268  [  300/ 3520]
loss: 0.052007  [  400/ 3520]
loss: 0.060979  [  500/ 3520]
loss: 0.006761  [  600/ 3520]
loss: 0.009274  [  700/ 3520]
loss: 0.003782  [  800/ 3520]
loss: 0.003705  [  900/ 3520]
loss: 0.004482  [ 1000/ 3520]
loss: 0.006815  [ 1100/ 3520]
loss: 0.007477  [ 1200/ 3520]
loss: 0.006019  [ 1300/ 3520]
loss: 0.011162  [ 1400/ 3520]
loss: 0.001998  [ 1500/ 3520]
loss: 0.003215  [ 1600/ 3520]
loss: 0.004131  [ 1700/ 3520]
loss: 0.101925  [ 1800/ 3520]
loss: 0.006101  [ 1900/ 3520]
loss: 0.010530  [ 2000/ 3520]
loss: 0.006637  [ 2100/ 3520]
loss: 0.006297  [ 2200/ 3520]
loss: 0.054821  [ 2300/ 3520]
loss: 0.009197  [ 2400/ 3520]
loss: 0.009743  [ 2500/ 3520]
loss: 0.007591  [ 2600/ 3520]
loss: 0.003014  [ 2700/ 3520]
loss: 0.015325  [ 2800/ 3520]
loss: 0.002524  [ 2900/ 3520]
loss: 0.011305  [ 3000/ 3520]
loss: 0.002399  [ 3100/ 3520]
loss: 0.005894  [ 3200/ 3520]
loss: 0.003982  [ 3300/ 3520]
loss: 0.007963  [ 3400/ 3520]
loss: 0.006794  [ 3500/ 3520]
Epoch 8
-------------------------------
loss: 0.008769  [    0/ 3520]
loss: 0.001882  [  100/ 3520]
loss: 0.110350  [  200/ 3520]
loss: 0.003877  [  300/ 3520]
loss: 0.052545  [  400/ 3520]
loss: 0.061617  [  500/ 3520]
loss: 0.006687  [  600/ 3520]
loss: 0.009373  [  700/ 3520]
loss: 0.003757  [  800/ 3520]
loss: 0.003518  [  900/ 3520]
loss: 0.004539  [ 1000/ 3520]
loss: 0.006884  [ 1100/ 3520]
loss: 0.006727  [ 1200/ 3520]
loss: 0.005198  [ 1300/ 3520]
loss: 0.010589  [ 1400/ 3520]
loss: 0.001932  [ 1500/ 3520]
loss: 0.003166  [ 1600/ 3520]
loss: 0.003967  [ 1700/ 3520]
loss: 0.099083  [ 1800/ 3520]
loss: 0.005954  [ 1900/ 3520]
loss: 0.010467  [ 2000/ 3520]
loss: 0.006709  [ 2100/ 3520]
loss: 0.006260  [ 2200/ 3520]
loss: 0.055333  [ 2300/ 3520]
loss: 0.009438  [ 2400/ 3520]
loss: 0.009653  [ 2500/ 3520]
loss: 0.007302  [ 2600/ 3520]
loss: 0.003015  [ 2700/ 3520]
loss: 0.015184  [ 2800/ 3520]
loss: 0.002456  [ 2900/ 3520]
loss: 0.011734  [ 3000/ 3520]
loss: 0.002446  [ 3100/ 3520]
loss: 0.005919  [ 3200/ 3520]
loss: 0.003975  [ 3300/ 3520]
loss: 0.008130  [ 3400/ 3520]
loss: 0.006295  [ 3500/ 3520]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3520
First Spike after testing: [1.1242735  0.46898606]
[0 1 2 ... 0 1 2]
[2 1 0 ... 2 1 0]
Cluster 0 Occurrences: 1160; KMEANS: 1214
Cluster 1 Occurrences: 1146; KMEANS: 1039
Cluster 2 Occurrences: 1214; KMEANS: 1267
Centroids: [[1.2100126, 0.6632501], [-0.21838896, 1.0790172], [0.064397894, -0.5737917]]
Centroids: [[0.07087506, -0.57558256], [-0.34667522, 1.1785074], [1.1883767, 0.6184914]]
Contingency Matrix: 
[[   0   29 1131]
 [   6 1006  134]
 [1208    4    2]]
[[-1, 29, 1131], [-1, 1006, 134], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1006, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1131   29    0]
 [ 134 1006    6]
 [   2    4 1208]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1131, 1006, 1208], Sum: 3345
All_Elements: [1131, 29, 0, 134, 1006, 6, 2, 4, 1208], Sum: 3520
Accuracy: 0.9502840909090909
Done!
