Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Difficult1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_57_36
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017209CFED30>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81B128>
Epoch 1
-------------------------------
loss: 0.150808  [    0/ 3448]
loss: 0.026047  [  100/ 3448]
loss: 0.021702  [  200/ 3448]
loss: 0.036151  [  300/ 3448]
loss: 0.019970  [  400/ 3448]
loss: 0.015654  [  500/ 3448]
loss: 0.020729  [  600/ 3448]
loss: 0.009426  [  700/ 3448]
loss: 0.013396  [  800/ 3448]
loss: 0.027070  [  900/ 3448]
loss: 0.087517  [ 1000/ 3448]
loss: 0.014829  [ 1100/ 3448]
loss: 0.009012  [ 1200/ 3448]
loss: 0.128967  [ 1300/ 3448]
loss: 0.009621  [ 1400/ 3448]
loss: 0.031684  [ 1500/ 3448]
loss: 0.020883  [ 1600/ 3448]
loss: 0.011584  [ 1700/ 3448]
loss: 0.007856  [ 1800/ 3448]
loss: 0.017974  [ 1900/ 3448]
loss: 0.008442  [ 2000/ 3448]
loss: 0.003894  [ 2100/ 3448]
loss: 0.004598  [ 2200/ 3448]
loss: 0.006728  [ 2300/ 3448]
loss: 0.009801  [ 2400/ 3448]
loss: 0.009390  [ 2500/ 3448]
loss: 0.012921  [ 2600/ 3448]
loss: 0.011085  [ 2700/ 3448]
loss: 0.006078  [ 2800/ 3448]
loss: 0.004442  [ 2900/ 3448]
loss: 0.004117  [ 3000/ 3448]
loss: 0.009490  [ 3100/ 3448]
loss: 0.013616  [ 3200/ 3448]
loss: 0.011273  [ 3300/ 3448]
loss: 0.006800  [ 3400/ 3448]
Epoch 2
-------------------------------
loss: 0.020064  [    0/ 3448]
loss: 0.007591  [  100/ 3448]
loss: 0.002250  [  200/ 3448]
loss: 0.005892  [  300/ 3448]
loss: 0.007536  [  400/ 3448]
loss: 0.012887  [  500/ 3448]
loss: 0.007132  [  600/ 3448]
loss: 0.007609  [  700/ 3448]
loss: 0.003987  [  800/ 3448]
loss: 0.006471  [  900/ 3448]
loss: 0.085872  [ 1000/ 3448]
loss: 0.014945  [ 1100/ 3448]
loss: 0.008453  [ 1200/ 3448]
loss: 0.125498  [ 1300/ 3448]
loss: 0.006284  [ 1400/ 3448]
loss: 0.022222  [ 1500/ 3448]
loss: 0.004382  [ 1600/ 3448]
loss: 0.010946  [ 1700/ 3448]
loss: 0.006508  [ 1800/ 3448]
loss: 0.018283  [ 1900/ 3448]
loss: 0.008553  [ 2000/ 3448]
loss: 0.003325  [ 2100/ 3448]
loss: 0.005066  [ 2200/ 3448]
loss: 0.005803  [ 2300/ 3448]
loss: 0.007537  [ 2400/ 3448]
loss: 0.008251  [ 2500/ 3448]
loss: 0.012726  [ 2600/ 3448]
loss: 0.009302  [ 2700/ 3448]
loss: 0.006457  [ 2800/ 3448]
loss: 0.002819  [ 2900/ 3448]
loss: 0.004044  [ 3000/ 3448]
loss: 0.012738  [ 3100/ 3448]
loss: 0.013264  [ 3200/ 3448]
loss: 0.010944  [ 3300/ 3448]
loss: 0.006672  [ 3400/ 3448]
Epoch 3
-------------------------------
loss: 0.020496  [    0/ 3448]
loss: 0.007933  [  100/ 3448]
loss: 0.001983  [  200/ 3448]
loss: 0.004137  [  300/ 3448]
loss: 0.006522  [  400/ 3448]
loss: 0.013382  [  500/ 3448]
loss: 0.006563  [  600/ 3448]
loss: 0.007832  [  700/ 3448]
loss: 0.003863  [  800/ 3448]
loss: 0.006100  [  900/ 3448]
loss: 0.085213  [ 1000/ 3448]
loss: 0.014962  [ 1100/ 3448]
loss: 0.008551  [ 1200/ 3448]
loss: 0.125344  [ 1300/ 3448]
loss: 0.006425  [ 1400/ 3448]
loss: 0.021182  [ 1500/ 3448]
loss: 0.004000  [ 1600/ 3448]
loss: 0.011337  [ 1700/ 3448]
loss: 0.006992  [ 1800/ 3448]
loss: 0.018663  [ 1900/ 3448]
loss: 0.008503  [ 2000/ 3448]
loss: 0.003411  [ 2100/ 3448]
loss: 0.005078  [ 2200/ 3448]
loss: 0.005821  [ 2300/ 3448]
loss: 0.007585  [ 2400/ 3448]
loss: 0.008097  [ 2500/ 3448]
loss: 0.012745  [ 2600/ 3448]
loss: 0.009253  [ 2700/ 3448]
loss: 0.006602  [ 2800/ 3448]
loss: 0.002708  [ 2900/ 3448]
loss: 0.003963  [ 3000/ 3448]
loss: 0.013182  [ 3100/ 3448]
loss: 0.013228  [ 3200/ 3448]
loss: 0.010914  [ 3300/ 3448]
loss: 0.006676  [ 3400/ 3448]
Epoch 4
-------------------------------
loss: 0.020239  [    0/ 3448]
loss: 0.007775  [  100/ 3448]
loss: 0.001994  [  200/ 3448]
loss: 0.004127  [  300/ 3448]
loss: 0.006632  [  400/ 3448]
loss: 0.013451  [  500/ 3448]
loss: 0.006501  [  600/ 3448]
loss: 0.007841  [  700/ 3448]
loss: 0.003848  [  800/ 3448]
loss: 0.006161  [  900/ 3448]
loss: 0.085278  [ 1000/ 3448]
loss: 0.014958  [ 1100/ 3448]
loss: 0.008464  [ 1200/ 3448]
loss: 0.125123  [ 1300/ 3448]
loss: 0.006443  [ 1400/ 3448]
loss: 0.020982  [ 1500/ 3448]
loss: 0.003939  [ 1600/ 3448]
loss: 0.011247  [ 1700/ 3448]
loss: 0.007171  [ 1800/ 3448]
loss: 0.016988  [ 1900/ 3448]
loss: 0.008482  [ 2000/ 3448]
loss: 0.003428  [ 2100/ 3448]
loss: 0.005068  [ 2200/ 3448]
loss: 0.005812  [ 2300/ 3448]
loss: 0.007468  [ 2400/ 3448]
loss: 0.008081  [ 2500/ 3448]
loss: 0.012744  [ 2600/ 3448]
loss: 0.009286  [ 2700/ 3448]
loss: 0.006664  [ 2800/ 3448]
loss: 0.002640  [ 2900/ 3448]
loss: 0.003892  [ 3000/ 3448]
loss: 0.013282  [ 3100/ 3448]
loss: 0.013038  [ 3200/ 3448]
loss: 0.010955  [ 3300/ 3448]
loss: 0.006688  [ 3400/ 3448]
Epoch 5
-------------------------------
loss: 0.020084  [    0/ 3448]
loss: 0.007722  [  100/ 3448]
loss: 0.001959  [  200/ 3448]
loss: 0.003807  [  300/ 3448]
loss: 0.006657  [  400/ 3448]
loss: 0.013182  [  500/ 3448]
loss: 0.006499  [  600/ 3448]
loss: 0.007929  [  700/ 3448]
loss: 0.003811  [  800/ 3448]
loss: 0.006086  [  900/ 3448]
loss: 0.084072  [ 1000/ 3448]
loss: 0.015140  [ 1100/ 3448]
loss: 0.008352  [ 1200/ 3448]
loss: 0.125102  [ 1300/ 3448]
loss: 0.006315  [ 1400/ 3448]
loss: 0.020831  [ 1500/ 3448]
loss: 0.003934  [ 1600/ 3448]
loss: 0.011046  [ 1700/ 3448]
loss: 0.007332  [ 1800/ 3448]
loss: 0.016894  [ 1900/ 3448]
loss: 0.008492  [ 2000/ 3448]
loss: 0.003368  [ 2100/ 3448]
loss: 0.004805  [ 2200/ 3448]
loss: 0.005809  [ 2300/ 3448]
loss: 0.008002  [ 2400/ 3448]
loss: 0.007914  [ 2500/ 3448]
loss: 0.012696  [ 2600/ 3448]
loss: 0.009329  [ 2700/ 3448]
loss: 0.006680  [ 2800/ 3448]
loss: 0.002543  [ 2900/ 3448]
loss: 0.003890  [ 3000/ 3448]
loss: 0.013554  [ 3100/ 3448]
loss: 0.012098  [ 3200/ 3448]
loss: 0.011188  [ 3300/ 3448]
loss: 0.006646  [ 3400/ 3448]
Epoch 6
-------------------------------
loss: 0.020011  [    0/ 3448]
loss: 0.007847  [  100/ 3448]
loss: 0.002070  [  200/ 3448]
loss: 0.003792  [  300/ 3448]
loss: 0.006732  [  400/ 3448]
loss: 0.013181  [  500/ 3448]
loss: 0.006507  [  600/ 3448]
loss: 0.008025  [  700/ 3448]
loss: 0.003781  [  800/ 3448]
loss: 0.005858  [  900/ 3448]
loss: 0.083386  [ 1000/ 3448]
loss: 0.015197  [ 1100/ 3448]
loss: 0.008101  [ 1200/ 3448]
loss: 0.125235  [ 1300/ 3448]
loss: 0.005979  [ 1400/ 3448]
loss: 0.020535  [ 1500/ 3448]
loss: 0.004049  [ 1600/ 3448]
loss: 0.010595  [ 1700/ 3448]
loss: 0.007509  [ 1800/ 3448]
loss: 0.016876  [ 1900/ 3448]
loss: 0.008537  [ 2000/ 3448]
loss: 0.003176  [ 2100/ 3448]
loss: 0.004595  [ 2200/ 3448]
loss: 0.005847  [ 2300/ 3448]
loss: 0.008106  [ 2400/ 3448]
loss: 0.007758  [ 2500/ 3448]
loss: 0.012737  [ 2600/ 3448]
loss: 0.009631  [ 2700/ 3448]
loss: 0.006706  [ 2800/ 3448]
loss: 0.002389  [ 2900/ 3448]
loss: 0.004005  [ 3000/ 3448]
loss: 0.013470  [ 3100/ 3448]
loss: 0.012235  [ 3200/ 3448]
loss: 0.011677  [ 3300/ 3448]
loss: 0.006519  [ 3400/ 3448]
Epoch 7
-------------------------------
loss: 0.019954  [    0/ 3448]
loss: 0.007913  [  100/ 3448]
loss: 0.002534  [  200/ 3448]
loss: 0.003855  [  300/ 3448]
loss: 0.006459  [  400/ 3448]
loss: 0.013030  [  500/ 3448]
loss: 0.006576  [  600/ 3448]
loss: 0.007878  [  700/ 3448]
loss: 0.003743  [  800/ 3448]
loss: 0.005653  [  900/ 3448]
loss: 0.084213  [ 1000/ 3448]
loss: 0.015392  [ 1100/ 3448]
loss: 0.007515  [ 1200/ 3448]
loss: 0.124975  [ 1300/ 3448]
loss: 0.005757  [ 1400/ 3448]
loss: 0.020915  [ 1500/ 3448]
loss: 0.003973  [ 1600/ 3448]
loss: 0.009953  [ 1700/ 3448]
loss: 0.007189  [ 1800/ 3448]
loss: 0.016955  [ 1900/ 3448]
loss: 0.008605  [ 2000/ 3448]
loss: 0.002962  [ 2100/ 3448]
loss: 0.004364  [ 2200/ 3448]
loss: 0.006057  [ 2300/ 3448]
loss: 0.007318  [ 2400/ 3448]
loss: 0.007817  [ 2500/ 3448]
loss: 0.012771  [ 2600/ 3448]
loss: 0.009885  [ 2700/ 3448]
loss: 0.006777  [ 2800/ 3448]
loss: 0.002341  [ 2900/ 3448]
loss: 0.003962  [ 3000/ 3448]
loss: 0.013214  [ 3100/ 3448]
loss: 0.011569  [ 3200/ 3448]
loss: 0.011934  [ 3300/ 3448]
loss: 0.006071  [ 3400/ 3448]
Epoch 8
-------------------------------
loss: 0.019779  [    0/ 3448]
loss: 0.007882  [  100/ 3448]
loss: 0.002916  [  200/ 3448]
loss: 0.004002  [  300/ 3448]
loss: 0.005778  [  400/ 3448]
loss: 0.012607  [  500/ 3448]
loss: 0.006758  [  600/ 3448]
loss: 0.007541  [  700/ 3448]
loss: 0.003729  [  800/ 3448]
loss: 0.005265  [  900/ 3448]
loss: 0.084655  [ 1000/ 3448]
loss: 0.015737  [ 1100/ 3448]
loss: 0.006787  [ 1200/ 3448]
loss: 0.125014  [ 1300/ 3448]
loss: 0.005467  [ 1400/ 3448]
loss: 0.021643  [ 1500/ 3448]
loss: 0.003964  [ 1600/ 3448]
loss: 0.008827  [ 1700/ 3448]
loss: 0.006629  [ 1800/ 3448]
loss: 0.018435  [ 1900/ 3448]
loss: 0.008571  [ 2000/ 3448]
loss: 0.002644  [ 2100/ 3448]
loss: 0.003979  [ 2200/ 3448]
loss: 0.006237  [ 2300/ 3448]
loss: 0.008078  [ 2400/ 3448]
loss: 0.008067  [ 2500/ 3448]
loss: 0.012576  [ 2600/ 3448]
loss: 0.010203  [ 2700/ 3448]
loss: 0.006674  [ 2800/ 3448]
loss: 0.002253  [ 2900/ 3448]
loss: 0.004004  [ 3000/ 3448]
loss: 0.013153  [ 3100/ 3448]
loss: 0.010315  [ 3200/ 3448]
loss: 0.012094  [ 3300/ 3448]
loss: 0.005671  [ 3400/ 3448]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3448
First Spike after testing: [0.6327497  0.32968986]
[2 2 2 ... 1 0 2]
[1 1 1 ... 0 2 1]
Cluster 0 Occurrences: 1164; KMEANS: 1175
Cluster 1 Occurrences: 1155; KMEANS: 1111
Cluster 2 Occurrences: 1129; KMEANS: 1162
Centroids: [[0.52203727, 0.052621722], [0.14957224, 0.67446715], [0.5987197, 0.6350605]]
Centroids: [[0.1278955, 0.7570505], [0.6172917, 0.5668338], [0.5337982, 0.032665897]]
Contingency Matrix: 
[[  16   41 1107]
 [ 968  166   21]
 [ 191  904   34]]
[[-1, -1, -1], [968, 166, -1], [191, 904, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, 904, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 1: 0, 2: 1}
New Contingency Matrix: 
[[1107   16   41]
 [  21  968  166]
 [  34  191  904]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1107, 968, 904], Sum: 2979
All_Elements: [1107, 16, 41, 21, 968, 166, 34, 191, 904], Sum: 3448
Accuracy: 0.8639791183294664
Done!
