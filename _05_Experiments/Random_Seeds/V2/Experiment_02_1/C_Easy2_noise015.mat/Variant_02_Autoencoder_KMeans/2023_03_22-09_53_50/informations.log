Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_53_50
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000171D9DE32B0>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81BEB8>
Epoch 1
-------------------------------
loss: 0.296830  [    0/ 3411]
loss: 0.096528  [  100/ 3411]
loss: 0.169037  [  200/ 3411]
loss: 0.020607  [  300/ 3411]
loss: 0.049595  [  400/ 3411]
loss: 0.028577  [  500/ 3411]
loss: 0.048562  [  600/ 3411]
loss: 0.048166  [  700/ 3411]
loss: 0.034468  [  800/ 3411]
loss: 0.052355  [  900/ 3411]
loss: 0.005005  [ 1000/ 3411]
loss: 0.051323  [ 1100/ 3411]
loss: 0.020585  [ 1200/ 3411]
loss: 0.035804  [ 1300/ 3411]
loss: 0.023063  [ 1400/ 3411]
loss: 0.072299  [ 1500/ 3411]
loss: 0.034408  [ 1600/ 3411]
loss: 0.023829  [ 1700/ 3411]
loss: 0.022256  [ 1800/ 3411]
loss: 0.003542  [ 1900/ 3411]
loss: 0.035270  [ 2000/ 3411]
loss: 0.008936  [ 2100/ 3411]
loss: 0.008755  [ 2200/ 3411]
loss: 0.147590  [ 2300/ 3411]
loss: 0.013701  [ 2400/ 3411]
loss: 0.005148  [ 2500/ 3411]
loss: 0.016990  [ 2600/ 3411]
loss: 0.009421  [ 2700/ 3411]
loss: 0.033336  [ 2800/ 3411]
loss: 0.016624  [ 2900/ 3411]
loss: 0.004465  [ 3000/ 3411]
loss: 0.005576  [ 3100/ 3411]
loss: 0.022867  [ 3200/ 3411]
loss: 0.014403  [ 3300/ 3411]
loss: 0.012034  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.023275  [    0/ 3411]
loss: 0.014797  [  100/ 3411]
loss: 0.011931  [  200/ 3411]
loss: 0.015909  [  300/ 3411]
loss: 0.016916  [  400/ 3411]
loss: 0.013339  [  500/ 3411]
loss: 0.004498  [  600/ 3411]
loss: 0.021155  [  700/ 3411]
loss: 0.024142  [  800/ 3411]
loss: 0.017856  [  900/ 3411]
loss: 0.004365  [ 1000/ 3411]
loss: 0.029390  [ 1100/ 3411]
loss: 0.019572  [ 1200/ 3411]
loss: 0.014728  [ 1300/ 3411]
loss: 0.019363  [ 1400/ 3411]
loss: 0.061969  [ 1500/ 3411]
loss: 0.029590  [ 1600/ 3411]
loss: 0.026021  [ 1700/ 3411]
loss: 0.025356  [ 1800/ 3411]
loss: 0.003496  [ 1900/ 3411]
loss: 0.033167  [ 2000/ 3411]
loss: 0.007839  [ 2100/ 3411]
loss: 0.008048  [ 2200/ 3411]
loss: 0.149553  [ 2300/ 3411]
loss: 0.017789  [ 2400/ 3411]
loss: 0.005752  [ 2500/ 3411]
loss: 0.015362  [ 2600/ 3411]
loss: 0.009118  [ 2700/ 3411]
loss: 0.033522  [ 2800/ 3411]
loss: 0.014478  [ 2900/ 3411]
loss: 0.003590  [ 3000/ 3411]
loss: 0.005186  [ 3100/ 3411]
loss: 0.019764  [ 3200/ 3411]
loss: 0.013867  [ 3300/ 3411]
loss: 0.010670  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.025365  [    0/ 3411]
loss: 0.014459  [  100/ 3411]
loss: 0.010663  [  200/ 3411]
loss: 0.014455  [  300/ 3411]
loss: 0.013621  [  400/ 3411]
loss: 0.008128  [  500/ 3411]
loss: 0.004271  [  600/ 3411]
loss: 0.024414  [  700/ 3411]
loss: 0.021605  [  800/ 3411]
loss: 0.018173  [  900/ 3411]
loss: 0.004011  [ 1000/ 3411]
loss: 0.026423  [ 1100/ 3411]
loss: 0.021443  [ 1200/ 3411]
loss: 0.015710  [ 1300/ 3411]
loss: 0.022114  [ 1400/ 3411]
loss: 0.060748  [ 1500/ 3411]
loss: 0.028636  [ 1600/ 3411]
loss: 0.020378  [ 1700/ 3411]
loss: 0.022437  [ 1800/ 3411]
loss: 0.004023  [ 1900/ 3411]
loss: 0.033426  [ 2000/ 3411]
loss: 0.008318  [ 2100/ 3411]
loss: 0.007457  [ 2200/ 3411]
loss: 0.150949  [ 2300/ 3411]
loss: 0.015420  [ 2400/ 3411]
loss: 0.007327  [ 2500/ 3411]
loss: 0.016217  [ 2600/ 3411]
loss: 0.009115  [ 2700/ 3411]
loss: 0.030721  [ 2800/ 3411]
loss: 0.011643  [ 2900/ 3411]
loss: 0.003556  [ 3000/ 3411]
loss: 0.005742  [ 3100/ 3411]
loss: 0.018177  [ 3200/ 3411]
loss: 0.014195  [ 3300/ 3411]
loss: 0.009727  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.024188  [    0/ 3411]
loss: 0.012901  [  100/ 3411]
loss: 0.010841  [  200/ 3411]
loss: 0.014177  [  300/ 3411]
loss: 0.018433  [  400/ 3411]
loss: 0.006446  [  500/ 3411]
loss: 0.003814  [  600/ 3411]
loss: 0.024989  [  700/ 3411]
loss: 0.018414  [  800/ 3411]
loss: 0.017028  [  900/ 3411]
loss: 0.003821  [ 1000/ 3411]
loss: 0.021380  [ 1100/ 3411]
loss: 0.022259  [ 1200/ 3411]
loss: 0.013631  [ 1300/ 3411]
loss: 0.021408  [ 1400/ 3411]
loss: 0.060463  [ 1500/ 3411]
loss: 0.027604  [ 1600/ 3411]
loss: 0.018790  [ 1700/ 3411]
loss: 0.022570  [ 1800/ 3411]
loss: 0.004160  [ 1900/ 3411]
loss: 0.032034  [ 2000/ 3411]
loss: 0.008242  [ 2100/ 3411]
loss: 0.007389  [ 2200/ 3411]
loss: 0.150654  [ 2300/ 3411]
loss: 0.015597  [ 2400/ 3411]
loss: 0.007415  [ 2500/ 3411]
loss: 0.015511  [ 2600/ 3411]
loss: 0.008862  [ 2700/ 3411]
loss: 0.029138  [ 2800/ 3411]
loss: 0.011034  [ 2900/ 3411]
loss: 0.004066  [ 3000/ 3411]
loss: 0.006153  [ 3100/ 3411]
loss: 0.017326  [ 3200/ 3411]
loss: 0.013754  [ 3300/ 3411]
loss: 0.010007  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.023254  [    0/ 3411]
loss: 0.012597  [  100/ 3411]
loss: 0.010970  [  200/ 3411]
loss: 0.013674  [  300/ 3411]
loss: 0.018571  [  400/ 3411]
loss: 0.006569  [  500/ 3411]
loss: 0.003613  [  600/ 3411]
loss: 0.023643  [  700/ 3411]
loss: 0.020185  [  800/ 3411]
loss: 0.017735  [  900/ 3411]
loss: 0.003760  [ 1000/ 3411]
loss: 0.018327  [ 1100/ 3411]
loss: 0.022255  [ 1200/ 3411]
loss: 0.012885  [ 1300/ 3411]
loss: 0.020782  [ 1400/ 3411]
loss: 0.059849  [ 1500/ 3411]
loss: 0.027143  [ 1600/ 3411]
loss: 0.018543  [ 1700/ 3411]
loss: 0.023040  [ 1800/ 3411]
loss: 0.004111  [ 1900/ 3411]
loss: 0.029690  [ 2000/ 3411]
loss: 0.008131  [ 2100/ 3411]
loss: 0.007380  [ 2200/ 3411]
loss: 0.150096  [ 2300/ 3411]
loss: 0.016108  [ 2400/ 3411]
loss: 0.007792  [ 2500/ 3411]
loss: 0.015280  [ 2600/ 3411]
loss: 0.009044  [ 2700/ 3411]
loss: 0.028935  [ 2800/ 3411]
loss: 0.011440  [ 2900/ 3411]
loss: 0.004328  [ 3000/ 3411]
loss: 0.005533  [ 3100/ 3411]
loss: 0.015436  [ 3200/ 3411]
loss: 0.013281  [ 3300/ 3411]
loss: 0.010185  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.023007  [    0/ 3411]
loss: 0.012905  [  100/ 3411]
loss: 0.010971  [  200/ 3411]
loss: 0.013214  [  300/ 3411]
loss: 0.015997  [  400/ 3411]
loss: 0.007237  [  500/ 3411]
loss: 0.003501  [  600/ 3411]
loss: 0.022761  [  700/ 3411]
loss: 0.021690  [  800/ 3411]
loss: 0.018395  [  900/ 3411]
loss: 0.003768  [ 1000/ 3411]
loss: 0.016734  [ 1100/ 3411]
loss: 0.022596  [ 1200/ 3411]
loss: 0.012926  [ 1300/ 3411]
loss: 0.018403  [ 1400/ 3411]
loss: 0.059895  [ 1500/ 3411]
loss: 0.026402  [ 1600/ 3411]
loss: 0.017905  [ 1700/ 3411]
loss: 0.022913  [ 1800/ 3411]
loss: 0.004083  [ 1900/ 3411]
loss: 0.024805  [ 2000/ 3411]
loss: 0.008155  [ 2100/ 3411]
loss: 0.007373  [ 2200/ 3411]
loss: 0.150021  [ 2300/ 3411]
loss: 0.016280  [ 2400/ 3411]
loss: 0.007784  [ 2500/ 3411]
loss: 0.015132  [ 2600/ 3411]
loss: 0.009110  [ 2700/ 3411]
loss: 0.029171  [ 2800/ 3411]
loss: 0.011715  [ 2900/ 3411]
loss: 0.004665  [ 3000/ 3411]
loss: 0.005236  [ 3100/ 3411]
loss: 0.013352  [ 3200/ 3411]
loss: 0.013121  [ 3300/ 3411]
loss: 0.010412  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.023369  [    0/ 3411]
loss: 0.012741  [  100/ 3411]
loss: 0.011036  [  200/ 3411]
loss: 0.013315  [  300/ 3411]
loss: 0.014330  [  400/ 3411]
loss: 0.007565  [  500/ 3411]
loss: 0.003428  [  600/ 3411]
loss: 0.022502  [  700/ 3411]
loss: 0.021475  [  800/ 3411]
loss: 0.018778  [  900/ 3411]
loss: 0.003719  [ 1000/ 3411]
loss: 0.015467  [ 1100/ 3411]
loss: 0.023194  [ 1200/ 3411]
loss: 0.012841  [ 1300/ 3411]
loss: 0.017287  [ 1400/ 3411]
loss: 0.060212  [ 1500/ 3411]
loss: 0.025757  [ 1600/ 3411]
loss: 0.017598  [ 1700/ 3411]
loss: 0.022875  [ 1800/ 3411]
loss: 0.004096  [ 1900/ 3411]
loss: 0.021913  [ 2000/ 3411]
loss: 0.008121  [ 2100/ 3411]
loss: 0.007409  [ 2200/ 3411]
loss: 0.148294  [ 2300/ 3411]
loss: 0.016694  [ 2400/ 3411]
loss: 0.007780  [ 2500/ 3411]
loss: 0.015078  [ 2600/ 3411]
loss: 0.009291  [ 2700/ 3411]
loss: 0.029597  [ 2800/ 3411]
loss: 0.011602  [ 2900/ 3411]
loss: 0.004643  [ 3000/ 3411]
loss: 0.005244  [ 3100/ 3411]
loss: 0.012812  [ 3200/ 3411]
loss: 0.012920  [ 3300/ 3411]
loss: 0.010557  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.023186  [    0/ 3411]
loss: 0.012839  [  100/ 3411]
loss: 0.011016  [  200/ 3411]
loss: 0.013079  [  300/ 3411]
loss: 0.013419  [  400/ 3411]
loss: 0.007766  [  500/ 3411]
loss: 0.003409  [  600/ 3411]
loss: 0.022737  [  700/ 3411]
loss: 0.020497  [  800/ 3411]
loss: 0.018671  [  900/ 3411]
loss: 0.003681  [ 1000/ 3411]
loss: 0.015220  [ 1100/ 3411]
loss: 0.024044  [ 1200/ 3411]
loss: 0.012539  [ 1300/ 3411]
loss: 0.015952  [ 1400/ 3411]
loss: 0.060173  [ 1500/ 3411]
loss: 0.025123  [ 1600/ 3411]
loss: 0.017475  [ 1700/ 3411]
loss: 0.022854  [ 1800/ 3411]
loss: 0.004046  [ 1900/ 3411]
loss: 0.020845  [ 2000/ 3411]
loss: 0.008199  [ 2100/ 3411]
loss: 0.007392  [ 2200/ 3411]
loss: 0.149067  [ 2300/ 3411]
loss: 0.016745  [ 2400/ 3411]
loss: 0.007993  [ 2500/ 3411]
loss: 0.014891  [ 2600/ 3411]
loss: 0.009178  [ 2700/ 3411]
loss: 0.029510  [ 2800/ 3411]
loss: 0.011260  [ 2900/ 3411]
loss: 0.004842  [ 3000/ 3411]
loss: 0.005146  [ 3100/ 3411]
loss: 0.012497  [ 3200/ 3411]
loss: 0.012884  [ 3300/ 3411]
loss: 0.010663  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [1.2941916 0.6861702]
[0 2 0 ... 1 1 2]
[2 1 2 ... 0 0 1]
Cluster 0 Occurrences: 1181; KMEANS: 886
Cluster 1 Occurrences: 1098; KMEANS: 1141
Cluster 2 Occurrences: 1132; KMEANS: 1384
Centroids: [[1.0853465, 0.88285506], [-0.09205507, 1.0640272], [0.50229174, -0.6801854]]
Centroids: [[-0.30732992, 1.2151173], [0.50955105, -0.67788], [1.040613, 0.8221467]]
Contingency Matrix: 
[[  29    7 1145]
 [ 856    8  234]
 [   1 1126    5]]
[[-1, -1, -1], [856, 8, -1], [1, 1126, -1]]
[[-1, -1, -1], [856, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 2: 1, 1: 0}
New Contingency Matrix: 
[[1145   29    7]
 [ 234  856    8]
 [   5    1 1126]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1145, 856, 1126], Sum: 3127
All_Elements: [1145, 29, 7, 234, 856, 8, 5, 1, 1126], Sum: 3411
Accuracy: 0.9167399589563178
Done!
