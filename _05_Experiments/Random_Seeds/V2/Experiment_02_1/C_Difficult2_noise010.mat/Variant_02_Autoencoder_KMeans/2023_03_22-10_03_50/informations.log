Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_03_50
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001720FEEDB38>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81B128>
Epoch 1
-------------------------------
loss: 0.160396  [    0/ 3462]
loss: 0.095863  [  100/ 3462]
loss: 0.063854  [  200/ 3462]
loss: 0.037691  [  300/ 3462]
loss: 0.048851  [  400/ 3462]
loss: 0.018929  [  500/ 3462]
loss: 0.012582  [  600/ 3462]
loss: 0.015608  [  700/ 3462]
loss: 0.011388  [  800/ 3462]
loss: 0.015495  [  900/ 3462]
loss: 0.015865  [ 1000/ 3462]
loss: 0.056545  [ 1100/ 3462]
loss: 0.013219  [ 1200/ 3462]
loss: 0.004863  [ 1300/ 3462]
loss: 0.010856  [ 1400/ 3462]
loss: 0.009043  [ 1500/ 3462]
loss: 0.008746  [ 1600/ 3462]
loss: 0.004949  [ 1700/ 3462]
loss: 0.016004  [ 1800/ 3462]
loss: 0.007021  [ 1900/ 3462]
loss: 0.011425  [ 2000/ 3462]
loss: 0.052837  [ 2100/ 3462]
loss: 0.002816  [ 2200/ 3462]
loss: 0.006174  [ 2300/ 3462]
loss: 0.012646  [ 2400/ 3462]
loss: 0.006768  [ 2500/ 3462]
loss: 0.011775  [ 2600/ 3462]
loss: 0.007371  [ 2700/ 3462]
loss: 0.005690  [ 2800/ 3462]
loss: 0.015678  [ 2900/ 3462]
loss: 0.116516  [ 3000/ 3462]
loss: 0.006967  [ 3100/ 3462]
loss: 0.008400  [ 3200/ 3462]
loss: 0.138002  [ 3300/ 3462]
loss: 0.012051  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.001739  [    0/ 3462]
loss: 0.011727  [  100/ 3462]
loss: 0.012092  [  200/ 3462]
loss: 0.012147  [  300/ 3462]
loss: 0.009732  [  400/ 3462]
loss: 0.008776  [  500/ 3462]
loss: 0.003540  [  600/ 3462]
loss: 0.015884  [  700/ 3462]
loss: 0.009520  [  800/ 3462]
loss: 0.016908  [  900/ 3462]
loss: 0.010571  [ 1000/ 3462]
loss: 0.039664  [ 1100/ 3462]
loss: 0.013758  [ 1200/ 3462]
loss: 0.002968  [ 1300/ 3462]
loss: 0.006643  [ 1400/ 3462]
loss: 0.010058  [ 1500/ 3462]
loss: 0.008063  [ 1600/ 3462]
loss: 0.005053  [ 1700/ 3462]
loss: 0.015703  [ 1800/ 3462]
loss: 0.006803  [ 1900/ 3462]
loss: 0.009421  [ 2000/ 3462]
loss: 0.046898  [ 2100/ 3462]
loss: 0.002003  [ 2200/ 3462]
loss: 0.006311  [ 2300/ 3462]
loss: 0.012277  [ 2400/ 3462]
loss: 0.006914  [ 2500/ 3462]
loss: 0.010984  [ 2600/ 3462]
loss: 0.006648  [ 2700/ 3462]
loss: 0.004419  [ 2800/ 3462]
loss: 0.015267  [ 2900/ 3462]
loss: 0.116100  [ 3000/ 3462]
loss: 0.006587  [ 3100/ 3462]
loss: 0.008513  [ 3200/ 3462]
loss: 0.136632  [ 3300/ 3462]
loss: 0.012304  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.001583  [    0/ 3462]
loss: 0.012109  [  100/ 3462]
loss: 0.010393  [  200/ 3462]
loss: 0.010880  [  300/ 3462]
loss: 0.008939  [  400/ 3462]
loss: 0.007266  [  500/ 3462]
loss: 0.002070  [  600/ 3462]
loss: 0.018188  [  700/ 3462]
loss: 0.009226  [  800/ 3462]
loss: 0.017078  [  900/ 3462]
loss: 0.009375  [ 1000/ 3462]
loss: 0.036978  [ 1100/ 3462]
loss: 0.012369  [ 1200/ 3462]
loss: 0.003012  [ 1300/ 3462]
loss: 0.004511  [ 1400/ 3462]
loss: 0.010293  [ 1500/ 3462]
loss: 0.006927  [ 1600/ 3462]
loss: 0.005271  [ 1700/ 3462]
loss: 0.014123  [ 1800/ 3462]
loss: 0.005991  [ 1900/ 3462]
loss: 0.007108  [ 2000/ 3462]
loss: 0.048095  [ 2100/ 3462]
loss: 0.002002  [ 2200/ 3462]
loss: 0.006780  [ 2300/ 3462]
loss: 0.012339  [ 2400/ 3462]
loss: 0.006406  [ 2500/ 3462]
loss: 0.010219  [ 2600/ 3462]
loss: 0.006414  [ 2700/ 3462]
loss: 0.004507  [ 2800/ 3462]
loss: 0.014465  [ 2900/ 3462]
loss: 0.114234  [ 3000/ 3462]
loss: 0.006298  [ 3100/ 3462]
loss: 0.008692  [ 3200/ 3462]
loss: 0.134098  [ 3300/ 3462]
loss: 0.012761  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.001562  [    0/ 3462]
loss: 0.012391  [  100/ 3462]
loss: 0.008186  [  200/ 3462]
loss: 0.012000  [  300/ 3462]
loss: 0.008984  [  400/ 3462]
loss: 0.005791  [  500/ 3462]
loss: 0.001623  [  600/ 3462]
loss: 0.019227  [  700/ 3462]
loss: 0.009408  [  800/ 3462]
loss: 0.016888  [  900/ 3462]
loss: 0.008362  [ 1000/ 3462]
loss: 0.039389  [ 1100/ 3462]
loss: 0.011528  [ 1200/ 3462]
loss: 0.002960  [ 1300/ 3462]
loss: 0.003476  [ 1400/ 3462]
loss: 0.010834  [ 1500/ 3462]
loss: 0.005943  [ 1600/ 3462]
loss: 0.005279  [ 1700/ 3462]
loss: 0.012384  [ 1800/ 3462]
loss: 0.005478  [ 1900/ 3462]
loss: 0.005893  [ 2000/ 3462]
loss: 0.051973  [ 2100/ 3462]
loss: 0.002028  [ 2200/ 3462]
loss: 0.007019  [ 2300/ 3462]
loss: 0.012357  [ 2400/ 3462]
loss: 0.006168  [ 2500/ 3462]
loss: 0.009480  [ 2600/ 3462]
loss: 0.006243  [ 2700/ 3462]
loss: 0.004492  [ 2800/ 3462]
loss: 0.014005  [ 2900/ 3462]
loss: 0.112549  [ 3000/ 3462]
loss: 0.006181  [ 3100/ 3462]
loss: 0.008702  [ 3200/ 3462]
loss: 0.129366  [ 3300/ 3462]
loss: 0.012613  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.001584  [    0/ 3462]
loss: 0.012127  [  100/ 3462]
loss: 0.006426  [  200/ 3462]
loss: 0.013092  [  300/ 3462]
loss: 0.009112  [  400/ 3462]
loss: 0.004733  [  500/ 3462]
loss: 0.001499  [  600/ 3462]
loss: 0.019841  [  700/ 3462]
loss: 0.009556  [  800/ 3462]
loss: 0.017002  [  900/ 3462]
loss: 0.007808  [ 1000/ 3462]
loss: 0.039833  [ 1100/ 3462]
loss: 0.011134  [ 1200/ 3462]
loss: 0.002786  [ 1300/ 3462]
loss: 0.002968  [ 1400/ 3462]
loss: 0.011330  [ 1500/ 3462]
loss: 0.005171  [ 1600/ 3462]
loss: 0.005165  [ 1700/ 3462]
loss: 0.010927  [ 1800/ 3462]
loss: 0.005069  [ 1900/ 3462]
loss: 0.005150  [ 2000/ 3462]
loss: 0.055243  [ 2100/ 3462]
loss: 0.002032  [ 2200/ 3462]
loss: 0.007139  [ 2300/ 3462]
loss: 0.012425  [ 2400/ 3462]
loss: 0.006016  [ 2500/ 3462]
loss: 0.008642  [ 2600/ 3462]
loss: 0.006134  [ 2700/ 3462]
loss: 0.004665  [ 2800/ 3462]
loss: 0.013516  [ 2900/ 3462]
loss: 0.111207  [ 3000/ 3462]
loss: 0.006019  [ 3100/ 3462]
loss: 0.008628  [ 3200/ 3462]
loss: 0.125807  [ 3300/ 3462]
loss: 0.012661  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.001582  [    0/ 3462]
loss: 0.011998  [  100/ 3462]
loss: 0.005273  [  200/ 3462]
loss: 0.014019  [  300/ 3462]
loss: 0.009305  [  400/ 3462]
loss: 0.004147  [  500/ 3462]
loss: 0.001823  [  600/ 3462]
loss: 0.020023  [  700/ 3462]
loss: 0.009615  [  800/ 3462]
loss: 0.016867  [  900/ 3462]
loss: 0.007385  [ 1000/ 3462]
loss: 0.039568  [ 1100/ 3462]
loss: 0.010192  [ 1200/ 3462]
loss: 0.002594  [ 1300/ 3462]
loss: 0.002698  [ 1400/ 3462]
loss: 0.011760  [ 1500/ 3462]
loss: 0.004659  [ 1600/ 3462]
loss: 0.005058  [ 1700/ 3462]
loss: 0.010336  [ 1800/ 3462]
loss: 0.004781  [ 1900/ 3462]
loss: 0.004763  [ 2000/ 3462]
loss: 0.057864  [ 2100/ 3462]
loss: 0.002011  [ 2200/ 3462]
loss: 0.007159  [ 2300/ 3462]
loss: 0.012418  [ 2400/ 3462]
loss: 0.005906  [ 2500/ 3462]
loss: 0.008086  [ 2600/ 3462]
loss: 0.006032  [ 2700/ 3462]
loss: 0.004871  [ 2800/ 3462]
loss: 0.013224  [ 2900/ 3462]
loss: 0.110568  [ 3000/ 3462]
loss: 0.005922  [ 3100/ 3462]
loss: 0.008567  [ 3200/ 3462]
loss: 0.123745  [ 3300/ 3462]
loss: 0.012617  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.001569  [    0/ 3462]
loss: 0.011933  [  100/ 3462]
loss: 0.004634  [  200/ 3462]
loss: 0.014874  [  300/ 3462]
loss: 0.009296  [  400/ 3462]
loss: 0.003535  [  500/ 3462]
loss: 0.002062  [  600/ 3462]
loss: 0.019929  [  700/ 3462]
loss: 0.009675  [  800/ 3462]
loss: 0.016755  [  900/ 3462]
loss: 0.007140  [ 1000/ 3462]
loss: 0.039361  [ 1100/ 3462]
loss: 0.010114  [ 1200/ 3462]
loss: 0.002468  [ 1300/ 3462]
loss: 0.002504  [ 1400/ 3462]
loss: 0.011851  [ 1500/ 3462]
loss: 0.004282  [ 1600/ 3462]
loss: 0.004969  [ 1700/ 3462]
loss: 0.009469  [ 1800/ 3462]
loss: 0.004600  [ 1900/ 3462]
loss: 0.004556  [ 2000/ 3462]
loss: 0.059321  [ 2100/ 3462]
loss: 0.001969  [ 2200/ 3462]
loss: 0.007164  [ 2300/ 3462]
loss: 0.012402  [ 2400/ 3462]
loss: 0.005765  [ 2500/ 3462]
loss: 0.007575  [ 2600/ 3462]
loss: 0.005951  [ 2700/ 3462]
loss: 0.004946  [ 2800/ 3462]
loss: 0.013024  [ 2900/ 3462]
loss: 0.109993  [ 3000/ 3462]
loss: 0.005848  [ 3100/ 3462]
loss: 0.008471  [ 3200/ 3462]
loss: 0.121126  [ 3300/ 3462]
loss: 0.012477  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.001568  [    0/ 3462]
loss: 0.011918  [  100/ 3462]
loss: 0.004235  [  200/ 3462]
loss: 0.015263  [  300/ 3462]
loss: 0.009399  [  400/ 3462]
loss: 0.003210  [  500/ 3462]
loss: 0.002223  [  600/ 3462]
loss: 0.019870  [  700/ 3462]
loss: 0.009614  [  800/ 3462]
loss: 0.016641  [  900/ 3462]
loss: 0.006921  [ 1000/ 3462]
loss: 0.039265  [ 1100/ 3462]
loss: 0.009824  [ 1200/ 3462]
loss: 0.002346  [ 1300/ 3462]
loss: 0.002366  [ 1400/ 3462]
loss: 0.011891  [ 1500/ 3462]
loss: 0.003989  [ 1600/ 3462]
loss: 0.004907  [ 1700/ 3462]
loss: 0.009015  [ 1800/ 3462]
loss: 0.004383  [ 1900/ 3462]
loss: 0.004397  [ 2000/ 3462]
loss: 0.060026  [ 2100/ 3462]
loss: 0.001921  [ 2200/ 3462]
loss: 0.007164  [ 2300/ 3462]
loss: 0.012331  [ 2400/ 3462]
loss: 0.005669  [ 2500/ 3462]
loss: 0.007289  [ 2600/ 3462]
loss: 0.005880  [ 2700/ 3462]
loss: 0.004900  [ 2800/ 3462]
loss: 0.012979  [ 2900/ 3462]
loss: 0.109465  [ 3000/ 3462]
loss: 0.005754  [ 3100/ 3462]
loss: 0.008381  [ 3200/ 3462]
loss: 0.119701  [ 3300/ 3462]
loss: 0.012364  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [0.945541   0.16749285]
[0 2 2 ... 0 1 2]
[0 2 2 ... 0 1 2]
Cluster 0 Occurrences: 1187; KMEANS: 1194
Cluster 1 Occurrences: 1136; KMEANS: 1138
Cluster 2 Occurrences: 1139; KMEANS: 1130
Centroids: [[0.9844336, 0.06854218], [-0.9420997, 1.0950023], [0.43937898, 0.54932034]]
Centroids: [[0.9994078, 0.05521476], [-0.94730467, 1.1002271], [0.42786714, 0.5601532]]
Contingency Matrix: 
[[1156    2   29]
 [   3 1128    5]
 [  35    8 1096]]
[[-1, -1, -1], [-1, 1128, 5], [-1, 8, 1096]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 1096]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[1156    2   29]
 [   3 1128    5]
 [  35    8 1096]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1156, 1128, 1096], Sum: 3380
All_Elements: [1156, 2, 29, 3, 1128, 5, 35, 8, 1096], Sum: 3462
Accuracy: 0.97631426920855
Done!
