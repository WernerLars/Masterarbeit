Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Drift_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_09_17
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001721BFA96A0>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
<torch.utils.data.dataloader.DataLoader object at 0x0000017209A177F0>
Epoch 1
-------------------------------
loss: 0.185668  [    0/ 3444]
loss: 0.059433  [  100/ 3444]
loss: 0.047963  [  200/ 3444]
loss: 0.023109  [  300/ 3444]
loss: 0.027964  [  400/ 3444]
loss: 0.020087  [  500/ 3444]
loss: 0.088601  [  600/ 3444]
loss: 0.025388  [  700/ 3444]
loss: 0.006382  [  800/ 3444]
loss: 0.023920  [  900/ 3444]
loss: 0.010138  [ 1000/ 3444]
loss: 0.016670  [ 1100/ 3444]
loss: 0.007438  [ 1200/ 3444]
loss: 0.026757  [ 1300/ 3444]
loss: 0.122575  [ 1400/ 3444]
loss: 0.008782  [ 1500/ 3444]
loss: 0.010753  [ 1600/ 3444]
loss: 0.009463  [ 1700/ 3444]
loss: 0.015987  [ 1800/ 3444]
loss: 0.009249  [ 1900/ 3444]
loss: 0.013361  [ 2000/ 3444]
loss: 0.020128  [ 2100/ 3444]
loss: 0.022695  [ 2200/ 3444]
loss: 0.015684  [ 2300/ 3444]
loss: 0.006470  [ 2400/ 3444]
loss: 0.007346  [ 2500/ 3444]
loss: 0.004426  [ 2600/ 3444]
loss: 0.003615  [ 2700/ 3444]
loss: 0.015194  [ 2800/ 3444]
loss: 0.009706  [ 2900/ 3444]
loss: 0.009636  [ 3000/ 3444]
loss: 0.063247  [ 3100/ 3444]
loss: 0.108592  [ 3200/ 3444]
loss: 0.009278  [ 3300/ 3444]
loss: 0.027281  [ 3400/ 3444]
Epoch 2
-------------------------------
loss: 0.016665  [    0/ 3444]
loss: 0.012776  [  100/ 3444]
loss: 0.007221  [  200/ 3444]
loss: 0.016157  [  300/ 3444]
loss: 0.016157  [  400/ 3444]
loss: 0.011144  [  500/ 3444]
loss: 0.036452  [  600/ 3444]
loss: 0.023025  [  700/ 3444]
loss: 0.006047  [  800/ 3444]
loss: 0.016804  [  900/ 3444]
loss: 0.010004  [ 1000/ 3444]
loss: 0.011797  [ 1100/ 3444]
loss: 0.003099  [ 1200/ 3444]
loss: 0.016214  [ 1300/ 3444]
loss: 0.114597  [ 1400/ 3444]
loss: 0.008512  [ 1500/ 3444]
loss: 0.010275  [ 1600/ 3444]
loss: 0.006780  [ 1700/ 3444]
loss: 0.014014  [ 1800/ 3444]
loss: 0.008994  [ 1900/ 3444]
loss: 0.011469  [ 2000/ 3444]
loss: 0.017221  [ 2100/ 3444]
loss: 0.017682  [ 2200/ 3444]
loss: 0.012558  [ 2300/ 3444]
loss: 0.006258  [ 2400/ 3444]
loss: 0.005297  [ 2500/ 3444]
loss: 0.004308  [ 2600/ 3444]
loss: 0.004526  [ 2700/ 3444]
loss: 0.014930  [ 2800/ 3444]
loss: 0.009964  [ 2900/ 3444]
loss: 0.009407  [ 3000/ 3444]
loss: 0.043267  [ 3100/ 3444]
loss: 0.104190  [ 3200/ 3444]
loss: 0.007204  [ 3300/ 3444]
loss: 0.026638  [ 3400/ 3444]
Epoch 3
-------------------------------
loss: 0.016098  [    0/ 3444]
loss: 0.012926  [  100/ 3444]
loss: 0.006879  [  200/ 3444]
loss: 0.016315  [  300/ 3444]
loss: 0.012934  [  400/ 3444]
loss: 0.008980  [  500/ 3444]
loss: 0.033769  [  600/ 3444]
loss: 0.023469  [  700/ 3444]
loss: 0.006970  [  800/ 3444]
loss: 0.017584  [  900/ 3444]
loss: 0.009851  [ 1000/ 3444]
loss: 0.011339  [ 1100/ 3444]
loss: 0.003162  [ 1200/ 3444]
loss: 0.014689  [ 1300/ 3444]
loss: 0.113454  [ 1400/ 3444]
loss: 0.008737  [ 1500/ 3444]
loss: 0.010047  [ 1600/ 3444]
loss: 0.006657  [ 1700/ 3444]
loss: 0.014559  [ 1800/ 3444]
loss: 0.009302  [ 1900/ 3444]
loss: 0.010903  [ 2000/ 3444]
loss: 0.016530  [ 2100/ 3444]
loss: 0.017022  [ 2200/ 3444]
loss: 0.012062  [ 2300/ 3444]
loss: 0.006130  [ 2400/ 3444]
loss: 0.004821  [ 2500/ 3444]
loss: 0.004431  [ 2600/ 3444]
loss: 0.005292  [ 2700/ 3444]
loss: 0.014932  [ 2800/ 3444]
loss: 0.010408  [ 2900/ 3444]
loss: 0.009302  [ 3000/ 3444]
loss: 0.039587  [ 3100/ 3444]
loss: 0.100877  [ 3200/ 3444]
loss: 0.007466  [ 3300/ 3444]
loss: 0.026879  [ 3400/ 3444]
Epoch 4
-------------------------------
loss: 0.015808  [    0/ 3444]
loss: 0.013633  [  100/ 3444]
loss: 0.006876  [  200/ 3444]
loss: 0.016535  [  300/ 3444]
loss: 0.011368  [  400/ 3444]
loss: 0.007888  [  500/ 3444]
loss: 0.033322  [  600/ 3444]
loss: 0.023727  [  700/ 3444]
loss: 0.007276  [  800/ 3444]
loss: 0.017662  [  900/ 3444]
loss: 0.009728  [ 1000/ 3444]
loss: 0.011065  [ 1100/ 3444]
loss: 0.003438  [ 1200/ 3444]
loss: 0.013510  [ 1300/ 3444]
loss: 0.114134  [ 1400/ 3444]
loss: 0.008558  [ 1500/ 3444]
loss: 0.010002  [ 1600/ 3444]
loss: 0.006745  [ 1700/ 3444]
loss: 0.015343  [ 1800/ 3444]
loss: 0.009462  [ 1900/ 3444]
loss: 0.011058  [ 2000/ 3444]
loss: 0.016084  [ 2100/ 3444]
loss: 0.017095  [ 2200/ 3444]
loss: 0.011765  [ 2300/ 3444]
loss: 0.005830  [ 2400/ 3444]
loss: 0.004504  [ 2500/ 3444]
loss: 0.004536  [ 2600/ 3444]
loss: 0.005434  [ 2700/ 3444]
loss: 0.015148  [ 2800/ 3444]
loss: 0.010852  [ 2900/ 3444]
loss: 0.009309  [ 3000/ 3444]
loss: 0.034463  [ 3100/ 3444]
loss: 0.101033  [ 3200/ 3444]
loss: 0.006928  [ 3300/ 3444]
loss: 0.026482  [ 3400/ 3444]
Epoch 5
-------------------------------
loss: 0.016001  [    0/ 3444]
loss: 0.013614  [  100/ 3444]
loss: 0.006842  [  200/ 3444]
loss: 0.016636  [  300/ 3444]
loss: 0.010680  [  400/ 3444]
loss: 0.007484  [  500/ 3444]
loss: 0.033169  [  600/ 3444]
loss: 0.024002  [  700/ 3444]
loss: 0.007279  [  800/ 3444]
loss: 0.017794  [  900/ 3444]
loss: 0.009776  [ 1000/ 3444]
loss: 0.010769  [ 1100/ 3444]
loss: 0.003635  [ 1200/ 3444]
loss: 0.013447  [ 1300/ 3444]
loss: 0.114819  [ 1400/ 3444]
loss: 0.008810  [ 1500/ 3444]
loss: 0.009991  [ 1600/ 3444]
loss: 0.006988  [ 1700/ 3444]
loss: 0.015839  [ 1800/ 3444]
loss: 0.009586  [ 1900/ 3444]
loss: 0.011077  [ 2000/ 3444]
loss: 0.016032  [ 2100/ 3444]
loss: 0.017141  [ 2200/ 3444]
loss: 0.011621  [ 2300/ 3444]
loss: 0.005638  [ 2400/ 3444]
loss: 0.004395  [ 2500/ 3444]
loss: 0.004547  [ 2600/ 3444]
loss: 0.005323  [ 2700/ 3444]
loss: 0.015122  [ 2800/ 3444]
loss: 0.011081  [ 2900/ 3444]
loss: 0.009229  [ 3000/ 3444]
loss: 0.031179  [ 3100/ 3444]
loss: 0.101582  [ 3200/ 3444]
loss: 0.006694  [ 3300/ 3444]
loss: 0.026204  [ 3400/ 3444]
Epoch 6
-------------------------------
loss: 0.016221  [    0/ 3444]
loss: 0.013178  [  100/ 3444]
loss: 0.006937  [  200/ 3444]
loss: 0.016665  [  300/ 3444]
loss: 0.010503  [  400/ 3444]
loss: 0.007367  [  500/ 3444]
loss: 0.032608  [  600/ 3444]
loss: 0.024085  [  700/ 3444]
loss: 0.007447  [  800/ 3444]
loss: 0.018126  [  900/ 3444]
loss: 0.009786  [ 1000/ 3444]
loss: 0.010690  [ 1100/ 3444]
loss: 0.003729  [ 1200/ 3444]
loss: 0.013122  [ 1300/ 3444]
loss: 0.115463  [ 1400/ 3444]
loss: 0.008721  [ 1500/ 3444]
loss: 0.009869  [ 1600/ 3444]
loss: 0.007271  [ 1700/ 3444]
loss: 0.016211  [ 1800/ 3444]
loss: 0.009531  [ 1900/ 3444]
loss: 0.010872  [ 2000/ 3444]
loss: 0.016015  [ 2100/ 3444]
loss: 0.017453  [ 2200/ 3444]
loss: 0.011584  [ 2300/ 3444]
loss: 0.005525  [ 2400/ 3444]
loss: 0.004284  [ 2500/ 3444]
loss: 0.004532  [ 2600/ 3444]
loss: 0.005244  [ 2700/ 3444]
loss: 0.015276  [ 2800/ 3444]
loss: 0.011319  [ 2900/ 3444]
loss: 0.009081  [ 3000/ 3444]
loss: 0.029267  [ 3100/ 3444]
loss: 0.102683  [ 3200/ 3444]
loss: 0.006575  [ 3300/ 3444]
loss: 0.025913  [ 3400/ 3444]
Epoch 7
-------------------------------
loss: 0.016374  [    0/ 3444]
loss: 0.013199  [  100/ 3444]
loss: 0.006816  [  200/ 3444]
loss: 0.016613  [  300/ 3444]
loss: 0.010530  [  400/ 3444]
loss: 0.007232  [  500/ 3444]
loss: 0.032100  [  600/ 3444]
loss: 0.025244  [  700/ 3444]
loss: 0.008019  [  800/ 3444]
loss: 0.017973  [  900/ 3444]
loss: 0.009805  [ 1000/ 3444]
loss: 0.010710  [ 1100/ 3444]
loss: 0.003839  [ 1200/ 3444]
loss: 0.013225  [ 1300/ 3444]
loss: 0.114737  [ 1400/ 3444]
loss: 0.008562  [ 1500/ 3444]
loss: 0.009851  [ 1600/ 3444]
loss: 0.007587  [ 1700/ 3444]
loss: 0.016829  [ 1800/ 3444]
loss: 0.009413  [ 1900/ 3444]
loss: 0.010791  [ 2000/ 3444]
loss: 0.016188  [ 2100/ 3444]
loss: 0.017907  [ 2200/ 3444]
loss: 0.011555  [ 2300/ 3444]
loss: 0.005411  [ 2400/ 3444]
loss: 0.004227  [ 2500/ 3444]
loss: 0.004425  [ 2600/ 3444]
loss: 0.005166  [ 2700/ 3444]
loss: 0.015250  [ 2800/ 3444]
loss: 0.011432  [ 2900/ 3444]
loss: 0.009147  [ 3000/ 3444]
loss: 0.027420  [ 3100/ 3444]
loss: 0.103824  [ 3200/ 3444]
loss: 0.006538  [ 3300/ 3444]
loss: 0.025597  [ 3400/ 3444]
Epoch 8
-------------------------------
loss: 0.016410  [    0/ 3444]
loss: 0.012957  [  100/ 3444]
loss: 0.006324  [  200/ 3444]
loss: 0.016663  [  300/ 3444]
loss: 0.009540  [  400/ 3444]
loss: 0.007272  [  500/ 3444]
loss: 0.031332  [  600/ 3444]
loss: 0.025015  [  700/ 3444]
loss: 0.007655  [  800/ 3444]
loss: 0.018299  [  900/ 3444]
loss: 0.009870  [ 1000/ 3444]
loss: 0.010589  [ 1100/ 3444]
loss: 0.003833  [ 1200/ 3444]
loss: 0.012934  [ 1300/ 3444]
loss: 0.115228  [ 1400/ 3444]
loss: 0.008440  [ 1500/ 3444]
loss: 0.009841  [ 1600/ 3444]
loss: 0.007657  [ 1700/ 3444]
loss: 0.017367  [ 1800/ 3444]
loss: 0.009222  [ 1900/ 3444]
loss: 0.010618  [ 2000/ 3444]
loss: 0.016063  [ 2100/ 3444]
loss: 0.017891  [ 2200/ 3444]
loss: 0.011654  [ 2300/ 3444]
loss: 0.005445  [ 2400/ 3444]
loss: 0.004253  [ 2500/ 3444]
loss: 0.004598  [ 2600/ 3444]
loss: 0.005119  [ 2700/ 3444]
loss: 0.015205  [ 2800/ 3444]
loss: 0.011566  [ 2900/ 3444]
loss: 0.009331  [ 3000/ 3444]
loss: 0.027164  [ 3100/ 3444]
loss: 0.104999  [ 3200/ 3444]
loss: 0.006615  [ 3300/ 3444]
loss: 0.025063  [ 3400/ 3444]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3444
First Spike after testing: [ 0.89552516 -0.30421782]
[2 2 0 ... 0 2 0]
[0 0 1 ... 1 0 1]
Cluster 0 Occurrences: 1142; KMEANS: 1116
Cluster 1 Occurrences: 1180; KMEANS: 1176
Cluster 2 Occurrences: 1122; KMEANS: 1152
Centroids: [[-0.5792994, 1.3173419], [0.07209474, 0.8563579], [0.9539941, -0.19087328]]
Centroids: [[0.9573151, -0.19626352], [-0.57502407, 1.3499503], [0.08833136, 0.8092323]]
Contingency Matrix: 
[[   0 1099   43]
 [   3   77 1100]
 [1113    0    9]]
[[-1, 1099, 43], [-1, 77, 1100], [-1, -1, -1]]
[[-1, 1099, -1], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 1: 2, 0: 1}
New Contingency Matrix: 
[[1099   43    0]
 [  77 1100    3]
 [   0    9 1113]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1099, 1100, 1113], Sum: 3312
All_Elements: [1099, 43, 0, 77, 1100, 3, 0, 9, 1113], Sum: 3444
Accuracy: 0.9616724738675958
Done!
