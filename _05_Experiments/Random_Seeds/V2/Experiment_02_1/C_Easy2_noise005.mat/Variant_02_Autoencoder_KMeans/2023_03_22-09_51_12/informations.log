Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Easy2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_51_12
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000171DAADBB70>
Sampling rate: 24000.0
Raw: [ 0.11862069  0.1123084   0.10401825 ... -0.10219323 -0.10268373
 -0.08956559]
Times: [    346     799    1005 ... 1436867 1437273 1437800]
Cluster: [3 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3410
First aligned Spike Frame: [ 2.05661766e-03  8.27536867e-03  1.66427268e-02  2.31246655e-02
  2.28936935e-02  1.99169368e-02  2.25281834e-02  3.37605443e-02
  4.94182133e-02  6.24484568e-02  8.42111946e-02  1.71357846e-01
  3.88441746e-01  6.99052305e-01  9.59509287e-01  1.03608873e+00
  9.29169963e-01  7.55567481e-01  6.10726415e-01  5.06818519e-01
  4.23878029e-01  3.55610047e-01  3.01970228e-01  2.53702042e-01
  1.98274486e-01  1.32802904e-01  6.40690121e-02  7.96454927e-04
 -5.66201776e-02 -1.11669131e-01 -1.62581026e-01 -2.01746625e-01
 -2.23071447e-01 -2.29516190e-01 -2.30160694e-01 -2.27148529e-01
 -2.18080531e-01 -2.04276810e-01 -1.90750996e-01 -1.81098693e-01
 -1.72421418e-01 -1.61640218e-01 -1.48460304e-01 -1.32332846e-01
 -1.13338953e-01 -9.43725979e-02 -7.56249106e-02]
Cluster 0, Occurrences: 1130
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1167
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81B5C0>
Epoch 1
-------------------------------
loss: 0.174595  [    0/ 3410]
loss: 0.083774  [  100/ 3410]
loss: 0.034129  [  200/ 3410]
loss: 0.093066  [  300/ 3410]
loss: 0.005797  [  400/ 3410]
loss: 0.008755  [  500/ 3410]
loss: 0.002232  [  600/ 3410]
loss: 0.003890  [  700/ 3410]
loss: 0.005181  [  800/ 3410]
loss: 0.008348  [  900/ 3410]
loss: 0.014973  [ 1000/ 3410]
loss: 0.002135  [ 1100/ 3410]
loss: 0.002294  [ 1200/ 3410]
loss: 0.005494  [ 1300/ 3410]
loss: 0.001793  [ 1400/ 3410]
loss: 0.002040  [ 1500/ 3410]
loss: 0.001363  [ 1600/ 3410]
loss: 0.007002  [ 1700/ 3410]
loss: 0.009733  [ 1800/ 3410]
loss: 0.001507  [ 1900/ 3410]
loss: 0.055110  [ 2000/ 3410]
loss: 0.003628  [ 2100/ 3410]
loss: 0.027692  [ 2200/ 3410]
loss: 0.002618  [ 2300/ 3410]
loss: 0.002355  [ 2400/ 3410]
loss: 0.114344  [ 2500/ 3410]
loss: 0.008582  [ 2600/ 3410]
loss: 0.003993  [ 2700/ 3410]
loss: 0.000820  [ 2800/ 3410]
loss: 0.007217  [ 2900/ 3410]
loss: 0.002235  [ 3000/ 3410]
loss: 0.001041  [ 3100/ 3410]
loss: 0.002638  [ 3200/ 3410]
loss: 0.001547  [ 3300/ 3410]
loss: 0.001233  [ 3400/ 3410]
Epoch 2
-------------------------------
loss: 0.000646  [    0/ 3410]
loss: 0.003290  [  100/ 3410]
loss: 0.005720  [  200/ 3410]
loss: 0.002987  [  300/ 3410]
loss: 0.002506  [  400/ 3410]
loss: 0.005162  [  500/ 3410]
loss: 0.001359  [  600/ 3410]
loss: 0.005434  [  700/ 3410]
loss: 0.003375  [  800/ 3410]
loss: 0.002370  [  900/ 3410]
loss: 0.006300  [ 1000/ 3410]
loss: 0.002807  [ 1100/ 3410]
loss: 0.001931  [ 1200/ 3410]
loss: 0.005633  [ 1300/ 3410]
loss: 0.001831  [ 1400/ 3410]
loss: 0.001794  [ 1500/ 3410]
loss: 0.001321  [ 1600/ 3410]
loss: 0.004969  [ 1700/ 3410]
loss: 0.006751  [ 1800/ 3410]
loss: 0.001279  [ 1900/ 3410]
loss: 0.054907  [ 2000/ 3410]
loss: 0.002915  [ 2100/ 3410]
loss: 0.027368  [ 2200/ 3410]
loss: 0.002240  [ 2300/ 3410]
loss: 0.001703  [ 2400/ 3410]
loss: 0.101292  [ 2500/ 3410]
loss: 0.007272  [ 2600/ 3410]
loss: 0.003995  [ 2700/ 3410]
loss: 0.000684  [ 2800/ 3410]
loss: 0.006758  [ 2900/ 3410]
loss: 0.002199  [ 3000/ 3410]
loss: 0.000999  [ 3100/ 3410]
loss: 0.002396  [ 3200/ 3410]
loss: 0.001472  [ 3300/ 3410]
loss: 0.001397  [ 3400/ 3410]
Epoch 3
-------------------------------
loss: 0.000475  [    0/ 3410]
loss: 0.003008  [  100/ 3410]
loss: 0.004947  [  200/ 3410]
loss: 0.003056  [  300/ 3410]
loss: 0.002414  [  400/ 3410]
loss: 0.005485  [  500/ 3410]
loss: 0.001225  [  600/ 3410]
loss: 0.005565  [  700/ 3410]
loss: 0.003075  [  800/ 3410]
loss: 0.002315  [  900/ 3410]
loss: 0.006066  [ 1000/ 3410]
loss: 0.002703  [ 1100/ 3410]
loss: 0.001657  [ 1200/ 3410]
loss: 0.005325  [ 1300/ 3410]
loss: 0.001716  [ 1400/ 3410]
loss: 0.001730  [ 1500/ 3410]
loss: 0.001317  [ 1600/ 3410]
loss: 0.004965  [ 1700/ 3410]
loss: 0.007041  [ 1800/ 3410]
loss: 0.001259  [ 1900/ 3410]
loss: 0.053813  [ 2000/ 3410]
loss: 0.002885  [ 2100/ 3410]
loss: 0.027003  [ 2200/ 3410]
loss: 0.002123  [ 2300/ 3410]
loss: 0.001388  [ 2400/ 3410]
loss: 0.093008  [ 2500/ 3410]
loss: 0.005525  [ 2600/ 3410]
loss: 0.004013  [ 2700/ 3410]
loss: 0.000723  [ 2800/ 3410]
loss: 0.006439  [ 2900/ 3410]
loss: 0.002203  [ 3000/ 3410]
loss: 0.000994  [ 3100/ 3410]
loss: 0.002120  [ 3200/ 3410]
loss: 0.001424  [ 3300/ 3410]
loss: 0.001543  [ 3400/ 3410]
Epoch 4
-------------------------------
loss: 0.000399  [    0/ 3410]
loss: 0.002867  [  100/ 3410]
loss: 0.004824  [  200/ 3410]
loss: 0.003196  [  300/ 3410]
loss: 0.002383  [  400/ 3410]
loss: 0.004982  [  500/ 3410]
loss: 0.001123  [  600/ 3410]
loss: 0.005412  [  700/ 3410]
loss: 0.003007  [  800/ 3410]
loss: 0.002320  [  900/ 3410]
loss: 0.005653  [ 1000/ 3410]
loss: 0.002487  [ 1100/ 3410]
loss: 0.001402  [ 1200/ 3410]
loss: 0.005073  [ 1300/ 3410]
loss: 0.001595  [ 1400/ 3410]
loss: 0.001745  [ 1500/ 3410]
loss: 0.001300  [ 1600/ 3410]
loss: 0.004723  [ 1700/ 3410]
loss: 0.006610  [ 1800/ 3410]
loss: 0.001256  [ 1900/ 3410]
loss: 0.052584  [ 2000/ 3410]
loss: 0.002904  [ 2100/ 3410]
loss: 0.026602  [ 2200/ 3410]
loss: 0.002044  [ 2300/ 3410]
loss: 0.001183  [ 2400/ 3410]
loss: 0.086943  [ 2500/ 3410]
loss: 0.004531  [ 2600/ 3410]
loss: 0.004066  [ 2700/ 3410]
loss: 0.000778  [ 2800/ 3410]
loss: 0.006187  [ 2900/ 3410]
loss: 0.002228  [ 3000/ 3410]
loss: 0.000927  [ 3100/ 3410]
loss: 0.001722  [ 3200/ 3410]
loss: 0.001431  [ 3300/ 3410]
loss: 0.001626  [ 3400/ 3410]
Epoch 5
-------------------------------
loss: 0.000354  [    0/ 3410]
loss: 0.002825  [  100/ 3410]
loss: 0.004513  [  200/ 3410]
loss: 0.003348  [  300/ 3410]
loss: 0.002329  [  400/ 3410]
loss: 0.004378  [  500/ 3410]
loss: 0.001080  [  600/ 3410]
loss: 0.005334  [  700/ 3410]
loss: 0.002951  [  800/ 3410]
loss: 0.002350  [  900/ 3410]
loss: 0.005283  [ 1000/ 3410]
loss: 0.002284  [ 1100/ 3410]
loss: 0.001236  [ 1200/ 3410]
loss: 0.004774  [ 1300/ 3410]
loss: 0.001726  [ 1400/ 3410]
loss: 0.001717  [ 1500/ 3410]
loss: 0.001314  [ 1600/ 3410]
loss: 0.004347  [ 1700/ 3410]
loss: 0.006922  [ 1800/ 3410]
loss: 0.001303  [ 1900/ 3410]
loss: 0.051957  [ 2000/ 3410]
loss: 0.002890  [ 2100/ 3410]
loss: 0.025763  [ 2200/ 3410]
loss: 0.001962  [ 2300/ 3410]
loss: 0.001073  [ 2400/ 3410]
loss: 0.081391  [ 2500/ 3410]
loss: 0.003889  [ 2600/ 3410]
loss: 0.004078  [ 2700/ 3410]
loss: 0.000829  [ 2800/ 3410]
loss: 0.006014  [ 2900/ 3410]
loss: 0.002258  [ 3000/ 3410]
loss: 0.000883  [ 3100/ 3410]
loss: 0.001563  [ 3200/ 3410]
loss: 0.001413  [ 3300/ 3410]
loss: 0.001623  [ 3400/ 3410]
Epoch 6
-------------------------------
loss: 0.000333  [    0/ 3410]
loss: 0.002804  [  100/ 3410]
loss: 0.004473  [  200/ 3410]
loss: 0.003452  [  300/ 3410]
loss: 0.002316  [  400/ 3410]
loss: 0.004327  [  500/ 3410]
loss: 0.001052  [  600/ 3410]
loss: 0.005277  [  700/ 3410]
loss: 0.002990  [  800/ 3410]
loss: 0.002376  [  900/ 3410]
loss: 0.005021  [ 1000/ 3410]
loss: 0.002143  [ 1100/ 3410]
loss: 0.001212  [ 1200/ 3410]
loss: 0.004549  [ 1300/ 3410]
loss: 0.001796  [ 1400/ 3410]
loss: 0.001716  [ 1500/ 3410]
loss: 0.001312  [ 1600/ 3410]
loss: 0.004026  [ 1700/ 3410]
loss: 0.006913  [ 1800/ 3410]
loss: 0.001328  [ 1900/ 3410]
loss: 0.051375  [ 2000/ 3410]
loss: 0.002830  [ 2100/ 3410]
loss: 0.025177  [ 2200/ 3410]
loss: 0.001960  [ 2300/ 3410]
loss: 0.001032  [ 2400/ 3410]
loss: 0.075637  [ 2500/ 3410]
loss: 0.003461  [ 2600/ 3410]
loss: 0.004116  [ 2700/ 3410]
loss: 0.000857  [ 2800/ 3410]
loss: 0.005820  [ 2900/ 3410]
loss: 0.002311  [ 3000/ 3410]
loss: 0.000814  [ 3100/ 3410]
loss: 0.001492  [ 3200/ 3410]
loss: 0.001361  [ 3300/ 3410]
loss: 0.001504  [ 3400/ 3410]
Epoch 7
-------------------------------
loss: 0.000322  [    0/ 3410]
loss: 0.002784  [  100/ 3410]
loss: 0.004480  [  200/ 3410]
loss: 0.003207  [  300/ 3410]
loss: 0.002367  [  400/ 3410]
loss: 0.003648  [  500/ 3410]
loss: 0.001098  [  600/ 3410]
loss: 0.005544  [  700/ 3410]
loss: 0.003165  [  800/ 3410]
loss: 0.002349  [  900/ 3410]
loss: 0.004727  [ 1000/ 3410]
loss: 0.002017  [ 1100/ 3410]
loss: 0.001267  [ 1200/ 3410]
loss: 0.004393  [ 1300/ 3410]
loss: 0.001788  [ 1400/ 3410]
loss: 0.001683  [ 1500/ 3410]
loss: 0.001362  [ 1600/ 3410]
loss: 0.003783  [ 1700/ 3410]
loss: 0.006400  [ 1800/ 3410]
loss: 0.001395  [ 1900/ 3410]
loss: 0.050595  [ 2000/ 3410]
loss: 0.002792  [ 2100/ 3410]
loss: 0.024590  [ 2200/ 3410]
loss: 0.001986  [ 2300/ 3410]
loss: 0.001104  [ 2400/ 3410]
loss: 0.070611  [ 2500/ 3410]
loss: 0.003126  [ 2600/ 3410]
loss: 0.004285  [ 2700/ 3410]
loss: 0.000876  [ 2800/ 3410]
loss: 0.005733  [ 2900/ 3410]
loss: 0.002555  [ 3000/ 3410]
loss: 0.000773  [ 3100/ 3410]
loss: 0.001387  [ 3200/ 3410]
loss: 0.001378  [ 3300/ 3410]
loss: 0.001288  [ 3400/ 3410]
Epoch 8
-------------------------------
loss: 0.000490  [    0/ 3410]
loss: 0.002658  [  100/ 3410]
loss: 0.004521  [  200/ 3410]
loss: 0.003161  [  300/ 3410]
loss: 0.002431  [  400/ 3410]
loss: 0.003906  [  500/ 3410]
loss: 0.001040  [  600/ 3410]
loss: 0.005306  [  700/ 3410]
loss: 0.003325  [  800/ 3410]
loss: 0.002367  [  900/ 3410]
loss: 0.004590  [ 1000/ 3410]
loss: 0.001957  [ 1100/ 3410]
loss: 0.001060  [ 1200/ 3410]
loss: 0.004394  [ 1300/ 3410]
loss: 0.001824  [ 1400/ 3410]
loss: 0.001609  [ 1500/ 3410]
loss: 0.001010  [ 1600/ 3410]
loss: 0.003457  [ 1700/ 3410]
loss: 0.005900  [ 1800/ 3410]
loss: 0.001406  [ 1900/ 3410]
loss: 0.050123  [ 2000/ 3410]
loss: 0.002723  [ 2100/ 3410]
loss: 0.024410  [ 2200/ 3410]
loss: 0.002032  [ 2300/ 3410]
loss: 0.001238  [ 2400/ 3410]
loss: 0.056082  [ 2500/ 3410]
loss: 0.002915  [ 2600/ 3410]
loss: 0.004218  [ 2700/ 3410]
loss: 0.000793  [ 2800/ 3410]
loss: 0.005604  [ 2900/ 3410]
loss: 0.002265  [ 3000/ 3410]
loss: 0.000740  [ 3100/ 3410]
loss: 0.001631  [ 3200/ 3410]
loss: 0.001375  [ 3300/ 3410]
loss: 0.001511  [ 3400/ 3410]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3410
First Spike after testing: [ 1.320505  -0.5039696]
[2 2 2 ... 2 0 2]
[1 1 1 ... 1 2 1]
Cluster 0 Occurrences: 1130; KMEANS: 1091
Cluster 1 Occurrences: 1113; KMEANS: 1165
Cluster 2 Occurrences: 1167; KMEANS: 1154
Centroids: [[-1.2247092, 1.5454195], [-0.07019166, 0.7908809], [1.2771599, -0.4942015]]
Centroids: [[-0.025490174, 0.76478416], [1.2791423, -0.49716452], [-1.2426256, 1.5551631]]
Contingency Matrix: 
[[  17    0 1113]
 [1070    2   41]
 [   4 1163    0]]
[[17, -1, 1113], [1070, -1, 41], [-1, -1, -1]]
[[-1, -1, -1], [1070, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[1113   17    0]
 [  41 1070    2]
 [   0    4 1163]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1113, 1070, 1163], Sum: 3346
All_Elements: [1113, 17, 0, 41, 1070, 2, 0, 4, 1163], Sum: 3410
Accuracy: 0.9812316715542522
Done!
