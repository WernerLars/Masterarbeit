Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_56_18
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000172057CB9B0>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81BEB8>
Epoch 1
-------------------------------
loss: 0.163598  [    0/ 3383]
loss: 0.033420  [  100/ 3383]
loss: 0.015987  [  200/ 3383]
loss: 0.008688  [  300/ 3383]
loss: 0.006112  [  400/ 3383]
loss: 0.010658  [  500/ 3383]
loss: 0.006781  [  600/ 3383]
loss: 0.012625  [  700/ 3383]
loss: 0.007495  [  800/ 3383]
loss: 0.006230  [  900/ 3383]
loss: 0.094044  [ 1000/ 3383]
loss: 0.056475  [ 1100/ 3383]
loss: 0.023056  [ 1200/ 3383]
loss: 0.012486  [ 1300/ 3383]
loss: 0.005788  [ 1400/ 3383]
loss: 0.015021  [ 1500/ 3383]
loss: 0.006889  [ 1600/ 3383]
loss: 0.001494  [ 1700/ 3383]
loss: 0.011626  [ 1800/ 3383]
loss: 0.013765  [ 1900/ 3383]
loss: 0.006532  [ 2000/ 3383]
loss: 0.003494  [ 2100/ 3383]
loss: 0.008447  [ 2200/ 3383]
loss: 0.001670  [ 2300/ 3383]
loss: 0.004010  [ 2400/ 3383]
loss: 0.027540  [ 2500/ 3383]
loss: 0.001622  [ 2600/ 3383]
loss: 0.003842  [ 2700/ 3383]
loss: 0.006549  [ 2800/ 3383]
loss: 0.005737  [ 2900/ 3383]
loss: 0.003827  [ 3000/ 3383]
loss: 0.004470  [ 3100/ 3383]
loss: 0.064123  [ 3200/ 3383]
loss: 0.002382  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.004373  [    0/ 3383]
loss: 0.005999  [  100/ 3383]
loss: 0.005886  [  200/ 3383]
loss: 0.002161  [  300/ 3383]
loss: 0.003407  [  400/ 3383]
loss: 0.004800  [  500/ 3383]
loss: 0.001132  [  600/ 3383]
loss: 0.001966  [  700/ 3383]
loss: 0.007393  [  800/ 3383]
loss: 0.001385  [  900/ 3383]
loss: 0.092001  [ 1000/ 3383]
loss: 0.058307  [ 1100/ 3383]
loss: 0.022431  [ 1200/ 3383]
loss: 0.009285  [ 1300/ 3383]
loss: 0.004200  [ 1400/ 3383]
loss: 0.014803  [ 1500/ 3383]
loss: 0.002606  [ 1600/ 3383]
loss: 0.001525  [ 1700/ 3383]
loss: 0.012234  [ 1800/ 3383]
loss: 0.014165  [ 1900/ 3383]
loss: 0.003123  [ 2000/ 3383]
loss: 0.003431  [ 2100/ 3383]
loss: 0.008795  [ 2200/ 3383]
loss: 0.001570  [ 2300/ 3383]
loss: 0.004284  [ 2400/ 3383]
loss: 0.028059  [ 2500/ 3383]
loss: 0.001498  [ 2600/ 3383]
loss: 0.004047  [ 2700/ 3383]
loss: 0.006452  [ 2800/ 3383]
loss: 0.005896  [ 2900/ 3383]
loss: 0.003380  [ 3000/ 3383]
loss: 0.004481  [ 3100/ 3383]
loss: 0.064325  [ 3200/ 3383]
loss: 0.002492  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.004243  [    0/ 3383]
loss: 0.006025  [  100/ 3383]
loss: 0.005850  [  200/ 3383]
loss: 0.002157  [  300/ 3383]
loss: 0.003368  [  400/ 3383]
loss: 0.004807  [  500/ 3383]
loss: 0.001173  [  600/ 3383]
loss: 0.001829  [  700/ 3383]
loss: 0.007397  [  800/ 3383]
loss: 0.001549  [  900/ 3383]
loss: 0.092974  [ 1000/ 3383]
loss: 0.058510  [ 1100/ 3383]
loss: 0.022652  [ 1200/ 3383]
loss: 0.009291  [ 1300/ 3383]
loss: 0.004212  [ 1400/ 3383]
loss: 0.014886  [ 1500/ 3383]
loss: 0.002573  [ 1600/ 3383]
loss: 0.001527  [ 1700/ 3383]
loss: 0.012123  [ 1800/ 3383]
loss: 0.014189  [ 1900/ 3383]
loss: 0.003112  [ 2000/ 3383]
loss: 0.003421  [ 2100/ 3383]
loss: 0.008732  [ 2200/ 3383]
loss: 0.001587  [ 2300/ 3383]
loss: 0.004193  [ 2400/ 3383]
loss: 0.027570  [ 2500/ 3383]
loss: 0.001427  [ 2600/ 3383]
loss: 0.004070  [ 2700/ 3383]
loss: 0.006440  [ 2800/ 3383]
loss: 0.006008  [ 2900/ 3383]
loss: 0.003399  [ 3000/ 3383]
loss: 0.004494  [ 3100/ 3383]
loss: 0.064216  [ 3200/ 3383]
loss: 0.002528  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.004220  [    0/ 3383]
loss: 0.005985  [  100/ 3383]
loss: 0.005622  [  200/ 3383]
loss: 0.002135  [  300/ 3383]
loss: 0.003352  [  400/ 3383]
loss: 0.004761  [  500/ 3383]
loss: 0.001259  [  600/ 3383]
loss: 0.001778  [  700/ 3383]
loss: 0.007415  [  800/ 3383]
loss: 0.001567  [  900/ 3383]
loss: 0.093335  [ 1000/ 3383]
loss: 0.058624  [ 1100/ 3383]
loss: 0.022987  [ 1200/ 3383]
loss: 0.009260  [ 1300/ 3383]
loss: 0.004190  [ 1400/ 3383]
loss: 0.014931  [ 1500/ 3383]
loss: 0.002575  [ 1600/ 3383]
loss: 0.001525  [ 1700/ 3383]
loss: 0.011988  [ 1800/ 3383]
loss: 0.014221  [ 1900/ 3383]
loss: 0.003079  [ 2000/ 3383]
loss: 0.003422  [ 2100/ 3383]
loss: 0.008673  [ 2200/ 3383]
loss: 0.001572  [ 2300/ 3383]
loss: 0.004064  [ 2400/ 3383]
loss: 0.027313  [ 2500/ 3383]
loss: 0.001350  [ 2600/ 3383]
loss: 0.004133  [ 2700/ 3383]
loss: 0.006418  [ 2800/ 3383]
loss: 0.006070  [ 2900/ 3383]
loss: 0.003640  [ 3000/ 3383]
loss: 0.004451  [ 3100/ 3383]
loss: 0.064160  [ 3200/ 3383]
loss: 0.002544  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.004226  [    0/ 3383]
loss: 0.005952  [  100/ 3383]
loss: 0.005514  [  200/ 3383]
loss: 0.002128  [  300/ 3383]
loss: 0.003354  [  400/ 3383]
loss: 0.004734  [  500/ 3383]
loss: 0.001292  [  600/ 3383]
loss: 0.001771  [  700/ 3383]
loss: 0.007421  [  800/ 3383]
loss: 0.001767  [  900/ 3383]
loss: 0.093679  [ 1000/ 3383]
loss: 0.058464  [ 1100/ 3383]
loss: 0.023197  [ 1200/ 3383]
loss: 0.009239  [ 1300/ 3383]
loss: 0.004172  [ 1400/ 3383]
loss: 0.014952  [ 1500/ 3383]
loss: 0.002584  [ 1600/ 3383]
loss: 0.001524  [ 1700/ 3383]
loss: 0.011894  [ 1800/ 3383]
loss: 0.014182  [ 1900/ 3383]
loss: 0.003045  [ 2000/ 3383]
loss: 0.003441  [ 2100/ 3383]
loss: 0.008610  [ 2200/ 3383]
loss: 0.001570  [ 2300/ 3383]
loss: 0.004214  [ 2400/ 3383]
loss: 0.026400  [ 2500/ 3383]
loss: 0.001297  [ 2600/ 3383]
loss: 0.004219  [ 2700/ 3383]
loss: 0.006421  [ 2800/ 3383]
loss: 0.006176  [ 2900/ 3383]
loss: 0.003604  [ 3000/ 3383]
loss: 0.004419  [ 3100/ 3383]
loss: 0.063536  [ 3200/ 3383]
loss: 0.002560  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.004405  [    0/ 3383]
loss: 0.005887  [  100/ 3383]
loss: 0.005283  [  200/ 3383]
loss: 0.002097  [  300/ 3383]
loss: 0.003357  [  400/ 3383]
loss: 0.004696  [  500/ 3383]
loss: 0.001331  [  600/ 3383]
loss: 0.001696  [  700/ 3383]
loss: 0.007428  [  800/ 3383]
loss: 0.001665  [  900/ 3383]
loss: 0.094237  [ 1000/ 3383]
loss: 0.058318  [ 1100/ 3383]
loss: 0.023167  [ 1200/ 3383]
loss: 0.009211  [ 1300/ 3383]
loss: 0.004147  [ 1400/ 3383]
loss: 0.014968  [ 1500/ 3383]
loss: 0.002586  [ 1600/ 3383]
loss: 0.001522  [ 1700/ 3383]
loss: 0.011768  [ 1800/ 3383]
loss: 0.014148  [ 1900/ 3383]
loss: 0.003035  [ 2000/ 3383]
loss: 0.003457  [ 2100/ 3383]
loss: 0.008564  [ 2200/ 3383]
loss: 0.001631  [ 2300/ 3383]
loss: 0.004023  [ 2400/ 3383]
loss: 0.027399  [ 2500/ 3383]
loss: 0.001223  [ 2600/ 3383]
loss: 0.004332  [ 2700/ 3383]
loss: 0.006466  [ 2800/ 3383]
loss: 0.006249  [ 2900/ 3383]
loss: 0.003471  [ 3000/ 3383]
loss: 0.004389  [ 3100/ 3383]
loss: 0.063470  [ 3200/ 3383]
loss: 0.002659  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.004387  [    0/ 3383]
loss: 0.005863  [  100/ 3383]
loss: 0.005219  [  200/ 3383]
loss: 0.002094  [  300/ 3383]
loss: 0.003318  [  400/ 3383]
loss: 0.004780  [  500/ 3383]
loss: 0.001376  [  600/ 3383]
loss: 0.001476  [  700/ 3383]
loss: 0.007274  [  800/ 3383]
loss: 0.001505  [  900/ 3383]
loss: 0.094338  [ 1000/ 3383]
loss: 0.058393  [ 1100/ 3383]
loss: 0.023319  [ 1200/ 3383]
loss: 0.009256  [ 1300/ 3383]
loss: 0.004011  [ 1400/ 3383]
loss: 0.015266  [ 1500/ 3383]
loss: 0.002675  [ 1600/ 3383]
loss: 0.001532  [ 1700/ 3383]
loss: 0.011095  [ 1800/ 3383]
loss: 0.014156  [ 1900/ 3383]
loss: 0.003016  [ 2000/ 3383]
loss: 0.003530  [ 2100/ 3383]
loss: 0.008482  [ 2200/ 3383]
loss: 0.001770  [ 2300/ 3383]
loss: 0.003935  [ 2400/ 3383]
loss: 0.027941  [ 2500/ 3383]
loss: 0.001190  [ 2600/ 3383]
loss: 0.003592  [ 2700/ 3383]
loss: 0.006176  [ 2800/ 3383]
loss: 0.006200  [ 2900/ 3383]
loss: 0.003486  [ 3000/ 3383]
loss: 0.004336  [ 3100/ 3383]
loss: 0.063769  [ 3200/ 3383]
loss: 0.002908  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.004752  [    0/ 3383]
loss: 0.005549  [  100/ 3383]
loss: 0.005036  [  200/ 3383]
loss: 0.002172  [  300/ 3383]
loss: 0.003089  [  400/ 3383]
loss: 0.004656  [  500/ 3383]
loss: 0.001390  [  600/ 3383]
loss: 0.001615  [  700/ 3383]
loss: 0.006631  [  800/ 3383]
loss: 0.001444  [  900/ 3383]
loss: 0.094977  [ 1000/ 3383]
loss: 0.058213  [ 1100/ 3383]
loss: 0.023392  [ 1200/ 3383]
loss: 0.009103  [ 1300/ 3383]
loss: 0.003537  [ 1400/ 3383]
loss: 0.015053  [ 1500/ 3383]
loss: 0.002422  [ 1600/ 3383]
loss: 0.001544  [ 1700/ 3383]
loss: 0.010102  [ 1800/ 3383]
loss: 0.014187  [ 1900/ 3383]
loss: 0.002982  [ 2000/ 3383]
loss: 0.003728  [ 2100/ 3383]
loss: 0.007987  [ 2200/ 3383]
loss: 0.002020  [ 2300/ 3383]
loss: 0.003754  [ 2400/ 3383]
loss: 0.027454  [ 2500/ 3383]
loss: 0.001236  [ 2600/ 3383]
loss: 0.003009  [ 2700/ 3383]
loss: 0.006124  [ 2800/ 3383]
loss: 0.006020  [ 2900/ 3383]
loss: 0.003073  [ 3000/ 3383]
loss: 0.004423  [ 3100/ 3383]
loss: 0.064055  [ 3200/ 3383]
loss: 0.002728  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [0.89121807 0.36760932]
[2 1 2 ... 0 1 2]
[0 1 0 ... 2 1 0]
Cluster 0 Occurrences: 1115; KMEANS: 1186
Cluster 1 Occurrences: 1113; KMEANS: 1092
Cluster 2 Occurrences: 1155; KMEANS: 1105
Centroids: [[0.6109502, 0.04360175], [0.17761199, 0.67643493], [0.8170486, 0.5710065]]
Centroids: [[0.82035595, 0.58162755], [0.15840334, 0.6774766], [0.6123658, 0.028403345]]
Contingency Matrix: 
[[  16    5 1094]
 [  30 1078    5]
 [1140    9    6]]
[[-1, 5, 1094], [-1, 1078, 5], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1078, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1094    5   16]
 [   5 1078   30]
 [   6    9 1140]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1094, 1078, 1140], Sum: 3312
All_Elements: [1094, 5, 16, 5, 1078, 30, 6, 9, 1140], Sum: 3383
Accuracy: 0.979012710611883
Done!
