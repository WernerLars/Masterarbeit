Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Easy1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_42_00
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000171DAADB470>
Sampling rate: 24000.0
Raw: [ 0.01223885  0.0148803   0.02156532 ... -0.02666729 -0.01215068
  0.01031338]
Times: [   1012    1333    1523 ... 1438660 1438690 1439287]
Cluster: [1 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3522
First aligned Spike Frame: [-0.12579972 -0.1620207  -0.18573939 -0.18961714 -0.17315203 -0.1396561
 -0.09426159 -0.04496221  0.00734136  0.05943689  0.09448878  0.07601101
  0.00811529  0.09446653  0.55421698  1.03008495  0.90195967  0.23116337
 -0.37857386 -0.59030761 -0.52695739 -0.40967661 -0.32471334 -0.26000903
 -0.19839489 -0.13975054 -0.09692457 -0.08223204 -0.09147337 -0.10695261
 -0.11338461 -0.10883018 -0.09915766 -0.08637804 -0.06514771 -0.03537735
 -0.00695045  0.01307529  0.02539335  0.03607991  0.04814655  0.05257424
  0.04538721  0.03512231  0.03354714  0.04141478  0.0511991 ]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1134
Cluster 2, Occurrences: 1237
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81BFD0>
Epoch 1
-------------------------------
loss: 0.102501  [    0/ 3522]
loss: 0.150198  [  100/ 3522]
loss: 0.107401  [  200/ 3522]
loss: 0.047294  [  300/ 3522]
loss: 0.067850  [  400/ 3522]
loss: 0.049644  [  500/ 3522]
loss: 0.127236  [  600/ 3522]
loss: 0.050539  [  700/ 3522]
loss: 0.036272  [  800/ 3522]
loss: 0.011251  [  900/ 3522]
loss: 0.005200  [ 1000/ 3522]
loss: 0.006315  [ 1100/ 3522]
loss: 0.082927  [ 1200/ 3522]
loss: 0.015260  [ 1300/ 3522]
loss: 0.003195  [ 1400/ 3522]
loss: 0.006619  [ 1500/ 3522]
loss: 0.010936  [ 1600/ 3522]
loss: 0.007188  [ 1700/ 3522]
loss: 0.009577  [ 1800/ 3522]
loss: 0.015786  [ 1900/ 3522]
loss: 0.011796  [ 2000/ 3522]
loss: 0.014572  [ 2100/ 3522]
loss: 0.005117  [ 2200/ 3522]
loss: 0.007194  [ 2300/ 3522]
loss: 0.007282  [ 2400/ 3522]
loss: 0.005109  [ 2500/ 3522]
loss: 0.071662  [ 2600/ 3522]
loss: 0.010702  [ 2700/ 3522]
loss: 0.003455  [ 2800/ 3522]
loss: 0.004305  [ 2900/ 3522]
loss: 0.008958  [ 3000/ 3522]
loss: 0.012098  [ 3100/ 3522]
loss: 0.013593  [ 3200/ 3522]
loss: 0.009161  [ 3300/ 3522]
loss: 0.009583  [ 3400/ 3522]
loss: 0.009533  [ 3500/ 3522]
Epoch 2
-------------------------------
loss: 0.010477  [    0/ 3522]
loss: 0.006355  [  100/ 3522]
loss: 0.005618  [  200/ 3522]
loss: 0.043628  [  300/ 3522]
loss: 0.008407  [  400/ 3522]
loss: 0.008584  [  500/ 3522]
loss: 0.117714  [  600/ 3522]
loss: 0.015078  [  700/ 3522]
loss: 0.013269  [  800/ 3522]
loss: 0.005456  [  900/ 3522]
loss: 0.005405  [ 1000/ 3522]
loss: 0.004145  [ 1100/ 3522]
loss: 0.091057  [ 1200/ 3522]
loss: 0.015164  [ 1300/ 3522]
loss: 0.002433  [ 1400/ 3522]
loss: 0.003103  [ 1500/ 3522]
loss: 0.009990  [ 1600/ 3522]
loss: 0.007856  [ 1700/ 3522]
loss: 0.008800  [ 1800/ 3522]
loss: 0.015590  [ 1900/ 3522]
loss: 0.011463  [ 2000/ 3522]
loss: 0.013868  [ 2100/ 3522]
loss: 0.004991  [ 2200/ 3522]
loss: 0.006265  [ 2300/ 3522]
loss: 0.007011  [ 2400/ 3522]
loss: 0.004329  [ 2500/ 3522]
loss: 0.064818  [ 2600/ 3522]
loss: 0.009281  [ 2700/ 3522]
loss: 0.003409  [ 2800/ 3522]
loss: 0.004043  [ 2900/ 3522]
loss: 0.006732  [ 3000/ 3522]
loss: 0.007170  [ 3100/ 3522]
loss: 0.013199  [ 3200/ 3522]
loss: 0.008285  [ 3300/ 3522]
loss: 0.009211  [ 3400/ 3522]
loss: 0.008021  [ 3500/ 3522]
Epoch 3
-------------------------------
loss: 0.009698  [    0/ 3522]
loss: 0.007038  [  100/ 3522]
loss: 0.004373  [  200/ 3522]
loss: 0.029162  [  300/ 3522]
loss: 0.008017  [  400/ 3522]
loss: 0.008339  [  500/ 3522]
loss: 0.114303  [  600/ 3522]
loss: 0.014269  [  700/ 3522]
loss: 0.012709  [  800/ 3522]
loss: 0.005499  [  900/ 3522]
loss: 0.004902  [ 1000/ 3522]
loss: 0.004257  [ 1100/ 3522]
loss: 0.093547  [ 1200/ 3522]
loss: 0.015768  [ 1300/ 3522]
loss: 0.002526  [ 1400/ 3522]
loss: 0.003191  [ 1500/ 3522]
loss: 0.009626  [ 1600/ 3522]
loss: 0.008837  [ 1700/ 3522]
loss: 0.008878  [ 1800/ 3522]
loss: 0.014952  [ 1900/ 3522]
loss: 0.010347  [ 2000/ 3522]
loss: 0.013004  [ 2100/ 3522]
loss: 0.004071  [ 2200/ 3522]
loss: 0.006525  [ 2300/ 3522]
loss: 0.006786  [ 2400/ 3522]
loss: 0.003512  [ 2500/ 3522]
loss: 0.063181  [ 2600/ 3522]
loss: 0.008948  [ 2700/ 3522]
loss: 0.003616  [ 2800/ 3522]
loss: 0.004170  [ 2900/ 3522]
loss: 0.006030  [ 3000/ 3522]
loss: 0.005479  [ 3100/ 3522]
loss: 0.010045  [ 3200/ 3522]
loss: 0.008228  [ 3300/ 3522]
loss: 0.009178  [ 3400/ 3522]
loss: 0.006415  [ 3500/ 3522]
Epoch 4
-------------------------------
loss: 0.008569  [    0/ 3522]
loss: 0.008745  [  100/ 3522]
loss: 0.004042  [  200/ 3522]
loss: 0.020836  [  300/ 3522]
loss: 0.007594  [  400/ 3522]
loss: 0.008499  [  500/ 3522]
loss: 0.112353  [  600/ 3522]
loss: 0.013036  [  700/ 3522]
loss: 0.010713  [  800/ 3522]
loss: 0.006389  [  900/ 3522]
loss: 0.004678  [ 1000/ 3522]
loss: 0.003800  [ 1100/ 3522]
loss: 0.088588  [ 1200/ 3522]
loss: 0.015768  [ 1300/ 3522]
loss: 0.002664  [ 1400/ 3522]
loss: 0.002933  [ 1500/ 3522]
loss: 0.009784  [ 1600/ 3522]
loss: 0.007509  [ 1700/ 3522]
loss: 0.011215  [ 1800/ 3522]
loss: 0.014614  [ 1900/ 3522]
loss: 0.009566  [ 2000/ 3522]
loss: 0.011935  [ 2100/ 3522]
loss: 0.003254  [ 2200/ 3522]
loss: 0.006570  [ 2300/ 3522]
loss: 0.005785  [ 2400/ 3522]
loss: 0.003223  [ 2500/ 3522]
loss: 0.063411  [ 2600/ 3522]
loss: 0.008179  [ 2700/ 3522]
loss: 0.003284  [ 2800/ 3522]
loss: 0.004768  [ 2900/ 3522]
loss: 0.005167  [ 3000/ 3522]
loss: 0.004418  [ 3100/ 3522]
loss: 0.007843  [ 3200/ 3522]
loss: 0.007846  [ 3300/ 3522]
loss: 0.009826  [ 3400/ 3522]
loss: 0.005531  [ 3500/ 3522]
Epoch 5
-------------------------------
loss: 0.009503  [    0/ 3522]
loss: 0.008570  [  100/ 3522]
loss: 0.003896  [  200/ 3522]
loss: 0.022493  [  300/ 3522]
loss: 0.007370  [  400/ 3522]
loss: 0.008599  [  500/ 3522]
loss: 0.110222  [  600/ 3522]
loss: 0.012010  [  700/ 3522]
loss: 0.008466  [  800/ 3522]
loss: 0.006541  [  900/ 3522]
loss: 0.004458  [ 1000/ 3522]
loss: 0.003480  [ 1100/ 3522]
loss: 0.086490  [ 1200/ 3522]
loss: 0.015779  [ 1300/ 3522]
loss: 0.002750  [ 1400/ 3522]
loss: 0.002414  [ 1500/ 3522]
loss: 0.009162  [ 1600/ 3522]
loss: 0.006386  [ 1700/ 3522]
loss: 0.012245  [ 1800/ 3522]
loss: 0.014232  [ 1900/ 3522]
loss: 0.009787  [ 2000/ 3522]
loss: 0.010902  [ 2100/ 3522]
loss: 0.003299  [ 2200/ 3522]
loss: 0.006457  [ 2300/ 3522]
loss: 0.004773  [ 2400/ 3522]
loss: 0.003034  [ 2500/ 3522]
loss: 0.063692  [ 2600/ 3522]
loss: 0.008083  [ 2700/ 3522]
loss: 0.003026  [ 2800/ 3522]
loss: 0.004673  [ 2900/ 3522]
loss: 0.004519  [ 3000/ 3522]
loss: 0.004422  [ 3100/ 3522]
loss: 0.007264  [ 3200/ 3522]
loss: 0.007606  [ 3300/ 3522]
loss: 0.010439  [ 3400/ 3522]
loss: 0.005318  [ 3500/ 3522]
Epoch 6
-------------------------------
loss: 0.009834  [    0/ 3522]
loss: 0.008828  [  100/ 3522]
loss: 0.003716  [  200/ 3522]
loss: 0.023706  [  300/ 3522]
loss: 0.007065  [  400/ 3522]
loss: 0.008802  [  500/ 3522]
loss: 0.109599  [  600/ 3522]
loss: 0.012210  [  700/ 3522]
loss: 0.007113  [  800/ 3522]
loss: 0.006392  [  900/ 3522]
loss: 0.004208  [ 1000/ 3522]
loss: 0.003423  [ 1100/ 3522]
loss: 0.084053  [ 1200/ 3522]
loss: 0.015488  [ 1300/ 3522]
loss: 0.002847  [ 1400/ 3522]
loss: 0.002142  [ 1500/ 3522]
loss: 0.008801  [ 1600/ 3522]
loss: 0.006233  [ 1700/ 3522]
loss: 0.012448  [ 1800/ 3522]
loss: 0.013760  [ 1900/ 3522]
loss: 0.009873  [ 2000/ 3522]
loss: 0.010161  [ 2100/ 3522]
loss: 0.003386  [ 2200/ 3522]
loss: 0.006547  [ 2300/ 3522]
loss: 0.003963  [ 2400/ 3522]
loss: 0.002804  [ 2500/ 3522]
loss: 0.064628  [ 2600/ 3522]
loss: 0.007983  [ 2700/ 3522]
loss: 0.003023  [ 2800/ 3522]
loss: 0.004739  [ 2900/ 3522]
loss: 0.004005  [ 3000/ 3522]
loss: 0.004477  [ 3100/ 3522]
loss: 0.007062  [ 3200/ 3522]
loss: 0.007547  [ 3300/ 3522]
loss: 0.010906  [ 3400/ 3522]
loss: 0.005390  [ 3500/ 3522]
Epoch 7
-------------------------------
loss: 0.009828  [    0/ 3522]
loss: 0.009094  [  100/ 3522]
loss: 0.003633  [  200/ 3522]
loss: 0.023943  [  300/ 3522]
loss: 0.006875  [  400/ 3522]
loss: 0.009087  [  500/ 3522]
loss: 0.109748  [  600/ 3522]
loss: 0.012003  [  700/ 3522]
loss: 0.006998  [  800/ 3522]
loss: 0.006429  [  900/ 3522]
loss: 0.004056  [ 1000/ 3522]
loss: 0.003624  [ 1100/ 3522]
loss: 0.084898  [ 1200/ 3522]
loss: 0.015434  [ 1300/ 3522]
loss: 0.002784  [ 1400/ 3522]
loss: 0.002120  [ 1500/ 3522]
loss: 0.008868  [ 1600/ 3522]
loss: 0.006362  [ 1700/ 3522]
loss: 0.012147  [ 1800/ 3522]
loss: 0.013443  [ 1900/ 3522]
loss: 0.010118  [ 2000/ 3522]
loss: 0.009639  [ 2100/ 3522]
loss: 0.003474  [ 2200/ 3522]
loss: 0.006430  [ 2300/ 3522]
loss: 0.003685  [ 2400/ 3522]
loss: 0.002718  [ 2500/ 3522]
loss: 0.065952  [ 2600/ 3522]
loss: 0.007870  [ 2700/ 3522]
loss: 0.002920  [ 2800/ 3522]
loss: 0.004695  [ 2900/ 3522]
loss: 0.003542  [ 3000/ 3522]
loss: 0.004536  [ 3100/ 3522]
loss: 0.006961  [ 3200/ 3522]
loss: 0.007502  [ 3300/ 3522]
loss: 0.011189  [ 3400/ 3522]
loss: 0.005571  [ 3500/ 3522]
Epoch 8
-------------------------------
loss: 0.009783  [    0/ 3522]
loss: 0.009178  [  100/ 3522]
loss: 0.003579  [  200/ 3522]
loss: 0.023181  [  300/ 3522]
loss: 0.006725  [  400/ 3522]
loss: 0.009187  [  500/ 3522]
loss: 0.108562  [  600/ 3522]
loss: 0.011960  [  700/ 3522]
loss: 0.006855  [  800/ 3522]
loss: 0.006444  [  900/ 3522]
loss: 0.003942  [ 1000/ 3522]
loss: 0.003738  [ 1100/ 3522]
loss: 0.089375  [ 1200/ 3522]
loss: 0.015253  [ 1300/ 3522]
loss: 0.002778  [ 1400/ 3522]
loss: 0.002064  [ 1500/ 3522]
loss: 0.008947  [ 1600/ 3522]
loss: 0.006439  [ 1700/ 3522]
loss: 0.012113  [ 1800/ 3522]
loss: 0.013259  [ 1900/ 3522]
loss: 0.010210  [ 2000/ 3522]
loss: 0.009304  [ 2100/ 3522]
loss: 0.003432  [ 2200/ 3522]
loss: 0.006418  [ 2300/ 3522]
loss: 0.003455  [ 2400/ 3522]
loss: 0.002584  [ 2500/ 3522]
loss: 0.067216  [ 2600/ 3522]
loss: 0.007759  [ 2700/ 3522]
loss: 0.002824  [ 2800/ 3522]
loss: 0.004672  [ 2900/ 3522]
loss: 0.003380  [ 3000/ 3522]
loss: 0.004411  [ 3100/ 3522]
loss: 0.006817  [ 3200/ 3522]
loss: 0.007479  [ 3300/ 3522]
loss: 0.011401  [ 3400/ 3522]
loss: 0.005983  [ 3500/ 3522]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3522
First Spike after testing: [ 1.3512188  -0.00429504]
[0 2 2 ... 2 0 2]
[0 2 2 ... 2 0 2]
Cluster 0 Occurrences: 1151; KMEANS: 1149
Cluster 1 Occurrences: 1134; KMEANS: 1129
Cluster 2 Occurrences: 1237; KMEANS: 1244
Centroids: [[1.4659586, 0.042260118], [-1.5353571, 0.71863157], [0.78526294, 1.9972049]]
Centroids: [[1.4696758, 0.030573208], [-1.5523638, 0.7248352], [0.789031, 1.9940872]]
Contingency Matrix: 
[[1142    0    9]
 [   6 1126    2]
 [   1    3 1233]]
[[1142, 0, -1], [6, 1126, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1126, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 0, 1: 1}
New Contingency Matrix: 
[[1142    0    9]
 [   6 1126    2]
 [   1    3 1233]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1142, 1126, 1233], Sum: 3501
All_Elements: [1142, 0, 9, 6, 1126, 2, 1, 3, 1233], Sum: 3522
Accuracy: 0.9940374787052811
Done!
