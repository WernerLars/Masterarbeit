Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_38_57
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000171DAADBB38>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81BFD0>
Epoch 1
-------------------------------
loss: 0.153514  [    0/ 3514]
loss: 0.108490  [  100/ 3514]
loss: 0.097720  [  200/ 3514]
loss: 0.060053  [  300/ 3514]
loss: 0.069345  [  400/ 3514]
loss: 0.044095  [  500/ 3514]
loss: 0.023197  [  600/ 3514]
loss: 0.006861  [  700/ 3514]
loss: 0.010991  [  800/ 3514]
loss: 0.010983  [  900/ 3514]
loss: 0.006827  [ 1000/ 3514]
loss: 0.094829  [ 1100/ 3514]
loss: 0.003494  [ 1200/ 3514]
loss: 0.001920  [ 1300/ 3514]
loss: 0.087858  [ 1400/ 3514]
loss: 0.000841  [ 1500/ 3514]
loss: 0.006459  [ 1600/ 3514]
loss: 0.005648  [ 1700/ 3514]
loss: 0.230762  [ 1800/ 3514]
loss: 0.007264  [ 1900/ 3514]
loss: 0.002395  [ 2000/ 3514]
loss: 0.005342  [ 2100/ 3514]
loss: 0.000716  [ 2200/ 3514]
loss: 0.001465  [ 2300/ 3514]
loss: 0.002279  [ 2400/ 3514]
loss: 0.006921  [ 2500/ 3514]
loss: 0.003828  [ 2600/ 3514]
loss: 0.003202  [ 2700/ 3514]
loss: 0.007241  [ 2800/ 3514]
loss: 0.003477  [ 2900/ 3514]
loss: 0.010459  [ 3000/ 3514]
loss: 0.001728  [ 3100/ 3514]
loss: 0.001602  [ 3200/ 3514]
loss: 0.005797  [ 3300/ 3514]
loss: 0.006729  [ 3400/ 3514]
loss: 0.003602  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.006876  [    0/ 3514]
loss: 0.002337  [  100/ 3514]
loss: 0.007302  [  200/ 3514]
loss: 0.003496  [  300/ 3514]
loss: 0.004239  [  400/ 3514]
loss: 0.005009  [  500/ 3514]
loss: 0.009279  [  600/ 3514]
loss: 0.002843  [  700/ 3514]
loss: 0.001385  [  800/ 3514]
loss: 0.004116  [  900/ 3514]
loss: 0.006452  [ 1000/ 3514]
loss: 0.090922  [ 1100/ 3514]
loss: 0.002652  [ 1200/ 3514]
loss: 0.001544  [ 1300/ 3514]
loss: 0.067317  [ 1400/ 3514]
loss: 0.000687  [ 1500/ 3514]
loss: 0.006001  [ 1600/ 3514]
loss: 0.005672  [ 1700/ 3514]
loss: 0.213069  [ 1800/ 3514]
loss: 0.007018  [ 1900/ 3514]
loss: 0.001950  [ 2000/ 3514]
loss: 0.005315  [ 2100/ 3514]
loss: 0.000761  [ 2200/ 3514]
loss: 0.001385  [ 2300/ 3514]
loss: 0.002133  [ 2400/ 3514]
loss: 0.007022  [ 2500/ 3514]
loss: 0.004082  [ 2600/ 3514]
loss: 0.002572  [ 2700/ 3514]
loss: 0.007228  [ 2800/ 3514]
loss: 0.002163  [ 2900/ 3514]
loss: 0.007523  [ 3000/ 3514]
loss: 0.001275  [ 3100/ 3514]
loss: 0.001639  [ 3200/ 3514]
loss: 0.006749  [ 3300/ 3514]
loss: 0.006651  [ 3400/ 3514]
loss: 0.003470  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.005954  [    0/ 3514]
loss: 0.001969  [  100/ 3514]
loss: 0.006926  [  200/ 3514]
loss: 0.003586  [  300/ 3514]
loss: 0.004427  [  400/ 3514]
loss: 0.003742  [  500/ 3514]
loss: 0.008380  [  600/ 3514]
loss: 0.002673  [  700/ 3514]
loss: 0.001257  [  800/ 3514]
loss: 0.004136  [  900/ 3514]
loss: 0.006326  [ 1000/ 3514]
loss: 0.090533  [ 1100/ 3514]
loss: 0.002398  [ 1200/ 3514]
loss: 0.001536  [ 1300/ 3514]
loss: 0.061899  [ 1400/ 3514]
loss: 0.000476  [ 1500/ 3514]
loss: 0.005544  [ 1600/ 3514]
loss: 0.005562  [ 1700/ 3514]
loss: 0.202503  [ 1800/ 3514]
loss: 0.006892  [ 1900/ 3514]
loss: 0.001918  [ 2000/ 3514]
loss: 0.005103  [ 2100/ 3514]
loss: 0.000800  [ 2200/ 3514]
loss: 0.001329  [ 2300/ 3514]
loss: 0.002038  [ 2400/ 3514]
loss: 0.006742  [ 2500/ 3514]
loss: 0.003702  [ 2600/ 3514]
loss: 0.002501  [ 2700/ 3514]
loss: 0.007157  [ 2800/ 3514]
loss: 0.002037  [ 2900/ 3514]
loss: 0.006205  [ 3000/ 3514]
loss: 0.001175  [ 3100/ 3514]
loss: 0.001630  [ 3200/ 3514]
loss: 0.006054  [ 3300/ 3514]
loss: 0.006916  [ 3400/ 3514]
loss: 0.003086  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.004980  [    0/ 3514]
loss: 0.001489  [  100/ 3514]
loss: 0.006903  [  200/ 3514]
loss: 0.003714  [  300/ 3514]
loss: 0.004437  [  400/ 3514]
loss: 0.003124  [  500/ 3514]
loss: 0.007247  [  600/ 3514]
loss: 0.002785  [  700/ 3514]
loss: 0.001280  [  800/ 3514]
loss: 0.004121  [  900/ 3514]
loss: 0.006152  [ 1000/ 3514]
loss: 0.091259  [ 1100/ 3514]
loss: 0.002113  [ 1200/ 3514]
loss: 0.001473  [ 1300/ 3514]
loss: 0.062974  [ 1400/ 3514]
loss: 0.000480  [ 1500/ 3514]
loss: 0.005330  [ 1600/ 3514]
loss: 0.005340  [ 1700/ 3514]
loss: 0.198943  [ 1800/ 3514]
loss: 0.006011  [ 1900/ 3514]
loss: 0.001696  [ 2000/ 3514]
loss: 0.005114  [ 2100/ 3514]
loss: 0.000765  [ 2200/ 3514]
loss: 0.001307  [ 2300/ 3514]
loss: 0.001879  [ 2400/ 3514]
loss: 0.006829  [ 2500/ 3514]
loss: 0.004038  [ 2600/ 3514]
loss: 0.002462  [ 2700/ 3514]
loss: 0.007006  [ 2800/ 3514]
loss: 0.001925  [ 2900/ 3514]
loss: 0.003923  [ 3000/ 3514]
loss: 0.001152  [ 3100/ 3514]
loss: 0.001640  [ 3200/ 3514]
loss: 0.005719  [ 3300/ 3514]
loss: 0.006261  [ 3400/ 3514]
loss: 0.002995  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.004376  [    0/ 3514]
loss: 0.001179  [  100/ 3514]
loss: 0.006918  [  200/ 3514]
loss: 0.003826  [  300/ 3514]
loss: 0.004471  [  400/ 3514]
loss: 0.002907  [  500/ 3514]
loss: 0.006128  [  600/ 3514]
loss: 0.002895  [  700/ 3514]
loss: 0.001510  [  800/ 3514]
loss: 0.004027  [  900/ 3514]
loss: 0.006169  [ 1000/ 3514]
loss: 0.092801  [ 1100/ 3514]
loss: 0.001308  [ 1200/ 3514]
loss: 0.001485  [ 1300/ 3514]
loss: 0.063430  [ 1400/ 3514]
loss: 0.000501  [ 1500/ 3514]
loss: 0.005202  [ 1600/ 3514]
loss: 0.005124  [ 1700/ 3514]
loss: 0.196706  [ 1800/ 3514]
loss: 0.005092  [ 1900/ 3514]
loss: 0.001438  [ 2000/ 3514]
loss: 0.004943  [ 2100/ 3514]
loss: 0.000793  [ 2200/ 3514]
loss: 0.001336  [ 2300/ 3514]
loss: 0.001685  [ 2400/ 3514]
loss: 0.006880  [ 2500/ 3514]
loss: 0.004184  [ 2600/ 3514]
loss: 0.002389  [ 2700/ 3514]
loss: 0.006929  [ 2800/ 3514]
loss: 0.002107  [ 2900/ 3514]
loss: 0.003119  [ 3000/ 3514]
loss: 0.001116  [ 3100/ 3514]
loss: 0.001639  [ 3200/ 3514]
loss: 0.005557  [ 3300/ 3514]
loss: 0.005763  [ 3400/ 3514]
loss: 0.002940  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.004642  [    0/ 3514]
loss: 0.000948  [  100/ 3514]
loss: 0.006842  [  200/ 3514]
loss: 0.003906  [  300/ 3514]
loss: 0.004648  [  400/ 3514]
loss: 0.003056  [  500/ 3514]
loss: 0.005804  [  600/ 3514]
loss: 0.002977  [  700/ 3514]
loss: 0.001650  [  800/ 3514]
loss: 0.003907  [  900/ 3514]
loss: 0.006247  [ 1000/ 3514]
loss: 0.093079  [ 1100/ 3514]
loss: 0.000967  [ 1200/ 3514]
loss: 0.001481  [ 1300/ 3514]
loss: 0.062496  [ 1400/ 3514]
loss: 0.000578  [ 1500/ 3514]
loss: 0.004940  [ 1600/ 3514]
loss: 0.005008  [ 1700/ 3514]
loss: 0.191721  [ 1800/ 3514]
loss: 0.004299  [ 1900/ 3514]
loss: 0.001201  [ 2000/ 3514]
loss: 0.004919  [ 2100/ 3514]
loss: 0.000830  [ 2200/ 3514]
loss: 0.001352  [ 2300/ 3514]
loss: 0.001661  [ 2400/ 3514]
loss: 0.006720  [ 2500/ 3514]
loss: 0.003871  [ 2600/ 3514]
loss: 0.002674  [ 2700/ 3514]
loss: 0.006946  [ 2800/ 3514]
loss: 0.002027  [ 2900/ 3514]
loss: 0.003097  [ 3000/ 3514]
loss: 0.001133  [ 3100/ 3514]
loss: 0.001576  [ 3200/ 3514]
loss: 0.005198  [ 3300/ 3514]
loss: 0.005524  [ 3400/ 3514]
loss: 0.002811  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.004388  [    0/ 3514]
loss: 0.000868  [  100/ 3514]
loss: 0.006960  [  200/ 3514]
loss: 0.003997  [  300/ 3514]
loss: 0.004646  [  400/ 3514]
loss: 0.003194  [  500/ 3514]
loss: 0.005873  [  600/ 3514]
loss: 0.002956  [  700/ 3514]
loss: 0.001689  [  800/ 3514]
loss: 0.003821  [  900/ 3514]
loss: 0.006230  [ 1000/ 3514]
loss: 0.093288  [ 1100/ 3514]
loss: 0.000845  [ 1200/ 3514]
loss: 0.001463  [ 1300/ 3514]
loss: 0.062777  [ 1400/ 3514]
loss: 0.000599  [ 1500/ 3514]
loss: 0.004869  [ 1600/ 3514]
loss: 0.004993  [ 1700/ 3514]
loss: 0.188275  [ 1800/ 3514]
loss: 0.004068  [ 1900/ 3514]
loss: 0.001060  [ 2000/ 3514]
loss: 0.004943  [ 2100/ 3514]
loss: 0.000808  [ 2200/ 3514]
loss: 0.001366  [ 2300/ 3514]
loss: 0.001695  [ 2400/ 3514]
loss: 0.006666  [ 2500/ 3514]
loss: 0.003945  [ 2600/ 3514]
loss: 0.002430  [ 2700/ 3514]
loss: 0.006880  [ 2800/ 3514]
loss: 0.001898  [ 2900/ 3514]
loss: 0.003162  [ 3000/ 3514]
loss: 0.001077  [ 3100/ 3514]
loss: 0.001565  [ 3200/ 3514]
loss: 0.005153  [ 3300/ 3514]
loss: 0.005220  [ 3400/ 3514]
loss: 0.002508  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.004092  [    0/ 3514]
loss: 0.000811  [  100/ 3514]
loss: 0.006941  [  200/ 3514]
loss: 0.003984  [  300/ 3514]
loss: 0.004542  [  400/ 3514]
loss: 0.003271  [  500/ 3514]
loss: 0.006090  [  600/ 3514]
loss: 0.002879  [  700/ 3514]
loss: 0.001712  [  800/ 3514]
loss: 0.003761  [  900/ 3514]
loss: 0.006231  [ 1000/ 3514]
loss: 0.093472  [ 1100/ 3514]
loss: 0.000824  [ 1200/ 3514]
loss: 0.001455  [ 1300/ 3514]
loss: 0.063968  [ 1400/ 3514]
loss: 0.000570  [ 1500/ 3514]
loss: 0.004909  [ 1600/ 3514]
loss: 0.004901  [ 1700/ 3514]
loss: 0.185538  [ 1800/ 3514]
loss: 0.004031  [ 1900/ 3514]
loss: 0.000949  [ 2000/ 3514]
loss: 0.004912  [ 2100/ 3514]
loss: 0.000602  [ 2200/ 3514]
loss: 0.001362  [ 2300/ 3514]
loss: 0.001721  [ 2400/ 3514]
loss: 0.006768  [ 2500/ 3514]
loss: 0.003820  [ 2600/ 3514]
loss: 0.002367  [ 2700/ 3514]
loss: 0.006930  [ 2800/ 3514]
loss: 0.001825  [ 2900/ 3514]
loss: 0.003170  [ 3000/ 3514]
loss: 0.001077  [ 3100/ 3514]
loss: 0.001565  [ 3200/ 3514]
loss: 0.004632  [ 3300/ 3514]
loss: 0.005094  [ 3400/ 3514]
loss: 0.002434  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [-0.77631617  0.6798296 ]
[1 0 2 ... 1 0 1]
[1 2 0 ... 1 2 1]
Cluster 0 Occurrences: 1165; KMEANS: 1199
Cluster 1 Occurrences: 1157; KMEANS: 1150
Cluster 2 Occurrences: 1192; KMEANS: 1165
Centroids: [[1.5407249, -0.05207816], [-1.010188, 0.7123591], [0.94807005, 1.6640415]]
Centroids: [[0.94910383, 1.6586261], [-1.025395, 0.7184449], [1.5429059, -0.05823034]]
Contingency Matrix: 
[[  10    0 1155]
 [   7 1143    7]
 [1182    7    3]]
[[-1, 0, 1155], [-1, 1143, 7], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1143, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1155    0   10]
 [   7 1143    7]
 [   3    7 1182]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1155, 1143, 1182], Sum: 3480
All_Elements: [1155, 0, 10, 7, 1143, 7, 3, 7, 1182], Sum: 3514
Accuracy: 0.9903244166192373
Done!
