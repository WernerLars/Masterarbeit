Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Easy1_noise035.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_48_49
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000171DA14E128>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81B9E8>
Epoch 1
-------------------------------
loss: 0.253721  [    0/ 3534]
loss: 0.334693  [  100/ 3534]
loss: 0.084712  [  200/ 3534]
loss: 0.160693  [  300/ 3534]
loss: 0.143831  [  400/ 3534]
loss: 0.132402  [  500/ 3534]
loss: 0.084212  [  600/ 3534]
loss: 0.069465  [  700/ 3534]
loss: 0.113533  [  800/ 3534]
loss: 0.059402  [  900/ 3534]
loss: 0.105385  [ 1000/ 3534]
loss: 0.026892  [ 1100/ 3534]
loss: 0.064408  [ 1200/ 3534]
loss: 0.096340  [ 1300/ 3534]
loss: 0.039577  [ 1400/ 3534]
loss: 0.126842  [ 1500/ 3534]
loss: 0.151727  [ 1600/ 3534]
loss: 0.047823  [ 1700/ 3534]
loss: 0.231793  [ 1800/ 3534]
loss: 0.038169  [ 1900/ 3534]
loss: 0.022581  [ 2000/ 3534]
loss: 0.035155  [ 2100/ 3534]
loss: 0.027952  [ 2200/ 3534]
loss: 0.137057  [ 2300/ 3534]
loss: 0.081928  [ 2400/ 3534]
loss: 0.094361  [ 2500/ 3534]
loss: 0.102011  [ 2600/ 3534]
loss: 0.035400  [ 2700/ 3534]
loss: 0.175902  [ 2800/ 3534]
loss: 0.053442  [ 2900/ 3534]
loss: 0.306564  [ 3000/ 3534]
loss: 0.055956  [ 3100/ 3534]
loss: 0.129450  [ 3200/ 3534]
loss: 0.047004  [ 3300/ 3534]
loss: 0.045638  [ 3400/ 3534]
loss: 0.075574  [ 3500/ 3534]
Epoch 2
-------------------------------
loss: 0.124327  [    0/ 3534]
loss: 0.055491  [  100/ 3534]
loss: 0.026535  [  200/ 3534]
loss: 0.113564  [  300/ 3534]
loss: 0.167457  [  400/ 3534]
loss: 0.028326  [  500/ 3534]
loss: 0.027450  [  600/ 3534]
loss: 0.074485  [  700/ 3534]
loss: 0.033532  [  800/ 3534]
loss: 0.032095  [  900/ 3534]
loss: 0.047369  [ 1000/ 3534]
loss: 0.025586  [ 1100/ 3534]
loss: 0.014559  [ 1200/ 3534]
loss: 0.050369  [ 1300/ 3534]
loss: 0.021980  [ 1400/ 3534]
loss: 0.046734  [ 1500/ 3534]
loss: 0.146617  [ 1600/ 3534]
loss: 0.051088  [ 1700/ 3534]
loss: 0.058404  [ 1800/ 3534]
loss: 0.036567  [ 1900/ 3534]
loss: 0.027364  [ 2000/ 3534]
loss: 0.036467  [ 2100/ 3534]
loss: 0.029597  [ 2200/ 3534]
loss: 0.129427  [ 2300/ 3534]
loss: 0.056223  [ 2400/ 3534]
loss: 0.094817  [ 2500/ 3534]
loss: 0.094808  [ 2600/ 3534]
loss: 0.030080  [ 2700/ 3534]
loss: 0.147563  [ 2800/ 3534]
loss: 0.032280  [ 2900/ 3534]
loss: 0.273611  [ 3000/ 3534]
loss: 0.050398  [ 3100/ 3534]
loss: 0.126734  [ 3200/ 3534]
loss: 0.052335  [ 3300/ 3534]
loss: 0.040941  [ 3400/ 3534]
loss: 0.072322  [ 3500/ 3534]
Epoch 3
-------------------------------
loss: 0.117654  [    0/ 3534]
loss: 0.056215  [  100/ 3534]
loss: 0.025590  [  200/ 3534]
loss: 0.101860  [  300/ 3534]
loss: 0.201449  [  400/ 3534]
loss: 0.019241  [  500/ 3534]
loss: 0.022623  [  600/ 3534]
loss: 0.076486  [  700/ 3534]
loss: 0.036480  [  800/ 3534]
loss: 0.032525  [  900/ 3534]
loss: 0.044124  [ 1000/ 3534]
loss: 0.022632  [ 1100/ 3534]
loss: 0.015859  [ 1200/ 3534]
loss: 0.054809  [ 1300/ 3534]
loss: 0.018779  [ 1400/ 3534]
loss: 0.043468  [ 1500/ 3534]
loss: 0.148742  [ 1600/ 3534]
loss: 0.052477  [ 1700/ 3534]
loss: 0.054652  [ 1800/ 3534]
loss: 0.036252  [ 1900/ 3534]
loss: 0.024891  [ 2000/ 3534]
loss: 0.034845  [ 2100/ 3534]
loss: 0.030039  [ 2200/ 3534]
loss: 0.127133  [ 2300/ 3534]
loss: 0.049724  [ 2400/ 3534]
loss: 0.095069  [ 2500/ 3534]
loss: 0.090013  [ 2600/ 3534]
loss: 0.028948  [ 2700/ 3534]
loss: 0.125451  [ 2800/ 3534]
loss: 0.032102  [ 2900/ 3534]
loss: 0.251344  [ 3000/ 3534]
loss: 0.050330  [ 3100/ 3534]
loss: 0.125036  [ 3200/ 3534]
loss: 0.058443  [ 3300/ 3534]
loss: 0.040254  [ 3400/ 3534]
loss: 0.071461  [ 3500/ 3534]
Epoch 4
-------------------------------
loss: 0.114459  [    0/ 3534]
loss: 0.053599  [  100/ 3534]
loss: 0.024643  [  200/ 3534]
loss: 0.100401  [  300/ 3534]
loss: 0.248412  [  400/ 3534]
loss: 0.014236  [  500/ 3534]
loss: 0.025463  [  600/ 3534]
loss: 0.078505  [  700/ 3534]
loss: 0.038278  [  800/ 3534]
loss: 0.033972  [  900/ 3534]
loss: 0.040400  [ 1000/ 3534]
loss: 0.020890  [ 1100/ 3534]
loss: 0.016039  [ 1200/ 3534]
loss: 0.051952  [ 1300/ 3534]
loss: 0.016558  [ 1400/ 3534]
loss: 0.042541  [ 1500/ 3534]
loss: 0.150050  [ 1600/ 3534]
loss: 0.052603  [ 1700/ 3534]
loss: 0.053374  [ 1800/ 3534]
loss: 0.035699  [ 1900/ 3534]
loss: 0.023832  [ 2000/ 3534]
loss: 0.033890  [ 2100/ 3534]
loss: 0.030436  [ 2200/ 3534]
loss: 0.124989  [ 2300/ 3534]
loss: 0.045438  [ 2400/ 3534]
loss: 0.094763  [ 2500/ 3534]
loss: 0.083867  [ 2600/ 3534]
loss: 0.027954  [ 2700/ 3534]
loss: 0.108586  [ 2800/ 3534]
loss: 0.031152  [ 2900/ 3534]
loss: 0.233735  [ 3000/ 3534]
loss: 0.051039  [ 3100/ 3534]
loss: 0.124857  [ 3200/ 3534]
loss: 0.063208  [ 3300/ 3534]
loss: 0.040979  [ 3400/ 3534]
loss: 0.071667  [ 3500/ 3534]
Epoch 5
-------------------------------
loss: 0.113516  [    0/ 3534]
loss: 0.049056  [  100/ 3534]
loss: 0.026454  [  200/ 3534]
loss: 0.099957  [  300/ 3534]
loss: 0.274697  [  400/ 3534]
loss: 0.011739  [  500/ 3534]
loss: 0.028809  [  600/ 3534]
loss: 0.079734  [  700/ 3534]
loss: 0.039708  [  800/ 3534]
loss: 0.042621  [  900/ 3534]
loss: 0.038635  [ 1000/ 3534]
loss: 0.020325  [ 1100/ 3534]
loss: 0.017166  [ 1200/ 3534]
loss: 0.050521  [ 1300/ 3534]
loss: 0.014599  [ 1400/ 3534]
loss: 0.040008  [ 1500/ 3534]
loss: 0.150265  [ 1600/ 3534]
loss: 0.052444  [ 1700/ 3534]
loss: 0.052802  [ 1800/ 3534]
loss: 0.035728  [ 1900/ 3534]
loss: 0.023095  [ 2000/ 3534]
loss: 0.033346  [ 2100/ 3534]
loss: 0.029273  [ 2200/ 3534]
loss: 0.122835  [ 2300/ 3534]
loss: 0.043068  [ 2400/ 3534]
loss: 0.095487  [ 2500/ 3534]
loss: 0.077100  [ 2600/ 3534]
loss: 0.027654  [ 2700/ 3534]
loss: 0.095916  [ 2800/ 3534]
loss: 0.029799  [ 2900/ 3534]
loss: 0.219611  [ 3000/ 3534]
loss: 0.053831  [ 3100/ 3534]
loss: 0.125126  [ 3200/ 3534]
loss: 0.068481  [ 3300/ 3534]
loss: 0.040445  [ 3400/ 3534]
loss: 0.072004  [ 3500/ 3534]
Epoch 6
-------------------------------
loss: 0.114256  [    0/ 3534]
loss: 0.050789  [  100/ 3534]
loss: 0.025996  [  200/ 3534]
loss: 0.099480  [  300/ 3534]
loss: 0.289702  [  400/ 3534]
loss: 0.010744  [  500/ 3534]
loss: 0.030932  [  600/ 3534]
loss: 0.081048  [  700/ 3534]
loss: 0.040599  [  800/ 3534]
loss: 0.044535  [  900/ 3534]
loss: 0.037789  [ 1000/ 3534]
loss: 0.020001  [ 1100/ 3534]
loss: 0.018609  [ 1200/ 3534]
loss: 0.049149  [ 1300/ 3534]
loss: 0.015098  [ 1400/ 3534]
loss: 0.038260  [ 1500/ 3534]
loss: 0.151726  [ 1600/ 3534]
loss: 0.052438  [ 1700/ 3534]
loss: 0.052067  [ 1800/ 3534]
loss: 0.037333  [ 1900/ 3534]
loss: 0.022557  [ 2000/ 3534]
loss: 0.032522  [ 2100/ 3534]
loss: 0.028982  [ 2200/ 3534]
loss: 0.120646  [ 2300/ 3534]
loss: 0.041066  [ 2400/ 3534]
loss: 0.094787  [ 2500/ 3534]
loss: 0.073375  [ 2600/ 3534]
loss: 0.027531  [ 2700/ 3534]
loss: 0.088026  [ 2800/ 3534]
loss: 0.029339  [ 2900/ 3534]
loss: 0.202862  [ 3000/ 3534]
loss: 0.055762  [ 3100/ 3534]
loss: 0.124838  [ 3200/ 3534]
loss: 0.074623  [ 3300/ 3534]
loss: 0.039996  [ 3400/ 3534]
loss: 0.071668  [ 3500/ 3534]
Epoch 7
-------------------------------
loss: 0.113947  [    0/ 3534]
loss: 0.048539  [  100/ 3534]
loss: 0.027336  [  200/ 3534]
loss: 0.101073  [  300/ 3534]
loss: 0.297708  [  400/ 3534]
loss: 0.010204  [  500/ 3534]
loss: 0.031456  [  600/ 3534]
loss: 0.081365  [  700/ 3534]
loss: 0.041940  [  800/ 3534]
loss: 0.049606  [  900/ 3534]
loss: 0.035993  [ 1000/ 3534]
loss: 0.019223  [ 1100/ 3534]
loss: 0.019110  [ 1200/ 3534]
loss: 0.048757  [ 1300/ 3534]
loss: 0.014538  [ 1400/ 3534]
loss: 0.036950  [ 1500/ 3534]
loss: 0.151815  [ 1600/ 3534]
loss: 0.052057  [ 1700/ 3534]
loss: 0.052112  [ 1800/ 3534]
loss: 0.038442  [ 1900/ 3534]
loss: 0.022922  [ 2000/ 3534]
loss: 0.031896  [ 2100/ 3534]
loss: 0.028264  [ 2200/ 3534]
loss: 0.118825  [ 2300/ 3534]
loss: 0.039858  [ 2400/ 3534]
loss: 0.095013  [ 2500/ 3534]
loss: 0.070798  [ 2600/ 3534]
loss: 0.027168  [ 2700/ 3534]
loss: 0.084287  [ 2800/ 3534]
loss: 0.030182  [ 2900/ 3534]
loss: 0.195677  [ 3000/ 3534]
loss: 0.056062  [ 3100/ 3534]
loss: 0.125141  [ 3200/ 3534]
loss: 0.077296  [ 3300/ 3534]
loss: 0.039435  [ 3400/ 3534]
loss: 0.071732  [ 3500/ 3534]
Epoch 8
-------------------------------
loss: 0.113706  [    0/ 3534]
loss: 0.049504  [  100/ 3534]
loss: 0.028022  [  200/ 3534]
loss: 0.102389  [  300/ 3534]
loss: 0.304725  [  400/ 3534]
loss: 0.010176  [  500/ 3534]
loss: 0.031965  [  600/ 3534]
loss: 0.080929  [  700/ 3534]
loss: 0.042358  [  800/ 3534]
loss: 0.051438  [  900/ 3534]
loss: 0.034690  [ 1000/ 3534]
loss: 0.018544  [ 1100/ 3534]
loss: 0.020387  [ 1200/ 3534]
loss: 0.048342  [ 1300/ 3534]
loss: 0.013744  [ 1400/ 3534]
loss: 0.035498  [ 1500/ 3534]
loss: 0.151767  [ 1600/ 3534]
loss: 0.051965  [ 1700/ 3534]
loss: 0.051201  [ 1800/ 3534]
loss: 0.039708  [ 1900/ 3534]
loss: 0.022794  [ 2000/ 3534]
loss: 0.031635  [ 2100/ 3534]
loss: 0.027895  [ 2200/ 3534]
loss: 0.117095  [ 2300/ 3534]
loss: 0.039059  [ 2400/ 3534]
loss: 0.094063  [ 2500/ 3534]
loss: 0.069587  [ 2600/ 3534]
loss: 0.027488  [ 2700/ 3534]
loss: 0.079087  [ 2800/ 3534]
loss: 0.029953  [ 2900/ 3534]
loss: 0.184891  [ 3000/ 3534]
loss: 0.056023  [ 3100/ 3534]
loss: 0.125145  [ 3200/ 3534]
loss: 0.077868  [ 3300/ 3534]
loss: 0.038896  [ 3400/ 3534]
loss: 0.071619  [ 3500/ 3534]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3534
First Spike after testing: [ 1.531378   -0.02063647]
[0 1 2 ... 2 2 1]
[2 1 0 ... 0 2 1]
Cluster 0 Occurrences: 1208; KMEANS: 1161
Cluster 1 Occurrences: 1137; KMEANS: 1130
Cluster 2 Occurrences: 1189; KMEANS: 1243
Centroids: [[1.4626269, -0.092542574], [-2.937596, 1.1801634], [1.1479291, 1.9277352]]
Centroids: [[1.2045482, 1.9693412], [-2.9766114, 1.2118286], [1.4133425, -0.10751375]]
Contingency Matrix: 
[[  45    0 1163]
 [  10 1106   21]
 [1106   24   59]]
[[-1, -1, -1], [10, 1106, -1], [1106, 24, -1]]
[[-1, -1, -1], [-1, -1, -1], [1106, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 1: 1, 2: 0}
New Contingency Matrix: 
[[1163    0   45]
 [  21 1106   10]
 [  59   24 1106]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1163, 1106, 1106], Sum: 3375
All_Elements: [1163, 0, 45, 21, 1106, 10, 59, 24, 1106], Sum: 3534
Accuracy: 0.9550084889643463
Done!
