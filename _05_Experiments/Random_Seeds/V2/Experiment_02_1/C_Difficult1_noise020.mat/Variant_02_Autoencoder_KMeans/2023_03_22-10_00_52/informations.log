Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Difficult1_noise020.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_00_52
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001720A6F7E80>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
<torch.utils.data.dataloader.DataLoader object at 0x00000171DA9C3A58>
Epoch 1
-------------------------------
loss: 0.195545  [    0/ 3414]
loss: 0.057594  [  100/ 3414]
loss: 0.018818  [  200/ 3414]
loss: 0.034462  [  300/ 3414]
loss: 0.051588  [  400/ 3414]
loss: 0.071064  [  500/ 3414]
loss: 0.035257  [  600/ 3414]
loss: 0.045140  [  700/ 3414]
loss: 0.066721  [  800/ 3414]
loss: 0.022485  [  900/ 3414]
loss: 0.019699  [ 1000/ 3414]
loss: 0.017304  [ 1100/ 3414]
loss: 0.051295  [ 1200/ 3414]
loss: 0.022024  [ 1300/ 3414]
loss: 0.018638  [ 1400/ 3414]
loss: 0.031171  [ 1500/ 3414]
loss: 0.030686  [ 1600/ 3414]
loss: 0.026465  [ 1700/ 3414]
loss: 0.026252  [ 1800/ 3414]
loss: 0.039486  [ 1900/ 3414]
loss: 0.037255  [ 2000/ 3414]
loss: 0.011690  [ 2100/ 3414]
loss: 0.047270  [ 2200/ 3414]
loss: 0.031243  [ 2300/ 3414]
loss: 0.010594  [ 2400/ 3414]
loss: 0.110139  [ 2500/ 3414]
loss: 0.020988  [ 2600/ 3414]
loss: 0.015185  [ 2700/ 3414]
loss: 0.007263  [ 2800/ 3414]
loss: 0.039087  [ 2900/ 3414]
loss: 0.016475  [ 3000/ 3414]
loss: 0.019031  [ 3100/ 3414]
loss: 0.031820  [ 3200/ 3414]
loss: 0.009859  [ 3300/ 3414]
loss: 0.022791  [ 3400/ 3414]
Epoch 2
-------------------------------
loss: 0.023099  [    0/ 3414]
loss: 0.029000  [  100/ 3414]
loss: 0.008345  [  200/ 3414]
loss: 0.049547  [  300/ 3414]
loss: 0.021698  [  400/ 3414]
loss: 0.049666  [  500/ 3414]
loss: 0.035586  [  600/ 3414]
loss: 0.023249  [  700/ 3414]
loss: 0.055433  [  800/ 3414]
loss: 0.015770  [  900/ 3414]
loss: 0.015809  [ 1000/ 3414]
loss: 0.023334  [ 1100/ 3414]
loss: 0.009851  [ 1200/ 3414]
loss: 0.032676  [ 1300/ 3414]
loss: 0.018293  [ 1400/ 3414]
loss: 0.028461  [ 1500/ 3414]
loss: 0.014068  [ 1600/ 3414]
loss: 0.013689  [ 1700/ 3414]
loss: 0.029341  [ 1800/ 3414]
loss: 0.020368  [ 1900/ 3414]
loss: 0.038119  [ 2000/ 3414]
loss: 0.026878  [ 2100/ 3414]
loss: 0.040332  [ 2200/ 3414]
loss: 0.033027  [ 2300/ 3414]
loss: 0.008797  [ 2400/ 3414]
loss: 0.151004  [ 2500/ 3414]
loss: 0.026075  [ 2600/ 3414]
loss: 0.014177  [ 2700/ 3414]
loss: 0.008676  [ 2800/ 3414]
loss: 0.039227  [ 2900/ 3414]
loss: 0.039987  [ 3000/ 3414]
loss: 0.031894  [ 3100/ 3414]
loss: 0.020992  [ 3200/ 3414]
loss: 0.012360  [ 3300/ 3414]
loss: 0.024344  [ 3400/ 3414]
Epoch 3
-------------------------------
loss: 0.036721  [    0/ 3414]
loss: 0.029529  [  100/ 3414]
loss: 0.008694  [  200/ 3414]
loss: 0.049624  [  300/ 3414]
loss: 0.013999  [  400/ 3414]
loss: 0.045233  [  500/ 3414]
loss: 0.029730  [  600/ 3414]
loss: 0.032284  [  700/ 3414]
loss: 0.052214  [  800/ 3414]
loss: 0.018962  [  900/ 3414]
loss: 0.016041  [ 1000/ 3414]
loss: 0.023519  [ 1100/ 3414]
loss: 0.007150  [ 1200/ 3414]
loss: 0.032802  [ 1300/ 3414]
loss: 0.018522  [ 1400/ 3414]
loss: 0.027950  [ 1500/ 3414]
loss: 0.011339  [ 1600/ 3414]
loss: 0.011091  [ 1700/ 3414]
loss: 0.029981  [ 1800/ 3414]
loss: 0.020513  [ 1900/ 3414]
loss: 0.034860  [ 2000/ 3414]
loss: 0.032651  [ 2100/ 3414]
loss: 0.040080  [ 2200/ 3414]
loss: 0.034331  [ 2300/ 3414]
loss: 0.008475  [ 2400/ 3414]
loss: 0.155657  [ 2500/ 3414]
loss: 0.025548  [ 2600/ 3414]
loss: 0.013779  [ 2700/ 3414]
loss: 0.011267  [ 2800/ 3414]
loss: 0.039873  [ 2900/ 3414]
loss: 0.043810  [ 3000/ 3414]
loss: 0.034561  [ 3100/ 3414]
loss: 0.020857  [ 3200/ 3414]
loss: 0.012412  [ 3300/ 3414]
loss: 0.025074  [ 3400/ 3414]
Epoch 4
-------------------------------
loss: 0.042459  [    0/ 3414]
loss: 0.029568  [  100/ 3414]
loss: 0.008662  [  200/ 3414]
loss: 0.049417  [  300/ 3414]
loss: 0.014141  [  400/ 3414]
loss: 0.044345  [  500/ 3414]
loss: 0.028603  [  600/ 3414]
loss: 0.034780  [  700/ 3414]
loss: 0.051925  [  800/ 3414]
loss: 0.020027  [  900/ 3414]
loss: 0.015945  [ 1000/ 3414]
loss: 0.023288  [ 1100/ 3414]
loss: 0.007105  [ 1200/ 3414]
loss: 0.032579  [ 1300/ 3414]
loss: 0.018682  [ 1400/ 3414]
loss: 0.027694  [ 1500/ 3414]
loss: 0.011044  [ 1600/ 3414]
loss: 0.010488  [ 1700/ 3414]
loss: 0.029801  [ 1800/ 3414]
loss: 0.020600  [ 1900/ 3414]
loss: 0.034019  [ 2000/ 3414]
loss: 0.033233  [ 2100/ 3414]
loss: 0.038888  [ 2200/ 3414]
loss: 0.034524  [ 2300/ 3414]
loss: 0.008373  [ 2400/ 3414]
loss: 0.156846  [ 2500/ 3414]
loss: 0.025101  [ 2600/ 3414]
loss: 0.013576  [ 2700/ 3414]
loss: 0.011664  [ 2800/ 3414]
loss: 0.039518  [ 2900/ 3414]
loss: 0.044325  [ 3000/ 3414]
loss: 0.034938  [ 3100/ 3414]
loss: 0.020773  [ 3200/ 3414]
loss: 0.012279  [ 3300/ 3414]
loss: 0.025181  [ 3400/ 3414]
Epoch 5
-------------------------------
loss: 0.043573  [    0/ 3414]
loss: 0.029658  [  100/ 3414]
loss: 0.008868  [  200/ 3414]
loss: 0.049116  [  300/ 3414]
loss: 0.014285  [  400/ 3414]
loss: 0.044210  [  500/ 3414]
loss: 0.028524  [  600/ 3414]
loss: 0.035404  [  700/ 3414]
loss: 0.051981  [  800/ 3414]
loss: 0.020544  [  900/ 3414]
loss: 0.015891  [ 1000/ 3414]
loss: 0.023099  [ 1100/ 3414]
loss: 0.007109  [ 1200/ 3414]
loss: 0.032557  [ 1300/ 3414]
loss: 0.018784  [ 1400/ 3414]
loss: 0.027487  [ 1500/ 3414]
loss: 0.010950  [ 1600/ 3414]
loss: 0.011014  [ 1700/ 3414]
loss: 0.029594  [ 1800/ 3414]
loss: 0.020609  [ 1900/ 3414]
loss: 0.033737  [ 2000/ 3414]
loss: 0.032949  [ 2100/ 3414]
loss: 0.038749  [ 2200/ 3414]
loss: 0.034594  [ 2300/ 3414]
loss: 0.008206  [ 2400/ 3414]
loss: 0.157526  [ 2500/ 3414]
loss: 0.024737  [ 2600/ 3414]
loss: 0.013443  [ 2700/ 3414]
loss: 0.011704  [ 2800/ 3414]
loss: 0.039279  [ 2900/ 3414]
loss: 0.044284  [ 3000/ 3414]
loss: 0.035016  [ 3100/ 3414]
loss: 0.020722  [ 3200/ 3414]
loss: 0.012158  [ 3300/ 3414]
loss: 0.025155  [ 3400/ 3414]
Epoch 6
-------------------------------
loss: 0.041753  [    0/ 3414]
loss: 0.029753  [  100/ 3414]
loss: 0.009012  [  200/ 3414]
loss: 0.048935  [  300/ 3414]
loss: 0.014316  [  400/ 3414]
loss: 0.044147  [  500/ 3414]
loss: 0.028723  [  600/ 3414]
loss: 0.035391  [  700/ 3414]
loss: 0.052069  [  800/ 3414]
loss: 0.021019  [  900/ 3414]
loss: 0.015772  [ 1000/ 3414]
loss: 0.022692  [ 1100/ 3414]
loss: 0.006864  [ 1200/ 3414]
loss: 0.032609  [ 1300/ 3414]
loss: 0.018834  [ 1400/ 3414]
loss: 0.027247  [ 1500/ 3414]
loss: 0.010937  [ 1600/ 3414]
loss: 0.011815  [ 1700/ 3414]
loss: 0.029480  [ 1800/ 3414]
loss: 0.020504  [ 1900/ 3414]
loss: 0.033334  [ 2000/ 3414]
loss: 0.033082  [ 2100/ 3414]
loss: 0.038460  [ 2200/ 3414]
loss: 0.034641  [ 2300/ 3414]
loss: 0.008054  [ 2400/ 3414]
loss: 0.157506  [ 2500/ 3414]
loss: 0.024110  [ 2600/ 3414]
loss: 0.013327  [ 2700/ 3414]
loss: 0.011979  [ 2800/ 3414]
loss: 0.039265  [ 2900/ 3414]
loss: 0.044486  [ 3000/ 3414]
loss: 0.035401  [ 3100/ 3414]
loss: 0.020649  [ 3200/ 3414]
loss: 0.012099  [ 3300/ 3414]
loss: 0.025242  [ 3400/ 3414]
Epoch 7
-------------------------------
loss: 0.036445  [    0/ 3414]
loss: 0.029830  [  100/ 3414]
loss: 0.008806  [  200/ 3414]
loss: 0.048872  [  300/ 3414]
loss: 0.014470  [  400/ 3414]
loss: 0.044038  [  500/ 3414]
loss: 0.028766  [  600/ 3414]
loss: 0.035755  [  700/ 3414]
loss: 0.052177  [  800/ 3414]
loss: 0.021265  [  900/ 3414]
loss: 0.015623  [ 1000/ 3414]
loss: 0.022229  [ 1100/ 3414]
loss: 0.007158  [ 1200/ 3414]
loss: 0.032513  [ 1300/ 3414]
loss: 0.018909  [ 1400/ 3414]
loss: 0.027149  [ 1500/ 3414]
loss: 0.010950  [ 1600/ 3414]
loss: 0.011059  [ 1700/ 3414]
loss: 0.029372  [ 1800/ 3414]
loss: 0.020499  [ 1900/ 3414]
loss: 0.032709  [ 2000/ 3414]
loss: 0.033135  [ 2100/ 3414]
loss: 0.038407  [ 2200/ 3414]
loss: 0.034731  [ 2300/ 3414]
loss: 0.007889  [ 2400/ 3414]
loss: 0.157895  [ 2500/ 3414]
loss: 0.023415  [ 2600/ 3414]
loss: 0.013303  [ 2700/ 3414]
loss: 0.012429  [ 2800/ 3414]
loss: 0.039453  [ 2900/ 3414]
loss: 0.044861  [ 3000/ 3414]
loss: 0.036110  [ 3100/ 3414]
loss: 0.020858  [ 3200/ 3414]
loss: 0.012127  [ 3300/ 3414]
loss: 0.025520  [ 3400/ 3414]
Epoch 8
-------------------------------
loss: 0.029867  [    0/ 3414]
loss: 0.029770  [  100/ 3414]
loss: 0.008677  [  200/ 3414]
loss: 0.048694  [  300/ 3414]
loss: 0.014697  [  400/ 3414]
loss: 0.043867  [  500/ 3414]
loss: 0.028551  [  600/ 3414]
loss: 0.036646  [  700/ 3414]
loss: 0.052121  [  800/ 3414]
loss: 0.021818  [  900/ 3414]
loss: 0.015459  [ 1000/ 3414]
loss: 0.021779  [ 1100/ 3414]
loss: 0.007243  [ 1200/ 3414]
loss: 0.032346  [ 1300/ 3414]
loss: 0.019000  [ 1400/ 3414]
loss: 0.027125  [ 1500/ 3414]
loss: 0.010973  [ 1600/ 3414]
loss: 0.009837  [ 1700/ 3414]
loss: 0.029384  [ 1800/ 3414]
loss: 0.020636  [ 1900/ 3414]
loss: 0.031885  [ 2000/ 3414]
loss: 0.034017  [ 2100/ 3414]
loss: 0.038438  [ 2200/ 3414]
loss: 0.034964  [ 2300/ 3414]
loss: 0.007833  [ 2400/ 3414]
loss: 0.157959  [ 2500/ 3414]
loss: 0.022744  [ 2600/ 3414]
loss: 0.013245  [ 2700/ 3414]
loss: 0.013176  [ 2800/ 3414]
loss: 0.039587  [ 2900/ 3414]
loss: 0.045507  [ 3000/ 3414]
loss: 0.036724  [ 3100/ 3414]
loss: 0.020833  [ 3200/ 3414]
loss: 0.012131  [ 3300/ 3414]
loss: 0.025738  [ 3400/ 3414]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3414
First Spike after testing: [-0.5994479  0.6835789]
[1 1 0 ... 0 0 2]
[2 0 2 ... 2 1 0]
Cluster 0 Occurrences: 1136; KMEANS: 953
Cluster 1 Occurrences: 1099; KMEANS: 1516
Cluster 2 Occurrences: 1179; KMEANS: 945
Centroids: [[0.3188202, 0.33735672], [0.47111925, 0.16292365], [0.6711558, 0.28380984]]
Centroids: [[0.84120727, -0.16427904], [0.50005794, 0.2749551], [0.117962144, 0.6736806]]
Contingency Matrix: 
[[185 465 486]
 [363 498 238]
 [405 553 221]]
[[185, -1, 486], [363, -1, 238], [-1, -1, -1]]
[[-1, -1, -1], [363, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[486 185 465]
 [238 363 498]
 [221 405 553]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [486, 363, 553], Sum: 1402
All_Elements: [486, 185, 465, 238, 363, 498, 221, 405, 553], Sum: 3414
Accuracy: 0.4106619800820152
Done!
