Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Difficult2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_02_28
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000171FFC3B0F0>
Sampling rate: 24000.0
Raw: [ 0.02085333  0.02043967  0.02052644 ... -0.02218732 -0.02150573
 -0.01811243]
Times: [   1583    1934    2430 ... 1439313 1439656 1439854]
Cluster: [3 3 3 ... 2 2 1]
Number of different clusters:  3
Number of Spikes: 3364
First aligned Spike Frame: [-0.05170878 -0.0548761  -0.06029554 -0.06053219 -0.04807119 -0.02780025
 -0.01550543 -0.01702494 -0.02945104 -0.04493807 -0.07056858 -0.07003585
  0.07629654  0.43081562  0.80470191  0.96319627  0.89198123  0.73643948
  0.58987232  0.46714337  0.36345495  0.2828462   0.22743292  0.182731
  0.13931053  0.09524506  0.05136602  0.01367166 -0.01393093 -0.03985679
 -0.07387102 -0.11218435 -0.1444455  -0.16672578 -0.17809238 -0.18020802
 -0.17953732 -0.18246903 -0.18617363 -0.18205375 -0.17299738 -0.16958427
 -0.17248955 -0.17516876 -0.1727246  -0.16696514 -0.15993314]
Cluster 0, Occurrences: 1120
Cluster 1, Occurrences: 1109
Cluster 2, Occurrences: 1135
<torch.utils.data.dataloader.DataLoader object at 0x00000171DB81B128>
Epoch 1
-------------------------------
loss: 0.147501  [    0/ 3364]
loss: 0.066508  [  100/ 3364]
loss: 0.049314  [  200/ 3364]
loss: 0.033983  [  300/ 3364]
loss: 0.012960  [  400/ 3364]
loss: 0.039492  [  500/ 3364]
loss: 0.004680  [  600/ 3364]
loss: 0.006162  [  700/ 3364]
loss: 0.003328  [  800/ 3364]
loss: 0.006157  [  900/ 3364]
loss: 0.005771  [ 1000/ 3364]
loss: 0.003710  [ 1100/ 3364]
loss: 0.005526  [ 1200/ 3364]
loss: 0.004753  [ 1300/ 3364]
loss: 0.087243  [ 1400/ 3364]
loss: 0.003098  [ 1500/ 3364]
loss: 0.006516  [ 1600/ 3364]
loss: 0.004828  [ 1700/ 3364]
loss: 0.001896  [ 1800/ 3364]
loss: 0.003952  [ 1900/ 3364]
loss: 0.002733  [ 2000/ 3364]
loss: 0.005203  [ 2100/ 3364]
loss: 0.006378  [ 2200/ 3364]
loss: 0.007333  [ 2300/ 3364]
loss: 0.001337  [ 2400/ 3364]
loss: 0.002668  [ 2500/ 3364]
loss: 0.002162  [ 2600/ 3364]
loss: 0.003968  [ 2700/ 3364]
loss: 0.004162  [ 2800/ 3364]
loss: 0.001805  [ 2900/ 3364]
loss: 0.003828  [ 3000/ 3364]
loss: 0.006286  [ 3100/ 3364]
loss: 0.001875  [ 3200/ 3364]
loss: 0.001147  [ 3300/ 3364]
Epoch 2
-------------------------------
loss: 0.001823  [    0/ 3364]
loss: 0.002352  [  100/ 3364]
loss: 0.004596  [  200/ 3364]
loss: 0.001073  [  300/ 3364]
loss: 0.000600  [  400/ 3364]
loss: 0.032362  [  500/ 3364]
loss: 0.004273  [  600/ 3364]
loss: 0.008953  [  700/ 3364]
loss: 0.002465  [  800/ 3364]
loss: 0.003037  [  900/ 3364]
loss: 0.003322  [ 1000/ 3364]
loss: 0.003743  [ 1100/ 3364]
loss: 0.002536  [ 1200/ 3364]
loss: 0.004939  [ 1300/ 3364]
loss: 0.086012  [ 1400/ 3364]
loss: 0.002758  [ 1500/ 3364]
loss: 0.006177  [ 1600/ 3364]
loss: 0.002979  [ 1700/ 3364]
loss: 0.001341  [ 1800/ 3364]
loss: 0.003468  [ 1900/ 3364]
loss: 0.002524  [ 2000/ 3364]
loss: 0.004640  [ 2100/ 3364]
loss: 0.005490  [ 2200/ 3364]
loss: 0.007142  [ 2300/ 3364]
loss: 0.000996  [ 2400/ 3364]
loss: 0.002439  [ 2500/ 3364]
loss: 0.001979  [ 2600/ 3364]
loss: 0.003850  [ 2700/ 3364]
loss: 0.003704  [ 2800/ 3364]
loss: 0.001657  [ 2900/ 3364]
loss: 0.003698  [ 3000/ 3364]
loss: 0.006232  [ 3100/ 3364]
loss: 0.001798  [ 3200/ 3364]
loss: 0.000938  [ 3300/ 3364]
Epoch 3
-------------------------------
loss: 0.001675  [    0/ 3364]
loss: 0.002557  [  100/ 3364]
loss: 0.004560  [  200/ 3364]
loss: 0.000840  [  300/ 3364]
loss: 0.000958  [  400/ 3364]
loss: 0.029815  [  500/ 3364]
loss: 0.004005  [  600/ 3364]
loss: 0.009019  [  700/ 3364]
loss: 0.002317  [  800/ 3364]
loss: 0.002737  [  900/ 3364]
loss: 0.003565  [ 1000/ 3364]
loss: 0.003645  [ 1100/ 3364]
loss: 0.002212  [ 1200/ 3364]
loss: 0.004694  [ 1300/ 3364]
loss: 0.086013  [ 1400/ 3364]
loss: 0.002719  [ 1500/ 3364]
loss: 0.006159  [ 1600/ 3364]
loss: 0.003002  [ 1700/ 3364]
loss: 0.001238  [ 1800/ 3364]
loss: 0.003631  [ 1900/ 3364]
loss: 0.002706  [ 2000/ 3364]
loss: 0.004619  [ 2100/ 3364]
loss: 0.005529  [ 2200/ 3364]
loss: 0.007255  [ 2300/ 3364]
loss: 0.000994  [ 2400/ 3364]
loss: 0.002375  [ 2500/ 3364]
loss: 0.002137  [ 2600/ 3364]
loss: 0.003682  [ 2700/ 3364]
loss: 0.003748  [ 2800/ 3364]
loss: 0.001667  [ 2900/ 3364]
loss: 0.003744  [ 3000/ 3364]
loss: 0.006247  [ 3100/ 3364]
loss: 0.001773  [ 3200/ 3364]
loss: 0.001369  [ 3300/ 3364]
Epoch 4
-------------------------------
loss: 0.001533  [    0/ 3364]
loss: 0.002539  [  100/ 3364]
loss: 0.004425  [  200/ 3364]
loss: 0.000815  [  300/ 3364]
loss: 0.000689  [  400/ 3364]
loss: 0.028977  [  500/ 3364]
loss: 0.003705  [  600/ 3364]
loss: 0.008098  [  700/ 3364]
loss: 0.002356  [  800/ 3364]
loss: 0.002770  [  900/ 3364]
loss: 0.002887  [ 1000/ 3364]
loss: 0.003609  [ 1100/ 3364]
loss: 0.002079  [ 1200/ 3364]
loss: 0.004452  [ 1300/ 3364]
loss: 0.086105  [ 1400/ 3364]
loss: 0.002734  [ 1500/ 3364]
loss: 0.006233  [ 1600/ 3364]
loss: 0.003003  [ 1700/ 3364]
loss: 0.001162  [ 1800/ 3364]
loss: 0.003961  [ 1900/ 3364]
loss: 0.002789  [ 2000/ 3364]
loss: 0.004374  [ 2100/ 3364]
loss: 0.005394  [ 2200/ 3364]
loss: 0.007349  [ 2300/ 3364]
loss: 0.001023  [ 2400/ 3364]
loss: 0.002354  [ 2500/ 3364]
loss: 0.002200  [ 2600/ 3364]
loss: 0.003662  [ 2700/ 3364]
loss: 0.003322  [ 2800/ 3364]
loss: 0.001743  [ 2900/ 3364]
loss: 0.003808  [ 3000/ 3364]
loss: 0.006259  [ 3100/ 3364]
loss: 0.001741  [ 3200/ 3364]
loss: 0.001490  [ 3300/ 3364]
Epoch 5
-------------------------------
loss: 0.001384  [    0/ 3364]
loss: 0.003159  [  100/ 3364]
loss: 0.004463  [  200/ 3364]
loss: 0.000778  [  300/ 3364]
loss: 0.000635  [  400/ 3364]
loss: 0.027793  [  500/ 3364]
loss: 0.003436  [  600/ 3364]
loss: 0.006072  [  700/ 3364]
loss: 0.002373  [  800/ 3364]
loss: 0.002722  [  900/ 3364]
loss: 0.001878  [ 1000/ 3364]
loss: 0.003573  [ 1100/ 3364]
loss: 0.001995  [ 1200/ 3364]
loss: 0.004301  [ 1300/ 3364]
loss: 0.086597  [ 1400/ 3364]
loss: 0.002714  [ 1500/ 3364]
loss: 0.006345  [ 1600/ 3364]
loss: 0.003014  [ 1700/ 3364]
loss: 0.001114  [ 1800/ 3364]
loss: 0.003830  [ 1900/ 3364]
loss: 0.002936  [ 2000/ 3364]
loss: 0.004269  [ 2100/ 3364]
loss: 0.005322  [ 2200/ 3364]
loss: 0.007546  [ 2300/ 3364]
loss: 0.001027  [ 2400/ 3364]
loss: 0.002378  [ 2500/ 3364]
loss: 0.002260  [ 2600/ 3364]
loss: 0.003631  [ 2700/ 3364]
loss: 0.003217  [ 2800/ 3364]
loss: 0.001833  [ 2900/ 3364]
loss: 0.003827  [ 3000/ 3364]
loss: 0.006285  [ 3100/ 3364]
loss: 0.001655  [ 3200/ 3364]
loss: 0.001381  [ 3300/ 3364]
Epoch 6
-------------------------------
loss: 0.001314  [    0/ 3364]
loss: 0.003199  [  100/ 3364]
loss: 0.004500  [  200/ 3364]
loss: 0.000756  [  300/ 3364]
loss: 0.000629  [  400/ 3364]
loss: 0.027440  [  500/ 3364]
loss: 0.003335  [  600/ 3364]
loss: 0.004669  [  700/ 3364]
loss: 0.002382  [  800/ 3364]
loss: 0.002801  [  900/ 3364]
loss: 0.001627  [ 1000/ 3364]
loss: 0.003526  [ 1100/ 3364]
loss: 0.001980  [ 1200/ 3364]
loss: 0.004213  [ 1300/ 3364]
loss: 0.086252  [ 1400/ 3364]
loss: 0.002751  [ 1500/ 3364]
loss: 0.007249  [ 1600/ 3364]
loss: 0.003063  [ 1700/ 3364]
loss: 0.001117  [ 1800/ 3364]
loss: 0.004008  [ 1900/ 3364]
loss: 0.002798  [ 2000/ 3364]
loss: 0.004008  [ 2100/ 3364]
loss: 0.005126  [ 2200/ 3364]
loss: 0.007544  [ 2300/ 3364]
loss: 0.001023  [ 2400/ 3364]
loss: 0.002335  [ 2500/ 3364]
loss: 0.002410  [ 2600/ 3364]
loss: 0.003431  [ 2700/ 3364]
loss: 0.003249  [ 2800/ 3364]
loss: 0.002019  [ 2900/ 3364]
loss: 0.003821  [ 3000/ 3364]
loss: 0.006563  [ 3100/ 3364]
loss: 0.001668  [ 3200/ 3364]
loss: 0.001455  [ 3300/ 3364]
Epoch 7
-------------------------------
loss: 0.001369  [    0/ 3364]
loss: 0.002702  [  100/ 3364]
loss: 0.004391  [  200/ 3364]
loss: 0.000671  [  300/ 3364]
loss: 0.000782  [  400/ 3364]
loss: 0.027058  [  500/ 3364]
loss: 0.003160  [  600/ 3364]
loss: 0.005912  [  700/ 3364]
loss: 0.002420  [  800/ 3364]
loss: 0.002856  [  900/ 3364]
loss: 0.001401  [ 1000/ 3364]
loss: 0.003537  [ 1100/ 3364]
loss: 0.001959  [ 1200/ 3364]
loss: 0.004098  [ 1300/ 3364]
loss: 0.087119  [ 1400/ 3364]
loss: 0.002717  [ 1500/ 3364]
loss: 0.007118  [ 1600/ 3364]
loss: 0.003069  [ 1700/ 3364]
loss: 0.001167  [ 1800/ 3364]
loss: 0.003891  [ 1900/ 3364]
loss: 0.002992  [ 2000/ 3364]
loss: 0.003804  [ 2100/ 3364]
loss: 0.004976  [ 2200/ 3364]
loss: 0.007525  [ 2300/ 3364]
loss: 0.001076  [ 2400/ 3364]
loss: 0.002414  [ 2500/ 3364]
loss: 0.002288  [ 2600/ 3364]
loss: 0.003482  [ 2700/ 3364]
loss: 0.003136  [ 2800/ 3364]
loss: 0.001664  [ 2900/ 3364]
loss: 0.003935  [ 3000/ 3364]
loss: 0.006510  [ 3100/ 3364]
loss: 0.001623  [ 3200/ 3364]
loss: 0.001409  [ 3300/ 3364]
Epoch 8
-------------------------------
loss: 0.001326  [    0/ 3364]
loss: 0.002898  [  100/ 3364]
loss: 0.004352  [  200/ 3364]
loss: 0.000632  [  300/ 3364]
loss: 0.000757  [  400/ 3364]
loss: 0.027247  [  500/ 3364]
loss: 0.003032  [  600/ 3364]
loss: 0.004202  [  700/ 3364]
loss: 0.002576  [  800/ 3364]
loss: 0.003755  [  900/ 3364]
loss: 0.001088  [ 1000/ 3364]
loss: 0.003550  [ 1100/ 3364]
loss: 0.001954  [ 1200/ 3364]
loss: 0.004102  [ 1300/ 3364]
loss: 0.086731  [ 1400/ 3364]
loss: 0.002725  [ 1500/ 3364]
loss: 0.007147  [ 1600/ 3364]
loss: 0.002974  [ 1700/ 3364]
loss: 0.001157  [ 1800/ 3364]
loss: 0.003852  [ 1900/ 3364]
loss: 0.003083  [ 2000/ 3364]
loss: 0.003801  [ 2100/ 3364]
loss: 0.004778  [ 2200/ 3364]
loss: 0.007531  [ 2300/ 3364]
loss: 0.001065  [ 2400/ 3364]
loss: 0.002450  [ 2500/ 3364]
loss: 0.002241  [ 2600/ 3364]
loss: 0.003378  [ 2700/ 3364]
loss: 0.003080  [ 2800/ 3364]
loss: 0.001639  [ 2900/ 3364]
loss: 0.003931  [ 3000/ 3364]
loss: 0.006474  [ 3100/ 3364]
loss: 0.001477  [ 3200/ 3364]
loss: 0.001393  [ 3300/ 3364]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3364
First Spike after testing: [0.5332595 0.9565268]
[2 2 2 ... 1 1 0]
[0 0 0 ... 1 1 2]
Cluster 0 Occurrences: 1120; KMEANS: 1109
Cluster 1 Occurrences: 1109; KMEANS: 1115
Cluster 2 Occurrences: 1135; KMEANS: 1140
Centroids: [[1.146591, 0.30794272], [-0.57431453, 1.3606251], [0.62034786, 0.8782761]]
Centroids: [[0.6012366, 0.89101446], [-0.57511586, 1.3697795], [1.1630217, 0.29406428]]
Contingency Matrix: 
[[   9    4 1107]
 [   5 1102    2]
 [1095    9   31]]
[[-1, -1, -1], [5, 1102, -1], [1095, 9, -1]]
[[-1, -1, -1], [-1, -1, -1], [1095, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 1: 1, 2: 0}
New Contingency Matrix: 
[[1107    4    9]
 [   2 1102    5]
 [  31    9 1095]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1107, 1102, 1095], Sum: 3304
All_Elements: [1107, 4, 9, 2, 1102, 5, 31, 9, 1095], Sum: 3364
Accuracy: 0.9821640903686087
Done!
