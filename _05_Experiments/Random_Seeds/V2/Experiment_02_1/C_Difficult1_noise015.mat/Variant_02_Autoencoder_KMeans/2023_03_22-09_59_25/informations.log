Experiment_path: Random_Seeds//V2/Experiment_02_1
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_1/C_Difficult1_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_59_25
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000171DA9C3A58>
Sampling rate: 24000.0
Raw: [ 0.04887081  0.02693095 -0.0154249  ... -0.09301659 -0.11629005
 -0.14613101]
Times: [    340     491     641 ... 1439047 1439065 1439816]
Cluster: [1 1 1 ... 3 2 2]
Number of different clusters:  3
Number of Spikes: 3472
First aligned Spike Frame: [ 0.12751554  0.12305882  0.10482977  0.09479529  0.10214978  0.11675932
  0.11777927  0.09307299  0.04670706 -0.00574343 -0.06143573 -0.14637617
 -0.20942665 -0.00208103  0.52241508  0.81651544  0.46446121 -0.19226425
 -0.60927882 -0.6713583  -0.57871227 -0.49011309 -0.4269388  -0.3668903
 -0.30523219 -0.24747124 -0.19738203 -0.15189972 -0.10449507 -0.05533325
 -0.01452429  0.01008816  0.02570853  0.04365027  0.06334113  0.07980397
  0.08484457  0.07688513  0.06142919  0.04320028  0.02240626  0.00477291
 -0.00393242 -0.00135684  0.00575182  0.0026944  -0.01541647]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1172
Cluster 2, Occurrences: 1141
<torch.utils.data.dataloader.DataLoader object at 0x000001721398CC50>
Epoch 1
-------------------------------
loss: 0.097997  [    0/ 3472]
loss: 0.060711  [  100/ 3472]
loss: 0.008609  [  200/ 3472]
loss: 0.025309  [  300/ 3472]
loss: 0.042316  [  400/ 3472]
loss: 0.014703  [  500/ 3472]
loss: 0.020085  [  600/ 3472]
loss: 0.018460  [  700/ 3472]
loss: 0.033720  [  800/ 3472]
loss: 0.027357  [  900/ 3472]
loss: 0.015044  [ 1000/ 3472]
loss: 0.025904  [ 1100/ 3472]
loss: 0.024012  [ 1200/ 3472]
loss: 0.018637  [ 1300/ 3472]
loss: 0.008018  [ 1400/ 3472]
loss: 0.051458  [ 1500/ 3472]
loss: 0.017692  [ 1600/ 3472]
loss: 0.006453  [ 1700/ 3472]
loss: 0.023552  [ 1800/ 3472]
loss: 0.169320  [ 1900/ 3472]
loss: 0.062530  [ 2000/ 3472]
loss: 0.012015  [ 2100/ 3472]
loss: 0.010269  [ 2200/ 3472]
loss: 0.020568  [ 2300/ 3472]
loss: 0.052858  [ 2400/ 3472]
loss: 0.021220  [ 2500/ 3472]
loss: 0.017361  [ 2600/ 3472]
loss: 0.023776  [ 2700/ 3472]
loss: 0.013598  [ 2800/ 3472]
loss: 0.009113  [ 2900/ 3472]
loss: 0.008694  [ 3000/ 3472]
loss: 0.004093  [ 3100/ 3472]
loss: 0.014413  [ 3200/ 3472]
loss: 0.015340  [ 3300/ 3472]
loss: 0.021088  [ 3400/ 3472]
Epoch 2
-------------------------------
loss: 0.009572  [    0/ 3472]
loss: 0.008143  [  100/ 3472]
loss: 0.010282  [  200/ 3472]
loss: 0.023645  [  300/ 3472]
loss: 0.012126  [  400/ 3472]
loss: 0.011147  [  500/ 3472]
loss: 0.024026  [  600/ 3472]
loss: 0.011152  [  700/ 3472]
loss: 0.036947  [  800/ 3472]
loss: 0.023850  [  900/ 3472]
loss: 0.010652  [ 1000/ 3472]
loss: 0.027582  [ 1100/ 3472]
loss: 0.023239  [ 1200/ 3472]
loss: 0.006944  [ 1300/ 3472]
loss: 0.005029  [ 1400/ 3472]
loss: 0.022714  [ 1500/ 3472]
loss: 0.013083  [ 1600/ 3472]
loss: 0.007793  [ 1700/ 3472]
loss: 0.042734  [ 1800/ 3472]
loss: 0.131211  [ 1900/ 3472]
loss: 0.062061  [ 2000/ 3472]
loss: 0.019522  [ 2100/ 3472]
loss: 0.010629  [ 2200/ 3472]
loss: 0.010543  [ 2300/ 3472]
loss: 0.021067  [ 2400/ 3472]
loss: 0.016532  [ 2500/ 3472]
loss: 0.010084  [ 2600/ 3472]
loss: 0.017516  [ 2700/ 3472]
loss: 0.028668  [ 2800/ 3472]
loss: 0.028364  [ 2900/ 3472]
loss: 0.008360  [ 3000/ 3472]
loss: 0.013916  [ 3100/ 3472]
loss: 0.014028  [ 3200/ 3472]
loss: 0.011165  [ 3300/ 3472]
loss: 0.012427  [ 3400/ 3472]
Epoch 3
-------------------------------
loss: 0.006747  [    0/ 3472]
loss: 0.008031  [  100/ 3472]
loss: 0.010198  [  200/ 3472]
loss: 0.018577  [  300/ 3472]
loss: 0.004715  [  400/ 3472]
loss: 0.014689  [  500/ 3472]
loss: 0.013021  [  600/ 3472]
loss: 0.007224  [  700/ 3472]
loss: 0.037598  [  800/ 3472]
loss: 0.026177  [  900/ 3472]
loss: 0.009693  [ 1000/ 3472]
loss: 0.028097  [ 1100/ 3472]
loss: 0.025068  [ 1200/ 3472]
loss: 0.004927  [ 1300/ 3472]
loss: 0.003605  [ 1400/ 3472]
loss: 0.033138  [ 1500/ 3472]
loss: 0.018052  [ 1600/ 3472]
loss: 0.010830  [ 1700/ 3472]
loss: 0.032865  [ 1800/ 3472]
loss: 0.131248  [ 1900/ 3472]
loss: 0.052448  [ 2000/ 3472]
loss: 0.015369  [ 2100/ 3472]
loss: 0.010776  [ 2200/ 3472]
loss: 0.005915  [ 2300/ 3472]
loss: 0.010159  [ 2400/ 3472]
loss: 0.013305  [ 2500/ 3472]
loss: 0.013927  [ 2600/ 3472]
loss: 0.012458  [ 2700/ 3472]
loss: 0.026922  [ 2800/ 3472]
loss: 0.030290  [ 2900/ 3472]
loss: 0.008316  [ 3000/ 3472]
loss: 0.020149  [ 3100/ 3472]
loss: 0.014008  [ 3200/ 3472]
loss: 0.009758  [ 3300/ 3472]
loss: 0.009779  [ 3400/ 3472]
Epoch 4
-------------------------------
loss: 0.008998  [    0/ 3472]
loss: 0.007578  [  100/ 3472]
loss: 0.010002  [  200/ 3472]
loss: 0.018122  [  300/ 3472]
loss: 0.005831  [  400/ 3472]
loss: 0.015276  [  500/ 3472]
loss: 0.012171  [  600/ 3472]
loss: 0.005887  [  700/ 3472]
loss: 0.036682  [  800/ 3472]
loss: 0.027042  [  900/ 3472]
loss: 0.009972  [ 1000/ 3472]
loss: 0.027117  [ 1100/ 3472]
loss: 0.024598  [ 1200/ 3472]
loss: 0.005924  [ 1300/ 3472]
loss: 0.003321  [ 1400/ 3472]
loss: 0.035665  [ 1500/ 3472]
loss: 0.018745  [ 1600/ 3472]
loss: 0.011151  [ 1700/ 3472]
loss: 0.030119  [ 1800/ 3472]
loss: 0.133122  [ 1900/ 3472]
loss: 0.050725  [ 2000/ 3472]
loss: 0.014339  [ 2100/ 3472]
loss: 0.010809  [ 2200/ 3472]
loss: 0.005465  [ 2300/ 3472]
loss: 0.009120  [ 2400/ 3472]
loss: 0.012923  [ 2500/ 3472]
loss: 0.014842  [ 2600/ 3472]
loss: 0.011719  [ 2700/ 3472]
loss: 0.026321  [ 2800/ 3472]
loss: 0.030294  [ 2900/ 3472]
loss: 0.008310  [ 3000/ 3472]
loss: 0.021099  [ 3100/ 3472]
loss: 0.013956  [ 3200/ 3472]
loss: 0.009497  [ 3300/ 3472]
loss: 0.009346  [ 3400/ 3472]
Epoch 5
-------------------------------
loss: 0.009389  [    0/ 3472]
loss: 0.007372  [  100/ 3472]
loss: 0.009966  [  200/ 3472]
loss: 0.018200  [  300/ 3472]
loss: 0.006168  [  400/ 3472]
loss: 0.015256  [  500/ 3472]
loss: 0.012094  [  600/ 3472]
loss: 0.005704  [  700/ 3472]
loss: 0.036376  [  800/ 3472]
loss: 0.027153  [  900/ 3472]
loss: 0.010055  [ 1000/ 3472]
loss: 0.026841  [ 1100/ 3472]
loss: 0.024385  [ 1200/ 3472]
loss: 0.006107  [ 1300/ 3472]
loss: 0.003241  [ 1400/ 3472]
loss: 0.036164  [ 1500/ 3472]
loss: 0.018779  [ 1600/ 3472]
loss: 0.011163  [ 1700/ 3472]
loss: 0.029454  [ 1800/ 3472]
loss: 0.133659  [ 1900/ 3472]
loss: 0.050307  [ 2000/ 3472]
loss: 0.014004  [ 2100/ 3472]
loss: 0.010813  [ 2200/ 3472]
loss: 0.005355  [ 2300/ 3472]
loss: 0.008834  [ 2400/ 3472]
loss: 0.012930  [ 2500/ 3472]
loss: 0.015157  [ 2600/ 3472]
loss: 0.011605  [ 2700/ 3472]
loss: 0.026213  [ 2800/ 3472]
loss: 0.030094  [ 2900/ 3472]
loss: 0.008314  [ 3000/ 3472]
loss: 0.021318  [ 3100/ 3472]
loss: 0.013914  [ 3200/ 3472]
loss: 0.009602  [ 3300/ 3472]
loss: 0.009203  [ 3400/ 3472]
Epoch 6
-------------------------------
loss: 0.009412  [    0/ 3472]
loss: 0.007254  [  100/ 3472]
loss: 0.009916  [  200/ 3472]
loss: 0.018296  [  300/ 3472]
loss: 0.006518  [  400/ 3472]
loss: 0.015126  [  500/ 3472]
loss: 0.012112  [  600/ 3472]
loss: 0.005648  [  700/ 3472]
loss: 0.036212  [  800/ 3472]
loss: 0.027114  [  900/ 3472]
loss: 0.010054  [ 1000/ 3472]
loss: 0.026711  [ 1100/ 3472]
loss: 0.024239  [ 1200/ 3472]
loss: 0.006099  [ 1300/ 3472]
loss: 0.003215  [ 1400/ 3472]
loss: 0.036020  [ 1500/ 3472]
loss: 0.018753  [ 1600/ 3472]
loss: 0.011119  [ 1700/ 3472]
loss: 0.029394  [ 1800/ 3472]
loss: 0.134640  [ 1900/ 3472]
loss: 0.050455  [ 2000/ 3472]
loss: 0.013914  [ 2100/ 3472]
loss: 0.010847  [ 2200/ 3472]
loss: 0.005357  [ 2300/ 3472]
loss: 0.008572  [ 2400/ 3472]
loss: 0.013021  [ 2500/ 3472]
loss: 0.015154  [ 2600/ 3472]
loss: 0.011665  [ 2700/ 3472]
loss: 0.026336  [ 2800/ 3472]
loss: 0.030011  [ 2900/ 3472]
loss: 0.008312  [ 3000/ 3472]
loss: 0.021198  [ 3100/ 3472]
loss: 0.013845  [ 3200/ 3472]
loss: 0.009728  [ 3300/ 3472]
loss: 0.009148  [ 3400/ 3472]
Epoch 7
-------------------------------
loss: 0.009311  [    0/ 3472]
loss: 0.007192  [  100/ 3472]
loss: 0.009934  [  200/ 3472]
loss: 0.018364  [  300/ 3472]
loss: 0.006669  [  400/ 3472]
loss: 0.015012  [  500/ 3472]
loss: 0.012121  [  600/ 3472]
loss: 0.005634  [  700/ 3472]
loss: 0.036090  [  800/ 3472]
loss: 0.027061  [  900/ 3472]
loss: 0.010049  [ 1000/ 3472]
loss: 0.026641  [ 1100/ 3472]
loss: 0.024121  [ 1200/ 3472]
loss: 0.006075  [ 1300/ 3472]
loss: 0.003228  [ 1400/ 3472]
loss: 0.036223  [ 1500/ 3472]
loss: 0.018722  [ 1600/ 3472]
loss: 0.011098  [ 1700/ 3472]
loss: 0.029401  [ 1800/ 3472]
loss: 0.135106  [ 1900/ 3472]
loss: 0.050823  [ 2000/ 3472]
loss: 0.013862  [ 2100/ 3472]
loss: 0.010842  [ 2200/ 3472]
loss: 0.005390  [ 2300/ 3472]
loss: 0.008566  [ 2400/ 3472]
loss: 0.013158  [ 2500/ 3472]
loss: 0.015090  [ 2600/ 3472]
loss: 0.011723  [ 2700/ 3472]
loss: 0.026481  [ 2800/ 3472]
loss: 0.029845  [ 2900/ 3472]
loss: 0.008340  [ 3000/ 3472]
loss: 0.021099  [ 3100/ 3472]
loss: 0.013812  [ 3200/ 3472]
loss: 0.009981  [ 3300/ 3472]
loss: 0.009154  [ 3400/ 3472]
Epoch 8
-------------------------------
loss: 0.009196  [    0/ 3472]
loss: 0.007109  [  100/ 3472]
loss: 0.009945  [  200/ 3472]
loss: 0.018450  [  300/ 3472]
loss: 0.006644  [  400/ 3472]
loss: 0.014944  [  500/ 3472]
loss: 0.012152  [  600/ 3472]
loss: 0.005638  [  700/ 3472]
loss: 0.035988  [  800/ 3472]
loss: 0.027013  [  900/ 3472]
loss: 0.010011  [ 1000/ 3472]
loss: 0.026541  [ 1100/ 3472]
loss: 0.023984  [ 1200/ 3472]
loss: 0.005999  [ 1300/ 3472]
loss: 0.003250  [ 1400/ 3472]
loss: 0.036685  [ 1500/ 3472]
loss: 0.018682  [ 1600/ 3472]
loss: 0.011079  [ 1700/ 3472]
loss: 0.029413  [ 1800/ 3472]
loss: 0.135518  [ 1900/ 3472]
loss: 0.050891  [ 2000/ 3472]
loss: 0.013821  [ 2100/ 3472]
loss: 0.010857  [ 2200/ 3472]
loss: 0.005416  [ 2300/ 3472]
loss: 0.008456  [ 2400/ 3472]
loss: 0.013307  [ 2500/ 3472]
loss: 0.015027  [ 2600/ 3472]
loss: 0.011805  [ 2700/ 3472]
loss: 0.026588  [ 2800/ 3472]
loss: 0.029750  [ 2900/ 3472]
loss: 0.008347  [ 3000/ 3472]
loss: 0.020961  [ 3100/ 3472]
loss: 0.013820  [ 3200/ 3472]
loss: 0.010321  [ 3300/ 3472]
loss: 0.009133  [ 3400/ 3472]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3472
First Spike after testing: [ 6.149788e-01 -7.901341e-05]
[0 0 0 ... 2 1 1]
[0 0 0 ... 2 0 2]
Cluster 0 Occurrences: 1159; KMEANS: 1128
Cluster 1 Occurrences: 1172; KMEANS: 1229
Cluster 2 Occurrences: 1141; KMEANS: 1115
Centroids: [[0.5806417, 0.2193657], [0.34796777, 0.55671835], [0.7365603, 0.5248508]]
Centroids: [[0.6987386, 0.13823056], [0.257587, 0.61252856], [0.7322384, 0.5352931]]
Contingency Matrix: 
[[781 248 130]
 [153 801 218]
 [194 180 767]]
[[781, -1, 130], [-1, -1, -1], [194, -1, 767]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 767]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 0: 0, 2: 2}
New Contingency Matrix: 
[[781 248 130]
 [153 801 218]
 [194 180 767]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [781, 801, 767], Sum: 2349
All_Elements: [781, 248, 130, 153, 801, 218, 194, 180, 767], Sum: 3472
Accuracy: 0.6765552995391705
Done!
