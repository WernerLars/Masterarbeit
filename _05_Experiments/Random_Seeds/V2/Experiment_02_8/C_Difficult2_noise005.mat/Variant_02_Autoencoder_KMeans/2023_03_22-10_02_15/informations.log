Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Difficult2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_02_15
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028C0199B518>
Sampling rate: 24000.0
Raw: [ 0.02085333  0.02043967  0.02052644 ... -0.02218732 -0.02150573
 -0.01811243]
Times: [   1583    1934    2430 ... 1439313 1439656 1439854]
Cluster: [3 3 3 ... 2 2 1]
Number of different clusters:  3
Number of Spikes: 3364
First aligned Spike Frame: [-0.05170878 -0.0548761  -0.06029554 -0.06053219 -0.04807119 -0.02780025
 -0.01550543 -0.01702494 -0.02945104 -0.04493807 -0.07056858 -0.07003585
  0.07629654  0.43081562  0.80470191  0.96319627  0.89198123  0.73643948
  0.58987232  0.46714337  0.36345495  0.2828462   0.22743292  0.182731
  0.13931053  0.09524506  0.05136602  0.01367166 -0.01393093 -0.03985679
 -0.07387102 -0.11218435 -0.1444455  -0.16672578 -0.17809238 -0.18020802
 -0.17953732 -0.18246903 -0.18617363 -0.18205375 -0.17299738 -0.16958427
 -0.17248955 -0.17516876 -0.1727246  -0.16696514 -0.15993314]
Cluster 0, Occurrences: 1120
Cluster 1, Occurrences: 1109
Cluster 2, Occurrences: 1135
<torch.utils.data.dataloader.DataLoader object at 0x0000028C072218D0>
Epoch 1
-------------------------------
loss: 0.145139  [    0/ 3364]
loss: 0.096544  [  100/ 3364]
loss: 0.050859  [  200/ 3364]
loss: 0.034848  [  300/ 3364]
loss: 0.001536  [  400/ 3364]
loss: 0.041203  [  500/ 3364]
loss: 0.005576  [  600/ 3364]
loss: 0.005974  [  700/ 3364]
loss: 0.003828  [  800/ 3364]
loss: 0.006944  [  900/ 3364]
loss: 0.007053  [ 1000/ 3364]
loss: 0.003899  [ 1100/ 3364]
loss: 0.006974  [ 1200/ 3364]
loss: 0.005113  [ 1300/ 3364]
loss: 0.086161  [ 1400/ 3364]
loss: 0.003476  [ 1500/ 3364]
loss: 0.007211  [ 1600/ 3364]
loss: 0.006816  [ 1700/ 3364]
loss: 0.001683  [ 1800/ 3364]
loss: 0.004702  [ 1900/ 3364]
loss: 0.002640  [ 2000/ 3364]
loss: 0.006799  [ 2100/ 3364]
loss: 0.005753  [ 2200/ 3364]
loss: 0.006877  [ 2300/ 3364]
loss: 0.001914  [ 2400/ 3364]
loss: 0.003438  [ 2500/ 3364]
loss: 0.003045  [ 2600/ 3364]
loss: 0.003515  [ 2700/ 3364]
loss: 0.004377  [ 2800/ 3364]
loss: 0.001796  [ 2900/ 3364]
loss: 0.004562  [ 3000/ 3364]
loss: 0.006230  [ 3100/ 3364]
loss: 0.001543  [ 3200/ 3364]
loss: 0.001738  [ 3300/ 3364]
Epoch 2
-------------------------------
loss: 0.001900  [    0/ 3364]
loss: 0.002623  [  100/ 3364]
loss: 0.004154  [  200/ 3364]
loss: 0.001862  [  300/ 3364]
loss: 0.000818  [  400/ 3364]
loss: 0.040408  [  500/ 3364]
loss: 0.004013  [  600/ 3364]
loss: 0.006663  [  700/ 3364]
loss: 0.002680  [  800/ 3364]
loss: 0.004086  [  900/ 3364]
loss: 0.004194  [ 1000/ 3364]
loss: 0.003407  [ 1100/ 3364]
loss: 0.003034  [ 1200/ 3364]
loss: 0.004978  [ 1300/ 3364]
loss: 0.086722  [ 1400/ 3364]
loss: 0.002494  [ 1500/ 3364]
loss: 0.006092  [ 1600/ 3364]
loss: 0.003558  [ 1700/ 3364]
loss: 0.001316  [ 1800/ 3364]
loss: 0.003413  [ 1900/ 3364]
loss: 0.002772  [ 2000/ 3364]
loss: 0.005665  [ 2100/ 3364]
loss: 0.004939  [ 2200/ 3364]
loss: 0.006964  [ 2300/ 3364]
loss: 0.001174  [ 2400/ 3364]
loss: 0.002778  [ 2500/ 3364]
loss: 0.002308  [ 2600/ 3364]
loss: 0.003243  [ 2700/ 3364]
loss: 0.004028  [ 2800/ 3364]
loss: 0.001539  [ 2900/ 3364]
loss: 0.004041  [ 3000/ 3364]
loss: 0.006275  [ 3100/ 3364]
loss: 0.001640  [ 3200/ 3364]
loss: 0.001760  [ 3300/ 3364]
Epoch 3
-------------------------------
loss: 0.001824  [    0/ 3364]
loss: 0.002534  [  100/ 3364]
loss: 0.004169  [  200/ 3364]
loss: 0.001228  [  300/ 3364]
loss: 0.000737  [  400/ 3364]
loss: 0.036583  [  500/ 3364]
loss: 0.004308  [  600/ 3364]
loss: 0.006692  [  700/ 3364]
loss: 0.002622  [  800/ 3364]
loss: 0.004030  [  900/ 3364]
loss: 0.003733  [ 1000/ 3364]
loss: 0.003442  [ 1100/ 3364]
loss: 0.002588  [ 1200/ 3364]
loss: 0.004939  [ 1300/ 3364]
loss: 0.087278  [ 1400/ 3364]
loss: 0.002669  [ 1500/ 3364]
loss: 0.005560  [ 1600/ 3364]
loss: 0.002995  [ 1700/ 3364]
loss: 0.001300  [ 1800/ 3364]
loss: 0.003323  [ 1900/ 3364]
loss: 0.003104  [ 2000/ 3364]
loss: 0.005500  [ 2100/ 3364]
loss: 0.004700  [ 2200/ 3364]
loss: 0.006467  [ 2300/ 3364]
loss: 0.001142  [ 2400/ 3364]
loss: 0.002602  [ 2500/ 3364]
loss: 0.002481  [ 2600/ 3364]
loss: 0.003027  [ 2700/ 3364]
loss: 0.004521  [ 2800/ 3364]
loss: 0.001660  [ 2900/ 3364]
loss: 0.003791  [ 3000/ 3364]
loss: 0.005919  [ 3100/ 3364]
loss: 0.001556  [ 3200/ 3364]
loss: 0.001692  [ 3300/ 3364]
Epoch 4
-------------------------------
loss: 0.001739  [    0/ 3364]
loss: 0.002236  [  100/ 3364]
loss: 0.003928  [  200/ 3364]
loss: 0.001068  [  300/ 3364]
loss: 0.000715  [  400/ 3364]
loss: 0.031734  [  500/ 3364]
loss: 0.003780  [  600/ 3364]
loss: 0.007432  [  700/ 3364]
loss: 0.002253  [  800/ 3364]
loss: 0.003895  [  900/ 3364]
loss: 0.003135  [ 1000/ 3364]
loss: 0.003481  [ 1100/ 3364]
loss: 0.002356  [ 1200/ 3364]
loss: 0.004829  [ 1300/ 3364]
loss: 0.087190  [ 1400/ 3364]
loss: 0.002692  [ 1500/ 3364]
loss: 0.005307  [ 1600/ 3364]
loss: 0.002597  [ 1700/ 3364]
loss: 0.001353  [ 1800/ 3364]
loss: 0.003517  [ 1900/ 3364]
loss: 0.003102  [ 2000/ 3364]
loss: 0.005018  [ 2100/ 3364]
loss: 0.004650  [ 2200/ 3364]
loss: 0.006140  [ 2300/ 3364]
loss: 0.001116  [ 2400/ 3364]
loss: 0.002464  [ 2500/ 3364]
loss: 0.002814  [ 2600/ 3364]
loss: 0.002784  [ 2700/ 3364]
loss: 0.004329  [ 2800/ 3364]
loss: 0.001624  [ 2900/ 3364]
loss: 0.003746  [ 3000/ 3364]
loss: 0.005532  [ 3100/ 3364]
loss: 0.001520  [ 3200/ 3364]
loss: 0.001378  [ 3300/ 3364]
Epoch 5
-------------------------------
loss: 0.001755  [    0/ 3364]
loss: 0.001968  [  100/ 3364]
loss: 0.003658  [  200/ 3364]
loss: 0.001033  [  300/ 3364]
loss: 0.000725  [  400/ 3364]
loss: 0.028781  [  500/ 3364]
loss: 0.003530  [  600/ 3364]
loss: 0.006648  [  700/ 3364]
loss: 0.002227  [  800/ 3364]
loss: 0.004246  [  900/ 3364]
loss: 0.002761  [ 1000/ 3364]
loss: 0.003503  [ 1100/ 3364]
loss: 0.002172  [ 1200/ 3364]
loss: 0.004643  [ 1300/ 3364]
loss: 0.087210  [ 1400/ 3364]
loss: 0.002759  [ 1500/ 3364]
loss: 0.004961  [ 1600/ 3364]
loss: 0.002608  [ 1700/ 3364]
loss: 0.001280  [ 1800/ 3364]
loss: 0.003416  [ 1900/ 3364]
loss: 0.003038  [ 2000/ 3364]
loss: 0.004883  [ 2100/ 3364]
loss: 0.004980  [ 2200/ 3364]
loss: 0.005628  [ 2300/ 3364]
loss: 0.000949  [ 2400/ 3364]
loss: 0.002418  [ 2500/ 3364]
loss: 0.002657  [ 2600/ 3364]
loss: 0.003104  [ 2700/ 3364]
loss: 0.004697  [ 2800/ 3364]
loss: 0.001773  [ 2900/ 3364]
loss: 0.003765  [ 3000/ 3364]
loss: 0.004680  [ 3100/ 3364]
loss: 0.001581  [ 3200/ 3364]
loss: 0.001407  [ 3300/ 3364]
Epoch 6
-------------------------------
loss: 0.001737  [    0/ 3364]
loss: 0.001638  [  100/ 3364]
loss: 0.003697  [  200/ 3364]
loss: 0.000941  [  300/ 3364]
loss: 0.000602  [  400/ 3364]
loss: 0.027390  [  500/ 3364]
loss: 0.003268  [  600/ 3364]
loss: 0.006133  [  700/ 3364]
loss: 0.002146  [  800/ 3364]
loss: 0.003408  [  900/ 3364]
loss: 0.002763  [ 1000/ 3364]
loss: 0.003330  [ 1100/ 3364]
loss: 0.002047  [ 1200/ 3364]
loss: 0.004572  [ 1300/ 3364]
loss: 0.086931  [ 1400/ 3364]
loss: 0.002846  [ 1500/ 3364]
loss: 0.004668  [ 1600/ 3364]
loss: 0.002843  [ 1700/ 3364]
loss: 0.001031  [ 1800/ 3364]
loss: 0.003632  [ 1900/ 3364]
loss: 0.003255  [ 2000/ 3364]
loss: 0.004662  [ 2100/ 3364]
loss: 0.005074  [ 2200/ 3364]
loss: 0.005569  [ 2300/ 3364]
loss: 0.000904  [ 2400/ 3364]
loss: 0.002457  [ 2500/ 3364]
loss: 0.002498  [ 2600/ 3364]
loss: 0.003234  [ 2700/ 3364]
loss: 0.004139  [ 2800/ 3364]
loss: 0.001692  [ 2900/ 3364]
loss: 0.003939  [ 3000/ 3364]
loss: 0.003911  [ 3100/ 3364]
loss: 0.001620  [ 3200/ 3364]
loss: 0.001580  [ 3300/ 3364]
Epoch 7
-------------------------------
loss: 0.001650  [    0/ 3364]
loss: 0.001626  [  100/ 3364]
loss: 0.003716  [  200/ 3364]
loss: 0.000926  [  300/ 3364]
loss: 0.000704  [  400/ 3364]
loss: 0.027084  [  500/ 3364]
loss: 0.003165  [  600/ 3364]
loss: 0.005290  [  700/ 3364]
loss: 0.002102  [  800/ 3364]
loss: 0.003350  [  900/ 3364]
loss: 0.002998  [ 1000/ 3364]
loss: 0.003286  [ 1100/ 3364]
loss: 0.002005  [ 1200/ 3364]
loss: 0.004477  [ 1300/ 3364]
loss: 0.086960  [ 1400/ 3364]
loss: 0.002855  [ 1500/ 3364]
loss: 0.004620  [ 1600/ 3364]
loss: 0.003044  [ 1700/ 3364]
loss: 0.000924  [ 1800/ 3364]
loss: 0.003860  [ 1900/ 3364]
loss: 0.003075  [ 2000/ 3364]
loss: 0.004657  [ 2100/ 3364]
loss: 0.004986  [ 2200/ 3364]
loss: 0.005744  [ 2300/ 3364]
loss: 0.000901  [ 2400/ 3364]
loss: 0.002455  [ 2500/ 3364]
loss: 0.002557  [ 2600/ 3364]
loss: 0.003130  [ 2700/ 3364]
loss: 0.003779  [ 2800/ 3364]
loss: 0.001647  [ 2900/ 3364]
loss: 0.003912  [ 3000/ 3364]
loss: 0.003409  [ 3100/ 3364]
loss: 0.001536  [ 3200/ 3364]
loss: 0.001489  [ 3300/ 3364]
Epoch 8
-------------------------------
loss: 0.001649  [    0/ 3364]
loss: 0.001664  [  100/ 3364]
loss: 0.003820  [  200/ 3364]
loss: 0.000886  [  300/ 3364]
loss: 0.000884  [  400/ 3364]
loss: 0.027335  [  500/ 3364]
loss: 0.003154  [  600/ 3364]
loss: 0.005247  [  700/ 3364]
loss: 0.002083  [  800/ 3364]
loss: 0.003094  [  900/ 3364]
loss: 0.002660  [ 1000/ 3364]
loss: 0.003261  [ 1100/ 3364]
loss: 0.001971  [ 1200/ 3364]
loss: 0.004629  [ 1300/ 3364]
loss: 0.086484  [ 1400/ 3364]
loss: 0.002862  [ 1500/ 3364]
loss: 0.004653  [ 1600/ 3364]
loss: 0.003027  [ 1700/ 3364]
loss: 0.000890  [ 1800/ 3364]
loss: 0.003950  [ 1900/ 3364]
loss: 0.002921  [ 2000/ 3364]
loss: 0.004411  [ 2100/ 3364]
loss: 0.005099  [ 2200/ 3364]
loss: 0.005772  [ 2300/ 3364]
loss: 0.000885  [ 2400/ 3364]
loss: 0.002433  [ 2500/ 3364]
loss: 0.002553  [ 2600/ 3364]
loss: 0.003207  [ 2700/ 3364]
loss: 0.003351  [ 2800/ 3364]
loss: 0.001691  [ 2900/ 3364]
loss: 0.003996  [ 3000/ 3364]
loss: 0.002904  [ 3100/ 3364]
loss: 0.001509  [ 3200/ 3364]
loss: 0.001455  [ 3300/ 3364]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3364
First Spike after testing: [-0.915692   -0.07987902]
[2 2 2 ... 1 1 0]
[2 2 2 ... 1 1 0]
Cluster 0 Occurrences: 1120; KMEANS: 1127
Cluster 1 Occurrences: 1109; KMEANS: 1107
Cluster 2 Occurrences: 1135; KMEANS: 1130
Centroids: [[-0.4431412, -0.4203913], [-0.77721894, 1.9283726], [-0.89735645, -0.10637703]]
Centroids: [[-0.423248, -0.43187463], [-0.77978414, 1.9372195], [-0.91728497, -0.09804449]]
Contingency Matrix: 
[[1102    3   15]
 [   2 1100    7]
 [  23    4 1108]]
[[1102, 3, -1], [2, 1100, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1100, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 0, 1: 1}
New Contingency Matrix: 
[[1102    3   15]
 [   2 1100    7]
 [  23    4 1108]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1102, 1100, 1108], Sum: 3310
All_Elements: [1102, 3, 15, 2, 1100, 7, 23, 4, 1108], Sum: 3364
Accuracy: 0.9839476813317479
Done!
