Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Difficult1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_57_46
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028C044056A0>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
<torch.utils.data.dataloader.DataLoader object at 0x0000028C072218D0>
Epoch 1
-------------------------------
loss: 0.175502  [    0/ 3448]
loss: 0.063345  [  100/ 3448]
loss: 0.028824  [  200/ 3448]
loss: 0.035303  [  300/ 3448]
loss: 0.019417  [  400/ 3448]
loss: 0.015117  [  500/ 3448]
loss: 0.022457  [  600/ 3448]
loss: 0.010533  [  700/ 3448]
loss: 0.015204  [  800/ 3448]
loss: 0.031908  [  900/ 3448]
loss: 0.091443  [ 1000/ 3448]
loss: 0.013861  [ 1100/ 3448]
loss: 0.010983  [ 1200/ 3448]
loss: 0.130192  [ 1300/ 3448]
loss: 0.009899  [ 1400/ 3448]
loss: 0.031803  [ 1500/ 3448]
loss: 0.021512  [ 1600/ 3448]
loss: 0.010796  [ 1700/ 3448]
loss: 0.008897  [ 1800/ 3448]
loss: 0.017788  [ 1900/ 3448]
loss: 0.007198  [ 2000/ 3448]
loss: 0.004139  [ 2100/ 3448]
loss: 0.011066  [ 2200/ 3448]
loss: 0.006385  [ 2300/ 3448]
loss: 0.021235  [ 2400/ 3448]
loss: 0.009960  [ 2500/ 3448]
loss: 0.010871  [ 2600/ 3448]
loss: 0.011645  [ 2700/ 3448]
loss: 0.006357  [ 2800/ 3448]
loss: 0.007675  [ 2900/ 3448]
loss: 0.004063  [ 3000/ 3448]
loss: 0.007965  [ 3100/ 3448]
loss: 0.013965  [ 3200/ 3448]
loss: 0.013110  [ 3300/ 3448]
loss: 0.007842  [ 3400/ 3448]
Epoch 2
-------------------------------
loss: 0.018195  [    0/ 3448]
loss: 0.007451  [  100/ 3448]
loss: 0.002933  [  200/ 3448]
loss: 0.007904  [  300/ 3448]
loss: 0.010601  [  400/ 3448]
loss: 0.013396  [  500/ 3448]
loss: 0.008029  [  600/ 3448]
loss: 0.007573  [  700/ 3448]
loss: 0.004711  [  800/ 3448]
loss: 0.005723  [  900/ 3448]
loss: 0.090397  [ 1000/ 3448]
loss: 0.014618  [ 1100/ 3448]
loss: 0.008646  [ 1200/ 3448]
loss: 0.126880  [ 1300/ 3448]
loss: 0.006144  [ 1400/ 3448]
loss: 0.022846  [ 1500/ 3448]
loss: 0.003948  [ 1600/ 3448]
loss: 0.010272  [ 1700/ 3448]
loss: 0.006541  [ 1800/ 3448]
loss: 0.017572  [ 1900/ 3448]
loss: 0.008304  [ 2000/ 3448]
loss: 0.003232  [ 2100/ 3448]
loss: 0.005215  [ 2200/ 3448]
loss: 0.005629  [ 2300/ 3448]
loss: 0.007605  [ 2400/ 3448]
loss: 0.008349  [ 2500/ 3448]
loss: 0.012667  [ 2600/ 3448]
loss: 0.009540  [ 2700/ 3448]
loss: 0.006409  [ 2800/ 3448]
loss: 0.002660  [ 2900/ 3448]
loss: 0.003985  [ 3000/ 3448]
loss: 0.012535  [ 3100/ 3448]
loss: 0.013020  [ 3200/ 3448]
loss: 0.011275  [ 3300/ 3448]
loss: 0.006745  [ 3400/ 3448]
Epoch 3
-------------------------------
loss: 0.019299  [    0/ 3448]
loss: 0.007449  [  100/ 3448]
loss: 0.002058  [  200/ 3448]
loss: 0.004721  [  300/ 3448]
loss: 0.007077  [  400/ 3448]
loss: 0.013415  [  500/ 3448]
loss: 0.006608  [  600/ 3448]
loss: 0.007685  [  700/ 3448]
loss: 0.004411  [  800/ 3448]
loss: 0.005233  [  900/ 3448]
loss: 0.085073  [ 1000/ 3448]
loss: 0.014744  [ 1100/ 3448]
loss: 0.008771  [ 1200/ 3448]
loss: 0.125739  [ 1300/ 3448]
loss: 0.006256  [ 1400/ 3448]
loss: 0.022007  [ 1500/ 3448]
loss: 0.003958  [ 1600/ 3448]
loss: 0.010578  [ 1700/ 3448]
loss: 0.006936  [ 1800/ 3448]
loss: 0.017670  [ 1900/ 3448]
loss: 0.008147  [ 2000/ 3448]
loss: 0.003311  [ 2100/ 3448]
loss: 0.005470  [ 2200/ 3448]
loss: 0.005785  [ 2300/ 3448]
loss: 0.007497  [ 2400/ 3448]
loss: 0.008128  [ 2500/ 3448]
loss: 0.012768  [ 2600/ 3448]
loss: 0.009653  [ 2700/ 3448]
loss: 0.006842  [ 2800/ 3448]
loss: 0.002441  [ 2900/ 3448]
loss: 0.004011  [ 3000/ 3448]
loss: 0.013246  [ 3100/ 3448]
loss: 0.012793  [ 3200/ 3448]
loss: 0.011191  [ 3300/ 3448]
loss: 0.006520  [ 3400/ 3448]
Epoch 4
-------------------------------
loss: 0.018917  [    0/ 3448]
loss: 0.007218  [  100/ 3448]
loss: 0.002172  [  200/ 3448]
loss: 0.004741  [  300/ 3448]
loss: 0.005931  [  400/ 3448]
loss: 0.013399  [  500/ 3448]
loss: 0.006544  [  600/ 3448]
loss: 0.007540  [  700/ 3448]
loss: 0.004447  [  800/ 3448]
loss: 0.005081  [  900/ 3448]
loss: 0.084702  [ 1000/ 3448]
loss: 0.014471  [ 1100/ 3448]
loss: 0.008347  [ 1200/ 3448]
loss: 0.125820  [ 1300/ 3448]
loss: 0.006124  [ 1400/ 3448]
loss: 0.022079  [ 1500/ 3448]
loss: 0.003894  [ 1600/ 3448]
loss: 0.010344  [ 1700/ 3448]
loss: 0.006937  [ 1800/ 3448]
loss: 0.017892  [ 1900/ 3448]
loss: 0.007851  [ 2000/ 3448]
loss: 0.003341  [ 2100/ 3448]
loss: 0.005346  [ 2200/ 3448]
loss: 0.006087  [ 2300/ 3448]
loss: 0.008628  [ 2400/ 3448]
loss: 0.008024  [ 2500/ 3448]
loss: 0.012863  [ 2600/ 3448]
loss: 0.009326  [ 2700/ 3448]
loss: 0.007360  [ 2800/ 3448]
loss: 0.002198  [ 2900/ 3448]
loss: 0.004034  [ 3000/ 3448]
loss: 0.013023  [ 3100/ 3448]
loss: 0.012787  [ 3200/ 3448]
loss: 0.011350  [ 3300/ 3448]
loss: 0.006459  [ 3400/ 3448]
Epoch 5
-------------------------------
loss: 0.017501  [    0/ 3448]
loss: 0.006852  [  100/ 3448]
loss: 0.002850  [  200/ 3448]
loss: 0.005691  [  300/ 3448]
loss: 0.004782  [  400/ 3448]
loss: 0.013354  [  500/ 3448]
loss: 0.006796  [  600/ 3448]
loss: 0.006989  [  700/ 3448]
loss: 0.004336  [  800/ 3448]
loss: 0.004871  [  900/ 3448]
loss: 0.084116  [ 1000/ 3448]
loss: 0.013532  [ 1100/ 3448]
loss: 0.007709  [ 1200/ 3448]
loss: 0.126121  [ 1300/ 3448]
loss: 0.005937  [ 1400/ 3448]
loss: 0.022819  [ 1500/ 3448]
loss: 0.004066  [ 1600/ 3448]
loss: 0.009980  [ 1700/ 3448]
loss: 0.006996  [ 1800/ 3448]
loss: 0.018022  [ 1900/ 3448]
loss: 0.007308  [ 2000/ 3448]
loss: 0.003331  [ 2100/ 3448]
loss: 0.005099  [ 2200/ 3448]
loss: 0.006181  [ 2300/ 3448]
loss: 0.009270  [ 2400/ 3448]
loss: 0.008029  [ 2500/ 3448]
loss: 0.013015  [ 2600/ 3448]
loss: 0.009106  [ 2700/ 3448]
loss: 0.007977  [ 2800/ 3448]
loss: 0.002107  [ 2900/ 3448]
loss: 0.004119  [ 3000/ 3448]
loss: 0.012866  [ 3100/ 3448]
loss: 0.012743  [ 3200/ 3448]
loss: 0.011361  [ 3300/ 3448]
loss: 0.006554  [ 3400/ 3448]
Epoch 6
-------------------------------
loss: 0.015936  [    0/ 3448]
loss: 0.006375  [  100/ 3448]
loss: 0.002971  [  200/ 3448]
loss: 0.005894  [  300/ 3448]
loss: 0.004924  [  400/ 3448]
loss: 0.013475  [  500/ 3448]
loss: 0.006828  [  600/ 3448]
loss: 0.006015  [  700/ 3448]
loss: 0.004598  [  800/ 3448]
loss: 0.004701  [  900/ 3448]
loss: 0.083203  [ 1000/ 3448]
loss: 0.012640  [ 1100/ 3448]
loss: 0.007302  [ 1200/ 3448]
loss: 0.126473  [ 1300/ 3448]
loss: 0.005960  [ 1400/ 3448]
loss: 0.021630  [ 1500/ 3448]
loss: 0.004718  [ 1600/ 3448]
loss: 0.009482  [ 1700/ 3448]
loss: 0.007104  [ 1800/ 3448]
loss: 0.018473  [ 1900/ 3448]
loss: 0.006793  [ 2000/ 3448]
loss: 0.003072  [ 2100/ 3448]
loss: 0.004854  [ 2200/ 3448]
loss: 0.006147  [ 2300/ 3448]
loss: 0.009523  [ 2400/ 3448]
loss: 0.007914  [ 2500/ 3448]
loss: 0.012723  [ 2600/ 3448]
loss: 0.008307  [ 2700/ 3448]
loss: 0.008231  [ 2800/ 3448]
loss: 0.001937  [ 2900/ 3448]
loss: 0.004737  [ 3000/ 3448]
loss: 0.013307  [ 3100/ 3448]
loss: 0.012345  [ 3200/ 3448]
loss: 0.011266  [ 3300/ 3448]
loss: 0.006919  [ 3400/ 3448]
Epoch 7
-------------------------------
loss: 0.015041  [    0/ 3448]
loss: 0.005880  [  100/ 3448]
loss: 0.003339  [  200/ 3448]
loss: 0.005667  [  300/ 3448]
loss: 0.004534  [  400/ 3448]
loss: 0.013200  [  500/ 3448]
loss: 0.006790  [  600/ 3448]
loss: 0.005563  [  700/ 3448]
loss: 0.005298  [  800/ 3448]
loss: 0.004556  [  900/ 3448]
loss: 0.082442  [ 1000/ 3448]
loss: 0.011858  [ 1100/ 3448]
loss: 0.007075  [ 1200/ 3448]
loss: 0.126339  [ 1300/ 3448]
loss: 0.005850  [ 1400/ 3448]
loss: 0.021074  [ 1500/ 3448]
loss: 0.004710  [ 1600/ 3448]
loss: 0.009646  [ 1700/ 3448]
loss: 0.007262  [ 1800/ 3448]
loss: 0.019241  [ 1900/ 3448]
loss: 0.006382  [ 2000/ 3448]
loss: 0.002935  [ 2100/ 3448]
loss: 0.004772  [ 2200/ 3448]
loss: 0.006078  [ 2300/ 3448]
loss: 0.009796  [ 2400/ 3448]
loss: 0.007590  [ 2500/ 3448]
loss: 0.012664  [ 2600/ 3448]
loss: 0.008054  [ 2700/ 3448]
loss: 0.008690  [ 2800/ 3448]
loss: 0.001774  [ 2900/ 3448]
loss: 0.005016  [ 3000/ 3448]
loss: 0.013281  [ 3100/ 3448]
loss: 0.011239  [ 3200/ 3448]
loss: 0.011076  [ 3300/ 3448]
loss: 0.007219  [ 3400/ 3448]
Epoch 8
-------------------------------
loss: 0.014650  [    0/ 3448]
loss: 0.005516  [  100/ 3448]
loss: 0.004969  [  200/ 3448]
loss: 0.006041  [  300/ 3448]
loss: 0.004677  [  400/ 3448]
loss: 0.013021  [  500/ 3448]
loss: 0.006932  [  600/ 3448]
loss: 0.005484  [  700/ 3448]
loss: 0.005849  [  800/ 3448]
loss: 0.004309  [  900/ 3448]
loss: 0.082041  [ 1000/ 3448]
loss: 0.011554  [ 1100/ 3448]
loss: 0.007119  [ 1200/ 3448]
loss: 0.126167  [ 1300/ 3448]
loss: 0.005726  [ 1400/ 3448]
loss: 0.020714  [ 1500/ 3448]
loss: 0.004925  [ 1600/ 3448]
loss: 0.009999  [ 1700/ 3448]
loss: 0.007161  [ 1800/ 3448]
loss: 0.019294  [ 1900/ 3448]
loss: 0.006272  [ 2000/ 3448]
loss: 0.002698  [ 2100/ 3448]
loss: 0.004507  [ 2200/ 3448]
loss: 0.006177  [ 2300/ 3448]
loss: 0.009913  [ 2400/ 3448]
loss: 0.007817  [ 2500/ 3448]
loss: 0.012026  [ 2600/ 3448]
loss: 0.007746  [ 2700/ 3448]
loss: 0.008193  [ 2800/ 3448]
loss: 0.001882  [ 2900/ 3448]
loss: 0.005165  [ 3000/ 3448]
loss: 0.012486  [ 3100/ 3448]
loss: 0.010305  [ 3200/ 3448]
loss: 0.011168  [ 3300/ 3448]
loss: 0.007514  [ 3400/ 3448]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3448
First Spike after testing: [ 0.25303245 -0.08882242]
[2 2 2 ... 1 0 2]
[0 2 0 ... 1 0 0]
Cluster 0 Occurrences: 1164; KMEANS: 1877
Cluster 1 Occurrences: 1155; KMEANS: 1134
Cluster 2 Occurrences: 1129; KMEANS: 437
Centroids: [[0.24348591, 0.24858916], [-0.5933647, -0.37070534], [0.31381437, -0.32753834]]
Centroids: [[0.1675467, -0.10921876], [-0.66025877, -0.40549013], [0.8847278, 0.35750973]]
Contingency Matrix: 
[[ 856   21  287]
 [  80 1050   25]
 [ 941   63  125]]
[[856, -1, 287], [-1, -1, -1], [941, -1, 125]]
[[-1, -1, 287], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 2: 0, 0: 2}
New Contingency Matrix: 
[[ 287   21  856]
 [  25 1050   80]
 [ 125   63  941]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [287, 1050, 941], Sum: 2278
All_Elements: [287, 21, 856, 25, 1050, 80, 125, 63, 941], Sum: 3448
Accuracy: 0.6606728538283063
Done!
