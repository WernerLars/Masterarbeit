Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_38_56
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028B8542C208>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x0000028B85474F98>
Epoch 1
-------------------------------
loss: 0.112243  [    0/ 3514]
loss: 0.290322  [  100/ 3514]
loss: 0.069135  [  200/ 3514]
loss: 0.046886  [  300/ 3514]
loss: 0.014199  [  400/ 3514]
loss: 0.004662  [  500/ 3514]
loss: 0.009661  [  600/ 3514]
loss: 0.003461  [  700/ 3514]
loss: 0.001568  [  800/ 3514]
loss: 0.004103  [  900/ 3514]
loss: 0.006103  [ 1000/ 3514]
loss: 0.089017  [ 1100/ 3514]
loss: 0.003024  [ 1200/ 3514]
loss: 0.001880  [ 1300/ 3514]
loss: 0.053032  [ 1400/ 3514]
loss: 0.000588  [ 1500/ 3514]
loss: 0.007269  [ 1600/ 3514]
loss: 0.005143  [ 1700/ 3514]
loss: 0.231826  [ 1800/ 3514]
loss: 0.007088  [ 1900/ 3514]
loss: 0.002447  [ 2000/ 3514]
loss: 0.005767  [ 2100/ 3514]
loss: 0.000912  [ 2200/ 3514]
loss: 0.001579  [ 2300/ 3514]
loss: 0.002287  [ 2400/ 3514]
loss: 0.006915  [ 2500/ 3514]
loss: 0.004163  [ 2600/ 3514]
loss: 0.002974  [ 2700/ 3514]
loss: 0.007129  [ 2800/ 3514]
loss: 0.001741  [ 2900/ 3514]
loss: 0.007138  [ 3000/ 3514]
loss: 0.001644  [ 3100/ 3514]
loss: 0.001744  [ 3200/ 3514]
loss: 0.006252  [ 3300/ 3514]
loss: 0.006102  [ 3400/ 3514]
loss: 0.003651  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.006624  [    0/ 3514]
loss: 0.003295  [  100/ 3514]
loss: 0.007563  [  200/ 3514]
loss: 0.003533  [  300/ 3514]
loss: 0.004464  [  400/ 3514]
loss: 0.003532  [  500/ 3514]
loss: 0.008116  [  600/ 3514]
loss: 0.002910  [  700/ 3514]
loss: 0.001092  [  800/ 3514]
loss: 0.003900  [  900/ 3514]
loss: 0.005976  [ 1000/ 3514]
loss: 0.089060  [ 1100/ 3514]
loss: 0.002924  [ 1200/ 3514]
loss: 0.001668  [ 1300/ 3514]
loss: 0.056907  [ 1400/ 3514]
loss: 0.000611  [ 1500/ 3514]
loss: 0.006610  [ 1600/ 3514]
loss: 0.005196  [ 1700/ 3514]
loss: 0.229811  [ 1800/ 3514]
loss: 0.006398  [ 1900/ 3514]
loss: 0.002123  [ 2000/ 3514]
loss: 0.005224  [ 2100/ 3514]
loss: 0.000836  [ 2200/ 3514]
loss: 0.001477  [ 2300/ 3514]
loss: 0.002091  [ 2400/ 3514]
loss: 0.006652  [ 2500/ 3514]
loss: 0.004275  [ 2600/ 3514]
loss: 0.002593  [ 2700/ 3514]
loss: 0.007088  [ 2800/ 3514]
loss: 0.001452  [ 2900/ 3514]
loss: 0.005279  [ 3000/ 3514]
loss: 0.001323  [ 3100/ 3514]
loss: 0.001704  [ 3200/ 3514]
loss: 0.006550  [ 3300/ 3514]
loss: 0.005903  [ 3400/ 3514]
loss: 0.003557  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.005212  [    0/ 3514]
loss: 0.002955  [  100/ 3514]
loss: 0.007570  [  200/ 3514]
loss: 0.003546  [  300/ 3514]
loss: 0.004080  [  400/ 3514]
loss: 0.003220  [  500/ 3514]
loss: 0.007939  [  600/ 3514]
loss: 0.003062  [  700/ 3514]
loss: 0.001034  [  800/ 3514]
loss: 0.003850  [  900/ 3514]
loss: 0.006344  [ 1000/ 3514]
loss: 0.089505  [ 1100/ 3514]
loss: 0.002757  [ 1200/ 3514]
loss: 0.001375  [ 1300/ 3514]
loss: 0.067403  [ 1400/ 3514]
loss: 0.000421  [ 1500/ 3514]
loss: 0.006741  [ 1600/ 3514]
loss: 0.005673  [ 1700/ 3514]
loss: 0.228899  [ 1800/ 3514]
loss: 0.006140  [ 1900/ 3514]
loss: 0.001688  [ 2000/ 3514]
loss: 0.005072  [ 2100/ 3514]
loss: 0.000716  [ 2200/ 3514]
loss: 0.001591  [ 2300/ 3514]
loss: 0.002091  [ 2400/ 3514]
loss: 0.005677  [ 2500/ 3514]
loss: 0.004214  [ 2600/ 3514]
loss: 0.002451  [ 2700/ 3514]
loss: 0.007047  [ 2800/ 3514]
loss: 0.001609  [ 2900/ 3514]
loss: 0.003727  [ 3000/ 3514]
loss: 0.001416  [ 3100/ 3514]
loss: 0.001758  [ 3200/ 3514]
loss: 0.007588  [ 3300/ 3514]
loss: 0.005894  [ 3400/ 3514]
loss: 0.003272  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.003701  [    0/ 3514]
loss: 0.002861  [  100/ 3514]
loss: 0.007460  [  200/ 3514]
loss: 0.003539  [  300/ 3514]
loss: 0.003965  [  400/ 3514]
loss: 0.002975  [  500/ 3514]
loss: 0.006834  [  600/ 3514]
loss: 0.003178  [  700/ 3514]
loss: 0.001159  [  800/ 3514]
loss: 0.003925  [  900/ 3514]
loss: 0.006232  [ 1000/ 3514]
loss: 0.091077  [ 1100/ 3514]
loss: 0.002672  [ 1200/ 3514]
loss: 0.001331  [ 1300/ 3514]
loss: 0.073402  [ 1400/ 3514]
loss: 0.000407  [ 1500/ 3514]
loss: 0.007987  [ 1600/ 3514]
loss: 0.005533  [ 1700/ 3514]
loss: 0.221320  [ 1800/ 3514]
loss: 0.007406  [ 1900/ 3514]
loss: 0.002385  [ 2000/ 3514]
loss: 0.005012  [ 2100/ 3514]
loss: 0.000789  [ 2200/ 3514]
loss: 0.001447  [ 2300/ 3514]
loss: 0.002035  [ 2400/ 3514]
loss: 0.004775  [ 2500/ 3514]
loss: 0.004189  [ 2600/ 3514]
loss: 0.002474  [ 2700/ 3514]
loss: 0.007136  [ 2800/ 3514]
loss: 0.002078  [ 2900/ 3514]
loss: 0.003293  [ 3000/ 3514]
loss: 0.001711  [ 3100/ 3514]
loss: 0.001757  [ 3200/ 3514]
loss: 0.007270  [ 3300/ 3514]
loss: 0.006052  [ 3400/ 3514]
loss: 0.003012  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.002877  [    0/ 3514]
loss: 0.002762  [  100/ 3514]
loss: 0.007051  [  200/ 3514]
loss: 0.003359  [  300/ 3514]
loss: 0.004182  [  400/ 3514]
loss: 0.003001  [  500/ 3514]
loss: 0.006101  [  600/ 3514]
loss: 0.003240  [  700/ 3514]
loss: 0.001542  [  800/ 3514]
loss: 0.004056  [  900/ 3514]
loss: 0.006615  [ 1000/ 3514]
loss: 0.093692  [ 1100/ 3514]
loss: 0.001953  [ 1200/ 3514]
loss: 0.001166  [ 1300/ 3514]
loss: 0.078103  [ 1400/ 3514]
loss: 0.000444  [ 1500/ 3514]
loss: 0.006267  [ 1600/ 3514]
loss: 0.005361  [ 1700/ 3514]
loss: 0.216624  [ 1800/ 3514]
loss: 0.006118  [ 1900/ 3514]
loss: 0.002385  [ 2000/ 3514]
loss: 0.005048  [ 2100/ 3514]
loss: 0.000905  [ 2200/ 3514]
loss: 0.001475  [ 2300/ 3514]
loss: 0.001888  [ 2400/ 3514]
loss: 0.005036  [ 2500/ 3514]
loss: 0.004160  [ 2600/ 3514]
loss: 0.002541  [ 2700/ 3514]
loss: 0.007222  [ 2800/ 3514]
loss: 0.001853  [ 2900/ 3514]
loss: 0.003167  [ 3000/ 3514]
loss: 0.001868  [ 3100/ 3514]
loss: 0.001808  [ 3200/ 3514]
loss: 0.006842  [ 3300/ 3514]
loss: 0.006247  [ 3400/ 3514]
loss: 0.002759  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.002656  [    0/ 3514]
loss: 0.002741  [  100/ 3514]
loss: 0.006995  [  200/ 3514]
loss: 0.003233  [  300/ 3514]
loss: 0.004627  [  400/ 3514]
loss: 0.003254  [  500/ 3514]
loss: 0.005845  [  600/ 3514]
loss: 0.003317  [  700/ 3514]
loss: 0.001369  [  800/ 3514]
loss: 0.004051  [  900/ 3514]
loss: 0.006600  [ 1000/ 3514]
loss: 0.090587  [ 1100/ 3514]
loss: 0.001645  [ 1200/ 3514]
loss: 0.001009  [ 1300/ 3514]
loss: 0.081411  [ 1400/ 3514]
loss: 0.000434  [ 1500/ 3514]
loss: 0.003846  [ 1600/ 3514]
loss: 0.005231  [ 1700/ 3514]
loss: 0.210729  [ 1800/ 3514]
loss: 0.004903  [ 1900/ 3514]
loss: 0.002507  [ 2000/ 3514]
loss: 0.005018  [ 2100/ 3514]
loss: 0.001030  [ 2200/ 3514]
loss: 0.001518  [ 2300/ 3514]
loss: 0.001787  [ 2400/ 3514]
loss: 0.005674  [ 2500/ 3514]
loss: 0.004131  [ 2600/ 3514]
loss: 0.002629  [ 2700/ 3514]
loss: 0.007248  [ 2800/ 3514]
loss: 0.001752  [ 2900/ 3514]
loss: 0.003112  [ 3000/ 3514]
loss: 0.001513  [ 3100/ 3514]
loss: 0.001854  [ 3200/ 3514]
loss: 0.006231  [ 3300/ 3514]
loss: 0.005882  [ 3400/ 3514]
loss: 0.002626  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.002353  [    0/ 3514]
loss: 0.002738  [  100/ 3514]
loss: 0.007083  [  200/ 3514]
loss: 0.003157  [  300/ 3514]
loss: 0.005151  [  400/ 3514]
loss: 0.003473  [  500/ 3514]
loss: 0.006012  [  600/ 3514]
loss: 0.003175  [  700/ 3514]
loss: 0.001368  [  800/ 3514]
loss: 0.004215  [  900/ 3514]
loss: 0.006785  [ 1000/ 3514]
loss: 0.090370  [ 1100/ 3514]
loss: 0.001441  [ 1200/ 3514]
loss: 0.000934  [ 1300/ 3514]
loss: 0.084151  [ 1400/ 3514]
loss: 0.000414  [ 1500/ 3514]
loss: 0.003260  [ 1600/ 3514]
loss: 0.005201  [ 1700/ 3514]
loss: 0.204981  [ 1800/ 3514]
loss: 0.004643  [ 1900/ 3514]
loss: 0.002781  [ 2000/ 3514]
loss: 0.004986  [ 2100/ 3514]
loss: 0.001164  [ 2200/ 3514]
loss: 0.001593  [ 2300/ 3514]
loss: 0.001671  [ 2400/ 3514]
loss: 0.006095  [ 2500/ 3514]
loss: 0.004119  [ 2600/ 3514]
loss: 0.002569  [ 2700/ 3514]
loss: 0.007254  [ 2800/ 3514]
loss: 0.001958  [ 2900/ 3514]
loss: 0.003285  [ 3000/ 3514]
loss: 0.001914  [ 3100/ 3514]
loss: 0.001910  [ 3200/ 3514]
loss: 0.006805  [ 3300/ 3514]
loss: 0.005607  [ 3400/ 3514]
loss: 0.002473  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.002200  [    0/ 3514]
loss: 0.002624  [  100/ 3514]
loss: 0.007300  [  200/ 3514]
loss: 0.003164  [  300/ 3514]
loss: 0.005130  [  400/ 3514]
loss: 0.003622  [  500/ 3514]
loss: 0.005905  [  600/ 3514]
loss: 0.002948  [  700/ 3514]
loss: 0.001368  [  800/ 3514]
loss: 0.004401  [  900/ 3514]
loss: 0.006582  [ 1000/ 3514]
loss: 0.090510  [ 1100/ 3514]
loss: 0.001272  [ 1200/ 3514]
loss: 0.001042  [ 1300/ 3514]
loss: 0.086736  [ 1400/ 3514]
loss: 0.000394  [ 1500/ 3514]
loss: 0.003686  [ 1600/ 3514]
loss: 0.005144  [ 1700/ 3514]
loss: 0.200106  [ 1800/ 3514]
loss: 0.004410  [ 1900/ 3514]
loss: 0.002801  [ 2000/ 3514]
loss: 0.005058  [ 2100/ 3514]
loss: 0.001235  [ 2200/ 3514]
loss: 0.001603  [ 2300/ 3514]
loss: 0.001456  [ 2400/ 3514]
loss: 0.005904  [ 2500/ 3514]
loss: 0.004092  [ 2600/ 3514]
loss: 0.002415  [ 2700/ 3514]
loss: 0.007123  [ 2800/ 3514]
loss: 0.002051  [ 2900/ 3514]
loss: 0.003513  [ 3000/ 3514]
loss: 0.001801  [ 3100/ 3514]
loss: 0.001983  [ 3200/ 3514]
loss: 0.006741  [ 3300/ 3514]
loss: 0.005885  [ 3400/ 3514]
loss: 0.002431  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [-0.6322466  1.2774442]
[1 0 2 ... 1 0 1]
[0 2 1 ... 0 2 0]
Cluster 0 Occurrences: 1165; KMEANS: 1138
Cluster 1 Occurrences: 1157; KMEANS: 1219
Cluster 2 Occurrences: 1192; KMEANS: 1157
Centroids: [[0.8972732, -0.48143855], [-0.46236357, 1.43151], [-1.3572675, -1.0814037]]
Centroids: [[-0.45039827, 1.4556631], [-1.3566271, -1.0748385], [0.9151146, -0.46669707]]
Contingency Matrix: 
[[   1   13 1151]
 [1137   14    6]
 [   0 1192    0]]
[[1, -1, 1151], [1137, -1, 6], [-1, -1, -1]]
[[-1, -1, -1], [1137, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[1151    1   13]
 [   6 1137   14]
 [   0    0 1192]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1151, 1137, 1192], Sum: 3480
All_Elements: [1151, 1, 13, 6, 1137, 14, 0, 0, 1192], Sum: 3514
Accuracy: 0.9903244166192373
Done!
