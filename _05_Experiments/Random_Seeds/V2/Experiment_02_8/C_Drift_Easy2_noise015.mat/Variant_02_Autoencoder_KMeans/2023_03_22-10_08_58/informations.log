Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Drift_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_08_58
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028C044056A0>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
<torch.utils.data.dataloader.DataLoader object at 0x0000028C09ACBB38>
Epoch 1
-------------------------------
loss: 0.180919  [    0/ 3444]
loss: 0.072007  [  100/ 3444]
loss: 0.023926  [  200/ 3444]
loss: 0.017915  [  300/ 3444]
loss: 0.023308  [  400/ 3444]
loss: 0.031974  [  500/ 3444]
loss: 0.063299  [  600/ 3444]
loss: 0.022008  [  700/ 3444]
loss: 0.008904  [  800/ 3444]
loss: 0.027925  [  900/ 3444]
loss: 0.010417  [ 1000/ 3444]
loss: 0.019319  [ 1100/ 3444]
loss: 0.015099  [ 1200/ 3444]
loss: 0.042316  [ 1300/ 3444]
loss: 0.118011  [ 1400/ 3444]
loss: 0.011185  [ 1500/ 3444]
loss: 0.011747  [ 1600/ 3444]
loss: 0.010341  [ 1700/ 3444]
loss: 0.015350  [ 1800/ 3444]
loss: 0.009592  [ 1900/ 3444]
loss: 0.014683  [ 2000/ 3444]
loss: 0.020201  [ 2100/ 3444]
loss: 0.021733  [ 2200/ 3444]
loss: 0.013008  [ 2300/ 3444]
loss: 0.006648  [ 2400/ 3444]
loss: 0.004199  [ 2500/ 3444]
loss: 0.003927  [ 2600/ 3444]
loss: 0.007559  [ 2700/ 3444]
loss: 0.015023  [ 2800/ 3444]
loss: 0.010138  [ 2900/ 3444]
loss: 0.007429  [ 3000/ 3444]
loss: 0.081196  [ 3100/ 3444]
loss: 0.126444  [ 3200/ 3444]
loss: 0.011215  [ 3300/ 3444]
loss: 0.028015  [ 3400/ 3444]
Epoch 2
-------------------------------
loss: 0.016952  [    0/ 3444]
loss: 0.014733  [  100/ 3444]
loss: 0.007920  [  200/ 3444]
loss: 0.015786  [  300/ 3444]
loss: 0.016123  [  400/ 3444]
loss: 0.016229  [  500/ 3444]
loss: 0.030947  [  600/ 3444]
loss: 0.021758  [  700/ 3444]
loss: 0.006727  [  800/ 3444]
loss: 0.019659  [  900/ 3444]
loss: 0.010250  [ 1000/ 3444]
loss: 0.012675  [ 1100/ 3444]
loss: 0.003468  [ 1200/ 3444]
loss: 0.018068  [ 1300/ 3444]
loss: 0.110771  [ 1400/ 3444]
loss: 0.009320  [ 1500/ 3444]
loss: 0.010045  [ 1600/ 3444]
loss: 0.008358  [ 1700/ 3444]
loss: 0.014109  [ 1800/ 3444]
loss: 0.010079  [ 1900/ 3444]
loss: 0.010668  [ 2000/ 3444]
loss: 0.018697  [ 2100/ 3444]
loss: 0.020194  [ 2200/ 3444]
loss: 0.011530  [ 2300/ 3444]
loss: 0.005436  [ 2400/ 3444]
loss: 0.004117  [ 2500/ 3444]
loss: 0.002689  [ 2600/ 3444]
loss: 0.005210  [ 2700/ 3444]
loss: 0.014265  [ 2800/ 3444]
loss: 0.011111  [ 2900/ 3444]
loss: 0.008449  [ 3000/ 3444]
loss: 0.033958  [ 3100/ 3444]
loss: 0.113353  [ 3200/ 3444]
loss: 0.009228  [ 3300/ 3444]
loss: 0.026440  [ 3400/ 3444]
Epoch 3
-------------------------------
loss: 0.016446  [    0/ 3444]
loss: 0.011745  [  100/ 3444]
loss: 0.006809  [  200/ 3444]
loss: 0.015830  [  300/ 3444]
loss: 0.013761  [  400/ 3444]
loss: 0.014491  [  500/ 3444]
loss: 0.027017  [  600/ 3444]
loss: 0.023241  [  700/ 3444]
loss: 0.007000  [  800/ 3444]
loss: 0.020394  [  900/ 3444]
loss: 0.009797  [ 1000/ 3444]
loss: 0.012024  [ 1100/ 3444]
loss: 0.003414  [ 1200/ 3444]
loss: 0.014498  [ 1300/ 3444]
loss: 0.112207  [ 1400/ 3444]
loss: 0.009100  [ 1500/ 3444]
loss: 0.009170  [ 1600/ 3444]
loss: 0.008143  [ 1700/ 3444]
loss: 0.015194  [ 1800/ 3444]
loss: 0.009756  [ 1900/ 3444]
loss: 0.009672  [ 2000/ 3444]
loss: 0.018118  [ 2100/ 3444]
loss: 0.019954  [ 2200/ 3444]
loss: 0.011477  [ 2300/ 3444]
loss: 0.005229  [ 2400/ 3444]
loss: 0.003689  [ 2500/ 3444]
loss: 0.003355  [ 2600/ 3444]
loss: 0.006604  [ 2700/ 3444]
loss: 0.014432  [ 2800/ 3444]
loss: 0.011668  [ 2900/ 3444]
loss: 0.009126  [ 3000/ 3444]
loss: 0.030260  [ 3100/ 3444]
loss: 0.106104  [ 3200/ 3444]
loss: 0.008402  [ 3300/ 3444]
loss: 0.027232  [ 3400/ 3444]
Epoch 4
-------------------------------
loss: 0.016528  [    0/ 3444]
loss: 0.011875  [  100/ 3444]
loss: 0.006592  [  200/ 3444]
loss: 0.015700  [  300/ 3444]
loss: 0.012343  [  400/ 3444]
loss: 0.013116  [  500/ 3444]
loss: 0.025902  [  600/ 3444]
loss: 0.024969  [  700/ 3444]
loss: 0.007082  [  800/ 3444]
loss: 0.020596  [  900/ 3444]
loss: 0.009816  [ 1000/ 3444]
loss: 0.011780  [ 1100/ 3444]
loss: 0.003535  [ 1200/ 3444]
loss: 0.014676  [ 1300/ 3444]
loss: 0.113227  [ 1400/ 3444]
loss: 0.008974  [ 1500/ 3444]
loss: 0.008705  [ 1600/ 3444]
loss: 0.008111  [ 1700/ 3444]
loss: 0.016399  [ 1800/ 3444]
loss: 0.009642  [ 1900/ 3444]
loss: 0.008623  [ 2000/ 3444]
loss: 0.017356  [ 2100/ 3444]
loss: 0.019762  [ 2200/ 3444]
loss: 0.011383  [ 2300/ 3444]
loss: 0.004789  [ 2400/ 3444]
loss: 0.003669  [ 2500/ 3444]
loss: 0.004072  [ 2600/ 3444]
loss: 0.006569  [ 2700/ 3444]
loss: 0.014699  [ 2800/ 3444]
loss: 0.012028  [ 2900/ 3444]
loss: 0.009380  [ 3000/ 3444]
loss: 0.027679  [ 3100/ 3444]
loss: 0.107701  [ 3200/ 3444]
loss: 0.007964  [ 3300/ 3444]
loss: 0.027205  [ 3400/ 3444]
Epoch 5
-------------------------------
loss: 0.017156  [    0/ 3444]
loss: 0.011868  [  100/ 3444]
loss: 0.006597  [  200/ 3444]
loss: 0.015809  [  300/ 3444]
loss: 0.011407  [  400/ 3444]
loss: 0.012383  [  500/ 3444]
loss: 0.024457  [  600/ 3444]
loss: 0.025445  [  700/ 3444]
loss: 0.007072  [  800/ 3444]
loss: 0.020648  [  900/ 3444]
loss: 0.009907  [ 1000/ 3444]
loss: 0.011545  [ 1100/ 3444]
loss: 0.003644  [ 1200/ 3444]
loss: 0.015343  [ 1300/ 3444]
loss: 0.113820  [ 1400/ 3444]
loss: 0.008989  [ 1500/ 3444]
loss: 0.008316  [ 1600/ 3444]
loss: 0.007998  [ 1700/ 3444]
loss: 0.017111  [ 1800/ 3444]
loss: 0.009364  [ 1900/ 3444]
loss: 0.007462  [ 2000/ 3444]
loss: 0.016583  [ 2100/ 3444]
loss: 0.019484  [ 2200/ 3444]
loss: 0.011211  [ 2300/ 3444]
loss: 0.004511  [ 2400/ 3444]
loss: 0.003562  [ 2500/ 3444]
loss: 0.004349  [ 2600/ 3444]
loss: 0.006431  [ 2700/ 3444]
loss: 0.014801  [ 2800/ 3444]
loss: 0.012374  [ 2900/ 3444]
loss: 0.009349  [ 3000/ 3444]
loss: 0.024662  [ 3100/ 3444]
loss: 0.110305  [ 3200/ 3444]
loss: 0.007913  [ 3300/ 3444]
loss: 0.027005  [ 3400/ 3444]
Epoch 6
-------------------------------
loss: 0.017771  [    0/ 3444]
loss: 0.012646  [  100/ 3444]
loss: 0.006919  [  200/ 3444]
loss: 0.016083  [  300/ 3444]
loss: 0.010832  [  400/ 3444]
loss: 0.012537  [  500/ 3444]
loss: 0.022693  [  600/ 3444]
loss: 0.025177  [  700/ 3444]
loss: 0.006948  [  800/ 3444]
loss: 0.020709  [  900/ 3444]
loss: 0.009964  [ 1000/ 3444]
loss: 0.011320  [ 1100/ 3444]
loss: 0.003798  [ 1200/ 3444]
loss: 0.016313  [ 1300/ 3444]
loss: 0.114260  [ 1400/ 3444]
loss: 0.008974  [ 1500/ 3444]
loss: 0.007990  [ 1600/ 3444]
loss: 0.008202  [ 1700/ 3444]
loss: 0.017482  [ 1800/ 3444]
loss: 0.008994  [ 1900/ 3444]
loss: 0.006652  [ 2000/ 3444]
loss: 0.016177  [ 2100/ 3444]
loss: 0.019128  [ 2200/ 3444]
loss: 0.010994  [ 2300/ 3444]
loss: 0.004129  [ 2400/ 3444]
loss: 0.003424  [ 2500/ 3444]
loss: 0.004326  [ 2600/ 3444]
loss: 0.006337  [ 2700/ 3444]
loss: 0.014814  [ 2800/ 3444]
loss: 0.012599  [ 2900/ 3444]
loss: 0.009173  [ 3000/ 3444]
loss: 0.023078  [ 3100/ 3444]
loss: 0.110100  [ 3200/ 3444]
loss: 0.008340  [ 3300/ 3444]
loss: 0.026328  [ 3400/ 3444]
Epoch 7
-------------------------------
loss: 0.017972  [    0/ 3444]
loss: 0.013374  [  100/ 3444]
loss: 0.007144  [  200/ 3444]
loss: 0.016169  [  300/ 3444]
loss: 0.010846  [  400/ 3444]
loss: 0.012463  [  500/ 3444]
loss: 0.021193  [  600/ 3444]
loss: 0.024415  [  700/ 3444]
loss: 0.006967  [  800/ 3444]
loss: 0.020863  [  900/ 3444]
loss: 0.010081  [ 1000/ 3444]
loss: 0.011119  [ 1100/ 3444]
loss: 0.003852  [ 1200/ 3444]
loss: 0.017262  [ 1300/ 3444]
loss: 0.114361  [ 1400/ 3444]
loss: 0.009179  [ 1500/ 3444]
loss: 0.007790  [ 1600/ 3444]
loss: 0.007992  [ 1700/ 3444]
loss: 0.017647  [ 1800/ 3444]
loss: 0.008572  [ 1900/ 3444]
loss: 0.006080  [ 2000/ 3444]
loss: 0.016113  [ 2100/ 3444]
loss: 0.018387  [ 2200/ 3444]
loss: 0.011000  [ 2300/ 3444]
loss: 0.003986  [ 2400/ 3444]
loss: 0.003435  [ 2500/ 3444]
loss: 0.004320  [ 2600/ 3444]
loss: 0.006301  [ 2700/ 3444]
loss: 0.014891  [ 2800/ 3444]
loss: 0.012644  [ 2900/ 3444]
loss: 0.008841  [ 3000/ 3444]
loss: 0.022900  [ 3100/ 3444]
loss: 0.111505  [ 3200/ 3444]
loss: 0.007091  [ 3300/ 3444]
loss: 0.025246  [ 3400/ 3444]
Epoch 8
-------------------------------
loss: 0.018332  [    0/ 3444]
loss: 0.013194  [  100/ 3444]
loss: 0.007753  [  200/ 3444]
loss: 0.016506  [  300/ 3444]
loss: 0.010263  [  400/ 3444]
loss: 0.011362  [  500/ 3444]
loss: 0.020915  [  600/ 3444]
loss: 0.022497  [  700/ 3444]
loss: 0.006952  [  800/ 3444]
loss: 0.021193  [  900/ 3444]
loss: 0.010271  [ 1000/ 3444]
loss: 0.010833  [ 1100/ 3444]
loss: 0.003821  [ 1200/ 3444]
loss: 0.017623  [ 1300/ 3444]
loss: 0.114922  [ 1400/ 3444]
loss: 0.009583  [ 1500/ 3444]
loss: 0.007655  [ 1600/ 3444]
loss: 0.007973  [ 1700/ 3444]
loss: 0.017457  [ 1800/ 3444]
loss: 0.008327  [ 1900/ 3444]
loss: 0.005841  [ 2000/ 3444]
loss: 0.016016  [ 2100/ 3444]
loss: 0.017507  [ 2200/ 3444]
loss: 0.011302  [ 2300/ 3444]
loss: 0.004073  [ 2400/ 3444]
loss: 0.003481  [ 2500/ 3444]
loss: 0.004119  [ 2600/ 3444]
loss: 0.006213  [ 2700/ 3444]
loss: 0.014986  [ 2800/ 3444]
loss: 0.012697  [ 2900/ 3444]
loss: 0.008597  [ 3000/ 3444]
loss: 0.022749  [ 3100/ 3444]
loss: 0.109273  [ 3200/ 3444]
loss: 0.006640  [ 3300/ 3444]
loss: 0.024091  [ 3400/ 3444]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3444
First Spike after testing: [ 0.09413768 -0.88650036]
[2 2 0 ... 0 2 0]
[0 0 1 ... 1 0 1]
Cluster 0 Occurrences: 1142; KMEANS: 1117
Cluster 1 Occurrences: 1180; KMEANS: 1163
Cluster 2 Occurrences: 1122; KMEANS: 1164
Centroids: [[-0.03574801, 1.3142142], [-0.8929168, 0.90097535], [-0.13307098, -0.84823185]]
Centroids: [[-0.1276236, -0.85497314], [-0.023172015, 1.3224413], [-0.92290986, 0.88425535]]
Contingency Matrix: 
[[   1 1127   14]
 [   2   35 1143]
 [1114    1    7]]
[[1, 1127, -1], [-1, -1, -1], [1114, 1, -1]]
[[-1, -1, -1], [-1, -1, -1], [1114, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 2, 0: 1, 2: 0}
New Contingency Matrix: 
[[1127   14    1]
 [  35 1143    2]
 [   1    7 1114]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1127, 1143, 1114], Sum: 3384
All_Elements: [1127, 14, 1, 35, 1143, 2, 1, 7, 1114], Sum: 3444
Accuracy: 0.9825783972125436
Done!
