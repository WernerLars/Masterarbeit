Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Difficult1_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_59_25
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028C035CDC88>
Sampling rate: 24000.0
Raw: [ 0.04887081  0.02693095 -0.0154249  ... -0.09301659 -0.11629005
 -0.14613101]
Times: [    340     491     641 ... 1439047 1439065 1439816]
Cluster: [1 1 1 ... 3 2 2]
Number of different clusters:  3
Number of Spikes: 3472
First aligned Spike Frame: [ 0.12751554  0.12305882  0.10482977  0.09479529  0.10214978  0.11675932
  0.11777927  0.09307299  0.04670706 -0.00574343 -0.06143573 -0.14637617
 -0.20942665 -0.00208103  0.52241508  0.81651544  0.46446121 -0.19226425
 -0.60927882 -0.6713583  -0.57871227 -0.49011309 -0.4269388  -0.3668903
 -0.30523219 -0.24747124 -0.19738203 -0.15189972 -0.10449507 -0.05533325
 -0.01452429  0.01008816  0.02570853  0.04365027  0.06334113  0.07980397
  0.08484457  0.07688513  0.06142919  0.04320028  0.02240626  0.00477291
 -0.00393242 -0.00135684  0.00575182  0.0026944  -0.01541647]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1172
Cluster 2, Occurrences: 1141
<torch.utils.data.dataloader.DataLoader object at 0x0000028C072218D0>
Epoch 1
-------------------------------
loss: 0.095068  [    0/ 3472]
loss: 0.122946  [  100/ 3472]
loss: 0.027758  [  200/ 3472]
loss: 0.027245  [  300/ 3472]
loss: 0.045096  [  400/ 3472]
loss: 0.014683  [  500/ 3472]
loss: 0.018211  [  600/ 3472]
loss: 0.015484  [  700/ 3472]
loss: 0.041057  [  800/ 3472]
loss: 0.027556  [  900/ 3472]
loss: 0.010796  [ 1000/ 3472]
loss: 0.029600  [ 1100/ 3472]
loss: 0.025624  [ 1200/ 3472]
loss: 0.010626  [ 1300/ 3472]
loss: 0.003974  [ 1400/ 3472]
loss: 0.048049  [ 1500/ 3472]
loss: 0.021546  [ 1600/ 3472]
loss: 0.009889  [ 1700/ 3472]
loss: 0.028872  [ 1800/ 3472]
loss: 0.138655  [ 1900/ 3472]
loss: 0.048216  [ 2000/ 3472]
loss: 0.014484  [ 2100/ 3472]
loss: 0.010920  [ 2200/ 3472]
loss: 0.005439  [ 2300/ 3472]
loss: 0.008973  [ 2400/ 3472]
loss: 0.013276  [ 2500/ 3472]
loss: 0.015560  [ 2600/ 3472]
loss: 0.010862  [ 2700/ 3472]
loss: 0.025952  [ 2800/ 3472]
loss: 0.030879  [ 2900/ 3472]
loss: 0.008530  [ 3000/ 3472]
loss: 0.021792  [ 3100/ 3472]
loss: 0.014156  [ 3200/ 3472]
loss: 0.009373  [ 3300/ 3472]
loss: 0.009217  [ 3400/ 3472]
Epoch 2
-------------------------------
loss: 0.008982  [    0/ 3472]
loss: 0.007597  [  100/ 3472]
loss: 0.010035  [  200/ 3472]
loss: 0.018093  [  300/ 3472]
loss: 0.006477  [  400/ 3472]
loss: 0.015445  [  500/ 3472]
loss: 0.012240  [  600/ 3472]
loss: 0.005564  [  700/ 3472]
loss: 0.036346  [  800/ 3472]
loss: 0.027653  [  900/ 3472]
loss: 0.010119  [ 1000/ 3472]
loss: 0.026662  [ 1100/ 3472]
loss: 0.024821  [ 1200/ 3472]
loss: 0.005835  [ 1300/ 3472]
loss: 0.003422  [ 1400/ 3472]
loss: 0.037534  [ 1500/ 3472]
loss: 0.018802  [ 1600/ 3472]
loss: 0.011016  [ 1700/ 3472]
loss: 0.029332  [ 1800/ 3472]
loss: 0.132823  [ 1900/ 3472]
loss: 0.049657  [ 2000/ 3472]
loss: 0.013913  [ 2100/ 3472]
loss: 0.010850  [ 2200/ 3472]
loss: 0.005151  [ 2300/ 3472]
loss: 0.008807  [ 2400/ 3472]
loss: 0.013772  [ 2500/ 3472]
loss: 0.015020  [ 2600/ 3472]
loss: 0.010940  [ 2700/ 3472]
loss: 0.026384  [ 2800/ 3472]
loss: 0.030273  [ 2900/ 3472]
loss: 0.008503  [ 3000/ 3472]
loss: 0.021706  [ 3100/ 3472]
loss: 0.014248  [ 3200/ 3472]
loss: 0.009495  [ 3300/ 3472]
loss: 0.009098  [ 3400/ 3472]
Epoch 3
-------------------------------
loss: 0.009130  [    0/ 3472]
loss: 0.007526  [  100/ 3472]
loss: 0.010080  [  200/ 3472]
loss: 0.018230  [  300/ 3472]
loss: 0.006511  [  400/ 3472]
loss: 0.015388  [  500/ 3472]
loss: 0.012336  [  600/ 3472]
loss: 0.005516  [  700/ 3472]
loss: 0.036259  [  800/ 3472]
loss: 0.027375  [  900/ 3472]
loss: 0.010106  [ 1000/ 3472]
loss: 0.026602  [ 1100/ 3472]
loss: 0.024699  [ 1200/ 3472]
loss: 0.005775  [ 1300/ 3472]
loss: 0.003367  [ 1400/ 3472]
loss: 0.037275  [ 1500/ 3472]
loss: 0.018700  [ 1600/ 3472]
loss: 0.011051  [ 1700/ 3472]
loss: 0.029192  [ 1800/ 3472]
loss: 0.132453  [ 1900/ 3472]
loss: 0.049721  [ 2000/ 3472]
loss: 0.013760  [ 2100/ 3472]
loss: 0.010863  [ 2200/ 3472]
loss: 0.005145  [ 2300/ 3472]
loss: 0.008742  [ 2400/ 3472]
loss: 0.013742  [ 2500/ 3472]
loss: 0.015156  [ 2600/ 3472]
loss: 0.011001  [ 2700/ 3472]
loss: 0.026488  [ 2800/ 3472]
loss: 0.030210  [ 2900/ 3472]
loss: 0.008549  [ 3000/ 3472]
loss: 0.021817  [ 3100/ 3472]
loss: 0.014167  [ 3200/ 3472]
loss: 0.009530  [ 3300/ 3472]
loss: 0.009096  [ 3400/ 3472]
Epoch 4
-------------------------------
loss: 0.009041  [    0/ 3472]
loss: 0.007378  [  100/ 3472]
loss: 0.010093  [  200/ 3472]
loss: 0.018390  [  300/ 3472]
loss: 0.006615  [  400/ 3472]
loss: 0.015296  [  500/ 3472]
loss: 0.012461  [  600/ 3472]
loss: 0.005459  [  700/ 3472]
loss: 0.036137  [  800/ 3472]
loss: 0.027437  [  900/ 3472]
loss: 0.010090  [ 1000/ 3472]
loss: 0.026461  [ 1100/ 3472]
loss: 0.024431  [ 1200/ 3472]
loss: 0.005764  [ 1300/ 3472]
loss: 0.003612  [ 1400/ 3472]
loss: 0.036738  [ 1500/ 3472]
loss: 0.018709  [ 1600/ 3472]
loss: 0.011117  [ 1700/ 3472]
loss: 0.029176  [ 1800/ 3472]
loss: 0.131889  [ 1900/ 3472]
loss: 0.050461  [ 2000/ 3472]
loss: 0.013739  [ 2100/ 3472]
loss: 0.010957  [ 2200/ 3472]
loss: 0.005204  [ 2300/ 3472]
loss: 0.008602  [ 2400/ 3472]
loss: 0.012967  [ 2500/ 3472]
loss: 0.015384  [ 2600/ 3472]
loss: 0.011180  [ 2700/ 3472]
loss: 0.026865  [ 2800/ 3472]
loss: 0.030030  [ 2900/ 3472]
loss: 0.008472  [ 3000/ 3472]
loss: 0.021801  [ 3100/ 3472]
loss: 0.013962  [ 3200/ 3472]
loss: 0.009818  [ 3300/ 3472]
loss: 0.009036  [ 3400/ 3472]
Epoch 5
-------------------------------
loss: 0.008638  [    0/ 3472]
loss: 0.007260  [  100/ 3472]
loss: 0.010167  [  200/ 3472]
loss: 0.018486  [  300/ 3472]
loss: 0.006501  [  400/ 3472]
loss: 0.015201  [  500/ 3472]
loss: 0.012766  [  600/ 3472]
loss: 0.005771  [  700/ 3472]
loss: 0.036119  [  800/ 3472]
loss: 0.027874  [  900/ 3472]
loss: 0.009945  [ 1000/ 3472]
loss: 0.026524  [ 1100/ 3472]
loss: 0.024226  [ 1200/ 3472]
loss: 0.005223  [ 1300/ 3472]
loss: 0.004365  [ 1400/ 3472]
loss: 0.034807  [ 1500/ 3472]
loss: 0.018671  [ 1600/ 3472]
loss: 0.011122  [ 1700/ 3472]
loss: 0.029922  [ 1800/ 3472]
loss: 0.130307  [ 1900/ 3472]
loss: 0.051766  [ 2000/ 3472]
loss: 0.013895  [ 2100/ 3472]
loss: 0.011048  [ 2200/ 3472]
loss: 0.005522  [ 2300/ 3472]
loss: 0.008765  [ 2400/ 3472]
loss: 0.013466  [ 2500/ 3472]
loss: 0.015261  [ 2600/ 3472]
loss: 0.011762  [ 2700/ 3472]
loss: 0.027577  [ 2800/ 3472]
loss: 0.029921  [ 2900/ 3472]
loss: 0.008525  [ 3000/ 3472]
loss: 0.021199  [ 3100/ 3472]
loss: 0.013770  [ 3200/ 3472]
loss: 0.009949  [ 3300/ 3472]
loss: 0.009197  [ 3400/ 3472]
Epoch 6
-------------------------------
loss: 0.007693  [    0/ 3472]
loss: 0.007240  [  100/ 3472]
loss: 0.010282  [  200/ 3472]
loss: 0.018398  [  300/ 3472]
loss: 0.006310  [  400/ 3472]
loss: 0.015030  [  500/ 3472]
loss: 0.012881  [  600/ 3472]
loss: 0.006222  [  700/ 3472]
loss: 0.035883  [  800/ 3472]
loss: 0.028211  [  900/ 3472]
loss: 0.009587  [ 1000/ 3472]
loss: 0.026537  [ 1100/ 3472]
loss: 0.023913  [ 1200/ 3472]
loss: 0.004803  [ 1300/ 3472]
loss: 0.004835  [ 1400/ 3472]
loss: 0.031706  [ 1500/ 3472]
loss: 0.018672  [ 1600/ 3472]
loss: 0.011247  [ 1700/ 3472]
loss: 0.030620  [ 1800/ 3472]
loss: 0.128397  [ 1900/ 3472]
loss: 0.053123  [ 2000/ 3472]
loss: 0.014103  [ 2100/ 3472]
loss: 0.011145  [ 2200/ 3472]
loss: 0.006002  [ 2300/ 3472]
loss: 0.009357  [ 2400/ 3472]
loss: 0.014111  [ 2500/ 3472]
loss: 0.014752  [ 2600/ 3472]
loss: 0.012480  [ 2700/ 3472]
loss: 0.028354  [ 2800/ 3472]
loss: 0.029586  [ 2900/ 3472]
loss: 0.008667  [ 3000/ 3472]
loss: 0.020236  [ 3100/ 3472]
loss: 0.013668  [ 3200/ 3472]
loss: 0.010436  [ 3300/ 3472]
loss: 0.009500  [ 3400/ 3472]
Epoch 7
-------------------------------
loss: 0.006837  [    0/ 3472]
loss: 0.007224  [  100/ 3472]
loss: 0.010488  [  200/ 3472]
loss: 0.018376  [  300/ 3472]
loss: 0.006064  [  400/ 3472]
loss: 0.014889  [  500/ 3472]
loss: 0.012949  [  600/ 3472]
loss: 0.006583  [  700/ 3472]
loss: 0.035970  [  800/ 3472]
loss: 0.028377  [  900/ 3472]
loss: 0.009313  [ 1000/ 3472]
loss: 0.026606  [ 1100/ 3472]
loss: 0.023640  [ 1200/ 3472]
loss: 0.004677  [ 1300/ 3472]
loss: 0.005075  [ 1400/ 3472]
loss: 0.030951  [ 1500/ 3472]
loss: 0.018948  [ 1600/ 3472]
loss: 0.011275  [ 1700/ 3472]
loss: 0.031419  [ 1800/ 3472]
loss: 0.127223  [ 1900/ 3472]
loss: 0.054408  [ 2000/ 3472]
loss: 0.014373  [ 2100/ 3472]
loss: 0.011257  [ 2200/ 3472]
loss: 0.006385  [ 2300/ 3472]
loss: 0.009837  [ 2400/ 3472]
loss: 0.015370  [ 2500/ 3472]
loss: 0.014475  [ 2600/ 3472]
loss: 0.012993  [ 2700/ 3472]
loss: 0.028756  [ 2800/ 3472]
loss: 0.029565  [ 2900/ 3472]
loss: 0.008708  [ 3000/ 3472]
loss: 0.019544  [ 3100/ 3472]
loss: 0.013593  [ 3200/ 3472]
loss: 0.010408  [ 3300/ 3472]
loss: 0.009807  [ 3400/ 3472]
Epoch 8
-------------------------------
loss: 0.006289  [    0/ 3472]
loss: 0.007251  [  100/ 3472]
loss: 0.010518  [  200/ 3472]
loss: 0.018482  [  300/ 3472]
loss: 0.005967  [  400/ 3472]
loss: 0.014710  [  500/ 3472]
loss: 0.012951  [  600/ 3472]
loss: 0.006885  [  700/ 3472]
loss: 0.035864  [  800/ 3472]
loss: 0.028357  [  900/ 3472]
loss: 0.009118  [ 1000/ 3472]
loss: 0.026448  [ 1100/ 3472]
loss: 0.023269  [ 1200/ 3472]
loss: 0.004707  [ 1300/ 3472]
loss: 0.005270  [ 1400/ 3472]
loss: 0.031348  [ 1500/ 3472]
loss: 0.019675  [ 1600/ 3472]
loss: 0.011380  [ 1700/ 3472]
loss: 0.031853  [ 1800/ 3472]
loss: 0.126691  [ 1900/ 3472]
loss: 0.055180  [ 2000/ 3472]
loss: 0.014342  [ 2100/ 3472]
loss: 0.011283  [ 2200/ 3472]
loss: 0.006640  [ 2300/ 3472]
loss: 0.010272  [ 2400/ 3472]
loss: 0.015733  [ 2500/ 3472]
loss: 0.014267  [ 2600/ 3472]
loss: 0.013462  [ 2700/ 3472]
loss: 0.029236  [ 2800/ 3472]
loss: 0.029319  [ 2900/ 3472]
loss: 0.008728  [ 3000/ 3472]
loss: 0.018869  [ 3100/ 3472]
loss: 0.013648  [ 3200/ 3472]
loss: 0.010336  [ 3300/ 3472]
loss: 0.009877  [ 3400/ 3472]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3472
First Spike after testing: [-0.03865993  0.25204742]
[0 0 0 ... 2 1 1]
[0 0 0 ... 2 0 1]
Cluster 0 Occurrences: 1159; KMEANS: 1069
Cluster 1 Occurrences: 1172; KMEANS: 1340
Cluster 2 Occurrences: 1141; KMEANS: 1063
Centroids: [[-0.054573633, -0.026810396], [-0.45677722, -0.42493483], [0.18026257, -0.5406505]]
Centroids: [[0.03737958, 0.04140553], [-0.54634875, -0.43946096], [0.2814999, -0.5657233]]
Contingency Matrix: 
[[799 248 112]
 [151 902 119]
 [119 190 832]]
[[799, -1, 112], [-1, -1, -1], [119, -1, 832]]
[[799, -1, -1], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 2: 2, 0: 0}
New Contingency Matrix: 
[[799 248 112]
 [151 902 119]
 [119 190 832]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [799, 902, 832], Sum: 2533
All_Elements: [799, 248, 112, 151, 902, 119, 119, 190, 832], Sum: 3472
Accuracy: 0.7295506912442397
Done!
