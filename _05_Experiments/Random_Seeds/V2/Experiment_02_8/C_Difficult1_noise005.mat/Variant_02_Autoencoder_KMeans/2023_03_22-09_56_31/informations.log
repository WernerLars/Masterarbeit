Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_56_31
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028C07221828>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x0000028B85474E80>
Epoch 1
-------------------------------
loss: 0.178004  [    0/ 3383]
loss: 0.054972  [  100/ 3383]
loss: 0.020585  [  200/ 3383]
loss: 0.009676  [  300/ 3383]
loss: 0.006802  [  400/ 3383]
loss: 0.009398  [  500/ 3383]
loss: 0.010214  [  600/ 3383]
loss: 0.014031  [  700/ 3383]
loss: 0.008976  [  800/ 3383]
loss: 0.005476  [  900/ 3383]
loss: 0.096827  [ 1000/ 3383]
loss: 0.057632  [ 1100/ 3383]
loss: 0.024972  [ 1200/ 3383]
loss: 0.009638  [ 1300/ 3383]
loss: 0.005464  [ 1400/ 3383]
loss: 0.014400  [ 1500/ 3383]
loss: 0.004601  [ 1600/ 3383]
loss: 0.001632  [ 1700/ 3383]
loss: 0.012365  [ 1800/ 3383]
loss: 0.014195  [ 1900/ 3383]
loss: 0.003317  [ 2000/ 3383]
loss: 0.003610  [ 2100/ 3383]
loss: 0.009134  [ 2200/ 3383]
loss: 0.001491  [ 2300/ 3383]
loss: 0.004151  [ 2400/ 3383]
loss: 0.027704  [ 2500/ 3383]
loss: 0.001391  [ 2600/ 3383]
loss: 0.003783  [ 2700/ 3383]
loss: 0.006304  [ 2800/ 3383]
loss: 0.005803  [ 2900/ 3383]
loss: 0.003473  [ 3000/ 3383]
loss: 0.004551  [ 3100/ 3383]
loss: 0.064756  [ 3200/ 3383]
loss: 0.002533  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.003783  [    0/ 3383]
loss: 0.006117  [  100/ 3383]
loss: 0.005692  [  200/ 3383]
loss: 0.002057  [  300/ 3383]
loss: 0.003088  [  400/ 3383]
loss: 0.004997  [  500/ 3383]
loss: 0.001168  [  600/ 3383]
loss: 0.001831  [  700/ 3383]
loss: 0.007441  [  800/ 3383]
loss: 0.001542  [  900/ 3383]
loss: 0.092800  [ 1000/ 3383]
loss: 0.057668  [ 1100/ 3383]
loss: 0.022987  [ 1200/ 3383]
loss: 0.009460  [ 1300/ 3383]
loss: 0.004272  [ 1400/ 3383]
loss: 0.015057  [ 1500/ 3383]
loss: 0.002607  [ 1600/ 3383]
loss: 0.001535  [ 1700/ 3383]
loss: 0.012121  [ 1800/ 3383]
loss: 0.014240  [ 1900/ 3383]
loss: 0.003069  [ 2000/ 3383]
loss: 0.003416  [ 2100/ 3383]
loss: 0.009015  [ 2200/ 3383]
loss: 0.001477  [ 2300/ 3383]
loss: 0.004001  [ 2400/ 3383]
loss: 0.026568  [ 2500/ 3383]
loss: 0.001251  [ 2600/ 3383]
loss: 0.003784  [ 2700/ 3383]
loss: 0.006301  [ 2800/ 3383]
loss: 0.006010  [ 2900/ 3383]
loss: 0.003340  [ 3000/ 3383]
loss: 0.004496  [ 3100/ 3383]
loss: 0.064400  [ 3200/ 3383]
loss: 0.002554  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.003841  [    0/ 3383]
loss: 0.006027  [  100/ 3383]
loss: 0.005589  [  200/ 3383]
loss: 0.002013  [  300/ 3383]
loss: 0.003134  [  400/ 3383]
loss: 0.004904  [  500/ 3383]
loss: 0.001180  [  600/ 3383]
loss: 0.001766  [  700/ 3383]
loss: 0.007450  [  800/ 3383]
loss: 0.001625  [  900/ 3383]
loss: 0.093197  [ 1000/ 3383]
loss: 0.057743  [ 1100/ 3383]
loss: 0.023057  [ 1200/ 3383]
loss: 0.009437  [ 1300/ 3383]
loss: 0.004282  [ 1400/ 3383]
loss: 0.015083  [ 1500/ 3383]
loss: 0.002603  [ 1600/ 3383]
loss: 0.001530  [ 1700/ 3383]
loss: 0.012058  [ 1800/ 3383]
loss: 0.014215  [ 1900/ 3383]
loss: 0.003039  [ 2000/ 3383]
loss: 0.003409  [ 2100/ 3383]
loss: 0.008925  [ 2200/ 3383]
loss: 0.001491  [ 2300/ 3383]
loss: 0.003980  [ 2400/ 3383]
loss: 0.026393  [ 2500/ 3383]
loss: 0.001221  [ 2600/ 3383]
loss: 0.003758  [ 2700/ 3383]
loss: 0.006298  [ 2800/ 3383]
loss: 0.006082  [ 2900/ 3383]
loss: 0.003301  [ 3000/ 3383]
loss: 0.004508  [ 3100/ 3383]
loss: 0.064398  [ 3200/ 3383]
loss: 0.002570  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.003808  [    0/ 3383]
loss: 0.005990  [  100/ 3383]
loss: 0.005486  [  200/ 3383]
loss: 0.002003  [  300/ 3383]
loss: 0.003113  [  400/ 3383]
loss: 0.004828  [  500/ 3383]
loss: 0.001185  [  600/ 3383]
loss: 0.001758  [  700/ 3383]
loss: 0.007450  [  800/ 3383]
loss: 0.001639  [  900/ 3383]
loss: 0.093469  [ 1000/ 3383]
loss: 0.057791  [ 1100/ 3383]
loss: 0.023169  [ 1200/ 3383]
loss: 0.009407  [ 1300/ 3383]
loss: 0.004285  [ 1400/ 3383]
loss: 0.015093  [ 1500/ 3383]
loss: 0.002597  [ 1600/ 3383]
loss: 0.001522  [ 1700/ 3383]
loss: 0.011996  [ 1800/ 3383]
loss: 0.014188  [ 1900/ 3383]
loss: 0.003017  [ 2000/ 3383]
loss: 0.003407  [ 2100/ 3383]
loss: 0.008838  [ 2200/ 3383]
loss: 0.001512  [ 2300/ 3383]
loss: 0.004014  [ 2400/ 3383]
loss: 0.027149  [ 2500/ 3383]
loss: 0.001193  [ 2600/ 3383]
loss: 0.003675  [ 2700/ 3383]
loss: 0.006328  [ 2800/ 3383]
loss: 0.006179  [ 2900/ 3383]
loss: 0.003181  [ 3000/ 3383]
loss: 0.004536  [ 3100/ 3383]
loss: 0.064415  [ 3200/ 3383]
loss: 0.002622  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.003753  [    0/ 3383]
loss: 0.005966  [  100/ 3383]
loss: 0.005398  [  200/ 3383]
loss: 0.001984  [  300/ 3383]
loss: 0.003037  [  400/ 3383]
loss: 0.004778  [  500/ 3383]
loss: 0.001193  [  600/ 3383]
loss: 0.001749  [  700/ 3383]
loss: 0.007443  [  800/ 3383]
loss: 0.001644  [  900/ 3383]
loss: 0.093652  [ 1000/ 3383]
loss: 0.057837  [ 1100/ 3383]
loss: 0.023297  [ 1200/ 3383]
loss: 0.009381  [ 1300/ 3383]
loss: 0.004281  [ 1400/ 3383]
loss: 0.015081  [ 1500/ 3383]
loss: 0.002589  [ 1600/ 3383]
loss: 0.001514  [ 1700/ 3383]
loss: 0.011917  [ 1800/ 3383]
loss: 0.014141  [ 1900/ 3383]
loss: 0.003011  [ 2000/ 3383]
loss: 0.003413  [ 2100/ 3383]
loss: 0.008777  [ 2200/ 3383]
loss: 0.001532  [ 2300/ 3383]
loss: 0.004003  [ 2400/ 3383]
loss: 0.026785  [ 2500/ 3383]
loss: 0.001163  [ 2600/ 3383]
loss: 0.003652  [ 2700/ 3383]
loss: 0.006333  [ 2800/ 3383]
loss: 0.006258  [ 2900/ 3383]
loss: 0.003156  [ 3000/ 3383]
loss: 0.004537  [ 3100/ 3383]
loss: 0.064423  [ 3200/ 3383]
loss: 0.002644  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.003742  [    0/ 3383]
loss: 0.005941  [  100/ 3383]
loss: 0.005334  [  200/ 3383]
loss: 0.001985  [  300/ 3383]
loss: 0.003003  [  400/ 3383]
loss: 0.004742  [  500/ 3383]
loss: 0.001204  [  600/ 3383]
loss: 0.001716  [  700/ 3383]
loss: 0.007424  [  800/ 3383]
loss: 0.001584  [  900/ 3383]
loss: 0.093715  [ 1000/ 3383]
loss: 0.057608  [ 1100/ 3383]
loss: 0.023459  [ 1200/ 3383]
loss: 0.009354  [ 1300/ 3383]
loss: 0.004215  [ 1400/ 3383]
loss: 0.015198  [ 1500/ 3383]
loss: 0.002579  [ 1600/ 3383]
loss: 0.001512  [ 1700/ 3383]
loss: 0.011542  [ 1800/ 3383]
loss: 0.014098  [ 1900/ 3383]
loss: 0.002908  [ 2000/ 3383]
loss: 0.003389  [ 2100/ 3383]
loss: 0.008763  [ 2200/ 3383]
loss: 0.001574  [ 2300/ 3383]
loss: 0.003855  [ 2400/ 3383]
loss: 0.027149  [ 2500/ 3383]
loss: 0.001069  [ 2600/ 3383]
loss: 0.003087  [ 2700/ 3383]
loss: 0.005967  [ 2800/ 3383]
loss: 0.005991  [ 2900/ 3383]
loss: 0.003654  [ 3000/ 3383]
loss: 0.004493  [ 3100/ 3383]
loss: 0.065331  [ 3200/ 3383]
loss: 0.002644  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.003747  [    0/ 3383]
loss: 0.005941  [  100/ 3383]
loss: 0.005472  [  200/ 3383]
loss: 0.002329  [  300/ 3383]
loss: 0.002821  [  400/ 3383]
loss: 0.004734  [  500/ 3383]
loss: 0.001201  [  600/ 3383]
loss: 0.001767  [  700/ 3383]
loss: 0.006688  [  800/ 3383]
loss: 0.001728  [  900/ 3383]
loss: 0.094369  [ 1000/ 3383]
loss: 0.057371  [ 1100/ 3383]
loss: 0.024023  [ 1200/ 3383]
loss: 0.009335  [ 1300/ 3383]
loss: 0.004021  [ 1400/ 3383]
loss: 0.015546  [ 1500/ 3383]
loss: 0.002480  [ 1600/ 3383]
loss: 0.001486  [ 1700/ 3383]
loss: 0.010149  [ 1800/ 3383]
loss: 0.013896  [ 1900/ 3383]
loss: 0.002951  [ 2000/ 3383]
loss: 0.003211  [ 2100/ 3383]
loss: 0.008731  [ 2200/ 3383]
loss: 0.001695  [ 2300/ 3383]
loss: 0.003484  [ 2400/ 3383]
loss: 0.025459  [ 2500/ 3383]
loss: 0.001115  [ 2600/ 3383]
loss: 0.002712  [ 2700/ 3383]
loss: 0.005610  [ 2800/ 3383]
loss: 0.005653  [ 2900/ 3383]
loss: 0.004137  [ 3000/ 3383]
loss: 0.004400  [ 3100/ 3383]
loss: 0.066101  [ 3200/ 3383]
loss: 0.002576  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.003714  [    0/ 3383]
loss: 0.005897  [  100/ 3383]
loss: 0.005486  [  200/ 3383]
loss: 0.002067  [  300/ 3383]
loss: 0.002485  [  400/ 3383]
loss: 0.004668  [  500/ 3383]
loss: 0.001211  [  600/ 3383]
loss: 0.001753  [  700/ 3383]
loss: 0.006433  [  800/ 3383]
loss: 0.001545  [  900/ 3383]
loss: 0.094829  [ 1000/ 3383]
loss: 0.057680  [ 1100/ 3383]
loss: 0.024258  [ 1200/ 3383]
loss: 0.009248  [ 1300/ 3383]
loss: 0.004088  [ 1400/ 3383]
loss: 0.015616  [ 1500/ 3383]
loss: 0.002417  [ 1600/ 3383]
loss: 0.001524  [ 1700/ 3383]
loss: 0.009745  [ 1800/ 3383]
loss: 0.013840  [ 1900/ 3383]
loss: 0.002975  [ 2000/ 3383]
loss: 0.003168  [ 2100/ 3383]
loss: 0.008644  [ 2200/ 3383]
loss: 0.001781  [ 2300/ 3383]
loss: 0.003402  [ 2400/ 3383]
loss: 0.025236  [ 2500/ 3383]
loss: 0.001108  [ 2600/ 3383]
loss: 0.002484  [ 2700/ 3383]
loss: 0.005494  [ 2800/ 3383]
loss: 0.005548  [ 2900/ 3383]
loss: 0.003985  [ 3000/ 3383]
loss: 0.004352  [ 3100/ 3383]
loss: 0.066409  [ 3200/ 3383]
loss: 0.002541  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [ 0.459971   -0.39635253]
[2 1 2 ... 0 1 2]
[0 2 0 ... 1 2 0]
Cluster 0 Occurrences: 1115; KMEANS: 1215
Cluster 1 Occurrences: 1113; KMEANS: 1082
Cluster 2 Occurrences: 1155; KMEANS: 1086
Centroids: [[0.10771728, 0.037431378], [-0.3708662, -0.46391562], [0.37058952, -0.6075152]]
Centroids: [[0.38219628, -0.61113626], [0.09454289, 0.05664051], [-0.39714763, -0.4558349]]
Contingency Matrix: 
[[  32 1078    5]
 [  36    2 1075]
 [1147    2    6]]
[[-1, 1078, 5], [-1, 2, 1075], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1075], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1078    5   32]
 [   2 1075   36]
 [   2    6 1147]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1078, 1075, 1147], Sum: 3300
All_Elements: [1078, 5, 32, 2, 1075, 36, 2, 6, 1147], Sum: 3383
Accuracy: 0.9754655631096659
Done!
