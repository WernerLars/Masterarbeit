Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Difficult1_noise020.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_00_37
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028C07E032B0>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
<torch.utils.data.dataloader.DataLoader object at 0x0000028C072218D0>
Epoch 1
-------------------------------
loss: 0.210969  [    0/ 3414]
loss: 0.104473  [  100/ 3414]
loss: 0.029746  [  200/ 3414]
loss: 0.039911  [  300/ 3414]
loss: 0.046041  [  400/ 3414]
loss: 0.067993  [  500/ 3414]
loss: 0.034620  [  600/ 3414]
loss: 0.049408  [  700/ 3414]
loss: 0.075922  [  800/ 3414]
loss: 0.033322  [  900/ 3414]
loss: 0.024083  [ 1000/ 3414]
loss: 0.017176  [ 1100/ 3414]
loss: 0.045601  [ 1200/ 3414]
loss: 0.029535  [ 1300/ 3414]
loss: 0.020441  [ 1400/ 3414]
loss: 0.023957  [ 1500/ 3414]
loss: 0.020840  [ 1600/ 3414]
loss: 0.023971  [ 1700/ 3414]
loss: 0.028967  [ 1800/ 3414]
loss: 0.036130  [ 1900/ 3414]
loss: 0.036591  [ 2000/ 3414]
loss: 0.029470  [ 2100/ 3414]
loss: 0.046975  [ 2200/ 3414]
loss: 0.042656  [ 2300/ 3414]
loss: 0.011771  [ 2400/ 3414]
loss: 0.161284  [ 2500/ 3414]
loss: 0.027094  [ 2600/ 3414]
loss: 0.015019  [ 2700/ 3414]
loss: 0.006554  [ 2800/ 3414]
loss: 0.042374  [ 2900/ 3414]
loss: 0.034625  [ 3000/ 3414]
loss: 0.031554  [ 3100/ 3414]
loss: 0.022643  [ 3200/ 3414]
loss: 0.011832  [ 3300/ 3414]
loss: 0.020013  [ 3400/ 3414]
Epoch 2
-------------------------------
loss: 0.029103  [    0/ 3414]
loss: 0.030458  [  100/ 3414]
loss: 0.008331  [  200/ 3414]
loss: 0.045873  [  300/ 3414]
loss: 0.012258  [  400/ 3414]
loss: 0.048437  [  500/ 3414]
loss: 0.030826  [  600/ 3414]
loss: 0.034525  [  700/ 3414]
loss: 0.054009  [  800/ 3414]
loss: 0.019860  [  900/ 3414]
loss: 0.016239  [ 1000/ 3414]
loss: 0.022387  [ 1100/ 3414]
loss: 0.006781  [ 1200/ 3414]
loss: 0.032843  [ 1300/ 3414]
loss: 0.018608  [ 1400/ 3414]
loss: 0.026604  [ 1500/ 3414]
loss: 0.010992  [ 1600/ 3414]
loss: 0.011022  [ 1700/ 3414]
loss: 0.028911  [ 1800/ 3414]
loss: 0.021554  [ 1900/ 3414]
loss: 0.034955  [ 2000/ 3414]
loss: 0.030111  [ 2100/ 3414]
loss: 0.039655  [ 2200/ 3414]
loss: 0.036370  [ 2300/ 3414]
loss: 0.008716  [ 2400/ 3414]
loss: 0.160046  [ 2500/ 3414]
loss: 0.024933  [ 2600/ 3414]
loss: 0.013840  [ 2700/ 3414]
loss: 0.009890  [ 2800/ 3414]
loss: 0.043587  [ 2900/ 3414]
loss: 0.042021  [ 3000/ 3414]
loss: 0.033503  [ 3100/ 3414]
loss: 0.021150  [ 3200/ 3414]
loss: 0.011774  [ 3300/ 3414]
loss: 0.023404  [ 3400/ 3414]
Epoch 3
-------------------------------
loss: 0.040255  [    0/ 3414]
loss: 0.030203  [  100/ 3414]
loss: 0.008406  [  200/ 3414]
loss: 0.047395  [  300/ 3414]
loss: 0.013739  [  400/ 3414]
loss: 0.044695  [  500/ 3414]
loss: 0.029062  [  600/ 3414]
loss: 0.034578  [  700/ 3414]
loss: 0.051695  [  800/ 3414]
loss: 0.021498  [  900/ 3414]
loss: 0.016224  [ 1000/ 3414]
loss: 0.022633  [ 1100/ 3414]
loss: 0.007105  [ 1200/ 3414]
loss: 0.032742  [ 1300/ 3414]
loss: 0.018680  [ 1400/ 3414]
loss: 0.026870  [ 1500/ 3414]
loss: 0.010677  [ 1600/ 3414]
loss: 0.010157  [ 1700/ 3414]
loss: 0.029030  [ 1800/ 3414]
loss: 0.020719  [ 1900/ 3414]
loss: 0.034173  [ 2000/ 3414]
loss: 0.031633  [ 2100/ 3414]
loss: 0.039853  [ 2200/ 3414]
loss: 0.036434  [ 2300/ 3414]
loss: 0.008540  [ 2400/ 3414]
loss: 0.160160  [ 2500/ 3414]
loss: 0.024419  [ 2600/ 3414]
loss: 0.013726  [ 2700/ 3414]
loss: 0.010989  [ 2800/ 3414]
loss: 0.043324  [ 2900/ 3414]
loss: 0.043281  [ 3000/ 3414]
loss: 0.034276  [ 3100/ 3414]
loss: 0.021011  [ 3200/ 3414]
loss: 0.011775  [ 3300/ 3414]
loss: 0.023992  [ 3400/ 3414]
Epoch 4
-------------------------------
loss: 0.044368  [    0/ 3414]
loss: 0.030191  [  100/ 3414]
loss: 0.008581  [  200/ 3414]
loss: 0.047867  [  300/ 3414]
loss: 0.014313  [  400/ 3414]
loss: 0.044030  [  500/ 3414]
loss: 0.028575  [  600/ 3414]
loss: 0.035187  [  700/ 3414]
loss: 0.051660  [  800/ 3414]
loss: 0.022320  [  900/ 3414]
loss: 0.016029  [ 1000/ 3414]
loss: 0.022567  [ 1100/ 3414]
loss: 0.007186  [ 1200/ 3414]
loss: 0.032580  [ 1300/ 3414]
loss: 0.018681  [ 1400/ 3414]
loss: 0.026814  [ 1500/ 3414]
loss: 0.010444  [ 1600/ 3414]
loss: 0.010074  [ 1700/ 3414]
loss: 0.029021  [ 1800/ 3414]
loss: 0.020498  [ 1900/ 3414]
loss: 0.033948  [ 2000/ 3414]
loss: 0.031758  [ 2100/ 3414]
loss: 0.039123  [ 2200/ 3414]
loss: 0.036652  [ 2300/ 3414]
loss: 0.008488  [ 2400/ 3414]
loss: 0.160636  [ 2500/ 3414]
loss: 0.024170  [ 2600/ 3414]
loss: 0.013914  [ 2700/ 3414]
loss: 0.011164  [ 2800/ 3414]
loss: 0.043445  [ 2900/ 3414]
loss: 0.043756  [ 3000/ 3414]
loss: 0.034334  [ 3100/ 3414]
loss: 0.020994  [ 3200/ 3414]
loss: 0.011692  [ 3300/ 3414]
loss: 0.024156  [ 3400/ 3414]
Epoch 5
-------------------------------
loss: 0.046489  [    0/ 3414]
loss: 0.030342  [  100/ 3414]
loss: 0.008571  [  200/ 3414]
loss: 0.048175  [  300/ 3414]
loss: 0.014595  [  400/ 3414]
loss: 0.043954  [  500/ 3414]
loss: 0.028453  [  600/ 3414]
loss: 0.035198  [  700/ 3414]
loss: 0.052045  [  800/ 3414]
loss: 0.022991  [  900/ 3414]
loss: 0.015872  [ 1000/ 3414]
loss: 0.022549  [ 1100/ 3414]
loss: 0.007037  [ 1200/ 3414]
loss: 0.032428  [ 1300/ 3414]
loss: 0.018686  [ 1400/ 3414]
loss: 0.026621  [ 1500/ 3414]
loss: 0.010292  [ 1600/ 3414]
loss: 0.010010  [ 1700/ 3414]
loss: 0.028915  [ 1800/ 3414]
loss: 0.020291  [ 1900/ 3414]
loss: 0.034007  [ 2000/ 3414]
loss: 0.031915  [ 2100/ 3414]
loss: 0.037730  [ 2200/ 3414]
loss: 0.036686  [ 2300/ 3414]
loss: 0.008307  [ 2400/ 3414]
loss: 0.161107  [ 2500/ 3414]
loss: 0.023972  [ 2600/ 3414]
loss: 0.014037  [ 2700/ 3414]
loss: 0.011211  [ 2800/ 3414]
loss: 0.043972  [ 2900/ 3414]
loss: 0.044491  [ 3000/ 3414]
loss: 0.034176  [ 3100/ 3414]
loss: 0.021026  [ 3200/ 3414]
loss: 0.011674  [ 3300/ 3414]
loss: 0.024301  [ 3400/ 3414]
Epoch 6
-------------------------------
loss: 0.045304  [    0/ 3414]
loss: 0.030516  [  100/ 3414]
loss: 0.008368  [  200/ 3414]
loss: 0.048215  [  300/ 3414]
loss: 0.014956  [  400/ 3414]
loss: 0.044042  [  500/ 3414]
loss: 0.028411  [  600/ 3414]
loss: 0.035162  [  700/ 3414]
loss: 0.050988  [  800/ 3414]
loss: 0.023659  [  900/ 3414]
loss: 0.015544  [ 1000/ 3414]
loss: 0.022413  [ 1100/ 3414]
loss: 0.006895  [ 1200/ 3414]
loss: 0.032302  [ 1300/ 3414]
loss: 0.018701  [ 1400/ 3414]
loss: 0.026523  [ 1500/ 3414]
loss: 0.010258  [ 1600/ 3414]
loss: 0.009989  [ 1700/ 3414]
loss: 0.028830  [ 1800/ 3414]
loss: 0.020132  [ 1900/ 3414]
loss: 0.033653  [ 2000/ 3414]
loss: 0.032068  [ 2100/ 3414]
loss: 0.037642  [ 2200/ 3414]
loss: 0.036817  [ 2300/ 3414]
loss: 0.008213  [ 2400/ 3414]
loss: 0.161539  [ 2500/ 3414]
loss: 0.023822  [ 2600/ 3414]
loss: 0.013839  [ 2700/ 3414]
loss: 0.011028  [ 2800/ 3414]
loss: 0.044118  [ 2900/ 3414]
loss: 0.044838  [ 3000/ 3414]
loss: 0.033962  [ 3100/ 3414]
loss: 0.020848  [ 3200/ 3414]
loss: 0.011678  [ 3300/ 3414]
loss: 0.024356  [ 3400/ 3414]
Epoch 7
-------------------------------
loss: 0.043494  [    0/ 3414]
loss: 0.030563  [  100/ 3414]
loss: 0.008317  [  200/ 3414]
loss: 0.048251  [  300/ 3414]
loss: 0.015128  [  400/ 3414]
loss: 0.043967  [  500/ 3414]
loss: 0.028585  [  600/ 3414]
loss: 0.035047  [  700/ 3414]
loss: 0.050851  [  800/ 3414]
loss: 0.023971  [  900/ 3414]
loss: 0.015311  [ 1000/ 3414]
loss: 0.022257  [ 1100/ 3414]
loss: 0.007053  [ 1200/ 3414]
loss: 0.032422  [ 1300/ 3414]
loss: 0.018611  [ 1400/ 3414]
loss: 0.026533  [ 1500/ 3414]
loss: 0.010229  [ 1600/ 3414]
loss: 0.009843  [ 1700/ 3414]
loss: 0.028816  [ 1800/ 3414]
loss: 0.020136  [ 1900/ 3414]
loss: 0.033625  [ 2000/ 3414]
loss: 0.032183  [ 2100/ 3414]
loss: 0.035920  [ 2200/ 3414]
loss: 0.037078  [ 2300/ 3414]
loss: 0.008183  [ 2400/ 3414]
loss: 0.161384  [ 2500/ 3414]
loss: 0.023675  [ 2600/ 3414]
loss: 0.013916  [ 2700/ 3414]
loss: 0.010988  [ 2800/ 3414]
loss: 0.044255  [ 2900/ 3414]
loss: 0.044279  [ 3000/ 3414]
loss: 0.033797  [ 3100/ 3414]
loss: 0.020734  [ 3200/ 3414]
loss: 0.011667  [ 3300/ 3414]
loss: 0.024350  [ 3400/ 3414]
Epoch 8
-------------------------------
loss: 0.041862  [    0/ 3414]
loss: 0.030568  [  100/ 3414]
loss: 0.008315  [  200/ 3414]
loss: 0.048226  [  300/ 3414]
loss: 0.015201  [  400/ 3414]
loss: 0.043996  [  500/ 3414]
loss: 0.028670  [  600/ 3414]
loss: 0.035045  [  700/ 3414]
loss: 0.050785  [  800/ 3414]
loss: 0.024149  [  900/ 3414]
loss: 0.015194  [ 1000/ 3414]
loss: 0.022112  [ 1100/ 3414]
loss: 0.007056  [ 1200/ 3414]
loss: 0.032452  [ 1300/ 3414]
loss: 0.018657  [ 1400/ 3414]
loss: 0.026417  [ 1500/ 3414]
loss: 0.010174  [ 1600/ 3414]
loss: 0.009785  [ 1700/ 3414]
loss: 0.028695  [ 1800/ 3414]
loss: 0.020126  [ 1900/ 3414]
loss: 0.033451  [ 2000/ 3414]
loss: 0.032242  [ 2100/ 3414]
loss: 0.035779  [ 2200/ 3414]
loss: 0.037140  [ 2300/ 3414]
loss: 0.008233  [ 2400/ 3414]
loss: 0.161851  [ 2500/ 3414]
loss: 0.023554  [ 2600/ 3414]
loss: 0.013997  [ 2700/ 3414]
loss: 0.010955  [ 2800/ 3414]
loss: 0.044081  [ 2900/ 3414]
loss: 0.044253  [ 3000/ 3414]
loss: 0.033745  [ 3100/ 3414]
loss: 0.020674  [ 3200/ 3414]
loss: 0.011624  [ 3300/ 3414]
loss: 0.024297  [ 3400/ 3414]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3414
First Spike after testing: [-1.2007896   0.09450945]
[1 1 0 ... 0 0 2]
[0 2 1 ... 0 2 1]
Cluster 0 Occurrences: 1136; KMEANS: 1171
Cluster 1 Occurrences: 1099; KMEANS: 1012
Cluster 2 Occurrences: 1179; KMEANS: 1231
Centroids: [[-0.48623416, -0.19671239], [-0.3225717, -0.08618535], [-0.09879303, -0.42796504]]
Centroids: [[-0.65237427, -0.30927277], [-0.08757167, -0.588624], [-0.13874288, 0.10974173]]
Contingency Matrix: 
[[648 135 353]
 [357 170 572]
 [166 707 306]]
[[648, -1, 353], [357, -1, 572], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 572], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 0, 1: 2}
New Contingency Matrix: 
[[648 353 135]
 [357 572 170]
 [166 306 707]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [648, 572, 707], Sum: 1927
All_Elements: [648, 353, 135, 357, 572, 170, 166, 306, 707], Sum: 3414
Accuracy: 0.5644405389572349
Done!
