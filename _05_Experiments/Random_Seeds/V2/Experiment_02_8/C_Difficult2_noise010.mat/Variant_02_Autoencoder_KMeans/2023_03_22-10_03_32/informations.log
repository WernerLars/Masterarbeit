Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_03_32
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028C1014F470>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x0000028C072218D0>
Epoch 1
-------------------------------
loss: 0.144906  [    0/ 3462]
loss: 0.122074  [  100/ 3462]
loss: 0.075092  [  200/ 3462]
loss: 0.058374  [  300/ 3462]
loss: 0.018095  [  400/ 3462]
loss: 0.009850  [  500/ 3462]
loss: 0.014708  [  600/ 3462]
loss: 0.016877  [  700/ 3462]
loss: 0.009771  [  800/ 3462]
loss: 0.014267  [  900/ 3462]
loss: 0.011108  [ 1000/ 3462]
loss: 0.063055  [ 1100/ 3462]
loss: 0.012274  [ 1200/ 3462]
loss: 0.005908  [ 1300/ 3462]
loss: 0.009452  [ 1400/ 3462]
loss: 0.006252  [ 1500/ 3462]
loss: 0.008482  [ 1600/ 3462]
loss: 0.005379  [ 1700/ 3462]
loss: 0.014301  [ 1800/ 3462]
loss: 0.007299  [ 1900/ 3462]
loss: 0.012734  [ 2000/ 3462]
loss: 0.058085  [ 2100/ 3462]
loss: 0.002301  [ 2200/ 3462]
loss: 0.005537  [ 2300/ 3462]
loss: 0.012320  [ 2400/ 3462]
loss: 0.006490  [ 2500/ 3462]
loss: 0.015597  [ 2600/ 3462]
loss: 0.006970  [ 2700/ 3462]
loss: 0.005897  [ 2800/ 3462]
loss: 0.014630  [ 2900/ 3462]
loss: 0.112955  [ 3000/ 3462]
loss: 0.007137  [ 3100/ 3462]
loss: 0.007772  [ 3200/ 3462]
loss: 0.140497  [ 3300/ 3462]
loss: 0.013857  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.001848  [    0/ 3462]
loss: 0.012556  [  100/ 3462]
loss: 0.013128  [  200/ 3462]
loss: 0.015444  [  300/ 3462]
loss: 0.011117  [  400/ 3462]
loss: 0.008360  [  500/ 3462]
loss: 0.006255  [  600/ 3462]
loss: 0.016820  [  700/ 3462]
loss: 0.008358  [  800/ 3462]
loss: 0.016013  [  900/ 3462]
loss: 0.010328  [ 1000/ 3462]
loss: 0.041992  [ 1100/ 3462]
loss: 0.014162  [ 1200/ 3462]
loss: 0.003442  [ 1300/ 3462]
loss: 0.007373  [ 1400/ 3462]
loss: 0.012025  [ 1500/ 3462]
loss: 0.007731  [ 1600/ 3462]
loss: 0.006021  [ 1700/ 3462]
loss: 0.015312  [ 1800/ 3462]
loss: 0.007451  [ 1900/ 3462]
loss: 0.011453  [ 2000/ 3462]
loss: 0.056757  [ 2100/ 3462]
loss: 0.001761  [ 2200/ 3462]
loss: 0.005464  [ 2300/ 3462]
loss: 0.012044  [ 2400/ 3462]
loss: 0.006029  [ 2500/ 3462]
loss: 0.013198  [ 2600/ 3462]
loss: 0.006100  [ 2700/ 3462]
loss: 0.005195  [ 2800/ 3462]
loss: 0.015705  [ 2900/ 3462]
loss: 0.114495  [ 3000/ 3462]
loss: 0.006225  [ 3100/ 3462]
loss: 0.008037  [ 3200/ 3462]
loss: 0.137040  [ 3300/ 3462]
loss: 0.012653  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.001889  [    0/ 3462]
loss: 0.012155  [  100/ 3462]
loss: 0.012179  [  200/ 3462]
loss: 0.012599  [  300/ 3462]
loss: 0.011105  [  400/ 3462]
loss: 0.007347  [  500/ 3462]
loss: 0.005240  [  600/ 3462]
loss: 0.016982  [  700/ 3462]
loss: 0.007946  [  800/ 3462]
loss: 0.015812  [  900/ 3462]
loss: 0.009269  [ 1000/ 3462]
loss: 0.042866  [ 1100/ 3462]
loss: 0.014118  [ 1200/ 3462]
loss: 0.003431  [ 1300/ 3462]
loss: 0.006139  [ 1400/ 3462]
loss: 0.012057  [ 1500/ 3462]
loss: 0.006757  [ 1600/ 3462]
loss: 0.005819  [ 1700/ 3462]
loss: 0.012874  [ 1800/ 3462]
loss: 0.006702  [ 1900/ 3462]
loss: 0.009794  [ 2000/ 3462]
loss: 0.052922  [ 2100/ 3462]
loss: 0.001784  [ 2200/ 3462]
loss: 0.004975  [ 2300/ 3462]
loss: 0.012133  [ 2400/ 3462]
loss: 0.005994  [ 2500/ 3462]
loss: 0.011308  [ 2600/ 3462]
loss: 0.005578  [ 2700/ 3462]
loss: 0.004583  [ 2800/ 3462]
loss: 0.015208  [ 2900/ 3462]
loss: 0.112409  [ 3000/ 3462]
loss: 0.006208  [ 3100/ 3462]
loss: 0.008331  [ 3200/ 3462]
loss: 0.131827  [ 3300/ 3462]
loss: 0.012626  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.001639  [    0/ 3462]
loss: 0.012064  [  100/ 3462]
loss: 0.010022  [  200/ 3462]
loss: 0.012478  [  300/ 3462]
loss: 0.011208  [  400/ 3462]
loss: 0.006285  [  500/ 3462]
loss: 0.003432  [  600/ 3462]
loss: 0.017618  [  700/ 3462]
loss: 0.008427  [  800/ 3462]
loss: 0.015188  [  900/ 3462]
loss: 0.007759  [ 1000/ 3462]
loss: 0.043555  [ 1100/ 3462]
loss: 0.013449  [ 1200/ 3462]
loss: 0.003164  [ 1300/ 3462]
loss: 0.004874  [ 1400/ 3462]
loss: 0.012161  [ 1500/ 3462]
loss: 0.005326  [ 1600/ 3462]
loss: 0.006040  [ 1700/ 3462]
loss: 0.009991  [ 1800/ 3462]
loss: 0.006345  [ 1900/ 3462]
loss: 0.008478  [ 2000/ 3462]
loss: 0.054795  [ 2100/ 3462]
loss: 0.001742  [ 2200/ 3462]
loss: 0.004868  [ 2300/ 3462]
loss: 0.012231  [ 2400/ 3462]
loss: 0.005886  [ 2500/ 3462]
loss: 0.009593  [ 2600/ 3462]
loss: 0.005396  [ 2700/ 3462]
loss: 0.004768  [ 2800/ 3462]
loss: 0.014417  [ 2900/ 3462]
loss: 0.109511  [ 3000/ 3462]
loss: 0.006122  [ 3100/ 3462]
loss: 0.008692  [ 3200/ 3462]
loss: 0.123743  [ 3300/ 3462]
loss: 0.012685  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.001715  [    0/ 3462]
loss: 0.011566  [  100/ 3462]
loss: 0.007497  [  200/ 3462]
loss: 0.013143  [  300/ 3462]
loss: 0.010879  [  400/ 3462]
loss: 0.004990  [  500/ 3462]
loss: 0.003567  [  600/ 3462]
loss: 0.019169  [  700/ 3462]
loss: 0.009183  [  800/ 3462]
loss: 0.014454  [  900/ 3462]
loss: 0.006902  [ 1000/ 3462]
loss: 0.041929  [ 1100/ 3462]
loss: 0.012188  [ 1200/ 3462]
loss: 0.002591  [ 1300/ 3462]
loss: 0.003570  [ 1400/ 3462]
loss: 0.012739  [ 1500/ 3462]
loss: 0.004002  [ 1600/ 3462]
loss: 0.005870  [ 1700/ 3462]
loss: 0.008063  [ 1800/ 3462]
loss: 0.005818  [ 1900/ 3462]
loss: 0.006941  [ 2000/ 3462]
loss: 0.058777  [ 2100/ 3462]
loss: 0.001773  [ 2200/ 3462]
loss: 0.005094  [ 2300/ 3462]
loss: 0.012230  [ 2400/ 3462]
loss: 0.005788  [ 2500/ 3462]
loss: 0.008446  [ 2600/ 3462]
loss: 0.005405  [ 2700/ 3462]
loss: 0.005054  [ 2800/ 3462]
loss: 0.013914  [ 2900/ 3462]
loss: 0.107108  [ 3000/ 3462]
loss: 0.005829  [ 3100/ 3462]
loss: 0.008723  [ 3200/ 3462]
loss: 0.117772  [ 3300/ 3462]
loss: 0.012551  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.001666  [    0/ 3462]
loss: 0.011215  [  100/ 3462]
loss: 0.005629  [  200/ 3462]
loss: 0.013933  [  300/ 3462]
loss: 0.010867  [  400/ 3462]
loss: 0.003942  [  500/ 3462]
loss: 0.004028  [  600/ 3462]
loss: 0.019687  [  700/ 3462]
loss: 0.009499  [  800/ 3462]
loss: 0.013984  [  900/ 3462]
loss: 0.006404  [ 1000/ 3462]
loss: 0.040435  [ 1100/ 3462]
loss: 0.010775  [ 1200/ 3462]
loss: 0.002259  [ 1300/ 3462]
loss: 0.002863  [ 1400/ 3462]
loss: 0.013257  [ 1500/ 3462]
loss: 0.003305  [ 1600/ 3462]
loss: 0.005607  [ 1700/ 3462]
loss: 0.007084  [ 1800/ 3462]
loss: 0.005196  [ 1900/ 3462]
loss: 0.006436  [ 2000/ 3462]
loss: 0.061158  [ 2100/ 3462]
loss: 0.001720  [ 2200/ 3462]
loss: 0.005200  [ 2300/ 3462]
loss: 0.012173  [ 2400/ 3462]
loss: 0.005635  [ 2500/ 3462]
loss: 0.007776  [ 2600/ 3462]
loss: 0.005543  [ 2700/ 3462]
loss: 0.005212  [ 2800/ 3462]
loss: 0.013524  [ 2900/ 3462]
loss: 0.105086  [ 3000/ 3462]
loss: 0.005357  [ 3100/ 3462]
loss: 0.008712  [ 3200/ 3462]
loss: 0.112154  [ 3300/ 3462]
loss: 0.012172  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.001686  [    0/ 3462]
loss: 0.010771  [  100/ 3462]
loss: 0.004560  [  200/ 3462]
loss: 0.014269  [  300/ 3462]
loss: 0.010521  [  400/ 3462]
loss: 0.003193  [  500/ 3462]
loss: 0.005306  [  600/ 3462]
loss: 0.019822  [  700/ 3462]
loss: 0.009403  [  800/ 3462]
loss: 0.013674  [  900/ 3462]
loss: 0.006120  [ 1000/ 3462]
loss: 0.040384  [ 1100/ 3462]
loss: 0.010903  [ 1200/ 3462]
loss: 0.002102  [ 1300/ 3462]
loss: 0.002402  [ 1400/ 3462]
loss: 0.013523  [ 1500/ 3462]
loss: 0.002677  [ 1600/ 3462]
loss: 0.005341  [ 1700/ 3462]
loss: 0.006190  [ 1800/ 3462]
loss: 0.005186  [ 1900/ 3462]
loss: 0.006504  [ 2000/ 3462]
loss: 0.059955  [ 2100/ 3462]
loss: 0.001612  [ 2200/ 3462]
loss: 0.005286  [ 2300/ 3462]
loss: 0.012191  [ 2400/ 3462]
loss: 0.005421  [ 2500/ 3462]
loss: 0.007314  [ 2600/ 3462]
loss: 0.005606  [ 2700/ 3462]
loss: 0.005381  [ 2800/ 3462]
loss: 0.013109  [ 2900/ 3462]
loss: 0.103952  [ 3000/ 3462]
loss: 0.005134  [ 3100/ 3462]
loss: 0.008662  [ 3200/ 3462]
loss: 0.108666  [ 3300/ 3462]
loss: 0.012245  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.001716  [    0/ 3462]
loss: 0.010505  [  100/ 3462]
loss: 0.004209  [  200/ 3462]
loss: 0.014817  [  300/ 3462]
loss: 0.010797  [  400/ 3462]
loss: 0.002954  [  500/ 3462]
loss: 0.005623  [  600/ 3462]
loss: 0.020078  [  700/ 3462]
loss: 0.009278  [  800/ 3462]
loss: 0.013568  [  900/ 3462]
loss: 0.005696  [ 1000/ 3462]
loss: 0.040437  [ 1100/ 3462]
loss: 0.009823  [ 1200/ 3462]
loss: 0.002056  [ 1300/ 3462]
loss: 0.002294  [ 1400/ 3462]
loss: 0.013606  [ 1500/ 3462]
loss: 0.002398  [ 1600/ 3462]
loss: 0.005224  [ 1700/ 3462]
loss: 0.005732  [ 1800/ 3462]
loss: 0.004634  [ 1900/ 3462]
loss: 0.006344  [ 2000/ 3462]
loss: 0.062000  [ 2100/ 3462]
loss: 0.001582  [ 2200/ 3462]
loss: 0.005331  [ 2300/ 3462]
loss: 0.012219  [ 2400/ 3462]
loss: 0.005250  [ 2500/ 3462]
loss: 0.006850  [ 2600/ 3462]
loss: 0.005592  [ 2700/ 3462]
loss: 0.005402  [ 2800/ 3462]
loss: 0.013002  [ 2900/ 3462]
loss: 0.103045  [ 3000/ 3462]
loss: 0.005020  [ 3100/ 3462]
loss: 0.008584  [ 3200/ 3462]
loss: 0.106624  [ 3300/ 3462]
loss: 0.012115  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [-0.1061573  -0.31927475]
[0 2 2 ... 0 1 2]
[2 0 0 ... 2 1 0]
Cluster 0 Occurrences: 1187; KMEANS: 1154
Cluster 1 Occurrences: 1136; KMEANS: 1135
Cluster 2 Occurrences: 1139; KMEANS: 1173
Centroids: [[0.02133674, -0.3022856], [-0.717162, 1.188949], [-0.48166636, 0.017262856]]
Centroids: [[-0.5205353, -0.005817363], [-0.721986, 1.1937186], [0.07004638, -0.28700948]]
Contingency Matrix: 
[[  71    1 1115]
 [   5 1128    3]
 [1078    6   55]]
[[71, -1, 1115], [-1, -1, -1], [1078, -1, 55]]
[[-1, -1, -1], [-1, -1, -1], [1078, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 0: 2, 2: 0}
New Contingency Matrix: 
[[1115    1   71]
 [   3 1128    5]
 [  55    6 1078]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1115, 1128, 1078], Sum: 3321
All_Elements: [1115, 1, 71, 3, 1128, 5, 55, 6, 1078], Sum: 3462
Accuracy: 0.9592720970537262
Done!
