Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Easy2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_51_20
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028B8AA1FE48>
Sampling rate: 24000.0
Raw: [ 0.11862069  0.1123084   0.10401825 ... -0.10219323 -0.10268373
 -0.08956559]
Times: [    346     799    1005 ... 1436867 1437273 1437800]
Cluster: [3 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3410
First aligned Spike Frame: [ 2.05661766e-03  8.27536867e-03  1.66427268e-02  2.31246655e-02
  2.28936935e-02  1.99169368e-02  2.25281834e-02  3.37605443e-02
  4.94182133e-02  6.24484568e-02  8.42111946e-02  1.71357846e-01
  3.88441746e-01  6.99052305e-01  9.59509287e-01  1.03608873e+00
  9.29169963e-01  7.55567481e-01  6.10726415e-01  5.06818519e-01
  4.23878029e-01  3.55610047e-01  3.01970228e-01  2.53702042e-01
  1.98274486e-01  1.32802904e-01  6.40690121e-02  7.96454927e-04
 -5.66201776e-02 -1.11669131e-01 -1.62581026e-01 -2.01746625e-01
 -2.23071447e-01 -2.29516190e-01 -2.30160694e-01 -2.27148529e-01
 -2.18080531e-01 -2.04276810e-01 -1.90750996e-01 -1.81098693e-01
 -1.72421418e-01 -1.61640218e-01 -1.48460304e-01 -1.32332846e-01
 -1.13338953e-01 -9.43725979e-02 -7.56249106e-02]
Cluster 0, Occurrences: 1130
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1167
<torch.utils.data.dataloader.DataLoader object at 0x0000028B8542C978>
Epoch 1
-------------------------------
loss: 0.168837  [    0/ 3410]
loss: 0.112581  [  100/ 3410]
loss: 0.011356  [  200/ 3410]
loss: 0.017729  [  300/ 3410]
loss: 0.003626  [  400/ 3410]
loss: 0.002977  [  500/ 3410]
loss: 0.001219  [  600/ 3410]
loss: 0.004188  [  700/ 3410]
loss: 0.007980  [  800/ 3410]
loss: 0.008416  [  900/ 3410]
loss: 0.016336  [ 1000/ 3410]
loss: 0.003187  [ 1100/ 3410]
loss: 0.003605  [ 1200/ 3410]
loss: 0.006128  [ 1300/ 3410]
loss: 0.001873  [ 1400/ 3410]
loss: 0.002175  [ 1500/ 3410]
loss: 0.001453  [ 1600/ 3410]
loss: 0.006310  [ 1700/ 3410]
loss: 0.006954  [ 1800/ 3410]
loss: 0.001138  [ 1900/ 3410]
loss: 0.046928  [ 2000/ 3410]
loss: 0.003011  [ 2100/ 3410]
loss: 0.028523  [ 2200/ 3410]
loss: 0.002729  [ 2300/ 3410]
loss: 0.002979  [ 2400/ 3410]
loss: 0.122798  [ 2500/ 3410]
loss: 0.009281  [ 2600/ 3410]
loss: 0.003910  [ 2700/ 3410]
loss: 0.001040  [ 2800/ 3410]
loss: 0.007519  [ 2900/ 3410]
loss: 0.002713  [ 3000/ 3410]
loss: 0.000986  [ 3100/ 3410]
loss: 0.003220  [ 3200/ 3410]
loss: 0.001575  [ 3300/ 3410]
loss: 0.001221  [ 3400/ 3410]
Epoch 2
-------------------------------
loss: 0.000657  [    0/ 3410]
loss: 0.003549  [  100/ 3410]
loss: 0.004359  [  200/ 3410]
loss: 0.002547  [  300/ 3410]
loss: 0.002274  [  400/ 3410]
loss: 0.004106  [  500/ 3410]
loss: 0.001097  [  600/ 3410]
loss: 0.005904  [  700/ 3410]
loss: 0.004352  [  800/ 3410]
loss: 0.002507  [  900/ 3410]
loss: 0.006378  [ 1000/ 3410]
loss: 0.003046  [ 1100/ 3410]
loss: 0.003130  [ 1200/ 3410]
loss: 0.005444  [ 1300/ 3410]
loss: 0.001334  [ 1400/ 3410]
loss: 0.001959  [ 1500/ 3410]
loss: 0.001489  [ 1600/ 3410]
loss: 0.005098  [ 1700/ 3410]
loss: 0.005673  [ 1800/ 3410]
loss: 0.001062  [ 1900/ 3410]
loss: 0.043611  [ 2000/ 3410]
loss: 0.002904  [ 2100/ 3410]
loss: 0.028768  [ 2200/ 3410]
loss: 0.002757  [ 2300/ 3410]
loss: 0.002643  [ 2400/ 3410]
loss: 0.119835  [ 2500/ 3410]
loss: 0.010831  [ 2600/ 3410]
loss: 0.004079  [ 2700/ 3410]
loss: 0.000778  [ 2800/ 3410]
loss: 0.007103  [ 2900/ 3410]
loss: 0.002678  [ 3000/ 3410]
loss: 0.001010  [ 3100/ 3410]
loss: 0.003106  [ 3200/ 3410]
loss: 0.001505  [ 3300/ 3410]
loss: 0.000899  [ 3400/ 3410]
Epoch 3
-------------------------------
loss: 0.000516  [    0/ 3410]
loss: 0.003164  [  100/ 3410]
loss: 0.004648  [  200/ 3410]
loss: 0.002480  [  300/ 3410]
loss: 0.002044  [  400/ 3410]
loss: 0.005732  [  500/ 3410]
loss: 0.001010  [  600/ 3410]
loss: 0.005892  [  700/ 3410]
loss: 0.004066  [  800/ 3410]
loss: 0.002490  [  900/ 3410]
loss: 0.006251  [ 1000/ 3410]
loss: 0.002881  [ 1100/ 3410]
loss: 0.002355  [ 1200/ 3410]
loss: 0.005233  [ 1300/ 3410]
loss: 0.001285  [ 1400/ 3410]
loss: 0.001890  [ 1500/ 3410]
loss: 0.001464  [ 1600/ 3410]
loss: 0.005113  [ 1700/ 3410]
loss: 0.005513  [ 1800/ 3410]
loss: 0.001020  [ 1900/ 3410]
loss: 0.036901  [ 2000/ 3410]
loss: 0.002976  [ 2100/ 3410]
loss: 0.028614  [ 2200/ 3410]
loss: 0.002572  [ 2300/ 3410]
loss: 0.002420  [ 2400/ 3410]
loss: 0.118570  [ 2500/ 3410]
loss: 0.008986  [ 2600/ 3410]
loss: 0.004062  [ 2700/ 3410]
loss: 0.000614  [ 2800/ 3410]
loss: 0.006823  [ 2900/ 3410]
loss: 0.002566  [ 3000/ 3410]
loss: 0.000984  [ 3100/ 3410]
loss: 0.002821  [ 3200/ 3410]
loss: 0.001473  [ 3300/ 3410]
loss: 0.001111  [ 3400/ 3410]
Epoch 4
-------------------------------
loss: 0.000401  [    0/ 3410]
loss: 0.002824  [  100/ 3410]
loss: 0.004985  [  200/ 3410]
loss: 0.003059  [  300/ 3410]
loss: 0.001992  [  400/ 3410]
loss: 0.005015  [  500/ 3410]
loss: 0.000965  [  600/ 3410]
loss: 0.005960  [  700/ 3410]
loss: 0.003520  [  800/ 3410]
loss: 0.002496  [  900/ 3410]
loss: 0.006162  [ 1000/ 3410]
loss: 0.002883  [ 1100/ 3410]
loss: 0.001889  [ 1200/ 3410]
loss: 0.005400  [ 1300/ 3410]
loss: 0.001223  [ 1400/ 3410]
loss: 0.001814  [ 1500/ 3410]
loss: 0.001440  [ 1600/ 3410]
loss: 0.004959  [ 1700/ 3410]
loss: 0.005452  [ 1800/ 3410]
loss: 0.000934  [ 1900/ 3410]
loss: 0.032728  [ 2000/ 3410]
loss: 0.002979  [ 2100/ 3410]
loss: 0.028335  [ 2200/ 3410]
loss: 0.002404  [ 2300/ 3410]
loss: 0.002267  [ 2400/ 3410]
loss: 0.116941  [ 2500/ 3410]
loss: 0.008143  [ 2600/ 3410]
loss: 0.004047  [ 2700/ 3410]
loss: 0.000615  [ 2800/ 3410]
loss: 0.006674  [ 2900/ 3410]
loss: 0.002465  [ 3000/ 3410]
loss: 0.000915  [ 3100/ 3410]
loss: 0.002760  [ 3200/ 3410]
loss: 0.001575  [ 3300/ 3410]
loss: 0.001460  [ 3400/ 3410]
Epoch 5
-------------------------------
loss: 0.000375  [    0/ 3410]
loss: 0.002725  [  100/ 3410]
loss: 0.004914  [  200/ 3410]
loss: 0.004178  [  300/ 3410]
loss: 0.001913  [  400/ 3410]
loss: 0.004861  [  500/ 3410]
loss: 0.000939  [  600/ 3410]
loss: 0.004800  [  700/ 3410]
loss: 0.003795  [  800/ 3410]
loss: 0.002486  [  900/ 3410]
loss: 0.006235  [ 1000/ 3410]
loss: 0.002841  [ 1100/ 3410]
loss: 0.002037  [ 1200/ 3410]
loss: 0.005579  [ 1300/ 3410]
loss: 0.001152  [ 1400/ 3410]
loss: 0.001685  [ 1500/ 3410]
loss: 0.001523  [ 1600/ 3410]
loss: 0.004952  [ 1700/ 3410]
loss: 0.005284  [ 1800/ 3410]
loss: 0.000889  [ 1900/ 3410]
loss: 0.028776  [ 2000/ 3410]
loss: 0.002932  [ 2100/ 3410]
loss: 0.028075  [ 2200/ 3410]
loss: 0.002333  [ 2300/ 3410]
loss: 0.002199  [ 2400/ 3410]
loss: 0.115813  [ 2500/ 3410]
loss: 0.008342  [ 2600/ 3410]
loss: 0.003892  [ 2700/ 3410]
loss: 0.000781  [ 2800/ 3410]
loss: 0.006547  [ 2900/ 3410]
loss: 0.002499  [ 3000/ 3410]
loss: 0.000927  [ 3100/ 3410]
loss: 0.002798  [ 3200/ 3410]
loss: 0.001506  [ 3300/ 3410]
loss: 0.001308  [ 3400/ 3410]
Epoch 6
-------------------------------
loss: 0.000338  [    0/ 3410]
loss: 0.002791  [  100/ 3410]
loss: 0.004887  [  200/ 3410]
loss: 0.004016  [  300/ 3410]
loss: 0.001884  [  400/ 3410]
loss: 0.003931  [  500/ 3410]
loss: 0.000986  [  600/ 3410]
loss: 0.004173  [  700/ 3410]
loss: 0.003672  [  800/ 3410]
loss: 0.002400  [  900/ 3410]
loss: 0.006120  [ 1000/ 3410]
loss: 0.002916  [ 1100/ 3410]
loss: 0.002078  [ 1200/ 3410]
loss: 0.005321  [ 1300/ 3410]
loss: 0.001148  [ 1400/ 3410]
loss: 0.001614  [ 1500/ 3410]
loss: 0.001526  [ 1600/ 3410]
loss: 0.004889  [ 1700/ 3410]
loss: 0.004800  [ 1800/ 3410]
loss: 0.000845  [ 1900/ 3410]
loss: 0.027005  [ 2000/ 3410]
loss: 0.002914  [ 2100/ 3410]
loss: 0.028129  [ 2200/ 3410]
loss: 0.002395  [ 2300/ 3410]
loss: 0.002260  [ 2400/ 3410]
loss: 0.114940  [ 2500/ 3410]
loss: 0.007696  [ 2600/ 3410]
loss: 0.003904  [ 2700/ 3410]
loss: 0.000711  [ 2800/ 3410]
loss: 0.006408  [ 2900/ 3410]
loss: 0.002600  [ 3000/ 3410]
loss: 0.000928  [ 3100/ 3410]
loss: 0.002496  [ 3200/ 3410]
loss: 0.001491  [ 3300/ 3410]
loss: 0.001138  [ 3400/ 3410]
Epoch 7
-------------------------------
loss: 0.000322  [    0/ 3410]
loss: 0.002853  [  100/ 3410]
loss: 0.004805  [  200/ 3410]
loss: 0.003907  [  300/ 3410]
loss: 0.001855  [  400/ 3410]
loss: 0.002354  [  500/ 3410]
loss: 0.001148  [  600/ 3410]
loss: 0.004035  [  700/ 3410]
loss: 0.004027  [  800/ 3410]
loss: 0.002466  [  900/ 3410]
loss: 0.005626  [ 1000/ 3410]
loss: 0.003020  [ 1100/ 3410]
loss: 0.001905  [ 1200/ 3410]
loss: 0.005288  [ 1300/ 3410]
loss: 0.001151  [ 1400/ 3410]
loss: 0.001562  [ 1500/ 3410]
loss: 0.001624  [ 1600/ 3410]
loss: 0.004771  [ 1700/ 3410]
loss: 0.004758  [ 1800/ 3410]
loss: 0.000852  [ 1900/ 3410]
loss: 0.026141  [ 2000/ 3410]
loss: 0.002902  [ 2100/ 3410]
loss: 0.027905  [ 2200/ 3410]
loss: 0.002532  [ 2300/ 3410]
loss: 0.002361  [ 2400/ 3410]
loss: 0.113727  [ 2500/ 3410]
loss: 0.007079  [ 2600/ 3410]
loss: 0.003954  [ 2700/ 3410]
loss: 0.000675  [ 2800/ 3410]
loss: 0.006193  [ 2900/ 3410]
loss: 0.002698  [ 3000/ 3410]
loss: 0.000923  [ 3100/ 3410]
loss: 0.002477  [ 3200/ 3410]
loss: 0.001506  [ 3300/ 3410]
loss: 0.001210  [ 3400/ 3410]
Epoch 8
-------------------------------
loss: 0.000332  [    0/ 3410]
loss: 0.002951  [  100/ 3410]
loss: 0.004671  [  200/ 3410]
loss: 0.003722  [  300/ 3410]
loss: 0.001820  [  400/ 3410]
loss: 0.002444  [  500/ 3410]
loss: 0.001172  [  600/ 3410]
loss: 0.003961  [  700/ 3410]
loss: 0.003944  [  800/ 3410]
loss: 0.002532  [  900/ 3410]
loss: 0.005309  [ 1000/ 3410]
loss: 0.002989  [ 1100/ 3410]
loss: 0.001949  [ 1200/ 3410]
loss: 0.005367  [ 1300/ 3410]
loss: 0.001103  [ 1400/ 3410]
loss: 0.001462  [ 1500/ 3410]
loss: 0.001680  [ 1600/ 3410]
loss: 0.004593  [ 1700/ 3410]
loss: 0.004791  [ 1800/ 3410]
loss: 0.000848  [ 1900/ 3410]
loss: 0.025582  [ 2000/ 3410]
loss: 0.002839  [ 2100/ 3410]
loss: 0.027886  [ 2200/ 3410]
loss: 0.002497  [ 2300/ 3410]
loss: 0.002562  [ 2400/ 3410]
loss: 0.112236  [ 2500/ 3410]
loss: 0.007090  [ 2600/ 3410]
loss: 0.004004  [ 2700/ 3410]
loss: 0.000607  [ 2800/ 3410]
loss: 0.006005  [ 2900/ 3410]
loss: 0.002807  [ 3000/ 3410]
loss: 0.000922  [ 3100/ 3410]
loss: 0.002400  [ 3200/ 3410]
loss: 0.001490  [ 3300/ 3410]
loss: 0.001150  [ 3400/ 3410]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3410
First Spike after testing: [ 0.17829558 -0.6952753 ]
[2 2 2 ... 2 0 2]
[0 0 0 ... 0 2 0]
Cluster 0 Occurrences: 1130; KMEANS: 1159
Cluster 1 Occurrences: 1113; KMEANS: 1092
Cluster 2 Occurrences: 1167; KMEANS: 1159
Centroids: [[0.086238705, 1.7767198], [-0.7816968, 0.9026409], [0.21792583, -0.6299514]]
Centroids: [[0.21987322, -0.6370156], [-0.8282824, 0.8630054], [0.11336669, 1.7886786]]
Contingency Matrix: 
[[   0   15 1115]
 [   1 1072   40]
 [1158    5    4]]
[[-1, 15, 1115], [-1, 1072, 40], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1072, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1115   15    0]
 [  40 1072    1]
 [   4    5 1158]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1115, 1072, 1158], Sum: 3345
All_Elements: [1115, 15, 0, 40, 1072, 1, 4, 5, 1158], Sum: 3410
Accuracy: 0.9809384164222874
Done!
