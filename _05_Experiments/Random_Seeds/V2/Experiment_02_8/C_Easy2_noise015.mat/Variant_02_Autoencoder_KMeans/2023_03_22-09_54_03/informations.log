Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_54_03
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028B9864E278>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x0000028B854745F8>
Epoch 1
-------------------------------
loss: 0.258336  [    0/ 3411]
loss: 0.116666  [  100/ 3411]
loss: 0.150516  [  200/ 3411]
loss: 0.017291  [  300/ 3411]
loss: 0.042312  [  400/ 3411]
loss: 0.025255  [  500/ 3411]
loss: 0.012868  [  600/ 3411]
loss: 0.028761  [  700/ 3411]
loss: 0.029098  [  800/ 3411]
loss: 0.037089  [  900/ 3411]
loss: 0.003539  [ 1000/ 3411]
loss: 0.055429  [ 1100/ 3411]
loss: 0.018521  [ 1200/ 3411]
loss: 0.021926  [ 1300/ 3411]
loss: 0.015830  [ 1400/ 3411]
loss: 0.061231  [ 1500/ 3411]
loss: 0.039755  [ 1600/ 3411]
loss: 0.037076  [ 1700/ 3411]
loss: 0.019890  [ 1800/ 3411]
loss: 0.005571  [ 1900/ 3411]
loss: 0.031099  [ 2000/ 3411]
loss: 0.010298  [ 2100/ 3411]
loss: 0.007886  [ 2200/ 3411]
loss: 0.161047  [ 2300/ 3411]
loss: 0.014769  [ 2400/ 3411]
loss: 0.012251  [ 2500/ 3411]
loss: 0.018625  [ 2600/ 3411]
loss: 0.009557  [ 2700/ 3411]
loss: 0.035684  [ 2800/ 3411]
loss: 0.011247  [ 2900/ 3411]
loss: 0.010734  [ 3000/ 3411]
loss: 0.005226  [ 3100/ 3411]
loss: 0.027935  [ 3200/ 3411]
loss: 0.019208  [ 3300/ 3411]
loss: 0.008507  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.020464  [    0/ 3411]
loss: 0.013830  [  100/ 3411]
loss: 0.013327  [  200/ 3411]
loss: 0.014965  [  300/ 3411]
loss: 0.040770  [  400/ 3411]
loss: 0.010603  [  500/ 3411]
loss: 0.005306  [  600/ 3411]
loss: 0.025415  [  700/ 3411]
loss: 0.021378  [  800/ 3411]
loss: 0.020858  [  900/ 3411]
loss: 0.003537  [ 1000/ 3411]
loss: 0.020785  [ 1100/ 3411]
loss: 0.019111  [ 1200/ 3411]
loss: 0.016552  [ 1300/ 3411]
loss: 0.014231  [ 1400/ 3411]
loss: 0.059727  [ 1500/ 3411]
loss: 0.031933  [ 1600/ 3411]
loss: 0.017797  [ 1700/ 3411]
loss: 0.020296  [ 1800/ 3411]
loss: 0.005209  [ 1900/ 3411]
loss: 0.029630  [ 2000/ 3411]
loss: 0.008202  [ 2100/ 3411]
loss: 0.007323  [ 2200/ 3411]
loss: 0.160832  [ 2300/ 3411]
loss: 0.015540  [ 2400/ 3411]
loss: 0.008777  [ 2500/ 3411]
loss: 0.016244  [ 2600/ 3411]
loss: 0.008105  [ 2700/ 3411]
loss: 0.031518  [ 2800/ 3411]
loss: 0.010382  [ 2900/ 3411]
loss: 0.008123  [ 3000/ 3411]
loss: 0.005536  [ 3100/ 3411]
loss: 0.025736  [ 3200/ 3411]
loss: 0.016551  [ 3300/ 3411]
loss: 0.009484  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.018792  [    0/ 3411]
loss: 0.013798  [  100/ 3411]
loss: 0.011735  [  200/ 3411]
loss: 0.012896  [  300/ 3411]
loss: 0.040703  [  400/ 3411]
loss: 0.011012  [  500/ 3411]
loss: 0.005354  [  600/ 3411]
loss: 0.020355  [  700/ 3411]
loss: 0.022532  [  800/ 3411]
loss: 0.018742  [  900/ 3411]
loss: 0.003440  [ 1000/ 3411]
loss: 0.015709  [ 1100/ 3411]
loss: 0.021264  [ 1200/ 3411]
loss: 0.015817  [ 1300/ 3411]
loss: 0.017443  [ 1400/ 3411]
loss: 0.062842  [ 1500/ 3411]
loss: 0.027133  [ 1600/ 3411]
loss: 0.014934  [ 1700/ 3411]
loss: 0.020725  [ 1800/ 3411]
loss: 0.004971  [ 1900/ 3411]
loss: 0.030153  [ 2000/ 3411]
loss: 0.008001  [ 2100/ 3411]
loss: 0.007842  [ 2200/ 3411]
loss: 0.151800  [ 2300/ 3411]
loss: 0.016734  [ 2400/ 3411]
loss: 0.009378  [ 2500/ 3411]
loss: 0.015218  [ 2600/ 3411]
loss: 0.007568  [ 2700/ 3411]
loss: 0.026958  [ 2800/ 3411]
loss: 0.011336  [ 2900/ 3411]
loss: 0.007196  [ 3000/ 3411]
loss: 0.005454  [ 3100/ 3411]
loss: 0.022883  [ 3200/ 3411]
loss: 0.013550  [ 3300/ 3411]
loss: 0.009945  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.017486  [    0/ 3411]
loss: 0.013479  [  100/ 3411]
loss: 0.011000  [  200/ 3411]
loss: 0.012964  [  300/ 3411]
loss: 0.038569  [  400/ 3411]
loss: 0.011106  [  500/ 3411]
loss: 0.005022  [  600/ 3411]
loss: 0.017955  [  700/ 3411]
loss: 0.022522  [  800/ 3411]
loss: 0.017573  [  900/ 3411]
loss: 0.003424  [ 1000/ 3411]
loss: 0.013973  [ 1100/ 3411]
loss: 0.022117  [ 1200/ 3411]
loss: 0.013949  [ 1300/ 3411]
loss: 0.018066  [ 1400/ 3411]
loss: 0.064392  [ 1500/ 3411]
loss: 0.024504  [ 1600/ 3411]
loss: 0.014759  [ 1700/ 3411]
loss: 0.020765  [ 1800/ 3411]
loss: 0.004918  [ 1900/ 3411]
loss: 0.030629  [ 2000/ 3411]
loss: 0.008004  [ 2100/ 3411]
loss: 0.008090  [ 2200/ 3411]
loss: 0.150233  [ 2300/ 3411]
loss: 0.016986  [ 2400/ 3411]
loss: 0.009205  [ 2500/ 3411]
loss: 0.014632  [ 2600/ 3411]
loss: 0.007568  [ 2700/ 3411]
loss: 0.025389  [ 2800/ 3411]
loss: 0.011914  [ 2900/ 3411]
loss: 0.007352  [ 3000/ 3411]
loss: 0.005414  [ 3100/ 3411]
loss: 0.022202  [ 3200/ 3411]
loss: 0.012580  [ 3300/ 3411]
loss: 0.010206  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.018568  [    0/ 3411]
loss: 0.013341  [  100/ 3411]
loss: 0.010905  [  200/ 3411]
loss: 0.013128  [  300/ 3411]
loss: 0.036676  [  400/ 3411]
loss: 0.011082  [  500/ 3411]
loss: 0.004743  [  600/ 3411]
loss: 0.016523  [  700/ 3411]
loss: 0.022550  [  800/ 3411]
loss: 0.017197  [  900/ 3411]
loss: 0.003505  [ 1000/ 3411]
loss: 0.012088  [ 1100/ 3411]
loss: 0.021860  [ 1200/ 3411]
loss: 0.013404  [ 1300/ 3411]
loss: 0.018325  [ 1400/ 3411]
loss: 0.063613  [ 1500/ 3411]
loss: 0.022441  [ 1600/ 3411]
loss: 0.014709  [ 1700/ 3411]
loss: 0.020875  [ 1800/ 3411]
loss: 0.004916  [ 1900/ 3411]
loss: 0.031098  [ 2000/ 3411]
loss: 0.008392  [ 2100/ 3411]
loss: 0.008086  [ 2200/ 3411]
loss: 0.150522  [ 2300/ 3411]
loss: 0.017242  [ 2400/ 3411]
loss: 0.008922  [ 2500/ 3411]
loss: 0.013826  [ 2600/ 3411]
loss: 0.007404  [ 2700/ 3411]
loss: 0.025061  [ 2800/ 3411]
loss: 0.011680  [ 2900/ 3411]
loss: 0.008692  [ 3000/ 3411]
loss: 0.005350  [ 3100/ 3411]
loss: 0.022131  [ 3200/ 3411]
loss: 0.012301  [ 3300/ 3411]
loss: 0.009931  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.019560  [    0/ 3411]
loss: 0.013296  [  100/ 3411]
loss: 0.010919  [  200/ 3411]
loss: 0.013142  [  300/ 3411]
loss: 0.035529  [  400/ 3411]
loss: 0.011086  [  500/ 3411]
loss: 0.004507  [  600/ 3411]
loss: 0.014511  [  700/ 3411]
loss: 0.022447  [  800/ 3411]
loss: 0.017132  [  900/ 3411]
loss: 0.003644  [ 1000/ 3411]
loss: 0.009154  [ 1100/ 3411]
loss: 0.021810  [ 1200/ 3411]
loss: 0.013205  [ 1300/ 3411]
loss: 0.018698  [ 1400/ 3411]
loss: 0.063464  [ 1500/ 3411]
loss: 0.021406  [ 1600/ 3411]
loss: 0.014482  [ 1700/ 3411]
loss: 0.020545  [ 1800/ 3411]
loss: 0.005004  [ 1900/ 3411]
loss: 0.031437  [ 2000/ 3411]
loss: 0.008418  [ 2100/ 3411]
loss: 0.008045  [ 2200/ 3411]
loss: 0.151065  [ 2300/ 3411]
loss: 0.017353  [ 2400/ 3411]
loss: 0.008818  [ 2500/ 3411]
loss: 0.013744  [ 2600/ 3411]
loss: 0.007374  [ 2700/ 3411]
loss: 0.025100  [ 2800/ 3411]
loss: 0.011428  [ 2900/ 3411]
loss: 0.007567  [ 3000/ 3411]
loss: 0.005383  [ 3100/ 3411]
loss: 0.021938  [ 3200/ 3411]
loss: 0.012273  [ 3300/ 3411]
loss: 0.009437  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.018963  [    0/ 3411]
loss: 0.013311  [  100/ 3411]
loss: 0.010987  [  200/ 3411]
loss: 0.013108  [  300/ 3411]
loss: 0.034581  [  400/ 3411]
loss: 0.010796  [  500/ 3411]
loss: 0.004383  [  600/ 3411]
loss: 0.011727  [  700/ 3411]
loss: 0.022188  [  800/ 3411]
loss: 0.017300  [  900/ 3411]
loss: 0.003755  [ 1000/ 3411]
loss: 0.007102  [ 1100/ 3411]
loss: 0.021603  [ 1200/ 3411]
loss: 0.013243  [ 1300/ 3411]
loss: 0.018848  [ 1400/ 3411]
loss: 0.063895  [ 1500/ 3411]
loss: 0.021016  [ 1600/ 3411]
loss: 0.013919  [ 1700/ 3411]
loss: 0.020052  [ 1800/ 3411]
loss: 0.004946  [ 1900/ 3411]
loss: 0.031768  [ 2000/ 3411]
loss: 0.008388  [ 2100/ 3411]
loss: 0.007909  [ 2200/ 3411]
loss: 0.151739  [ 2300/ 3411]
loss: 0.017546  [ 2400/ 3411]
loss: 0.008448  [ 2500/ 3411]
loss: 0.010730  [ 2600/ 3411]
loss: 0.007280  [ 2700/ 3411]
loss: 0.025241  [ 2800/ 3411]
loss: 0.011857  [ 2900/ 3411]
loss: 0.009706  [ 3000/ 3411]
loss: 0.005415  [ 3100/ 3411]
loss: 0.022117  [ 3200/ 3411]
loss: 0.012252  [ 3300/ 3411]
loss: 0.008425  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.019169  [    0/ 3411]
loss: 0.013320  [  100/ 3411]
loss: 0.012529  [  200/ 3411]
loss: 0.013101  [  300/ 3411]
loss: 0.033758  [  400/ 3411]
loss: 0.010670  [  500/ 3411]
loss: 0.003837  [  600/ 3411]
loss: 0.007616  [  700/ 3411]
loss: 0.022064  [  800/ 3411]
loss: 0.017733  [  900/ 3411]
loss: 0.004376  [ 1000/ 3411]
loss: 0.008398  [ 1100/ 3411]
loss: 0.021445  [ 1200/ 3411]
loss: 0.013328  [ 1300/ 3411]
loss: 0.019203  [ 1400/ 3411]
loss: 0.065856  [ 1500/ 3411]
loss: 0.020501  [ 1600/ 3411]
loss: 0.013778  [ 1700/ 3411]
loss: 0.018033  [ 1800/ 3411]
loss: 0.005288  [ 1900/ 3411]
loss: 0.032113  [ 2000/ 3411]
loss: 0.008714  [ 2100/ 3411]
loss: 0.007757  [ 2200/ 3411]
loss: 0.153319  [ 2300/ 3411]
loss: 0.017801  [ 2400/ 3411]
loss: 0.007463  [ 2500/ 3411]
loss: 0.008206  [ 2600/ 3411]
loss: 0.007273  [ 2700/ 3411]
loss: 0.025685  [ 2800/ 3411]
loss: 0.010696  [ 2900/ 3411]
loss: 0.011636  [ 3000/ 3411]
loss: 0.005422  [ 3100/ 3411]
loss: 0.022231  [ 3200/ 3411]
loss: 0.012518  [ 3300/ 3411]
loss: 0.009180  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [0.49452016 1.674881  ]
[0 2 0 ... 1 1 2]
[0 1 2 ... 2 2 1]
Cluster 0 Occurrences: 1181; KMEANS: 1183
Cluster 1 Occurrences: 1098; KMEANS: 1113
Cluster 2 Occurrences: 1132; KMEANS: 1115
Centroids: [[0.6934082, 1.5890845], [-0.042286273, 0.7982248], [-0.20261127, -1.2942027]]
Centroids: [[0.76059735, 1.6103866], [-0.20185322, -1.331342], [-0.118381366, 0.77562183]]
Contingency Matrix: 
[[1078    0  103]
 [ 100    0  998]
 [   5 1113   14]]
[[1078, -1, 103], [100, -1, 998], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 998], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 0, 1: 2}
New Contingency Matrix: 
[[1078  103    0]
 [ 100  998    0]
 [   5   14 1113]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [1078, 998, 1113], Sum: 3189
All_Elements: [1078, 103, 0, 100, 998, 0, 5, 14, 1113], Sum: 3411
Accuracy: 0.9349164467897977
Done!
