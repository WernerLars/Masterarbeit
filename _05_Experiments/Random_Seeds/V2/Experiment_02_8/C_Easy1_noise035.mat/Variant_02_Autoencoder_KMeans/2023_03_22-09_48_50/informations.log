Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Easy1_noise035.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_48_50
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028B85314908>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
<torch.utils.data.dataloader.DataLoader object at 0x0000028B85474198>
Epoch 1
-------------------------------
loss: 0.230521  [    0/ 3534]
loss: 0.322533  [  100/ 3534]
loss: 0.238544  [  200/ 3534]
loss: 0.324773  [  300/ 3534]
loss: 0.140791  [  400/ 3534]
loss: 0.115526  [  500/ 3534]
loss: 0.057136  [  600/ 3534]
loss: 0.082669  [  700/ 3534]
loss: 0.066508  [  800/ 3534]
loss: 0.049223  [  900/ 3534]
loss: 0.069026  [ 1000/ 3534]
loss: 0.029930  [ 1100/ 3534]
loss: 0.084431  [ 1200/ 3534]
loss: 0.111596  [ 1300/ 3534]
loss: 0.042424  [ 1400/ 3534]
loss: 0.145733  [ 1500/ 3534]
loss: 0.152040  [ 1600/ 3534]
loss: 0.048754  [ 1700/ 3534]
loss: 0.311883  [ 1800/ 3534]
loss: 0.056499  [ 1900/ 3534]
loss: 0.048347  [ 2000/ 3534]
loss: 0.032018  [ 2100/ 3534]
loss: 0.027175  [ 2200/ 3534]
loss: 0.133250  [ 2300/ 3534]
loss: 0.084222  [ 2400/ 3534]
loss: 0.090615  [ 2500/ 3534]
loss: 0.078997  [ 2600/ 3534]
loss: 0.030291  [ 2700/ 3534]
loss: 0.176095  [ 2800/ 3534]
loss: 0.141551  [ 2900/ 3534]
loss: 0.230666  [ 3000/ 3534]
loss: 0.065497  [ 3100/ 3534]
loss: 0.129644  [ 3200/ 3534]
loss: 0.035428  [ 3300/ 3534]
loss: 0.072058  [ 3400/ 3534]
loss: 0.075624  [ 3500/ 3534]
Epoch 2
-------------------------------
loss: 0.128744  [    0/ 3534]
loss: 0.048827  [  100/ 3534]
loss: 0.031530  [  200/ 3534]
loss: 0.124477  [  300/ 3534]
loss: 0.140798  [  400/ 3534]
loss: 0.046407  [  500/ 3534]
loss: 0.056032  [  600/ 3534]
loss: 0.061911  [  700/ 3534]
loss: 0.037983  [  800/ 3534]
loss: 0.034708  [  900/ 3534]
loss: 0.020362  [ 1000/ 3534]
loss: 0.022207  [ 1100/ 3534]
loss: 0.032277  [ 1200/ 3534]
loss: 0.066122  [ 1300/ 3534]
loss: 0.023026  [ 1400/ 3534]
loss: 0.063183  [ 1500/ 3534]
loss: 0.134642  [ 1600/ 3534]
loss: 0.058642  [ 1700/ 3534]
loss: 0.098518  [ 1800/ 3534]
loss: 0.027193  [ 1900/ 3534]
loss: 0.030767  [ 2000/ 3534]
loss: 0.032228  [ 2100/ 3534]
loss: 0.034216  [ 2200/ 3534]
loss: 0.128622  [ 2300/ 3534]
loss: 0.062358  [ 2400/ 3534]
loss: 0.097020  [ 2500/ 3534]
loss: 0.052988  [ 2600/ 3534]
loss: 0.027764  [ 2700/ 3534]
loss: 0.129249  [ 2800/ 3534]
loss: 0.045338  [ 2900/ 3534]
loss: 0.219229  [ 3000/ 3534]
loss: 0.045390  [ 3100/ 3534]
loss: 0.127687  [ 3200/ 3534]
loss: 0.053270  [ 3300/ 3534]
loss: 0.042839  [ 3400/ 3534]
loss: 0.072272  [ 3500/ 3534]
Epoch 3
-------------------------------
loss: 0.124521  [    0/ 3534]
loss: 0.036178  [  100/ 3534]
loss: 0.027039  [  200/ 3534]
loss: 0.116467  [  300/ 3534]
loss: 0.195157  [  400/ 3534]
loss: 0.032652  [  500/ 3534]
loss: 0.063362  [  600/ 3534]
loss: 0.072987  [  700/ 3534]
loss: 0.033450  [  800/ 3534]
loss: 0.031830  [  900/ 3534]
loss: 0.037526  [ 1000/ 3534]
loss: 0.023799  [ 1100/ 3534]
loss: 0.023755  [ 1200/ 3534]
loss: 0.050474  [ 1300/ 3534]
loss: 0.022567  [ 1400/ 3534]
loss: 0.040706  [ 1500/ 3534]
loss: 0.133372  [ 1600/ 3534]
loss: 0.056359  [ 1700/ 3534]
loss: 0.058128  [ 1800/ 3534]
loss: 0.029593  [ 1900/ 3534]
loss: 0.030579  [ 2000/ 3534]
loss: 0.036696  [ 2100/ 3534]
loss: 0.035193  [ 2200/ 3534]
loss: 0.126817  [ 2300/ 3534]
loss: 0.057517  [ 2400/ 3534]
loss: 0.094227  [ 2500/ 3534]
loss: 0.045091  [ 2600/ 3534]
loss: 0.027950  [ 2700/ 3534]
loss: 0.107959  [ 2800/ 3534]
loss: 0.035596  [ 2900/ 3534]
loss: 0.222365  [ 3000/ 3534]
loss: 0.043467  [ 3100/ 3534]
loss: 0.126750  [ 3200/ 3534]
loss: 0.062495  [ 3300/ 3534]
loss: 0.040416  [ 3400/ 3534]
loss: 0.071215  [ 3500/ 3534]
Epoch 4
-------------------------------
loss: 0.123417  [    0/ 3534]
loss: 0.036096  [  100/ 3534]
loss: 0.026327  [  200/ 3534]
loss: 0.114388  [  300/ 3534]
loss: 0.202547  [  400/ 3534]
loss: 0.028417  [  500/ 3534]
loss: 0.061096  [  600/ 3534]
loss: 0.074515  [  700/ 3534]
loss: 0.033577  [  800/ 3534]
loss: 0.028442  [  900/ 3534]
loss: 0.039933  [ 1000/ 3534]
loss: 0.024044  [ 1100/ 3534]
loss: 0.021598  [ 1200/ 3534]
loss: 0.053423  [ 1300/ 3534]
loss: 0.022130  [ 1400/ 3534]
loss: 0.035501  [ 1500/ 3534]
loss: 0.133653  [ 1600/ 3534]
loss: 0.053243  [ 1700/ 3534]
loss: 0.056348  [ 1800/ 3534]
loss: 0.032107  [ 1900/ 3534]
loss: 0.029746  [ 2000/ 3534]
loss: 0.037085  [ 2100/ 3534]
loss: 0.034823  [ 2200/ 3534]
loss: 0.126426  [ 2300/ 3534]
loss: 0.056043  [ 2400/ 3534]
loss: 0.093564  [ 2500/ 3534]
loss: 0.040687  [ 2600/ 3534]
loss: 0.028101  [ 2700/ 3534]
loss: 0.090427  [ 2800/ 3534]
loss: 0.032230  [ 2900/ 3534]
loss: 0.215006  [ 3000/ 3534]
loss: 0.043656  [ 3100/ 3534]
loss: 0.126307  [ 3200/ 3534]
loss: 0.067194  [ 3300/ 3534]
loss: 0.039643  [ 3400/ 3534]
loss: 0.070682  [ 3500/ 3534]
Epoch 5
-------------------------------
loss: 0.123193  [    0/ 3534]
loss: 0.037400  [  100/ 3534]
loss: 0.027992  [  200/ 3534]
loss: 0.111954  [  300/ 3534]
loss: 0.199043  [  400/ 3534]
loss: 0.026882  [  500/ 3534]
loss: 0.056139  [  600/ 3534]
loss: 0.075541  [  700/ 3534]
loss: 0.033648  [  800/ 3534]
loss: 0.028267  [  900/ 3534]
loss: 0.037299  [ 1000/ 3534]
loss: 0.024291  [ 1100/ 3534]
loss: 0.023040  [ 1200/ 3534]
loss: 0.054612  [ 1300/ 3534]
loss: 0.021665  [ 1400/ 3534]
loss: 0.031565  [ 1500/ 3534]
loss: 0.134868  [ 1600/ 3534]
loss: 0.051678  [ 1700/ 3534]
loss: 0.056674  [ 1800/ 3534]
loss: 0.033988  [ 1900/ 3534]
loss: 0.029168  [ 2000/ 3534]
loss: 0.036933  [ 2100/ 3534]
loss: 0.034117  [ 2200/ 3534]
loss: 0.128591  [ 2300/ 3534]
loss: 0.055356  [ 2400/ 3534]
loss: 0.093637  [ 2500/ 3534]
loss: 0.039372  [ 2600/ 3534]
loss: 0.028149  [ 2700/ 3534]
loss: 0.074061  [ 2800/ 3534]
loss: 0.031245  [ 2900/ 3534]
loss: 0.197963  [ 3000/ 3534]
loss: 0.044770  [ 3100/ 3534]
loss: 0.126461  [ 3200/ 3534]
loss: 0.070922  [ 3300/ 3534]
loss: 0.039288  [ 3400/ 3534]
loss: 0.070905  [ 3500/ 3534]
Epoch 6
-------------------------------
loss: 0.122799  [    0/ 3534]
loss: 0.038886  [  100/ 3534]
loss: 0.031075  [  200/ 3534]
loss: 0.110033  [  300/ 3534]
loss: 0.191590  [  400/ 3534]
loss: 0.025674  [  500/ 3534]
loss: 0.051798  [  600/ 3534]
loss: 0.075672  [  700/ 3534]
loss: 0.034107  [  800/ 3534]
loss: 0.028423  [  900/ 3534]
loss: 0.036316  [ 1000/ 3534]
loss: 0.024356  [ 1100/ 3534]
loss: 0.020162  [ 1200/ 3534]
loss: 0.055286  [ 1300/ 3534]
loss: 0.020729  [ 1400/ 3534]
loss: 0.028915  [ 1500/ 3534]
loss: 0.137702  [ 1600/ 3534]
loss: 0.050953  [ 1700/ 3534]
loss: 0.055692  [ 1800/ 3534]
loss: 0.034008  [ 1900/ 3534]
loss: 0.028372  [ 2000/ 3534]
loss: 0.037014  [ 2100/ 3534]
loss: 0.032524  [ 2200/ 3534]
loss: 0.127882  [ 2300/ 3534]
loss: 0.055819  [ 2400/ 3534]
loss: 0.095841  [ 2500/ 3534]
loss: 0.039195  [ 2600/ 3534]
loss: 0.028172  [ 2700/ 3534]
loss: 0.061920  [ 2800/ 3534]
loss: 0.032826  [ 2900/ 3534]
loss: 0.177137  [ 3000/ 3534]
loss: 0.045018  [ 3100/ 3534]
loss: 0.128038  [ 3200/ 3534]
loss: 0.079709  [ 3300/ 3534]
loss: 0.039064  [ 3400/ 3534]
loss: 0.071499  [ 3500/ 3534]
Epoch 7
-------------------------------
loss: 0.122129  [    0/ 3534]
loss: 0.056618  [  100/ 3534]
loss: 0.024816  [  200/ 3534]
loss: 0.107980  [  300/ 3534]
loss: 0.182909  [  400/ 3534]
loss: 0.024260  [  500/ 3534]
loss: 0.047586  [  600/ 3534]
loss: 0.075408  [  700/ 3534]
loss: 0.035234  [  800/ 3534]
loss: 0.028483  [  900/ 3534]
loss: 0.038881  [ 1000/ 3534]
loss: 0.024104  [ 1100/ 3534]
loss: 0.020450  [ 1200/ 3534]
loss: 0.057990  [ 1300/ 3534]
loss: 0.019334  [ 1400/ 3534]
loss: 0.027974  [ 1500/ 3534]
loss: 0.143093  [ 1600/ 3534]
loss: 0.050961  [ 1700/ 3534]
loss: 0.053293  [ 1800/ 3534]
loss: 0.030559  [ 1900/ 3534]
loss: 0.028221  [ 2000/ 3534]
loss: 0.037196  [ 2100/ 3534]
loss: 0.031336  [ 2200/ 3534]
loss: 0.128246  [ 2300/ 3534]
loss: 0.054844  [ 2400/ 3534]
loss: 0.095741  [ 2500/ 3534]
loss: 0.038643  [ 2600/ 3534]
loss: 0.028527  [ 2700/ 3534]
loss: 0.040844  [ 2800/ 3534]
loss: 0.032576  [ 2900/ 3534]
loss: 0.159882  [ 3000/ 3534]
loss: 0.046155  [ 3100/ 3534]
loss: 0.129757  [ 3200/ 3534]
loss: 0.078826  [ 3300/ 3534]
loss: 0.038886  [ 3400/ 3534]
loss: 0.071284  [ 3500/ 3534]
Epoch 8
-------------------------------
loss: 0.121165  [    0/ 3534]
loss: 0.065450  [  100/ 3534]
loss: 0.023617  [  200/ 3534]
loss: 0.106922  [  300/ 3534]
loss: 0.185920  [  400/ 3534]
loss: 0.023111  [  500/ 3534]
loss: 0.040728  [  600/ 3534]
loss: 0.075004  [  700/ 3534]
loss: 0.035845  [  800/ 3534]
loss: 0.029680  [  900/ 3534]
loss: 0.039025  [ 1000/ 3534]
loss: 0.024620  [ 1100/ 3534]
loss: 0.020230  [ 1200/ 3534]
loss: 0.058618  [ 1300/ 3534]
loss: 0.017613  [ 1400/ 3534]
loss: 0.028249  [ 1500/ 3534]
loss: 0.147967  [ 1600/ 3534]
loss: 0.051168  [ 1700/ 3534]
loss: 0.051330  [ 1800/ 3534]
loss: 0.030200  [ 1900/ 3534]
loss: 0.027523  [ 2000/ 3534]
loss: 0.037337  [ 2100/ 3534]
loss: 0.030296  [ 2200/ 3534]
loss: 0.128936  [ 2300/ 3534]
loss: 0.054140  [ 2400/ 3534]
loss: 0.096146  [ 2500/ 3534]
loss: 0.041757  [ 2600/ 3534]
loss: 0.028717  [ 2700/ 3534]
loss: 0.029975  [ 2800/ 3534]
loss: 0.031163  [ 2900/ 3534]
loss: 0.153924  [ 3000/ 3534]
loss: 0.047020  [ 3100/ 3534]
loss: 0.128862  [ 3200/ 3534]
loss: 0.077914  [ 3300/ 3534]
loss: 0.038816  [ 3400/ 3534]
loss: 0.071019  [ 3500/ 3534]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3534
First Spike after testing: [-0.06130934 -0.46659067]
[0 1 2 ... 2 2 1]
[1 2 1 ... 1 1 0]
Cluster 0 Occurrences: 1208; KMEANS: 647
Cluster 1 Occurrences: 1137; KMEANS: 2380
Cluster 2 Occurrences: 1189; KMEANS: 507
Centroids: [[0.019938989, -0.3847464], [1.7494849, 4.7216763], [-1.3015193, -0.096644714]]
Centroids: [[1.3588629, 3.6944377], [-0.646687, -0.27365068], [2.220266, 6.015481]]
Contingency Matrix: 
[[   1 1207    0]
 [ 618   12  507]
 [  28 1161    0]]
[[-1, -1, -1], [618, -1, 507], [28, -1, 0]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 0]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 1, 1: 0, 2: 2}
New Contingency Matrix: 
[[1207    1    0]
 [  12  618  507]
 [1161   28    0]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [1207, 618, 0], Sum: 1825
All_Elements: [1207, 1, 0, 12, 618, 507, 1161, 28, 0], Sum: 3534
Accuracy: 0.5164119977362762
Done!
