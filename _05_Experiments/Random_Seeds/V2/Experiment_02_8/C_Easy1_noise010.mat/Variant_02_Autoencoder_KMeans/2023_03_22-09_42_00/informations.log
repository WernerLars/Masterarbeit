Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Easy1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_42_00
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028B8542C940>
Sampling rate: 24000.0
Raw: [ 0.01223885  0.0148803   0.02156532 ... -0.02666729 -0.01215068
  0.01031338]
Times: [   1012    1333    1523 ... 1438660 1438690 1439287]
Cluster: [1 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3522
First aligned Spike Frame: [-0.12579972 -0.1620207  -0.18573939 -0.18961714 -0.17315203 -0.1396561
 -0.09426159 -0.04496221  0.00734136  0.05943689  0.09448878  0.07601101
  0.00811529  0.09446653  0.55421698  1.03008495  0.90195967  0.23116337
 -0.37857386 -0.59030761 -0.52695739 -0.40967661 -0.32471334 -0.26000903
 -0.19839489 -0.13975054 -0.09692457 -0.08223204 -0.09147337 -0.10695261
 -0.11338461 -0.10883018 -0.09915766 -0.08637804 -0.06514771 -0.03537735
 -0.00695045  0.01307529  0.02539335  0.03607991  0.04814655  0.05257424
  0.04538721  0.03512231  0.03354714  0.04141478  0.0511991 ]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1134
Cluster 2, Occurrences: 1237
<torch.utils.data.dataloader.DataLoader object at 0x0000028B85474F98>
Epoch 1
-------------------------------
loss: 0.123913  [    0/ 3522]
loss: 0.269214  [  100/ 3522]
loss: 0.086745  [  200/ 3522]
loss: 0.055985  [  300/ 3522]
loss: 0.018970  [  400/ 3522]
loss: 0.010460  [  500/ 3522]
loss: 0.110162  [  600/ 3522]
loss: 0.022425  [  700/ 3522]
loss: 0.016724  [  800/ 3522]
loss: 0.007322  [  900/ 3522]
loss: 0.005110  [ 1000/ 3522]
loss: 0.005001  [ 1100/ 3522]
loss: 0.089583  [ 1200/ 3522]
loss: 0.017352  [ 1300/ 3522]
loss: 0.002770  [ 1400/ 3522]
loss: 0.003826  [ 1500/ 3522]
loss: 0.009624  [ 1600/ 3522]
loss: 0.008062  [ 1700/ 3522]
loss: 0.010678  [ 1800/ 3522]
loss: 0.014340  [ 1900/ 3522]
loss: 0.011561  [ 2000/ 3522]
loss: 0.013291  [ 2100/ 3522]
loss: 0.004204  [ 2200/ 3522]
loss: 0.006310  [ 2300/ 3522]
loss: 0.004736  [ 2400/ 3522]
loss: 0.004854  [ 2500/ 3522]
loss: 0.066076  [ 2600/ 3522]
loss: 0.009593  [ 2700/ 3522]
loss: 0.002887  [ 2800/ 3522]
loss: 0.004619  [ 2900/ 3522]
loss: 0.007699  [ 3000/ 3522]
loss: 0.007935  [ 3100/ 3522]
loss: 0.014680  [ 3200/ 3522]
loss: 0.008467  [ 3300/ 3522]
loss: 0.011646  [ 3400/ 3522]
loss: 0.006996  [ 3500/ 3522]
Epoch 2
-------------------------------
loss: 0.011049  [    0/ 3522]
loss: 0.008363  [  100/ 3522]
loss: 0.004517  [  200/ 3522]
loss: 0.048579  [  300/ 3522]
loss: 0.008308  [  400/ 3522]
loss: 0.009578  [  500/ 3522]
loss: 0.109975  [  600/ 3522]
loss: 0.014671  [  700/ 3522]
loss: 0.011577  [  800/ 3522]
loss: 0.006314  [  900/ 3522]
loss: 0.004235  [ 1000/ 3522]
loss: 0.004172  [ 1100/ 3522]
loss: 0.090625  [ 1200/ 3522]
loss: 0.017043  [ 1300/ 3522]
loss: 0.002863  [ 1400/ 3522]
loss: 0.003219  [ 1500/ 3522]
loss: 0.011024  [ 1600/ 3522]
loss: 0.007320  [ 1700/ 3522]
loss: 0.011294  [ 1800/ 3522]
loss: 0.012714  [ 1900/ 3522]
loss: 0.010780  [ 2000/ 3522]
loss: 0.009907  [ 2100/ 3522]
loss: 0.003964  [ 2200/ 3522]
loss: 0.006034  [ 2300/ 3522]
loss: 0.003941  [ 2400/ 3522]
loss: 0.004470  [ 2500/ 3522]
loss: 0.074565  [ 2600/ 3522]
loss: 0.007733  [ 2700/ 3522]
loss: 0.003108  [ 2800/ 3522]
loss: 0.004842  [ 2900/ 3522]
loss: 0.009431  [ 3000/ 3522]
loss: 0.007451  [ 3100/ 3522]
loss: 0.014741  [ 3200/ 3522]
loss: 0.008958  [ 3300/ 3522]
loss: 0.011992  [ 3400/ 3522]
loss: 0.006883  [ 3500/ 3522]
Epoch 3
-------------------------------
loss: 0.010774  [    0/ 3522]
loss: 0.007558  [  100/ 3522]
loss: 0.004338  [  200/ 3522]
loss: 0.046261  [  300/ 3522]
loss: 0.008304  [  400/ 3522]
loss: 0.009407  [  500/ 3522]
loss: 0.110941  [  600/ 3522]
loss: 0.014095  [  700/ 3522]
loss: 0.009727  [  800/ 3522]
loss: 0.005915  [  900/ 3522]
loss: 0.003756  [ 1000/ 3522]
loss: 0.004076  [ 1100/ 3522]
loss: 0.093667  [ 1200/ 3522]
loss: 0.015558  [ 1300/ 3522]
loss: 0.003109  [ 1400/ 3522]
loss: 0.003029  [ 1500/ 3522]
loss: 0.010612  [ 1600/ 3522]
loss: 0.007229  [ 1700/ 3522]
loss: 0.012147  [ 1800/ 3522]
loss: 0.012471  [ 1900/ 3522]
loss: 0.010741  [ 2000/ 3522]
loss: 0.008709  [ 2100/ 3522]
loss: 0.004026  [ 2200/ 3522]
loss: 0.006141  [ 2300/ 3522]
loss: 0.003791  [ 2400/ 3522]
loss: 0.004562  [ 2500/ 3522]
loss: 0.073894  [ 2600/ 3522]
loss: 0.006344  [ 2700/ 3522]
loss: 0.003526  [ 2800/ 3522]
loss: 0.004724  [ 2900/ 3522]
loss: 0.009861  [ 3000/ 3522]
loss: 0.006629  [ 3100/ 3522]
loss: 0.014586  [ 3200/ 3522]
loss: 0.009072  [ 3300/ 3522]
loss: 0.011380  [ 3400/ 3522]
loss: 0.006381  [ 3500/ 3522]
Epoch 4
-------------------------------
loss: 0.010771  [    0/ 3522]
loss: 0.006931  [  100/ 3522]
loss: 0.003973  [  200/ 3522]
loss: 0.045823  [  300/ 3522]
loss: 0.008189  [  400/ 3522]
loss: 0.009255  [  500/ 3522]
loss: 0.110998  [  600/ 3522]
loss: 0.013679  [  700/ 3522]
loss: 0.009043  [  800/ 3522]
loss: 0.005365  [  900/ 3522]
loss: 0.003489  [ 1000/ 3522]
loss: 0.003995  [ 1100/ 3522]
loss: 0.089655  [ 1200/ 3522]
loss: 0.014640  [ 1300/ 3522]
loss: 0.003299  [ 1400/ 3522]
loss: 0.002951  [ 1500/ 3522]
loss: 0.010402  [ 1600/ 3522]
loss: 0.007085  [ 1700/ 3522]
loss: 0.012382  [ 1800/ 3522]
loss: 0.012226  [ 1900/ 3522]
loss: 0.010963  [ 2000/ 3522]
loss: 0.007876  [ 2100/ 3522]
loss: 0.004081  [ 2200/ 3522]
loss: 0.006329  [ 2300/ 3522]
loss: 0.003737  [ 2400/ 3522]
loss: 0.004606  [ 2500/ 3522]
loss: 0.071520  [ 2600/ 3522]
loss: 0.005293  [ 2700/ 3522]
loss: 0.003684  [ 2800/ 3522]
loss: 0.004595  [ 2900/ 3522]
loss: 0.009957  [ 3000/ 3522]
loss: 0.005664  [ 3100/ 3522]
loss: 0.014468  [ 3200/ 3522]
loss: 0.009123  [ 3300/ 3522]
loss: 0.010802  [ 3400/ 3522]
loss: 0.006141  [ 3500/ 3522]
Epoch 5
-------------------------------
loss: 0.010816  [    0/ 3522]
loss: 0.006527  [  100/ 3522]
loss: 0.003844  [  200/ 3522]
loss: 0.044783  [  300/ 3522]
loss: 0.007757  [  400/ 3522]
loss: 0.009145  [  500/ 3522]
loss: 0.112220  [  600/ 3522]
loss: 0.013259  [  700/ 3522]
loss: 0.008345  [  800/ 3522]
loss: 0.004926  [  900/ 3522]
loss: 0.003317  [ 1000/ 3522]
loss: 0.003958  [ 1100/ 3522]
loss: 0.089785  [ 1200/ 3522]
loss: 0.014184  [ 1300/ 3522]
loss: 0.003544  [ 1400/ 3522]
loss: 0.002830  [ 1500/ 3522]
loss: 0.010281  [ 1600/ 3522]
loss: 0.006684  [ 1700/ 3522]
loss: 0.012432  [ 1800/ 3522]
loss: 0.011528  [ 1900/ 3522]
loss: 0.011209  [ 2000/ 3522]
loss: 0.007565  [ 2100/ 3522]
loss: 0.004110  [ 2200/ 3522]
loss: 0.006199  [ 2300/ 3522]
loss: 0.003521  [ 2400/ 3522]
loss: 0.004592  [ 2500/ 3522]
loss: 0.071103  [ 2600/ 3522]
loss: 0.004794  [ 2700/ 3522]
loss: 0.003897  [ 2800/ 3522]
loss: 0.004608  [ 2900/ 3522]
loss: 0.009942  [ 3000/ 3522]
loss: 0.005326  [ 3100/ 3522]
loss: 0.014519  [ 3200/ 3522]
loss: 0.009216  [ 3300/ 3522]
loss: 0.010135  [ 3400/ 3522]
loss: 0.006015  [ 3500/ 3522]
Epoch 6
-------------------------------
loss: 0.010853  [    0/ 3522]
loss: 0.006392  [  100/ 3522]
loss: 0.003764  [  200/ 3522]
loss: 0.043503  [  300/ 3522]
loss: 0.007697  [  400/ 3522]
loss: 0.009048  [  500/ 3522]
loss: 0.113626  [  600/ 3522]
loss: 0.012902  [  700/ 3522]
loss: 0.007859  [  800/ 3522]
loss: 0.004714  [  900/ 3522]
loss: 0.003215  [ 1000/ 3522]
loss: 0.003998  [ 1100/ 3522]
loss: 0.090872  [ 1200/ 3522]
loss: 0.014063  [ 1300/ 3522]
loss: 0.003671  [ 1400/ 3522]
loss: 0.002774  [ 1500/ 3522]
loss: 0.010241  [ 1600/ 3522]
loss: 0.006747  [ 1700/ 3522]
loss: 0.012821  [ 1800/ 3522]
loss: 0.011126  [ 1900/ 3522]
loss: 0.011427  [ 2000/ 3522]
loss: 0.007351  [ 2100/ 3522]
loss: 0.004154  [ 2200/ 3522]
loss: 0.005579  [ 2300/ 3522]
loss: 0.003549  [ 2400/ 3522]
loss: 0.004585  [ 2500/ 3522]
loss: 0.071154  [ 2600/ 3522]
loss: 0.005184  [ 2700/ 3522]
loss: 0.003990  [ 2800/ 3522]
loss: 0.004686  [ 2900/ 3522]
loss: 0.009753  [ 3000/ 3522]
loss: 0.004939  [ 3100/ 3522]
loss: 0.014024  [ 3200/ 3522]
loss: 0.009238  [ 3300/ 3522]
loss: 0.009807  [ 3400/ 3522]
loss: 0.005999  [ 3500/ 3522]
Epoch 7
-------------------------------
loss: 0.010767  [    0/ 3522]
loss: 0.006344  [  100/ 3522]
loss: 0.003760  [  200/ 3522]
loss: 0.045038  [  300/ 3522]
loss: 0.007507  [  400/ 3522]
loss: 0.009036  [  500/ 3522]
loss: 0.114564  [  600/ 3522]
loss: 0.012594  [  700/ 3522]
loss: 0.007474  [  800/ 3522]
loss: 0.004650  [  900/ 3522]
loss: 0.003219  [ 1000/ 3522]
loss: 0.003998  [ 1100/ 3522]
loss: 0.090217  [ 1200/ 3522]
loss: 0.013981  [ 1300/ 3522]
loss: 0.003728  [ 1400/ 3522]
loss: 0.002579  [ 1500/ 3522]
loss: 0.010429  [ 1600/ 3522]
loss: 0.006741  [ 1700/ 3522]
loss: 0.012546  [ 1800/ 3522]
loss: 0.010761  [ 1900/ 3522]
loss: 0.011711  [ 2000/ 3522]
loss: 0.007212  [ 2100/ 3522]
loss: 0.004151  [ 2200/ 3522]
loss: 0.005237  [ 2300/ 3522]
loss: 0.003562  [ 2400/ 3522]
loss: 0.004889  [ 2500/ 3522]
loss: 0.071470  [ 2600/ 3522]
loss: 0.005325  [ 2700/ 3522]
loss: 0.003953  [ 2800/ 3522]
loss: 0.004684  [ 2900/ 3522]
loss: 0.009610  [ 3000/ 3522]
loss: 0.004305  [ 3100/ 3522]
loss: 0.013612  [ 3200/ 3522]
loss: 0.009256  [ 3300/ 3522]
loss: 0.009463  [ 3400/ 3522]
loss: 0.005966  [ 3500/ 3522]
Epoch 8
-------------------------------
loss: 0.010671  [    0/ 3522]
loss: 0.006368  [  100/ 3522]
loss: 0.003826  [  200/ 3522]
loss: 0.040277  [  300/ 3522]
loss: 0.007502  [  400/ 3522]
loss: 0.009024  [  500/ 3522]
loss: 0.115828  [  600/ 3522]
loss: 0.012162  [  700/ 3522]
loss: 0.007138  [  800/ 3522]
loss: 0.004794  [  900/ 3522]
loss: 0.003194  [ 1000/ 3522]
loss: 0.004069  [ 1100/ 3522]
loss: 0.092147  [ 1200/ 3522]
loss: 0.014213  [ 1300/ 3522]
loss: 0.003804  [ 1400/ 3522]
loss: 0.002385  [ 1500/ 3522]
loss: 0.010370  [ 1600/ 3522]
loss: 0.007188  [ 1700/ 3522]
loss: 0.012671  [ 1800/ 3522]
loss: 0.010643  [ 1900/ 3522]
loss: 0.011845  [ 2000/ 3522]
loss: 0.007185  [ 2100/ 3522]
loss: 0.004083  [ 2200/ 3522]
loss: 0.005053  [ 2300/ 3522]
loss: 0.003639  [ 2400/ 3522]
loss: 0.004650  [ 2500/ 3522]
loss: 0.071473  [ 2600/ 3522]
loss: 0.005038  [ 2700/ 3522]
loss: 0.003903  [ 2800/ 3522]
loss: 0.004638  [ 2900/ 3522]
loss: 0.009419  [ 3000/ 3522]
loss: 0.003739  [ 3100/ 3522]
loss: 0.012929  [ 3200/ 3522]
loss: 0.009227  [ 3300/ 3522]
loss: 0.009160  [ 3400/ 3522]
loss: 0.005899  [ 3500/ 3522]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3522
First Spike after testing: [ 1.3348765  -0.04366347]
[0 2 2 ... 2 0 2]
[2 1 1 ... 1 2 1]
Cluster 0 Occurrences: 1151; KMEANS: 1110
Cluster 1 Occurrences: 1134; KMEANS: 1263
Cluster 2 Occurrences: 1237; KMEANS: 1149
Centroids: [[1.2768362, -0.11442098], [-0.3358066, 1.6982803], [-1.4384655, -0.7317053]]
Centroids: [[-0.3240997, 1.7314428], [-1.4405222, -0.71775323], [1.2955458, -0.10996271]]
Contingency Matrix: 
[[   0    9 1142]
 [1110   18    6]
 [   0 1236    1]]
[[0, -1, 1142], [1110, -1, 6], [-1, -1, -1]]
[[-1, -1, -1], [1110, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[1142    0    9]
 [   6 1110   18]
 [   1    0 1236]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1142, 1110, 1236], Sum: 3488
All_Elements: [1142, 0, 9, 6, 1110, 18, 1, 0, 1236], Sum: 3522
Accuracy: 0.9903463940942646
Done!
