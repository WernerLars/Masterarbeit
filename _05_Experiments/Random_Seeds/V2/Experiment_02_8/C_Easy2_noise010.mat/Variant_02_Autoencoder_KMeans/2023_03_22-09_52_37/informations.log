Experiment_path: Random_Seeds//V2/Experiment_02_8
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_8/C_Easy2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_52_37
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000028C07221908>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
<torch.utils.data.dataloader.DataLoader object at 0x0000028B854740B8>
Epoch 1
-------------------------------
loss: 0.206111  [    0/ 3520]
loss: 0.061299  [  100/ 3520]
loss: 0.185043  [  200/ 3520]
loss: 0.015773  [  300/ 3520]
loss: 0.095132  [  400/ 3520]
loss: 0.152984  [  500/ 3520]
loss: 0.012979  [  600/ 3520]
loss: 0.008249  [  700/ 3520]
loss: 0.007236  [  800/ 3520]
loss: 0.008818  [  900/ 3520]
loss: 0.004405  [ 1000/ 3520]
loss: 0.011689  [ 1100/ 3520]
loss: 0.012789  [ 1200/ 3520]
loss: 0.029208  [ 1300/ 3520]
loss: 0.010163  [ 1400/ 3520]
loss: 0.002523  [ 1500/ 3520]
loss: 0.004225  [ 1600/ 3520]
loss: 0.003028  [ 1700/ 3520]
loss: 0.043512  [ 1800/ 3520]
loss: 0.008136  [ 1900/ 3520]
loss: 0.014436  [ 2000/ 3520]
loss: 0.007480  [ 2100/ 3520]
loss: 0.009136  [ 2200/ 3520]
loss: 0.097395  [ 2300/ 3520]
loss: 0.008923  [ 2400/ 3520]
loss: 0.008671  [ 2500/ 3520]
loss: 0.008620  [ 2600/ 3520]
loss: 0.002951  [ 2700/ 3520]
loss: 0.010906  [ 2800/ 3520]
loss: 0.005369  [ 2900/ 3520]
loss: 0.012004  [ 3000/ 3520]
loss: 0.014951  [ 3100/ 3520]
loss: 0.005381  [ 3200/ 3520]
loss: 0.003771  [ 3300/ 3520]
loss: 0.007238  [ 3400/ 3520]
loss: 0.014407  [ 3500/ 3520]
Epoch 2
-------------------------------
loss: 0.013963  [    0/ 3520]
loss: 0.001996  [  100/ 3520]
loss: 0.172425  [  200/ 3520]
loss: 0.005012  [  300/ 3520]
loss: 0.047136  [  400/ 3520]
loss: 0.098803  [  500/ 3520]
loss: 0.004513  [  600/ 3520]
loss: 0.007187  [  700/ 3520]
loss: 0.006898  [  800/ 3520]
loss: 0.004129  [  900/ 3520]
loss: 0.003543  [ 1000/ 3520]
loss: 0.008221  [ 1100/ 3520]
loss: 0.009644  [ 1200/ 3520]
loss: 0.023781  [ 1300/ 3520]
loss: 0.008452  [ 1400/ 3520]
loss: 0.002100  [ 1500/ 3520]
loss: 0.003540  [ 1600/ 3520]
loss: 0.002794  [ 1700/ 3520]
loss: 0.028228  [ 1800/ 3520]
loss: 0.007919  [ 1900/ 3520]
loss: 0.014038  [ 2000/ 3520]
loss: 0.007546  [ 2100/ 3520]
loss: 0.006901  [ 2200/ 3520]
loss: 0.090585  [ 2300/ 3520]
loss: 0.008399  [ 2400/ 3520]
loss: 0.007863  [ 2500/ 3520]
loss: 0.006966  [ 2600/ 3520]
loss: 0.002589  [ 2700/ 3520]
loss: 0.011705  [ 2800/ 3520]
loss: 0.005080  [ 2900/ 3520]
loss: 0.012780  [ 3000/ 3520]
loss: 0.006109  [ 3100/ 3520]
loss: 0.004899  [ 3200/ 3520]
loss: 0.003701  [ 3300/ 3520]
loss: 0.006090  [ 3400/ 3520]
loss: 0.013952  [ 3500/ 3520]
Epoch 3
-------------------------------
loss: 0.013686  [    0/ 3520]
loss: 0.001995  [  100/ 3520]
loss: 0.158300  [  200/ 3520]
loss: 0.004525  [  300/ 3520]
loss: 0.043072  [  400/ 3520]
loss: 0.065580  [  500/ 3520]
loss: 0.004219  [  600/ 3520]
loss: 0.007691  [  700/ 3520]
loss: 0.006721  [  800/ 3520]
loss: 0.003768  [  900/ 3520]
loss: 0.003509  [ 1000/ 3520]
loss: 0.007601  [ 1100/ 3520]
loss: 0.009438  [ 1200/ 3520]
loss: 0.020327  [ 1300/ 3520]
loss: 0.006232  [ 1400/ 3520]
loss: 0.001792  [ 1500/ 3520]
loss: 0.002911  [ 1600/ 3520]
loss: 0.002921  [ 1700/ 3520]
loss: 0.031091  [ 1800/ 3520]
loss: 0.007031  [ 1900/ 3520]
loss: 0.014285  [ 2000/ 3520]
loss: 0.007531  [ 2100/ 3520]
loss: 0.006024  [ 2200/ 3520]
loss: 0.080656  [ 2300/ 3520]
loss: 0.008422  [ 2400/ 3520]
loss: 0.007607  [ 2500/ 3520]
loss: 0.006881  [ 2600/ 3520]
loss: 0.002690  [ 2700/ 3520]
loss: 0.012034  [ 2800/ 3520]
loss: 0.005841  [ 2900/ 3520]
loss: 0.012862  [ 3000/ 3520]
loss: 0.003581  [ 3100/ 3520]
loss: 0.004825  [ 3200/ 3520]
loss: 0.003484  [ 3300/ 3520]
loss: 0.006011  [ 3400/ 3520]
loss: 0.013329  [ 3500/ 3520]
Epoch 4
-------------------------------
loss: 0.013426  [    0/ 3520]
loss: 0.002074  [  100/ 3520]
loss: 0.134878  [  200/ 3520]
loss: 0.004451  [  300/ 3520]
loss: 0.040698  [  400/ 3520]
loss: 0.061991  [  500/ 3520]
loss: 0.004190  [  600/ 3520]
loss: 0.008290  [  700/ 3520]
loss: 0.006593  [  800/ 3520]
loss: 0.003745  [  900/ 3520]
loss: 0.003573  [ 1000/ 3520]
loss: 0.007246  [ 1100/ 3520]
loss: 0.009330  [ 1200/ 3520]
loss: 0.016038  [ 1300/ 3520]
loss: 0.004671  [ 1400/ 3520]
loss: 0.001484  [ 1500/ 3520]
loss: 0.002496  [ 1600/ 3520]
loss: 0.003159  [ 1700/ 3520]
loss: 0.048027  [ 1800/ 3520]
loss: 0.006433  [ 1900/ 3520]
loss: 0.014671  [ 2000/ 3520]
loss: 0.007603  [ 2100/ 3520]
loss: 0.005607  [ 2200/ 3520]
loss: 0.068260  [ 2300/ 3520]
loss: 0.009034  [ 2400/ 3520]
loss: 0.007755  [ 2500/ 3520]
loss: 0.008004  [ 2600/ 3520]
loss: 0.002931  [ 2700/ 3520]
loss: 0.012454  [ 2800/ 3520]
loss: 0.005694  [ 2900/ 3520]
loss: 0.012869  [ 3000/ 3520]
loss: 0.004647  [ 3100/ 3520]
loss: 0.004919  [ 3200/ 3520]
loss: 0.003023  [ 3300/ 3520]
loss: 0.006070  [ 3400/ 3520]
loss: 0.012727  [ 3500/ 3520]
Epoch 5
-------------------------------
loss: 0.013214  [    0/ 3520]
loss: 0.002232  [  100/ 3520]
loss: 0.118204  [  200/ 3520]
loss: 0.004567  [  300/ 3520]
loss: 0.040983  [  400/ 3520]
loss: 0.066598  [  500/ 3520]
loss: 0.004454  [  600/ 3520]
loss: 0.008576  [  700/ 3520]
loss: 0.006465  [  800/ 3520]
loss: 0.003178  [  900/ 3520]
loss: 0.003695  [ 1000/ 3520]
loss: 0.007494  [ 1100/ 3520]
loss: 0.009508  [ 1200/ 3520]
loss: 0.012430  [ 1300/ 3520]
loss: 0.004289  [ 1400/ 3520]
loss: 0.001406  [ 1500/ 3520]
loss: 0.002364  [ 1600/ 3520]
loss: 0.003555  [ 1700/ 3520]
loss: 0.066387  [ 1800/ 3520]
loss: 0.006444  [ 1900/ 3520]
loss: 0.015220  [ 2000/ 3520]
loss: 0.007830  [ 2100/ 3520]
loss: 0.005949  [ 2200/ 3520]
loss: 0.060382  [ 2300/ 3520]
loss: 0.009054  [ 2400/ 3520]
loss: 0.008031  [ 2500/ 3520]
loss: 0.009097  [ 2600/ 3520]
loss: 0.002989  [ 2700/ 3520]
loss: 0.012381  [ 2800/ 3520]
loss: 0.005095  [ 2900/ 3520]
loss: 0.012614  [ 3000/ 3520]
loss: 0.005948  [ 3100/ 3520]
loss: 0.005065  [ 3200/ 3520]
loss: 0.002357  [ 3300/ 3520]
loss: 0.006276  [ 3400/ 3520]
loss: 0.011911  [ 3500/ 3520]
Epoch 6
-------------------------------
loss: 0.012861  [    0/ 3520]
loss: 0.002499  [  100/ 3520]
loss: 0.107200  [  200/ 3520]
loss: 0.004573  [  300/ 3520]
loss: 0.040261  [  400/ 3520]
loss: 0.070959  [  500/ 3520]
loss: 0.004736  [  600/ 3520]
loss: 0.008172  [  700/ 3520]
loss: 0.006392  [  800/ 3520]
loss: 0.002662  [  900/ 3520]
loss: 0.003817  [ 1000/ 3520]
loss: 0.007868  [ 1100/ 3520]
loss: 0.009478  [ 1200/ 3520]
loss: 0.009582  [ 1300/ 3520]
loss: 0.004575  [ 1400/ 3520]
loss: 0.001424  [ 1500/ 3520]
loss: 0.002311  [ 1600/ 3520]
loss: 0.003555  [ 1700/ 3520]
loss: 0.078036  [ 1800/ 3520]
loss: 0.006579  [ 1900/ 3520]
loss: 0.014636  [ 2000/ 3520]
loss: 0.007865  [ 2100/ 3520]
loss: 0.006051  [ 2200/ 3520]
loss: 0.057978  [ 2300/ 3520]
loss: 0.007960  [ 2400/ 3520]
loss: 0.008286  [ 2500/ 3520]
loss: 0.010086  [ 2600/ 3520]
loss: 0.003167  [ 2700/ 3520]
loss: 0.012564  [ 2800/ 3520]
loss: 0.004774  [ 2900/ 3520]
loss: 0.012264  [ 3000/ 3520]
loss: 0.008310  [ 3100/ 3520]
loss: 0.005079  [ 3200/ 3520]
loss: 0.001558  [ 3300/ 3520]
loss: 0.006530  [ 3400/ 3520]
loss: 0.011138  [ 3500/ 3520]
Epoch 7
-------------------------------
loss: 0.012346  [    0/ 3520]
loss: 0.002634  [  100/ 3520]
loss: 0.102129  [  200/ 3520]
loss: 0.004672  [  300/ 3520]
loss: 0.038099  [  400/ 3520]
loss: 0.073947  [  500/ 3520]
loss: 0.004973  [  600/ 3520]
loss: 0.007951  [  700/ 3520]
loss: 0.006290  [  800/ 3520]
loss: 0.002210  [  900/ 3520]
loss: 0.004091  [ 1000/ 3520]
loss: 0.008111  [ 1100/ 3520]
loss: 0.009738  [ 1200/ 3520]
loss: 0.007576  [ 1300/ 3520]
loss: 0.005355  [ 1400/ 3520]
loss: 0.001478  [ 1500/ 3520]
loss: 0.002245  [ 1600/ 3520]
loss: 0.003545  [ 1700/ 3520]
loss: 0.085475  [ 1800/ 3520]
loss: 0.006887  [ 1900/ 3520]
loss: 0.013806  [ 2000/ 3520]
loss: 0.007834  [ 2100/ 3520]
loss: 0.006131  [ 2200/ 3520]
loss: 0.058475  [ 2300/ 3520]
loss: 0.007109  [ 2400/ 3520]
loss: 0.008758  [ 2500/ 3520]
loss: 0.010615  [ 2600/ 3520]
loss: 0.003229  [ 2700/ 3520]
loss: 0.012622  [ 2800/ 3520]
loss: 0.004604  [ 2900/ 3520]
loss: 0.011920  [ 3000/ 3520]
loss: 0.009771  [ 3100/ 3520]
loss: 0.005137  [ 3200/ 3520]
loss: 0.001431  [ 3300/ 3520]
loss: 0.006614  [ 3400/ 3520]
loss: 0.010442  [ 3500/ 3520]
Epoch 8
-------------------------------
loss: 0.011761  [    0/ 3520]
loss: 0.002909  [  100/ 3520]
loss: 0.098658  [  200/ 3520]
loss: 0.004718  [  300/ 3520]
loss: 0.035588  [  400/ 3520]
loss: 0.072065  [  500/ 3520]
loss: 0.005072  [  600/ 3520]
loss: 0.007812  [  700/ 3520]
loss: 0.006177  [  800/ 3520]
loss: 0.001963  [  900/ 3520]
loss: 0.003880  [ 1000/ 3520]
loss: 0.008386  [ 1100/ 3520]
loss: 0.009669  [ 1200/ 3520]
loss: 0.006287  [ 1300/ 3520]
loss: 0.006034  [ 1400/ 3520]
loss: 0.001488  [ 1500/ 3520]
loss: 0.002262  [ 1600/ 3520]
loss: 0.003692  [ 1700/ 3520]
loss: 0.089694  [ 1800/ 3520]
loss: 0.007093  [ 1900/ 3520]
loss: 0.013314  [ 2000/ 3520]
loss: 0.007697  [ 2100/ 3520]
loss: 0.006680  [ 2200/ 3520]
loss: 0.061304  [ 2300/ 3520]
loss: 0.006524  [ 2400/ 3520]
loss: 0.008655  [ 2500/ 3520]
loss: 0.010881  [ 2600/ 3520]
loss: 0.003158  [ 2700/ 3520]
loss: 0.012849  [ 2800/ 3520]
loss: 0.004389  [ 2900/ 3520]
loss: 0.011618  [ 3000/ 3520]
loss: 0.010445  [ 3100/ 3520]
loss: 0.005109  [ 3200/ 3520]
loss: 0.001250  [ 3300/ 3520]
loss: 0.006641  [ 3400/ 3520]
loss: 0.010008  [ 3500/ 3520]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3520
First Spike after testing: [-0.06242945  1.8841853 ]
[0 1 2 ... 0 1 2]
[1 2 0 ... 1 2 0]
Cluster 0 Occurrences: 1160; KMEANS: 1210
Cluster 1 Occurrences: 1146; KMEANS: 1194
Cluster 2 Occurrences: 1214; KMEANS: 1116
Centroids: [[0.39598474, 2.0352728], [-0.46957734, 1.1414754], [-0.37656146, -0.574338]]
Centroids: [[-0.37526387, -0.57947886], [0.43084195, 2.0332224], [-0.5343145, 1.1158626]]
Contingency Matrix: 
[[   0 1139   21]
 [   0   54 1092]
 [1210    1    3]]
[[-1, 1139, 21], [-1, 54, 1092], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1092], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1139   21    0]
 [  54 1092    0]
 [   1    3 1210]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1139, 1092, 1210], Sum: 3441
All_Elements: [1139, 21, 0, 54, 1092, 0, 1, 3, 1210], Sum: 3520
Accuracy: 0.9775568181818182
Done!
