Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Difficult2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_02_08
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000020696889400>
Sampling rate: 24000.0
Raw: [ 0.02085333  0.02043967  0.02052644 ... -0.02218732 -0.02150573
 -0.01811243]
Times: [   1583    1934    2430 ... 1439313 1439656 1439854]
Cluster: [3 3 3 ... 2 2 1]
Number of different clusters:  3
Number of Spikes: 3364
First aligned Spike Frame: [-0.05170878 -0.0548761  -0.06029554 -0.06053219 -0.04807119 -0.02780025
 -0.01550543 -0.01702494 -0.02945104 -0.04493807 -0.07056858 -0.07003585
  0.07629654  0.43081562  0.80470191  0.96319627  0.89198123  0.73643948
  0.58987232  0.46714337  0.36345495  0.2828462   0.22743292  0.182731
  0.13931053  0.09524506  0.05136602  0.01367166 -0.01393093 -0.03985679
 -0.07387102 -0.11218435 -0.1444455  -0.16672578 -0.17809238 -0.18020802
 -0.17953732 -0.18246903 -0.18617363 -0.18205375 -0.17299738 -0.16958427
 -0.17248955 -0.17516876 -0.1727246  -0.16696514 -0.15993314]
Cluster 0, Occurrences: 1120
Cluster 1, Occurrences: 1109
Cluster 2, Occurrences: 1135
<torch.utils.data.dataloader.DataLoader object at 0x00000206899FF4E0>
Epoch 1
-------------------------------
loss: 0.117723  [    0/ 3364]
loss: 0.101655  [  100/ 3364]
loss: 0.076631  [  200/ 3364]
loss: 0.079634  [  300/ 3364]
loss: 0.004473  [  400/ 3364]
loss: 0.048630  [  500/ 3364]
loss: 0.032263  [  600/ 3364]
loss: 0.031681  [  700/ 3364]
loss: 0.018395  [  800/ 3364]
loss: 0.017982  [  900/ 3364]
loss: 0.008335  [ 1000/ 3364]
loss: 0.004486  [ 1100/ 3364]
loss: 0.010749  [ 1200/ 3364]
loss: 0.005949  [ 1300/ 3364]
loss: 0.089169  [ 1400/ 3364]
loss: 0.004950  [ 1500/ 3364]
loss: 0.006343  [ 1600/ 3364]
loss: 0.005958  [ 1700/ 3364]
loss: 0.002913  [ 1800/ 3364]
loss: 0.004950  [ 1900/ 3364]
loss: 0.004628  [ 2000/ 3364]
loss: 0.006073  [ 2100/ 3364]
loss: 0.005256  [ 2200/ 3364]
loss: 0.009184  [ 2300/ 3364]
loss: 0.001061  [ 2400/ 3364]
loss: 0.002616  [ 2500/ 3364]
loss: 0.001993  [ 2600/ 3364]
loss: 0.003049  [ 2700/ 3364]
loss: 0.003801  [ 2800/ 3364]
loss: 0.002721  [ 2900/ 3364]
loss: 0.003837  [ 3000/ 3364]
loss: 0.006879  [ 3100/ 3364]
loss: 0.001476  [ 3200/ 3364]
loss: 0.000626  [ 3300/ 3364]
Epoch 2
-------------------------------
loss: 0.001617  [    0/ 3364]
loss: 0.002861  [  100/ 3364]
loss: 0.004472  [  200/ 3364]
loss: 0.001008  [  300/ 3364]
loss: 0.000810  [  400/ 3364]
loss: 0.037141  [  500/ 3364]
loss: 0.004002  [  600/ 3364]
loss: 0.006070  [  700/ 3364]
loss: 0.002795  [  800/ 3364]
loss: 0.005153  [  900/ 3364]
loss: 0.003371  [ 1000/ 3364]
loss: 0.003440  [ 1100/ 3364]
loss: 0.002621  [ 1200/ 3364]
loss: 0.005072  [ 1300/ 3364]
loss: 0.086811  [ 1400/ 3364]
loss: 0.003458  [ 1500/ 3364]
loss: 0.005951  [ 1600/ 3364]
loss: 0.002943  [ 1700/ 3364]
loss: 0.002028  [ 1800/ 3364]
loss: 0.003696  [ 1900/ 3364]
loss: 0.003188  [ 2000/ 3364]
loss: 0.004444  [ 2100/ 3364]
loss: 0.003524  [ 2200/ 3364]
loss: 0.008337  [ 2300/ 3364]
loss: 0.000777  [ 2400/ 3364]
loss: 0.002638  [ 2500/ 3364]
loss: 0.002481  [ 2600/ 3364]
loss: 0.002897  [ 2700/ 3364]
loss: 0.003693  [ 2800/ 3364]
loss: 0.002009  [ 2900/ 3364]
loss: 0.003963  [ 3000/ 3364]
loss: 0.006527  [ 3100/ 3364]
loss: 0.001554  [ 3200/ 3364]
loss: 0.000668  [ 3300/ 3364]
Epoch 3
-------------------------------
loss: 0.001262  [    0/ 3364]
loss: 0.002814  [  100/ 3364]
loss: 0.004750  [  200/ 3364]
loss: 0.000895  [  300/ 3364]
loss: 0.000777  [  400/ 3364]
loss: 0.035682  [  500/ 3364]
loss: 0.003491  [  600/ 3364]
loss: 0.005070  [  700/ 3364]
loss: 0.002866  [  800/ 3364]
loss: 0.003861  [  900/ 3364]
loss: 0.002807  [ 1000/ 3364]
loss: 0.003430  [ 1100/ 3364]
loss: 0.002495  [ 1200/ 3364]
loss: 0.004861  [ 1300/ 3364]
loss: 0.085258  [ 1400/ 3364]
loss: 0.003327  [ 1500/ 3364]
loss: 0.006085  [ 1600/ 3364]
loss: 0.002350  [ 1700/ 3364]
loss: 0.001743  [ 1800/ 3364]
loss: 0.003672  [ 1900/ 3364]
loss: 0.002660  [ 2000/ 3364]
loss: 0.004171  [ 2100/ 3364]
loss: 0.003569  [ 2200/ 3364]
loss: 0.007674  [ 2300/ 3364]
loss: 0.000814  [ 2400/ 3364]
loss: 0.002614  [ 2500/ 3364]
loss: 0.002375  [ 2600/ 3364]
loss: 0.002870  [ 2700/ 3364]
loss: 0.003708  [ 2800/ 3364]
loss: 0.001891  [ 2900/ 3364]
loss: 0.003939  [ 3000/ 3364]
loss: 0.006432  [ 3100/ 3364]
loss: 0.001577  [ 3200/ 3364]
loss: 0.000545  [ 3300/ 3364]
Epoch 4
-------------------------------
loss: 0.001303  [    0/ 3364]
loss: 0.002836  [  100/ 3364]
loss: 0.004719  [  200/ 3364]
loss: 0.000872  [  300/ 3364]
loss: 0.000718  [  400/ 3364]
loss: 0.033886  [  500/ 3364]
loss: 0.003178  [  600/ 3364]
loss: 0.004472  [  700/ 3364]
loss: 0.003042  [  800/ 3364]
loss: 0.003401  [  900/ 3364]
loss: 0.002531  [ 1000/ 3364]
loss: 0.003483  [ 1100/ 3364]
loss: 0.002494  [ 1200/ 3364]
loss: 0.004786  [ 1300/ 3364]
loss: 0.084480  [ 1400/ 3364]
loss: 0.003325  [ 1500/ 3364]
loss: 0.006173  [ 1600/ 3364]
loss: 0.002184  [ 1700/ 3364]
loss: 0.001619  [ 1800/ 3364]
loss: 0.003749  [ 1900/ 3364]
loss: 0.002431  [ 2000/ 3364]
loss: 0.004221  [ 2100/ 3364]
loss: 0.003609  [ 2200/ 3364]
loss: 0.007394  [ 2300/ 3364]
loss: 0.000918  [ 2400/ 3364]
loss: 0.002597  [ 2500/ 3364]
loss: 0.002008  [ 2600/ 3364]
loss: 0.002849  [ 2700/ 3364]
loss: 0.003726  [ 2800/ 3364]
loss: 0.001765  [ 2900/ 3364]
loss: 0.003850  [ 3000/ 3364]
loss: 0.006432  [ 3100/ 3364]
loss: 0.001569  [ 3200/ 3364]
loss: 0.000577  [ 3300/ 3364]
Epoch 5
-------------------------------
loss: 0.001229  [    0/ 3364]
loss: 0.002821  [  100/ 3364]
loss: 0.004795  [  200/ 3364]
loss: 0.000830  [  300/ 3364]
loss: 0.000698  [  400/ 3364]
loss: 0.032821  [  500/ 3364]
loss: 0.003086  [  600/ 3364]
loss: 0.004378  [  700/ 3364]
loss: 0.002803  [  800/ 3364]
loss: 0.003371  [  900/ 3364]
loss: 0.002507  [ 1000/ 3364]
loss: 0.003486  [ 1100/ 3364]
loss: 0.002432  [ 1200/ 3364]
loss: 0.004695  [ 1300/ 3364]
loss: 0.083927  [ 1400/ 3364]
loss: 0.003266  [ 1500/ 3364]
loss: 0.006189  [ 1600/ 3364]
loss: 0.002187  [ 1700/ 3364]
loss: 0.001579  [ 1800/ 3364]
loss: 0.003699  [ 1900/ 3364]
loss: 0.002419  [ 2000/ 3364]
loss: 0.004009  [ 2100/ 3364]
loss: 0.003688  [ 2200/ 3364]
loss: 0.007295  [ 2300/ 3364]
loss: 0.000884  [ 2400/ 3364]
loss: 0.002576  [ 2500/ 3364]
loss: 0.002080  [ 2600/ 3364]
loss: 0.002890  [ 2700/ 3364]
loss: 0.003684  [ 2800/ 3364]
loss: 0.001780  [ 2900/ 3364]
loss: 0.003941  [ 3000/ 3364]
loss: 0.006410  [ 3100/ 3364]
loss: 0.001579  [ 3200/ 3364]
loss: 0.000593  [ 3300/ 3364]
Epoch 6
-------------------------------
loss: 0.001283  [    0/ 3364]
loss: 0.002832  [  100/ 3364]
loss: 0.004700  [  200/ 3364]
loss: 0.000895  [  300/ 3364]
loss: 0.000691  [  400/ 3364]
loss: 0.032194  [  500/ 3364]
loss: 0.003009  [  600/ 3364]
loss: 0.004350  [  700/ 3364]
loss: 0.002891  [  800/ 3364]
loss: 0.003193  [  900/ 3364]
loss: 0.002643  [ 1000/ 3364]
loss: 0.003500  [ 1100/ 3364]
loss: 0.002453  [ 1200/ 3364]
loss: 0.004615  [ 1300/ 3364]
loss: 0.083924  [ 1400/ 3364]
loss: 0.003349  [ 1500/ 3364]
loss: 0.006275  [ 1600/ 3364]
loss: 0.002227  [ 1700/ 3364]
loss: 0.001536  [ 1800/ 3364]
loss: 0.003718  [ 1900/ 3364]
loss: 0.002384  [ 2000/ 3364]
loss: 0.004241  [ 2100/ 3364]
loss: 0.003736  [ 2200/ 3364]
loss: 0.007275  [ 2300/ 3364]
loss: 0.000976  [ 2400/ 3364]
loss: 0.002570  [ 2500/ 3364]
loss: 0.002089  [ 2600/ 3364]
loss: 0.002802  [ 2700/ 3364]
loss: 0.003705  [ 2800/ 3364]
loss: 0.001703  [ 2900/ 3364]
loss: 0.003891  [ 3000/ 3364]
loss: 0.006410  [ 3100/ 3364]
loss: 0.001575  [ 3200/ 3364]
loss: 0.000582  [ 3300/ 3364]
Epoch 7
-------------------------------
loss: 0.001272  [    0/ 3364]
loss: 0.002851  [  100/ 3364]
loss: 0.004722  [  200/ 3364]
loss: 0.000855  [  300/ 3364]
loss: 0.000696  [  400/ 3364]
loss: 0.031667  [  500/ 3364]
loss: 0.002955  [  600/ 3364]
loss: 0.004398  [  700/ 3364]
loss: 0.003118  [  800/ 3364]
loss: 0.003213  [  900/ 3364]
loss: 0.002663  [ 1000/ 3364]
loss: 0.003506  [ 1100/ 3364]
loss: 0.002395  [ 1200/ 3364]
loss: 0.004551  [ 1300/ 3364]
loss: 0.083583  [ 1400/ 3364]
loss: 0.003341  [ 1500/ 3364]
loss: 0.006301  [ 1600/ 3364]
loss: 0.002250  [ 1700/ 3364]
loss: 0.001495  [ 1800/ 3364]
loss: 0.003660  [ 1900/ 3364]
loss: 0.002384  [ 2000/ 3364]
loss: 0.003973  [ 2100/ 3364]
loss: 0.003766  [ 2200/ 3364]
loss: 0.007174  [ 2300/ 3364]
loss: 0.000866  [ 2400/ 3364]
loss: 0.002613  [ 2500/ 3364]
loss: 0.001789  [ 2600/ 3364]
loss: 0.002858  [ 2700/ 3364]
loss: 0.003646  [ 2800/ 3364]
loss: 0.001752  [ 2900/ 3364]
loss: 0.003981  [ 3000/ 3364]
loss: 0.006451  [ 3100/ 3364]
loss: 0.001586  [ 3200/ 3364]
loss: 0.000809  [ 3300/ 3364]
Epoch 8
-------------------------------
loss: 0.001317  [    0/ 3364]
loss: 0.002880  [  100/ 3364]
loss: 0.004688  [  200/ 3364]
loss: 0.000923  [  300/ 3364]
loss: 0.000690  [  400/ 3364]
loss: 0.031170  [  500/ 3364]
loss: 0.002929  [  600/ 3364]
loss: 0.004556  [  700/ 3364]
loss: 0.003128  [  800/ 3364]
loss: 0.003275  [  900/ 3364]
loss: 0.002685  [ 1000/ 3364]
loss: 0.003489  [ 1100/ 3364]
loss: 0.002394  [ 1200/ 3364]
loss: 0.004488  [ 1300/ 3364]
loss: 0.083625  [ 1400/ 3364]
loss: 0.003406  [ 1500/ 3364]
loss: 0.006288  [ 1600/ 3364]
loss: 0.002305  [ 1700/ 3364]
loss: 0.001459  [ 1800/ 3364]
loss: 0.003672  [ 1900/ 3364]
loss: 0.002362  [ 2000/ 3364]
loss: 0.004227  [ 2100/ 3364]
loss: 0.003757  [ 2200/ 3364]
loss: 0.007176  [ 2300/ 3364]
loss: 0.000910  [ 2400/ 3364]
loss: 0.002578  [ 2500/ 3364]
loss: 0.001895  [ 2600/ 3364]
loss: 0.002778  [ 2700/ 3364]
loss: 0.003636  [ 2800/ 3364]
loss: 0.001737  [ 2900/ 3364]
loss: 0.003966  [ 3000/ 3364]
loss: 0.006436  [ 3100/ 3364]
loss: 0.001567  [ 3200/ 3364]
loss: 0.001283  [ 3300/ 3364]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3364
First Spike after testing: [ 2.2690432 -6.28508  ]
[2 2 2 ... 1 1 0]
[1 1 1 ... 0 0 2]
Cluster 0 Occurrences: 1120; KMEANS: 1095
Cluster 1 Occurrences: 1109; KMEANS: 1126
Cluster 2 Occurrences: 1135; KMEANS: 1143
Centroids: [[3.4607759, -5.0974154], [-0.4020023, -5.3018603], [2.355679, -6.252228]]
Centroids: [[-0.43878153, -5.149367], [2.4442143, -6.600215], [3.3527775, -4.9122915]]
Contingency Matrix: 
[[   0   45 1075]
 [1079   30    0]
 [  16 1051   68]]
[[-1, 45, 1075], [-1, -1, -1], [-1, 1051, 68]]
[[-1, -1, -1], [-1, -1, -1], [-1, 1051, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 0, 0: 2, 2: 1}
New Contingency Matrix: 
[[1075    0   45]
 [   0 1079   30]
 [  68   16 1051]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1075, 1079, 1051], Sum: 3205
All_Elements: [1075, 0, 45, 0, 1079, 30, 68, 16, 1051], Sum: 3364
Accuracy: 0.9527348394768134
Done!
