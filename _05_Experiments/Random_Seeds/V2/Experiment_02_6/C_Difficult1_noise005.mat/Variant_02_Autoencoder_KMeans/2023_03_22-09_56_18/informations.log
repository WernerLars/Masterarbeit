Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_56_18
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002068A6BEBA8>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x0000020629A67080>
Epoch 1
-------------------------------
loss: 0.182723  [    0/ 3383]
loss: 0.075493  [  100/ 3383]
loss: 0.045127  [  200/ 3383]
loss: 0.035977  [  300/ 3383]
loss: 0.011107  [  400/ 3383]
loss: 0.012525  [  500/ 3383]
loss: 0.012736  [  600/ 3383]
loss: 0.018485  [  700/ 3383]
loss: 0.010530  [  800/ 3383]
loss: 0.012727  [  900/ 3383]
loss: 0.112264  [ 1000/ 3383]
loss: 0.057439  [ 1100/ 3383]
loss: 0.033715  [ 1200/ 3383]
loss: 0.014814  [ 1300/ 3383]
loss: 0.007954  [ 1400/ 3383]
loss: 0.015161  [ 1500/ 3383]
loss: 0.010095  [ 1600/ 3383]
loss: 0.002920  [ 1700/ 3383]
loss: 0.013802  [ 1800/ 3383]
loss: 0.015315  [ 1900/ 3383]
loss: 0.009888  [ 2000/ 3383]
loss: 0.004424  [ 2100/ 3383]
loss: 0.013020  [ 2200/ 3383]
loss: 0.014140  [ 2300/ 3383]
loss: 0.004143  [ 2400/ 3383]
loss: 0.029664  [ 2500/ 3383]
loss: 0.009830  [ 2600/ 3383]
loss: 0.002622  [ 2700/ 3383]
loss: 0.005776  [ 2800/ 3383]
loss: 0.005844  [ 2900/ 3383]
loss: 0.005002  [ 3000/ 3383]
loss: 0.005428  [ 3100/ 3383]
loss: 0.067183  [ 3200/ 3383]
loss: 0.007127  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.006502  [    0/ 3383]
loss: 0.010549  [  100/ 3383]
loss: 0.009216  [  200/ 3383]
loss: 0.005519  [  300/ 3383]
loss: 0.002179  [  400/ 3383]
loss: 0.008135  [  500/ 3383]
loss: 0.004037  [  600/ 3383]
loss: 0.008171  [  700/ 3383]
loss: 0.006594  [  800/ 3383]
loss: 0.003424  [  900/ 3383]
loss: 0.094412  [ 1000/ 3383]
loss: 0.059406  [ 1100/ 3383]
loss: 0.026061  [ 1200/ 3383]
loss: 0.011413  [ 1300/ 3383]
loss: 0.003299  [ 1400/ 3383]
loss: 0.012471  [ 1500/ 3383]
loss: 0.001964  [ 1600/ 3383]
loss: 0.001704  [ 1700/ 3383]
loss: 0.011207  [ 1800/ 3383]
loss: 0.013736  [ 1900/ 3383]
loss: 0.003830  [ 2000/ 3383]
loss: 0.003556  [ 2100/ 3383]
loss: 0.007462  [ 2200/ 3383]
loss: 0.002841  [ 2300/ 3383]
loss: 0.003864  [ 2400/ 3383]
loss: 0.027489  [ 2500/ 3383]
loss: 0.001081  [ 2600/ 3383]
loss: 0.002858  [ 2700/ 3383]
loss: 0.006201  [ 2800/ 3383]
loss: 0.005912  [ 2900/ 3383]
loss: 0.004689  [ 3000/ 3383]
loss: 0.004771  [ 3100/ 3383]
loss: 0.065298  [ 3200/ 3383]
loss: 0.002507  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.004558  [    0/ 3383]
loss: 0.005936  [  100/ 3383]
loss: 0.004499  [  200/ 3383]
loss: 0.003165  [  300/ 3383]
loss: 0.002406  [  400/ 3383]
loss: 0.003984  [  500/ 3383]
loss: 0.001065  [  600/ 3383]
loss: 0.002025  [  700/ 3383]
loss: 0.007739  [  800/ 3383]
loss: 0.002011  [  900/ 3383]
loss: 0.092957  [ 1000/ 3383]
loss: 0.057675  [ 1100/ 3383]
loss: 0.025092  [ 1200/ 3383]
loss: 0.009279  [ 1300/ 3383]
loss: 0.004087  [ 1400/ 3383]
loss: 0.014655  [ 1500/ 3383]
loss: 0.002607  [ 1600/ 3383]
loss: 0.001603  [ 1700/ 3383]
loss: 0.011698  [ 1800/ 3383]
loss: 0.014047  [ 1900/ 3383]
loss: 0.003021  [ 2000/ 3383]
loss: 0.003362  [ 2100/ 3383]
loss: 0.008049  [ 2200/ 3383]
loss: 0.001704  [ 2300/ 3383]
loss: 0.003765  [ 2400/ 3383]
loss: 0.027092  [ 2500/ 3383]
loss: 0.001128  [ 2600/ 3383]
loss: 0.002743  [ 2700/ 3383]
loss: 0.006150  [ 2800/ 3383]
loss: 0.006118  [ 2900/ 3383]
loss: 0.003281  [ 3000/ 3383]
loss: 0.004615  [ 3100/ 3383]
loss: 0.065040  [ 3200/ 3383]
loss: 0.002657  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.003913  [    0/ 3383]
loss: 0.005907  [  100/ 3383]
loss: 0.005067  [  200/ 3383]
loss: 0.002672  [  300/ 3383]
loss: 0.002508  [  400/ 3383]
loss: 0.004192  [  500/ 3383]
loss: 0.001050  [  600/ 3383]
loss: 0.001778  [  700/ 3383]
loss: 0.007472  [  800/ 3383]
loss: 0.001637  [  900/ 3383]
loss: 0.092260  [ 1000/ 3383]
loss: 0.057782  [ 1100/ 3383]
loss: 0.024430  [ 1200/ 3383]
loss: 0.009349  [ 1300/ 3383]
loss: 0.004186  [ 1400/ 3383]
loss: 0.014896  [ 1500/ 3383]
loss: 0.002599  [ 1600/ 3383]
loss: 0.001583  [ 1700/ 3383]
loss: 0.011507  [ 1800/ 3383]
loss: 0.013985  [ 1900/ 3383]
loss: 0.003019  [ 2000/ 3383]
loss: 0.003360  [ 2100/ 3383]
loss: 0.008281  [ 2200/ 3383]
loss: 0.001711  [ 2300/ 3383]
loss: 0.003772  [ 2400/ 3383]
loss: 0.022836  [ 2500/ 3383]
loss: 0.001002  [ 2600/ 3383]
loss: 0.002839  [ 2700/ 3383]
loss: 0.006250  [ 2800/ 3383]
loss: 0.006224  [ 2900/ 3383]
loss: 0.003093  [ 3000/ 3383]
loss: 0.004618  [ 3100/ 3383]
loss: 0.065022  [ 3200/ 3383]
loss: 0.002718  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.003970  [    0/ 3383]
loss: 0.005954  [  100/ 3383]
loss: 0.005404  [  200/ 3383]
loss: 0.002532  [  300/ 3383]
loss: 0.002529  [  400/ 3383]
loss: 0.004229  [  500/ 3383]
loss: 0.001056  [  600/ 3383]
loss: 0.001744  [  700/ 3383]
loss: 0.007370  [  800/ 3383]
loss: 0.001519  [  900/ 3383]
loss: 0.091805  [ 1000/ 3383]
loss: 0.057819  [ 1100/ 3383]
loss: 0.024366  [ 1200/ 3383]
loss: 0.009354  [ 1300/ 3383]
loss: 0.004163  [ 1400/ 3383]
loss: 0.014972  [ 1500/ 3383]
loss: 0.002588  [ 1600/ 3383]
loss: 0.001579  [ 1700/ 3383]
loss: 0.011415  [ 1800/ 3383]
loss: 0.013988  [ 1900/ 3383]
loss: 0.002997  [ 2000/ 3383]
loss: 0.003397  [ 2100/ 3383]
loss: 0.008344  [ 2200/ 3383]
loss: 0.001736  [ 2300/ 3383]
loss: 0.003770  [ 2400/ 3383]
loss: 0.022904  [ 2500/ 3383]
loss: 0.000991  [ 2600/ 3383]
loss: 0.002817  [ 2700/ 3383]
loss: 0.006344  [ 2800/ 3383]
loss: 0.006273  [ 2900/ 3383]
loss: 0.002998  [ 3000/ 3383]
loss: 0.004631  [ 3100/ 3383]
loss: 0.065035  [ 3200/ 3383]
loss: 0.002754  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.003661  [    0/ 3383]
loss: 0.005988  [  100/ 3383]
loss: 0.005323  [  200/ 3383]
loss: 0.002468  [  300/ 3383]
loss: 0.002533  [  400/ 3383]
loss: 0.004222  [  500/ 3383]
loss: 0.001058  [  600/ 3383]
loss: 0.001757  [  700/ 3383]
loss: 0.007325  [  800/ 3383]
loss: 0.001451  [  900/ 3383]
loss: 0.091567  [ 1000/ 3383]
loss: 0.057854  [ 1100/ 3383]
loss: 0.024346  [ 1200/ 3383]
loss: 0.009348  [ 1300/ 3383]
loss: 0.004157  [ 1400/ 3383]
loss: 0.014976  [ 1500/ 3383]
loss: 0.002571  [ 1600/ 3383]
loss: 0.001568  [ 1700/ 3383]
loss: 0.011343  [ 1800/ 3383]
loss: 0.013979  [ 1900/ 3383]
loss: 0.002987  [ 2000/ 3383]
loss: 0.003403  [ 2100/ 3383]
loss: 0.008353  [ 2200/ 3383]
loss: 0.001756  [ 2300/ 3383]
loss: 0.003752  [ 2400/ 3383]
loss: 0.022729  [ 2500/ 3383]
loss: 0.001061  [ 2600/ 3383]
loss: 0.002822  [ 2700/ 3383]
loss: 0.006230  [ 2800/ 3383]
loss: 0.006290  [ 2900/ 3383]
loss: 0.002963  [ 3000/ 3383]
loss: 0.004613  [ 3100/ 3383]
loss: 0.065021  [ 3200/ 3383]
loss: 0.002754  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.003664  [    0/ 3383]
loss: 0.005937  [  100/ 3383]
loss: 0.005318  [  200/ 3383]
loss: 0.002441  [  300/ 3383]
loss: 0.002535  [  400/ 3383]
loss: 0.004208  [  500/ 3383]
loss: 0.001050  [  600/ 3383]
loss: 0.001775  [  700/ 3383]
loss: 0.007314  [  800/ 3383]
loss: 0.001442  [  900/ 3383]
loss: 0.091622  [ 1000/ 3383]
loss: 0.057857  [ 1100/ 3383]
loss: 0.024316  [ 1200/ 3383]
loss: 0.009338  [ 1300/ 3383]
loss: 0.004155  [ 1400/ 3383]
loss: 0.014981  [ 1500/ 3383]
loss: 0.002560  [ 1600/ 3383]
loss: 0.001565  [ 1700/ 3383]
loss: 0.011311  [ 1800/ 3383]
loss: 0.013975  [ 1900/ 3383]
loss: 0.002973  [ 2000/ 3383]
loss: 0.003420  [ 2100/ 3383]
loss: 0.008368  [ 2200/ 3383]
loss: 0.001739  [ 2300/ 3383]
loss: 0.003727  [ 2400/ 3383]
loss: 0.022309  [ 2500/ 3383]
loss: 0.000999  [ 2600/ 3383]
loss: 0.002811  [ 2700/ 3383]
loss: 0.006242  [ 2800/ 3383]
loss: 0.006329  [ 2900/ 3383]
loss: 0.002895  [ 3000/ 3383]
loss: 0.004626  [ 3100/ 3383]
loss: 0.065111  [ 3200/ 3383]
loss: 0.002768  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.003676  [    0/ 3383]
loss: 0.005928  [  100/ 3383]
loss: 0.005328  [  200/ 3383]
loss: 0.002440  [  300/ 3383]
loss: 0.002516  [  400/ 3383]
loss: 0.004204  [  500/ 3383]
loss: 0.001057  [  600/ 3383]
loss: 0.001771  [  700/ 3383]
loss: 0.007304  [  800/ 3383]
loss: 0.001412  [  900/ 3383]
loss: 0.091576  [ 1000/ 3383]
loss: 0.057865  [ 1100/ 3383]
loss: 0.024391  [ 1200/ 3383]
loss: 0.009327  [ 1300/ 3383]
loss: 0.004160  [ 1400/ 3383]
loss: 0.014986  [ 1500/ 3383]
loss: 0.002573  [ 1600/ 3383]
loss: 0.001556  [ 1700/ 3383]
loss: 0.011286  [ 1800/ 3383]
loss: 0.013960  [ 1900/ 3383]
loss: 0.002969  [ 2000/ 3383]
loss: 0.003420  [ 2100/ 3383]
loss: 0.008350  [ 2200/ 3383]
loss: 0.001761  [ 2300/ 3383]
loss: 0.003738  [ 2400/ 3383]
loss: 0.022727  [ 2500/ 3383]
loss: 0.001056  [ 2600/ 3383]
loss: 0.002861  [ 2700/ 3383]
loss: 0.006208  [ 2800/ 3383]
loss: 0.006315  [ 2900/ 3383]
loss: 0.002877  [ 3000/ 3383]
loss: 0.004587  [ 3100/ 3383]
loss: 0.065032  [ 3200/ 3383]
loss: 0.002768  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [-2.161525  -9.2258415]
[2 1 2 ... 0 1 2]
[0 2 0 ... 1 2 0]
Cluster 0 Occurrences: 1115; KMEANS: 1243
Cluster 1 Occurrences: 1113; KMEANS: 1010
Cluster 2 Occurrences: 1155; KMEANS: 1130
Centroids: [[-0.41242594, -4.683461], [-1.6595156, -5.301722], [-2.7570832, -9.988928]]
Centroids: [[-2.7760034, -10.024572], [-0.39978084, -4.0810556], [-1.4486516, -5.3784757]]
Contingency Matrix: 
[[  39  807  269]
 [  53  203  857]
 [1151    0    4]]
[[-1, 807, 269], [-1, 203, 857], [-1, -1, -1]]
[[-1, 807, -1], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 1: 2, 0: 1}
New Contingency Matrix: 
[[ 807  269   39]
 [ 203  857   53]
 [   0    4 1151]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [807, 857, 1151], Sum: 2815
All_Elements: [807, 269, 39, 203, 857, 53, 0, 4, 1151], Sum: 3383
Accuracy: 0.8321016848950635
Done!
