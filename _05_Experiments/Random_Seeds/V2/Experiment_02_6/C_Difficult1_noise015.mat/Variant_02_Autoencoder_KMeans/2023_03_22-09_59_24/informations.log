Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Difficult1_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_59_24
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000020686474080>
Sampling rate: 24000.0
Raw: [ 0.04887081  0.02693095 -0.0154249  ... -0.09301659 -0.11629005
 -0.14613101]
Times: [    340     491     641 ... 1439047 1439065 1439816]
Cluster: [1 1 1 ... 3 2 2]
Number of different clusters:  3
Number of Spikes: 3472
First aligned Spike Frame: [ 0.12751554  0.12305882  0.10482977  0.09479529  0.10214978  0.11675932
  0.11777927  0.09307299  0.04670706 -0.00574343 -0.06143573 -0.14637617
 -0.20942665 -0.00208103  0.52241508  0.81651544  0.46446121 -0.19226425
 -0.60927882 -0.6713583  -0.57871227 -0.49011309 -0.4269388  -0.3668903
 -0.30523219 -0.24747124 -0.19738203 -0.15189972 -0.10449507 -0.05533325
 -0.01452429  0.01008816  0.02570853  0.04365027  0.06334113  0.07980397
  0.08484457  0.07688513  0.06142919  0.04320028  0.02240626  0.00477291
 -0.00393242 -0.00135684  0.00575182  0.0026944  -0.01541647]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1172
Cluster 2, Occurrences: 1141
<torch.utils.data.dataloader.DataLoader object at 0x00000206899FF0F0>
Epoch 1
-------------------------------
loss: 0.105401  [    0/ 3472]
loss: 0.200070  [  100/ 3472]
loss: 0.062434  [  200/ 3472]
loss: 0.029031  [  300/ 3472]
loss: 0.046458  [  400/ 3472]
loss: 0.016188  [  500/ 3472]
loss: 0.024033  [  600/ 3472]
loss: 0.021044  [  700/ 3472]
loss: 0.043954  [  800/ 3472]
loss: 0.031503  [  900/ 3472]
loss: 0.017276  [ 1000/ 3472]
loss: 0.030796  [ 1100/ 3472]
loss: 0.027238  [ 1200/ 3472]
loss: 0.024674  [ 1300/ 3472]
loss: 0.016757  [ 1400/ 3472]
loss: 0.084046  [ 1500/ 3472]
loss: 0.025323  [ 1600/ 3472]
loss: 0.010823  [ 1700/ 3472]
loss: 0.023273  [ 1800/ 3472]
loss: 0.176614  [ 1900/ 3472]
loss: 0.046102  [ 2000/ 3472]
loss: 0.009648  [ 2100/ 3472]
loss: 0.011571  [ 2200/ 3472]
loss: 0.018964  [ 2300/ 3472]
loss: 0.054664  [ 2400/ 3472]
loss: 0.019833  [ 2500/ 3472]
loss: 0.036658  [ 2600/ 3472]
loss: 0.021314  [ 2700/ 3472]
loss: 0.016329  [ 2800/ 3472]
loss: 0.027618  [ 2900/ 3472]
loss: 0.009394  [ 3000/ 3472]
loss: 0.022707  [ 3100/ 3472]
loss: 0.012740  [ 3200/ 3472]
loss: 0.015547  [ 3300/ 3472]
loss: 0.019502  [ 3400/ 3472]
Epoch 2
-------------------------------
loss: 0.014746  [    0/ 3472]
loss: 0.009324  [  100/ 3472]
loss: 0.007083  [  200/ 3472]
loss: 0.022968  [  300/ 3472]
loss: 0.029015  [  400/ 3472]
loss: 0.013970  [  500/ 3472]
loss: 0.020758  [  600/ 3472]
loss: 0.006367  [  700/ 3472]
loss: 0.027866  [  800/ 3472]
loss: 0.031543  [  900/ 3472]
loss: 0.014458  [ 1000/ 3472]
loss: 0.021874  [ 1100/ 3472]
loss: 0.017971  [ 1200/ 3472]
loss: 0.020913  [ 1300/ 3472]
loss: 0.005205  [ 1400/ 3472]
loss: 0.058614  [ 1500/ 3472]
loss: 0.015502  [ 1600/ 3472]
loss: 0.006167  [ 1700/ 3472]
loss: 0.010393  [ 1800/ 3472]
loss: 0.172416  [ 1900/ 3472]
loss: 0.033510  [ 2000/ 3472]
loss: 0.006543  [ 2100/ 3472]
loss: 0.010932  [ 2200/ 3472]
loss: 0.016139  [ 2300/ 3472]
loss: 0.042841  [ 2400/ 3472]
loss: 0.015522  [ 2500/ 3472]
loss: 0.027115  [ 2600/ 3472]
loss: 0.014418  [ 2700/ 3472]
loss: 0.011906  [ 2800/ 3472]
loss: 0.018365  [ 2900/ 3472]
loss: 0.009432  [ 3000/ 3472]
loss: 0.020548  [ 3100/ 3472]
loss: 0.014249  [ 3200/ 3472]
loss: 0.010158  [ 3300/ 3472]
loss: 0.013563  [ 3400/ 3472]
Epoch 3
-------------------------------
loss: 0.020677  [    0/ 3472]
loss: 0.006610  [  100/ 3472]
loss: 0.008466  [  200/ 3472]
loss: 0.021283  [  300/ 3472]
loss: 0.022239  [  400/ 3472]
loss: 0.015297  [  500/ 3472]
loss: 0.018606  [  600/ 3472]
loss: 0.002719  [  700/ 3472]
loss: 0.029290  [  800/ 3472]
loss: 0.031185  [  900/ 3472]
loss: 0.013624  [ 1000/ 3472]
loss: 0.018816  [ 1100/ 3472]
loss: 0.017088  [ 1200/ 3472]
loss: 0.020178  [ 1300/ 3472]
loss: 0.002691  [ 1400/ 3472]
loss: 0.052269  [ 1500/ 3472]
loss: 0.018998  [ 1600/ 3472]
loss: 0.008946  [ 1700/ 3472]
loss: 0.007799  [ 1800/ 3472]
loss: 0.168459  [ 1900/ 3472]
loss: 0.031974  [ 2000/ 3472]
loss: 0.005743  [ 2100/ 3472]
loss: 0.010851  [ 2200/ 3472]
loss: 0.010429  [ 2300/ 3472]
loss: 0.025962  [ 2400/ 3472]
loss: 0.012122  [ 2500/ 3472]
loss: 0.023808  [ 2600/ 3472]
loss: 0.009686  [ 2700/ 3472]
loss: 0.014299  [ 2800/ 3472]
loss: 0.020639  [ 2900/ 3472]
loss: 0.009021  [ 3000/ 3472]
loss: 0.023786  [ 3100/ 3472]
loss: 0.014575  [ 3200/ 3472]
loss: 0.007134  [ 3300/ 3472]
loss: 0.008953  [ 3400/ 3472]
Epoch 4
-------------------------------
loss: 0.020582  [    0/ 3472]
loss: 0.005907  [  100/ 3472]
loss: 0.009109  [  200/ 3472]
loss: 0.019807  [  300/ 3472]
loss: 0.016035  [  400/ 3472]
loss: 0.016199  [  500/ 3472]
loss: 0.015156  [  600/ 3472]
loss: 0.002172  [  700/ 3472]
loss: 0.032200  [  800/ 3472]
loss: 0.030584  [  900/ 3472]
loss: 0.012175  [ 1000/ 3472]
loss: 0.019475  [ 1100/ 3472]
loss: 0.019192  [ 1200/ 3472]
loss: 0.015450  [ 1300/ 3472]
loss: 0.002224  [ 1400/ 3472]
loss: 0.047535  [ 1500/ 3472]
loss: 0.020848  [ 1600/ 3472]
loss: 0.011008  [ 1700/ 3472]
loss: 0.013102  [ 1800/ 3472]
loss: 0.154972  [ 1900/ 3472]
loss: 0.037100  [ 2000/ 3472]
loss: 0.007749  [ 2100/ 3472]
loss: 0.010862  [ 2200/ 3472]
loss: 0.005953  [ 2300/ 3472]
loss: 0.013611  [ 2400/ 3472]
loss: 0.011004  [ 2500/ 3472]
loss: 0.020822  [ 2600/ 3472]
loss: 0.008517  [ 2700/ 3472]
loss: 0.019823  [ 2800/ 3472]
loss: 0.025165  [ 2900/ 3472]
loss: 0.008604  [ 3000/ 3472]
loss: 0.025310  [ 3100/ 3472]
loss: 0.014428  [ 3200/ 3472]
loss: 0.006457  [ 3300/ 3472]
loss: 0.007519  [ 3400/ 3472]
Epoch 5
-------------------------------
loss: 0.016208  [    0/ 3472]
loss: 0.006213  [  100/ 3472]
loss: 0.009438  [  200/ 3472]
loss: 0.019005  [  300/ 3472]
loss: 0.011048  [  400/ 3472]
loss: 0.016371  [  500/ 3472]
loss: 0.012886  [  600/ 3472]
loss: 0.003202  [  700/ 3472]
loss: 0.034427  [  800/ 3472]
loss: 0.029418  [  900/ 3472]
loss: 0.011320  [ 1000/ 3472]
loss: 0.022022  [ 1100/ 3472]
loss: 0.021404  [ 1200/ 3472]
loss: 0.010767  [ 1300/ 3472]
loss: 0.002536  [ 1400/ 3472]
loss: 0.042713  [ 1500/ 3472]
loss: 0.020303  [ 1600/ 3472]
loss: 0.011403  [ 1700/ 3472]
loss: 0.020054  [ 1800/ 3472]
loss: 0.143529  [ 1900/ 3472]
loss: 0.042203  [ 2000/ 3472]
loss: 0.010309  [ 2100/ 3472]
loss: 0.010885  [ 2200/ 3472]
loss: 0.004647  [ 2300/ 3472]
loss: 0.009186  [ 2400/ 3472]
loss: 0.011477  [ 2500/ 3472]
loss: 0.018609  [ 2600/ 3472]
loss: 0.009270  [ 2700/ 3472]
loss: 0.023581  [ 2800/ 3472]
loss: 0.027775  [ 2900/ 3472]
loss: 0.008397  [ 3000/ 3472]
loss: 0.024661  [ 3100/ 3472]
loss: 0.014322  [ 3200/ 3472]
loss: 0.006868  [ 3300/ 3472]
loss: 0.007692  [ 3400/ 3472]
Epoch 6
-------------------------------
loss: 0.012503  [    0/ 3472]
loss: 0.006572  [  100/ 3472]
loss: 0.009615  [  200/ 3472]
loss: 0.018770  [  300/ 3472]
loss: 0.008677  [  400/ 3472]
loss: 0.016060  [  500/ 3472]
loss: 0.012234  [  600/ 3472]
loss: 0.004118  [  700/ 3472]
loss: 0.035122  [  800/ 3472]
loss: 0.028811  [  900/ 3472]
loss: 0.010875  [ 1000/ 3472]
loss: 0.024007  [ 1100/ 3472]
loss: 0.022636  [ 1200/ 3472]
loss: 0.008150  [ 1300/ 3472]
loss: 0.002926  [ 1400/ 3472]
loss: 0.040159  [ 1500/ 3472]
loss: 0.019367  [ 1600/ 3472]
loss: 0.011128  [ 1700/ 3472]
loss: 0.024124  [ 1800/ 3472]
loss: 0.136854  [ 1900/ 3472]
loss: 0.046014  [ 2000/ 3472]
loss: 0.011840  [ 2100/ 3472]
loss: 0.010895  [ 2200/ 3472]
loss: 0.004582  [ 2300/ 3472]
loss: 0.008334  [ 2400/ 3472]
loss: 0.012165  [ 2500/ 3472]
loss: 0.017532  [ 2600/ 3472]
loss: 0.010152  [ 2700/ 3472]
loss: 0.025178  [ 2800/ 3472]
loss: 0.028526  [ 2900/ 3472]
loss: 0.008285  [ 3000/ 3472]
loss: 0.023705  [ 3100/ 3472]
loss: 0.014226  [ 3200/ 3472]
loss: 0.007247  [ 3300/ 3472]
loss: 0.008061  [ 3400/ 3472]
Epoch 7
-------------------------------
loss: 0.010607  [    0/ 3472]
loss: 0.006650  [  100/ 3472]
loss: 0.009683  [  200/ 3472]
loss: 0.018726  [  300/ 3472]
loss: 0.007667  [  400/ 3472]
loss: 0.015772  [  500/ 3472]
loss: 0.012363  [  600/ 3472]
loss: 0.004673  [  700/ 3472]
loss: 0.035990  [  800/ 3472]
loss: 0.028350  [  900/ 3472]
loss: 0.010677  [ 1000/ 3472]
loss: 0.025041  [ 1100/ 3472]
loss: 0.023226  [ 1200/ 3472]
loss: 0.006988  [ 1300/ 3472]
loss: 0.003632  [ 1400/ 3472]
loss: 0.038337  [ 1500/ 3472]
loss: 0.018695  [ 1600/ 3472]
loss: 0.010907  [ 1700/ 3472]
loss: 0.026364  [ 1800/ 3472]
loss: 0.134010  [ 1900/ 3472]
loss: 0.047492  [ 2000/ 3472]
loss: 0.012659  [ 2100/ 3472]
loss: 0.011043  [ 2200/ 3472]
loss: 0.004725  [ 2300/ 3472]
loss: 0.008287  [ 2400/ 3472]
loss: 0.012664  [ 2500/ 3472]
loss: 0.016784  [ 2600/ 3472]
loss: 0.010762  [ 2700/ 3472]
loss: 0.026129  [ 2800/ 3472]
loss: 0.028772  [ 2900/ 3472]
loss: 0.008301  [ 3000/ 3472]
loss: 0.023215  [ 3100/ 3472]
loss: 0.013881  [ 3200/ 3472]
loss: 0.007504  [ 3300/ 3472]
loss: 0.008214  [ 3400/ 3472]
Epoch 8
-------------------------------
loss: 0.009706  [    0/ 3472]
loss: 0.006644  [  100/ 3472]
loss: 0.009814  [  200/ 3472]
loss: 0.018827  [  300/ 3472]
loss: 0.007338  [  400/ 3472]
loss: 0.015637  [  500/ 3472]
loss: 0.012618  [  600/ 3472]
loss: 0.004958  [  700/ 3472]
loss: 0.035996  [  800/ 3472]
loss: 0.028131  [  900/ 3472]
loss: 0.010691  [ 1000/ 3472]
loss: 0.025604  [ 1100/ 3472]
loss: 0.023493  [ 1200/ 3472]
loss: 0.006373  [ 1300/ 3472]
loss: 0.003718  [ 1400/ 3472]
loss: 0.037615  [ 1500/ 3472]
loss: 0.018293  [ 1600/ 3472]
loss: 0.010761  [ 1700/ 3472]
loss: 0.027403  [ 1800/ 3472]
loss: 0.132358  [ 1900/ 3472]
loss: 0.048877  [ 2000/ 3472]
loss: 0.013052  [ 2100/ 3472]
loss: 0.010968  [ 2200/ 3472]
loss: 0.004873  [ 2300/ 3472]
loss: 0.008275  [ 2400/ 3472]
loss: 0.013037  [ 2500/ 3472]
loss: 0.016652  [ 2600/ 3472]
loss: 0.011091  [ 2700/ 3472]
loss: 0.026561  [ 2800/ 3472]
loss: 0.028834  [ 2900/ 3472]
loss: 0.008281  [ 3000/ 3472]
loss: 0.023289  [ 3100/ 3472]
loss: 0.013734  [ 3200/ 3472]
loss: 0.007678  [ 3300/ 3472]
loss: 0.008381  [ 3400/ 3472]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3472
First Spike after testing: [ 0.19013576 -2.3442178 ]
[0 0 0 ... 2 1 1]
[1 1 0 ... 0 0 0]
Cluster 0 Occurrences: 1159; KMEANS: 1478
Cluster 1 Occurrences: 1172; KMEANS: 1154
Cluster 2 Occurrences: 1141; KMEANS: 840
Centroids: [[0.4982117, -3.2224767], [1.1890974, -3.652102], [0.69304025, -5.4042616]]
Centroids: [[0.85488415, -4.192139], [0.81053966, -2.534369], [0.6701509, -6.024683]]
Contingency Matrix: 
[[433 674  52]
 [617 450 105]
 [428  30 683]]
[[433, 674, -1], [617, 450, -1], [-1, -1, -1]]
[[-1, -1, -1], [617, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 1, 1: 0}
New Contingency Matrix: 
[[674 433  52]
 [450 617 105]
 [ 30 428 683]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [674, 617, 683], Sum: 1974
All_Elements: [674, 433, 52, 450, 617, 105, 30, 428, 683], Sum: 3472
Accuracy: 0.5685483870967742
Done!
