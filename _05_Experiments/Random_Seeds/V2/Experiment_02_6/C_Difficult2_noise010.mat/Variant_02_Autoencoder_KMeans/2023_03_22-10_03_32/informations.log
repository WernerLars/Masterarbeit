Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_03_32
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000206367E5278>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x00000206899FF240>
Epoch 1
-------------------------------
loss: 0.138777  [    0/ 3462]
loss: 0.135855  [  100/ 3462]
loss: 0.110126  [  200/ 3462]
loss: 0.117657  [  300/ 3462]
loss: 0.029334  [  400/ 3462]
loss: 0.017073  [  500/ 3462]
loss: 0.036884  [  600/ 3462]
loss: 0.055965  [  700/ 3462]
loss: 0.012289  [  800/ 3462]
loss: 0.018132  [  900/ 3462]
loss: 0.021024  [ 1000/ 3462]
loss: 0.054156  [ 1100/ 3462]
loss: 0.015293  [ 1200/ 3462]
loss: 0.004343  [ 1300/ 3462]
loss: 0.012956  [ 1400/ 3462]
loss: 0.014588  [ 1500/ 3462]
loss: 0.007594  [ 1600/ 3462]
loss: 0.004176  [ 1700/ 3462]
loss: 0.013952  [ 1800/ 3462]
loss: 0.008907  [ 1900/ 3462]
loss: 0.011555  [ 2000/ 3462]
loss: 0.066272  [ 2100/ 3462]
loss: 0.009768  [ 2200/ 3462]
loss: 0.006297  [ 2300/ 3462]
loss: 0.012970  [ 2400/ 3462]
loss: 0.005609  [ 2500/ 3462]
loss: 0.020042  [ 2600/ 3462]
loss: 0.006776  [ 2700/ 3462]
loss: 0.012237  [ 2800/ 3462]
loss: 0.016567  [ 2900/ 3462]
loss: 0.111410  [ 3000/ 3462]
loss: 0.006213  [ 3100/ 3462]
loss: 0.012420  [ 3200/ 3462]
loss: 0.136131  [ 3300/ 3462]
loss: 0.009338  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.002304  [    0/ 3462]
loss: 0.013434  [  100/ 3462]
loss: 0.013833  [  200/ 3462]
loss: 0.009828  [  300/ 3462]
loss: 0.009962  [  400/ 3462]
loss: 0.008236  [  500/ 3462]
loss: 0.007859  [  600/ 3462]
loss: 0.016178  [  700/ 3462]
loss: 0.011359  [  800/ 3462]
loss: 0.013960  [  900/ 3462]
loss: 0.007226  [ 1000/ 3462]
loss: 0.031873  [ 1100/ 3462]
loss: 0.013956  [ 1200/ 3462]
loss: 0.003916  [ 1300/ 3462]
loss: 0.004553  [ 1400/ 3462]
loss: 0.004304  [ 1500/ 3462]
loss: 0.007770  [ 1600/ 3462]
loss: 0.005082  [ 1700/ 3462]
loss: 0.015528  [ 1800/ 3462]
loss: 0.008746  [ 1900/ 3462]
loss: 0.010300  [ 2000/ 3462]
loss: 0.059062  [ 2100/ 3462]
loss: 0.002306  [ 2200/ 3462]
loss: 0.008225  [ 2300/ 3462]
loss: 0.011934  [ 2400/ 3462]
loss: 0.005875  [ 2500/ 3462]
loss: 0.019174  [ 2600/ 3462]
loss: 0.005206  [ 2700/ 3462]
loss: 0.007179  [ 2800/ 3462]
loss: 0.014853  [ 2900/ 3462]
loss: 0.112134  [ 3000/ 3462]
loss: 0.005930  [ 3100/ 3462]
loss: 0.008875  [ 3200/ 3462]
loss: 0.130964  [ 3300/ 3462]
loss: 0.007556  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.002268  [    0/ 3462]
loss: 0.013725  [  100/ 3462]
loss: 0.013202  [  200/ 3462]
loss: 0.006582  [  300/ 3462]
loss: 0.008375  [  400/ 3462]
loss: 0.007960  [  500/ 3462]
loss: 0.004854  [  600/ 3462]
loss: 0.014026  [  700/ 3462]
loss: 0.010867  [  800/ 3462]
loss: 0.012805  [  900/ 3462]
loss: 0.006287  [ 1000/ 3462]
loss: 0.029863  [ 1100/ 3462]
loss: 0.013978  [ 1200/ 3462]
loss: 0.003856  [ 1300/ 3462]
loss: 0.004540  [ 1400/ 3462]
loss: 0.002992  [ 1500/ 3462]
loss: 0.007781  [ 1600/ 3462]
loss: 0.004960  [ 1700/ 3462]
loss: 0.016146  [ 1800/ 3462]
loss: 0.008934  [ 1900/ 3462]
loss: 0.010082  [ 2000/ 3462]
loss: 0.055726  [ 2100/ 3462]
loss: 0.001958  [ 2200/ 3462]
loss: 0.008668  [ 2300/ 3462]
loss: 0.011671  [ 2400/ 3462]
loss: 0.005881  [ 2500/ 3462]
loss: 0.019012  [ 2600/ 3462]
loss: 0.005469  [ 2700/ 3462]
loss: 0.006555  [ 2800/ 3462]
loss: 0.014740  [ 2900/ 3462]
loss: 0.113753  [ 3000/ 3462]
loss: 0.005980  [ 3100/ 3462]
loss: 0.007831  [ 3200/ 3462]
loss: 0.129774  [ 3300/ 3462]
loss: 0.006798  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.002209  [    0/ 3462]
loss: 0.013820  [  100/ 3462]
loss: 0.013237  [  200/ 3462]
loss: 0.006316  [  300/ 3462]
loss: 0.006837  [  400/ 3462]
loss: 0.008088  [  500/ 3462]
loss: 0.003903  [  600/ 3462]
loss: 0.013557  [  700/ 3462]
loss: 0.010408  [  800/ 3462]
loss: 0.012191  [  900/ 3462]
loss: 0.006668  [ 1000/ 3462]
loss: 0.028281  [ 1100/ 3462]
loss: 0.013700  [ 1200/ 3462]
loss: 0.003639  [ 1300/ 3462]
loss: 0.004540  [ 1400/ 3462]
loss: 0.002882  [ 1500/ 3462]
loss: 0.007819  [ 1600/ 3462]
loss: 0.004760  [ 1700/ 3462]
loss: 0.016430  [ 1800/ 3462]
loss: 0.009079  [ 1900/ 3462]
loss: 0.009568  [ 2000/ 3462]
loss: 0.054174  [ 2100/ 3462]
loss: 0.001873  [ 2200/ 3462]
loss: 0.008914  [ 2300/ 3462]
loss: 0.011632  [ 2400/ 3462]
loss: 0.005830  [ 2500/ 3462]
loss: 0.018321  [ 2600/ 3462]
loss: 0.005516  [ 2700/ 3462]
loss: 0.006094  [ 2800/ 3462]
loss: 0.015040  [ 2900/ 3462]
loss: 0.114763  [ 3000/ 3462]
loss: 0.006190  [ 3100/ 3462]
loss: 0.007813  [ 3200/ 3462]
loss: 0.129272  [ 3300/ 3462]
loss: 0.006946  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.002148  [    0/ 3462]
loss: 0.013941  [  100/ 3462]
loss: 0.013489  [  200/ 3462]
loss: 0.005872  [  300/ 3462]
loss: 0.006406  [  400/ 3462]
loss: 0.007892  [  500/ 3462]
loss: 0.003306  [  600/ 3462]
loss: 0.013666  [  700/ 3462]
loss: 0.010266  [  800/ 3462]
loss: 0.012043  [  900/ 3462]
loss: 0.006903  [ 1000/ 3462]
loss: 0.027517  [ 1100/ 3462]
loss: 0.013998  [ 1200/ 3462]
loss: 0.003371  [ 1300/ 3462]
loss: 0.004509  [ 1400/ 3462]
loss: 0.003223  [ 1500/ 3462]
loss: 0.007924  [ 1600/ 3462]
loss: 0.004517  [ 1700/ 3462]
loss: 0.018887  [ 1800/ 3462]
loss: 0.008758  [ 1900/ 3462]
loss: 0.009169  [ 2000/ 3462]
loss: 0.053344  [ 2100/ 3462]
loss: 0.001602  [ 2200/ 3462]
loss: 0.008974  [ 2300/ 3462]
loss: 0.011528  [ 2400/ 3462]
loss: 0.005853  [ 2500/ 3462]
loss: 0.017140  [ 2600/ 3462]
loss: 0.005615  [ 2700/ 3462]
loss: 0.005822  [ 2800/ 3462]
loss: 0.015260  [ 2900/ 3462]
loss: 0.115994  [ 3000/ 3462]
loss: 0.006442  [ 3100/ 3462]
loss: 0.007334  [ 3200/ 3462]
loss: 0.129914  [ 3300/ 3462]
loss: 0.006849  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.002135  [    0/ 3462]
loss: 0.013383  [  100/ 3462]
loss: 0.013584  [  200/ 3462]
loss: 0.005876  [  300/ 3462]
loss: 0.006161  [  400/ 3462]
loss: 0.007786  [  500/ 3462]
loss: 0.002687  [  600/ 3462]
loss: 0.013893  [  700/ 3462]
loss: 0.010378  [  800/ 3462]
loss: 0.012229  [  900/ 3462]
loss: 0.007454  [ 1000/ 3462]
loss: 0.026444  [ 1100/ 3462]
loss: 0.014262  [ 1200/ 3462]
loss: 0.003319  [ 1300/ 3462]
loss: 0.004591  [ 1400/ 3462]
loss: 0.003820  [ 1500/ 3462]
loss: 0.007940  [ 1600/ 3462]
loss: 0.004601  [ 1700/ 3462]
loss: 0.018385  [ 1800/ 3462]
loss: 0.008754  [ 1900/ 3462]
loss: 0.008615  [ 2000/ 3462]
loss: 0.052823  [ 2100/ 3462]
loss: 0.001652  [ 2200/ 3462]
loss: 0.009044  [ 2300/ 3462]
loss: 0.011587  [ 2400/ 3462]
loss: 0.005893  [ 2500/ 3462]
loss: 0.016550  [ 2600/ 3462]
loss: 0.005717  [ 2700/ 3462]
loss: 0.005664  [ 2800/ 3462]
loss: 0.015628  [ 2900/ 3462]
loss: 0.116859  [ 3000/ 3462]
loss: 0.006892  [ 3100/ 3462]
loss: 0.007643  [ 3200/ 3462]
loss: 0.130531  [ 3300/ 3462]
loss: 0.007097  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.002093  [    0/ 3462]
loss: 0.013382  [  100/ 3462]
loss: 0.013155  [  200/ 3462]
loss: 0.006065  [  300/ 3462]
loss: 0.005817  [  400/ 3462]
loss: 0.007697  [  500/ 3462]
loss: 0.002411  [  600/ 3462]
loss: 0.014196  [  700/ 3462]
loss: 0.010421  [  800/ 3462]
loss: 0.012201  [  900/ 3462]
loss: 0.007737  [ 1000/ 3462]
loss: 0.025919  [ 1100/ 3462]
loss: 0.014223  [ 1200/ 3462]
loss: 0.003279  [ 1300/ 3462]
loss: 0.004551  [ 1400/ 3462]
loss: 0.004017  [ 1500/ 3462]
loss: 0.007962  [ 1600/ 3462]
loss: 0.004631  [ 1700/ 3462]
loss: 0.018256  [ 1800/ 3462]
loss: 0.008747  [ 1900/ 3462]
loss: 0.008298  [ 2000/ 3462]
loss: 0.052654  [ 2100/ 3462]
loss: 0.001649  [ 2200/ 3462]
loss: 0.009108  [ 2300/ 3462]
loss: 0.011511  [ 2400/ 3462]
loss: 0.005963  [ 2500/ 3462]
loss: 0.016457  [ 2600/ 3462]
loss: 0.005689  [ 2700/ 3462]
loss: 0.005766  [ 2800/ 3462]
loss: 0.015662  [ 2900/ 3462]
loss: 0.117405  [ 3000/ 3462]
loss: 0.006719  [ 3100/ 3462]
loss: 0.007367  [ 3200/ 3462]
loss: 0.131342  [ 3300/ 3462]
loss: 0.007099  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.002089  [    0/ 3462]
loss: 0.013489  [  100/ 3462]
loss: 0.013191  [  200/ 3462]
loss: 0.006317  [  300/ 3462]
loss: 0.006147  [  400/ 3462]
loss: 0.007490  [  500/ 3462]
loss: 0.001963  [  600/ 3462]
loss: 0.014422  [  700/ 3462]
loss: 0.010503  [  800/ 3462]
loss: 0.012324  [  900/ 3462]
loss: 0.008158  [ 1000/ 3462]
loss: 0.024897  [ 1100/ 3462]
loss: 0.014460  [ 1200/ 3462]
loss: 0.003241  [ 1300/ 3462]
loss: 0.004586  [ 1400/ 3462]
loss: 0.004200  [ 1500/ 3462]
loss: 0.007924  [ 1600/ 3462]
loss: 0.004711  [ 1700/ 3462]
loss: 0.018484  [ 1800/ 3462]
loss: 0.008833  [ 1900/ 3462]
loss: 0.007995  [ 2000/ 3462]
loss: 0.052736  [ 2100/ 3462]
loss: 0.001680  [ 2200/ 3462]
loss: 0.009091  [ 2300/ 3462]
loss: 0.011541  [ 2400/ 3462]
loss: 0.006035  [ 2500/ 3462]
loss: 0.016103  [ 2600/ 3462]
loss: 0.005641  [ 2700/ 3462]
loss: 0.005768  [ 2800/ 3462]
loss: 0.015730  [ 2900/ 3462]
loss: 0.117849  [ 3000/ 3462]
loss: 0.007093  [ 3100/ 3462]
loss: 0.007428  [ 3200/ 3462]
loss: 0.132201  [ 3300/ 3462]
loss: 0.007429  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [ 3.693172  -3.5108728]
[0 2 2 ... 0 1 2]
[1 0 0 ... 1 2 0]
Cluster 0 Occurrences: 1187; KMEANS: 1083
Cluster 1 Occurrences: 1136; KMEANS: 1260
Cluster 2 Occurrences: 1139; KMEANS: 1119
Centroids: [[3.736956, -2.8319185], [-0.02895775, -5.3900385], [2.4518998, -4.7871857]]
Centroids: [[2.7679703, -5.2760644], [3.393383, -2.5821], [-0.06951761, -5.3348994]]
Contingency Matrix: 
[[ 147 1040    0]
 [  18    0 1118]
 [ 918  220    1]]
[[147, 1040, -1], [-1, -1, -1], [918, 220, -1]]
[[-1, -1, -1], [-1, -1, -1], [918, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 2, 0: 1, 2: 0}
New Contingency Matrix: 
[[1040    0  147]
 [   0 1118   18]
 [ 220    1  918]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1040, 1118, 918], Sum: 3076
All_Elements: [1040, 0, 147, 0, 1118, 18, 220, 1, 918], Sum: 3462
Accuracy: 0.8885037550548815
Done!
