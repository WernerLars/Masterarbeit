Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_53_50
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000020628C1BB38>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x0000020629A67588>
Epoch 1
-------------------------------
loss: 0.234501  [    0/ 3411]
loss: 0.193497  [  100/ 3411]
loss: 0.160978  [  200/ 3411]
loss: 0.067846  [  300/ 3411]
loss: 0.117988  [  400/ 3411]
loss: 0.036610  [  500/ 3411]
loss: 0.029010  [  600/ 3411]
loss: 0.018638  [  700/ 3411]
loss: 0.050786  [  800/ 3411]
loss: 0.060932  [  900/ 3411]
loss: 0.005986  [ 1000/ 3411]
loss: 0.051557  [ 1100/ 3411]
loss: 0.023792  [ 1200/ 3411]
loss: 0.049911  [ 1300/ 3411]
loss: 0.030258  [ 1400/ 3411]
loss: 0.070240  [ 1500/ 3411]
loss: 0.037290  [ 1600/ 3411]
loss: 0.042416  [ 1700/ 3411]
loss: 0.021218  [ 1800/ 3411]
loss: 0.003364  [ 1900/ 3411]
loss: 0.043178  [ 2000/ 3411]
loss: 0.008777  [ 2100/ 3411]
loss: 0.007801  [ 2200/ 3411]
loss: 0.162298  [ 2300/ 3411]
loss: 0.014798  [ 2400/ 3411]
loss: 0.007674  [ 2500/ 3411]
loss: 0.016621  [ 2600/ 3411]
loss: 0.007737  [ 2700/ 3411]
loss: 0.032848  [ 2800/ 3411]
loss: 0.017495  [ 2900/ 3411]
loss: 0.008578  [ 3000/ 3411]
loss: 0.007700  [ 3100/ 3411]
loss: 0.054306  [ 3200/ 3411]
loss: 0.012837  [ 3300/ 3411]
loss: 0.011417  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.015656  [    0/ 3411]
loss: 0.021633  [  100/ 3411]
loss: 0.013118  [  200/ 3411]
loss: 0.014935  [  300/ 3411]
loss: 0.029623  [  400/ 3411]
loss: 0.028058  [  500/ 3411]
loss: 0.005463  [  600/ 3411]
loss: 0.019307  [  700/ 3411]
loss: 0.036562  [  800/ 3411]
loss: 0.028074  [  900/ 3411]
loss: 0.003401  [ 1000/ 3411]
loss: 0.037763  [ 1100/ 3411]
loss: 0.021670  [ 1200/ 3411]
loss: 0.031065  [ 1300/ 3411]
loss: 0.028409  [ 1400/ 3411]
loss: 0.060349  [ 1500/ 3411]
loss: 0.032863  [ 1600/ 3411]
loss: 0.031498  [ 1700/ 3411]
loss: 0.020901  [ 1800/ 3411]
loss: 0.003479  [ 1900/ 3411]
loss: 0.040697  [ 2000/ 3411]
loss: 0.008411  [ 2100/ 3411]
loss: 0.007329  [ 2200/ 3411]
loss: 0.152195  [ 2300/ 3411]
loss: 0.014592  [ 2400/ 3411]
loss: 0.003454  [ 2500/ 3411]
loss: 0.015871  [ 2600/ 3411]
loss: 0.007250  [ 2700/ 3411]
loss: 0.029097  [ 2800/ 3411]
loss: 0.017814  [ 2900/ 3411]
loss: 0.007226  [ 3000/ 3411]
loss: 0.006338  [ 3100/ 3411]
loss: 0.035726  [ 3200/ 3411]
loss: 0.008416  [ 3300/ 3411]
loss: 0.013942  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.013847  [    0/ 3411]
loss: 0.020714  [  100/ 3411]
loss: 0.013025  [  200/ 3411]
loss: 0.014854  [  300/ 3411]
loss: 0.025311  [  400/ 3411]
loss: 0.022971  [  500/ 3411]
loss: 0.004575  [  600/ 3411]
loss: 0.015680  [  700/ 3411]
loss: 0.031179  [  800/ 3411]
loss: 0.019728  [  900/ 3411]
loss: 0.003778  [ 1000/ 3411]
loss: 0.032891  [ 1100/ 3411]
loss: 0.020560  [ 1200/ 3411]
loss: 0.021528  [ 1300/ 3411]
loss: 0.025971  [ 1400/ 3411]
loss: 0.061639  [ 1500/ 3411]
loss: 0.030950  [ 1600/ 3411]
loss: 0.032842  [ 1700/ 3411]
loss: 0.023056  [ 1800/ 3411]
loss: 0.003420  [ 1900/ 3411]
loss: 0.039100  [ 2000/ 3411]
loss: 0.008109  [ 2100/ 3411]
loss: 0.007335  [ 2200/ 3411]
loss: 0.148621  [ 2300/ 3411]
loss: 0.015323  [ 2400/ 3411]
loss: 0.003080  [ 2500/ 3411]
loss: 0.015817  [ 2600/ 3411]
loss: 0.007570  [ 2700/ 3411]
loss: 0.028998  [ 2800/ 3411]
loss: 0.017386  [ 2900/ 3411]
loss: 0.006593  [ 3000/ 3411]
loss: 0.005662  [ 3100/ 3411]
loss: 0.028819  [ 3200/ 3411]
loss: 0.008297  [ 3300/ 3411]
loss: 0.015083  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.013858  [    0/ 3411]
loss: 0.019864  [  100/ 3411]
loss: 0.013052  [  200/ 3411]
loss: 0.015273  [  300/ 3411]
loss: 0.025003  [  400/ 3411]
loss: 0.020220  [  500/ 3411]
loss: 0.004408  [  600/ 3411]
loss: 0.014635  [  700/ 3411]
loss: 0.028197  [  800/ 3411]
loss: 0.016454  [  900/ 3411]
loss: 0.003825  [ 1000/ 3411]
loss: 0.033039  [ 1100/ 3411]
loss: 0.020099  [ 1200/ 3411]
loss: 0.017575  [ 1300/ 3411]
loss: 0.024344  [ 1400/ 3411]
loss: 0.062242  [ 1500/ 3411]
loss: 0.030278  [ 1600/ 3411]
loss: 0.034990  [ 1700/ 3411]
loss: 0.024001  [ 1800/ 3411]
loss: 0.003467  [ 1900/ 3411]
loss: 0.037735  [ 2000/ 3411]
loss: 0.007894  [ 2100/ 3411]
loss: 0.007454  [ 2200/ 3411]
loss: 0.147743  [ 2300/ 3411]
loss: 0.015813  [ 2400/ 3411]
loss: 0.003146  [ 2500/ 3411]
loss: 0.015972  [ 2600/ 3411]
loss: 0.007739  [ 2700/ 3411]
loss: 0.029066  [ 2800/ 3411]
loss: 0.017092  [ 2900/ 3411]
loss: 0.006573  [ 3000/ 3411]
loss: 0.005405  [ 3100/ 3411]
loss: 0.025775  [ 3200/ 3411]
loss: 0.008253  [ 3300/ 3411]
loss: 0.015478  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.013967  [    0/ 3411]
loss: 0.019386  [  100/ 3411]
loss: 0.013037  [  200/ 3411]
loss: 0.015406  [  300/ 3411]
loss: 0.024927  [  400/ 3411]
loss: 0.018785  [  500/ 3411]
loss: 0.004408  [  600/ 3411]
loss: 0.015678  [  700/ 3411]
loss: 0.026743  [  800/ 3411]
loss: 0.015125  [  900/ 3411]
loss: 0.003878  [ 1000/ 3411]
loss: 0.034617  [ 1100/ 3411]
loss: 0.019878  [ 1200/ 3411]
loss: 0.015645  [ 1300/ 3411]
loss: 0.023380  [ 1400/ 3411]
loss: 0.062315  [ 1500/ 3411]
loss: 0.030036  [ 1600/ 3411]
loss: 0.036482  [ 1700/ 3411]
loss: 0.024312  [ 1800/ 3411]
loss: 0.003453  [ 1900/ 3411]
loss: 0.036999  [ 2000/ 3411]
loss: 0.007948  [ 2100/ 3411]
loss: 0.007552  [ 2200/ 3411]
loss: 0.147623  [ 2300/ 3411]
loss: 0.016035  [ 2400/ 3411]
loss: 0.003258  [ 2500/ 3411]
loss: 0.015989  [ 2600/ 3411]
loss: 0.007839  [ 2700/ 3411]
loss: 0.029291  [ 2800/ 3411]
loss: 0.016662  [ 2900/ 3411]
loss: 0.006592  [ 3000/ 3411]
loss: 0.005357  [ 3100/ 3411]
loss: 0.024324  [ 3200/ 3411]
loss: 0.008219  [ 3300/ 3411]
loss: 0.015600  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.014196  [    0/ 3411]
loss: 0.019106  [  100/ 3411]
loss: 0.013016  [  200/ 3411]
loss: 0.015591  [  300/ 3411]
loss: 0.025014  [  400/ 3411]
loss: 0.018100  [  500/ 3411]
loss: 0.004510  [  600/ 3411]
loss: 0.013988  [  700/ 3411]
loss: 0.025965  [  800/ 3411]
loss: 0.014413  [  900/ 3411]
loss: 0.003896  [ 1000/ 3411]
loss: 0.033746  [ 1100/ 3411]
loss: 0.019746  [ 1200/ 3411]
loss: 0.014648  [ 1300/ 3411]
loss: 0.022801  [ 1400/ 3411]
loss: 0.062393  [ 1500/ 3411]
loss: 0.029863  [ 1600/ 3411]
loss: 0.037083  [ 1700/ 3411]
loss: 0.024507  [ 1800/ 3411]
loss: 0.003537  [ 1900/ 3411]
loss: 0.036529  [ 2000/ 3411]
loss: 0.007704  [ 2100/ 3411]
loss: 0.008017  [ 2200/ 3411]
loss: 0.147416  [ 2300/ 3411]
loss: 0.016264  [ 2400/ 3411]
loss: 0.003404  [ 2500/ 3411]
loss: 0.016037  [ 2600/ 3411]
loss: 0.007890  [ 2700/ 3411]
loss: 0.029475  [ 2800/ 3411]
loss: 0.016704  [ 2900/ 3411]
loss: 0.006560  [ 3000/ 3411]
loss: 0.005278  [ 3100/ 3411]
loss: 0.023663  [ 3200/ 3411]
loss: 0.008204  [ 3300/ 3411]
loss: 0.015580  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.014034  [    0/ 3411]
loss: 0.018893  [  100/ 3411]
loss: 0.012969  [  200/ 3411]
loss: 0.015604  [  300/ 3411]
loss: 0.025249  [  400/ 3411]
loss: 0.017674  [  500/ 3411]
loss: 0.004568  [  600/ 3411]
loss: 0.015272  [  700/ 3411]
loss: 0.025427  [  800/ 3411]
loss: 0.014100  [  900/ 3411]
loss: 0.003914  [ 1000/ 3411]
loss: 0.035849  [ 1100/ 3411]
loss: 0.019665  [ 1200/ 3411]
loss: 0.014031  [ 1300/ 3411]
loss: 0.022407  [ 1400/ 3411]
loss: 0.062506  [ 1500/ 3411]
loss: 0.029772  [ 1600/ 3411]
loss: 0.037626  [ 1700/ 3411]
loss: 0.024620  [ 1800/ 3411]
loss: 0.003413  [ 1900/ 3411]
loss: 0.036282  [ 2000/ 3411]
loss: 0.007898  [ 2100/ 3411]
loss: 0.007465  [ 2200/ 3411]
loss: 0.147378  [ 2300/ 3411]
loss: 0.016348  [ 2400/ 3411]
loss: 0.003482  [ 2500/ 3411]
loss: 0.016044  [ 2600/ 3411]
loss: 0.007914  [ 2700/ 3411]
loss: 0.029575  [ 2800/ 3411]
loss: 0.016165  [ 2900/ 3411]
loss: 0.006557  [ 3000/ 3411]
loss: 0.005241  [ 3100/ 3411]
loss: 0.023278  [ 3200/ 3411]
loss: 0.008210  [ 3300/ 3411]
loss: 0.015702  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.014112  [    0/ 3411]
loss: 0.018906  [  100/ 3411]
loss: 0.012926  [  200/ 3411]
loss: 0.015605  [  300/ 3411]
loss: 0.025171  [  400/ 3411]
loss: 0.017485  [  500/ 3411]
loss: 0.004571  [  600/ 3411]
loss: 0.014008  [  700/ 3411]
loss: 0.025181  [  800/ 3411]
loss: 0.013903  [  900/ 3411]
loss: 0.003927  [ 1000/ 3411]
loss: 0.034343  [ 1100/ 3411]
loss: 0.019643  [ 1200/ 3411]
loss: 0.013772  [ 1300/ 3411]
loss: 0.022317  [ 1400/ 3411]
loss: 0.062827  [ 1500/ 3411]
loss: 0.029921  [ 1600/ 3411]
loss: 0.037633  [ 1700/ 3411]
loss: 0.024584  [ 1800/ 3411]
loss: 0.003459  [ 1900/ 3411]
loss: 0.036215  [ 2000/ 3411]
loss: 0.007715  [ 2100/ 3411]
loss: 0.007477  [ 2200/ 3411]
loss: 0.147277  [ 2300/ 3411]
loss: 0.016471  [ 2400/ 3411]
loss: 0.003512  [ 2500/ 3411]
loss: 0.016053  [ 2600/ 3411]
loss: 0.007943  [ 2700/ 3411]
loss: 0.029598  [ 2800/ 3411]
loss: 0.015982  [ 2900/ 3411]
loss: 0.006489  [ 3000/ 3411]
loss: 0.005205  [ 3100/ 3411]
loss: 0.023142  [ 3200/ 3411]
loss: 0.008211  [ 3300/ 3411]
loss: 0.015665  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [ -4.330745 -10.999166]
[0 2 0 ... 1 1 2]
[2 1 1 ... 0 0 1]
Cluster 0 Occurrences: 1181; KMEANS: 1264
Cluster 1 Occurrences: 1098; KMEANS: 1235
Cluster 2 Occurrences: 1132; KMEANS: 912
Centroids: [[-3.883328, -10.036933], [-1.4552703, -4.5422974], [-0.20004936, -6.4074044]]
Centroids: [[-0.3777781, -3.8020046], [-1.694039, -7.3686037], [-4.211517, -11.171363]]
Contingency Matrix: 
[[ 10 353 818]
 [753 303  42]
 [501 579  52]]
[[-1, -1, -1], [753, 303, -1], [501, 579, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, 579, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 1: 0, 2: 1}
New Contingency Matrix: 
[[818  10 353]
 [ 42 753 303]
 [ 52 501 579]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [818, 753, 579], Sum: 2150
All_Elements: [818, 10, 353, 42, 753, 303, 52, 501, 579], Sum: 3411
Accuracy: 0.6303136909997068
Done!
