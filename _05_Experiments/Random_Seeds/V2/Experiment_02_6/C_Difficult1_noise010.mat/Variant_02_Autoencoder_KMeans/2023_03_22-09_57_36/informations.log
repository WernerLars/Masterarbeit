Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Difficult1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_57_36
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002068DFA3F60>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
<torch.utils.data.dataloader.DataLoader object at 0x0000020685D55E48>
Epoch 1
-------------------------------
loss: 0.177522  [    0/ 3448]
loss: 0.102406  [  100/ 3448]
loss: 0.037106  [  200/ 3448]
loss: 0.045194  [  300/ 3448]
loss: 0.021923  [  400/ 3448]
loss: 0.015375  [  500/ 3448]
loss: 0.023693  [  600/ 3448]
loss: 0.011297  [  700/ 3448]
loss: 0.015329  [  800/ 3448]
loss: 0.037695  [  900/ 3448]
loss: 0.090042  [ 1000/ 3448]
loss: 0.014938  [ 1100/ 3448]
loss: 0.017431  [ 1200/ 3448]
loss: 0.130453  [ 1300/ 3448]
loss: 0.013467  [ 1400/ 3448]
loss: 0.037516  [ 1500/ 3448]
loss: 0.029762  [ 1600/ 3448]
loss: 0.020533  [ 1700/ 3448]
loss: 0.017830  [ 1800/ 3448]
loss: 0.023313  [ 1900/ 3448]
loss: 0.010719  [ 2000/ 3448]
loss: 0.006054  [ 2100/ 3448]
loss: 0.016238  [ 2200/ 3448]
loss: 0.008459  [ 2300/ 3448]
loss: 0.023558  [ 2400/ 3448]
loss: 0.012703  [ 2500/ 3448]
loss: 0.012158  [ 2600/ 3448]
loss: 0.012952  [ 2700/ 3448]
loss: 0.008299  [ 2800/ 3448]
loss: 0.008193  [ 2900/ 3448]
loss: 0.004634  [ 3000/ 3448]
loss: 0.013493  [ 3100/ 3448]
loss: 0.011320  [ 3200/ 3448]
loss: 0.008777  [ 3300/ 3448]
loss: 0.007667  [ 3400/ 3448]
Epoch 2
-------------------------------
loss: 0.018383  [    0/ 3448]
loss: 0.005899  [  100/ 3448]
loss: 0.002095  [  200/ 3448]
loss: 0.013965  [  300/ 3448]
loss: 0.008225  [  400/ 3448]
loss: 0.008343  [  500/ 3448]
loss: 0.009139  [  600/ 3448]
loss: 0.007983  [  700/ 3448]
loss: 0.006222  [  800/ 3448]
loss: 0.012712  [  900/ 3448]
loss: 0.085640  [ 1000/ 3448]
loss: 0.014535  [ 1100/ 3448]
loss: 0.008808  [ 1200/ 3448]
loss: 0.122005  [ 1300/ 3448]
loss: 0.006643  [ 1400/ 3448]
loss: 0.024456  [ 1500/ 3448]
loss: 0.008211  [ 1600/ 3448]
loss: 0.010243  [ 1700/ 3448]
loss: 0.008525  [ 1800/ 3448]
loss: 0.019317  [ 1900/ 3448]
loss: 0.008004  [ 2000/ 3448]
loss: 0.002631  [ 2100/ 3448]
loss: 0.004891  [ 2200/ 3448]
loss: 0.006058  [ 2300/ 3448]
loss: 0.007939  [ 2400/ 3448]
loss: 0.009570  [ 2500/ 3448]
loss: 0.011284  [ 2600/ 3448]
loss: 0.009948  [ 2700/ 3448]
loss: 0.006592  [ 2800/ 3448]
loss: 0.002666  [ 2900/ 3448]
loss: 0.004111  [ 3000/ 3448]
loss: 0.011575  [ 3100/ 3448]
loss: 0.010222  [ 3200/ 3448]
loss: 0.010984  [ 3300/ 3448]
loss: 0.006884  [ 3400/ 3448]
Epoch 3
-------------------------------
loss: 0.018416  [    0/ 3448]
loss: 0.006759  [  100/ 3448]
loss: 0.001564  [  200/ 3448]
loss: 0.005845  [  300/ 3448]
loss: 0.007955  [  400/ 3448]
loss: 0.011780  [  500/ 3448]
loss: 0.007288  [  600/ 3448]
loss: 0.007630  [  700/ 3448]
loss: 0.004190  [  800/ 3448]
loss: 0.006462  [  900/ 3448]
loss: 0.085754  [ 1000/ 3448]
loss: 0.014673  [ 1100/ 3448]
loss: 0.008587  [ 1200/ 3448]
loss: 0.124914  [ 1300/ 3448]
loss: 0.006302  [ 1400/ 3448]
loss: 0.021748  [ 1500/ 3448]
loss: 0.004481  [ 1600/ 3448]
loss: 0.010482  [ 1700/ 3448]
loss: 0.007661  [ 1800/ 3448]
loss: 0.018598  [ 1900/ 3448]
loss: 0.007835  [ 2000/ 3448]
loss: 0.002921  [ 2100/ 3448]
loss: 0.005165  [ 2200/ 3448]
loss: 0.005799  [ 2300/ 3448]
loss: 0.008140  [ 2400/ 3448]
loss: 0.008748  [ 2500/ 3448]
loss: 0.011972  [ 2600/ 3448]
loss: 0.009440  [ 2700/ 3448]
loss: 0.006594  [ 2800/ 3448]
loss: 0.002563  [ 2900/ 3448]
loss: 0.003722  [ 3000/ 3448]
loss: 0.012453  [ 3100/ 3448]
loss: 0.011107  [ 3200/ 3448]
loss: 0.011197  [ 3300/ 3448]
loss: 0.006742  [ 3400/ 3448]
Epoch 4
-------------------------------
loss: 0.018912  [    0/ 3448]
loss: 0.006955  [  100/ 3448]
loss: 0.001448  [  200/ 3448]
loss: 0.004609  [  300/ 3448]
loss: 0.007554  [  400/ 3448]
loss: 0.012489  [  500/ 3448]
loss: 0.007121  [  600/ 3448]
loss: 0.007689  [  700/ 3448]
loss: 0.003862  [  800/ 3448]
loss: 0.005635  [  900/ 3448]
loss: 0.085438  [ 1000/ 3448]
loss: 0.014674  [ 1100/ 3448]
loss: 0.008724  [ 1200/ 3448]
loss: 0.125259  [ 1300/ 3448]
loss: 0.006377  [ 1400/ 3448]
loss: 0.020920  [ 1500/ 3448]
loss: 0.003921  [ 1600/ 3448]
loss: 0.010835  [ 1700/ 3448]
loss: 0.007572  [ 1800/ 3448]
loss: 0.018034  [ 1900/ 3448]
loss: 0.007805  [ 2000/ 3448]
loss: 0.003064  [ 2100/ 3448]
loss: 0.005315  [ 2200/ 3448]
loss: 0.005726  [ 2300/ 3448]
loss: 0.008109  [ 2400/ 3448]
loss: 0.008608  [ 2500/ 3448]
loss: 0.012160  [ 2600/ 3448]
loss: 0.009250  [ 2700/ 3448]
loss: 0.006666  [ 2800/ 3448]
loss: 0.002528  [ 2900/ 3448]
loss: 0.003707  [ 3000/ 3448]
loss: 0.012847  [ 3100/ 3448]
loss: 0.011283  [ 3200/ 3448]
loss: 0.011215  [ 3300/ 3448]
loss: 0.006690  [ 3400/ 3448]
Epoch 5
-------------------------------
loss: 0.019057  [    0/ 3448]
loss: 0.007000  [  100/ 3448]
loss: 0.001459  [  200/ 3448]
loss: 0.004127  [  300/ 3448]
loss: 0.007349  [  400/ 3448]
loss: 0.012631  [  500/ 3448]
loss: 0.007015  [  600/ 3448]
loss: 0.007700  [  700/ 3448]
loss: 0.003772  [  800/ 3448]
loss: 0.005552  [  900/ 3448]
loss: 0.084688  [ 1000/ 3448]
loss: 0.014711  [ 1100/ 3448]
loss: 0.008697  [ 1200/ 3448]
loss: 0.125735  [ 1300/ 3448]
loss: 0.006435  [ 1400/ 3448]
loss: 0.020341  [ 1500/ 3448]
loss: 0.003806  [ 1600/ 3448]
loss: 0.011139  [ 1700/ 3448]
loss: 0.007641  [ 1800/ 3448]
loss: 0.018080  [ 1900/ 3448]
loss: 0.007824  [ 2000/ 3448]
loss: 0.003152  [ 2100/ 3448]
loss: 0.005324  [ 2200/ 3448]
loss: 0.005737  [ 2300/ 3448]
loss: 0.008017  [ 2400/ 3448]
loss: 0.008470  [ 2500/ 3448]
loss: 0.012257  [ 2600/ 3448]
loss: 0.009279  [ 2700/ 3448]
loss: 0.006769  [ 2800/ 3448]
loss: 0.002516  [ 2900/ 3448]
loss: 0.003718  [ 3000/ 3448]
loss: 0.013056  [ 3100/ 3448]
loss: 0.011995  [ 3200/ 3448]
loss: 0.011216  [ 3300/ 3448]
loss: 0.006697  [ 3400/ 3448]
Epoch 6
-------------------------------
loss: 0.019198  [    0/ 3448]
loss: 0.007002  [  100/ 3448]
loss: 0.001619  [  200/ 3448]
loss: 0.003843  [  300/ 3448]
loss: 0.007293  [  400/ 3448]
loss: 0.012749  [  500/ 3448]
loss: 0.006877  [  600/ 3448]
loss: 0.007670  [  700/ 3448]
loss: 0.003721  [  800/ 3448]
loss: 0.005649  [  900/ 3448]
loss: 0.084896  [ 1000/ 3448]
loss: 0.014726  [ 1100/ 3448]
loss: 0.008548  [ 1200/ 3448]
loss: 0.125620  [ 1300/ 3448]
loss: 0.006543  [ 1400/ 3448]
loss: 0.019795  [ 1500/ 3448]
loss: 0.003773  [ 1600/ 3448]
loss: 0.011574  [ 1700/ 3448]
loss: 0.007736  [ 1800/ 3448]
loss: 0.017768  [ 1900/ 3448]
loss: 0.007942  [ 2000/ 3448]
loss: 0.003232  [ 2100/ 3448]
loss: 0.005229  [ 2200/ 3448]
loss: 0.005733  [ 2300/ 3448]
loss: 0.008121  [ 2400/ 3448]
loss: 0.008362  [ 2500/ 3448]
loss: 0.012299  [ 2600/ 3448]
loss: 0.009353  [ 2700/ 3448]
loss: 0.006812  [ 2800/ 3448]
loss: 0.002513  [ 2900/ 3448]
loss: 0.003753  [ 3000/ 3448]
loss: 0.013208  [ 3100/ 3448]
loss: 0.011869  [ 3200/ 3448]
loss: 0.011179  [ 3300/ 3448]
loss: 0.006646  [ 3400/ 3448]
Epoch 7
-------------------------------
loss: 0.019229  [    0/ 3448]
loss: 0.006956  [  100/ 3448]
loss: 0.001659  [  200/ 3448]
loss: 0.003655  [  300/ 3448]
loss: 0.007369  [  400/ 3448]
loss: 0.012813  [  500/ 3448]
loss: 0.006840  [  600/ 3448]
loss: 0.007652  [  700/ 3448]
loss: 0.003857  [  800/ 3448]
loss: 0.006529  [  900/ 3448]
loss: 0.084644  [ 1000/ 3448]
loss: 0.014873  [ 1100/ 3448]
loss: 0.008539  [ 1200/ 3448]
loss: 0.125452  [ 1300/ 3448]
loss: 0.006550  [ 1400/ 3448]
loss: 0.019744  [ 1500/ 3448]
loss: 0.003808  [ 1600/ 3448]
loss: 0.011579  [ 1700/ 3448]
loss: 0.007840  [ 1800/ 3448]
loss: 0.017924  [ 1900/ 3448]
loss: 0.007900  [ 2000/ 3448]
loss: 0.003240  [ 2100/ 3448]
loss: 0.005232  [ 2200/ 3448]
loss: 0.005800  [ 2300/ 3448]
loss: 0.007998  [ 2400/ 3448]
loss: 0.008332  [ 2500/ 3448]
loss: 0.012330  [ 2600/ 3448]
loss: 0.009387  [ 2700/ 3448]
loss: 0.006840  [ 2800/ 3448]
loss: 0.002487  [ 2900/ 3448]
loss: 0.003741  [ 3000/ 3448]
loss: 0.013253  [ 3100/ 3448]
loss: 0.012159  [ 3200/ 3448]
loss: 0.011173  [ 3300/ 3448]
loss: 0.006652  [ 3400/ 3448]
Epoch 8
-------------------------------
loss: 0.019279  [    0/ 3448]
loss: 0.006975  [  100/ 3448]
loss: 0.001708  [  200/ 3448]
loss: 0.003621  [  300/ 3448]
loss: 0.007312  [  400/ 3448]
loss: 0.012820  [  500/ 3448]
loss: 0.006768  [  600/ 3448]
loss: 0.007653  [  700/ 3448]
loss: 0.003656  [  800/ 3448]
loss: 0.005533  [  900/ 3448]
loss: 0.084814  [ 1000/ 3448]
loss: 0.014742  [ 1100/ 3448]
loss: 0.008494  [ 1200/ 3448]
loss: 0.125546  [ 1300/ 3448]
loss: 0.006587  [ 1400/ 3448]
loss: 0.019539  [ 1500/ 3448]
loss: 0.003788  [ 1600/ 3448]
loss: 0.011722  [ 1700/ 3448]
loss: 0.007795  [ 1800/ 3448]
loss: 0.017774  [ 1900/ 3448]
loss: 0.007927  [ 2000/ 3448]
loss: 0.003270  [ 2100/ 3448]
loss: 0.005217  [ 2200/ 3448]
loss: 0.005771  [ 2300/ 3448]
loss: 0.008067  [ 2400/ 3448]
loss: 0.008293  [ 2500/ 3448]
loss: 0.012339  [ 2600/ 3448]
loss: 0.009416  [ 2700/ 3448]
loss: 0.006856  [ 2800/ 3448]
loss: 0.002497  [ 2900/ 3448]
loss: 0.003744  [ 3000/ 3448]
loss: 0.013325  [ 3100/ 3448]
loss: 0.011835  [ 3200/ 3448]
loss: 0.011189  [ 3300/ 3448]
loss: 0.006622  [ 3400/ 3448]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3448
First Spike after testing: [ -2.7620635 -10.085469 ]
[2 2 2 ... 1 0 2]
[2 1 1 ... 2 0 1]
Cluster 0 Occurrences: 1164; KMEANS: 1138
Cluster 1 Occurrences: 1155; KMEANS: 1046
Cluster 2 Occurrences: 1129; KMEANS: 1264
Centroids: [[-1.3430734, -6.519685], [-2.2769406, -6.9671674], [-3.8929048, -12.5092]]
Centroids: [[-1.1441691, -4.991905], [-4.0946436, -13.077737], [-2.3759747, -8.226881]]
Contingency Matrix: 
[[638  45 481]
 [498  62 595]
 [  2 939 188]]
[[638, -1, 481], [498, -1, 595], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 595], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 0, 1: 2}
New Contingency Matrix: 
[[638 481  45]
 [498 595  62]
 [  2 188 939]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [638, 595, 939], Sum: 2172
All_Elements: [638, 481, 45, 498, 595, 62, 2, 188, 939], Sum: 3448
Accuracy: 0.6299303944315545
Done!
