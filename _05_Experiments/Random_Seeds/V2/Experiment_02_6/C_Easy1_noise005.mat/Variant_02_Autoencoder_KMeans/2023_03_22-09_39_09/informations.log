Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_39_09
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000020628D3BE48>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x0000020628D95240>
Epoch 1
-------------------------------
loss: 0.109415  [    0/ 3514]
loss: 0.301300  [  100/ 3514]
loss: 0.080713  [  200/ 3514]
loss: 0.070018  [  300/ 3514]
loss: 0.019157  [  400/ 3514]
loss: 0.007599  [  500/ 3514]
loss: 0.009520  [  600/ 3514]
loss: 0.003523  [  700/ 3514]
loss: 0.028394  [  800/ 3514]
loss: 0.020512  [  900/ 3514]
loss: 0.006077  [ 1000/ 3514]
loss: 0.087207  [ 1100/ 3514]
loss: 0.002337  [ 1200/ 3514]
loss: 0.002122  [ 1300/ 3514]
loss: 0.087728  [ 1400/ 3514]
loss: 0.000498  [ 1500/ 3514]
loss: 0.004724  [ 1600/ 3514]
loss: 0.006096  [ 1700/ 3514]
loss: 0.226261  [ 1800/ 3514]
loss: 0.007669  [ 1900/ 3514]
loss: 0.002245  [ 2000/ 3514]
loss: 0.005636  [ 2100/ 3514]
loss: 0.000678  [ 2200/ 3514]
loss: 0.001883  [ 2300/ 3514]
loss: 0.002238  [ 2400/ 3514]
loss: 0.006973  [ 2500/ 3514]
loss: 0.003957  [ 2600/ 3514]
loss: 0.003085  [ 2700/ 3514]
loss: 0.007536  [ 2800/ 3514]
loss: 0.002095  [ 2900/ 3514]
loss: 0.009371  [ 3000/ 3514]
loss: 0.001729  [ 3100/ 3514]
loss: 0.001808  [ 3200/ 3514]
loss: 0.008429  [ 3300/ 3514]
loss: 0.006213  [ 3400/ 3514]
loss: 0.004024  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.006387  [    0/ 3514]
loss: 0.002451  [  100/ 3514]
loss: 0.006643  [  200/ 3514]
loss: 0.003347  [  300/ 3514]
loss: 0.004448  [  400/ 3514]
loss: 0.005837  [  500/ 3514]
loss: 0.008997  [  600/ 3514]
loss: 0.002730  [  700/ 3514]
loss: 0.001132  [  800/ 3514]
loss: 0.004149  [  900/ 3514]
loss: 0.005537  [ 1000/ 3514]
loss: 0.088338  [ 1100/ 3514]
loss: 0.002371  [ 1200/ 3514]
loss: 0.001882  [ 1300/ 3514]
loss: 0.084325  [ 1400/ 3514]
loss: 0.001137  [ 1500/ 3514]
loss: 0.004956  [ 1600/ 3514]
loss: 0.005535  [ 1700/ 3514]
loss: 0.201989  [ 1800/ 3514]
loss: 0.007094  [ 1900/ 3514]
loss: 0.002400  [ 2000/ 3514]
loss: 0.006195  [ 2100/ 3514]
loss: 0.000750  [ 2200/ 3514]
loss: 0.001601  [ 2300/ 3514]
loss: 0.002458  [ 2400/ 3514]
loss: 0.006847  [ 2500/ 3514]
loss: 0.004266  [ 2600/ 3514]
loss: 0.002232  [ 2700/ 3514]
loss: 0.007667  [ 2800/ 3514]
loss: 0.001394  [ 2900/ 3514]
loss: 0.005434  [ 3000/ 3514]
loss: 0.001625  [ 3100/ 3514]
loss: 0.001997  [ 3200/ 3514]
loss: 0.006529  [ 3300/ 3514]
loss: 0.005867  [ 3400/ 3514]
loss: 0.003283  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.001706  [    0/ 3514]
loss: 0.002181  [  100/ 3514]
loss: 0.006862  [  200/ 3514]
loss: 0.003206  [  300/ 3514]
loss: 0.004023  [  400/ 3514]
loss: 0.004529  [  500/ 3514]
loss: 0.008120  [  600/ 3514]
loss: 0.002889  [  700/ 3514]
loss: 0.001002  [  800/ 3514]
loss: 0.004070  [  900/ 3514]
loss: 0.005530  [ 1000/ 3514]
loss: 0.089512  [ 1100/ 3514]
loss: 0.002371  [ 1200/ 3514]
loss: 0.002135  [ 1300/ 3514]
loss: 0.089436  [ 1400/ 3514]
loss: 0.001201  [ 1500/ 3514]
loss: 0.005307  [ 1600/ 3514]
loss: 0.005167  [ 1700/ 3514]
loss: 0.182322  [ 1800/ 3514]
loss: 0.005384  [ 1900/ 3514]
loss: 0.001785  [ 2000/ 3514]
loss: 0.005786  [ 2100/ 3514]
loss: 0.000785  [ 2200/ 3514]
loss: 0.001530  [ 2300/ 3514]
loss: 0.002112  [ 2400/ 3514]
loss: 0.006524  [ 2500/ 3514]
loss: 0.004554  [ 2600/ 3514]
loss: 0.002157  [ 2700/ 3514]
loss: 0.007815  [ 2800/ 3514]
loss: 0.001729  [ 2900/ 3514]
loss: 0.005268  [ 3000/ 3514]
loss: 0.001769  [ 3100/ 3514]
loss: 0.002032  [ 3200/ 3514]
loss: 0.005335  [ 3300/ 3514]
loss: 0.005506  [ 3400/ 3514]
loss: 0.003051  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.001683  [    0/ 3514]
loss: 0.002000  [  100/ 3514]
loss: 0.006900  [  200/ 3514]
loss: 0.003175  [  300/ 3514]
loss: 0.003772  [  400/ 3514]
loss: 0.004916  [  500/ 3514]
loss: 0.007548  [  600/ 3514]
loss: 0.003202  [  700/ 3514]
loss: 0.000972  [  800/ 3514]
loss: 0.004008  [  900/ 3514]
loss: 0.005215  [ 1000/ 3514]
loss: 0.090050  [ 1100/ 3514]
loss: 0.002227  [ 1200/ 3514]
loss: 0.002192  [ 1300/ 3514]
loss: 0.087987  [ 1400/ 3514]
loss: 0.000969  [ 1500/ 3514]
loss: 0.005649  [ 1600/ 3514]
loss: 0.005246  [ 1700/ 3514]
loss: 0.173624  [ 1800/ 3514]
loss: 0.005005  [ 1900/ 3514]
loss: 0.001436  [ 2000/ 3514]
loss: 0.005653  [ 2100/ 3514]
loss: 0.000738  [ 2200/ 3514]
loss: 0.001504  [ 2300/ 3514]
loss: 0.002137  [ 2400/ 3514]
loss: 0.006664  [ 2500/ 3514]
loss: 0.004496  [ 2600/ 3514]
loss: 0.002168  [ 2700/ 3514]
loss: 0.007690  [ 2800/ 3514]
loss: 0.002216  [ 2900/ 3514]
loss: 0.005507  [ 3000/ 3514]
loss: 0.001735  [ 3100/ 3514]
loss: 0.001931  [ 3200/ 3514]
loss: 0.005086  [ 3300/ 3514]
loss: 0.005283  [ 3400/ 3514]
loss: 0.002864  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.001811  [    0/ 3514]
loss: 0.001793  [  100/ 3514]
loss: 0.006557  [  200/ 3514]
loss: 0.003156  [  300/ 3514]
loss: 0.003803  [  400/ 3514]
loss: 0.005239  [  500/ 3514]
loss: 0.007285  [  600/ 3514]
loss: 0.002998  [  700/ 3514]
loss: 0.000911  [  800/ 3514]
loss: 0.003990  [  900/ 3514]
loss: 0.005568  [ 1000/ 3514]
loss: 0.090030  [ 1100/ 3514]
loss: 0.002178  [ 1200/ 3514]
loss: 0.002141  [ 1300/ 3514]
loss: 0.087707  [ 1400/ 3514]
loss: 0.000830  [ 1500/ 3514]
loss: 0.005927  [ 1600/ 3514]
loss: 0.005174  [ 1700/ 3514]
loss: 0.170877  [ 1800/ 3514]
loss: 0.004700  [ 1900/ 3514]
loss: 0.001184  [ 2000/ 3514]
loss: 0.005955  [ 2100/ 3514]
loss: 0.000788  [ 2200/ 3514]
loss: 0.001553  [ 2300/ 3514]
loss: 0.002327  [ 2400/ 3514]
loss: 0.006413  [ 2500/ 3514]
loss: 0.004702  [ 2600/ 3514]
loss: 0.002456  [ 2700/ 3514]
loss: 0.007493  [ 2800/ 3514]
loss: 0.002236  [ 2900/ 3514]
loss: 0.005260  [ 3000/ 3514]
loss: 0.002103  [ 3100/ 3514]
loss: 0.001858  [ 3200/ 3514]
loss: 0.005112  [ 3300/ 3514]
loss: 0.004935  [ 3400/ 3514]
loss: 0.002712  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.001970  [    0/ 3514]
loss: 0.001616  [  100/ 3514]
loss: 0.006588  [  200/ 3514]
loss: 0.003219  [  300/ 3514]
loss: 0.003747  [  400/ 3514]
loss: 0.005308  [  500/ 3514]
loss: 0.007252  [  600/ 3514]
loss: 0.002984  [  700/ 3514]
loss: 0.000988  [  800/ 3514]
loss: 0.003877  [  900/ 3514]
loss: 0.005621  [ 1000/ 3514]
loss: 0.090033  [ 1100/ 3514]
loss: 0.001394  [ 1200/ 3514]
loss: 0.002097  [ 1300/ 3514]
loss: 0.091333  [ 1400/ 3514]
loss: 0.000658  [ 1500/ 3514]
loss: 0.006250  [ 1600/ 3514]
loss: 0.005116  [ 1700/ 3514]
loss: 0.167181  [ 1800/ 3514]
loss: 0.004556  [ 1900/ 3514]
loss: 0.001237  [ 2000/ 3514]
loss: 0.005727  [ 2100/ 3514]
loss: 0.000743  [ 2200/ 3514]
loss: 0.001446  [ 2300/ 3514]
loss: 0.002256  [ 2400/ 3514]
loss: 0.006114  [ 2500/ 3514]
loss: 0.004787  [ 2600/ 3514]
loss: 0.002168  [ 2700/ 3514]
loss: 0.007342  [ 2800/ 3514]
loss: 0.002646  [ 2900/ 3514]
loss: 0.004993  [ 3000/ 3514]
loss: 0.002311  [ 3100/ 3514]
loss: 0.001864  [ 3200/ 3514]
loss: 0.005375  [ 3300/ 3514]
loss: 0.004865  [ 3400/ 3514]
loss: 0.002613  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.002237  [    0/ 3514]
loss: 0.001544  [  100/ 3514]
loss: 0.006452  [  200/ 3514]
loss: 0.003270  [  300/ 3514]
loss: 0.003887  [  400/ 3514]
loss: 0.005578  [  500/ 3514]
loss: 0.006967  [  600/ 3514]
loss: 0.002879  [  700/ 3514]
loss: 0.001344  [  800/ 3514]
loss: 0.003739  [  900/ 3514]
loss: 0.005506  [ 1000/ 3514]
loss: 0.090519  [ 1100/ 3514]
loss: 0.001104  [ 1200/ 3514]
loss: 0.002051  [ 1300/ 3514]
loss: 0.090937  [ 1400/ 3514]
loss: 0.000655  [ 1500/ 3514]
loss: 0.006328  [ 1600/ 3514]
loss: 0.005158  [ 1700/ 3514]
loss: 0.169568  [ 1800/ 3514]
loss: 0.004298  [ 1900/ 3514]
loss: 0.001201  [ 2000/ 3514]
loss: 0.005909  [ 2100/ 3514]
loss: 0.000736  [ 2200/ 3514]
loss: 0.001388  [ 2300/ 3514]
loss: 0.002100  [ 2400/ 3514]
loss: 0.006150  [ 2500/ 3514]
loss: 0.004593  [ 2600/ 3514]
loss: 0.001969  [ 2700/ 3514]
loss: 0.007171  [ 2800/ 3514]
loss: 0.002105  [ 2900/ 3514]
loss: 0.004742  [ 3000/ 3514]
loss: 0.001606  [ 3100/ 3514]
loss: 0.001873  [ 3200/ 3514]
loss: 0.005424  [ 3300/ 3514]
loss: 0.004841  [ 3400/ 3514]
loss: 0.002599  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.002492  [    0/ 3514]
loss: 0.001420  [  100/ 3514]
loss: 0.006397  [  200/ 3514]
loss: 0.003208  [  300/ 3514]
loss: 0.003980  [  400/ 3514]
loss: 0.006264  [  500/ 3514]
loss: 0.006875  [  600/ 3514]
loss: 0.002686  [  700/ 3514]
loss: 0.001366  [  800/ 3514]
loss: 0.003694  [  900/ 3514]
loss: 0.005558  [ 1000/ 3514]
loss: 0.091652  [ 1100/ 3514]
loss: 0.000831  [ 1200/ 3514]
loss: 0.002045  [ 1300/ 3514]
loss: 0.089375  [ 1400/ 3514]
loss: 0.000623  [ 1500/ 3514]
loss: 0.006124  [ 1600/ 3514]
loss: 0.005240  [ 1700/ 3514]
loss: 0.173199  [ 1800/ 3514]
loss: 0.003922  [ 1900/ 3514]
loss: 0.001130  [ 2000/ 3514]
loss: 0.005691  [ 2100/ 3514]
loss: 0.000619  [ 2200/ 3514]
loss: 0.001430  [ 2300/ 3514]
loss: 0.001696  [ 2400/ 3514]
loss: 0.006217  [ 2500/ 3514]
loss: 0.004287  [ 2600/ 3514]
loss: 0.001818  [ 2700/ 3514]
loss: 0.007026  [ 2800/ 3514]
loss: 0.001565  [ 2900/ 3514]
loss: 0.004515  [ 3000/ 3514]
loss: 0.001313  [ 3100/ 3514]
loss: 0.001903  [ 3200/ 3514]
loss: 0.005301  [ 3300/ 3514]
loss: 0.004524  [ 3400/ 3514]
loss: 0.002497  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [-0.49452138  1.3589928 ]
[1 0 2 ... 1 0 1]
[1 2 0 ... 1 2 1]
Cluster 0 Occurrences: 1165; KMEANS: 1217
Cluster 1 Occurrences: 1157; KMEANS: 1146
Cluster 2 Occurrences: 1192; KMEANS: 1151
Centroids: [[0.9738085, -1.3497338], [-0.28198943, 1.425722], [-1.7385737, -1.9789686]]
Centroids: [[-1.7367494, -1.9715383], [-0.26109466, 1.446073], [0.9979874, -1.3376613]]
Contingency Matrix: 
[[  13    4 1148]
 [  12 1142    3]
 [1192    0    0]]
[[-1, 4, 1148], [-1, 1142, 3], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1142, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1148    4   13]
 [   3 1142   12]
 [   0    0 1192]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1148, 1142, 1192], Sum: 3482
All_Elements: [1148, 4, 13, 3, 1142, 12, 0, 0, 1192], Sum: 3514
Accuracy: 0.9908935685828116
Done!
