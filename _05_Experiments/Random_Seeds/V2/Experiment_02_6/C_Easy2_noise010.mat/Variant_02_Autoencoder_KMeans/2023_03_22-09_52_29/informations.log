Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Easy2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_52_29
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002068094B160>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
<torch.utils.data.dataloader.DataLoader object at 0x0000020629A673C8>
Epoch 1
-------------------------------
loss: 0.179570  [    0/ 3520]
loss: 0.116215  [  100/ 3520]
loss: 0.267863  [  200/ 3520]
loss: 0.045921  [  300/ 3520]
loss: 0.139624  [  400/ 3520]
loss: 0.317408  [  500/ 3520]
loss: 0.020329  [  600/ 3520]
loss: 0.075561  [  700/ 3520]
loss: 0.006793  [  800/ 3520]
loss: 0.022348  [  900/ 3520]
loss: 0.054483  [ 1000/ 3520]
loss: 0.030365  [ 1100/ 3520]
loss: 0.021260  [ 1200/ 3520]
loss: 0.045711  [ 1300/ 3520]
loss: 0.022740  [ 1400/ 3520]
loss: 0.015852  [ 1500/ 3520]
loss: 0.015420  [ 1600/ 3520]
loss: 0.013057  [ 1700/ 3520]
loss: 0.099604  [ 1800/ 3520]
loss: 0.008109  [ 1900/ 3520]
loss: 0.012800  [ 2000/ 3520]
loss: 0.010117  [ 2100/ 3520]
loss: 0.005936  [ 2200/ 3520]
loss: 0.097856  [ 2300/ 3520]
loss: 0.007298  [ 2400/ 3520]
loss: 0.013464  [ 2500/ 3520]
loss: 0.014025  [ 2600/ 3520]
loss: 0.005413  [ 2700/ 3520]
loss: 0.027979  [ 2800/ 3520]
loss: 0.013038  [ 2900/ 3520]
loss: 0.019751  [ 3000/ 3520]
loss: 0.011701  [ 3100/ 3520]
loss: 0.012937  [ 3200/ 3520]
loss: 0.002813  [ 3300/ 3520]
loss: 0.013839  [ 3400/ 3520]
loss: 0.020636  [ 3500/ 3520]
Epoch 2
-------------------------------
loss: 0.013413  [    0/ 3520]
loss: 0.003953  [  100/ 3520]
loss: 0.176476  [  200/ 3520]
loss: 0.007666  [  300/ 3520]
loss: 0.088575  [  400/ 3520]
loss: 0.116795  [  500/ 3520]
loss: 0.010214  [  600/ 3520]
loss: 0.008309  [  700/ 3520]
loss: 0.004717  [  800/ 3520]
loss: 0.012261  [  900/ 3520]
loss: 0.004208  [ 1000/ 3520]
loss: 0.007425  [ 1100/ 3520]
loss: 0.009354  [ 1200/ 3520]
loss: 0.014109  [ 1300/ 3520]
loss: 0.015446  [ 1400/ 3520]
loss: 0.002170  [ 1500/ 3520]
loss: 0.001663  [ 1600/ 3520]
loss: 0.001837  [ 1700/ 3520]
loss: 0.101096  [ 1800/ 3520]
loss: 0.006863  [ 1900/ 3520]
loss: 0.012956  [ 2000/ 3520]
loss: 0.007567  [ 2100/ 3520]
loss: 0.002281  [ 2200/ 3520]
loss: 0.072021  [ 2300/ 3520]
loss: 0.007969  [ 2400/ 3520]
loss: 0.007447  [ 2500/ 3520]
loss: 0.012413  [ 2600/ 3520]
loss: 0.005148  [ 2700/ 3520]
loss: 0.018202  [ 2800/ 3520]
loss: 0.007461  [ 2900/ 3520]
loss: 0.012328  [ 3000/ 3520]
loss: 0.014587  [ 3100/ 3520]
loss: 0.006002  [ 3200/ 3520]
loss: 0.003019  [ 3300/ 3520]
loss: 0.005983  [ 3400/ 3520]
loss: 0.012157  [ 3500/ 3520]
Epoch 3
-------------------------------
loss: 0.014050  [    0/ 3520]
loss: 0.002827  [  100/ 3520]
loss: 0.177069  [  200/ 3520]
loss: 0.006316  [  300/ 3520]
loss: 0.081200  [  400/ 3520]
loss: 0.126711  [  500/ 3520]
loss: 0.008210  [  600/ 3520]
loss: 0.008273  [  700/ 3520]
loss: 0.004533  [  800/ 3520]
loss: 0.010120  [  900/ 3520]
loss: 0.004180  [ 1000/ 3520]
loss: 0.007121  [ 1100/ 3520]
loss: 0.008359  [ 1200/ 3520]
loss: 0.013802  [ 1300/ 3520]
loss: 0.013507  [ 1400/ 3520]
loss: 0.001706  [ 1500/ 3520]
loss: 0.001692  [ 1600/ 3520]
loss: 0.001640  [ 1700/ 3520]
loss: 0.104330  [ 1800/ 3520]
loss: 0.006798  [ 1900/ 3520]
loss: 0.013172  [ 2000/ 3520]
loss: 0.007387  [ 2100/ 3520]
loss: 0.002119  [ 2200/ 3520]
loss: 0.075772  [ 2300/ 3520]
loss: 0.007223  [ 2400/ 3520]
loss: 0.007731  [ 2500/ 3520]
loss: 0.011671  [ 2600/ 3520]
loss: 0.004928  [ 2700/ 3520]
loss: 0.016806  [ 2800/ 3520]
loss: 0.006827  [ 2900/ 3520]
loss: 0.011914  [ 3000/ 3520]
loss: 0.015580  [ 3100/ 3520]
loss: 0.005748  [ 3200/ 3520]
loss: 0.003033  [ 3300/ 3520]
loss: 0.006185  [ 3400/ 3520]
loss: 0.012044  [ 3500/ 3520]
Epoch 4
-------------------------------
loss: 0.014425  [    0/ 3520]
loss: 0.002623  [  100/ 3520]
loss: 0.177360  [  200/ 3520]
loss: 0.006091  [  300/ 3520]
loss: 0.079536  [  400/ 3520]
loss: 0.129971  [  500/ 3520]
loss: 0.007604  [  600/ 3520]
loss: 0.008254  [  700/ 3520]
loss: 0.004535  [  800/ 3520]
loss: 0.009507  [  900/ 3520]
loss: 0.004362  [ 1000/ 3520]
loss: 0.007152  [ 1100/ 3520]
loss: 0.008060  [ 1200/ 3520]
loss: 0.013483  [ 1300/ 3520]
loss: 0.012940  [ 1400/ 3520]
loss: 0.001521  [ 1500/ 3520]
loss: 0.001595  [ 1600/ 3520]
loss: 0.001743  [ 1700/ 3520]
loss: 0.105145  [ 1800/ 3520]
loss: 0.006962  [ 1900/ 3520]
loss: 0.013044  [ 2000/ 3520]
loss: 0.007316  [ 2100/ 3520]
loss: 0.001869  [ 2200/ 3520]
loss: 0.078975  [ 2300/ 3520]
loss: 0.007276  [ 2400/ 3520]
loss: 0.007898  [ 2500/ 3520]
loss: 0.011470  [ 2600/ 3520]
loss: 0.004759  [ 2700/ 3520]
loss: 0.016367  [ 2800/ 3520]
loss: 0.006547  [ 2900/ 3520]
loss: 0.011833  [ 3000/ 3520]
loss: 0.015739  [ 3100/ 3520]
loss: 0.005758  [ 3200/ 3520]
loss: 0.002974  [ 3300/ 3520]
loss: 0.006240  [ 3400/ 3520]
loss: 0.011965  [ 3500/ 3520]
Epoch 5
-------------------------------
loss: 0.014522  [    0/ 3520]
loss: 0.002498  [  100/ 3520]
loss: 0.176861  [  200/ 3520]
loss: 0.005986  [  300/ 3520]
loss: 0.078757  [  400/ 3520]
loss: 0.131005  [  500/ 3520]
loss: 0.007368  [  600/ 3520]
loss: 0.008118  [  700/ 3520]
loss: 0.004514  [  800/ 3520]
loss: 0.009304  [  900/ 3520]
loss: 0.004250  [ 1000/ 3520]
loss: 0.007318  [ 1100/ 3520]
loss: 0.007967  [ 1200/ 3520]
loss: 0.013400  [ 1300/ 3520]
loss: 0.012660  [ 1400/ 3520]
loss: 0.001515  [ 1500/ 3520]
loss: 0.001595  [ 1600/ 3520]
loss: 0.001935  [ 1700/ 3520]
loss: 0.106047  [ 1800/ 3520]
loss: 0.006848  [ 1900/ 3520]
loss: 0.013100  [ 2000/ 3520]
loss: 0.007317  [ 2100/ 3520]
loss: 0.002024  [ 2200/ 3520]
loss: 0.077806  [ 2300/ 3520]
loss: 0.007127  [ 2400/ 3520]
loss: 0.008009  [ 2500/ 3520]
loss: 0.011166  [ 2600/ 3520]
loss: 0.004916  [ 2700/ 3520]
loss: 0.015981  [ 2800/ 3520]
loss: 0.006405  [ 2900/ 3520]
loss: 0.011764  [ 3000/ 3520]
loss: 0.016169  [ 3100/ 3520]
loss: 0.005738  [ 3200/ 3520]
loss: 0.002979  [ 3300/ 3520]
loss: 0.006299  [ 3400/ 3520]
loss: 0.011934  [ 3500/ 3520]
Epoch 6
-------------------------------
loss: 0.014537  [    0/ 3520]
loss: 0.002304  [  100/ 3520]
loss: 0.176535  [  200/ 3520]
loss: 0.005811  [  300/ 3520]
loss: 0.078276  [  400/ 3520]
loss: 0.132416  [  500/ 3520]
loss: 0.007188  [  600/ 3520]
loss: 0.008242  [  700/ 3520]
loss: 0.004429  [  800/ 3520]
loss: 0.009086  [  900/ 3520]
loss: 0.004291  [ 1000/ 3520]
loss: 0.007363  [ 1100/ 3520]
loss: 0.007789  [ 1200/ 3520]
loss: 0.012331  [ 1300/ 3520]
loss: 0.012289  [ 1400/ 3520]
loss: 0.001552  [ 1500/ 3520]
loss: 0.001612  [ 1600/ 3520]
loss: 0.001858  [ 1700/ 3520]
loss: 0.104381  [ 1800/ 3520]
loss: 0.006841  [ 1900/ 3520]
loss: 0.013146  [ 2000/ 3520]
loss: 0.007279  [ 2100/ 3520]
loss: 0.001762  [ 2200/ 3520]
loss: 0.078462  [ 2300/ 3520]
loss: 0.007323  [ 2400/ 3520]
loss: 0.007981  [ 2500/ 3520]
loss: 0.011518  [ 2600/ 3520]
loss: 0.004689  [ 2700/ 3520]
loss: 0.015922  [ 2800/ 3520]
loss: 0.006254  [ 2900/ 3520]
loss: 0.011864  [ 3000/ 3520]
loss: 0.016146  [ 3100/ 3520]
loss: 0.005778  [ 3200/ 3520]
loss: 0.002967  [ 3300/ 3520]
loss: 0.006432  [ 3400/ 3520]
loss: 0.012008  [ 3500/ 3520]
Epoch 7
-------------------------------
loss: 0.014605  [    0/ 3520]
loss: 0.002273  [  100/ 3520]
loss: 0.176909  [  200/ 3520]
loss: 0.005860  [  300/ 3520]
loss: 0.078479  [  400/ 3520]
loss: 0.131610  [  500/ 3520]
loss: 0.007214  [  600/ 3520]
loss: 0.008196  [  700/ 3520]
loss: 0.004471  [  800/ 3520]
loss: 0.009194  [  900/ 3520]
loss: 0.004264  [ 1000/ 3520]
loss: 0.007355  [ 1100/ 3520]
loss: 0.007894  [ 1200/ 3520]
loss: 0.012447  [ 1300/ 3520]
loss: 0.012506  [ 1400/ 3520]
loss: 0.001568  [ 1500/ 3520]
loss: 0.001611  [ 1600/ 3520]
loss: 0.001931  [ 1700/ 3520]
loss: 0.105810  [ 1800/ 3520]
loss: 0.006863  [ 1900/ 3520]
loss: 0.013002  [ 2000/ 3520]
loss: 0.007301  [ 2100/ 3520]
loss: 0.001918  [ 2200/ 3520]
loss: 0.078636  [ 2300/ 3520]
loss: 0.007155  [ 2400/ 3520]
loss: 0.007892  [ 2500/ 3520]
loss: 0.011329  [ 2600/ 3520]
loss: 0.004966  [ 2700/ 3520]
loss: 0.015681  [ 2800/ 3520]
loss: 0.006175  [ 2900/ 3520]
loss: 0.011755  [ 3000/ 3520]
loss: 0.016061  [ 3100/ 3520]
loss: 0.005740  [ 3200/ 3520]
loss: 0.002970  [ 3300/ 3520]
loss: 0.006419  [ 3400/ 3520]
loss: 0.011841  [ 3500/ 3520]
Epoch 8
-------------------------------
loss: 0.014515  [    0/ 3520]
loss: 0.002219  [  100/ 3520]
loss: 0.176705  [  200/ 3520]
loss: 0.005804  [  300/ 3520]
loss: 0.077770  [  400/ 3520]
loss: 0.131665  [  500/ 3520]
loss: 0.006983  [  600/ 3520]
loss: 0.008086  [  700/ 3520]
loss: 0.004412  [  800/ 3520]
loss: 0.008979  [  900/ 3520]
loss: 0.004240  [ 1000/ 3520]
loss: 0.007345  [ 1100/ 3520]
loss: 0.007726  [ 1200/ 3520]
loss: 0.011342  [ 1300/ 3520]
loss: 0.012102  [ 1400/ 3520]
loss: 0.001529  [ 1500/ 3520]
loss: 0.001605  [ 1600/ 3520]
loss: 0.002044  [ 1700/ 3520]
loss: 0.106214  [ 1800/ 3520]
loss: 0.006824  [ 1900/ 3520]
loss: 0.013006  [ 2000/ 3520]
loss: 0.007421  [ 2100/ 3520]
loss: 0.001985  [ 2200/ 3520]
loss: 0.079460  [ 2300/ 3520]
loss: 0.007133  [ 2400/ 3520]
loss: 0.008105  [ 2500/ 3520]
loss: 0.011130  [ 2600/ 3520]
loss: 0.004857  [ 2700/ 3520]
loss: 0.015411  [ 2800/ 3520]
loss: 0.005879  [ 2900/ 3520]
loss: 0.011760  [ 3000/ 3520]
loss: 0.017716  [ 3100/ 3520]
loss: 0.005716  [ 3200/ 3520]
loss: 0.002899  [ 3300/ 3520]
loss: 0.006278  [ 3400/ 3520]
loss: 0.011608  [ 3500/ 3520]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3520
First Spike after testing: [-1.8101455 -6.7266946]
[0 1 2 ... 0 1 2]
[0 1 2 ... 0 1 2]
Cluster 0 Occurrences: 1160; KMEANS: 1222
Cluster 1 Occurrences: 1146; KMEANS: 1106
Cluster 2 Occurrences: 1214; KMEANS: 1192
Centroids: [[-2.0222278, -7.581644], [-1.6629081, -3.9504817], [0.22832714, -2.6258628]]
Centroids: [[-2.0145469, -7.5697036], [-1.620447, -3.8001432], [0.23465037, -2.564278]]
Contingency Matrix: 
[[1155    5    0]
 [  62 1073   11]
 [   5   28 1181]]
[[1155, 5, -1], [62, 1073, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1073, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 0, 1: 1}
New Contingency Matrix: 
[[1155    5    0]
 [  62 1073   11]
 [   5   28 1181]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1155, 1073, 1181], Sum: 3409
All_Elements: [1155, 5, 0, 62, 1073, 11, 5, 28, 1181], Sum: 3520
Accuracy: 0.9684659090909091
Done!
