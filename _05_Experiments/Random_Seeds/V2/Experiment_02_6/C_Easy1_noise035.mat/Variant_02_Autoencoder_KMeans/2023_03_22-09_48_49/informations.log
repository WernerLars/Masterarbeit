Experiment_path: Random_Seeds//V2/Experiment_02_6
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_6/C_Easy1_noise035.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_48_49
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000020628D3BFD0>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
<torch.utils.data.dataloader.DataLoader object at 0x0000020628D950F0>
Epoch 1
-------------------------------
loss: 0.253832  [    0/ 3534]
loss: 0.310248  [  100/ 3534]
loss: 0.153699  [  200/ 3534]
loss: 0.209238  [  300/ 3534]
loss: 0.154522  [  400/ 3534]
loss: 0.155406  [  500/ 3534]
loss: 0.035154  [  600/ 3534]
loss: 0.073294  [  700/ 3534]
loss: 0.145340  [  800/ 3534]
loss: 0.053901  [  900/ 3534]
loss: 0.125269  [ 1000/ 3534]
loss: 0.028867  [ 1100/ 3534]
loss: 0.122986  [ 1200/ 3534]
loss: 0.086111  [ 1300/ 3534]
loss: 0.021753  [ 1400/ 3534]
loss: 0.148303  [ 1500/ 3534]
loss: 0.142609  [ 1600/ 3534]
loss: 0.036891  [ 1700/ 3534]
loss: 0.447090  [ 1800/ 3534]
loss: 0.107724  [ 1900/ 3534]
loss: 0.086635  [ 2000/ 3534]
loss: 0.034729  [ 2100/ 3534]
loss: 0.042740  [ 2200/ 3534]
loss: 0.107682  [ 2300/ 3534]
loss: 0.062801  [ 2400/ 3534]
loss: 0.072236  [ 2500/ 3534]
loss: 0.082821  [ 2600/ 3534]
loss: 0.025613  [ 2700/ 3534]
loss: 0.136872  [ 2800/ 3534]
loss: 0.239869  [ 2900/ 3534]
loss: 0.293939  [ 3000/ 3534]
loss: 0.055032  [ 3100/ 3534]
loss: 0.126342  [ 3200/ 3534]
loss: 0.068005  [ 3300/ 3534]
loss: 0.091155  [ 3400/ 3534]
loss: 0.077734  [ 3500/ 3534]
Epoch 2
-------------------------------
loss: 0.134189  [    0/ 3534]
loss: 0.042326  [  100/ 3534]
loss: 0.041050  [  200/ 3534]
loss: 0.130020  [  300/ 3534]
loss: 0.123912  [  400/ 3534]
loss: 0.027702  [  500/ 3534]
loss: 0.056337  [  600/ 3534]
loss: 0.062827  [  700/ 3534]
loss: 0.076394  [  800/ 3534]
loss: 0.032341  [  900/ 3534]
loss: 0.107895  [ 1000/ 3534]
loss: 0.036391  [ 1100/ 3534]
loss: 0.085504  [ 1200/ 3534]
loss: 0.057055  [ 1300/ 3534]
loss: 0.010696  [ 1400/ 3534]
loss: 0.089047  [ 1500/ 3534]
loss: 0.142656  [ 1600/ 3534]
loss: 0.029860  [ 1700/ 3534]
loss: 0.320775  [ 1800/ 3534]
loss: 0.085111  [ 1900/ 3534]
loss: 0.048448  [ 2000/ 3534]
loss: 0.049664  [ 2100/ 3534]
loss: 0.031240  [ 2200/ 3534]
loss: 0.106131  [ 2300/ 3534]
loss: 0.061080  [ 2400/ 3534]
loss: 0.060463  [ 2500/ 3534]
loss: 0.077016  [ 2600/ 3534]
loss: 0.034435  [ 2700/ 3534]
loss: 0.098250  [ 2800/ 3534]
loss: 0.135250  [ 2900/ 3534]
loss: 0.182008  [ 3000/ 3534]
loss: 0.072025  [ 3100/ 3534]
loss: 0.128934  [ 3200/ 3534]
loss: 0.053269  [ 3300/ 3534]
loss: 0.058611  [ 3400/ 3534]
loss: 0.077367  [ 3500/ 3534]
Epoch 3
-------------------------------
loss: 0.123802  [    0/ 3534]
loss: 0.050145  [  100/ 3534]
loss: 0.033724  [  200/ 3534]
loss: 0.109280  [  300/ 3534]
loss: 0.144218  [  400/ 3534]
loss: 0.023731  [  500/ 3534]
loss: 0.045059  [  600/ 3534]
loss: 0.048803  [  700/ 3534]
loss: 0.055602  [  800/ 3534]
loss: 0.033965  [  900/ 3534]
loss: 0.110630  [ 1000/ 3534]
loss: 0.033189  [ 1100/ 3534]
loss: 0.060664  [ 1200/ 3534]
loss: 0.039973  [ 1300/ 3534]
loss: 0.009993  [ 1400/ 3534]
loss: 0.073016  [ 1500/ 3534]
loss: 0.135683  [ 1600/ 3534]
loss: 0.037138  [ 1700/ 3534]
loss: 0.153603  [ 1800/ 3534]
loss: 0.056205  [ 1900/ 3534]
loss: 0.021201  [ 2000/ 3534]
loss: 0.068421  [ 2100/ 3534]
loss: 0.028425  [ 2200/ 3534]
loss: 0.115002  [ 2300/ 3534]
loss: 0.058832  [ 2400/ 3534]
loss: 0.055275  [ 2500/ 3534]
loss: 0.078180  [ 2600/ 3534]
loss: 0.043451  [ 2700/ 3534]
loss: 0.089892  [ 2800/ 3534]
loss: 0.071636  [ 2900/ 3534]
loss: 0.178444  [ 3000/ 3534]
loss: 0.070880  [ 3100/ 3534]
loss: 0.134501  [ 3200/ 3534]
loss: 0.052089  [ 3300/ 3534]
loss: 0.050816  [ 3400/ 3534]
loss: 0.075944  [ 3500/ 3534]
Epoch 4
-------------------------------
loss: 0.119026  [    0/ 3534]
loss: 0.059830  [  100/ 3534]
loss: 0.027703  [  200/ 3534]
loss: 0.112393  [  300/ 3534]
loss: 0.154693  [  400/ 3534]
loss: 0.018265  [  500/ 3534]
loss: 0.034672  [  600/ 3534]
loss: 0.045640  [  700/ 3534]
loss: 0.052680  [  800/ 3534]
loss: 0.028092  [  900/ 3534]
loss: 0.105002  [ 1000/ 3534]
loss: 0.029484  [ 1100/ 3534]
loss: 0.048363  [ 1200/ 3534]
loss: 0.039442  [ 1300/ 3534]
loss: 0.009648  [ 1400/ 3534]
loss: 0.058762  [ 1500/ 3534]
loss: 0.140407  [ 1600/ 3534]
loss: 0.040318  [ 1700/ 3534]
loss: 0.092481  [ 1800/ 3534]
loss: 0.050784  [ 1900/ 3534]
loss: 0.018111  [ 2000/ 3534]
loss: 0.078232  [ 2100/ 3534]
loss: 0.030482  [ 2200/ 3534]
loss: 0.123746  [ 2300/ 3534]
loss: 0.053227  [ 2400/ 3534]
loss: 0.049370  [ 2500/ 3534]
loss: 0.073979  [ 2600/ 3534]
loss: 0.041318  [ 2700/ 3534]
loss: 0.086910  [ 2800/ 3534]
loss: 0.052494  [ 2900/ 3534]
loss: 0.174524  [ 3000/ 3534]
loss: 0.066046  [ 3100/ 3534]
loss: 0.135797  [ 3200/ 3534]
loss: 0.054021  [ 3300/ 3534]
loss: 0.043983  [ 3400/ 3534]
loss: 0.074258  [ 3500/ 3534]
Epoch 5
-------------------------------
loss: 0.119116  [    0/ 3534]
loss: 0.061840  [  100/ 3534]
loss: 0.029162  [  200/ 3534]
loss: 0.115810  [  300/ 3534]
loss: 0.164249  [  400/ 3534]
loss: 0.010771  [  500/ 3534]
loss: 0.032084  [  600/ 3534]
loss: 0.044348  [  700/ 3534]
loss: 0.052795  [  800/ 3534]
loss: 0.021712  [  900/ 3534]
loss: 0.094750  [ 1000/ 3534]
loss: 0.027691  [ 1100/ 3534]
loss: 0.038878  [ 1200/ 3534]
loss: 0.043665  [ 1300/ 3534]
loss: 0.009857  [ 1400/ 3534]
loss: 0.054057  [ 1500/ 3534]
loss: 0.143430  [ 1600/ 3534]
loss: 0.041342  [ 1700/ 3534]
loss: 0.078155  [ 1800/ 3534]
loss: 0.049309  [ 1900/ 3534]
loss: 0.019333  [ 2000/ 3534]
loss: 0.075564  [ 2100/ 3534]
loss: 0.032046  [ 2200/ 3534]
loss: 0.128016  [ 2300/ 3534]
loss: 0.049171  [ 2400/ 3534]
loss: 0.053859  [ 2500/ 3534]
loss: 0.071316  [ 2600/ 3534]
loss: 0.040258  [ 2700/ 3534]
loss: 0.082675  [ 2800/ 3534]
loss: 0.041501  [ 2900/ 3534]
loss: 0.169763  [ 3000/ 3534]
loss: 0.064314  [ 3100/ 3534]
loss: 0.135562  [ 3200/ 3534]
loss: 0.054457  [ 3300/ 3534]
loss: 0.040707  [ 3400/ 3534]
loss: 0.074327  [ 3500/ 3534]
Epoch 6
-------------------------------
loss: 0.118902  [    0/ 3534]
loss: 0.062216  [  100/ 3534]
loss: 0.027349  [  200/ 3534]
loss: 0.113214  [  300/ 3534]
loss: 0.168392  [  400/ 3534]
loss: 0.008965  [  500/ 3534]
loss: 0.033739  [  600/ 3534]
loss: 0.043520  [  700/ 3534]
loss: 0.051067  [  800/ 3534]
loss: 0.020283  [  900/ 3534]
loss: 0.080487  [ 1000/ 3534]
loss: 0.024530  [ 1100/ 3534]
loss: 0.033966  [ 1200/ 3534]
loss: 0.048249  [ 1300/ 3534]
loss: 0.011192  [ 1400/ 3534]
loss: 0.049695  [ 1500/ 3534]
loss: 0.149033  [ 1600/ 3534]
loss: 0.039906  [ 1700/ 3534]
loss: 0.073981  [ 1800/ 3534]
loss: 0.046716  [ 1900/ 3534]
loss: 0.020303  [ 2000/ 3534]
loss: 0.067634  [ 2100/ 3534]
loss: 0.029787  [ 2200/ 3534]
loss: 0.131985  [ 2300/ 3534]
loss: 0.046647  [ 2400/ 3534]
loss: 0.055972  [ 2500/ 3534]
loss: 0.069797  [ 2600/ 3534]
loss: 0.043340  [ 2700/ 3534]
loss: 0.073698  [ 2800/ 3534]
loss: 0.034515  [ 2900/ 3534]
loss: 0.161971  [ 3000/ 3534]
loss: 0.061496  [ 3100/ 3534]
loss: 0.135047  [ 3200/ 3534]
loss: 0.054501  [ 3300/ 3534]
loss: 0.039540  [ 3400/ 3534]
loss: 0.074202  [ 3500/ 3534]
Epoch 7
-------------------------------
loss: 0.117800  [    0/ 3534]
loss: 0.062824  [  100/ 3534]
loss: 0.026808  [  200/ 3534]
loss: 0.112704  [  300/ 3534]
loss: 0.168796  [  400/ 3534]
loss: 0.009455  [  500/ 3534]
loss: 0.027777  [  600/ 3534]
loss: 0.045334  [  700/ 3534]
loss: 0.050013  [  800/ 3534]
loss: 0.021407  [  900/ 3534]
loss: 0.071237  [ 1000/ 3534]
loss: 0.022726  [ 1100/ 3534]
loss: 0.030910  [ 1200/ 3534]
loss: 0.052818  [ 1300/ 3534]
loss: 0.013077  [ 1400/ 3534]
loss: 0.045637  [ 1500/ 3534]
loss: 0.151130  [ 1600/ 3534]
loss: 0.039677  [ 1700/ 3534]
loss: 0.064688  [ 1800/ 3534]
loss: 0.043729  [ 1900/ 3534]
loss: 0.021704  [ 2000/ 3534]
loss: 0.061058  [ 2100/ 3534]
loss: 0.029188  [ 2200/ 3534]
loss: 0.133925  [ 2300/ 3534]
loss: 0.047018  [ 2400/ 3534]
loss: 0.055344  [ 2500/ 3534]
loss: 0.069097  [ 2600/ 3534]
loss: 0.043584  [ 2700/ 3534]
loss: 0.069030  [ 2800/ 3534]
loss: 0.036598  [ 2900/ 3534]
loss: 0.156000  [ 3000/ 3534]
loss: 0.059880  [ 3100/ 3534]
loss: 0.135008  [ 3200/ 3534]
loss: 0.053576  [ 3300/ 3534]
loss: 0.039235  [ 3400/ 3534]
loss: 0.073725  [ 3500/ 3534]
Epoch 8
-------------------------------
loss: 0.117993  [    0/ 3534]
loss: 0.064951  [  100/ 3534]
loss: 0.026998  [  200/ 3534]
loss: 0.113986  [  300/ 3534]
loss: 0.175390  [  400/ 3534]
loss: 0.009769  [  500/ 3534]
loss: 0.027848  [  600/ 3534]
loss: 0.047349  [  700/ 3534]
loss: 0.048451  [  800/ 3534]
loss: 0.023819  [  900/ 3534]
loss: 0.064622  [ 1000/ 3534]
loss: 0.021129  [ 1100/ 3534]
loss: 0.028457  [ 1200/ 3534]
loss: 0.055261  [ 1300/ 3534]
loss: 0.012852  [ 1400/ 3534]
loss: 0.042479  [ 1500/ 3534]
loss: 0.150455  [ 1600/ 3534]
loss: 0.039112  [ 1700/ 3534]
loss: 0.051441  [ 1800/ 3534]
loss: 0.041046  [ 1900/ 3534]
loss: 0.023462  [ 2000/ 3534]
loss: 0.056130  [ 2100/ 3534]
loss: 0.029139  [ 2200/ 3534]
loss: 0.134047  [ 2300/ 3534]
loss: 0.046892  [ 2400/ 3534]
loss: 0.056302  [ 2500/ 3534]
loss: 0.069024  [ 2600/ 3534]
loss: 0.038390  [ 2700/ 3534]
loss: 0.066972  [ 2800/ 3534]
loss: 0.042942  [ 2900/ 3534]
loss: 0.153953  [ 3000/ 3534]
loss: 0.056992  [ 3100/ 3534]
loss: 0.135625  [ 3200/ 3534]
loss: 0.052408  [ 3300/ 3534]
loss: 0.039522  [ 3400/ 3534]
loss: 0.073710  [ 3500/ 3534]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3534
First Spike after testing: [ 1.504954  -1.8283587]
[0 1 2 ... 2 2 1]
[1 0 2 ... 2 2 0]
Cluster 0 Occurrences: 1208; KMEANS: 1161
Cluster 1 Occurrences: 1137; KMEANS: 1186
Cluster 2 Occurrences: 1189; KMEANS: 1187
Centroids: [[1.4936069, -1.4267584], [-1.1972418, 2.6410873], [-1.3383362, -1.3337497]]
Centroids: [[-1.1941956, 2.6159174], [1.5306734, -1.410204], [-1.3287162, -1.4077625]]
Contingency Matrix: 
[[   1 1181   26]
 [1128    3    6]
 [  32    2 1155]]
[[-1, -1, -1], [1128, -1, 6], [32, -1, 1155]]
[[-1, -1, -1], [1128, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 1, 2: 2, 1: 0}
New Contingency Matrix: 
[[1181    1   26]
 [   3 1128    6]
 [   2   32 1155]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [1181, 1128, 1155], Sum: 3464
All_Elements: [1181, 1, 26, 3, 1128, 6, 2, 32, 1155], Sum: 3534
Accuracy: 0.980192416525184
Done!
