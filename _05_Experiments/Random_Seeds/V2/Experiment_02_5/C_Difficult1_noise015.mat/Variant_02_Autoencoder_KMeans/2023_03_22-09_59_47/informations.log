Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Difficult1_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_59_47
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B843BB198>
Sampling rate: 24000.0
Raw: [ 0.04887081  0.02693095 -0.0154249  ... -0.09301659 -0.11629005
 -0.14613101]
Times: [    340     491     641 ... 1439047 1439065 1439816]
Cluster: [1 1 1 ... 3 2 2]
Number of different clusters:  3
Number of Spikes: 3472
First aligned Spike Frame: [ 0.12751554  0.12305882  0.10482977  0.09479529  0.10214978  0.11675932
  0.11777927  0.09307299  0.04670706 -0.00574343 -0.06143573 -0.14637617
 -0.20942665 -0.00208103  0.52241508  0.81651544  0.46446121 -0.19226425
 -0.60927882 -0.6713583  -0.57871227 -0.49011309 -0.4269388  -0.3668903
 -0.30523219 -0.24747124 -0.19738203 -0.15189972 -0.10449507 -0.05533325
 -0.01452429  0.01008816  0.02570853  0.04365027  0.06334113  0.07980397
  0.08484457  0.07688513  0.06142919  0.04320028  0.02240626  0.00477291
 -0.00393242 -0.00135684  0.00575182  0.0026944  -0.01541647]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1172
Cluster 2, Occurrences: 1141
<torch.utils.data.dataloader.DataLoader object at 0x0000019B89ADF390>
Epoch 1
-------------------------------
loss: 0.139986  [    0/ 3472]
loss: 0.062878  [  100/ 3472]
loss: 0.012472  [  200/ 3472]
loss: 0.024760  [  300/ 3472]
loss: 0.035868  [  400/ 3472]
loss: 0.016437  [  500/ 3472]
loss: 0.023152  [  600/ 3472]
loss: 0.015336  [  700/ 3472]
loss: 0.035262  [  800/ 3472]
loss: 0.025792  [  900/ 3472]
loss: 0.009866  [ 1000/ 3472]
loss: 0.028403  [ 1100/ 3472]
loss: 0.022532  [ 1200/ 3472]
loss: 0.007047  [ 1300/ 3472]
loss: 0.006256  [ 1400/ 3472]
loss: 0.033845  [ 1500/ 3472]
loss: 0.014835  [ 1600/ 3472]
loss: 0.009936  [ 1700/ 3472]
loss: 0.042421  [ 1800/ 3472]
loss: 0.128184  [ 1900/ 3472]
loss: 0.061067  [ 2000/ 3472]
loss: 0.019034  [ 2100/ 3472]
loss: 0.011550  [ 2200/ 3472]
loss: 0.009581  [ 2300/ 3472]
loss: 0.017160  [ 2400/ 3472]
loss: 0.015405  [ 2500/ 3472]
loss: 0.009347  [ 2600/ 3472]
loss: 0.015873  [ 2700/ 3472]
loss: 0.028484  [ 2800/ 3472]
loss: 0.029485  [ 2900/ 3472]
loss: 0.008556  [ 3000/ 3472]
loss: 0.015449  [ 3100/ 3472]
loss: 0.014428  [ 3200/ 3472]
loss: 0.010295  [ 3300/ 3472]
loss: 0.011518  [ 3400/ 3472]
Epoch 2
-------------------------------
loss: 0.006854  [    0/ 3472]
loss: 0.008249  [  100/ 3472]
loss: 0.009597  [  200/ 3472]
loss: 0.017567  [  300/ 3472]
loss: 0.004731  [  400/ 3472]
loss: 0.015726  [  500/ 3472]
loss: 0.012932  [  600/ 3472]
loss: 0.006738  [  700/ 3472]
loss: 0.038058  [  800/ 3472]
loss: 0.026775  [  900/ 3472]
loss: 0.009403  [ 1000/ 3472]
loss: 0.028598  [ 1100/ 3472]
loss: 0.024700  [ 1200/ 3472]
loss: 0.005136  [ 1300/ 3472]
loss: 0.003539  [ 1400/ 3472]
loss: 0.034177  [ 1500/ 3472]
loss: 0.018666  [ 1600/ 3472]
loss: 0.010436  [ 1700/ 3472]
loss: 0.032194  [ 1800/ 3472]
loss: 0.132496  [ 1900/ 3472]
loss: 0.052806  [ 2000/ 3472]
loss: 0.015638  [ 2100/ 3472]
loss: 0.010824  [ 2200/ 3472]
loss: 0.006702  [ 2300/ 3472]
loss: 0.007883  [ 2400/ 3472]
loss: 0.013566  [ 2500/ 3472]
loss: 0.012865  [ 2600/ 3472]
loss: 0.012244  [ 2700/ 3472]
loss: 0.025967  [ 2800/ 3472]
loss: 0.031167  [ 2900/ 3472]
loss: 0.008696  [ 3000/ 3472]
loss: 0.020166  [ 3100/ 3472]
loss: 0.013873  [ 3200/ 3472]
loss: 0.008289  [ 3300/ 3472]
loss: 0.009349  [ 3400/ 3472]
Epoch 3
-------------------------------
loss: 0.008114  [    0/ 3472]
loss: 0.007813  [  100/ 3472]
loss: 0.009605  [  200/ 3472]
loss: 0.017243  [  300/ 3472]
loss: 0.005686  [  400/ 3472]
loss: 0.015789  [  500/ 3472]
loss: 0.012265  [  600/ 3472]
loss: 0.005720  [  700/ 3472]
loss: 0.037373  [  800/ 3472]
loss: 0.027623  [  900/ 3472]
loss: 0.009468  [ 1000/ 3472]
loss: 0.027090  [ 1100/ 3472]
loss: 0.023651  [ 1200/ 3472]
loss: 0.005728  [ 1300/ 3472]
loss: 0.003391  [ 1400/ 3472]
loss: 0.032632  [ 1500/ 3472]
loss: 0.019251  [ 1600/ 3472]
loss: 0.010224  [ 1700/ 3472]
loss: 0.029656  [ 1800/ 3472]
loss: 0.134233  [ 1900/ 3472]
loss: 0.051382  [ 2000/ 3472]
loss: 0.014856  [ 2100/ 3472]
loss: 0.010860  [ 2200/ 3472]
loss: 0.006434  [ 2300/ 3472]
loss: 0.006132  [ 2400/ 3472]
loss: 0.013655  [ 2500/ 3472]
loss: 0.013332  [ 2600/ 3472]
loss: 0.011728  [ 2700/ 3472]
loss: 0.025494  [ 2800/ 3472]
loss: 0.031315  [ 2900/ 3472]
loss: 0.008946  [ 3000/ 3472]
loss: 0.020952  [ 3100/ 3472]
loss: 0.013534  [ 3200/ 3472]
loss: 0.008338  [ 3300/ 3472]
loss: 0.008757  [ 3400/ 3472]
Epoch 4
-------------------------------
loss: 0.007805  [    0/ 3472]
loss: 0.007164  [  100/ 3472]
loss: 0.009456  [  200/ 3472]
loss: 0.017360  [  300/ 3472]
loss: 0.005890  [  400/ 3472]
loss: 0.015375  [  500/ 3472]
loss: 0.012128  [  600/ 3472]
loss: 0.005729  [  700/ 3472]
loss: 0.037180  [  800/ 3472]
loss: 0.027779  [  900/ 3472]
loss: 0.009202  [ 1000/ 3472]
loss: 0.026432  [ 1100/ 3472]
loss: 0.023095  [ 1200/ 3472]
loss: 0.005771  [ 1300/ 3472]
loss: 0.003320  [ 1400/ 3472]
loss: 0.029587  [ 1500/ 3472]
loss: 0.019808  [ 1600/ 3472]
loss: 0.010362  [ 1700/ 3472]
loss: 0.027173  [ 1800/ 3472]
loss: 0.135590  [ 1900/ 3472]
loss: 0.050643  [ 2000/ 3472]
loss: 0.013979  [ 2100/ 3472]
loss: 0.010964  [ 2200/ 3472]
loss: 0.006139  [ 2300/ 3472]
loss: 0.005511  [ 2400/ 3472]
loss: 0.013549  [ 2500/ 3472]
loss: 0.013619  [ 2600/ 3472]
loss: 0.011541  [ 2700/ 3472]
loss: 0.024770  [ 2800/ 3472]
loss: 0.031357  [ 2900/ 3472]
loss: 0.009277  [ 3000/ 3472]
loss: 0.021656  [ 3100/ 3472]
loss: 0.013041  [ 3200/ 3472]
loss: 0.007856  [ 3300/ 3472]
loss: 0.008316  [ 3400/ 3472]
Epoch 5
-------------------------------
loss: 0.007572  [    0/ 3472]
loss: 0.006747  [  100/ 3472]
loss: 0.009559  [  200/ 3472]
loss: 0.017267  [  300/ 3472]
loss: 0.005938  [  400/ 3472]
loss: 0.015373  [  500/ 3472]
loss: 0.011965  [  600/ 3472]
loss: 0.005342  [  700/ 3472]
loss: 0.036589  [  800/ 3472]
loss: 0.027941  [  900/ 3472]
loss: 0.009042  [ 1000/ 3472]
loss: 0.025905  [ 1100/ 3472]
loss: 0.022691  [ 1200/ 3472]
loss: 0.005939  [ 1300/ 3472]
loss: 0.003203  [ 1400/ 3472]
loss: 0.026779  [ 1500/ 3472]
loss: 0.019789  [ 1600/ 3472]
loss: 0.010327  [ 1700/ 3472]
loss: 0.025872  [ 1800/ 3472]
loss: 0.136927  [ 1900/ 3472]
loss: 0.049847  [ 2000/ 3472]
loss: 0.013561  [ 2100/ 3472]
loss: 0.011189  [ 2200/ 3472]
loss: 0.006062  [ 2300/ 3472]
loss: 0.005653  [ 2400/ 3472]
loss: 0.013246  [ 2500/ 3472]
loss: 0.012711  [ 2600/ 3472]
loss: 0.011424  [ 2700/ 3472]
loss: 0.023745  [ 2800/ 3472]
loss: 0.030903  [ 2900/ 3472]
loss: 0.009480  [ 3000/ 3472]
loss: 0.020921  [ 3100/ 3472]
loss: 0.012847  [ 3200/ 3472]
loss: 0.007559  [ 3300/ 3472]
loss: 0.008160  [ 3400/ 3472]
Epoch 6
-------------------------------
loss: 0.006911  [    0/ 3472]
loss: 0.006710  [  100/ 3472]
loss: 0.009677  [  200/ 3472]
loss: 0.017335  [  300/ 3472]
loss: 0.005820  [  400/ 3472]
loss: 0.015549  [  500/ 3472]
loss: 0.011864  [  600/ 3472]
loss: 0.004694  [  700/ 3472]
loss: 0.036055  [  800/ 3472]
loss: 0.027718  [  900/ 3472]
loss: 0.008817  [ 1000/ 3472]
loss: 0.025291  [ 1100/ 3472]
loss: 0.022056  [ 1200/ 3472]
loss: 0.005896  [ 1300/ 3472]
loss: 0.003039  [ 1400/ 3472]
loss: 0.022930  [ 1500/ 3472]
loss: 0.019188  [ 1600/ 3472]
loss: 0.009899  [ 1700/ 3472]
loss: 0.026289  [ 1800/ 3472]
loss: 0.137598  [ 1900/ 3472]
loss: 0.049608  [ 2000/ 3472]
loss: 0.013497  [ 2100/ 3472]
loss: 0.011257  [ 2200/ 3472]
loss: 0.006462  [ 2300/ 3472]
loss: 0.006053  [ 2400/ 3472]
loss: 0.013743  [ 2500/ 3472]
loss: 0.011254  [ 2600/ 3472]
loss: 0.012111  [ 2700/ 3472]
loss: 0.023153  [ 2800/ 3472]
loss: 0.030548  [ 2900/ 3472]
loss: 0.009706  [ 3000/ 3472]
loss: 0.018715  [ 3100/ 3472]
loss: 0.012628  [ 3200/ 3472]
loss: 0.007165  [ 3300/ 3472]
loss: 0.008268  [ 3400/ 3472]
Epoch 7
-------------------------------
loss: 0.005747  [    0/ 3472]
loss: 0.006646  [  100/ 3472]
loss: 0.009729  [  200/ 3472]
loss: 0.017520  [  300/ 3472]
loss: 0.005048  [  400/ 3472]
loss: 0.015365  [  500/ 3472]
loss: 0.011909  [  600/ 3472]
loss: 0.004314  [  700/ 3472]
loss: 0.035479  [  800/ 3472]
loss: 0.027348  [  900/ 3472]
loss: 0.008346  [ 1000/ 3472]
loss: 0.025080  [ 1100/ 3472]
loss: 0.021371  [ 1200/ 3472]
loss: 0.005410  [ 1300/ 3472]
loss: 0.002910  [ 1400/ 3472]
loss: 0.021081  [ 1500/ 3472]
loss: 0.018744  [ 1600/ 3472]
loss: 0.010635  [ 1700/ 3472]
loss: 0.024008  [ 1800/ 3472]
loss: 0.140306  [ 1900/ 3472]
loss: 0.049128  [ 2000/ 3472]
loss: 0.012999  [ 2100/ 3472]
loss: 0.011498  [ 2200/ 3472]
loss: 0.006351  [ 2300/ 3472]
loss: 0.006614  [ 2400/ 3472]
loss: 0.013440  [ 2500/ 3472]
loss: 0.010699  [ 2600/ 3472]
loss: 0.012173  [ 2700/ 3472]
loss: 0.021443  [ 2800/ 3472]
loss: 0.029090  [ 2900/ 3472]
loss: 0.010016  [ 3000/ 3472]
loss: 0.017567  [ 3100/ 3472]
loss: 0.012476  [ 3200/ 3472]
loss: 0.006766  [ 3300/ 3472]
loss: 0.008427  [ 3400/ 3472]
Epoch 8
-------------------------------
loss: 0.005032  [    0/ 3472]
loss: 0.006524  [  100/ 3472]
loss: 0.009926  [  200/ 3472]
loss: 0.017410  [  300/ 3472]
loss: 0.004515  [  400/ 3472]
loss: 0.015309  [  500/ 3472]
loss: 0.012139  [  600/ 3472]
loss: 0.003849  [  700/ 3472]
loss: 0.034923  [  800/ 3472]
loss: 0.026888  [  900/ 3472]
loss: 0.008071  [ 1000/ 3472]
loss: 0.024819  [ 1100/ 3472]
loss: 0.020739  [ 1200/ 3472]
loss: 0.004646  [ 1300/ 3472]
loss: 0.002871  [ 1400/ 3472]
loss: 0.019451  [ 1500/ 3472]
loss: 0.017600  [ 1600/ 3472]
loss: 0.010683  [ 1700/ 3472]
loss: 0.020845  [ 1800/ 3472]
loss: 0.142367  [ 1900/ 3472]
loss: 0.048677  [ 2000/ 3472]
loss: 0.012239  [ 2100/ 3472]
loss: 0.011601  [ 2200/ 3472]
loss: 0.006515  [ 2300/ 3472]
loss: 0.007259  [ 2400/ 3472]
loss: 0.013423  [ 2500/ 3472]
loss: 0.009901  [ 2600/ 3472]
loss: 0.012028  [ 2700/ 3472]
loss: 0.019662  [ 2800/ 3472]
loss: 0.027611  [ 2900/ 3472]
loss: 0.010527  [ 3000/ 3472]
loss: 0.016406  [ 3100/ 3472]
loss: 0.012555  [ 3200/ 3472]
loss: 0.006406  [ 3300/ 3472]
loss: 0.008206  [ 3400/ 3472]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3472
First Spike after testing: [-0.14267448  0.60372853]
[0 0 0 ... 2 1 1]
[2 2 2 ... 1 1 0]
Cluster 0 Occurrences: 1159; KMEANS: 1246
Cluster 1 Occurrences: 1172; KMEANS: 1228
Cluster 2 Occurrences: 1141; KMEANS: 998
Centroids: [[-0.32060578, 0.3169806], [-0.37322053, -0.26972526], [-0.87582284, 0.009754582]]
Centroids: [[-0.29490712, -0.33442378], [-0.91666317, 0.037190102], [-0.3158255, 0.4342837]]
Contingency Matrix: 
[[197 117 845]
 [883 214  75]
 [166 897  78]]
[[197, -1, 845], [883, -1, 75], [-1, -1, -1]]
[[-1, -1, 845], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 1: 0, 0: 2}
New Contingency Matrix: 
[[845 197 117]
 [ 75 883 214]
 [ 78 166 897]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [845, 883, 897], Sum: 2625
All_Elements: [845, 197, 117, 75, 883, 214, 78, 166, 897], Sum: 3472
Accuracy: 0.7560483870967742
Done!
