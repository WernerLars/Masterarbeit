Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Easy2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_51_27
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B2B6814E0>
Sampling rate: 24000.0
Raw: [ 0.11862069  0.1123084   0.10401825 ... -0.10219323 -0.10268373
 -0.08956559]
Times: [    346     799    1005 ... 1436867 1437273 1437800]
Cluster: [3 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3410
First aligned Spike Frame: [ 2.05661766e-03  8.27536867e-03  1.66427268e-02  2.31246655e-02
  2.28936935e-02  1.99169368e-02  2.25281834e-02  3.37605443e-02
  4.94182133e-02  6.24484568e-02  8.42111946e-02  1.71357846e-01
  3.88441746e-01  6.99052305e-01  9.59509287e-01  1.03608873e+00
  9.29169963e-01  7.55567481e-01  6.10726415e-01  5.06818519e-01
  4.23878029e-01  3.55610047e-01  3.01970228e-01  2.53702042e-01
  1.98274486e-01  1.32802904e-01  6.40690121e-02  7.96454927e-04
 -5.66201776e-02 -1.11669131e-01 -1.62581026e-01 -2.01746625e-01
 -2.23071447e-01 -2.29516190e-01 -2.30160694e-01 -2.27148529e-01
 -2.18080531e-01 -2.04276810e-01 -1.90750996e-01 -1.81098693e-01
 -1.72421418e-01 -1.61640218e-01 -1.48460304e-01 -1.32332846e-01
 -1.13338953e-01 -9.43725979e-02 -7.56249106e-02]
Cluster 0, Occurrences: 1130
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1167
<torch.utils.data.dataloader.DataLoader object at 0x0000019B261544E0>
Epoch 1
-------------------------------
loss: 0.192153  [    0/ 3410]
loss: 0.103786  [  100/ 3410]
loss: 0.064608  [  200/ 3410]
loss: 0.016628  [  300/ 3410]
loss: 0.006639  [  400/ 3410]
loss: 0.004042  [  500/ 3410]
loss: 0.001517  [  600/ 3410]
loss: 0.003906  [  700/ 3410]
loss: 0.010930  [  800/ 3410]
loss: 0.015974  [  900/ 3410]
loss: 0.024069  [ 1000/ 3410]
loss: 0.003267  [ 1100/ 3410]
loss: 0.002890  [ 1200/ 3410]
loss: 0.005467  [ 1300/ 3410]
loss: 0.004376  [ 1400/ 3410]
loss: 0.002198  [ 1500/ 3410]
loss: 0.001280  [ 1600/ 3410]
loss: 0.012031  [ 1700/ 3410]
loss: 0.006189  [ 1800/ 3410]
loss: 0.001646  [ 1900/ 3410]
loss: 0.055955  [ 2000/ 3410]
loss: 0.005830  [ 2100/ 3410]
loss: 0.027375  [ 2200/ 3410]
loss: 0.001782  [ 2300/ 3410]
loss: 0.003076  [ 2400/ 3410]
loss: 0.107487  [ 2500/ 3410]
loss: 0.006862  [ 2600/ 3410]
loss: 0.003732  [ 2700/ 3410]
loss: 0.001716  [ 2800/ 3410]
loss: 0.006821  [ 2900/ 3410]
loss: 0.001865  [ 3000/ 3410]
loss: 0.000989  [ 3100/ 3410]
loss: 0.002299  [ 3200/ 3410]
loss: 0.001614  [ 3300/ 3410]
loss: 0.001919  [ 3400/ 3410]
Epoch 2
-------------------------------
loss: 0.000759  [    0/ 3410]
loss: 0.001611  [  100/ 3410]
loss: 0.004150  [  200/ 3410]
loss: 0.002817  [  300/ 3410]
loss: 0.002266  [  400/ 3410]
loss: 0.008569  [  500/ 3410]
loss: 0.001109  [  600/ 3410]
loss: 0.004792  [  700/ 3410]
loss: 0.004182  [  800/ 3410]
loss: 0.002107  [  900/ 3410]
loss: 0.005367  [ 1000/ 3410]
loss: 0.002477  [ 1100/ 3410]
loss: 0.002425  [ 1200/ 3410]
loss: 0.005936  [ 1300/ 3410]
loss: 0.001205  [ 1400/ 3410]
loss: 0.001282  [ 1500/ 3410]
loss: 0.001221  [ 1600/ 3410]
loss: 0.003609  [ 1700/ 3410]
loss: 0.007740  [ 1800/ 3410]
loss: 0.001192  [ 1900/ 3410]
loss: 0.054218  [ 2000/ 3410]
loss: 0.003477  [ 2100/ 3410]
loss: 0.025950  [ 2200/ 3410]
loss: 0.001587  [ 2300/ 3410]
loss: 0.002259  [ 2400/ 3410]
loss: 0.092285  [ 2500/ 3410]
loss: 0.003353  [ 2600/ 3410]
loss: 0.003830  [ 2700/ 3410]
loss: 0.001110  [ 2800/ 3410]
loss: 0.006481  [ 2900/ 3410]
loss: 0.001901  [ 3000/ 3410]
loss: 0.000771  [ 3100/ 3410]
loss: 0.001282  [ 3200/ 3410]
loss: 0.001447  [ 3300/ 3410]
loss: 0.001551  [ 3400/ 3410]
Epoch 3
-------------------------------
loss: 0.000798  [    0/ 3410]
loss: 0.001692  [  100/ 3410]
loss: 0.004240  [  200/ 3410]
loss: 0.002703  [  300/ 3410]
loss: 0.002169  [  400/ 3410]
loss: 0.006453  [  500/ 3410]
loss: 0.000957  [  600/ 3410]
loss: 0.005061  [  700/ 3410]
loss: 0.004126  [  800/ 3410]
loss: 0.002257  [  900/ 3410]
loss: 0.005372  [ 1000/ 3410]
loss: 0.002335  [ 1100/ 3410]
loss: 0.002149  [ 1200/ 3410]
loss: 0.005607  [ 1300/ 3410]
loss: 0.001099  [ 1400/ 3410]
loss: 0.001236  [ 1500/ 3410]
loss: 0.001171  [ 1600/ 3410]
loss: 0.003697  [ 1700/ 3410]
loss: 0.007707  [ 1800/ 3410]
loss: 0.001235  [ 1900/ 3410]
loss: 0.053142  [ 2000/ 3410]
loss: 0.003495  [ 2100/ 3410]
loss: 0.025741  [ 2200/ 3410]
loss: 0.002020  [ 2300/ 3410]
loss: 0.002450  [ 2400/ 3410]
loss: 0.085313  [ 2500/ 3410]
loss: 0.003318  [ 2600/ 3410]
loss: 0.003874  [ 2700/ 3410]
loss: 0.000875  [ 2800/ 3410]
loss: 0.006464  [ 2900/ 3410]
loss: 0.002017  [ 3000/ 3410]
loss: 0.000755  [ 3100/ 3410]
loss: 0.001593  [ 3200/ 3410]
loss: 0.001371  [ 3300/ 3410]
loss: 0.001244  [ 3400/ 3410]
Epoch 4
-------------------------------
loss: 0.000636  [    0/ 3410]
loss: 0.002041  [  100/ 3410]
loss: 0.004309  [  200/ 3410]
loss: 0.002733  [  300/ 3410]
loss: 0.002137  [  400/ 3410]
loss: 0.006097  [  500/ 3410]
loss: 0.000758  [  600/ 3410]
loss: 0.005419  [  700/ 3410]
loss: 0.003899  [  800/ 3410]
loss: 0.002444  [  900/ 3410]
loss: 0.005138  [ 1000/ 3410]
loss: 0.002207  [ 1100/ 3410]
loss: 0.002090  [ 1200/ 3410]
loss: 0.005333  [ 1300/ 3410]
loss: 0.001023  [ 1400/ 3410]
loss: 0.001214  [ 1500/ 3410]
loss: 0.001173  [ 1600/ 3410]
loss: 0.003985  [ 1700/ 3410]
loss: 0.008247  [ 1800/ 3410]
loss: 0.001364  [ 1900/ 3410]
loss: 0.054147  [ 2000/ 3410]
loss: 0.003636  [ 2100/ 3410]
loss: 0.025164  [ 2200/ 3410]
loss: 0.002728  [ 2300/ 3410]
loss: 0.002834  [ 2400/ 3410]
loss: 0.082249  [ 2500/ 3410]
loss: 0.003159  [ 2600/ 3410]
loss: 0.004045  [ 2700/ 3410]
loss: 0.000832  [ 2800/ 3410]
loss: 0.006336  [ 2900/ 3410]
loss: 0.002318  [ 3000/ 3410]
loss: 0.000695  [ 3100/ 3410]
loss: 0.001240  [ 3200/ 3410]
loss: 0.001310  [ 3300/ 3410]
loss: 0.001267  [ 3400/ 3410]
Epoch 5
-------------------------------
loss: 0.000611  [    0/ 3410]
loss: 0.002160  [  100/ 3410]
loss: 0.004514  [  200/ 3410]
loss: 0.002992  [  300/ 3410]
loss: 0.002118  [  400/ 3410]
loss: 0.005355  [  500/ 3410]
loss: 0.000714  [  600/ 3410]
loss: 0.005584  [  700/ 3410]
loss: 0.003611  [  800/ 3410]
loss: 0.002407  [  900/ 3410]
loss: 0.005148  [ 1000/ 3410]
loss: 0.002074  [ 1100/ 3410]
loss: 0.002167  [ 1200/ 3410]
loss: 0.005112  [ 1300/ 3410]
loss: 0.001017  [ 1400/ 3410]
loss: 0.001136  [ 1500/ 3410]
loss: 0.001201  [ 1600/ 3410]
loss: 0.003724  [ 1700/ 3410]
loss: 0.006976  [ 1800/ 3410]
loss: 0.001393  [ 1900/ 3410]
loss: 0.054966  [ 2000/ 3410]
loss: 0.003526  [ 2100/ 3410]
loss: 0.024018  [ 2200/ 3410]
loss: 0.002973  [ 2300/ 3410]
loss: 0.002853  [ 2400/ 3410]
loss: 0.079169  [ 2500/ 3410]
loss: 0.002783  [ 2600/ 3410]
loss: 0.004094  [ 2700/ 3410]
loss: 0.000913  [ 2800/ 3410]
loss: 0.006286  [ 2900/ 3410]
loss: 0.002444  [ 3000/ 3410]
loss: 0.000669  [ 3100/ 3410]
loss: 0.001170  [ 3200/ 3410]
loss: 0.001198  [ 3300/ 3410]
loss: 0.001495  [ 3400/ 3410]
Epoch 6
-------------------------------
loss: 0.000623  [    0/ 3410]
loss: 0.002534  [  100/ 3410]
loss: 0.004509  [  200/ 3410]
loss: 0.003016  [  300/ 3410]
loss: 0.002138  [  400/ 3410]
loss: 0.005220  [  500/ 3410]
loss: 0.000713  [  600/ 3410]
loss: 0.005600  [  700/ 3410]
loss: 0.003375  [  800/ 3410]
loss: 0.002415  [  900/ 3410]
loss: 0.004914  [ 1000/ 3410]
loss: 0.002005  [ 1100/ 3410]
loss: 0.002184  [ 1200/ 3410]
loss: 0.005029  [ 1300/ 3410]
loss: 0.001046  [ 1400/ 3410]
loss: 0.001069  [ 1500/ 3410]
loss: 0.001263  [ 1600/ 3410]
loss: 0.003370  [ 1700/ 3410]
loss: 0.005894  [ 1800/ 3410]
loss: 0.001406  [ 1900/ 3410]
loss: 0.055588  [ 2000/ 3410]
loss: 0.003509  [ 2100/ 3410]
loss: 0.023028  [ 2200/ 3410]
loss: 0.003019  [ 2300/ 3410]
loss: 0.002807  [ 2400/ 3410]
loss: 0.076665  [ 2500/ 3410]
loss: 0.002570  [ 2600/ 3410]
loss: 0.004260  [ 2700/ 3410]
loss: 0.000877  [ 2800/ 3410]
loss: 0.006177  [ 2900/ 3410]
loss: 0.002583  [ 3000/ 3410]
loss: 0.000654  [ 3100/ 3410]
loss: 0.001238  [ 3200/ 3410]
loss: 0.001154  [ 3300/ 3410]
loss: 0.001411  [ 3400/ 3410]
Epoch 7
-------------------------------
loss: 0.000588  [    0/ 3410]
loss: 0.002800  [  100/ 3410]
loss: 0.004495  [  200/ 3410]
loss: 0.002901  [  300/ 3410]
loss: 0.002131  [  400/ 3410]
loss: 0.005100  [  500/ 3410]
loss: 0.000748  [  600/ 3410]
loss: 0.005635  [  700/ 3410]
loss: 0.003413  [  800/ 3410]
loss: 0.002307  [  900/ 3410]
loss: 0.004651  [ 1000/ 3410]
loss: 0.001964  [ 1100/ 3410]
loss: 0.002477  [ 1200/ 3410]
loss: 0.005016  [ 1300/ 3410]
loss: 0.001037  [ 1400/ 3410]
loss: 0.000998  [ 1500/ 3410]
loss: 0.001386  [ 1600/ 3410]
loss: 0.003239  [ 1700/ 3410]
loss: 0.005146  [ 1800/ 3410]
loss: 0.001371  [ 1900/ 3410]
loss: 0.055528  [ 2000/ 3410]
loss: 0.003481  [ 2100/ 3410]
loss: 0.022737  [ 2200/ 3410]
loss: 0.003077  [ 2300/ 3410]
loss: 0.002799  [ 2400/ 3410]
loss: 0.074588  [ 2500/ 3410]
loss: 0.002555  [ 2600/ 3410]
loss: 0.004286  [ 2700/ 3410]
loss: 0.000865  [ 2800/ 3410]
loss: 0.005972  [ 2900/ 3410]
loss: 0.002620  [ 3000/ 3410]
loss: 0.000643  [ 3100/ 3410]
loss: 0.001200  [ 3200/ 3410]
loss: 0.001180  [ 3300/ 3410]
loss: 0.001065  [ 3400/ 3410]
Epoch 8
-------------------------------
loss: 0.000532  [    0/ 3410]
loss: 0.003013  [  100/ 3410]
loss: 0.004500  [  200/ 3410]
loss: 0.002671  [  300/ 3410]
loss: 0.002112  [  400/ 3410]
loss: 0.004870  [  500/ 3410]
loss: 0.000733  [  600/ 3410]
loss: 0.005666  [  700/ 3410]
loss: 0.003389  [  800/ 3410]
loss: 0.002289  [  900/ 3410]
loss: 0.004398  [ 1000/ 3410]
loss: 0.001922  [ 1100/ 3410]
loss: 0.002534  [ 1200/ 3410]
loss: 0.004928  [ 1300/ 3410]
loss: 0.001095  [ 1400/ 3410]
loss: 0.000963  [ 1500/ 3410]
loss: 0.001461  [ 1600/ 3410]
loss: 0.003134  [ 1700/ 3410]
loss: 0.005413  [ 1800/ 3410]
loss: 0.001396  [ 1900/ 3410]
loss: 0.054681  [ 2000/ 3410]
loss: 0.003503  [ 2100/ 3410]
loss: 0.022418  [ 2200/ 3410]
loss: 0.003223  [ 2300/ 3410]
loss: 0.002850  [ 2400/ 3410]
loss: 0.072709  [ 2500/ 3410]
loss: 0.002588  [ 2600/ 3410]
loss: 0.004341  [ 2700/ 3410]
loss: 0.000870  [ 2800/ 3410]
loss: 0.005769  [ 2900/ 3410]
loss: 0.002569  [ 3000/ 3410]
loss: 0.000631  [ 3100/ 3410]
loss: 0.001191  [ 3200/ 3410]
loss: 0.001184  [ 3300/ 3410]
loss: 0.000926  [ 3400/ 3410]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3410
First Spike after testing: [-1.0733948  -0.73500687]
[2 2 2 ... 2 0 2]
[2 2 2 ... 2 1 2]
Cluster 0 Occurrences: 1130; KMEANS: 1081
Cluster 1 Occurrences: 1113; KMEANS: 1163
Cluster 2 Occurrences: 1167; KMEANS: 1166
Centroids: [[1.8837273, -1.2222348], [0.5234746, -0.45959067], [-1.0743024, -0.62538385]]
Centroids: [[0.46434852, -0.4412653], [1.9000566, -1.2188038], [-1.0756423, -0.6243535]]
Contingency Matrix: 
[[  13 1117    0]
 [1065   46    2]
 [   3    0 1164]]
[[13, 1117, -1], [1065, 46, -1], [-1, -1, -1]]
[[-1, -1, -1], [1065, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 1, 1: 0}
New Contingency Matrix: 
[[1117   13    0]
 [  46 1065    2]
 [   0    3 1164]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [1117, 1065, 1164], Sum: 3346
All_Elements: [1117, 13, 0, 46, 1065, 2, 0, 3, 1164], Sum: 3410
Accuracy: 0.9812316715542522
Done!
