Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_56_31
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B871C0E48>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x0000019B2610BC88>
Epoch 1
-------------------------------
loss: 0.203774  [    0/ 3383]
loss: 0.046438  [  100/ 3383]
loss: 0.015194  [  200/ 3383]
loss: 0.007457  [  300/ 3383]
loss: 0.005134  [  400/ 3383]
loss: 0.009386  [  500/ 3383]
loss: 0.007292  [  600/ 3383]
loss: 0.011560  [  700/ 3383]
loss: 0.007230  [  800/ 3383]
loss: 0.006819  [  900/ 3383]
loss: 0.093064  [ 1000/ 3383]
loss: 0.058383  [ 1100/ 3383]
loss: 0.024699  [ 1200/ 3383]
loss: 0.010707  [ 1300/ 3383]
loss: 0.003639  [ 1400/ 3383]
loss: 0.011965  [ 1500/ 3383]
loss: 0.002501  [ 1600/ 3383]
loss: 0.001640  [ 1700/ 3383]
loss: 0.011778  [ 1800/ 3383]
loss: 0.014190  [ 1900/ 3383]
loss: 0.003504  [ 2000/ 3383]
loss: 0.003644  [ 2100/ 3383]
loss: 0.008823  [ 2200/ 3383]
loss: 0.001238  [ 2300/ 3383]
loss: 0.004079  [ 2400/ 3383]
loss: 0.028481  [ 2500/ 3383]
loss: 0.001619  [ 2600/ 3383]
loss: 0.003861  [ 2700/ 3383]
loss: 0.006406  [ 2800/ 3383]
loss: 0.005434  [ 2900/ 3383]
loss: 0.004234  [ 3000/ 3383]
loss: 0.004573  [ 3100/ 3383]
loss: 0.064543  [ 3200/ 3383]
loss: 0.002254  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.004033  [    0/ 3383]
loss: 0.005891  [  100/ 3383]
loss: 0.005741  [  200/ 3383]
loss: 0.002338  [  300/ 3383]
loss: 0.003074  [  400/ 3383]
loss: 0.005027  [  500/ 3383]
loss: 0.001078  [  600/ 3383]
loss: 0.002122  [  700/ 3383]
loss: 0.007471  [  800/ 3383]
loss: 0.001438  [  900/ 3383]
loss: 0.091177  [ 1000/ 3383]
loss: 0.057899  [ 1100/ 3383]
loss: 0.022686  [ 1200/ 3383]
loss: 0.009251  [ 1300/ 3383]
loss: 0.004125  [ 1400/ 3383]
loss: 0.014784  [ 1500/ 3383]
loss: 0.002666  [ 1600/ 3383]
loss: 0.001529  [ 1700/ 3383]
loss: 0.012304  [ 1800/ 3383]
loss: 0.014217  [ 1900/ 3383]
loss: 0.003075  [ 2000/ 3383]
loss: 0.003490  [ 2100/ 3383]
loss: 0.008925  [ 2200/ 3383]
loss: 0.001361  [ 2300/ 3383]
loss: 0.004354  [ 2400/ 3383]
loss: 0.029026  [ 2500/ 3383]
loss: 0.001404  [ 2600/ 3383]
loss: 0.003285  [ 2700/ 3383]
loss: 0.006321  [ 2800/ 3383]
loss: 0.005769  [ 2900/ 3383]
loss: 0.003768  [ 3000/ 3383]
loss: 0.004409  [ 3100/ 3383]
loss: 0.064447  [ 3200/ 3383]
loss: 0.002360  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.004174  [    0/ 3383]
loss: 0.005951  [  100/ 3383]
loss: 0.005872  [  200/ 3383]
loss: 0.002297  [  300/ 3383]
loss: 0.003069  [  400/ 3383]
loss: 0.004971  [  500/ 3383]
loss: 0.001129  [  600/ 3383]
loss: 0.002011  [  700/ 3383]
loss: 0.007512  [  800/ 3383]
loss: 0.001520  [  900/ 3383]
loss: 0.091770  [ 1000/ 3383]
loss: 0.057880  [ 1100/ 3383]
loss: 0.022636  [ 1200/ 3383]
loss: 0.009309  [ 1300/ 3383]
loss: 0.004189  [ 1400/ 3383]
loss: 0.014594  [ 1500/ 3383]
loss: 0.002696  [ 1600/ 3383]
loss: 0.001517  [ 1700/ 3383]
loss: 0.012437  [ 1800/ 3383]
loss: 0.014112  [ 1900/ 3383]
loss: 0.003123  [ 2000/ 3383]
loss: 0.003665  [ 2100/ 3383]
loss: 0.007980  [ 2200/ 3383]
loss: 0.001490  [ 2300/ 3383]
loss: 0.004066  [ 2400/ 3383]
loss: 0.028524  [ 2500/ 3383]
loss: 0.001223  [ 2600/ 3383]
loss: 0.002612  [ 2700/ 3383]
loss: 0.006486  [ 2800/ 3383]
loss: 0.005638  [ 2900/ 3383]
loss: 0.004038  [ 3000/ 3383]
loss: 0.004469  [ 3100/ 3383]
loss: 0.064170  [ 3200/ 3383]
loss: 0.002311  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.004251  [    0/ 3383]
loss: 0.005842  [  100/ 3383]
loss: 0.005676  [  200/ 3383]
loss: 0.002425  [  300/ 3383]
loss: 0.002961  [  400/ 3383]
loss: 0.004887  [  500/ 3383]
loss: 0.001165  [  600/ 3383]
loss: 0.002248  [  700/ 3383]
loss: 0.007590  [  800/ 3383]
loss: 0.001562  [  900/ 3383]
loss: 0.091978  [ 1000/ 3383]
loss: 0.057402  [ 1100/ 3383]
loss: 0.022806  [ 1200/ 3383]
loss: 0.009232  [ 1300/ 3383]
loss: 0.004193  [ 1400/ 3383]
loss: 0.014249  [ 1500/ 3383]
loss: 0.002627  [ 1600/ 3383]
loss: 0.001528  [ 1700/ 3383]
loss: 0.012232  [ 1800/ 3383]
loss: 0.014001  [ 1900/ 3383]
loss: 0.003133  [ 2000/ 3383]
loss: 0.003660  [ 2100/ 3383]
loss: 0.007164  [ 2200/ 3383]
loss: 0.001793  [ 2300/ 3383]
loss: 0.003989  [ 2400/ 3383]
loss: 0.028392  [ 2500/ 3383]
loss: 0.001192  [ 2600/ 3383]
loss: 0.002458  [ 2700/ 3383]
loss: 0.006515  [ 2800/ 3383]
loss: 0.005641  [ 2900/ 3383]
loss: 0.003696  [ 3000/ 3383]
loss: 0.004486  [ 3100/ 3383]
loss: 0.064044  [ 3200/ 3383]
loss: 0.002419  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.004082  [    0/ 3383]
loss: 0.005671  [  100/ 3383]
loss: 0.005208  [  200/ 3383]
loss: 0.002481  [  300/ 3383]
loss: 0.002901  [  400/ 3383]
loss: 0.004688  [  500/ 3383]
loss: 0.001169  [  600/ 3383]
loss: 0.002256  [  700/ 3383]
loss: 0.007654  [  800/ 3383]
loss: 0.001495  [  900/ 3383]
loss: 0.093590  [ 1000/ 3383]
loss: 0.057277  [ 1100/ 3383]
loss: 0.022845  [ 1200/ 3383]
loss: 0.009124  [ 1300/ 3383]
loss: 0.004152  [ 1400/ 3383]
loss: 0.014159  [ 1500/ 3383]
loss: 0.002569  [ 1600/ 3383]
loss: 0.001528  [ 1700/ 3383]
loss: 0.012206  [ 1800/ 3383]
loss: 0.013974  [ 1900/ 3383]
loss: 0.003133  [ 2000/ 3383]
loss: 0.003688  [ 2100/ 3383]
loss: 0.006961  [ 2200/ 3383]
loss: 0.001825  [ 2300/ 3383]
loss: 0.003981  [ 2400/ 3383]
loss: 0.028777  [ 2500/ 3383]
loss: 0.001163  [ 2600/ 3383]
loss: 0.002385  [ 2700/ 3383]
loss: 0.006467  [ 2800/ 3383]
loss: 0.005661  [ 2900/ 3383]
loss: 0.003466  [ 3000/ 3383]
loss: 0.004498  [ 3100/ 3383]
loss: 0.064007  [ 3200/ 3383]
loss: 0.002372  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.004082  [    0/ 3383]
loss: 0.005522  [  100/ 3383]
loss: 0.005047  [  200/ 3383]
loss: 0.002416  [  300/ 3383]
loss: 0.002875  [  400/ 3383]
loss: 0.004618  [  500/ 3383]
loss: 0.001163  [  600/ 3383]
loss: 0.002440  [  700/ 3383]
loss: 0.007662  [  800/ 3383]
loss: 0.001570  [  900/ 3383]
loss: 0.094731  [ 1000/ 3383]
loss: 0.057352  [ 1100/ 3383]
loss: 0.022948  [ 1200/ 3383]
loss: 0.009073  [ 1300/ 3383]
loss: 0.004139  [ 1400/ 3383]
loss: 0.014192  [ 1500/ 3383]
loss: 0.002543  [ 1600/ 3383]
loss: 0.001531  [ 1700/ 3383]
loss: 0.012121  [ 1800/ 3383]
loss: 0.013987  [ 1900/ 3383]
loss: 0.003123  [ 2000/ 3383]
loss: 0.003650  [ 2100/ 3383]
loss: 0.006959  [ 2200/ 3383]
loss: 0.001780  [ 2300/ 3383]
loss: 0.003923  [ 2400/ 3383]
loss: 0.029100  [ 2500/ 3383]
loss: 0.001148  [ 2600/ 3383]
loss: 0.002384  [ 2700/ 3383]
loss: 0.006470  [ 2800/ 3383]
loss: 0.005701  [ 2900/ 3383]
loss: 0.003359  [ 3000/ 3383]
loss: 0.004511  [ 3100/ 3383]
loss: 0.064029  [ 3200/ 3383]
loss: 0.002401  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.004069  [    0/ 3383]
loss: 0.005534  [  100/ 3383]
loss: 0.005044  [  200/ 3383]
loss: 0.002452  [  300/ 3383]
loss: 0.002900  [  400/ 3383]
loss: 0.004634  [  500/ 3383]
loss: 0.001179  [  600/ 3383]
loss: 0.002395  [  700/ 3383]
loss: 0.007647  [  800/ 3383]
loss: 0.001583  [  900/ 3383]
loss: 0.094553  [ 1000/ 3383]
loss: 0.057393  [ 1100/ 3383]
loss: 0.023036  [ 1200/ 3383]
loss: 0.009090  [ 1300/ 3383]
loss: 0.004153  [ 1400/ 3383]
loss: 0.014278  [ 1500/ 3383]
loss: 0.002515  [ 1600/ 3383]
loss: 0.001531  [ 1700/ 3383]
loss: 0.011959  [ 1800/ 3383]
loss: 0.014008  [ 1900/ 3383]
loss: 0.003093  [ 2000/ 3383]
loss: 0.003571  [ 2100/ 3383]
loss: 0.007113  [ 2200/ 3383]
loss: 0.001770  [ 2300/ 3383]
loss: 0.003899  [ 2400/ 3383]
loss: 0.027647  [ 2500/ 3383]
loss: 0.001099  [ 2600/ 3383]
loss: 0.002415  [ 2700/ 3383]
loss: 0.006430  [ 2800/ 3383]
loss: 0.005852  [ 2900/ 3383]
loss: 0.003330  [ 3000/ 3383]
loss: 0.004526  [ 3100/ 3383]
loss: 0.063979  [ 3200/ 3383]
loss: 0.002435  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.004065  [    0/ 3383]
loss: 0.005513  [  100/ 3383]
loss: 0.005015  [  200/ 3383]
loss: 0.002372  [  300/ 3383]
loss: 0.002912  [  400/ 3383]
loss: 0.004607  [  500/ 3383]
loss: 0.001184  [  600/ 3383]
loss: 0.002301  [  700/ 3383]
loss: 0.007613  [  800/ 3383]
loss: 0.001622  [  900/ 3383]
loss: 0.095525  [ 1000/ 3383]
loss: 0.057432  [ 1100/ 3383]
loss: 0.023145  [ 1200/ 3383]
loss: 0.009113  [ 1300/ 3383]
loss: 0.004154  [ 1400/ 3383]
loss: 0.014391  [ 1500/ 3383]
loss: 0.002512  [ 1600/ 3383]
loss: 0.001519  [ 1700/ 3383]
loss: 0.011834  [ 1800/ 3383]
loss: 0.014041  [ 1900/ 3383]
loss: 0.003091  [ 2000/ 3383]
loss: 0.003523  [ 2100/ 3383]
loss: 0.007293  [ 2200/ 3383]
loss: 0.001685  [ 2300/ 3383]
loss: 0.003847  [ 2400/ 3383]
loss: 0.027904  [ 2500/ 3383]
loss: 0.001081  [ 2600/ 3383]
loss: 0.002292  [ 2700/ 3383]
loss: 0.006381  [ 2800/ 3383]
loss: 0.005880  [ 2900/ 3383]
loss: 0.003222  [ 3000/ 3383]
loss: 0.004538  [ 3100/ 3383]
loss: 0.064180  [ 3200/ 3383]
loss: 0.002459  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [-0.8965966   0.59525317]
[2 1 2 ... 0 1 2]
[1 0 1 ... 2 0 1]
Cluster 0 Occurrences: 1115; KMEANS: 1099
Cluster 1 Occurrences: 1113; KMEANS: 1187
Cluster 2 Occurrences: 1155; KMEANS: 1097
Centroids: [[-0.3552244, 0.58798623], [-0.10584965, -0.47891676], [-0.90343994, 0.28427964]]
Centroids: [[-0.086433604, -0.5091465], [-0.9148767, 0.28958312], [-0.34312668, 0.60777587]]
Contingency Matrix: 
[[   6   28 1081]
 [1076   28    9]
 [  17 1131    7]]
[[6, -1, 1081], [1076, -1, 9], [-1, -1, -1]]
[[-1, -1, -1], [1076, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[1081    6   28]
 [   9 1076   28]
 [   7   17 1131]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1081, 1076, 1131], Sum: 3288
All_Elements: [1081, 6, 28, 9, 1076, 28, 7, 17, 1131], Sum: 3383
Accuracy: 0.971918415607449
Done!
