Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Difficult1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_57_47
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B30AE6128>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
<torch.utils.data.dataloader.DataLoader object at 0x0000019B89ADF3C8>
Epoch 1
-------------------------------
loss: 0.210831  [    0/ 3448]
loss: 0.044100  [  100/ 3448]
loss: 0.019252  [  200/ 3448]
loss: 0.032641  [  300/ 3448]
loss: 0.019904  [  400/ 3448]
loss: 0.012063  [  500/ 3448]
loss: 0.016146  [  600/ 3448]
loss: 0.008695  [  700/ 3448]
loss: 0.009545  [  800/ 3448]
loss: 0.019004  [  900/ 3448]
loss: 0.093389  [ 1000/ 3448]
loss: 0.014612  [ 1100/ 3448]
loss: 0.007819  [ 1200/ 3448]
loss: 0.127925  [ 1300/ 3448]
loss: 0.004967  [ 1400/ 3448]
loss: 0.027938  [ 1500/ 3448]
loss: 0.008245  [ 1600/ 3448]
loss: 0.007975  [ 1700/ 3448]
loss: 0.006871  [ 1800/ 3448]
loss: 0.017699  [ 1900/ 3448]
loss: 0.008391  [ 2000/ 3448]
loss: 0.002543  [ 2100/ 3448]
loss: 0.004607  [ 2200/ 3448]
loss: 0.006113  [ 2300/ 3448]
loss: 0.008366  [ 2400/ 3448]
loss: 0.008849  [ 2500/ 3448]
loss: 0.012370  [ 2600/ 3448]
loss: 0.010665  [ 2700/ 3448]
loss: 0.005405  [ 2800/ 3448]
loss: 0.003552  [ 2900/ 3448]
loss: 0.004398  [ 3000/ 3448]
loss: 0.010309  [ 3100/ 3448]
loss: 0.013353  [ 3200/ 3448]
loss: 0.011344  [ 3300/ 3448]
loss: 0.006632  [ 3400/ 3448]
Epoch 2
-------------------------------
loss: 0.021151  [    0/ 3448]
loss: 0.008476  [  100/ 3448]
loss: 0.002263  [  200/ 3448]
loss: 0.005386  [  300/ 3448]
loss: 0.008426  [  400/ 3448]
loss: 0.012820  [  500/ 3448]
loss: 0.006967  [  600/ 3448]
loss: 0.007398  [  700/ 3448]
loss: 0.004079  [  800/ 3448]
loss: 0.006802  [  900/ 3448]
loss: 0.086310  [ 1000/ 3448]
loss: 0.015390  [ 1100/ 3448]
loss: 0.008652  [ 1200/ 3448]
loss: 0.126419  [ 1300/ 3448]
loss: 0.006265  [ 1400/ 3448]
loss: 0.022418  [ 1500/ 3448]
loss: 0.004156  [ 1600/ 3448]
loss: 0.010738  [ 1700/ 3448]
loss: 0.006147  [ 1800/ 3448]
loss: 0.017559  [ 1900/ 3448]
loss: 0.008696  [ 2000/ 3448]
loss: 0.003084  [ 2100/ 3448]
loss: 0.005521  [ 2200/ 3448]
loss: 0.005788  [ 2300/ 3448]
loss: 0.007733  [ 2400/ 3448]
loss: 0.008358  [ 2500/ 3448]
loss: 0.012592  [ 2600/ 3448]
loss: 0.009411  [ 2700/ 3448]
loss: 0.006003  [ 2800/ 3448]
loss: 0.003030  [ 2900/ 3448]
loss: 0.004317  [ 3000/ 3448]
loss: 0.012010  [ 3100/ 3448]
loss: 0.013179  [ 3200/ 3448]
loss: 0.010921  [ 3300/ 3448]
loss: 0.006652  [ 3400/ 3448]
Epoch 3
-------------------------------
loss: 0.021262  [    0/ 3448]
loss: 0.008504  [  100/ 3448]
loss: 0.002024  [  200/ 3448]
loss: 0.004234  [  300/ 3448]
loss: 0.007233  [  400/ 3448]
loss: 0.013181  [  500/ 3448]
loss: 0.006625  [  600/ 3448]
loss: 0.007655  [  700/ 3448]
loss: 0.003948  [  800/ 3448]
loss: 0.006096  [  900/ 3448]
loss: 0.085185  [ 1000/ 3448]
loss: 0.015300  [ 1100/ 3448]
loss: 0.008761  [ 1200/ 3448]
loss: 0.125893  [ 1300/ 3448]
loss: 0.006334  [ 1400/ 3448]
loss: 0.021706  [ 1500/ 3448]
loss: 0.004029  [ 1600/ 3448]
loss: 0.011020  [ 1700/ 3448]
loss: 0.006368  [ 1800/ 3448]
loss: 0.017245  [ 1900/ 3448]
loss: 0.008730  [ 2000/ 3448]
loss: 0.003192  [ 2100/ 3448]
loss: 0.005602  [ 2200/ 3448]
loss: 0.005772  [ 2300/ 3448]
loss: 0.007682  [ 2400/ 3448]
loss: 0.008244  [ 2500/ 3448]
loss: 0.012653  [ 2600/ 3448]
loss: 0.009347  [ 2700/ 3448]
loss: 0.006181  [ 2800/ 3448]
loss: 0.002911  [ 2900/ 3448]
loss: 0.004231  [ 3000/ 3448]
loss: 0.012431  [ 3100/ 3448]
loss: 0.013039  [ 3200/ 3448]
loss: 0.010834  [ 3300/ 3448]
loss: 0.006641  [ 3400/ 3448]
Epoch 4
-------------------------------
loss: 0.021115  [    0/ 3448]
loss: 0.008287  [  100/ 3448]
loss: 0.001997  [  200/ 3448]
loss: 0.004142  [  300/ 3448]
loss: 0.007085  [  400/ 3448]
loss: 0.013201  [  500/ 3448]
loss: 0.006539  [  600/ 3448]
loss: 0.007726  [  700/ 3448]
loss: 0.003984  [  800/ 3448]
loss: 0.005889  [  900/ 3448]
loss: 0.085088  [ 1000/ 3448]
loss: 0.015166  [ 1100/ 3448]
loss: 0.008705  [ 1200/ 3448]
loss: 0.125518  [ 1300/ 3448]
loss: 0.006319  [ 1400/ 3448]
loss: 0.021544  [ 1500/ 3448]
loss: 0.004019  [ 1600/ 3448]
loss: 0.011095  [ 1700/ 3448]
loss: 0.006490  [ 1800/ 3448]
loss: 0.017161  [ 1900/ 3448]
loss: 0.008581  [ 2000/ 3448]
loss: 0.003256  [ 2100/ 3448]
loss: 0.005604  [ 2200/ 3448]
loss: 0.005783  [ 2300/ 3448]
loss: 0.007663  [ 2400/ 3448]
loss: 0.008209  [ 2500/ 3448]
loss: 0.012731  [ 2600/ 3448]
loss: 0.009308  [ 2700/ 3448]
loss: 0.006310  [ 2800/ 3448]
loss: 0.002831  [ 2900/ 3448]
loss: 0.004152  [ 3000/ 3448]
loss: 0.012603  [ 3100/ 3448]
loss: 0.013078  [ 3200/ 3448]
loss: 0.010832  [ 3300/ 3448]
loss: 0.006643  [ 3400/ 3448]
Epoch 5
-------------------------------
loss: 0.020983  [    0/ 3448]
loss: 0.008059  [  100/ 3448]
loss: 0.002022  [  200/ 3448]
loss: 0.004265  [  300/ 3448]
loss: 0.007014  [  400/ 3448]
loss: 0.013167  [  500/ 3448]
loss: 0.006491  [  600/ 3448]
loss: 0.007754  [  700/ 3448]
loss: 0.003987  [  800/ 3448]
loss: 0.005583  [  900/ 3448]
loss: 0.085374  [ 1000/ 3448]
loss: 0.015215  [ 1100/ 3448]
loss: 0.008643  [ 1200/ 3448]
loss: 0.125071  [ 1300/ 3448]
loss: 0.006358  [ 1400/ 3448]
loss: 0.022061  [ 1500/ 3448]
loss: 0.004052  [ 1600/ 3448]
loss: 0.010931  [ 1700/ 3448]
loss: 0.006663  [ 1800/ 3448]
loss: 0.017171  [ 1900/ 3448]
loss: 0.008489  [ 2000/ 3448]
loss: 0.003266  [ 2100/ 3448]
loss: 0.005614  [ 2200/ 3448]
loss: 0.005771  [ 2300/ 3448]
loss: 0.007522  [ 2400/ 3448]
loss: 0.008196  [ 2500/ 3448]
loss: 0.012754  [ 2600/ 3448]
loss: 0.009347  [ 2700/ 3448]
loss: 0.006406  [ 2800/ 3448]
loss: 0.002752  [ 2900/ 3448]
loss: 0.004093  [ 3000/ 3448]
loss: 0.012628  [ 3100/ 3448]
loss: 0.013077  [ 3200/ 3448]
loss: 0.010834  [ 3300/ 3448]
loss: 0.006613  [ 3400/ 3448]
Epoch 6
-------------------------------
loss: 0.020466  [    0/ 3448]
loss: 0.007871  [  100/ 3448]
loss: 0.002056  [  200/ 3448]
loss: 0.004526  [  300/ 3448]
loss: 0.007024  [  400/ 3448]
loss: 0.013127  [  500/ 3448]
loss: 0.006629  [  600/ 3448]
loss: 0.007711  [  700/ 3448]
loss: 0.004091  [  800/ 3448]
loss: 0.005438  [  900/ 3448]
loss: 0.085511  [ 1000/ 3448]
loss: 0.015215  [ 1100/ 3448]
loss: 0.008569  [ 1200/ 3448]
loss: 0.125662  [ 1300/ 3448]
loss: 0.006379  [ 1400/ 3448]
loss: 0.022259  [ 1500/ 3448]
loss: 0.003922  [ 1600/ 3448]
loss: 0.010897  [ 1700/ 3448]
loss: 0.006591  [ 1800/ 3448]
loss: 0.017213  [ 1900/ 3448]
loss: 0.008443  [ 2000/ 3448]
loss: 0.003246  [ 2100/ 3448]
loss: 0.005576  [ 2200/ 3448]
loss: 0.005776  [ 2300/ 3448]
loss: 0.007517  [ 2400/ 3448]
loss: 0.008245  [ 2500/ 3448]
loss: 0.012759  [ 2600/ 3448]
loss: 0.009299  [ 2700/ 3448]
loss: 0.006386  [ 2800/ 3448]
loss: 0.002632  [ 2900/ 3448]
loss: 0.004131  [ 3000/ 3448]
loss: 0.012606  [ 3100/ 3448]
loss: 0.013067  [ 3200/ 3448]
loss: 0.010895  [ 3300/ 3448]
loss: 0.006576  [ 3400/ 3448]
Epoch 7
-------------------------------
loss: 0.020202  [    0/ 3448]
loss: 0.007703  [  100/ 3448]
loss: 0.002079  [  200/ 3448]
loss: 0.005350  [  300/ 3448]
loss: 0.007094  [  400/ 3448]
loss: 0.013072  [  500/ 3448]
loss: 0.006753  [  600/ 3448]
loss: 0.007681  [  700/ 3448]
loss: 0.004270  [  800/ 3448]
loss: 0.005471  [  900/ 3448]
loss: 0.085733  [ 1000/ 3448]
loss: 0.015589  [ 1100/ 3448]
loss: 0.008551  [ 1200/ 3448]
loss: 0.125518  [ 1300/ 3448]
loss: 0.006334  [ 1400/ 3448]
loss: 0.022154  [ 1500/ 3448]
loss: 0.003782  [ 1600/ 3448]
loss: 0.011090  [ 1700/ 3448]
loss: 0.006627  [ 1800/ 3448]
loss: 0.017226  [ 1900/ 3448]
loss: 0.008344  [ 2000/ 3448]
loss: 0.003288  [ 2100/ 3448]
loss: 0.005641  [ 2200/ 3448]
loss: 0.005776  [ 2300/ 3448]
loss: 0.007845  [ 2400/ 3448]
loss: 0.008281  [ 2500/ 3448]
loss: 0.012848  [ 2600/ 3448]
loss: 0.009350  [ 2700/ 3448]
loss: 0.006428  [ 2800/ 3448]
loss: 0.002574  [ 2900/ 3448]
loss: 0.004150  [ 3000/ 3448]
loss: 0.012533  [ 3100/ 3448]
loss: 0.012608  [ 3200/ 3448]
loss: 0.010887  [ 3300/ 3448]
loss: 0.006510  [ 3400/ 3448]
Epoch 8
-------------------------------
loss: 0.020351  [    0/ 3448]
loss: 0.007598  [  100/ 3448]
loss: 0.002208  [  200/ 3448]
loss: 0.005035  [  300/ 3448]
loss: 0.007083  [  400/ 3448]
loss: 0.012753  [  500/ 3448]
loss: 0.006850  [  600/ 3448]
loss: 0.007657  [  700/ 3448]
loss: 0.004222  [  800/ 3448]
loss: 0.005616  [  900/ 3448]
loss: 0.085598  [ 1000/ 3448]
loss: 0.014920  [ 1100/ 3448]
loss: 0.008591  [ 1200/ 3448]
loss: 0.125555  [ 1300/ 3448]
loss: 0.006356  [ 1400/ 3448]
loss: 0.022079  [ 1500/ 3448]
loss: 0.003751  [ 1600/ 3448]
loss: 0.011233  [ 1700/ 3448]
loss: 0.006400  [ 1800/ 3448]
loss: 0.017342  [ 1900/ 3448]
loss: 0.008287  [ 2000/ 3448]
loss: 0.003255  [ 2100/ 3448]
loss: 0.005649  [ 2200/ 3448]
loss: 0.005734  [ 2300/ 3448]
loss: 0.007798  [ 2400/ 3448]
loss: 0.008290  [ 2500/ 3448]
loss: 0.012774  [ 2600/ 3448]
loss: 0.009386  [ 2700/ 3448]
loss: 0.006400  [ 2800/ 3448]
loss: 0.002465  [ 2900/ 3448]
loss: 0.004149  [ 3000/ 3448]
loss: 0.012650  [ 3100/ 3448]
loss: 0.012192  [ 3200/ 3448]
loss: 0.010939  [ 3300/ 3448]
loss: 0.006519  [ 3400/ 3448]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3448
First Spike after testing: [-0.9250638   0.25939158]
[2 2 2 ... 1 0 2]
[1 1 1 ... 0 2 1]
Cluster 0 Occurrences: 1164; KMEANS: 1056
Cluster 1 Occurrences: 1155; KMEANS: 988
Cluster 2 Occurrences: 1129; KMEANS: 1404
Centroids: [[-0.6387105, 0.25858325], [-0.49755055, -0.34291938], [-1.0560533, 0.14653493]]
Centroids: [[-0.44088185, -0.40899906], [-1.1107689, 0.30764407], [-0.6747888, 0.14124477]]
Contingency Matrix: 
[[ 63 164 937]
 [947  34 174]
 [ 46 790 293]]
[[-1, 164, 937], [-1, -1, -1], [-1, 790, 293]]
[[-1, -1, -1], [-1, -1, -1], [-1, 790, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 0, 0: 2, 2: 1}
New Contingency Matrix: 
[[937  63 164]
 [174 947  34]
 [293  46 790]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [937, 947, 790], Sum: 2674
All_Elements: [937, 63, 164, 174, 947, 34, 293, 46, 790], Sum: 3448
Accuracy: 0.775522041763341
Done!
