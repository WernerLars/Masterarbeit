Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Difficult1_noise020.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_01_17
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B31F5DD68>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
<torch.utils.data.dataloader.DataLoader object at 0x0000019B89ADF3C8>
Epoch 1
-------------------------------
loss: 0.238196  [    0/ 3414]
loss: 0.073377  [  100/ 3414]
loss: 0.018825  [  200/ 3414]
loss: 0.044277  [  300/ 3414]
loss: 0.052327  [  400/ 3414]
loss: 0.060620  [  500/ 3414]
loss: 0.027125  [  600/ 3414]
loss: 0.045182  [  700/ 3414]
loss: 0.067191  [  800/ 3414]
loss: 0.026665  [  900/ 3414]
loss: 0.015858  [ 1000/ 3414]
loss: 0.018416  [ 1100/ 3414]
loss: 0.047670  [ 1200/ 3414]
loss: 0.020281  [ 1300/ 3414]
loss: 0.019573  [ 1400/ 3414]
loss: 0.033617  [ 1500/ 3414]
loss: 0.028131  [ 1600/ 3414]
loss: 0.016893  [ 1700/ 3414]
loss: 0.030755  [ 1800/ 3414]
loss: 0.045591  [ 1900/ 3414]
loss: 0.019117  [ 2000/ 3414]
loss: 0.044327  [ 2100/ 3414]
loss: 0.038466  [ 2200/ 3414]
loss: 0.035771  [ 2300/ 3414]
loss: 0.010790  [ 2400/ 3414]
loss: 0.110014  [ 2500/ 3414]
loss: 0.009261  [ 2600/ 3414]
loss: 0.010604  [ 2700/ 3414]
loss: 0.036225  [ 2800/ 3414]
loss: 0.036666  [ 2900/ 3414]
loss: 0.053961  [ 3000/ 3414]
loss: 0.045701  [ 3100/ 3414]
loss: 0.029195  [ 3200/ 3414]
loss: 0.013273  [ 3300/ 3414]
loss: 0.031742  [ 3400/ 3414]
Epoch 2
-------------------------------
loss: 0.077406  [    0/ 3414]
loss: 0.024907  [  100/ 3414]
loss: 0.008026  [  200/ 3414]
loss: 0.048533  [  300/ 3414]
loss: 0.024541  [  400/ 3414]
loss: 0.041853  [  500/ 3414]
loss: 0.018134  [  600/ 3414]
loss: 0.049197  [  700/ 3414]
loss: 0.051064  [  800/ 3414]
loss: 0.026465  [  900/ 3414]
loss: 0.015649  [ 1000/ 3414]
loss: 0.022913  [ 1100/ 3414]
loss: 0.008336  [ 1200/ 3414]
loss: 0.030276  [ 1300/ 3414]
loss: 0.018343  [ 1400/ 3414]
loss: 0.029592  [ 1500/ 3414]
loss: 0.010908  [ 1600/ 3414]
loss: 0.008131  [ 1700/ 3414]
loss: 0.033012  [ 1800/ 3414]
loss: 0.024359  [ 1900/ 3414]
loss: 0.030147  [ 2000/ 3414]
loss: 0.037909  [ 2100/ 3414]
loss: 0.039393  [ 2200/ 3414]
loss: 0.033408  [ 2300/ 3414]
loss: 0.009239  [ 2400/ 3414]
loss: 0.157440  [ 2500/ 3414]
loss: 0.025641  [ 2600/ 3414]
loss: 0.014581  [ 2700/ 3414]
loss: 0.015981  [ 2800/ 3414]
loss: 0.039155  [ 2900/ 3414]
loss: 0.049245  [ 3000/ 3414]
loss: 0.037613  [ 3100/ 3414]
loss: 0.019871  [ 3200/ 3414]
loss: 0.013374  [ 3300/ 3414]
loss: 0.025922  [ 3400/ 3414]
Epoch 3
-------------------------------
loss: 0.048708  [    0/ 3414]
loss: 0.028739  [  100/ 3414]
loss: 0.008069  [  200/ 3414]
loss: 0.049484  [  300/ 3414]
loss: 0.014075  [  400/ 3414]
loss: 0.044819  [  500/ 3414]
loss: 0.025825  [  600/ 3414]
loss: 0.036188  [  700/ 3414]
loss: 0.051498  [  800/ 3414]
loss: 0.020656  [  900/ 3414]
loss: 0.016103  [ 1000/ 3414]
loss: 0.023751  [ 1100/ 3414]
loss: 0.005855  [ 1200/ 3414]
loss: 0.032339  [ 1300/ 3414]
loss: 0.018233  [ 1400/ 3414]
loss: 0.029371  [ 1500/ 3414]
loss: 0.011303  [ 1600/ 3414]
loss: 0.010134  [ 1700/ 3414]
loss: 0.031857  [ 1800/ 3414]
loss: 0.021692  [ 1900/ 3414]
loss: 0.033359  [ 2000/ 3414]
loss: 0.034130  [ 2100/ 3414]
loss: 0.039674  [ 2200/ 3414]
loss: 0.033081  [ 2300/ 3414]
loss: 0.008786  [ 2400/ 3414]
loss: 0.155852  [ 2500/ 3414]
loss: 0.026116  [ 2600/ 3414]
loss: 0.014750  [ 2700/ 3414]
loss: 0.013334  [ 2800/ 3414]
loss: 0.039562  [ 2900/ 3414]
loss: 0.046658  [ 3000/ 3414]
loss: 0.035546  [ 3100/ 3414]
loss: 0.020423  [ 3200/ 3414]
loss: 0.013115  [ 3300/ 3414]
loss: 0.025358  [ 3400/ 3414]
Epoch 4
-------------------------------
loss: 0.043439  [    0/ 3414]
loss: 0.029100  [  100/ 3414]
loss: 0.008253  [  200/ 3414]
loss: 0.049481  [  300/ 3414]
loss: 0.013802  [  400/ 3414]
loss: 0.044985  [  500/ 3414]
loss: 0.027101  [  600/ 3414]
loss: 0.034771  [  700/ 3414]
loss: 0.051573  [  800/ 3414]
loss: 0.019848  [  900/ 3414]
loss: 0.016249  [ 1000/ 3414]
loss: 0.023762  [ 1100/ 3414]
loss: 0.005804  [ 1200/ 3414]
loss: 0.032559  [ 1300/ 3414]
loss: 0.018322  [ 1400/ 3414]
loss: 0.029094  [ 1500/ 3414]
loss: 0.011379  [ 1600/ 3414]
loss: 0.010381  [ 1700/ 3414]
loss: 0.031251  [ 1800/ 3414]
loss: 0.021175  [ 1900/ 3414]
loss: 0.033631  [ 2000/ 3414]
loss: 0.033494  [ 2100/ 3414]
loss: 0.039873  [ 2200/ 3414]
loss: 0.033205  [ 2300/ 3414]
loss: 0.008680  [ 2400/ 3414]
loss: 0.156306  [ 2500/ 3414]
loss: 0.026000  [ 2600/ 3414]
loss: 0.014533  [ 2700/ 3414]
loss: 0.012782  [ 2800/ 3414]
loss: 0.039535  [ 2900/ 3414]
loss: 0.046112  [ 3000/ 3414]
loss: 0.035206  [ 3100/ 3414]
loss: 0.020957  [ 3200/ 3414]
loss: 0.012792  [ 3300/ 3414]
loss: 0.025173  [ 3400/ 3414]
Epoch 5
-------------------------------
loss: 0.042188  [    0/ 3414]
loss: 0.029286  [  100/ 3414]
loss: 0.008184  [  200/ 3414]
loss: 0.049301  [  300/ 3414]
loss: 0.013777  [  400/ 3414]
loss: 0.044892  [  500/ 3414]
loss: 0.027494  [  600/ 3414]
loss: 0.034808  [  700/ 3414]
loss: 0.051584  [  800/ 3414]
loss: 0.019755  [  900/ 3414]
loss: 0.016289  [ 1000/ 3414]
loss: 0.023699  [ 1100/ 3414]
loss: 0.005864  [ 1200/ 3414]
loss: 0.032611  [ 1300/ 3414]
loss: 0.018418  [ 1400/ 3414]
loss: 0.028749  [ 1500/ 3414]
loss: 0.011333  [ 1600/ 3414]
loss: 0.010508  [ 1700/ 3414]
loss: 0.030814  [ 1800/ 3414]
loss: 0.020948  [ 1900/ 3414]
loss: 0.033615  [ 2000/ 3414]
loss: 0.033074  [ 2100/ 3414]
loss: 0.039680  [ 2200/ 3414]
loss: 0.033383  [ 2300/ 3414]
loss: 0.008561  [ 2400/ 3414]
loss: 0.157167  [ 2500/ 3414]
loss: 0.025733  [ 2600/ 3414]
loss: 0.014380  [ 2700/ 3414]
loss: 0.012580  [ 2800/ 3414]
loss: 0.039543  [ 2900/ 3414]
loss: 0.045951  [ 3000/ 3414]
loss: 0.035116  [ 3100/ 3414]
loss: 0.021027  [ 3200/ 3414]
loss: 0.012579  [ 3300/ 3414]
loss: 0.025132  [ 3400/ 3414]
Epoch 6
-------------------------------
loss: 0.041985  [    0/ 3414]
loss: 0.029418  [  100/ 3414]
loss: 0.008256  [  200/ 3414]
loss: 0.049114  [  300/ 3414]
loss: 0.013808  [  400/ 3414]
loss: 0.044772  [  500/ 3414]
loss: 0.027715  [  600/ 3414]
loss: 0.035011  [  700/ 3414]
loss: 0.051540  [  800/ 3414]
loss: 0.019861  [  900/ 3414]
loss: 0.016298  [ 1000/ 3414]
loss: 0.023595  [ 1100/ 3414]
loss: 0.006134  [ 1200/ 3414]
loss: 0.032626  [ 1300/ 3414]
loss: 0.018501  [ 1400/ 3414]
loss: 0.028482  [ 1500/ 3414]
loss: 0.011244  [ 1600/ 3414]
loss: 0.010473  [ 1700/ 3414]
loss: 0.030373  [ 1800/ 3414]
loss: 0.020770  [ 1900/ 3414]
loss: 0.033546  [ 2000/ 3414]
loss: 0.033022  [ 2100/ 3414]
loss: 0.039744  [ 2200/ 3414]
loss: 0.033607  [ 2300/ 3414]
loss: 0.008523  [ 2400/ 3414]
loss: 0.157776  [ 2500/ 3414]
loss: 0.025440  [ 2600/ 3414]
loss: 0.014236  [ 2700/ 3414]
loss: 0.012445  [ 2800/ 3414]
loss: 0.039529  [ 2900/ 3414]
loss: 0.045774  [ 3000/ 3414]
loss: 0.035065  [ 3100/ 3414]
loss: 0.021336  [ 3200/ 3414]
loss: 0.012459  [ 3300/ 3414]
loss: 0.024951  [ 3400/ 3414]
Epoch 7
-------------------------------
loss: 0.041675  [    0/ 3414]
loss: 0.029533  [  100/ 3414]
loss: 0.008317  [  200/ 3414]
loss: 0.048869  [  300/ 3414]
loss: 0.013712  [  400/ 3414]
loss: 0.044659  [  500/ 3414]
loss: 0.027867  [  600/ 3414]
loss: 0.035248  [  700/ 3414]
loss: 0.051660  [  800/ 3414]
loss: 0.020054  [  900/ 3414]
loss: 0.016258  [ 1000/ 3414]
loss: 0.023470  [ 1100/ 3414]
loss: 0.006184  [ 1200/ 3414]
loss: 0.032653  [ 1300/ 3414]
loss: 0.018545  [ 1400/ 3414]
loss: 0.028174  [ 1500/ 3414]
loss: 0.011157  [ 1600/ 3414]
loss: 0.010385  [ 1700/ 3414]
loss: 0.029990  [ 1800/ 3414]
loss: 0.020562  [ 1900/ 3414]
loss: 0.033482  [ 2000/ 3414]
loss: 0.032724  [ 2100/ 3414]
loss: 0.039492  [ 2200/ 3414]
loss: 0.033830  [ 2300/ 3414]
loss: 0.008419  [ 2400/ 3414]
loss: 0.158255  [ 2500/ 3414]
loss: 0.025076  [ 2600/ 3414]
loss: 0.014111  [ 2700/ 3414]
loss: 0.012391  [ 2800/ 3414]
loss: 0.039587  [ 2900/ 3414]
loss: 0.045723  [ 3000/ 3414]
loss: 0.034875  [ 3100/ 3414]
loss: 0.020986  [ 3200/ 3414]
loss: 0.012280  [ 3300/ 3414]
loss: 0.024949  [ 3400/ 3414]
Epoch 8
-------------------------------
loss: 0.041550  [    0/ 3414]
loss: 0.029654  [  100/ 3414]
loss: 0.008407  [  200/ 3414]
loss: 0.048776  [  300/ 3414]
loss: 0.013796  [  400/ 3414]
loss: 0.044513  [  500/ 3414]
loss: 0.028046  [  600/ 3414]
loss: 0.035253  [  700/ 3414]
loss: 0.051555  [  800/ 3414]
loss: 0.020261  [  900/ 3414]
loss: 0.016195  [ 1000/ 3414]
loss: 0.023346  [ 1100/ 3414]
loss: 0.006488  [ 1200/ 3414]
loss: 0.032698  [ 1300/ 3414]
loss: 0.018586  [ 1400/ 3414]
loss: 0.027924  [ 1500/ 3414]
loss: 0.011060  [ 1600/ 3414]
loss: 0.010298  [ 1700/ 3414]
loss: 0.029733  [ 1800/ 3414]
loss: 0.020438  [ 1900/ 3414]
loss: 0.033384  [ 2000/ 3414]
loss: 0.032653  [ 2100/ 3414]
loss: 0.039279  [ 2200/ 3414]
loss: 0.034131  [ 2300/ 3414]
loss: 0.008354  [ 2400/ 3414]
loss: 0.158757  [ 2500/ 3414]
loss: 0.024710  [ 2600/ 3414]
loss: 0.013979  [ 2700/ 3414]
loss: 0.012408  [ 2800/ 3414]
loss: 0.039595  [ 2900/ 3414]
loss: 0.045684  [ 3000/ 3414]
loss: 0.034835  [ 3100/ 3414]
loss: 0.020984  [ 3200/ 3414]
loss: 0.012192  [ 3300/ 3414]
loss: 0.024880  [ 3400/ 3414]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3414
First Spike after testing: [0.07045068 0.31004757]
[1 1 0 ... 0 0 2]
[0 2 1 ... 0 0 0]
Cluster 0 Occurrences: 1136; KMEANS: 1515
Cluster 1 Occurrences: 1099; KMEANS: 1074
Cluster 2 Occurrences: 1179; KMEANS: 825
Centroids: [[-0.5537839, 0.0010049973], [-0.51253325, -0.15610158], [-0.8708817, -0.051484417]]
Centroids: [[-0.6266386, -0.09161788], [-0.9796131, 0.3179647], [-0.26385477, -0.52582675]]
Contingency Matrix: 
[[520 344 272]
 [506 207 386]
 [489 523 167]]
[[520, -1, 272], [506, -1, 386], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 386], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 0, 1: 2}
New Contingency Matrix: 
[[520 272 344]
 [506 386 207]
 [489 167 523]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [520, 386, 523], Sum: 1429
All_Elements: [520, 272, 344, 506, 386, 207, 489, 167, 523], Sum: 3414
Accuracy: 0.4185705916813122
Done!
