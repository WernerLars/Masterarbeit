Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_38_59
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B2610BC88>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x0000019B26154FD0>
Epoch 1
-------------------------------
loss: 0.120976  [    0/ 3514]
loss: 0.132662  [  100/ 3514]
loss: 0.053323  [  200/ 3514]
loss: 0.051721  [  300/ 3514]
loss: 0.019000  [  400/ 3514]
loss: 0.012780  [  500/ 3514]
loss: 0.008355  [  600/ 3514]
loss: 0.003677  [  700/ 3514]
loss: 0.001829  [  800/ 3514]
loss: 0.004351  [  900/ 3514]
loss: 0.006270  [ 1000/ 3514]
loss: 0.094783  [ 1100/ 3514]
loss: 0.002559  [ 1200/ 3514]
loss: 0.002224  [ 1300/ 3514]
loss: 0.091955  [ 1400/ 3514]
loss: 0.000683  [ 1500/ 3514]
loss: 0.006334  [ 1600/ 3514]
loss: 0.005587  [ 1700/ 3514]
loss: 0.226213  [ 1800/ 3514]
loss: 0.008053  [ 1900/ 3514]
loss: 0.002273  [ 2000/ 3514]
loss: 0.005373  [ 2100/ 3514]
loss: 0.000594  [ 2200/ 3514]
loss: 0.001278  [ 2300/ 3514]
loss: 0.002114  [ 2400/ 3514]
loss: 0.007054  [ 2500/ 3514]
loss: 0.003574  [ 2600/ 3514]
loss: 0.002807  [ 2700/ 3514]
loss: 0.007448  [ 2800/ 3514]
loss: 0.002789  [ 2900/ 3514]
loss: 0.006319  [ 3000/ 3514]
loss: 0.001926  [ 3100/ 3514]
loss: 0.001923  [ 3200/ 3514]
loss: 0.006915  [ 3300/ 3514]
loss: 0.007465  [ 3400/ 3514]
loss: 0.002818  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.004756  [    0/ 3514]
loss: 0.002116  [  100/ 3514]
loss: 0.006907  [  200/ 3514]
loss: 0.003897  [  300/ 3514]
loss: 0.004694  [  400/ 3514]
loss: 0.004290  [  500/ 3514]
loss: 0.007410  [  600/ 3514]
loss: 0.002695  [  700/ 3514]
loss: 0.001527  [  800/ 3514]
loss: 0.004040  [  900/ 3514]
loss: 0.006975  [ 1000/ 3514]
loss: 0.092907  [ 1100/ 3514]
loss: 0.002931  [ 1200/ 3514]
loss: 0.002009  [ 1300/ 3514]
loss: 0.070451  [ 1400/ 3514]
loss: 0.001086  [ 1500/ 3514]
loss: 0.005726  [ 1600/ 3514]
loss: 0.006615  [ 1700/ 3514]
loss: 0.206218  [ 1800/ 3514]
loss: 0.005727  [ 1900/ 3514]
loss: 0.001818  [ 2000/ 3514]
loss: 0.005504  [ 2100/ 3514]
loss: 0.000687  [ 2200/ 3514]
loss: 0.001322  [ 2300/ 3514]
loss: 0.001906  [ 2400/ 3514]
loss: 0.006625  [ 2500/ 3514]
loss: 0.003720  [ 2600/ 3514]
loss: 0.002522  [ 2700/ 3514]
loss: 0.007230  [ 2800/ 3514]
loss: 0.001977  [ 2900/ 3514]
loss: 0.003823  [ 3000/ 3514]
loss: 0.001685  [ 3100/ 3514]
loss: 0.001996  [ 3200/ 3514]
loss: 0.007279  [ 3300/ 3514]
loss: 0.006905  [ 3400/ 3514]
loss: 0.002756  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.003892  [    0/ 3514]
loss: 0.001505  [  100/ 3514]
loss: 0.006858  [  200/ 3514]
loss: 0.003734  [  300/ 3514]
loss: 0.004114  [  400/ 3514]
loss: 0.004023  [  500/ 3514]
loss: 0.006793  [  600/ 3514]
loss: 0.002356  [  700/ 3514]
loss: 0.001469  [  800/ 3514]
loss: 0.004382  [  900/ 3514]
loss: 0.006643  [ 1000/ 3514]
loss: 0.092695  [ 1100/ 3514]
loss: 0.002612  [ 1200/ 3514]
loss: 0.002026  [ 1300/ 3514]
loss: 0.069207  [ 1400/ 3514]
loss: 0.000924  [ 1500/ 3514]
loss: 0.005339  [ 1600/ 3514]
loss: 0.005594  [ 1700/ 3514]
loss: 0.187665  [ 1800/ 3514]
loss: 0.004302  [ 1900/ 3514]
loss: 0.001582  [ 2000/ 3514]
loss: 0.005689  [ 2100/ 3514]
loss: 0.000674  [ 2200/ 3514]
loss: 0.001306  [ 2300/ 3514]
loss: 0.001766  [ 2400/ 3514]
loss: 0.006686  [ 2500/ 3514]
loss: 0.003806  [ 2600/ 3514]
loss: 0.002601  [ 2700/ 3514]
loss: 0.007350  [ 2800/ 3514]
loss: 0.001508  [ 2900/ 3514]
loss: 0.003282  [ 3000/ 3514]
loss: 0.001700  [ 3100/ 3514]
loss: 0.001980  [ 3200/ 3514]
loss: 0.006923  [ 3300/ 3514]
loss: 0.006336  [ 3400/ 3514]
loss: 0.002755  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.003962  [    0/ 3514]
loss: 0.001087  [  100/ 3514]
loss: 0.006967  [  200/ 3514]
loss: 0.003626  [  300/ 3514]
loss: 0.004172  [  400/ 3514]
loss: 0.004142  [  500/ 3514]
loss: 0.006556  [  600/ 3514]
loss: 0.002052  [  700/ 3514]
loss: 0.001366  [  800/ 3514]
loss: 0.004264  [  900/ 3514]
loss: 0.006311  [ 1000/ 3514]
loss: 0.092334  [ 1100/ 3514]
loss: 0.002689  [ 1200/ 3514]
loss: 0.001998  [ 1300/ 3514]
loss: 0.068348  [ 1400/ 3514]
loss: 0.001072  [ 1500/ 3514]
loss: 0.004992  [ 1600/ 3514]
loss: 0.005282  [ 1700/ 3514]
loss: 0.172369  [ 1800/ 3514]
loss: 0.004079  [ 1900/ 3514]
loss: 0.001408  [ 2000/ 3514]
loss: 0.005362  [ 2100/ 3514]
loss: 0.000677  [ 2200/ 3514]
loss: 0.001325  [ 2300/ 3514]
loss: 0.001839  [ 2400/ 3514]
loss: 0.006658  [ 2500/ 3514]
loss: 0.003916  [ 2600/ 3514]
loss: 0.002647  [ 2700/ 3514]
loss: 0.007430  [ 2800/ 3514]
loss: 0.001494  [ 2900/ 3514]
loss: 0.002971  [ 3000/ 3514]
loss: 0.002034  [ 3100/ 3514]
loss: 0.001896  [ 3200/ 3514]
loss: 0.006743  [ 3300/ 3514]
loss: 0.006126  [ 3400/ 3514]
loss: 0.002466  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.004240  [    0/ 3514]
loss: 0.000842  [  100/ 3514]
loss: 0.006974  [  200/ 3514]
loss: 0.003538  [  300/ 3514]
loss: 0.004577  [  400/ 3514]
loss: 0.004262  [  500/ 3514]
loss: 0.006537  [  600/ 3514]
loss: 0.001865  [  700/ 3514]
loss: 0.001280  [  800/ 3514]
loss: 0.004291  [  900/ 3514]
loss: 0.006215  [ 1000/ 3514]
loss: 0.092214  [ 1100/ 3514]
loss: 0.001706  [ 1200/ 3514]
loss: 0.002046  [ 1300/ 3514]
loss: 0.068211  [ 1400/ 3514]
loss: 0.001068  [ 1500/ 3514]
loss: 0.004153  [ 1600/ 3514]
loss: 0.006469  [ 1700/ 3514]
loss: 0.158011  [ 1800/ 3514]
loss: 0.003758  [ 1900/ 3514]
loss: 0.001336  [ 2000/ 3514]
loss: 0.005588  [ 2100/ 3514]
loss: 0.000653  [ 2200/ 3514]
loss: 0.001428  [ 2300/ 3514]
loss: 0.001792  [ 2400/ 3514]
loss: 0.006905  [ 2500/ 3514]
loss: 0.003993  [ 2600/ 3514]
loss: 0.002950  [ 2700/ 3514]
loss: 0.007461  [ 2800/ 3514]
loss: 0.001483  [ 2900/ 3514]
loss: 0.002882  [ 3000/ 3514]
loss: 0.001696  [ 3100/ 3514]
loss: 0.001863  [ 3200/ 3514]
loss: 0.006862  [ 3300/ 3514]
loss: 0.006173  [ 3400/ 3514]
loss: 0.002343  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.004222  [    0/ 3514]
loss: 0.000719  [  100/ 3514]
loss: 0.006945  [  200/ 3514]
loss: 0.003417  [  300/ 3514]
loss: 0.004564  [  400/ 3514]
loss: 0.004422  [  500/ 3514]
loss: 0.006496  [  600/ 3514]
loss: 0.001742  [  700/ 3514]
loss: 0.001246  [  800/ 3514]
loss: 0.004316  [  900/ 3514]
loss: 0.006033  [ 1000/ 3514]
loss: 0.092313  [ 1100/ 3514]
loss: 0.001759  [ 1200/ 3514]
loss: 0.002061  [ 1300/ 3514]
loss: 0.068737  [ 1400/ 3514]
loss: 0.000973  [ 1500/ 3514]
loss: 0.003804  [ 1600/ 3514]
loss: 0.006354  [ 1700/ 3514]
loss: 0.145830  [ 1800/ 3514]
loss: 0.003683  [ 1900/ 3514]
loss: 0.001321  [ 2000/ 3514]
loss: 0.005246  [ 2100/ 3514]
loss: 0.000658  [ 2200/ 3514]
loss: 0.001529  [ 2300/ 3514]
loss: 0.001728  [ 2400/ 3514]
loss: 0.007016  [ 2500/ 3514]
loss: 0.003975  [ 2600/ 3514]
loss: 0.002974  [ 2700/ 3514]
loss: 0.007411  [ 2800/ 3514]
loss: 0.001565  [ 2900/ 3514]
loss: 0.002688  [ 3000/ 3514]
loss: 0.001394  [ 3100/ 3514]
loss: 0.001847  [ 3200/ 3514]
loss: 0.006625  [ 3300/ 3514]
loss: 0.005985  [ 3400/ 3514]
loss: 0.002286  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.004115  [    0/ 3514]
loss: 0.000675  [  100/ 3514]
loss: 0.006979  [  200/ 3514]
loss: 0.003234  [  300/ 3514]
loss: 0.004710  [  400/ 3514]
loss: 0.004077  [  500/ 3514]
loss: 0.006447  [  600/ 3514]
loss: 0.001681  [  700/ 3514]
loss: 0.001219  [  800/ 3514]
loss: 0.004327  [  900/ 3514]
loss: 0.005991  [ 1000/ 3514]
loss: 0.092218  [ 1100/ 3514]
loss: 0.001811  [ 1200/ 3514]
loss: 0.002125  [ 1300/ 3514]
loss: 0.069200  [ 1400/ 3514]
loss: 0.000950  [ 1500/ 3514]
loss: 0.003672  [ 1600/ 3514]
loss: 0.005685  [ 1700/ 3514]
loss: 0.138373  [ 1800/ 3514]
loss: 0.003541  [ 1900/ 3514]
loss: 0.001326  [ 2000/ 3514]
loss: 0.005221  [ 2100/ 3514]
loss: 0.000657  [ 2200/ 3514]
loss: 0.001636  [ 2300/ 3514]
loss: 0.001712  [ 2400/ 3514]
loss: 0.007156  [ 2500/ 3514]
loss: 0.003973  [ 2600/ 3514]
loss: 0.003083  [ 2700/ 3514]
loss: 0.007274  [ 2800/ 3514]
loss: 0.001614  [ 2900/ 3514]
loss: 0.002484  [ 3000/ 3514]
loss: 0.001461  [ 3100/ 3514]
loss: 0.001809  [ 3200/ 3514]
loss: 0.007255  [ 3300/ 3514]
loss: 0.005993  [ 3400/ 3514]
loss: 0.002255  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.003857  [    0/ 3514]
loss: 0.000675  [  100/ 3514]
loss: 0.007091  [  200/ 3514]
loss: 0.003059  [  300/ 3514]
loss: 0.004696  [  400/ 3514]
loss: 0.003998  [  500/ 3514]
loss: 0.006350  [  600/ 3514]
loss: 0.001661  [  700/ 3514]
loss: 0.001197  [  800/ 3514]
loss: 0.004377  [  900/ 3514]
loss: 0.005855  [ 1000/ 3514]
loss: 0.091980  [ 1100/ 3514]
loss: 0.001795  [ 1200/ 3514]
loss: 0.002372  [ 1300/ 3514]
loss: 0.069786  [ 1400/ 3514]
loss: 0.000983  [ 1500/ 3514]
loss: 0.003558  [ 1600/ 3514]
loss: 0.006626  [ 1700/ 3514]
loss: 0.133988  [ 1800/ 3514]
loss: 0.003608  [ 1900/ 3514]
loss: 0.001327  [ 2000/ 3514]
loss: 0.005352  [ 2100/ 3514]
loss: 0.000643  [ 2200/ 3514]
loss: 0.001754  [ 2300/ 3514]
loss: 0.001715  [ 2400/ 3514]
loss: 0.007126  [ 2500/ 3514]
loss: 0.004007  [ 2600/ 3514]
loss: 0.003152  [ 2700/ 3514]
loss: 0.007052  [ 2800/ 3514]
loss: 0.001761  [ 2900/ 3514]
loss: 0.002252  [ 3000/ 3514]
loss: 0.001366  [ 3100/ 3514]
loss: 0.001813  [ 3200/ 3514]
loss: 0.007156  [ 3300/ 3514]
loss: 0.006116  [ 3400/ 3514]
loss: 0.002180  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [ 1.1508619  -0.00994114]
[1 0 2 ... 1 0 1]
[0 2 1 ... 0 2 0]
Cluster 0 Occurrences: 1165; KMEANS: 1143
Cluster 1 Occurrences: 1157; KMEANS: 1216
Cluster 2 Occurrences: 1192; KMEANS: 1155
Centroids: [[-1.3576372, 1.1066115], [1.3186646, -0.017654466], [-0.84428775, -1.6101698]]
Centroids: [[1.3273059, 0.0012017223], [-0.82792944, -1.6073879], [-1.361638, 1.1278474]]
Contingency Matrix: 
[[   2   14 1149]
 [1141   11    5]
 [   0 1191    1]]
[[2, -1, 1149], [1141, -1, 5], [-1, -1, -1]]
[[-1, -1, -1], [1141, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[1149    2   14]
 [   5 1141   11]
 [   1    0 1191]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1149, 1141, 1191], Sum: 3481
All_Elements: [1149, 2, 14, 5, 1141, 11, 1, 0, 1191], Sum: 3514
Accuracy: 0.9906089926010244
Done!
