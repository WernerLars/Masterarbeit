Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Difficult2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_02_56
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B83EF8BA8>
Sampling rate: 24000.0
Raw: [ 0.02085333  0.02043967  0.02052644 ... -0.02218732 -0.02150573
 -0.01811243]
Times: [   1583    1934    2430 ... 1439313 1439656 1439854]
Cluster: [3 3 3 ... 2 2 1]
Number of different clusters:  3
Number of Spikes: 3364
First aligned Spike Frame: [-0.05170878 -0.0548761  -0.06029554 -0.06053219 -0.04807119 -0.02780025
 -0.01550543 -0.01702494 -0.02945104 -0.04493807 -0.07056858 -0.07003585
  0.07629654  0.43081562  0.80470191  0.96319627  0.89198123  0.73643948
  0.58987232  0.46714337  0.36345495  0.2828462   0.22743292  0.182731
  0.13931053  0.09524506  0.05136602  0.01367166 -0.01393093 -0.03985679
 -0.07387102 -0.11218435 -0.1444455  -0.16672578 -0.17809238 -0.18020802
 -0.17953732 -0.18246903 -0.18617363 -0.18205375 -0.17299738 -0.16958427
 -0.17248955 -0.17516876 -0.1727246  -0.16696514 -0.15993314]
Cluster 0, Occurrences: 1120
Cluster 1, Occurrences: 1109
Cluster 2, Occurrences: 1135
<torch.utils.data.dataloader.DataLoader object at 0x0000019B89ADF390>
Epoch 1
-------------------------------
loss: 0.167152  [    0/ 3364]
loss: 0.093844  [  100/ 3364]
loss: 0.017723  [  200/ 3364]
loss: 0.008536  [  300/ 3364]
loss: 0.006389  [  400/ 3364]
loss: 0.045079  [  500/ 3364]
loss: 0.004394  [  600/ 3364]
loss: 0.007198  [  700/ 3364]
loss: 0.004142  [  800/ 3364]
loss: 0.006213  [  900/ 3364]
loss: 0.006081  [ 1000/ 3364]
loss: 0.003941  [ 1100/ 3364]
loss: 0.005004  [ 1200/ 3364]
loss: 0.005095  [ 1300/ 3364]
loss: 0.084946  [ 1400/ 3364]
loss: 0.003139  [ 1500/ 3364]
loss: 0.006136  [ 1600/ 3364]
loss: 0.004815  [ 1700/ 3364]
loss: 0.001062  [ 1800/ 3364]
loss: 0.004777  [ 1900/ 3364]
loss: 0.002875  [ 2000/ 3364]
loss: 0.004934  [ 2100/ 3364]
loss: 0.005864  [ 2200/ 3364]
loss: 0.008703  [ 2300/ 3364]
loss: 0.001745  [ 2400/ 3364]
loss: 0.002359  [ 2500/ 3364]
loss: 0.003726  [ 2600/ 3364]
loss: 0.003796  [ 2700/ 3364]
loss: 0.003543  [ 2800/ 3364]
loss: 0.001211  [ 2900/ 3364]
loss: 0.003718  [ 3000/ 3364]
loss: 0.004464  [ 3100/ 3364]
loss: 0.001339  [ 3200/ 3364]
loss: 0.002110  [ 3300/ 3364]
Epoch 2
-------------------------------
loss: 0.001613  [    0/ 3364]
loss: 0.002767  [  100/ 3364]
loss: 0.004837  [  200/ 3364]
loss: 0.001266  [  300/ 3364]
loss: 0.001145  [  400/ 3364]
loss: 0.038278  [  500/ 3364]
loss: 0.004078  [  600/ 3364]
loss: 0.009188  [  700/ 3364]
loss: 0.002821  [  800/ 3364]
loss: 0.002837  [  900/ 3364]
loss: 0.003866  [ 1000/ 3364]
loss: 0.003937  [ 1100/ 3364]
loss: 0.002504  [ 1200/ 3364]
loss: 0.005630  [ 1300/ 3364]
loss: 0.084857  [ 1400/ 3364]
loss: 0.002654  [ 1500/ 3364]
loss: 0.006388  [ 1600/ 3364]
loss: 0.003100  [ 1700/ 3364]
loss: 0.001061  [ 1800/ 3364]
loss: 0.004436  [ 1900/ 3364]
loss: 0.002361  [ 2000/ 3364]
loss: 0.003929  [ 2100/ 3364]
loss: 0.004937  [ 2200/ 3364]
loss: 0.008063  [ 2300/ 3364]
loss: 0.001107  [ 2400/ 3364]
loss: 0.002202  [ 2500/ 3364]
loss: 0.002494  [ 2600/ 3364]
loss: 0.003562  [ 2700/ 3364]
loss: 0.003237  [ 2800/ 3364]
loss: 0.001375  [ 2900/ 3364]
loss: 0.003595  [ 3000/ 3364]
loss: 0.004304  [ 3100/ 3364]
loss: 0.001360  [ 3200/ 3364]
loss: 0.001007  [ 3300/ 3364]
Epoch 3
-------------------------------
loss: 0.001511  [    0/ 3364]
loss: 0.002826  [  100/ 3364]
loss: 0.004988  [  200/ 3364]
loss: 0.000870  [  300/ 3364]
loss: 0.001095  [  400/ 3364]
loss: 0.034325  [  500/ 3364]
loss: 0.004201  [  600/ 3364]
loss: 0.007832  [  700/ 3364]
loss: 0.002578  [  800/ 3364]
loss: 0.002564  [  900/ 3364]
loss: 0.003241  [ 1000/ 3364]
loss: 0.003697  [ 1100/ 3364]
loss: 0.002253  [ 1200/ 3364]
loss: 0.005400  [ 1300/ 3364]
loss: 0.084538  [ 1400/ 3364]
loss: 0.002500  [ 1500/ 3364]
loss: 0.006310  [ 1600/ 3364]
loss: 0.003072  [ 1700/ 3364]
loss: 0.001019  [ 1800/ 3364]
loss: 0.004090  [ 1900/ 3364]
loss: 0.002444  [ 2000/ 3364]
loss: 0.004010  [ 2100/ 3364]
loss: 0.004603  [ 2200/ 3364]
loss: 0.007456  [ 2300/ 3364]
loss: 0.001014  [ 2400/ 3364]
loss: 0.002386  [ 2500/ 3364]
loss: 0.002876  [ 2600/ 3364]
loss: 0.003630  [ 2700/ 3364]
loss: 0.003294  [ 2800/ 3364]
loss: 0.001439  [ 2900/ 3364]
loss: 0.003622  [ 3000/ 3364]
loss: 0.004230  [ 3100/ 3364]
loss: 0.001330  [ 3200/ 3364]
loss: 0.000912  [ 3300/ 3364]
Epoch 4
-------------------------------
loss: 0.001563  [    0/ 3364]
loss: 0.002684  [  100/ 3364]
loss: 0.004752  [  200/ 3364]
loss: 0.000767  [  300/ 3364]
loss: 0.000837  [  400/ 3364]
loss: 0.032482  [  500/ 3364]
loss: 0.003892  [  600/ 3364]
loss: 0.005376  [  700/ 3364]
loss: 0.002448  [  800/ 3364]
loss: 0.002596  [  900/ 3364]
loss: 0.002322  [ 1000/ 3364]
loss: 0.003548  [ 1100/ 3364]
loss: 0.002256  [ 1200/ 3364]
loss: 0.005383  [ 1300/ 3364]
loss: 0.083946  [ 1400/ 3364]
loss: 0.002565  [ 1500/ 3364]
loss: 0.006327  [ 1600/ 3364]
loss: 0.003023  [ 1700/ 3364]
loss: 0.000972  [ 1800/ 3364]
loss: 0.003982  [ 1900/ 3364]
loss: 0.002677  [ 2000/ 3364]
loss: 0.004024  [ 2100/ 3364]
loss: 0.004695  [ 2200/ 3364]
loss: 0.007533  [ 2300/ 3364]
loss: 0.001024  [ 2400/ 3364]
loss: 0.002389  [ 2500/ 3364]
loss: 0.002921  [ 2600/ 3364]
loss: 0.003570  [ 2700/ 3364]
loss: 0.003377  [ 2800/ 3364]
loss: 0.001482  [ 2900/ 3364]
loss: 0.003757  [ 3000/ 3364]
loss: 0.004228  [ 3100/ 3364]
loss: 0.001330  [ 3200/ 3364]
loss: 0.001006  [ 3300/ 3364]
Epoch 5
-------------------------------
loss: 0.001548  [    0/ 3364]
loss: 0.002738  [  100/ 3364]
loss: 0.004649  [  200/ 3364]
loss: 0.000871  [  300/ 3364]
loss: 0.000847  [  400/ 3364]
loss: 0.032111  [  500/ 3364]
loss: 0.003523  [  600/ 3364]
loss: 0.004485  [  700/ 3364]
loss: 0.002418  [  800/ 3364]
loss: 0.002738  [  900/ 3364]
loss: 0.001844  [ 1000/ 3364]
loss: 0.003474  [ 1100/ 3364]
loss: 0.002214  [ 1200/ 3364]
loss: 0.005358  [ 1300/ 3364]
loss: 0.084239  [ 1400/ 3364]
loss: 0.002640  [ 1500/ 3364]
loss: 0.006236  [ 1600/ 3364]
loss: 0.003043  [ 1700/ 3364]
loss: 0.000903  [ 1800/ 3364]
loss: 0.004010  [ 1900/ 3364]
loss: 0.002991  [ 2000/ 3364]
loss: 0.003876  [ 2100/ 3364]
loss: 0.004817  [ 2200/ 3364]
loss: 0.007771  [ 2300/ 3364]
loss: 0.001051  [ 2400/ 3364]
loss: 0.002357  [ 2500/ 3364]
loss: 0.002829  [ 2600/ 3364]
loss: 0.003437  [ 2700/ 3364]
loss: 0.003323  [ 2800/ 3364]
loss: 0.001518  [ 2900/ 3364]
loss: 0.003801  [ 3000/ 3364]
loss: 0.003851  [ 3100/ 3364]
loss: 0.001299  [ 3200/ 3364]
loss: 0.001160  [ 3300/ 3364]
Epoch 6
-------------------------------
loss: 0.001514  [    0/ 3364]
loss: 0.002672  [  100/ 3364]
loss: 0.004491  [  200/ 3364]
loss: 0.000883  [  300/ 3364]
loss: 0.000802  [  400/ 3364]
loss: 0.031986  [  500/ 3364]
loss: 0.003244  [  600/ 3364]
loss: 0.004127  [  700/ 3364]
loss: 0.002526  [  800/ 3364]
loss: 0.002713  [  900/ 3364]
loss: 0.001571  [ 1000/ 3364]
loss: 0.003398  [ 1100/ 3364]
loss: 0.002196  [ 1200/ 3364]
loss: 0.005353  [ 1300/ 3364]
loss: 0.084881  [ 1400/ 3364]
loss: 0.002807  [ 1500/ 3364]
loss: 0.006843  [ 1600/ 3364]
loss: 0.003112  [ 1700/ 3364]
loss: 0.000881  [ 1800/ 3364]
loss: 0.004077  [ 1900/ 3364]
loss: 0.003177  [ 2000/ 3364]
loss: 0.003729  [ 2100/ 3364]
loss: 0.004678  [ 2200/ 3364]
loss: 0.007953  [ 2300/ 3364]
loss: 0.001049  [ 2400/ 3364]
loss: 0.002368  [ 2500/ 3364]
loss: 0.002859  [ 2600/ 3364]
loss: 0.003453  [ 2700/ 3364]
loss: 0.003041  [ 2800/ 3364]
loss: 0.001655  [ 2900/ 3364]
loss: 0.003790  [ 3000/ 3364]
loss: 0.003753  [ 3100/ 3364]
loss: 0.001258  [ 3200/ 3364]
loss: 0.001221  [ 3300/ 3364]
Epoch 7
-------------------------------
loss: 0.001592  [    0/ 3364]
loss: 0.002697  [  100/ 3364]
loss: 0.004388  [  200/ 3364]
loss: 0.000909  [  300/ 3364]
loss: 0.000875  [  400/ 3364]
loss: 0.031854  [  500/ 3364]
loss: 0.003183  [  600/ 3364]
loss: 0.004252  [  700/ 3364]
loss: 0.002465  [  800/ 3364]
loss: 0.004061  [  900/ 3364]
loss: 0.001169  [ 1000/ 3364]
loss: 0.003405  [ 1100/ 3364]
loss: 0.002202  [ 1200/ 3364]
loss: 0.005182  [ 1300/ 3364]
loss: 0.084730  [ 1400/ 3364]
loss: 0.002896  [ 1500/ 3364]
loss: 0.006933  [ 1600/ 3364]
loss: 0.002984  [ 1700/ 3364]
loss: 0.000849  [ 1800/ 3364]
loss: 0.004043  [ 1900/ 3364]
loss: 0.003188  [ 2000/ 3364]
loss: 0.003698  [ 2100/ 3364]
loss: 0.004351  [ 2200/ 3364]
loss: 0.008095  [ 2300/ 3364]
loss: 0.001023  [ 2400/ 3364]
loss: 0.002416  [ 2500/ 3364]
loss: 0.002730  [ 2600/ 3364]
loss: 0.003414  [ 2700/ 3364]
loss: 0.002776  [ 2800/ 3364]
loss: 0.001650  [ 2900/ 3364]
loss: 0.003799  [ 3000/ 3364]
loss: 0.003629  [ 3100/ 3364]
loss: 0.001213  [ 3200/ 3364]
loss: 0.001164  [ 3300/ 3364]
Epoch 8
-------------------------------
loss: 0.001608  [    0/ 3364]
loss: 0.002694  [  100/ 3364]
loss: 0.004405  [  200/ 3364]
loss: 0.000878  [  300/ 3364]
loss: 0.000922  [  400/ 3364]
loss: 0.031740  [  500/ 3364]
loss: 0.003163  [  600/ 3364]
loss: 0.004032  [  700/ 3364]
loss: 0.002441  [  800/ 3364]
loss: 0.004077  [  900/ 3364]
loss: 0.001139  [ 1000/ 3364]
loss: 0.003386  [ 1100/ 3364]
loss: 0.002207  [ 1200/ 3364]
loss: 0.005155  [ 1300/ 3364]
loss: 0.084583  [ 1400/ 3364]
loss: 0.002932  [ 1500/ 3364]
loss: 0.006882  [ 1600/ 3364]
loss: 0.002954  [ 1700/ 3364]
loss: 0.000827  [ 1800/ 3364]
loss: 0.004006  [ 1900/ 3364]
loss: 0.003212  [ 2000/ 3364]
loss: 0.003643  [ 2100/ 3364]
loss: 0.004215  [ 2200/ 3364]
loss: 0.008220  [ 2300/ 3364]
loss: 0.001053  [ 2400/ 3364]
loss: 0.002376  [ 2500/ 3364]
loss: 0.002760  [ 2600/ 3364]
loss: 0.003576  [ 2700/ 3364]
loss: 0.002560  [ 2800/ 3364]
loss: 0.001669  [ 2900/ 3364]
loss: 0.003906  [ 3000/ 3364]
loss: 0.003474  [ 3100/ 3364]
loss: 0.001250  [ 3200/ 3364]
loss: 0.001164  [ 3300/ 3364]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3364
First Spike after testing: [-0.00897418 -1.077234  ]
[2 2 2 ... 1 1 0]
[0 0 0 ... 1 1 2]
Cluster 0 Occurrences: 1120; KMEANS: 1132
Cluster 1 Occurrences: 1109; KMEANS: 1103
Cluster 2 Occurrences: 1135; KMEANS: 1129
Centroids: [[-0.7805114, -0.6396311], [1.9565086, -0.110031486], [-0.05808365, -1.0480006]]
Centroids: [[-0.042514376, -1.0878272], [1.9755452, -0.1056308], [-0.7982547, -0.60226846]]
Contingency Matrix: 
[[  19    2 1099]
 [   9 1098    2]
 [1104    3   28]]
[[-1, 2, 1099], [-1, 1098, 2], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1098, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1099    2   19]
 [   2 1098    9]
 [  28    3 1104]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1099, 1098, 1104], Sum: 3301
All_Elements: [1099, 2, 19, 2, 1098, 9, 28, 3, 1104], Sum: 3364
Accuracy: 0.9812722948870393
Done!
