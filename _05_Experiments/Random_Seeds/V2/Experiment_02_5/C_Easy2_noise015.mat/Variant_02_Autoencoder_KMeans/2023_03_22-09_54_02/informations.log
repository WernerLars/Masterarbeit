Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_54_02
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B2398BDA0>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x0000019B2610BC50>
Epoch 1
-------------------------------
loss: 0.303595  [    0/ 3411]
loss: 0.171736  [  100/ 3411]
loss: 0.108913  [  200/ 3411]
loss: 0.025927  [  300/ 3411]
loss: 0.049775  [  400/ 3411]
loss: 0.035371  [  500/ 3411]
loss: 0.009989  [  600/ 3411]
loss: 0.019603  [  700/ 3411]
loss: 0.031559  [  800/ 3411]
loss: 0.038079  [  900/ 3411]
loss: 0.005162  [ 1000/ 3411]
loss: 0.041386  [ 1100/ 3411]
loss: 0.021018  [ 1200/ 3411]
loss: 0.029250  [ 1300/ 3411]
loss: 0.027859  [ 1400/ 3411]
loss: 0.057691  [ 1500/ 3411]
loss: 0.035072  [ 1600/ 3411]
loss: 0.045860  [ 1700/ 3411]
loss: 0.023027  [ 1800/ 3411]
loss: 0.004084  [ 1900/ 3411]
loss: 0.034764  [ 2000/ 3411]
loss: 0.010989  [ 2100/ 3411]
loss: 0.007131  [ 2200/ 3411]
loss: 0.148782  [ 2300/ 3411]
loss: 0.017226  [ 2400/ 3411]
loss: 0.002428  [ 2500/ 3411]
loss: 0.013834  [ 2600/ 3411]
loss: 0.007312  [ 2700/ 3411]
loss: 0.028920  [ 2800/ 3411]
loss: 0.010702  [ 2900/ 3411]
loss: 0.007800  [ 3000/ 3411]
loss: 0.004850  [ 3100/ 3411]
loss: 0.021791  [ 3200/ 3411]
loss: 0.010864  [ 3300/ 3411]
loss: 0.012203  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.017492  [    0/ 3411]
loss: 0.014245  [  100/ 3411]
loss: 0.013627  [  200/ 3411]
loss: 0.012520  [  300/ 3411]
loss: 0.036929  [  400/ 3411]
loss: 0.011008  [  500/ 3411]
loss: 0.003940  [  600/ 3411]
loss: 0.019464  [  700/ 3411]
loss: 0.021077  [  800/ 3411]
loss: 0.015732  [  900/ 3411]
loss: 0.003436  [ 1000/ 3411]
loss: 0.016114  [ 1100/ 3411]
loss: 0.019157  [ 1200/ 3411]
loss: 0.012130  [ 1300/ 3411]
loss: 0.019674  [ 1400/ 3411]
loss: 0.056338  [ 1500/ 3411]
loss: 0.029506  [ 1600/ 3411]
loss: 0.026893  [ 1700/ 3411]
loss: 0.021207  [ 1800/ 3411]
loss: 0.004897  [ 1900/ 3411]
loss: 0.031925  [ 2000/ 3411]
loss: 0.010995  [ 2100/ 3411]
loss: 0.007475  [ 2200/ 3411]
loss: 0.144320  [ 2300/ 3411]
loss: 0.017466  [ 2400/ 3411]
loss: 0.005005  [ 2500/ 3411]
loss: 0.015094  [ 2600/ 3411]
loss: 0.007890  [ 2700/ 3411]
loss: 0.026862  [ 2800/ 3411]
loss: 0.011241  [ 2900/ 3411]
loss: 0.006992  [ 3000/ 3411]
loss: 0.005081  [ 3100/ 3411]
loss: 0.022748  [ 3200/ 3411]
loss: 0.011340  [ 3300/ 3411]
loss: 0.011113  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.017487  [    0/ 3411]
loss: 0.014215  [  100/ 3411]
loss: 0.013590  [  200/ 3411]
loss: 0.012673  [  300/ 3411]
loss: 0.035660  [  400/ 3411]
loss: 0.009946  [  500/ 3411]
loss: 0.003786  [  600/ 3411]
loss: 0.021694  [  700/ 3411]
loss: 0.021031  [  800/ 3411]
loss: 0.016257  [  900/ 3411]
loss: 0.003254  [ 1000/ 3411]
loss: 0.015243  [ 1100/ 3411]
loss: 0.019245  [ 1200/ 3411]
loss: 0.012289  [ 1300/ 3411]
loss: 0.019792  [ 1400/ 3411]
loss: 0.054564  [ 1500/ 3411]
loss: 0.029117  [ 1600/ 3411]
loss: 0.022489  [ 1700/ 3411]
loss: 0.021095  [ 1800/ 3411]
loss: 0.004757  [ 1900/ 3411]
loss: 0.031947  [ 2000/ 3411]
loss: 0.011170  [ 2100/ 3411]
loss: 0.007235  [ 2200/ 3411]
loss: 0.144126  [ 2300/ 3411]
loss: 0.017742  [ 2400/ 3411]
loss: 0.005764  [ 2500/ 3411]
loss: 0.015130  [ 2600/ 3411]
loss: 0.007912  [ 2700/ 3411]
loss: 0.026503  [ 2800/ 3411]
loss: 0.011480  [ 2900/ 3411]
loss: 0.006551  [ 3000/ 3411]
loss: 0.005087  [ 3100/ 3411]
loss: 0.022839  [ 3200/ 3411]
loss: 0.011488  [ 3300/ 3411]
loss: 0.010624  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.017172  [    0/ 3411]
loss: 0.014125  [  100/ 3411]
loss: 0.012985  [  200/ 3411]
loss: 0.012781  [  300/ 3411]
loss: 0.035301  [  400/ 3411]
loss: 0.009724  [  500/ 3411]
loss: 0.003649  [  600/ 3411]
loss: 0.022502  [  700/ 3411]
loss: 0.021094  [  800/ 3411]
loss: 0.016560  [  900/ 3411]
loss: 0.003114  [ 1000/ 3411]
loss: 0.015037  [ 1100/ 3411]
loss: 0.019352  [ 1200/ 3411]
loss: 0.012502  [ 1300/ 3411]
loss: 0.019758  [ 1400/ 3411]
loss: 0.054093  [ 1500/ 3411]
loss: 0.028920  [ 1600/ 3411]
loss: 0.021185  [ 1700/ 3411]
loss: 0.020902  [ 1800/ 3411]
loss: 0.004479  [ 1900/ 3411]
loss: 0.031903  [ 2000/ 3411]
loss: 0.010961  [ 2100/ 3411]
loss: 0.007036  [ 2200/ 3411]
loss: 0.144025  [ 2300/ 3411]
loss: 0.017984  [ 2400/ 3411]
loss: 0.006281  [ 2500/ 3411]
loss: 0.015346  [ 2600/ 3411]
loss: 0.007864  [ 2700/ 3411]
loss: 0.026372  [ 2800/ 3411]
loss: 0.011617  [ 2900/ 3411]
loss: 0.006195  [ 3000/ 3411]
loss: 0.005163  [ 3100/ 3411]
loss: 0.022754  [ 3200/ 3411]
loss: 0.011454  [ 3300/ 3411]
loss: 0.010206  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.017019  [    0/ 3411]
loss: 0.014033  [  100/ 3411]
loss: 0.012356  [  200/ 3411]
loss: 0.012834  [  300/ 3411]
loss: 0.034929  [  400/ 3411]
loss: 0.009661  [  500/ 3411]
loss: 0.003550  [  600/ 3411]
loss: 0.020862  [  700/ 3411]
loss: 0.021042  [  800/ 3411]
loss: 0.016676  [  900/ 3411]
loss: 0.003371  [ 1000/ 3411]
loss: 0.011392  [ 1100/ 3411]
loss: 0.019486  [ 1200/ 3411]
loss: 0.012888  [ 1300/ 3411]
loss: 0.019565  [ 1400/ 3411]
loss: 0.053811  [ 1500/ 3411]
loss: 0.026714  [ 1600/ 3411]
loss: 0.020000  [ 1700/ 3411]
loss: 0.019048  [ 1800/ 3411]
loss: 0.004752  [ 1900/ 3411]
loss: 0.031290  [ 2000/ 3411]
loss: 0.012392  [ 2100/ 3411]
loss: 0.007091  [ 2200/ 3411]
loss: 0.145172  [ 2300/ 3411]
loss: 0.018186  [ 2400/ 3411]
loss: 0.005968  [ 2500/ 3411]
loss: 0.011729  [ 2600/ 3411]
loss: 0.007900  [ 2700/ 3411]
loss: 0.025988  [ 2800/ 3411]
loss: 0.011939  [ 2900/ 3411]
loss: 0.009310  [ 3000/ 3411]
loss: 0.005306  [ 3100/ 3411]
loss: 0.023345  [ 3200/ 3411]
loss: 0.011329  [ 3300/ 3411]
loss: 0.008941  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.016821  [    0/ 3411]
loss: 0.013867  [  100/ 3411]
loss: 0.009424  [  200/ 3411]
loss: 0.012880  [  300/ 3411]
loss: 0.034413  [  400/ 3411]
loss: 0.010158  [  500/ 3411]
loss: 0.003581  [  600/ 3411]
loss: 0.009754  [  700/ 3411]
loss: 0.021328  [  800/ 3411]
loss: 0.017357  [  900/ 3411]
loss: 0.003460  [ 1000/ 3411]
loss: 0.008887  [ 1100/ 3411]
loss: 0.019564  [ 1200/ 3411]
loss: 0.012901  [ 1300/ 3411]
loss: 0.019068  [ 1400/ 3411]
loss: 0.056295  [ 1500/ 3411]
loss: 0.022052  [ 1600/ 3411]
loss: 0.017658  [ 1700/ 3411]
loss: 0.017349  [ 1800/ 3411]
loss: 0.005127  [ 1900/ 3411]
loss: 0.031029  [ 2000/ 3411]
loss: 0.011836  [ 2100/ 3411]
loss: 0.007272  [ 2200/ 3411]
loss: 0.146661  [ 2300/ 3411]
loss: 0.018287  [ 2400/ 3411]
loss: 0.006502  [ 2500/ 3411]
loss: 0.009491  [ 2600/ 3411]
loss: 0.007768  [ 2700/ 3411]
loss: 0.025907  [ 2800/ 3411]
loss: 0.011831  [ 2900/ 3411]
loss: 0.009647  [ 3000/ 3411]
loss: 0.005139  [ 3100/ 3411]
loss: 0.023639  [ 3200/ 3411]
loss: 0.011430  [ 3300/ 3411]
loss: 0.007601  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.017844  [    0/ 3411]
loss: 0.013467  [  100/ 3411]
loss: 0.010208  [  200/ 3411]
loss: 0.012835  [  300/ 3411]
loss: 0.034098  [  400/ 3411]
loss: 0.010600  [  500/ 3411]
loss: 0.003561  [  600/ 3411]
loss: 0.006829  [  700/ 3411]
loss: 0.021236  [  800/ 3411]
loss: 0.017622  [  900/ 3411]
loss: 0.003610  [ 1000/ 3411]
loss: 0.007833  [ 1100/ 3411]
loss: 0.019641  [ 1200/ 3411]
loss: 0.013098  [ 1300/ 3411]
loss: 0.018982  [ 1400/ 3411]
loss: 0.060303  [ 1500/ 3411]
loss: 0.021175  [ 1600/ 3411]
loss: 0.016323  [ 1700/ 3411]
loss: 0.014616  [ 1800/ 3411]
loss: 0.005465  [ 1900/ 3411]
loss: 0.031080  [ 2000/ 3411]
loss: 0.009871  [ 2100/ 3411]
loss: 0.007497  [ 2200/ 3411]
loss: 0.148003  [ 2300/ 3411]
loss: 0.018154  [ 2400/ 3411]
loss: 0.006767  [ 2500/ 3411]
loss: 0.007828  [ 2600/ 3411]
loss: 0.007620  [ 2700/ 3411]
loss: 0.026101  [ 2800/ 3411]
loss: 0.011424  [ 2900/ 3411]
loss: 0.010529  [ 3000/ 3411]
loss: 0.005141  [ 3100/ 3411]
loss: 0.023718  [ 3200/ 3411]
loss: 0.011543  [ 3300/ 3411]
loss: 0.006982  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.018450  [    0/ 3411]
loss: 0.013522  [  100/ 3411]
loss: 0.011821  [  200/ 3411]
loss: 0.012770  [  300/ 3411]
loss: 0.033291  [  400/ 3411]
loss: 0.010818  [  500/ 3411]
loss: 0.003302  [  600/ 3411]
loss: 0.005234  [  700/ 3411]
loss: 0.021007  [  800/ 3411]
loss: 0.017779  [  900/ 3411]
loss: 0.003618  [ 1000/ 3411]
loss: 0.006993  [ 1100/ 3411]
loss: 0.019645  [ 1200/ 3411]
loss: 0.013509  [ 1300/ 3411]
loss: 0.019208  [ 1400/ 3411]
loss: 0.064373  [ 1500/ 3411]
loss: 0.019881  [ 1600/ 3411]
loss: 0.014956  [ 1700/ 3411]
loss: 0.014322  [ 1800/ 3411]
loss: 0.006682  [ 1900/ 3411]
loss: 0.031043  [ 2000/ 3411]
loss: 0.008186  [ 2100/ 3411]
loss: 0.007923  [ 2200/ 3411]
loss: 0.150221  [ 2300/ 3411]
loss: 0.017745  [ 2400/ 3411]
loss: 0.007376  [ 2500/ 3411]
loss: 0.006984  [ 2600/ 3411]
loss: 0.007338  [ 2700/ 3411]
loss: 0.026444  [ 2800/ 3411]
loss: 0.011055  [ 2900/ 3411]
loss: 0.011410  [ 3000/ 3411]
loss: 0.005188  [ 3100/ 3411]
loss: 0.024051  [ 3200/ 3411]
loss: 0.011676  [ 3300/ 3411]
loss: 0.006448  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [ 1.3204334  -0.58619356]
[0 2 0 ... 1 1 2]
[2 1 0 ... 0 0 1]
Cluster 0 Occurrences: 1181; KMEANS: 1088
Cluster 1 Occurrences: 1098; KMEANS: 1115
Cluster 2 Occurrences: 1132; KMEANS: 1208
Centroids: [[1.3293537, -0.3853705], [0.44598272, 0.059649207], [-1.6786156, -0.35688263]]
Centroids: [[0.396637, 0.07310092], [-1.7035946, -0.350646], [1.34721, -0.39915758]]
Contingency Matrix: 
[[  59    0 1122]
 [1014    1   83]
 [  15 1114    3]]
[[-1, -1, -1], [1014, 1, -1], [15, 1114, -1]]
[[-1, -1, -1], [1014, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 2: 1, 1: 0}
New Contingency Matrix: 
[[1122   59    0]
 [  83 1014    1]
 [   3   15 1114]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1122, 1014, 1114], Sum: 3250
All_Elements: [1122, 59, 0, 83, 1014, 1, 3, 15, 1114], Sum: 3411
Accuracy: 0.9527997654646732
Done!
