Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Drift_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_09_30
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B962D1588>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
<torch.utils.data.dataloader.DataLoader object at 0x0000019B95F8B358>
Epoch 1
-------------------------------
loss: 0.188702  [    0/ 3444]
loss: 0.095452  [  100/ 3444]
loss: 0.066576  [  200/ 3444]
loss: 0.026221  [  300/ 3444]
loss: 0.023450  [  400/ 3444]
loss: 0.031025  [  500/ 3444]
loss: 0.043594  [  600/ 3444]
loss: 0.024208  [  700/ 3444]
loss: 0.008372  [  800/ 3444]
loss: 0.028435  [  900/ 3444]
loss: 0.008732  [ 1000/ 3444]
loss: 0.020307  [ 1100/ 3444]
loss: 0.013571  [ 1200/ 3444]
loss: 0.036284  [ 1300/ 3444]
loss: 0.112497  [ 1400/ 3444]
loss: 0.012546  [ 1500/ 3444]
loss: 0.011002  [ 1600/ 3444]
loss: 0.013033  [ 1700/ 3444]
loss: 0.015697  [ 1800/ 3444]
loss: 0.014566  [ 1900/ 3444]
loss: 0.005873  [ 2000/ 3444]
loss: 0.018957  [ 2100/ 3444]
loss: 0.028111  [ 2200/ 3444]
loss: 0.021370  [ 2300/ 3444]
loss: 0.005500  [ 2400/ 3444]
loss: 0.010746  [ 2500/ 3444]
loss: 0.007673  [ 2600/ 3444]
loss: 0.011964  [ 2700/ 3444]
loss: 0.013861  [ 2800/ 3444]
loss: 0.009026  [ 2900/ 3444]
loss: 0.016909  [ 3000/ 3444]
loss: 0.042986  [ 3100/ 3444]
loss: 0.100959  [ 3200/ 3444]
loss: 0.009233  [ 3300/ 3444]
loss: 0.033456  [ 3400/ 3444]
Epoch 2
-------------------------------
loss: 0.017211  [    0/ 3444]
loss: 0.008792  [  100/ 3444]
loss: 0.005564  [  200/ 3444]
loss: 0.018200  [  300/ 3444]
loss: 0.011780  [  400/ 3444]
loss: 0.008054  [  500/ 3444]
loss: 0.025445  [  600/ 3444]
loss: 0.026772  [  700/ 3444]
loss: 0.006767  [  800/ 3444]
loss: 0.016126  [  900/ 3444]
loss: 0.009592  [ 1000/ 3444]
loss: 0.014427  [ 1100/ 3444]
loss: 0.005871  [ 1200/ 3444]
loss: 0.015195  [ 1300/ 3444]
loss: 0.115018  [ 1400/ 3444]
loss: 0.006889  [ 1500/ 3444]
loss: 0.011395  [ 1600/ 3444]
loss: 0.007954  [ 1700/ 3444]
loss: 0.017870  [ 1800/ 3444]
loss: 0.008594  [ 1900/ 3444]
loss: 0.009511  [ 2000/ 3444]
loss: 0.016882  [ 2100/ 3444]
loss: 0.023003  [ 2200/ 3444]
loss: 0.013442  [ 2300/ 3444]
loss: 0.005378  [ 2400/ 3444]
loss: 0.005176  [ 2500/ 3444]
loss: 0.007403  [ 2600/ 3444]
loss: 0.008420  [ 2700/ 3444]
loss: 0.015073  [ 2800/ 3444]
loss: 0.009785  [ 2900/ 3444]
loss: 0.013731  [ 3000/ 3444]
loss: 0.040991  [ 3100/ 3444]
loss: 0.104308  [ 3200/ 3444]
loss: 0.006832  [ 3300/ 3444]
loss: 0.028212  [ 3400/ 3444]
Epoch 3
-------------------------------
loss: 0.016911  [    0/ 3444]
loss: 0.010818  [  100/ 3444]
loss: 0.006154  [  200/ 3444]
loss: 0.017531  [  300/ 3444]
loss: 0.010988  [  400/ 3444]
loss: 0.007770  [  500/ 3444]
loss: 0.028896  [  600/ 3444]
loss: 0.025637  [  700/ 3444]
loss: 0.007049  [  800/ 3444]
loss: 0.018193  [  900/ 3444]
loss: 0.009183  [ 1000/ 3444]
loss: 0.012148  [ 1100/ 3444]
loss: 0.004216  [ 1200/ 3444]
loss: 0.014979  [ 1300/ 3444]
loss: 0.115204  [ 1400/ 3444]
loss: 0.007451  [ 1500/ 3444]
loss: 0.010507  [ 1600/ 3444]
loss: 0.007591  [ 1700/ 3444]
loss: 0.017925  [ 1800/ 3444]
loss: 0.008971  [ 1900/ 3444]
loss: 0.008779  [ 2000/ 3444]
loss: 0.016809  [ 2100/ 3444]
loss: 0.020980  [ 2200/ 3444]
loss: 0.012558  [ 2300/ 3444]
loss: 0.004829  [ 2400/ 3444]
loss: 0.004663  [ 2500/ 3444]
loss: 0.007041  [ 2600/ 3444]
loss: 0.007482  [ 2700/ 3444]
loss: 0.015134  [ 2800/ 3444]
loss: 0.010020  [ 2900/ 3444]
loss: 0.012552  [ 3000/ 3444]
loss: 0.033282  [ 3100/ 3444]
loss: 0.103158  [ 3200/ 3444]
loss: 0.006524  [ 3300/ 3444]
loss: 0.026824  [ 3400/ 3444]
Epoch 4
-------------------------------
loss: 0.016874  [    0/ 3444]
loss: 0.010501  [  100/ 3444]
loss: 0.006338  [  200/ 3444]
loss: 0.016990  [  300/ 3444]
loss: 0.010540  [  400/ 3444]
loss: 0.008049  [  500/ 3444]
loss: 0.028684  [  600/ 3444]
loss: 0.025036  [  700/ 3444]
loss: 0.007060  [  800/ 3444]
loss: 0.018702  [  900/ 3444]
loss: 0.009560  [ 1000/ 3444]
loss: 0.010876  [ 1100/ 3444]
loss: 0.003874  [ 1200/ 3444]
loss: 0.014071  [ 1300/ 3444]
loss: 0.115501  [ 1400/ 3444]
loss: 0.007591  [ 1500/ 3444]
loss: 0.010290  [ 1600/ 3444]
loss: 0.007329  [ 1700/ 3444]
loss: 0.017943  [ 1800/ 3444]
loss: 0.009494  [ 1900/ 3444]
loss: 0.006565  [ 2000/ 3444]
loss: 0.016741  [ 2100/ 3444]
loss: 0.020376  [ 2200/ 3444]
loss: 0.012155  [ 2300/ 3444]
loss: 0.004887  [ 2400/ 3444]
loss: 0.004326  [ 2500/ 3444]
loss: 0.006769  [ 2600/ 3444]
loss: 0.007026  [ 2700/ 3444]
loss: 0.015041  [ 2800/ 3444]
loss: 0.010548  [ 2900/ 3444]
loss: 0.012038  [ 3000/ 3444]
loss: 0.025750  [ 3100/ 3444]
loss: 0.102426  [ 3200/ 3444]
loss: 0.006425  [ 3300/ 3444]
loss: 0.026138  [ 3400/ 3444]
Epoch 5
-------------------------------
loss: 0.016180  [    0/ 3444]
loss: 0.009718  [  100/ 3444]
loss: 0.006461  [  200/ 3444]
loss: 0.016520  [  300/ 3444]
loss: 0.010323  [  400/ 3444]
loss: 0.008393  [  500/ 3444]
loss: 0.025778  [  600/ 3444]
loss: 0.024873  [  700/ 3444]
loss: 0.006933  [  800/ 3444]
loss: 0.019103  [  900/ 3444]
loss: 0.010175  [ 1000/ 3444]
loss: 0.010430  [ 1100/ 3444]
loss: 0.003795  [ 1200/ 3444]
loss: 0.014262  [ 1300/ 3444]
loss: 0.116021  [ 1400/ 3444]
loss: 0.007463  [ 1500/ 3444]
loss: 0.010130  [ 1600/ 3444]
loss: 0.007364  [ 1700/ 3444]
loss: 0.017870  [ 1800/ 3444]
loss: 0.009453  [ 1900/ 3444]
loss: 0.004777  [ 2000/ 3444]
loss: 0.016638  [ 2100/ 3444]
loss: 0.020380  [ 2200/ 3444]
loss: 0.011885  [ 2300/ 3444]
loss: 0.005252  [ 2400/ 3444]
loss: 0.004094  [ 2500/ 3444]
loss: 0.006589  [ 2600/ 3444]
loss: 0.007067  [ 2700/ 3444]
loss: 0.015019  [ 2800/ 3444]
loss: 0.010850  [ 2900/ 3444]
loss: 0.012015  [ 3000/ 3444]
loss: 0.022216  [ 3100/ 3444]
loss: 0.101344  [ 3200/ 3444]
loss: 0.006456  [ 3300/ 3444]
loss: 0.025869  [ 3400/ 3444]
Epoch 6
-------------------------------
loss: 0.015459  [    0/ 3444]
loss: 0.010150  [  100/ 3444]
loss: 0.006798  [  200/ 3444]
loss: 0.016252  [  300/ 3444]
loss: 0.010437  [  400/ 3444]
loss: 0.008574  [  500/ 3444]
loss: 0.022247  [  600/ 3444]
loss: 0.024910  [  700/ 3444]
loss: 0.006859  [  800/ 3444]
loss: 0.019157  [  900/ 3444]
loss: 0.010547  [ 1000/ 3444]
loss: 0.010411  [ 1100/ 3444]
loss: 0.003621  [ 1200/ 3444]
loss: 0.014226  [ 1300/ 3444]
loss: 0.116296  [ 1400/ 3444]
loss: 0.007346  [ 1500/ 3444]
loss: 0.009809  [ 1600/ 3444]
loss: 0.007460  [ 1700/ 3444]
loss: 0.017532  [ 1800/ 3444]
loss: 0.009491  [ 1900/ 3444]
loss: 0.003971  [ 2000/ 3444]
loss: 0.016532  [ 2100/ 3444]
loss: 0.020398  [ 2200/ 3444]
loss: 0.011867  [ 2300/ 3444]
loss: 0.005639  [ 2400/ 3444]
loss: 0.003972  [ 2500/ 3444]
loss: 0.006494  [ 2600/ 3444]
loss: 0.007040  [ 2700/ 3444]
loss: 0.015074  [ 2800/ 3444]
loss: 0.011072  [ 2900/ 3444]
loss: 0.012108  [ 3000/ 3444]
loss: 0.019276  [ 3100/ 3444]
loss: 0.102529  [ 3200/ 3444]
loss: 0.006537  [ 3300/ 3444]
loss: 0.025999  [ 3400/ 3444]
Epoch 7
-------------------------------
loss: 0.015240  [    0/ 3444]
loss: 0.009714  [  100/ 3444]
loss: 0.006724  [  200/ 3444]
loss: 0.016380  [  300/ 3444]
loss: 0.010539  [  400/ 3444]
loss: 0.008584  [  500/ 3444]
loss: 0.019728  [  600/ 3444]
loss: 0.025568  [  700/ 3444]
loss: 0.007141  [  800/ 3444]
loss: 0.019020  [  900/ 3444]
loss: 0.010541  [ 1000/ 3444]
loss: 0.010415  [ 1100/ 3444]
loss: 0.003520  [ 1200/ 3444]
loss: 0.013861  [ 1300/ 3444]
loss: 0.116042  [ 1400/ 3444]
loss: 0.007163  [ 1500/ 3444]
loss: 0.009419  [ 1600/ 3444]
loss: 0.007661  [ 1700/ 3444]
loss: 0.017053  [ 1800/ 3444]
loss: 0.009556  [ 1900/ 3444]
loss: 0.003684  [ 2000/ 3444]
loss: 0.016385  [ 2100/ 3444]
loss: 0.020844  [ 2200/ 3444]
loss: 0.011777  [ 2300/ 3444]
loss: 0.005854  [ 2400/ 3444]
loss: 0.003998  [ 2500/ 3444]
loss: 0.006506  [ 2600/ 3444]
loss: 0.006957  [ 2700/ 3444]
loss: 0.015162  [ 2800/ 3444]
loss: 0.011104  [ 2900/ 3444]
loss: 0.012132  [ 3000/ 3444]
loss: 0.017901  [ 3100/ 3444]
loss: 0.103545  [ 3200/ 3444]
loss: 0.006505  [ 3300/ 3444]
loss: 0.025932  [ 3400/ 3444]
Epoch 8
-------------------------------
loss: 0.014539  [    0/ 3444]
loss: 0.009679  [  100/ 3444]
loss: 0.006651  [  200/ 3444]
loss: 0.016447  [  300/ 3444]
loss: 0.010625  [  400/ 3444]
loss: 0.008529  [  500/ 3444]
loss: 0.018796  [  600/ 3444]
loss: 0.025930  [  700/ 3444]
loss: 0.007028  [  800/ 3444]
loss: 0.019124  [  900/ 3444]
loss: 0.010337  [ 1000/ 3444]
loss: 0.010221  [ 1100/ 3444]
loss: 0.003409  [ 1200/ 3444]
loss: 0.013479  [ 1300/ 3444]
loss: 0.115545  [ 1400/ 3444]
loss: 0.007094  [ 1500/ 3444]
loss: 0.008849  [ 1600/ 3444]
loss: 0.007696  [ 1700/ 3444]
loss: 0.016849  [ 1800/ 3444]
loss: 0.009700  [ 1900/ 3444]
loss: 0.003711  [ 2000/ 3444]
loss: 0.016212  [ 2100/ 3444]
loss: 0.020726  [ 2200/ 3444]
loss: 0.011801  [ 2300/ 3444]
loss: 0.006259  [ 2400/ 3444]
loss: 0.004004  [ 2500/ 3444]
loss: 0.006375  [ 2600/ 3444]
loss: 0.006735  [ 2700/ 3444]
loss: 0.015149  [ 2800/ 3444]
loss: 0.011056  [ 2900/ 3444]
loss: 0.011932  [ 3000/ 3444]
loss: 0.017500  [ 3100/ 3444]
loss: 0.103345  [ 3200/ 3444]
loss: 0.006573  [ 3300/ 3444]
loss: 0.025920  [ 3400/ 3444]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3444
First Spike after testing: [-1.504818    0.02567793]
[2 2 0 ... 0 2 0]
[1 1 2 ... 0 1 2]
Cluster 0 Occurrences: 1142; KMEANS: 1280
Cluster 1 Occurrences: 1180; KMEANS: 1081
Cluster 2 Occurrences: 1122; KMEANS: 1083
Centroids: [[1.3720323, -0.39968264], [0.42330307, -0.15346861], [-1.4739187, -0.16495733]]
Centroids: [[0.4055149, -0.08267839], [-1.5223309, -0.14796458], [1.4212393, -0.5141593]]
Contingency Matrix: 
[[ 153    0  989]
 [1088    0   92]
 [  39 1081    2]]
[[-1, 0, 989], [-1, -1, -1], [-1, 1081, 2]]
[[-1, -1, 989], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 0, 2: 1, 0: 2}
New Contingency Matrix: 
[[ 989  153    0]
 [  92 1088    0]
 [   2   39 1081]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [989, 1088, 1081], Sum: 3158
All_Elements: [989, 153, 0, 92, 1088, 0, 2, 39, 1081], Sum: 3444
Accuracy: 0.9169570267131243
Done!
