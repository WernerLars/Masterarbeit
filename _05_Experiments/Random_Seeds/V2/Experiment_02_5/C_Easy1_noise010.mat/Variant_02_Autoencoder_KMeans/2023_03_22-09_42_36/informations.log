Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Easy1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_42_36
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B2610B9E8>
Sampling rate: 24000.0
Raw: [ 0.01223885  0.0148803   0.02156532 ... -0.02666729 -0.01215068
  0.01031338]
Times: [   1012    1333    1523 ... 1438660 1438690 1439287]
Cluster: [1 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3522
First aligned Spike Frame: [-0.12579972 -0.1620207  -0.18573939 -0.18961714 -0.17315203 -0.1396561
 -0.09426159 -0.04496221  0.00734136  0.05943689  0.09448878  0.07601101
  0.00811529  0.09446653  0.55421698  1.03008495  0.90195967  0.23116337
 -0.37857386 -0.59030761 -0.52695739 -0.40967661 -0.32471334 -0.26000903
 -0.19839489 -0.13975054 -0.09692457 -0.08223204 -0.09147337 -0.10695261
 -0.11338461 -0.10883018 -0.09915766 -0.08637804 -0.06514771 -0.03537735
 -0.00695045  0.01307529  0.02539335  0.03607991  0.04814655  0.05257424
  0.04538721  0.03512231  0.03354714  0.04141478  0.0511991 ]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1134
Cluster 2, Occurrences: 1237
<torch.utils.data.dataloader.DataLoader object at 0x0000019B26154FD0>
Epoch 1
-------------------------------
loss: 0.153087  [    0/ 3522]
loss: 0.151282  [  100/ 3522]
loss: 0.052953  [  200/ 3522]
loss: 0.042292  [  300/ 3522]
loss: 0.026221  [  400/ 3522]
loss: 0.014234  [  500/ 3522]
loss: 0.115310  [  600/ 3522]
loss: 0.018544  [  700/ 3522]
loss: 0.013719  [  800/ 3522]
loss: 0.007175  [  900/ 3522]
loss: 0.004790  [ 1000/ 3522]
loss: 0.003986  [ 1100/ 3522]
loss: 0.091512  [ 1200/ 3522]
loss: 0.015958  [ 1300/ 3522]
loss: 0.002695  [ 1400/ 3522]
loss: 0.004899  [ 1500/ 3522]
loss: 0.010456  [ 1600/ 3522]
loss: 0.008894  [ 1700/ 3522]
loss: 0.010421  [ 1800/ 3522]
loss: 0.015336  [ 1900/ 3522]
loss: 0.012319  [ 2000/ 3522]
loss: 0.011550  [ 2100/ 3522]
loss: 0.005508  [ 2200/ 3522]
loss: 0.007231  [ 2300/ 3522]
loss: 0.003593  [ 2400/ 3522]
loss: 0.003894  [ 2500/ 3522]
loss: 0.073256  [ 2600/ 3522]
loss: 0.008969  [ 2700/ 3522]
loss: 0.003694  [ 2800/ 3522]
loss: 0.004379  [ 2900/ 3522]
loss: 0.009234  [ 3000/ 3522]
loss: 0.009192  [ 3100/ 3522]
loss: 0.012143  [ 3200/ 3522]
loss: 0.010177  [ 3300/ 3522]
loss: 0.008942  [ 3400/ 3522]
loss: 0.006599  [ 3500/ 3522]
Epoch 2
-------------------------------
loss: 0.010644  [    0/ 3522]
loss: 0.007491  [  100/ 3522]
loss: 0.006019  [  200/ 3522]
loss: 0.030362  [  300/ 3522]
loss: 0.007733  [  400/ 3522]
loss: 0.010118  [  500/ 3522]
loss: 0.111595  [  600/ 3522]
loss: 0.014700  [  700/ 3522]
loss: 0.012709  [  800/ 3522]
loss: 0.005957  [  900/ 3522]
loss: 0.003320  [ 1000/ 3522]
loss: 0.003990  [ 1100/ 3522]
loss: 0.092038  [ 1200/ 3522]
loss: 0.016477  [ 1300/ 3522]
loss: 0.002606  [ 1400/ 3522]
loss: 0.002636  [ 1500/ 3522]
loss: 0.010817  [ 1600/ 3522]
loss: 0.009100  [ 1700/ 3522]
loss: 0.009597  [ 1800/ 3522]
loss: 0.011356  [ 1900/ 3522]
loss: 0.011548  [ 2000/ 3522]
loss: 0.008227  [ 2100/ 3522]
loss: 0.004482  [ 2200/ 3522]
loss: 0.007150  [ 2300/ 3522]
loss: 0.004216  [ 2400/ 3522]
loss: 0.003509  [ 2500/ 3522]
loss: 0.072745  [ 2600/ 3522]
loss: 0.008240  [ 2700/ 3522]
loss: 0.003523  [ 2800/ 3522]
loss: 0.004365  [ 2900/ 3522]
loss: 0.008195  [ 3000/ 3522]
loss: 0.005940  [ 3100/ 3522]
loss: 0.009313  [ 3200/ 3522]
loss: 0.008837  [ 3300/ 3522]
loss: 0.008606  [ 3400/ 3522]
loss: 0.006471  [ 3500/ 3522]
Epoch 3
-------------------------------
loss: 0.009626  [    0/ 3522]
loss: 0.008590  [  100/ 3522]
loss: 0.005400  [  200/ 3522]
loss: 0.019569  [  300/ 3522]
loss: 0.006969  [  400/ 3522]
loss: 0.009710  [  500/ 3522]
loss: 0.112726  [  600/ 3522]
loss: 0.013642  [  700/ 3522]
loss: 0.011054  [  800/ 3522]
loss: 0.006258  [  900/ 3522]
loss: 0.003370  [ 1000/ 3522]
loss: 0.003667  [ 1100/ 3522]
loss: 0.090453  [ 1200/ 3522]
loss: 0.015615  [ 1300/ 3522]
loss: 0.002820  [ 1400/ 3522]
loss: 0.002626  [ 1500/ 3522]
loss: 0.010512  [ 1600/ 3522]
loss: 0.008246  [ 1700/ 3522]
loss: 0.009929  [ 1800/ 3522]
loss: 0.011141  [ 1900/ 3522]
loss: 0.010480  [ 2000/ 3522]
loss: 0.007350  [ 2100/ 3522]
loss: 0.003618  [ 2200/ 3522]
loss: 0.007379  [ 2300/ 3522]
loss: 0.003890  [ 2400/ 3522]
loss: 0.003357  [ 2500/ 3522]
loss: 0.073496  [ 2600/ 3522]
loss: 0.008037  [ 2700/ 3522]
loss: 0.003446  [ 2800/ 3522]
loss: 0.004444  [ 2900/ 3522]
loss: 0.007245  [ 3000/ 3522]
loss: 0.005827  [ 3100/ 3522]
loss: 0.007741  [ 3200/ 3522]
loss: 0.008663  [ 3300/ 3522]
loss: 0.008689  [ 3400/ 3522]
loss: 0.006707  [ 3500/ 3522]
Epoch 4
-------------------------------
loss: 0.008903  [    0/ 3522]
loss: 0.008810  [  100/ 3522]
loss: 0.005352  [  200/ 3522]
loss: 0.017306  [  300/ 3522]
loss: 0.006866  [  400/ 3522]
loss: 0.009602  [  500/ 3522]
loss: 0.111549  [  600/ 3522]
loss: 0.012970  [  700/ 3522]
loss: 0.009957  [  800/ 3522]
loss: 0.006635  [  900/ 3522]
loss: 0.003405  [ 1000/ 3522]
loss: 0.003298  [ 1100/ 3522]
loss: 0.082196  [ 1200/ 3522]
loss: 0.014874  [ 1300/ 3522]
loss: 0.002869  [ 1400/ 3522]
loss: 0.002749  [ 1500/ 3522]
loss: 0.010014  [ 1600/ 3522]
loss: 0.007781  [ 1700/ 3522]
loss: 0.010549  [ 1800/ 3522]
loss: 0.011034  [ 1900/ 3522]
loss: 0.010181  [ 2000/ 3522]
loss: 0.006991  [ 2100/ 3522]
loss: 0.003240  [ 2200/ 3522]
loss: 0.007730  [ 2300/ 3522]
loss: 0.003713  [ 2400/ 3522]
loss: 0.003384  [ 2500/ 3522]
loss: 0.073921  [ 2600/ 3522]
loss: 0.007705  [ 2700/ 3522]
loss: 0.003360  [ 2800/ 3522]
loss: 0.004502  [ 2900/ 3522]
loss: 0.006757  [ 3000/ 3522]
loss: 0.005024  [ 3100/ 3522]
loss: 0.007311  [ 3200/ 3522]
loss: 0.008433  [ 3300/ 3522]
loss: 0.009125  [ 3400/ 3522]
loss: 0.006853  [ 3500/ 3522]
Epoch 5
-------------------------------
loss: 0.008589  [    0/ 3522]
loss: 0.008695  [  100/ 3522]
loss: 0.005260  [  200/ 3522]
loss: 0.017834  [  300/ 3522]
loss: 0.006819  [  400/ 3522]
loss: 0.009518  [  500/ 3522]
loss: 0.112009  [  600/ 3522]
loss: 0.012681  [  700/ 3522]
loss: 0.009364  [  800/ 3522]
loss: 0.006608  [  900/ 3522]
loss: 0.003369  [ 1000/ 3522]
loss: 0.003143  [ 1100/ 3522]
loss: 0.083063  [ 1200/ 3522]
loss: 0.014493  [ 1300/ 3522]
loss: 0.002838  [ 1400/ 3522]
loss: 0.002676  [ 1500/ 3522]
loss: 0.010028  [ 1600/ 3522]
loss: 0.007470  [ 1700/ 3522]
loss: 0.010359  [ 1800/ 3522]
loss: 0.010954  [ 1900/ 3522]
loss: 0.010119  [ 2000/ 3522]
loss: 0.006739  [ 2100/ 3522]
loss: 0.003114  [ 2200/ 3522]
loss: 0.007803  [ 2300/ 3522]
loss: 0.003783  [ 2400/ 3522]
loss: 0.003283  [ 2500/ 3522]
loss: 0.073703  [ 2600/ 3522]
loss: 0.007280  [ 2700/ 3522]
loss: 0.003325  [ 2800/ 3522]
loss: 0.004564  [ 2900/ 3522]
loss: 0.006526  [ 3000/ 3522]
loss: 0.005312  [ 3100/ 3522]
loss: 0.007313  [ 3200/ 3522]
loss: 0.008556  [ 3300/ 3522]
loss: 0.009559  [ 3400/ 3522]
loss: 0.007052  [ 3500/ 3522]
Epoch 6
-------------------------------
loss: 0.008575  [    0/ 3522]
loss: 0.008719  [  100/ 3522]
loss: 0.005233  [  200/ 3522]
loss: 0.017134  [  300/ 3522]
loss: 0.006825  [  400/ 3522]
loss: 0.009453  [  500/ 3522]
loss: 0.113112  [  600/ 3522]
loss: 0.012347  [  700/ 3522]
loss: 0.008769  [  800/ 3522]
loss: 0.006696  [  900/ 3522]
loss: 0.003365  [ 1000/ 3522]
loss: 0.003076  [ 1100/ 3522]
loss: 0.083101  [ 1200/ 3522]
loss: 0.014220  [ 1300/ 3522]
loss: 0.002854  [ 1400/ 3522]
loss: 0.002551  [ 1500/ 3522]
loss: 0.010067  [ 1600/ 3522]
loss: 0.007142  [ 1700/ 3522]
loss: 0.010616  [ 1800/ 3522]
loss: 0.010797  [ 1900/ 3522]
loss: 0.009906  [ 2000/ 3522]
loss: 0.006643  [ 2100/ 3522]
loss: 0.003039  [ 2200/ 3522]
loss: 0.007535  [ 2300/ 3522]
loss: 0.003841  [ 2400/ 3522]
loss: 0.003097  [ 2500/ 3522]
loss: 0.073885  [ 2600/ 3522]
loss: 0.006954  [ 2700/ 3522]
loss: 0.003316  [ 2800/ 3522]
loss: 0.004627  [ 2900/ 3522]
loss: 0.006581  [ 3000/ 3522]
loss: 0.005509  [ 3100/ 3522]
loss: 0.007722  [ 3200/ 3522]
loss: 0.008677  [ 3300/ 3522]
loss: 0.009988  [ 3400/ 3522]
loss: 0.007071  [ 3500/ 3522]
Epoch 7
-------------------------------
loss: 0.008417  [    0/ 3522]
loss: 0.009175  [  100/ 3522]
loss: 0.005193  [  200/ 3522]
loss: 0.016744  [  300/ 3522]
loss: 0.006887  [  400/ 3522]
loss: 0.009436  [  500/ 3522]
loss: 0.114554  [  600/ 3522]
loss: 0.012167  [  700/ 3522]
loss: 0.008451  [  800/ 3522]
loss: 0.006503  [  900/ 3522]
loss: 0.003322  [ 1000/ 3522]
loss: 0.003073  [ 1100/ 3522]
loss: 0.083489  [ 1200/ 3522]
loss: 0.013902  [ 1300/ 3522]
loss: 0.002820  [ 1400/ 3522]
loss: 0.002546  [ 1500/ 3522]
loss: 0.010951  [ 1600/ 3522]
loss: 0.006799  [ 1700/ 3522]
loss: 0.012182  [ 1800/ 3522]
loss: 0.010287  [ 1900/ 3522]
loss: 0.009889  [ 2000/ 3522]
loss: 0.006595  [ 2100/ 3522]
loss: 0.003037  [ 2200/ 3522]
loss: 0.008016  [ 2300/ 3522]
loss: 0.004491  [ 2400/ 3522]
loss: 0.002852  [ 2500/ 3522]
loss: 0.074279  [ 2600/ 3522]
loss: 0.006722  [ 2700/ 3522]
loss: 0.003299  [ 2800/ 3522]
loss: 0.004660  [ 2900/ 3522]
loss: 0.006503  [ 3000/ 3522]
loss: 0.006309  [ 3100/ 3522]
loss: 0.007685  [ 3200/ 3522]
loss: 0.008671  [ 3300/ 3522]
loss: 0.010683  [ 3400/ 3522]
loss: 0.007229  [ 3500/ 3522]
Epoch 8
-------------------------------
loss: 0.008481  [    0/ 3522]
loss: 0.008531  [  100/ 3522]
loss: 0.005036  [  200/ 3522]
loss: 0.014815  [  300/ 3522]
loss: 0.006862  [  400/ 3522]
loss: 0.009521  [  500/ 3522]
loss: 0.115108  [  600/ 3522]
loss: 0.011906  [  700/ 3522]
loss: 0.008178  [  800/ 3522]
loss: 0.006472  [  900/ 3522]
loss: 0.003177  [ 1000/ 3522]
loss: 0.003150  [ 1100/ 3522]
loss: 0.084721  [ 1200/ 3522]
loss: 0.013617  [ 1300/ 3522]
loss: 0.002911  [ 1400/ 3522]
loss: 0.002571  [ 1500/ 3522]
loss: 0.011186  [ 1600/ 3522]
loss: 0.006573  [ 1700/ 3522]
loss: 0.012391  [ 1800/ 3522]
loss: 0.010149  [ 1900/ 3522]
loss: 0.009680  [ 2000/ 3522]
loss: 0.006566  [ 2100/ 3522]
loss: 0.002977  [ 2200/ 3522]
loss: 0.008030  [ 2300/ 3522]
loss: 0.004529  [ 2400/ 3522]
loss: 0.002738  [ 2500/ 3522]
loss: 0.074665  [ 2600/ 3522]
loss: 0.006513  [ 2700/ 3522]
loss: 0.003269  [ 2800/ 3522]
loss: 0.004719  [ 2900/ 3522]
loss: 0.006544  [ 3000/ 3522]
loss: 0.006670  [ 3100/ 3522]
loss: 0.008157  [ 3200/ 3522]
loss: 0.008679  [ 3300/ 3522]
loss: 0.011319  [ 3400/ 3522]
loss: 0.007135  [ 3500/ 3522]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3522
First Spike after testing: [-1.3898752  0.7717711]
[0 2 2 ... 2 0 2]
[0 2 2 ... 2 0 2]
Cluster 0 Occurrences: 1151; KMEANS: 1157
Cluster 1 Occurrences: 1134; KMEANS: 1116
Cluster 2 Occurrences: 1237; KMEANS: 1249
Centroids: [[-1.69561, 0.8204819], [1.5984181, 0.76659447], [-1.1999191, -1.2638936]]
Centroids: [[-1.7114233, 0.8341075], [1.656412, 0.77106583], [-1.1943796, -1.2612616]]
Contingency Matrix: 
[[1138    0   13]
 [  14 1114    6]
 [   5    2 1230]]
[[1138, 0, -1], [14, 1114, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1114, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 0, 1: 1}
New Contingency Matrix: 
[[1138    0   13]
 [  14 1114    6]
 [   5    2 1230]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1138, 1114, 1230], Sum: 3482
All_Elements: [1138, 0, 13, 14, 1114, 6, 5, 2, 1230], Sum: 3522
Accuracy: 0.9886428165814878
Done!
