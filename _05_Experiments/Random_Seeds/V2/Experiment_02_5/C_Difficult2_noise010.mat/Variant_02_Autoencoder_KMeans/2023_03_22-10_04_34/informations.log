Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_04_34
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B89A90828>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x0000019B89ADF3C8>
Epoch 1
-------------------------------
loss: 0.174875  [    0/ 3462]
loss: 0.115743  [  100/ 3462]
loss: 0.036643  [  200/ 3462]
loss: 0.016310  [  300/ 3462]
loss: 0.024147  [  400/ 3462]
loss: 0.016157  [  500/ 3462]
loss: 0.010382  [  600/ 3462]
loss: 0.019559  [  700/ 3462]
loss: 0.011694  [  800/ 3462]
loss: 0.015904  [  900/ 3462]
loss: 0.012608  [ 1000/ 3462]
loss: 0.050170  [ 1100/ 3462]
loss: 0.021012  [ 1200/ 3462]
loss: 0.005200  [ 1300/ 3462]
loss: 0.009847  [ 1400/ 3462]
loss: 0.008700  [ 1500/ 3462]
loss: 0.008586  [ 1600/ 3462]
loss: 0.004864  [ 1700/ 3462]
loss: 0.017604  [ 1800/ 3462]
loss: 0.005588  [ 1900/ 3462]
loss: 0.010912  [ 2000/ 3462]
loss: 0.061853  [ 2100/ 3462]
loss: 0.001740  [ 2200/ 3462]
loss: 0.006315  [ 2300/ 3462]
loss: 0.011826  [ 2400/ 3462]
loss: 0.005770  [ 2500/ 3462]
loss: 0.015453  [ 2600/ 3462]
loss: 0.008172  [ 2700/ 3462]
loss: 0.005091  [ 2800/ 3462]
loss: 0.015989  [ 2900/ 3462]
loss: 0.116277  [ 3000/ 3462]
loss: 0.007399  [ 3100/ 3462]
loss: 0.007692  [ 3200/ 3462]
loss: 0.126225  [ 3300/ 3462]
loss: 0.011678  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.001968  [    0/ 3462]
loss: 0.011232  [  100/ 3462]
loss: 0.011898  [  200/ 3462]
loss: 0.013038  [  300/ 3462]
loss: 0.011734  [  400/ 3462]
loss: 0.004872  [  500/ 3462]
loss: 0.007012  [  600/ 3462]
loss: 0.016959  [  700/ 3462]
loss: 0.008999  [  800/ 3462]
loss: 0.013953  [  900/ 3462]
loss: 0.010557  [ 1000/ 3462]
loss: 0.037783  [ 1100/ 3462]
loss: 0.028473  [ 1200/ 3462]
loss: 0.003922  [ 1300/ 3462]
loss: 0.006960  [ 1400/ 3462]
loss: 0.009463  [ 1500/ 3462]
loss: 0.008618  [ 1600/ 3462]
loss: 0.003897  [ 1700/ 3462]
loss: 0.018160  [ 1800/ 3462]
loss: 0.003287  [ 1900/ 3462]
loss: 0.008581  [ 2000/ 3462]
loss: 0.057587  [ 2100/ 3462]
loss: 0.001518  [ 2200/ 3462]
loss: 0.006009  [ 2300/ 3462]
loss: 0.011611  [ 2400/ 3462]
loss: 0.005268  [ 2500/ 3462]
loss: 0.015828  [ 2600/ 3462]
loss: 0.007464  [ 2700/ 3462]
loss: 0.003975  [ 2800/ 3462]
loss: 0.013185  [ 2900/ 3462]
loss: 0.116410  [ 3000/ 3462]
loss: 0.007201  [ 3100/ 3462]
loss: 0.007349  [ 3200/ 3462]
loss: 0.115879  [ 3300/ 3462]
loss: 0.011739  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.001899  [    0/ 3462]
loss: 0.011088  [  100/ 3462]
loss: 0.011924  [  200/ 3462]
loss: 0.009669  [  300/ 3462]
loss: 0.010967  [  400/ 3462]
loss: 0.002921  [  500/ 3462]
loss: 0.006544  [  600/ 3462]
loss: 0.017086  [  700/ 3462]
loss: 0.007685  [  800/ 3462]
loss: 0.014075  [  900/ 3462]
loss: 0.010020  [ 1000/ 3462]
loss: 0.037010  [ 1100/ 3462]
loss: 0.030515  [ 1200/ 3462]
loss: 0.003691  [ 1300/ 3462]
loss: 0.006151  [ 1400/ 3462]
loss: 0.007716  [ 1500/ 3462]
loss: 0.008642  [ 1600/ 3462]
loss: 0.003669  [ 1700/ 3462]
loss: 0.018305  [ 1800/ 3462]
loss: 0.003620  [ 1900/ 3462]
loss: 0.007211  [ 2000/ 3462]
loss: 0.051273  [ 2100/ 3462]
loss: 0.001657  [ 2200/ 3462]
loss: 0.006335  [ 2300/ 3462]
loss: 0.011544  [ 2400/ 3462]
loss: 0.004990  [ 2500/ 3462]
loss: 0.016291  [ 2600/ 3462]
loss: 0.007220  [ 2700/ 3462]
loss: 0.003075  [ 2800/ 3462]
loss: 0.011970  [ 2900/ 3462]
loss: 0.116326  [ 3000/ 3462]
loss: 0.007629  [ 3100/ 3462]
loss: 0.007300  [ 3200/ 3462]
loss: 0.106215  [ 3300/ 3462]
loss: 0.011517  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.001876  [    0/ 3462]
loss: 0.011524  [  100/ 3462]
loss: 0.012036  [  200/ 3462]
loss: 0.008975  [  300/ 3462]
loss: 0.010307  [  400/ 3462]
loss: 0.002542  [  500/ 3462]
loss: 0.006302  [  600/ 3462]
loss: 0.017505  [  700/ 3462]
loss: 0.006883  [  800/ 3462]
loss: 0.014598  [  900/ 3462]
loss: 0.009400  [ 1000/ 3462]
loss: 0.036569  [ 1100/ 3462]
loss: 0.026808  [ 1200/ 3462]
loss: 0.003818  [ 1300/ 3462]
loss: 0.005491  [ 1400/ 3462]
loss: 0.006544  [ 1500/ 3462]
loss: 0.008512  [ 1600/ 3462]
loss: 0.003836  [ 1700/ 3462]
loss: 0.018816  [ 1800/ 3462]
loss: 0.003933  [ 1900/ 3462]
loss: 0.006344  [ 2000/ 3462]
loss: 0.048235  [ 2100/ 3462]
loss: 0.001834  [ 2200/ 3462]
loss: 0.006159  [ 2300/ 3462]
loss: 0.011330  [ 2400/ 3462]
loss: 0.004589  [ 2500/ 3462]
loss: 0.016279  [ 2600/ 3462]
loss: 0.007157  [ 2700/ 3462]
loss: 0.002517  [ 2800/ 3462]
loss: 0.011674  [ 2900/ 3462]
loss: 0.116239  [ 3000/ 3462]
loss: 0.007885  [ 3100/ 3462]
loss: 0.007404  [ 3200/ 3462]
loss: 0.098603  [ 3300/ 3462]
loss: 0.011281  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.001801  [    0/ 3462]
loss: 0.012081  [  100/ 3462]
loss: 0.011409  [  200/ 3462]
loss: 0.012193  [  300/ 3462]
loss: 0.009987  [  400/ 3462]
loss: 0.002860  [  500/ 3462]
loss: 0.005213  [  600/ 3462]
loss: 0.018119  [  700/ 3462]
loss: 0.006383  [  800/ 3462]
loss: 0.014116  [  900/ 3462]
loss: 0.008807  [ 1000/ 3462]
loss: 0.035426  [ 1100/ 3462]
loss: 0.024933  [ 1200/ 3462]
loss: 0.004212  [ 1300/ 3462]
loss: 0.005077  [ 1400/ 3462]
loss: 0.005848  [ 1500/ 3462]
loss: 0.008182  [ 1600/ 3462]
loss: 0.004185  [ 1700/ 3462]
loss: 0.019113  [ 1800/ 3462]
loss: 0.004336  [ 1900/ 3462]
loss: 0.005883  [ 2000/ 3462]
loss: 0.047130  [ 2100/ 3462]
loss: 0.001914  [ 2200/ 3462]
loss: 0.005372  [ 2300/ 3462]
loss: 0.011087  [ 2400/ 3462]
loss: 0.004363  [ 2500/ 3462]
loss: 0.014936  [ 2600/ 3462]
loss: 0.007254  [ 2700/ 3462]
loss: 0.002230  [ 2800/ 3462]
loss: 0.011379  [ 2900/ 3462]
loss: 0.115713  [ 3000/ 3462]
loss: 0.007740  [ 3100/ 3462]
loss: 0.007457  [ 3200/ 3462]
loss: 0.095634  [ 3300/ 3462]
loss: 0.011051  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.001713  [    0/ 3462]
loss: 0.012065  [  100/ 3462]
loss: 0.010212  [  200/ 3462]
loss: 0.014395  [  300/ 3462]
loss: 0.009932  [  400/ 3462]
loss: 0.002554  [  500/ 3462]
loss: 0.003909  [  600/ 3462]
loss: 0.018219  [  700/ 3462]
loss: 0.006082  [  800/ 3462]
loss: 0.014099  [  900/ 3462]
loss: 0.008240  [ 1000/ 3462]
loss: 0.034909  [ 1100/ 3462]
loss: 0.021605  [ 1200/ 3462]
loss: 0.004876  [ 1300/ 3462]
loss: 0.005115  [ 1400/ 3462]
loss: 0.006000  [ 1500/ 3462]
loss: 0.007675  [ 1600/ 3462]
loss: 0.004863  [ 1700/ 3462]
loss: 0.019230  [ 1800/ 3462]
loss: 0.004082  [ 1900/ 3462]
loss: 0.005663  [ 2000/ 3462]
loss: 0.046760  [ 2100/ 3462]
loss: 0.002033  [ 2200/ 3462]
loss: 0.004695  [ 2300/ 3462]
loss: 0.010908  [ 2400/ 3462]
loss: 0.004272  [ 2500/ 3462]
loss: 0.013038  [ 2600/ 3462]
loss: 0.007186  [ 2700/ 3462]
loss: 0.002027  [ 2800/ 3462]
loss: 0.011304  [ 2900/ 3462]
loss: 0.114919  [ 3000/ 3462]
loss: 0.007889  [ 3100/ 3462]
loss: 0.007613  [ 3200/ 3462]
loss: 0.091121  [ 3300/ 3462]
loss: 0.010857  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.001658  [    0/ 3462]
loss: 0.012320  [  100/ 3462]
loss: 0.008592  [  200/ 3462]
loss: 0.013031  [  300/ 3462]
loss: 0.009831  [  400/ 3462]
loss: 0.002203  [  500/ 3462]
loss: 0.003202  [  600/ 3462]
loss: 0.018524  [  700/ 3462]
loss: 0.005950  [  800/ 3462]
loss: 0.013779  [  900/ 3462]
loss: 0.007531  [ 1000/ 3462]
loss: 0.034830  [ 1100/ 3462]
loss: 0.020339  [ 1200/ 3462]
loss: 0.004291  [ 1300/ 3462]
loss: 0.004876  [ 1400/ 3462]
loss: 0.006392  [ 1500/ 3462]
loss: 0.006627  [ 1600/ 3462]
loss: 0.005675  [ 1700/ 3462]
loss: 0.018574  [ 1800/ 3462]
loss: 0.004154  [ 1900/ 3462]
loss: 0.005574  [ 2000/ 3462]
loss: 0.048027  [ 2100/ 3462]
loss: 0.002059  [ 2200/ 3462]
loss: 0.004116  [ 2300/ 3462]
loss: 0.010661  [ 2400/ 3462]
loss: 0.004250  [ 2500/ 3462]
loss: 0.011498  [ 2600/ 3462]
loss: 0.007057  [ 2700/ 3462]
loss: 0.001964  [ 2800/ 3462]
loss: 0.010962  [ 2900/ 3462]
loss: 0.114016  [ 3000/ 3462]
loss: 0.008012  [ 3100/ 3462]
loss: 0.007677  [ 3200/ 3462]
loss: 0.089599  [ 3300/ 3462]
loss: 0.010670  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.001737  [    0/ 3462]
loss: 0.012861  [  100/ 3462]
loss: 0.007330  [  200/ 3462]
loss: 0.012152  [  300/ 3462]
loss: 0.009878  [  400/ 3462]
loss: 0.002032  [  500/ 3462]
loss: 0.002861  [  600/ 3462]
loss: 0.018594  [  700/ 3462]
loss: 0.005958  [  800/ 3462]
loss: 0.013461  [  900/ 3462]
loss: 0.006821  [ 1000/ 3462]
loss: 0.035672  [ 1100/ 3462]
loss: 0.015328  [ 1200/ 3462]
loss: 0.004139  [ 1300/ 3462]
loss: 0.004617  [ 1400/ 3462]
loss: 0.006794  [ 1500/ 3462]
loss: 0.006020  [ 1600/ 3462]
loss: 0.006165  [ 1700/ 3462]
loss: 0.018313  [ 1800/ 3462]
loss: 0.004349  [ 1900/ 3462]
loss: 0.005487  [ 2000/ 3462]
loss: 0.049582  [ 2100/ 3462]
loss: 0.002039  [ 2200/ 3462]
loss: 0.003973  [ 2300/ 3462]
loss: 0.010651  [ 2400/ 3462]
loss: 0.004468  [ 2500/ 3462]
loss: 0.010094  [ 2600/ 3462]
loss: 0.006945  [ 2700/ 3462]
loss: 0.001908  [ 2800/ 3462]
loss: 0.011243  [ 2900/ 3462]
loss: 0.112893  [ 3000/ 3462]
loss: 0.007463  [ 3100/ 3462]
loss: 0.007669  [ 3200/ 3462]
loss: 0.091788  [ 3300/ 3462]
loss: 0.010697  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [-0.9635237  -0.34920007]
[0 2 2 ... 0 1 2]
[2 0 0 ... 2 1 0]
Cluster 0 Occurrences: 1187; KMEANS: 1217
Cluster 1 Occurrences: 1136; KMEANS: 1127
Cluster 2 Occurrences: 1139; KMEANS: 1118
Centroids: [[-1.0688446, -0.09777662], [2.014698, 0.06158018], [-0.22314405, -0.7370294]]
Centroids: [[-0.23495616, -0.76541775], [2.0362716, 0.058184844], [-1.1119132, -0.017569833]]
Contingency Matrix: 
[[ 100    1 1086]
 [  11 1123    2]
 [1106    3   30]]
[[100, -1, 1086], [-1, -1, -1], [1106, -1, 30]]
[[-1, -1, 1086], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {1: 1, 2: 0, 0: 2}
New Contingency Matrix: 
[[1086    1  100]
 [   2 1123   11]
 [  30    3 1106]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1086, 1123, 1106], Sum: 3315
All_Elements: [1086, 1, 100, 2, 1123, 11, 30, 3, 1106], Sum: 3462
Accuracy: 0.9575389948006933
Done!
