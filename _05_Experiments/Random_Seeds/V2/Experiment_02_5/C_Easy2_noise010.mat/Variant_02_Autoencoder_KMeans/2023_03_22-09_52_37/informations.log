Experiment_path: Random_Seeds//V2/Experiment_02_5
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_5/C_Easy2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_52_37
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000019B257DE048>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
<torch.utils.data.dataloader.DataLoader object at 0x0000019B2610BA58>
Epoch 1
-------------------------------
loss: 0.235111  [    0/ 3520]
loss: 0.096674  [  100/ 3520]
loss: 0.194739  [  200/ 3520]
loss: 0.021400  [  300/ 3520]
loss: 0.086728  [  400/ 3520]
loss: 0.175491  [  500/ 3520]
loss: 0.015190  [  600/ 3520]
loss: 0.009587  [  700/ 3520]
loss: 0.006624  [  800/ 3520]
loss: 0.018776  [  900/ 3520]
loss: 0.003955  [ 1000/ 3520]
loss: 0.019899  [ 1100/ 3520]
loss: 0.016375  [ 1200/ 3520]
loss: 0.032356  [ 1300/ 3520]
loss: 0.015026  [ 1400/ 3520]
loss: 0.004765  [ 1500/ 3520]
loss: 0.001841  [ 1600/ 3520]
loss: 0.003373  [ 1700/ 3520]
loss: 0.087152  [ 1800/ 3520]
loss: 0.007971  [ 1900/ 3520]
loss: 0.015249  [ 2000/ 3520]
loss: 0.007894  [ 2100/ 3520]
loss: 0.001893  [ 2200/ 3520]
loss: 0.074968  [ 2300/ 3520]
loss: 0.009993  [ 2400/ 3520]
loss: 0.008072  [ 2500/ 3520]
loss: 0.012300  [ 2600/ 3520]
loss: 0.005023  [ 2700/ 3520]
loss: 0.015219  [ 2800/ 3520]
loss: 0.005742  [ 2900/ 3520]
loss: 0.011490  [ 3000/ 3520]
loss: 0.015356  [ 3100/ 3520]
loss: 0.005503  [ 3200/ 3520]
loss: 0.003856  [ 3300/ 3520]
loss: 0.006900  [ 3400/ 3520]
loss: 0.012300  [ 3500/ 3520]
Epoch 2
-------------------------------
loss: 0.013675  [    0/ 3520]
loss: 0.003364  [  100/ 3520]
loss: 0.153129  [  200/ 3520]
loss: 0.005779  [  300/ 3520]
loss: 0.074582  [  400/ 3520]
loss: 0.125592  [  500/ 3520]
loss: 0.004839  [  600/ 3520]
loss: 0.009216  [  700/ 3520]
loss: 0.005701  [  800/ 3520]
loss: 0.004922  [  900/ 3520]
loss: 0.003294  [ 1000/ 3520]
loss: 0.007009  [ 1100/ 3520]
loss: 0.010051  [ 1200/ 3520]
loss: 0.012926  [ 1300/ 3520]
loss: 0.005411  [ 1400/ 3520]
loss: 0.001281  [ 1500/ 3520]
loss: 0.001921  [ 1600/ 3520]
loss: 0.004429  [ 1700/ 3520]
loss: 0.102340  [ 1800/ 3520]
loss: 0.007435  [ 1900/ 3520]
loss: 0.015387  [ 2000/ 3520]
loss: 0.007392  [ 2100/ 3520]
loss: 0.003652  [ 2200/ 3520]
loss: 0.057621  [ 2300/ 3520]
loss: 0.010299  [ 2400/ 3520]
loss: 0.009150  [ 2500/ 3520]
loss: 0.010553  [ 2600/ 3520]
loss: 0.003686  [ 2700/ 3520]
loss: 0.014971  [ 2800/ 3520]
loss: 0.004515  [ 2900/ 3520]
loss: 0.011844  [ 3000/ 3520]
loss: 0.006880  [ 3100/ 3520]
loss: 0.005852  [ 3200/ 3520]
loss: 0.003903  [ 3300/ 3520]
loss: 0.007079  [ 3400/ 3520]
loss: 0.011175  [ 3500/ 3520]
Epoch 3
-------------------------------
loss: 0.014058  [    0/ 3520]
loss: 0.002823  [  100/ 3520]
loss: 0.111288  [  200/ 3520]
loss: 0.004421  [  300/ 3520]
loss: 0.057733  [  400/ 3520]
loss: 0.081286  [  500/ 3520]
loss: 0.004149  [  600/ 3520]
loss: 0.008739  [  700/ 3520]
loss: 0.005848  [  800/ 3520]
loss: 0.003543  [  900/ 3520]
loss: 0.003244  [ 1000/ 3520]
loss: 0.007803  [ 1100/ 3520]
loss: 0.009321  [ 1200/ 3520]
loss: 0.010605  [ 1300/ 3520]
loss: 0.003635  [ 1400/ 3520]
loss: 0.001532  [ 1500/ 3520]
loss: 0.002221  [ 1600/ 3520]
loss: 0.004537  [ 1700/ 3520]
loss: 0.095617  [ 1800/ 3520]
loss: 0.006814  [ 1900/ 3520]
loss: 0.015388  [ 2000/ 3520]
loss: 0.007195  [ 2100/ 3520]
loss: 0.005468  [ 2200/ 3520]
loss: 0.055730  [ 2300/ 3520]
loss: 0.010609  [ 2400/ 3520]
loss: 0.009082  [ 2500/ 3520]
loss: 0.010159  [ 2600/ 3520]
loss: 0.003411  [ 2700/ 3520]
loss: 0.015669  [ 2800/ 3520]
loss: 0.003864  [ 2900/ 3520]
loss: 0.011684  [ 3000/ 3520]
loss: 0.004404  [ 3100/ 3520]
loss: 0.005873  [ 3200/ 3520]
loss: 0.004248  [ 3300/ 3520]
loss: 0.007536  [ 3400/ 3520]
loss: 0.010616  [ 3500/ 3520]
Epoch 4
-------------------------------
loss: 0.013383  [    0/ 3520]
loss: 0.002630  [  100/ 3520]
loss: 0.096890  [  200/ 3520]
loss: 0.004255  [  300/ 3520]
loss: 0.053835  [  400/ 3520]
loss: 0.068468  [  500/ 3520]
loss: 0.004520  [  600/ 3520]
loss: 0.008900  [  700/ 3520]
loss: 0.005507  [  800/ 3520]
loss: 0.002913  [  900/ 3520]
loss: 0.003302  [ 1000/ 3520]
loss: 0.008106  [ 1100/ 3520]
loss: 0.009454  [ 1200/ 3520]
loss: 0.007078  [ 1300/ 3520]
loss: 0.004453  [ 1400/ 3520]
loss: 0.002077  [ 1500/ 3520]
loss: 0.002324  [ 1600/ 3520]
loss: 0.004147  [ 1700/ 3520]
loss: 0.094649  [ 1800/ 3520]
loss: 0.006592  [ 1900/ 3520]
loss: 0.014487  [ 2000/ 3520]
loss: 0.006224  [ 2100/ 3520]
loss: 0.005088  [ 2200/ 3520]
loss: 0.056107  [ 2300/ 3520]
loss: 0.010338  [ 2400/ 3520]
loss: 0.009274  [ 2500/ 3520]
loss: 0.010396  [ 2600/ 3520]
loss: 0.003275  [ 2700/ 3520]
loss: 0.015798  [ 2800/ 3520]
loss: 0.003206  [ 2900/ 3520]
loss: 0.011372  [ 3000/ 3520]
loss: 0.004340  [ 3100/ 3520]
loss: 0.006039  [ 3200/ 3520]
loss: 0.003749  [ 3300/ 3520]
loss: 0.009696  [ 3400/ 3520]
loss: 0.010043  [ 3500/ 3520]
Epoch 5
-------------------------------
loss: 0.011973  [    0/ 3520]
loss: 0.002374  [  100/ 3520]
loss: 0.098101  [  200/ 3520]
loss: 0.004559  [  300/ 3520]
loss: 0.054535  [  400/ 3520]
loss: 0.069053  [  500/ 3520]
loss: 0.004100  [  600/ 3520]
loss: 0.009346  [  700/ 3520]
loss: 0.005207  [  800/ 3520]
loss: 0.002615  [  900/ 3520]
loss: 0.003181  [ 1000/ 3520]
loss: 0.008212  [ 1100/ 3520]
loss: 0.009224  [ 1200/ 3520]
loss: 0.005177  [ 1300/ 3520]
loss: 0.005016  [ 1400/ 3520]
loss: 0.002679  [ 1500/ 3520]
loss: 0.002496  [ 1600/ 3520]
loss: 0.004562  [ 1700/ 3520]
loss: 0.097085  [ 1800/ 3520]
loss: 0.006588  [ 1900/ 3520]
loss: 0.014944  [ 2000/ 3520]
loss: 0.005768  [ 2100/ 3520]
loss: 0.005197  [ 2200/ 3520]
loss: 0.052665  [ 2300/ 3520]
loss: 0.010665  [ 2400/ 3520]
loss: 0.009512  [ 2500/ 3520]
loss: 0.009495  [ 2600/ 3520]
loss: 0.003266  [ 2700/ 3520]
loss: 0.014908  [ 2800/ 3520]
loss: 0.002972  [ 2900/ 3520]
loss: 0.011051  [ 3000/ 3520]
loss: 0.005338  [ 3100/ 3520]
loss: 0.006238  [ 3200/ 3520]
loss: 0.003369  [ 3300/ 3520]
loss: 0.011088  [ 3400/ 3520]
loss: 0.008977  [ 3500/ 3520]
Epoch 6
-------------------------------
loss: 0.011757  [    0/ 3520]
loss: 0.002205  [  100/ 3520]
loss: 0.093328  [  200/ 3520]
loss: 0.004183  [  300/ 3520]
loss: 0.052338  [  400/ 3520]
loss: 0.067563  [  500/ 3520]
loss: 0.003506  [  600/ 3520]
loss: 0.009418  [  700/ 3520]
loss: 0.005112  [  800/ 3520]
loss: 0.002833  [  900/ 3520]
loss: 0.003199  [ 1000/ 3520]
loss: 0.008009  [ 1100/ 3520]
loss: 0.009060  [ 1200/ 3520]
loss: 0.004313  [ 1300/ 3520]
loss: 0.004571  [ 1400/ 3520]
loss: 0.002824  [ 1500/ 3520]
loss: 0.002570  [ 1600/ 3520]
loss: 0.004550  [ 1700/ 3520]
loss: 0.099927  [ 1800/ 3520]
loss: 0.006673  [ 1900/ 3520]
loss: 0.015111  [ 2000/ 3520]
loss: 0.005735  [ 2100/ 3520]
loss: 0.005274  [ 2200/ 3520]
loss: 0.052820  [ 2300/ 3520]
loss: 0.010360  [ 2400/ 3520]
loss: 0.009384  [ 2500/ 3520]
loss: 0.009229  [ 2600/ 3520]
loss: 0.003274  [ 2700/ 3520]
loss: 0.015097  [ 2800/ 3520]
loss: 0.003035  [ 2900/ 3520]
loss: 0.010719  [ 3000/ 3520]
loss: 0.005773  [ 3100/ 3520]
loss: 0.006227  [ 3200/ 3520]
loss: 0.003203  [ 3300/ 3520]
loss: 0.011538  [ 3400/ 3520]
loss: 0.008940  [ 3500/ 3520]
Epoch 7
-------------------------------
loss: 0.011691  [    0/ 3520]
loss: 0.002226  [  100/ 3520]
loss: 0.089684  [  200/ 3520]
loss: 0.004089  [  300/ 3520]
loss: 0.052295  [  400/ 3520]
loss: 0.067306  [  500/ 3520]
loss: 0.003418  [  600/ 3520]
loss: 0.009301  [  700/ 3520]
loss: 0.005128  [  800/ 3520]
loss: 0.002817  [  900/ 3520]
loss: 0.003243  [ 1000/ 3520]
loss: 0.007887  [ 1100/ 3520]
loss: 0.008896  [ 1200/ 3520]
loss: 0.003618  [ 1300/ 3520]
loss: 0.004205  [ 1400/ 3520]
loss: 0.002784  [ 1500/ 3520]
loss: 0.002419  [ 1600/ 3520]
loss: 0.004609  [ 1700/ 3520]
loss: 0.098619  [ 1800/ 3520]
loss: 0.006801  [ 1900/ 3520]
loss: 0.014793  [ 2000/ 3520]
loss: 0.005826  [ 2100/ 3520]
loss: 0.005325  [ 2200/ 3520]
loss: 0.053122  [ 2300/ 3520]
loss: 0.010402  [ 2400/ 3520]
loss: 0.009211  [ 2500/ 3520]
loss: 0.009013  [ 2600/ 3520]
loss: 0.003236  [ 2700/ 3520]
loss: 0.015275  [ 2800/ 3520]
loss: 0.003074  [ 2900/ 3520]
loss: 0.010537  [ 3000/ 3520]
loss: 0.005816  [ 3100/ 3520]
loss: 0.006174  [ 3200/ 3520]
loss: 0.003078  [ 3300/ 3520]
loss: 0.011353  [ 3400/ 3520]
loss: 0.008920  [ 3500/ 3520]
Epoch 8
-------------------------------
loss: 0.011811  [    0/ 3520]
loss: 0.002178  [  100/ 3520]
loss: 0.089612  [  200/ 3520]
loss: 0.004065  [  300/ 3520]
loss: 0.052089  [  400/ 3520]
loss: 0.065949  [  500/ 3520]
loss: 0.003338  [  600/ 3520]
loss: 0.009235  [  700/ 3520]
loss: 0.005131  [  800/ 3520]
loss: 0.002939  [  900/ 3520]
loss: 0.003333  [ 1000/ 3520]
loss: 0.007827  [ 1100/ 3520]
loss: 0.008820  [ 1200/ 3520]
loss: 0.003778  [ 1300/ 3520]
loss: 0.003951  [ 1400/ 3520]
loss: 0.002726  [ 1500/ 3520]
loss: 0.002433  [ 1600/ 3520]
loss: 0.004647  [ 1700/ 3520]
loss: 0.097752  [ 1800/ 3520]
loss: 0.006840  [ 1900/ 3520]
loss: 0.014967  [ 2000/ 3520]
loss: 0.005622  [ 2100/ 3520]
loss: 0.005474  [ 2200/ 3520]
loss: 0.053718  [ 2300/ 3520]
loss: 0.010536  [ 2400/ 3520]
loss: 0.009339  [ 2500/ 3520]
loss: 0.008991  [ 2600/ 3520]
loss: 0.003208  [ 2700/ 3520]
loss: 0.015367  [ 2800/ 3520]
loss: 0.003123  [ 2900/ 3520]
loss: 0.010448  [ 3000/ 3520]
loss: 0.005945  [ 3100/ 3520]
loss: 0.006162  [ 3200/ 3520]
loss: 0.002989  [ 3300/ 3520]
loss: 0.011528  [ 3400/ 3520]
loss: 0.009068  [ 3500/ 3520]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3520
First Spike after testing: [ 1.0886846 -0.9675824]
[0 1 2 ... 0 1 2]
[1 2 0 ... 1 2 0]
Cluster 0 Occurrences: 1160; KMEANS: 1214
Cluster 1 Occurrences: 1146; KMEANS: 1212
Cluster 2 Occurrences: 1214; KMEANS: 1094
Centroids: [[1.4612778, -1.0011493], [0.36549634, -0.17210306], [-1.0787274, -0.20922497]]
Centroids: [[-1.0803262, -0.20930958], [1.4682095, -0.99292004], [0.30750656, -0.14172003]]
Contingency Matrix: 
[[   0 1155    5]
 [   4   56 1086]
 [1210    1    3]]
[[-1, 1155, 5], [-1, 56, 1086], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1086], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1155    5    0]
 [  56 1086    4]
 [   1    3 1210]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1155, 1086, 1210], Sum: 3451
All_Elements: [1155, 5, 0, 56, 1086, 4, 1, 3, 1210], Sum: 3520
Accuracy: 0.9803977272727272
Done!
