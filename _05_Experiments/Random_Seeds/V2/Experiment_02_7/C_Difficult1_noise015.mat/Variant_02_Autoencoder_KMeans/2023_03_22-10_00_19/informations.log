Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Difficult1_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_00_19
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017468DBEC50>
Sampling rate: 24000.0
Raw: [ 0.04887081  0.02693095 -0.0154249  ... -0.09301659 -0.11629005
 -0.14613101]
Times: [    340     491     641 ... 1439047 1439065 1439816]
Cluster: [1 1 1 ... 3 2 2]
Number of different clusters:  3
Number of Spikes: 3472
First aligned Spike Frame: [ 0.12751554  0.12305882  0.10482977  0.09479529  0.10214978  0.11675932
  0.11777927  0.09307299  0.04670706 -0.00574343 -0.06143573 -0.14637617
 -0.20942665 -0.00208103  0.52241508  0.81651544  0.46446121 -0.19226425
 -0.60927882 -0.6713583  -0.57871227 -0.49011309 -0.4269388  -0.3668903
 -0.30523219 -0.24747124 -0.19738203 -0.15189972 -0.10449507 -0.05533325
 -0.01452429  0.01008816  0.02570853  0.04365027  0.06334113  0.07980397
  0.08484457  0.07688513  0.06142919  0.04320028  0.02240626  0.00477291
 -0.00393242 -0.00135684  0.00575182  0.0026944  -0.01541647]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1172
Cluster 2, Occurrences: 1141
<torch.utils.data.dataloader.DataLoader object at 0x00000174870F2CC0>
Epoch 1
-------------------------------
loss: 0.122573  [    0/ 3472]
loss: 0.086242  [  100/ 3472]
loss: 0.012693  [  200/ 3472]
loss: 0.024709  [  300/ 3472]
loss: 0.032950  [  400/ 3472]
loss: 0.016311  [  500/ 3472]
loss: 0.026194  [  600/ 3472]
loss: 0.013427  [  700/ 3472]
loss: 0.037675  [  800/ 3472]
loss: 0.026265  [  900/ 3472]
loss: 0.013087  [ 1000/ 3472]
loss: 0.029216  [ 1100/ 3472]
loss: 0.025148  [ 1200/ 3472]
loss: 0.024670  [ 1300/ 3472]
loss: 0.004127  [ 1400/ 3472]
loss: 0.040522  [ 1500/ 3472]
loss: 0.022784  [ 1600/ 3472]
loss: 0.012054  [ 1700/ 3472]
loss: 0.037568  [ 1800/ 3472]
loss: 0.170110  [ 1900/ 3472]
loss: 0.038856  [ 2000/ 3472]
loss: 0.017240  [ 2100/ 3472]
loss: 0.010884  [ 2200/ 3472]
loss: 0.016406  [ 2300/ 3472]
loss: 0.036264  [ 2400/ 3472]
loss: 0.010346  [ 2500/ 3472]
loss: 0.015295  [ 2600/ 3472]
loss: 0.012083  [ 2700/ 3472]
loss: 0.026294  [ 2800/ 3472]
loss: 0.032840  [ 2900/ 3472]
loss: 0.007791  [ 3000/ 3472]
loss: 0.022948  [ 3100/ 3472]
loss: 0.013514  [ 3200/ 3472]
loss: 0.012576  [ 3300/ 3472]
loss: 0.010622  [ 3400/ 3472]
Epoch 2
-------------------------------
loss: 0.009149  [    0/ 3472]
loss: 0.006555  [  100/ 3472]
loss: 0.010091  [  200/ 3472]
loss: 0.018318  [  300/ 3472]
loss: 0.007570  [  400/ 3472]
loss: 0.015079  [  500/ 3472]
loss: 0.012462  [  600/ 3472]
loss: 0.005273  [  700/ 3472]
loss: 0.036837  [  800/ 3472]
loss: 0.028204  [  900/ 3472]
loss: 0.010143  [ 1000/ 3472]
loss: 0.026991  [ 1100/ 3472]
loss: 0.024423  [ 1200/ 3472]
loss: 0.005825  [ 1300/ 3472]
loss: 0.003350  [ 1400/ 3472]
loss: 0.035040  [ 1500/ 3472]
loss: 0.018392  [ 1600/ 3472]
loss: 0.010757  [ 1700/ 3472]
loss: 0.028750  [ 1800/ 3472]
loss: 0.137400  [ 1900/ 3472]
loss: 0.049197  [ 2000/ 3472]
loss: 0.013755  [ 2100/ 3472]
loss: 0.010981  [ 2200/ 3472]
loss: 0.005543  [ 2300/ 3472]
loss: 0.010835  [ 2400/ 3472]
loss: 0.014428  [ 2500/ 3472]
loss: 0.015157  [ 2600/ 3472]
loss: 0.011520  [ 2700/ 3472]
loss: 0.026602  [ 2800/ 3472]
loss: 0.030161  [ 2900/ 3472]
loss: 0.009227  [ 3000/ 3472]
loss: 0.020942  [ 3100/ 3472]
loss: 0.013970  [ 3200/ 3472]
loss: 0.011650  [ 3300/ 3472]
loss: 0.008984  [ 3400/ 3472]
Epoch 3
-------------------------------
loss: 0.008881  [    0/ 3472]
loss: 0.006804  [  100/ 3472]
loss: 0.010880  [  200/ 3472]
loss: 0.017874  [  300/ 3472]
loss: 0.006497  [  400/ 3472]
loss: 0.015253  [  500/ 3472]
loss: 0.012670  [  600/ 3472]
loss: 0.005264  [  700/ 3472]
loss: 0.036161  [  800/ 3472]
loss: 0.028168  [  900/ 3472]
loss: 0.009733  [ 1000/ 3472]
loss: 0.026943  [ 1100/ 3472]
loss: 0.024339  [ 1200/ 3472]
loss: 0.005607  [ 1300/ 3472]
loss: 0.003152  [ 1400/ 3472]
loss: 0.033432  [ 1500/ 3472]
loss: 0.018187  [ 1600/ 3472]
loss: 0.010970  [ 1700/ 3472]
loss: 0.028459  [ 1800/ 3472]
loss: 0.136889  [ 1900/ 3472]
loss: 0.049668  [ 2000/ 3472]
loss: 0.013579  [ 2100/ 3472]
loss: 0.011067  [ 2200/ 3472]
loss: 0.005471  [ 2300/ 3472]
loss: 0.010155  [ 2400/ 3472]
loss: 0.014621  [ 2500/ 3472]
loss: 0.015007  [ 2600/ 3472]
loss: 0.012345  [ 2700/ 3472]
loss: 0.026325  [ 2800/ 3472]
loss: 0.029364  [ 2900/ 3472]
loss: 0.009786  [ 3000/ 3472]
loss: 0.020328  [ 3100/ 3472]
loss: 0.013580  [ 3200/ 3472]
loss: 0.011405  [ 3300/ 3472]
loss: 0.009084  [ 3400/ 3472]
Epoch 4
-------------------------------
loss: 0.008488  [    0/ 3472]
loss: 0.006778  [  100/ 3472]
loss: 0.011058  [  200/ 3472]
loss: 0.017732  [  300/ 3472]
loss: 0.006383  [  400/ 3472]
loss: 0.015066  [  500/ 3472]
loss: 0.013089  [  600/ 3472]
loss: 0.004963  [  700/ 3472]
loss: 0.036052  [  800/ 3472]
loss: 0.028726  [  900/ 3472]
loss: 0.009158  [ 1000/ 3472]
loss: 0.027095  [ 1100/ 3472]
loss: 0.023803  [ 1200/ 3472]
loss: 0.005087  [ 1300/ 3472]
loss: 0.003079  [ 1400/ 3472]
loss: 0.032133  [ 1500/ 3472]
loss: 0.017465  [ 1600/ 3472]
loss: 0.011164  [ 1700/ 3472]
loss: 0.027913  [ 1800/ 3472]
loss: 0.137339  [ 1900/ 3472]
loss: 0.049619  [ 2000/ 3472]
loss: 0.013385  [ 2100/ 3472]
loss: 0.011197  [ 2200/ 3472]
loss: 0.005488  [ 2300/ 3472]
loss: 0.009971  [ 2400/ 3472]
loss: 0.014640  [ 2500/ 3472]
loss: 0.014727  [ 2600/ 3472]
loss: 0.012504  [ 2700/ 3472]
loss: 0.025782  [ 2800/ 3472]
loss: 0.029017  [ 2900/ 3472]
loss: 0.010112  [ 3000/ 3472]
loss: 0.019197  [ 3100/ 3472]
loss: 0.013455  [ 3200/ 3472]
loss: 0.009238  [ 3300/ 3472]
loss: 0.009293  [ 3400/ 3472]
Epoch 5
-------------------------------
loss: 0.007945  [    0/ 3472]
loss: 0.006585  [  100/ 3472]
loss: 0.011058  [  200/ 3472]
loss: 0.017853  [  300/ 3472]
loss: 0.006234  [  400/ 3472]
loss: 0.014764  [  500/ 3472]
loss: 0.013583  [  600/ 3472]
loss: 0.004754  [  700/ 3472]
loss: 0.035460  [  800/ 3472]
loss: 0.028831  [  900/ 3472]
loss: 0.008728  [ 1000/ 3472]
loss: 0.026933  [ 1100/ 3472]
loss: 0.023229  [ 1200/ 3472]
loss: 0.004570  [ 1300/ 3472]
loss: 0.002976  [ 1400/ 3472]
loss: 0.030892  [ 1500/ 3472]
loss: 0.016876  [ 1600/ 3472]
loss: 0.011447  [ 1700/ 3472]
loss: 0.027255  [ 1800/ 3472]
loss: 0.138564  [ 1900/ 3472]
loss: 0.049368  [ 2000/ 3472]
loss: 0.013194  [ 2100/ 3472]
loss: 0.011474  [ 2200/ 3472]
loss: 0.005764  [ 2300/ 3472]
loss: 0.010215  [ 2400/ 3472]
loss: 0.014534  [ 2500/ 3472]
loss: 0.013808  [ 2600/ 3472]
loss: 0.012936  [ 2700/ 3472]
loss: 0.025110  [ 2800/ 3472]
loss: 0.028055  [ 2900/ 3472]
loss: 0.010448  [ 3000/ 3472]
loss: 0.016910  [ 3100/ 3472]
loss: 0.013315  [ 3200/ 3472]
loss: 0.008946  [ 3300/ 3472]
loss: 0.009677  [ 3400/ 3472]
Epoch 6
-------------------------------
loss: 0.007404  [    0/ 3472]
loss: 0.006673  [  100/ 3472]
loss: 0.010936  [  200/ 3472]
loss: 0.018219  [  300/ 3472]
loss: 0.005790  [  400/ 3472]
loss: 0.014476  [  500/ 3472]
loss: 0.014305  [  600/ 3472]
loss: 0.004321  [  700/ 3472]
loss: 0.034715  [  800/ 3472]
loss: 0.028719  [  900/ 3472]
loss: 0.008085  [ 1000/ 3472]
loss: 0.026034  [ 1100/ 3472]
loss: 0.022066  [ 1200/ 3472]
loss: 0.004025  [ 1300/ 3472]
loss: 0.002865  [ 1400/ 3472]
loss: 0.027271  [ 1500/ 3472]
loss: 0.015904  [ 1600/ 3472]
loss: 0.011796  [ 1700/ 3472]
loss: 0.026440  [ 1800/ 3472]
loss: 0.140164  [ 1900/ 3472]
loss: 0.049437  [ 2000/ 3472]
loss: 0.012982  [ 2100/ 3472]
loss: 0.011613  [ 2200/ 3472]
loss: 0.006242  [ 2300/ 3472]
loss: 0.009501  [ 2400/ 3472]
loss: 0.014687  [ 2500/ 3472]
loss: 0.012511  [ 2600/ 3472]
loss: 0.013320  [ 2700/ 3472]
loss: 0.024131  [ 2800/ 3472]
loss: 0.027228  [ 2900/ 3472]
loss: 0.010559  [ 3000/ 3472]
loss: 0.015079  [ 3100/ 3472]
loss: 0.013224  [ 3200/ 3472]
loss: 0.008549  [ 3300/ 3472]
loss: 0.010010  [ 3400/ 3472]
Epoch 7
-------------------------------
loss: 0.006813  [    0/ 3472]
loss: 0.006680  [  100/ 3472]
loss: 0.011225  [  200/ 3472]
loss: 0.018305  [  300/ 3472]
loss: 0.005191  [  400/ 3472]
loss: 0.014297  [  500/ 3472]
loss: 0.014555  [  600/ 3472]
loss: 0.003920  [  700/ 3472]
loss: 0.034033  [  800/ 3472]
loss: 0.028011  [  900/ 3472]
loss: 0.007897  [ 1000/ 3472]
loss: 0.023403  [ 1100/ 3472]
loss: 0.020016  [ 1200/ 3472]
loss: 0.003692  [ 1300/ 3472]
loss: 0.002769  [ 1400/ 3472]
loss: 0.023602  [ 1500/ 3472]
loss: 0.015022  [ 1600/ 3472]
loss: 0.011611  [ 1700/ 3472]
loss: 0.025190  [ 1800/ 3472]
loss: 0.141099  [ 1900/ 3472]
loss: 0.048868  [ 2000/ 3472]
loss: 0.012455  [ 2100/ 3472]
loss: 0.011745  [ 2200/ 3472]
loss: 0.006607  [ 2300/ 3472]
loss: 0.008063  [ 2400/ 3472]
loss: 0.015097  [ 2500/ 3472]
loss: 0.011686  [ 2600/ 3472]
loss: 0.013543  [ 2700/ 3472]
loss: 0.022761  [ 2800/ 3472]
loss: 0.026262  [ 2900/ 3472]
loss: 0.011486  [ 3000/ 3472]
loss: 0.013507  [ 3100/ 3472]
loss: 0.013184  [ 3200/ 3472]
loss: 0.007793  [ 3300/ 3472]
loss: 0.009743  [ 3400/ 3472]
Epoch 8
-------------------------------
loss: 0.006078  [    0/ 3472]
loss: 0.006731  [  100/ 3472]
loss: 0.011321  [  200/ 3472]
loss: 0.018238  [  300/ 3472]
loss: 0.004998  [  400/ 3472]
loss: 0.014285  [  500/ 3472]
loss: 0.015142  [  600/ 3472]
loss: 0.003568  [  700/ 3472]
loss: 0.033466  [  800/ 3472]
loss: 0.028157  [  900/ 3472]
loss: 0.007922  [ 1000/ 3472]
loss: 0.022714  [ 1100/ 3472]
loss: 0.019314  [ 1200/ 3472]
loss: 0.004182  [ 1300/ 3472]
loss: 0.002654  [ 1400/ 3472]
loss: 0.021421  [ 1500/ 3472]
loss: 0.014326  [ 1600/ 3472]
loss: 0.011617  [ 1700/ 3472]
loss: 0.023937  [ 1800/ 3472]
loss: 0.141612  [ 1900/ 3472]
loss: 0.048111  [ 2000/ 3472]
loss: 0.012041  [ 2100/ 3472]
loss: 0.011738  [ 2200/ 3472]
loss: 0.007052  [ 2300/ 3472]
loss: 0.007573  [ 2400/ 3472]
loss: 0.015161  [ 2500/ 3472]
loss: 0.010577  [ 2600/ 3472]
loss: 0.013642  [ 2700/ 3472]
loss: 0.021666  [ 2800/ 3472]
loss: 0.025309  [ 2900/ 3472]
loss: 0.011733  [ 3000/ 3472]
loss: 0.012414  [ 3100/ 3472]
loss: 0.013050  [ 3200/ 3472]
loss: 0.007550  [ 3300/ 3472]
loss: 0.009604  [ 3400/ 3472]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3472
First Spike after testing: [-0.56973183 -0.24040325]
[0 0 0 ... 2 1 1]
[2 2 2 ... 1 2 0]
Cluster 0 Occurrences: 1159; KMEANS: 1207
Cluster 1 Occurrences: 1172; KMEANS: 864
Cluster 2 Occurrences: 1141; KMEANS: 1401
Centroids: [[-0.2994643, -0.13098158], [0.31365192, -0.1649208], [0.2977351, 0.34604618]]
Centroids: [[0.21698894, -0.25665182], [0.6298559, 0.36799482], [-0.31824732, 0.029675331]]
Contingency Matrix: 
[[219  36 904]
 [863 185 124]
 [125 643 373]]
[[-1, -1, -1], [863, 185, -1], [125, 643, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, 643, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 1: 0, 2: 1}
New Contingency Matrix: 
[[904 219  36]
 [124 863 185]
 [373 125 643]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [904, 863, 643], Sum: 2410
All_Elements: [904, 219, 36, 124, 863, 185, 373, 125, 643], Sum: 3472
Accuracy: 0.6941244239631337
Done!
