Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Difficult1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_58_29
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017484582898>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
<torch.utils.data.dataloader.DataLoader object at 0x00000174870F2588>
Epoch 1
-------------------------------
loss: 0.182897  [    0/ 3448]
loss: 0.035531  [  100/ 3448]
loss: 0.021600  [  200/ 3448]
loss: 0.026956  [  300/ 3448]
loss: 0.024068  [  400/ 3448]
loss: 0.014501  [  500/ 3448]
loss: 0.014052  [  600/ 3448]
loss: 0.009699  [  700/ 3448]
loss: 0.009365  [  800/ 3448]
loss: 0.017370  [  900/ 3448]
loss: 0.092343  [ 1000/ 3448]
loss: 0.014275  [ 1100/ 3448]
loss: 0.011968  [ 1200/ 3448]
loss: 0.127379  [ 1300/ 3448]
loss: 0.008843  [ 1400/ 3448]
loss: 0.024820  [ 1500/ 3448]
loss: 0.018216  [ 1600/ 3448]
loss: 0.013577  [ 1700/ 3448]
loss: 0.011377  [ 1800/ 3448]
loss: 0.018379  [ 1900/ 3448]
loss: 0.008297  [ 2000/ 3448]
loss: 0.004390  [ 2100/ 3448]
loss: 0.014245  [ 2200/ 3448]
loss: 0.008128  [ 2300/ 3448]
loss: 0.023799  [ 2400/ 3448]
loss: 0.007158  [ 2500/ 3448]
loss: 0.011828  [ 2600/ 3448]
loss: 0.017603  [ 2700/ 3448]
loss: 0.007455  [ 2800/ 3448]
loss: 0.010501  [ 2900/ 3448]
loss: 0.004240  [ 3000/ 3448]
loss: 0.017794  [ 3100/ 3448]
loss: 0.015036  [ 3200/ 3448]
loss: 0.013435  [ 3300/ 3448]
loss: 0.007736  [ 3400/ 3448]
Epoch 2
-------------------------------
loss: 0.019121  [    0/ 3448]
loss: 0.008956  [  100/ 3448]
loss: 0.004691  [  200/ 3448]
loss: 0.006635  [  300/ 3448]
loss: 0.012126  [  400/ 3448]
loss: 0.015336  [  500/ 3448]
loss: 0.006726  [  600/ 3448]
loss: 0.009926  [  700/ 3448]
loss: 0.003814  [  800/ 3448]
loss: 0.006799  [  900/ 3448]
loss: 0.083127  [ 1000/ 3448]
loss: 0.012515  [ 1100/ 3448]
loss: 0.011110  [ 1200/ 3448]
loss: 0.123761  [ 1300/ 3448]
loss: 0.007588  [ 1400/ 3448]
loss: 0.016749  [ 1500/ 3448]
loss: 0.007772  [ 1600/ 3448]
loss: 0.012030  [ 1700/ 3448]
loss: 0.009421  [ 1800/ 3448]
loss: 0.017314  [ 1900/ 3448]
loss: 0.007348  [ 2000/ 3448]
loss: 0.003843  [ 2100/ 3448]
loss: 0.007194  [ 2200/ 3448]
loss: 0.006073  [ 2300/ 3448]
loss: 0.009378  [ 2400/ 3448]
loss: 0.007197  [ 2500/ 3448]
loss: 0.012511  [ 2600/ 3448]
loss: 0.007843  [ 2700/ 3448]
loss: 0.007271  [ 2800/ 3448]
loss: 0.002876  [ 2900/ 3448]
loss: 0.004144  [ 3000/ 3448]
loss: 0.015428  [ 3100/ 3448]
loss: 0.012955  [ 3200/ 3448]
loss: 0.010253  [ 3300/ 3448]
loss: 0.006794  [ 3400/ 3448]
Epoch 3
-------------------------------
loss: 0.021029  [    0/ 3448]
loss: 0.007851  [  100/ 3448]
loss: 0.001964  [  200/ 3448]
loss: 0.002961  [  300/ 3448]
loss: 0.006324  [  400/ 3448]
loss: 0.013859  [  500/ 3448]
loss: 0.005853  [  600/ 3448]
loss: 0.008597  [  700/ 3448]
loss: 0.003541  [  800/ 3448]
loss: 0.005565  [  900/ 3448]
loss: 0.083535  [ 1000/ 3448]
loss: 0.014295  [ 1100/ 3448]
loss: 0.008956  [ 1200/ 3448]
loss: 0.124984  [ 1300/ 3448]
loss: 0.006659  [ 1400/ 3448]
loss: 0.020789  [ 1500/ 3448]
loss: 0.004581  [ 1600/ 3448]
loss: 0.011330  [ 1700/ 3448]
loss: 0.007224  [ 1800/ 3448]
loss: 0.017504  [ 1900/ 3448]
loss: 0.007675  [ 2000/ 3448]
loss: 0.003470  [ 2100/ 3448]
loss: 0.005899  [ 2200/ 3448]
loss: 0.005829  [ 2300/ 3448]
loss: 0.006882  [ 2400/ 3448]
loss: 0.008147  [ 2500/ 3448]
loss: 0.012619  [ 2600/ 3448]
loss: 0.008973  [ 2700/ 3448]
loss: 0.006938  [ 2800/ 3448]
loss: 0.002298  [ 2900/ 3448]
loss: 0.004225  [ 3000/ 3448]
loss: 0.013976  [ 3100/ 3448]
loss: 0.013637  [ 3200/ 3448]
loss: 0.010608  [ 3300/ 3448]
loss: 0.006616  [ 3400/ 3448]
Epoch 4
-------------------------------
loss: 0.019959  [    0/ 3448]
loss: 0.007353  [  100/ 3448]
loss: 0.002508  [  200/ 3448]
loss: 0.003844  [  300/ 3448]
loss: 0.005887  [  400/ 3448]
loss: 0.013629  [  500/ 3448]
loss: 0.006484  [  600/ 3448]
loss: 0.007985  [  700/ 3448]
loss: 0.003911  [  800/ 3448]
loss: 0.005807  [  900/ 3448]
loss: 0.084152  [ 1000/ 3448]
loss: 0.013980  [ 1100/ 3448]
loss: 0.008801  [ 1200/ 3448]
loss: 0.124590  [ 1300/ 3448]
loss: 0.006453  [ 1400/ 3448]
loss: 0.022217  [ 1500/ 3448]
loss: 0.004030  [ 1600/ 3448]
loss: 0.010925  [ 1700/ 3448]
loss: 0.006873  [ 1800/ 3448]
loss: 0.017615  [ 1900/ 3448]
loss: 0.007647  [ 2000/ 3448]
loss: 0.003296  [ 2100/ 3448]
loss: 0.005704  [ 2200/ 3448]
loss: 0.005977  [ 2300/ 3448]
loss: 0.005529  [ 2400/ 3448]
loss: 0.008467  [ 2500/ 3448]
loss: 0.012314  [ 2600/ 3448]
loss: 0.009526  [ 2700/ 3448]
loss: 0.007047  [ 2800/ 3448]
loss: 0.002280  [ 2900/ 3448]
loss: 0.004149  [ 3000/ 3448]
loss: 0.013499  [ 3100/ 3448]
loss: 0.013936  [ 3200/ 3448]
loss: 0.010789  [ 3300/ 3448]
loss: 0.006341  [ 3400/ 3448]
Epoch 5
-------------------------------
loss: 0.019665  [    0/ 3448]
loss: 0.007183  [  100/ 3448]
loss: 0.003202  [  200/ 3448]
loss: 0.004049  [  300/ 3448]
loss: 0.005362  [  400/ 3448]
loss: 0.013530  [  500/ 3448]
loss: 0.006871  [  600/ 3448]
loss: 0.007868  [  700/ 3448]
loss: 0.004232  [  800/ 3448]
loss: 0.005891  [  900/ 3448]
loss: 0.084888  [ 1000/ 3448]
loss: 0.013881  [ 1100/ 3448]
loss: 0.008618  [ 1200/ 3448]
loss: 0.124799  [ 1300/ 3448]
loss: 0.006630  [ 1400/ 3448]
loss: 0.022855  [ 1500/ 3448]
loss: 0.003824  [ 1600/ 3448]
loss: 0.010571  [ 1700/ 3448]
loss: 0.006743  [ 1800/ 3448]
loss: 0.017690  [ 1900/ 3448]
loss: 0.007448  [ 2000/ 3448]
loss: 0.003167  [ 2100/ 3448]
loss: 0.005581  [ 2200/ 3448]
loss: 0.006215  [ 2300/ 3448]
loss: 0.005400  [ 2400/ 3448]
loss: 0.008753  [ 2500/ 3448]
loss: 0.011989  [ 2600/ 3448]
loss: 0.009549  [ 2700/ 3448]
loss: 0.007032  [ 2800/ 3448]
loss: 0.002192  [ 2900/ 3448]
loss: 0.004186  [ 3000/ 3448]
loss: 0.013563  [ 3100/ 3448]
loss: 0.013736  [ 3200/ 3448]
loss: 0.010919  [ 3300/ 3448]
loss: 0.006131  [ 3400/ 3448]
Epoch 6
-------------------------------
loss: 0.019662  [    0/ 3448]
loss: 0.007368  [  100/ 3448]
loss: 0.003883  [  200/ 3448]
loss: 0.004720  [  300/ 3448]
loss: 0.005498  [  400/ 3448]
loss: 0.013351  [  500/ 3448]
loss: 0.007163  [  600/ 3448]
loss: 0.008151  [  700/ 3448]
loss: 0.004425  [  800/ 3448]
loss: 0.005760  [  900/ 3448]
loss: 0.084741  [ 1000/ 3448]
loss: 0.014279  [ 1100/ 3448]
loss: 0.008494  [ 1200/ 3448]
loss: 0.124608  [ 1300/ 3448]
loss: 0.006498  [ 1400/ 3448]
loss: 0.023499  [ 1500/ 3448]
loss: 0.004284  [ 1600/ 3448]
loss: 0.010350  [ 1700/ 3448]
loss: 0.006797  [ 1800/ 3448]
loss: 0.017657  [ 1900/ 3448]
loss: 0.007155  [ 2000/ 3448]
loss: 0.002986  [ 2100/ 3448]
loss: 0.005074  [ 2200/ 3448]
loss: 0.006419  [ 2300/ 3448]
loss: 0.005910  [ 2400/ 3448]
loss: 0.009114  [ 2500/ 3448]
loss: 0.011605  [ 2600/ 3448]
loss: 0.009617  [ 2700/ 3448]
loss: 0.007083  [ 2800/ 3448]
loss: 0.002025  [ 2900/ 3448]
loss: 0.004353  [ 3000/ 3448]
loss: 0.014143  [ 3100/ 3448]
loss: 0.013118  [ 3200/ 3448]
loss: 0.010948  [ 3300/ 3448]
loss: 0.006247  [ 3400/ 3448]
Epoch 7
-------------------------------
loss: 0.019884  [    0/ 3448]
loss: 0.007909  [  100/ 3448]
loss: 0.004817  [  200/ 3448]
loss: 0.004619  [  300/ 3448]
loss: 0.005697  [  400/ 3448]
loss: 0.013086  [  500/ 3448]
loss: 0.007299  [  600/ 3448]
loss: 0.007682  [  700/ 3448]
loss: 0.004639  [  800/ 3448]
loss: 0.005526  [  900/ 3448]
loss: 0.083666  [ 1000/ 3448]
loss: 0.014443  [ 1100/ 3448]
loss: 0.008122  [ 1200/ 3448]
loss: 0.124304  [ 1300/ 3448]
loss: 0.006302  [ 1400/ 3448]
loss: 0.023929  [ 1500/ 3448]
loss: 0.005485  [ 1600/ 3448]
loss: 0.009379  [ 1700/ 3448]
loss: 0.007029  [ 1800/ 3448]
loss: 0.017485  [ 1900/ 3448]
loss: 0.006748  [ 2000/ 3448]
loss: 0.002684  [ 2100/ 3448]
loss: 0.004744  [ 2200/ 3448]
loss: 0.006293  [ 2300/ 3448]
loss: 0.006631  [ 2400/ 3448]
loss: 0.009620  [ 2500/ 3448]
loss: 0.011279  [ 2600/ 3448]
loss: 0.009818  [ 2700/ 3448]
loss: 0.006943  [ 2800/ 3448]
loss: 0.001838  [ 2900/ 3448]
loss: 0.004592  [ 3000/ 3448]
loss: 0.014279  [ 3100/ 3448]
loss: 0.012295  [ 3200/ 3448]
loss: 0.011104  [ 3300/ 3448]
loss: 0.006266  [ 3400/ 3448]
Epoch 8
-------------------------------
loss: 0.020601  [    0/ 3448]
loss: 0.008027  [  100/ 3448]
loss: 0.006322  [  200/ 3448]
loss: 0.003778  [  300/ 3448]
loss: 0.005029  [  400/ 3448]
loss: 0.012748  [  500/ 3448]
loss: 0.006264  [  600/ 3448]
loss: 0.006631  [  700/ 3448]
loss: 0.005398  [  800/ 3448]
loss: 0.004718  [  900/ 3448]
loss: 0.082158  [ 1000/ 3448]
loss: 0.014455  [ 1100/ 3448]
loss: 0.007341  [ 1200/ 3448]
loss: 0.124594  [ 1300/ 3448]
loss: 0.005875  [ 1400/ 3448]
loss: 0.023247  [ 1500/ 3448]
loss: 0.006133  [ 1600/ 3448]
loss: 0.008877  [ 1700/ 3448]
loss: 0.007649  [ 1800/ 3448]
loss: 0.017673  [ 1900/ 3448]
loss: 0.006636  [ 2000/ 3448]
loss: 0.002176  [ 2100/ 3448]
loss: 0.004355  [ 2200/ 3448]
loss: 0.006308  [ 2300/ 3448]
loss: 0.007427  [ 2400/ 3448]
loss: 0.010678  [ 2500/ 3448]
loss: 0.010660  [ 2600/ 3448]
loss: 0.009472  [ 2700/ 3448]
loss: 0.006609  [ 2800/ 3448]
loss: 0.001526  [ 2900/ 3448]
loss: 0.004732  [ 3000/ 3448]
loss: 0.013873  [ 3100/ 3448]
loss: 0.011600  [ 3200/ 3448]
loss: 0.011062  [ 3300/ 3448]
loss: 0.006018  [ 3400/ 3448]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3448
First Spike after testing: [0.0285871 0.2285717]
[2 2 2 ... 1 0 2]
[0 0 0 ... 2 1 0]
Cluster 0 Occurrences: 1164; KMEANS: 1106
Cluster 1 Occurrences: 1155; KMEANS: 1282
Cluster 2 Occurrences: 1129; KMEANS: 1060
Centroids: [[-0.36165404, 0.08523163], [0.33756548, -0.17194332], [0.23212826, 0.44139585]]
Centroids: [[0.254681, 0.45290437], [-0.36735457, 0.11191159], [0.39647833, -0.23153955]]
Contingency Matrix: 
[[  29 1112   23]
 [  75   90  990]
 [1002   80   47]]
[[-1, -1, -1], [75, -1, 990], [1002, -1, 47]]
[[-1, -1, -1], [-1, -1, 990], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 1, 2: 0, 1: 2}
New Contingency Matrix: 
[[1112   23   29]
 [  90  990   75]
 [  80   47 1002]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1112, 990, 1002], Sum: 3104
All_Elements: [1112, 23, 29, 90, 990, 75, 80, 47, 1002], Sum: 3448
Accuracy: 0.9002320185614849
Done!
