Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_54_17
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017452CFEC18>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x0000017452F74F98>
Epoch 1
-------------------------------
loss: 0.274833  [    0/ 3411]
loss: 0.100686  [  100/ 3411]
loss: 0.092403  [  200/ 3411]
loss: 0.016276  [  300/ 3411]
loss: 0.039123  [  400/ 3411]
loss: 0.027923  [  500/ 3411]
loss: 0.011274  [  600/ 3411]
loss: 0.024827  [  700/ 3411]
loss: 0.033075  [  800/ 3411]
loss: 0.030039  [  900/ 3411]
loss: 0.004115  [ 1000/ 3411]
loss: 0.043623  [ 1100/ 3411]
loss: 0.022433  [ 1200/ 3411]
loss: 0.020754  [ 1300/ 3411]
loss: 0.027406  [ 1400/ 3411]
loss: 0.059596  [ 1500/ 3411]
loss: 0.039150  [ 1600/ 3411]
loss: 0.036725  [ 1700/ 3411]
loss: 0.022567  [ 1800/ 3411]
loss: 0.004743  [ 1900/ 3411]
loss: 0.039098  [ 2000/ 3411]
loss: 0.009216  [ 2100/ 3411]
loss: 0.008395  [ 2200/ 3411]
loss: 0.150027  [ 2300/ 3411]
loss: 0.015403  [ 2400/ 3411]
loss: 0.003928  [ 2500/ 3411]
loss: 0.018283  [ 2600/ 3411]
loss: 0.008528  [ 2700/ 3411]
loss: 0.029718  [ 2800/ 3411]
loss: 0.013109  [ 2900/ 3411]
loss: 0.004790  [ 3000/ 3411]
loss: 0.005439  [ 3100/ 3411]
loss: 0.022635  [ 3200/ 3411]
loss: 0.012102  [ 3300/ 3411]
loss: 0.010088  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.018559  [    0/ 3411]
loss: 0.016047  [  100/ 3411]
loss: 0.014218  [  200/ 3411]
loss: 0.014265  [  300/ 3411]
loss: 0.022160  [  400/ 3411]
loss: 0.009960  [  500/ 3411]
loss: 0.005288  [  600/ 3411]
loss: 0.022261  [  700/ 3411]
loss: 0.021460  [  800/ 3411]
loss: 0.017421  [  900/ 3411]
loss: 0.004391  [ 1000/ 3411]
loss: 0.018947  [ 1100/ 3411]
loss: 0.019431  [ 1200/ 3411]
loss: 0.013245  [ 1300/ 3411]
loss: 0.021977  [ 1400/ 3411]
loss: 0.056781  [ 1500/ 3411]
loss: 0.029653  [ 1600/ 3411]
loss: 0.022153  [ 1700/ 3411]
loss: 0.018504  [ 1800/ 3411]
loss: 0.004297  [ 1900/ 3411]
loss: 0.034450  [ 2000/ 3411]
loss: 0.009871  [ 2100/ 3411]
loss: 0.007494  [ 2200/ 3411]
loss: 0.147106  [ 2300/ 3411]
loss: 0.018267  [ 2400/ 3411]
loss: 0.005824  [ 2500/ 3411]
loss: 0.014671  [ 2600/ 3411]
loss: 0.007730  [ 2700/ 3411]
loss: 0.026906  [ 2800/ 3411]
loss: 0.010560  [ 2900/ 3411]
loss: 0.006234  [ 3000/ 3411]
loss: 0.005659  [ 3100/ 3411]
loss: 0.023049  [ 3200/ 3411]
loss: 0.012308  [ 3300/ 3411]
loss: 0.009230  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.018216  [    0/ 3411]
loss: 0.015263  [  100/ 3411]
loss: 0.010173  [  200/ 3411]
loss: 0.012859  [  300/ 3411]
loss: 0.031247  [  400/ 3411]
loss: 0.009764  [  500/ 3411]
loss: 0.004707  [  600/ 3411]
loss: 0.011147  [  700/ 3411]
loss: 0.020776  [  800/ 3411]
loss: 0.017413  [  900/ 3411]
loss: 0.003730  [ 1000/ 3411]
loss: 0.009442  [ 1100/ 3411]
loss: 0.019505  [ 1200/ 3411]
loss: 0.013030  [ 1300/ 3411]
loss: 0.019373  [ 1400/ 3411]
loss: 0.058298  [ 1500/ 3411]
loss: 0.023692  [ 1600/ 3411]
loss: 0.016108  [ 1700/ 3411]
loss: 0.016762  [ 1800/ 3411]
loss: 0.004920  [ 1900/ 3411]
loss: 0.031952  [ 2000/ 3411]
loss: 0.009062  [ 2100/ 3411]
loss: 0.007589  [ 2200/ 3411]
loss: 0.147207  [ 2300/ 3411]
loss: 0.018070  [ 2400/ 3411]
loss: 0.006244  [ 2500/ 3411]
loss: 0.011220  [ 2600/ 3411]
loss: 0.007656  [ 2700/ 3411]
loss: 0.026117  [ 2800/ 3411]
loss: 0.010741  [ 2900/ 3411]
loss: 0.008091  [ 3000/ 3411]
loss: 0.005336  [ 3100/ 3411]
loss: 0.022924  [ 3200/ 3411]
loss: 0.012218  [ 3300/ 3411]
loss: 0.008200  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.018513  [    0/ 3411]
loss: 0.014485  [  100/ 3411]
loss: 0.011026  [  200/ 3411]
loss: 0.012849  [  300/ 3411]
loss: 0.031846  [  400/ 3411]
loss: 0.010554  [  500/ 3411]
loss: 0.004360  [  600/ 3411]
loss: 0.009166  [  700/ 3411]
loss: 0.020964  [  800/ 3411]
loss: 0.017889  [  900/ 3411]
loss: 0.003671  [ 1000/ 3411]
loss: 0.005050  [ 1100/ 3411]
loss: 0.019433  [ 1200/ 3411]
loss: 0.013065  [ 1300/ 3411]
loss: 0.018843  [ 1400/ 3411]
loss: 0.061241  [ 1500/ 3411]
loss: 0.021504  [ 1600/ 3411]
loss: 0.014835  [ 1700/ 3411]
loss: 0.014625  [ 1800/ 3411]
loss: 0.005582  [ 1900/ 3411]
loss: 0.031423  [ 2000/ 3411]
loss: 0.008650  [ 2100/ 3411]
loss: 0.007884  [ 2200/ 3411]
loss: 0.149218  [ 2300/ 3411]
loss: 0.017950  [ 2400/ 3411]
loss: 0.006209  [ 2500/ 3411]
loss: 0.009772  [ 2600/ 3411]
loss: 0.007632  [ 2700/ 3411]
loss: 0.026175  [ 2800/ 3411]
loss: 0.010727  [ 2900/ 3411]
loss: 0.009063  [ 3000/ 3411]
loss: 0.005219  [ 3100/ 3411]
loss: 0.022410  [ 3200/ 3411]
loss: 0.012319  [ 3300/ 3411]
loss: 0.007149  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.019107  [    0/ 3411]
loss: 0.014133  [  100/ 3411]
loss: 0.012069  [  200/ 3411]
loss: 0.012625  [  300/ 3411]
loss: 0.031769  [  400/ 3411]
loss: 0.010640  [  500/ 3411]
loss: 0.004133  [  600/ 3411]
loss: 0.008061  [  700/ 3411]
loss: 0.020752  [  800/ 3411]
loss: 0.018052  [  900/ 3411]
loss: 0.003603  [ 1000/ 3411]
loss: 0.004035  [ 1100/ 3411]
loss: 0.019568  [ 1200/ 3411]
loss: 0.013483  [ 1300/ 3411]
loss: 0.019154  [ 1400/ 3411]
loss: 0.064423  [ 1500/ 3411]
loss: 0.020916  [ 1600/ 3411]
loss: 0.014092  [ 1700/ 3411]
loss: 0.013454  [ 1800/ 3411]
loss: 0.006018  [ 1900/ 3411]
loss: 0.031776  [ 2000/ 3411]
loss: 0.008469  [ 2100/ 3411]
loss: 0.008286  [ 2200/ 3411]
loss: 0.150927  [ 2300/ 3411]
loss: 0.017826  [ 2400/ 3411]
loss: 0.006111  [ 2500/ 3411]
loss: 0.008987  [ 2600/ 3411]
loss: 0.007449  [ 2700/ 3411]
loss: 0.026381  [ 2800/ 3411]
loss: 0.010520  [ 2900/ 3411]
loss: 0.009519  [ 3000/ 3411]
loss: 0.005062  [ 3100/ 3411]
loss: 0.021837  [ 3200/ 3411]
loss: 0.012297  [ 3300/ 3411]
loss: 0.006742  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.019480  [    0/ 3411]
loss: 0.014132  [  100/ 3411]
loss: 0.013108  [  200/ 3411]
loss: 0.012460  [  300/ 3411]
loss: 0.031095  [  400/ 3411]
loss: 0.010588  [  500/ 3411]
loss: 0.004018  [  600/ 3411]
loss: 0.007197  [  700/ 3411]
loss: 0.020377  [  800/ 3411]
loss: 0.018755  [  900/ 3411]
loss: 0.003556  [ 1000/ 3411]
loss: 0.004054  [ 1100/ 3411]
loss: 0.019559  [ 1200/ 3411]
loss: 0.013489  [ 1300/ 3411]
loss: 0.019326  [ 1400/ 3411]
loss: 0.066087  [ 1500/ 3411]
loss: 0.020800  [ 1600/ 3411]
loss: 0.013736  [ 1700/ 3411]
loss: 0.012976  [ 1800/ 3411]
loss: 0.006256  [ 1900/ 3411]
loss: 0.032097  [ 2000/ 3411]
loss: 0.008302  [ 2100/ 3411]
loss: 0.008517  [ 2200/ 3411]
loss: 0.152283  [ 2300/ 3411]
loss: 0.017741  [ 2400/ 3411]
loss: 0.006012  [ 2500/ 3411]
loss: 0.008223  [ 2600/ 3411]
loss: 0.007257  [ 2700/ 3411]
loss: 0.026465  [ 2800/ 3411]
loss: 0.010394  [ 2900/ 3411]
loss: 0.010082  [ 3000/ 3411]
loss: 0.005023  [ 3100/ 3411]
loss: 0.021418  [ 3200/ 3411]
loss: 0.012234  [ 3300/ 3411]
loss: 0.006180  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.019746  [    0/ 3411]
loss: 0.013939  [  100/ 3411]
loss: 0.013932  [  200/ 3411]
loss: 0.012300  [  300/ 3411]
loss: 0.030686  [  400/ 3411]
loss: 0.010721  [  500/ 3411]
loss: 0.003951  [  600/ 3411]
loss: 0.007001  [  700/ 3411]
loss: 0.020302  [  800/ 3411]
loss: 0.019060  [  900/ 3411]
loss: 0.003537  [ 1000/ 3411]
loss: 0.004539  [ 1100/ 3411]
loss: 0.019567  [ 1200/ 3411]
loss: 0.013706  [ 1300/ 3411]
loss: 0.019342  [ 1400/ 3411]
loss: 0.067111  [ 1500/ 3411]
loss: 0.020862  [ 1600/ 3411]
loss: 0.013253  [ 1700/ 3411]
loss: 0.012578  [ 1800/ 3411]
loss: 0.006308  [ 1900/ 3411]
loss: 0.032207  [ 2000/ 3411]
loss: 0.008156  [ 2100/ 3411]
loss: 0.008452  [ 2200/ 3411]
loss: 0.153181  [ 2300/ 3411]
loss: 0.017712  [ 2400/ 3411]
loss: 0.006052  [ 2500/ 3411]
loss: 0.007622  [ 2600/ 3411]
loss: 0.007058  [ 2700/ 3411]
loss: 0.026572  [ 2800/ 3411]
loss: 0.010235  [ 2900/ 3411]
loss: 0.010438  [ 3000/ 3411]
loss: 0.004956  [ 3100/ 3411]
loss: 0.021504  [ 3200/ 3411]
loss: 0.012378  [ 3300/ 3411]
loss: 0.005905  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.020012  [    0/ 3411]
loss: 0.013801  [  100/ 3411]
loss: 0.014795  [  200/ 3411]
loss: 0.012269  [  300/ 3411]
loss: 0.030532  [  400/ 3411]
loss: 0.010814  [  500/ 3411]
loss: 0.003859  [  600/ 3411]
loss: 0.005488  [  700/ 3411]
loss: 0.020185  [  800/ 3411]
loss: 0.019215  [  900/ 3411]
loss: 0.003532  [ 1000/ 3411]
loss: 0.005054  [ 1100/ 3411]
loss: 0.019580  [ 1200/ 3411]
loss: 0.013921  [ 1300/ 3411]
loss: 0.019225  [ 1400/ 3411]
loss: 0.068761  [ 1500/ 3411]
loss: 0.020935  [ 1600/ 3411]
loss: 0.013018  [ 1700/ 3411]
loss: 0.012280  [ 1800/ 3411]
loss: 0.006447  [ 1900/ 3411]
loss: 0.032212  [ 2000/ 3411]
loss: 0.007933  [ 2100/ 3411]
loss: 0.008651  [ 2200/ 3411]
loss: 0.153897  [ 2300/ 3411]
loss: 0.017713  [ 2400/ 3411]
loss: 0.005778  [ 2500/ 3411]
loss: 0.007306  [ 2600/ 3411]
loss: 0.006901  [ 2700/ 3411]
loss: 0.026518  [ 2800/ 3411]
loss: 0.010146  [ 2900/ 3411]
loss: 0.010432  [ 3000/ 3411]
loss: 0.004986  [ 3100/ 3411]
loss: 0.021699  [ 3200/ 3411]
loss: 0.012323  [ 3300/ 3411]
loss: 0.005722  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [-1.0104022 -1.5095235]
[0 2 0 ... 1 1 2]
[1 0 2 ... 2 2 0]
Cluster 0 Occurrences: 1181; KMEANS: 1120
Cluster 1 Occurrences: 1098; KMEANS: 1186
Cluster 2 Occurrences: 1132; KMEANS: 1105
Centroids: [[-1.1560061, -1.432658], [-0.5775137, -0.6310139], [1.4726517, 0.9490404]]
Centroids: [[1.4831008, 0.96581346], [-1.2101643, -1.4452397], [-0.50509435, -0.61372435]]
Contingency Matrix: 
[[   0 1089   92]
 [   1   97 1000]
 [1119    0   13]]
[[-1, 1089, 92], [-1, 97, 1000], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1000], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1089   92    0]
 [  97 1000    1]
 [   0   13 1119]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1089, 1000, 1119], Sum: 3208
All_Elements: [1089, 92, 0, 97, 1000, 1, 0, 13, 1119], Sum: 3411
Accuracy: 0.9404866608032835
Done!
