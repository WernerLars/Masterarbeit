Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Easy1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_42_55
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017452F2BAC8>
Sampling rate: 24000.0
Raw: [ 0.01223885  0.0148803   0.02156532 ... -0.02666729 -0.01215068
  0.01031338]
Times: [   1012    1333    1523 ... 1438660 1438690 1439287]
Cluster: [1 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3522
First aligned Spike Frame: [-0.12579972 -0.1620207  -0.18573939 -0.18961714 -0.17315203 -0.1396561
 -0.09426159 -0.04496221  0.00734136  0.05943689  0.09448878  0.07601101
  0.00811529  0.09446653  0.55421698  1.03008495  0.90195967  0.23116337
 -0.37857386 -0.59030761 -0.52695739 -0.40967661 -0.32471334 -0.26000903
 -0.19839489 -0.13975054 -0.09692457 -0.08223204 -0.09147337 -0.10695261
 -0.11338461 -0.10883018 -0.09915766 -0.08637804 -0.06514771 -0.03537735
 -0.00695045  0.01307529  0.02539335  0.03607991  0.04814655  0.05257424
  0.04538721  0.03512231  0.03354714  0.04141478  0.0511991 ]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1134
Cluster 2, Occurrences: 1237
<torch.utils.data.dataloader.DataLoader object at 0x0000017452F74F98>
Epoch 1
-------------------------------
loss: 0.120253  [    0/ 3522]
loss: 0.192003  [  100/ 3522]
loss: 0.075672  [  200/ 3522]
loss: 0.050724  [  300/ 3522]
loss: 0.013987  [  400/ 3522]
loss: 0.009476  [  500/ 3522]
loss: 0.113907  [  600/ 3522]
loss: 0.033097  [  700/ 3522]
loss: 0.021405  [  800/ 3522]
loss: 0.010209  [  900/ 3522]
loss: 0.005143  [ 1000/ 3522]
loss: 0.004109  [ 1100/ 3522]
loss: 0.091462  [ 1200/ 3522]
loss: 0.016820  [ 1300/ 3522]
loss: 0.003052  [ 1400/ 3522]
loss: 0.002649  [ 1500/ 3522]
loss: 0.010275  [ 1600/ 3522]
loss: 0.006946  [ 1700/ 3522]
loss: 0.009728  [ 1800/ 3522]
loss: 0.015694  [ 1900/ 3522]
loss: 0.009601  [ 2000/ 3522]
loss: 0.014424  [ 2100/ 3522]
loss: 0.004245  [ 2200/ 3522]
loss: 0.007027  [ 2300/ 3522]
loss: 0.006203  [ 2400/ 3522]
loss: 0.004939  [ 2500/ 3522]
loss: 0.077046  [ 2600/ 3522]
loss: 0.011743  [ 2700/ 3522]
loss: 0.003147  [ 2800/ 3522]
loss: 0.004519  [ 2900/ 3522]
loss: 0.003866  [ 3000/ 3522]
loss: 0.009370  [ 3100/ 3522]
loss: 0.015106  [ 3200/ 3522]
loss: 0.007954  [ 3300/ 3522]
loss: 0.010401  [ 3400/ 3522]
loss: 0.008665  [ 3500/ 3522]
Epoch 2
-------------------------------
loss: 0.010652  [    0/ 3522]
loss: 0.008705  [  100/ 3522]
loss: 0.005118  [  200/ 3522]
loss: 0.053990  [  300/ 3522]
loss: 0.007368  [  400/ 3522]
loss: 0.008916  [  500/ 3522]
loss: 0.096245  [  600/ 3522]
loss: 0.013788  [  700/ 3522]
loss: 0.011037  [  800/ 3522]
loss: 0.007582  [  900/ 3522]
loss: 0.004741  [ 1000/ 3522]
loss: 0.003820  [ 1100/ 3522]
loss: 0.089293  [ 1200/ 3522]
loss: 0.015062  [ 1300/ 3522]
loss: 0.002849  [ 1400/ 3522]
loss: 0.002937  [ 1500/ 3522]
loss: 0.010851  [ 1600/ 3522]
loss: 0.006885  [ 1700/ 3522]
loss: 0.012807  [ 1800/ 3522]
loss: 0.012004  [ 1900/ 3522]
loss: 0.008952  [ 2000/ 3522]
loss: 0.012722  [ 2100/ 3522]
loss: 0.003992  [ 2200/ 3522]
loss: 0.007467  [ 2300/ 3522]
loss: 0.003891  [ 2400/ 3522]
loss: 0.004601  [ 2500/ 3522]
loss: 0.076842  [ 2600/ 3522]
loss: 0.008345  [ 2700/ 3522]
loss: 0.003093  [ 2800/ 3522]
loss: 0.005376  [ 2900/ 3522]
loss: 0.004384  [ 3000/ 3522]
loss: 0.008939  [ 3100/ 3522]
loss: 0.015013  [ 3200/ 3522]
loss: 0.007915  [ 3300/ 3522]
loss: 0.013839  [ 3400/ 3522]
loss: 0.007528  [ 3500/ 3522]
Epoch 3
-------------------------------
loss: 0.010315  [    0/ 3522]
loss: 0.008567  [  100/ 3522]
loss: 0.005113  [  200/ 3522]
loss: 0.049201  [  300/ 3522]
loss: 0.009118  [  400/ 3522]
loss: 0.008706  [  500/ 3522]
loss: 0.100239  [  600/ 3522]
loss: 0.012131  [  700/ 3522]
loss: 0.008067  [  800/ 3522]
loss: 0.007724  [  900/ 3522]
loss: 0.004003  [ 1000/ 3522]
loss: 0.003664  [ 1100/ 3522]
loss: 0.090139  [ 1200/ 3522]
loss: 0.013542  [ 1300/ 3522]
loss: 0.002814  [ 1400/ 3522]
loss: 0.003713  [ 1500/ 3522]
loss: 0.010973  [ 1600/ 3522]
loss: 0.006316  [ 1700/ 3522]
loss: 0.012773  [ 1800/ 3522]
loss: 0.010968  [ 1900/ 3522]
loss: 0.008145  [ 2000/ 3522]
loss: 0.012227  [ 2100/ 3522]
loss: 0.003501  [ 2200/ 3522]
loss: 0.007379  [ 2300/ 3522]
loss: 0.003868  [ 2400/ 3522]
loss: 0.004174  [ 2500/ 3522]
loss: 0.077589  [ 2600/ 3522]
loss: 0.008744  [ 2700/ 3522]
loss: 0.003121  [ 2800/ 3522]
loss: 0.005570  [ 2900/ 3522]
loss: 0.006805  [ 3000/ 3522]
loss: 0.008818  [ 3100/ 3522]
loss: 0.014125  [ 3200/ 3522]
loss: 0.007628  [ 3300/ 3522]
loss: 0.012235  [ 3400/ 3522]
loss: 0.007499  [ 3500/ 3522]
Epoch 4
-------------------------------
loss: 0.009580  [    0/ 3522]
loss: 0.008334  [  100/ 3522]
loss: 0.004793  [  200/ 3522]
loss: 0.035081  [  300/ 3522]
loss: 0.008814  [  400/ 3522]
loss: 0.008906  [  500/ 3522]
loss: 0.090435  [  600/ 3522]
loss: 0.011541  [  700/ 3522]
loss: 0.007485  [  800/ 3522]
loss: 0.008329  [  900/ 3522]
loss: 0.003983  [ 1000/ 3522]
loss: 0.002841  [ 1100/ 3522]
loss: 0.090080  [ 1200/ 3522]
loss: 0.012653  [ 1300/ 3522]
loss: 0.002709  [ 1400/ 3522]
loss: 0.004210  [ 1500/ 3522]
loss: 0.010780  [ 1600/ 3522]
loss: 0.005902  [ 1700/ 3522]
loss: 0.011831  [ 1800/ 3522]
loss: 0.010865  [ 1900/ 3522]
loss: 0.006496  [ 2000/ 3522]
loss: 0.012337  [ 2100/ 3522]
loss: 0.002543  [ 2200/ 3522]
loss: 0.006662  [ 2300/ 3522]
loss: 0.003925  [ 2400/ 3522]
loss: 0.003801  [ 2500/ 3522]
loss: 0.076819  [ 2600/ 3522]
loss: 0.008893  [ 2700/ 3522]
loss: 0.003012  [ 2800/ 3522]
loss: 0.005517  [ 2900/ 3522]
loss: 0.006830  [ 3000/ 3522]
loss: 0.007302  [ 3100/ 3522]
loss: 0.012225  [ 3200/ 3522]
loss: 0.007317  [ 3300/ 3522]
loss: 0.011410  [ 3400/ 3522]
loss: 0.008213  [ 3500/ 3522]
Epoch 5
-------------------------------
loss: 0.008391  [    0/ 3522]
loss: 0.008639  [  100/ 3522]
loss: 0.004855  [  200/ 3522]
loss: 0.022858  [  300/ 3522]
loss: 0.009903  [  400/ 3522]
loss: 0.008398  [  500/ 3522]
loss: 0.087550  [  600/ 3522]
loss: 0.011687  [  700/ 3522]
loss: 0.007083  [  800/ 3522]
loss: 0.007874  [  900/ 3522]
loss: 0.003630  [ 1000/ 3522]
loss: 0.002939  [ 1100/ 3522]
loss: 0.088029  [ 1200/ 3522]
loss: 0.012727  [ 1300/ 3522]
loss: 0.002713  [ 1400/ 3522]
loss: 0.005058  [ 1500/ 3522]
loss: 0.010226  [ 1600/ 3522]
loss: 0.005556  [ 1700/ 3522]
loss: 0.012217  [ 1800/ 3522]
loss: 0.010415  [ 1900/ 3522]
loss: 0.006964  [ 2000/ 3522]
loss: 0.012163  [ 2100/ 3522]
loss: 0.002549  [ 2200/ 3522]
loss: 0.006066  [ 2300/ 3522]
loss: 0.003784  [ 2400/ 3522]
loss: 0.003450  [ 2500/ 3522]
loss: 0.077025  [ 2600/ 3522]
loss: 0.007657  [ 2700/ 3522]
loss: 0.002947  [ 2800/ 3522]
loss: 0.005460  [ 2900/ 3522]
loss: 0.006204  [ 3000/ 3522]
loss: 0.006026  [ 3100/ 3522]
loss: 0.011084  [ 3200/ 3522]
loss: 0.006551  [ 3300/ 3522]
loss: 0.012271  [ 3400/ 3522]
loss: 0.009063  [ 3500/ 3522]
Epoch 6
-------------------------------
loss: 0.007984  [    0/ 3522]
loss: 0.008878  [  100/ 3522]
loss: 0.004614  [  200/ 3522]
loss: 0.016204  [  300/ 3522]
loss: 0.008056  [  400/ 3522]
loss: 0.008110  [  500/ 3522]
loss: 0.085683  [  600/ 3522]
loss: 0.011178  [  700/ 3522]
loss: 0.006900  [  800/ 3522]
loss: 0.007524  [  900/ 3522]
loss: 0.003655  [ 1000/ 3522]
loss: 0.002877  [ 1100/ 3522]
loss: 0.086038  [ 1200/ 3522]
loss: 0.012745  [ 1300/ 3522]
loss: 0.002745  [ 1400/ 3522]
loss: 0.004460  [ 1500/ 3522]
loss: 0.011241  [ 1600/ 3522]
loss: 0.005899  [ 1700/ 3522]
loss: 0.012510  [ 1800/ 3522]
loss: 0.010686  [ 1900/ 3522]
loss: 0.007495  [ 2000/ 3522]
loss: 0.012484  [ 2100/ 3522]
loss: 0.002719  [ 2200/ 3522]
loss: 0.005989  [ 2300/ 3522]
loss: 0.003768  [ 2400/ 3522]
loss: 0.003287  [ 2500/ 3522]
loss: 0.076738  [ 2600/ 3522]
loss: 0.008099  [ 2700/ 3522]
loss: 0.002969  [ 2800/ 3522]
loss: 0.005516  [ 2900/ 3522]
loss: 0.005736  [ 3000/ 3522]
loss: 0.005535  [ 3100/ 3522]
loss: 0.010261  [ 3200/ 3522]
loss: 0.006940  [ 3300/ 3522]
loss: 0.013083  [ 3400/ 3522]
loss: 0.007860  [ 3500/ 3522]
Epoch 7
-------------------------------
loss: 0.007815  [    0/ 3522]
loss: 0.008905  [  100/ 3522]
loss: 0.004210  [  200/ 3522]
loss: 0.012723  [  300/ 3522]
loss: 0.009606  [  400/ 3522]
loss: 0.008087  [  500/ 3522]
loss: 0.084811  [  600/ 3522]
loss: 0.011147  [  700/ 3522]
loss: 0.007287  [  800/ 3522]
loss: 0.007470  [  900/ 3522]
loss: 0.003604  [ 1000/ 3522]
loss: 0.003047  [ 1100/ 3522]
loss: 0.083799  [ 1200/ 3522]
loss: 0.012457  [ 1300/ 3522]
loss: 0.002683  [ 1400/ 3522]
loss: 0.003886  [ 1500/ 3522]
loss: 0.012049  [ 1600/ 3522]
loss: 0.005495  [ 1700/ 3522]
loss: 0.012081  [ 1800/ 3522]
loss: 0.010932  [ 1900/ 3522]
loss: 0.007927  [ 2000/ 3522]
loss: 0.012583  [ 2100/ 3522]
loss: 0.002566  [ 2200/ 3522]
loss: 0.006015  [ 2300/ 3522]
loss: 0.003714  [ 2400/ 3522]
loss: 0.003205  [ 2500/ 3522]
loss: 0.076981  [ 2600/ 3522]
loss: 0.008127  [ 2700/ 3522]
loss: 0.003035  [ 2800/ 3522]
loss: 0.005537  [ 2900/ 3522]
loss: 0.005965  [ 3000/ 3522]
loss: 0.004792  [ 3100/ 3522]
loss: 0.009467  [ 3200/ 3522]
loss: 0.006575  [ 3300/ 3522]
loss: 0.012668  [ 3400/ 3522]
loss: 0.008097  [ 3500/ 3522]
Epoch 8
-------------------------------
loss: 0.007732  [    0/ 3522]
loss: 0.009007  [  100/ 3522]
loss: 0.003819  [  200/ 3522]
loss: 0.011499  [  300/ 3522]
loss: 0.009106  [  400/ 3522]
loss: 0.007962  [  500/ 3522]
loss: 0.082167  [  600/ 3522]
loss: 0.011147  [  700/ 3522]
loss: 0.007130  [  800/ 3522]
loss: 0.007639  [  900/ 3522]
loss: 0.003633  [ 1000/ 3522]
loss: 0.003199  [ 1100/ 3522]
loss: 0.081092  [ 1200/ 3522]
loss: 0.012425  [ 1300/ 3522]
loss: 0.002631  [ 1400/ 3522]
loss: 0.003610  [ 1500/ 3522]
loss: 0.011895  [ 1600/ 3522]
loss: 0.005551  [ 1700/ 3522]
loss: 0.012174  [ 1800/ 3522]
loss: 0.011507  [ 1900/ 3522]
loss: 0.008227  [ 2000/ 3522]
loss: 0.012565  [ 2100/ 3522]
loss: 0.002630  [ 2200/ 3522]
loss: 0.006110  [ 2300/ 3522]
loss: 0.003479  [ 2400/ 3522]
loss: 0.003054  [ 2500/ 3522]
loss: 0.076295  [ 2600/ 3522]
loss: 0.008106  [ 2700/ 3522]
loss: 0.003032  [ 2800/ 3522]
loss: 0.005449  [ 2900/ 3522]
loss: 0.005594  [ 3000/ 3522]
loss: 0.004450  [ 3100/ 3522]
loss: 0.008792  [ 3200/ 3522]
loss: 0.006488  [ 3300/ 3522]
loss: 0.013519  [ 3400/ 3522]
loss: 0.008131  [ 3500/ 3522]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3522
First Spike after testing: [ 0.9665037  -0.32978994]
[0 2 2 ... 2 0 2]
[0 2 2 ... 2 0 2]
Cluster 0 Occurrences: 1151; KMEANS: 1145
Cluster 1 Occurrences: 1134; KMEANS: 1125
Cluster 2 Occurrences: 1237; KMEANS: 1252
Centroids: [[0.70412683, -0.2753559], [-2.4422855, -0.7553701], [0.7543296, 1.5535971]]
Centroids: [[0.69994825, -0.29139367], [-2.4649978, -0.7616976], [0.7553398, 1.5485867]]
Contingency Matrix: 
[[1139    0   12]
 [   6 1122    6]
 [   0    3 1234]]
[[1139, 0, -1], [6, 1122, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1122, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 0, 1: 1}
New Contingency Matrix: 
[[1139    0   12]
 [   6 1122    6]
 [   0    3 1234]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1139, 1122, 1234], Sum: 3495
All_Elements: [1139, 0, 12, 6, 1122, 6, 0, 3, 1234], Sum: 3522
Accuracy: 0.9923339011925043
Done!
