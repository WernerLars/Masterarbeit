Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_05_15
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017490047F60>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x00000174870F2E48>
Epoch 1
-------------------------------
loss: 0.135327  [    0/ 3462]
loss: 0.079049  [  100/ 3462]
loss: 0.042606  [  200/ 3462]
loss: 0.025758  [  300/ 3462]
loss: 0.012782  [  400/ 3462]
loss: 0.008038  [  500/ 3462]
loss: 0.011596  [  600/ 3462]
loss: 0.022253  [  700/ 3462]
loss: 0.008110  [  800/ 3462]
loss: 0.016153  [  900/ 3462]
loss: 0.009316  [ 1000/ 3462]
loss: 0.045616  [ 1100/ 3462]
loss: 0.014471  [ 1200/ 3462]
loss: 0.003686  [ 1300/ 3462]
loss: 0.007068  [ 1400/ 3462]
loss: 0.010326  [ 1500/ 3462]
loss: 0.007827  [ 1600/ 3462]
loss: 0.005391  [ 1700/ 3462]
loss: 0.015563  [ 1800/ 3462]
loss: 0.008581  [ 1900/ 3462]
loss: 0.011519  [ 2000/ 3462]
loss: 0.066987  [ 2100/ 3462]
loss: 0.001712  [ 2200/ 3462]
loss: 0.006499  [ 2300/ 3462]
loss: 0.012356  [ 2400/ 3462]
loss: 0.005851  [ 2500/ 3462]
loss: 0.014128  [ 2600/ 3462]
loss: 0.006389  [ 2700/ 3462]
loss: 0.004167  [ 2800/ 3462]
loss: 0.015193  [ 2900/ 3462]
loss: 0.113286  [ 3000/ 3462]
loss: 0.006567  [ 3100/ 3462]
loss: 0.007510  [ 3200/ 3462]
loss: 0.139485  [ 3300/ 3462]
loss: 0.013205  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.001697  [    0/ 3462]
loss: 0.012863  [  100/ 3462]
loss: 0.012051  [  200/ 3462]
loss: 0.010685  [  300/ 3462]
loss: 0.011024  [  400/ 3462]
loss: 0.007214  [  500/ 3462]
loss: 0.003365  [  600/ 3462]
loss: 0.018514  [  700/ 3462]
loss: 0.006840  [  800/ 3462]
loss: 0.017094  [  900/ 3462]
loss: 0.009114  [ 1000/ 3462]
loss: 0.040216  [ 1100/ 3462]
loss: 0.012790  [ 1200/ 3462]
loss: 0.003589  [ 1300/ 3462]
loss: 0.005309  [ 1400/ 3462]
loss: 0.011125  [ 1500/ 3462]
loss: 0.006726  [ 1600/ 3462]
loss: 0.006456  [ 1700/ 3462]
loss: 0.011964  [ 1800/ 3462]
loss: 0.007618  [ 1900/ 3462]
loss: 0.008196  [ 2000/ 3462]
loss: 0.057029  [ 2100/ 3462]
loss: 0.001869  [ 2200/ 3462]
loss: 0.005860  [ 2300/ 3462]
loss: 0.012004  [ 2400/ 3462]
loss: 0.005985  [ 2500/ 3462]
loss: 0.010962  [ 2600/ 3462]
loss: 0.005964  [ 2700/ 3462]
loss: 0.002982  [ 2800/ 3462]
loss: 0.013877  [ 2900/ 3462]
loss: 0.109201  [ 3000/ 3462]
loss: 0.006340  [ 3100/ 3462]
loss: 0.008084  [ 3200/ 3462]
loss: 0.137931  [ 3300/ 3462]
loss: 0.012698  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.001520  [    0/ 3462]
loss: 0.012974  [  100/ 3462]
loss: 0.009602  [  200/ 3462]
loss: 0.012624  [  300/ 3462]
loss: 0.010405  [  400/ 3462]
loss: 0.005596  [  500/ 3462]
loss: 0.001901  [  600/ 3462]
loss: 0.018374  [  700/ 3462]
loss: 0.008198  [  800/ 3462]
loss: 0.017064  [  900/ 3462]
loss: 0.007501  [ 1000/ 3462]
loss: 0.041787  [ 1100/ 3462]
loss: 0.011007  [ 1200/ 3462]
loss: 0.003414  [ 1300/ 3462]
loss: 0.003623  [ 1400/ 3462]
loss: 0.011192  [ 1500/ 3462]
loss: 0.005121  [ 1600/ 3462]
loss: 0.006171  [ 1700/ 3462]
loss: 0.008623  [ 1800/ 3462]
loss: 0.006900  [ 1900/ 3462]
loss: 0.006382  [ 2000/ 3462]
loss: 0.058465  [ 2100/ 3462]
loss: 0.001840  [ 2200/ 3462]
loss: 0.005189  [ 2300/ 3462]
loss: 0.012024  [ 2400/ 3462]
loss: 0.006160  [ 2500/ 3462]
loss: 0.008619  [ 2600/ 3462]
loss: 0.005784  [ 2700/ 3462]
loss: 0.003559  [ 2800/ 3462]
loss: 0.013052  [ 2900/ 3462]
loss: 0.105800  [ 3000/ 3462]
loss: 0.006276  [ 3100/ 3462]
loss: 0.008607  [ 3200/ 3462]
loss: 0.133990  [ 3300/ 3462]
loss: 0.012108  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.001633  [    0/ 3462]
loss: 0.012613  [  100/ 3462]
loss: 0.007853  [  200/ 3462]
loss: 0.013943  [  300/ 3462]
loss: 0.010908  [  400/ 3462]
loss: 0.004618  [  500/ 3462]
loss: 0.002410  [  600/ 3462]
loss: 0.018531  [  700/ 3462]
loss: 0.009440  [  800/ 3462]
loss: 0.016807  [  900/ 3462]
loss: 0.006313  [ 1000/ 3462]
loss: 0.041660  [ 1100/ 3462]
loss: 0.009458  [ 1200/ 3462]
loss: 0.002985  [ 1300/ 3462]
loss: 0.002653  [ 1400/ 3462]
loss: 0.011419  [ 1500/ 3462]
loss: 0.003854  [ 1600/ 3462]
loss: 0.005754  [ 1700/ 3462]
loss: 0.006565  [ 1800/ 3462]
loss: 0.006192  [ 1900/ 3462]
loss: 0.005856  [ 2000/ 3462]
loss: 0.060054  [ 2100/ 3462]
loss: 0.001894  [ 2200/ 3462]
loss: 0.004897  [ 2300/ 3462]
loss: 0.012062  [ 2400/ 3462]
loss: 0.006242  [ 2500/ 3462]
loss: 0.007344  [ 2600/ 3462]
loss: 0.005685  [ 2700/ 3462]
loss: 0.004275  [ 2800/ 3462]
loss: 0.012557  [ 2900/ 3462]
loss: 0.104546  [ 3000/ 3462]
loss: 0.005602  [ 3100/ 3462]
loss: 0.008719  [ 3200/ 3462]
loss: 0.128845  [ 3300/ 3462]
loss: 0.011735  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.001644  [    0/ 3462]
loss: 0.012815  [  100/ 3462]
loss: 0.006169  [  200/ 3462]
loss: 0.014418  [  300/ 3462]
loss: 0.011411  [  400/ 3462]
loss: 0.004031  [  500/ 3462]
loss: 0.002644  [  600/ 3462]
loss: 0.018743  [  700/ 3462]
loss: 0.009526  [  800/ 3462]
loss: 0.016528  [  900/ 3462]
loss: 0.005555  [ 1000/ 3462]
loss: 0.040742  [ 1100/ 3462]
loss: 0.008902  [ 1200/ 3462]
loss: 0.002838  [ 1300/ 3462]
loss: 0.002267  [ 1400/ 3462]
loss: 0.011725  [ 1500/ 3462]
loss: 0.003067  [ 1600/ 3462]
loss: 0.005789  [ 1700/ 3462]
loss: 0.005598  [ 1800/ 3462]
loss: 0.005904  [ 1900/ 3462]
loss: 0.005951  [ 2000/ 3462]
loss: 0.060479  [ 2100/ 3462]
loss: 0.001829  [ 2200/ 3462]
loss: 0.004568  [ 2300/ 3462]
loss: 0.012093  [ 2400/ 3462]
loss: 0.006322  [ 2500/ 3462]
loss: 0.006762  [ 2600/ 3462]
loss: 0.005595  [ 2700/ 3462]
loss: 0.004579  [ 2800/ 3462]
loss: 0.012224  [ 2900/ 3462]
loss: 0.103588  [ 3000/ 3462]
loss: 0.005083  [ 3100/ 3462]
loss: 0.008712  [ 3200/ 3462]
loss: 0.126547  [ 3300/ 3462]
loss: 0.011567  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.001728  [    0/ 3462]
loss: 0.012790  [  100/ 3462]
loss: 0.005231  [  200/ 3462]
loss: 0.013970  [  300/ 3462]
loss: 0.011765  [  400/ 3462]
loss: 0.003743  [  500/ 3462]
loss: 0.003246  [  600/ 3462]
loss: 0.019150  [  700/ 3462]
loss: 0.009816  [  800/ 3462]
loss: 0.016119  [  900/ 3462]
loss: 0.004991  [ 1000/ 3462]
loss: 0.040937  [ 1100/ 3462]
loss: 0.008648  [ 1200/ 3462]
loss: 0.002956  [ 1300/ 3462]
loss: 0.002111  [ 1400/ 3462]
loss: 0.012057  [ 1500/ 3462]
loss: 0.002278  [ 1600/ 3462]
loss: 0.006467  [ 1700/ 3462]
loss: 0.004832  [ 1800/ 3462]
loss: 0.005842  [ 1900/ 3462]
loss: 0.006050  [ 2000/ 3462]
loss: 0.060293  [ 2100/ 3462]
loss: 0.001833  [ 2200/ 3462]
loss: 0.004715  [ 2300/ 3462]
loss: 0.012009  [ 2400/ 3462]
loss: 0.006367  [ 2500/ 3462]
loss: 0.006735  [ 2600/ 3462]
loss: 0.005451  [ 2700/ 3462]
loss: 0.004682  [ 2800/ 3462]
loss: 0.012198  [ 2900/ 3462]
loss: 0.101880  [ 3000/ 3462]
loss: 0.004745  [ 3100/ 3462]
loss: 0.008661  [ 3200/ 3462]
loss: 0.125051  [ 3300/ 3462]
loss: 0.011129  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.001856  [    0/ 3462]
loss: 0.012588  [  100/ 3462]
loss: 0.005121  [  200/ 3462]
loss: 0.013257  [  300/ 3462]
loss: 0.011941  [  400/ 3462]
loss: 0.003427  [  500/ 3462]
loss: 0.003650  [  600/ 3462]
loss: 0.018940  [  700/ 3462]
loss: 0.009934  [  800/ 3462]
loss: 0.015933  [  900/ 3462]
loss: 0.004685  [ 1000/ 3462]
loss: 0.039840  [ 1100/ 3462]
loss: 0.008089  [ 1200/ 3462]
loss: 0.002783  [ 1300/ 3462]
loss: 0.002029  [ 1400/ 3462]
loss: 0.012190  [ 1500/ 3462]
loss: 0.001855  [ 1600/ 3462]
loss: 0.006969  [ 1700/ 3462]
loss: 0.003715  [ 1800/ 3462]
loss: 0.005602  [ 1900/ 3462]
loss: 0.006364  [ 2000/ 3462]
loss: 0.061122  [ 2100/ 3462]
loss: 0.001711  [ 2200/ 3462]
loss: 0.005061  [ 2300/ 3462]
loss: 0.011886  [ 2400/ 3462]
loss: 0.006391  [ 2500/ 3462]
loss: 0.007008  [ 2600/ 3462]
loss: 0.005215  [ 2700/ 3462]
loss: 0.004986  [ 2800/ 3462]
loss: 0.012455  [ 2900/ 3462]
loss: 0.098058  [ 3000/ 3462]
loss: 0.004614  [ 3100/ 3462]
loss: 0.008665  [ 3200/ 3462]
loss: 0.122483  [ 3300/ 3462]
loss: 0.011373  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.002058  [    0/ 3462]
loss: 0.012053  [  100/ 3462]
loss: 0.004651  [  200/ 3462]
loss: 0.012605  [  300/ 3462]
loss: 0.011544  [  400/ 3462]
loss: 0.003036  [  500/ 3462]
loss: 0.003846  [  600/ 3462]
loss: 0.019222  [  700/ 3462]
loss: 0.010440  [  800/ 3462]
loss: 0.014851  [  900/ 3462]
loss: 0.004428  [ 1000/ 3462]
loss: 0.041446  [ 1100/ 3462]
loss: 0.007742  [ 1200/ 3462]
loss: 0.003631  [ 1300/ 3462]
loss: 0.002071  [ 1400/ 3462]
loss: 0.012557  [ 1500/ 3462]
loss: 0.001606  [ 1600/ 3462]
loss: 0.007918  [ 1700/ 3462]
loss: 0.003338  [ 1800/ 3462]
loss: 0.005502  [ 1900/ 3462]
loss: 0.006332  [ 2000/ 3462]
loss: 0.061112  [ 2100/ 3462]
loss: 0.001700  [ 2200/ 3462]
loss: 0.004710  [ 2300/ 3462]
loss: 0.011880  [ 2400/ 3462]
loss: 0.006342  [ 2500/ 3462]
loss: 0.006991  [ 2600/ 3462]
loss: 0.005047  [ 2700/ 3462]
loss: 0.005149  [ 2800/ 3462]
loss: 0.012612  [ 2900/ 3462]
loss: 0.096891  [ 3000/ 3462]
loss: 0.004477  [ 3100/ 3462]
loss: 0.008446  [ 3200/ 3462]
loss: 0.121553  [ 3300/ 3462]
loss: 0.011385  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [0.52690965 0.23478007]
[0 2 2 ... 0 1 2]
[2 0 0 ... 2 1 0]
Cluster 0 Occurrences: 1187; KMEANS: 1128
Cluster 1 Occurrences: 1136; KMEANS: 1131
Cluster 2 Occurrences: 1139; KMEANS: 1203
Centroids: [[0.4492681, 0.31068516], [-1.1696496, -0.71320796], [0.076120116, -0.34662637]]
Centroids: [[0.0650855, -0.37274885], [-1.1764951, -0.71820366], [0.45590988, 0.32960984]]
Contingency Matrix: 
[[  19    1 1167]
 [   4 1129    3]
 [1105    1   33]]
[[-1, -1, -1], [4, 1129, -1], [1105, 1, -1]]
[[-1, -1, -1], [-1, -1, -1], [1105, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 1: 1, 2: 0}
New Contingency Matrix: 
[[1167    1   19]
 [   3 1129    4]
 [  33    1 1105]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1167, 1129, 1105], Sum: 3401
All_Elements: [1167, 1, 19, 3, 1129, 4, 33, 1, 1105], Sum: 3462
Accuracy: 0.9823801270941652
Done!
