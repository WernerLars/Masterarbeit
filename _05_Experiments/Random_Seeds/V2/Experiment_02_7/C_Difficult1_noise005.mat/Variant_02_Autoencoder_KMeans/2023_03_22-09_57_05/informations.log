Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_57_05
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017485A59048>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x0000017452F74F98>
Epoch 1
-------------------------------
loss: 0.187209  [    0/ 3383]
loss: 0.029264  [  100/ 3383]
loss: 0.013705  [  200/ 3383]
loss: 0.008952  [  300/ 3383]
loss: 0.006789  [  400/ 3383]
loss: 0.008345  [  500/ 3383]
loss: 0.011520  [  600/ 3383]
loss: 0.017445  [  700/ 3383]
loss: 0.009036  [  800/ 3383]
loss: 0.005940  [  900/ 3383]
loss: 0.094873  [ 1000/ 3383]
loss: 0.060709  [ 1100/ 3383]
loss: 0.023869  [ 1200/ 3383]
loss: 0.010509  [ 1300/ 3383]
loss: 0.007180  [ 1400/ 3383]
loss: 0.016197  [ 1500/ 3383]
loss: 0.010069  [ 1600/ 3383]
loss: 0.001696  [ 1700/ 3383]
loss: 0.012496  [ 1800/ 3383]
loss: 0.015248  [ 1900/ 3383]
loss: 0.011074  [ 2000/ 3383]
loss: 0.003880  [ 2100/ 3383]
loss: 0.009390  [ 2200/ 3383]
loss: 0.009659  [ 2300/ 3383]
loss: 0.003728  [ 2400/ 3383]
loss: 0.024182  [ 2500/ 3383]
loss: 0.010580  [ 2600/ 3383]
loss: 0.002988  [ 2700/ 3383]
loss: 0.006803  [ 2800/ 3383]
loss: 0.005269  [ 2900/ 3383]
loss: 0.003047  [ 3000/ 3383]
loss: 0.005810  [ 3100/ 3383]
loss: 0.060556  [ 3200/ 3383]
loss: 0.005409  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.005975  [    0/ 3383]
loss: 0.006144  [  100/ 3383]
loss: 0.007466  [  200/ 3383]
loss: 0.002314  [  300/ 3383]
loss: 0.002609  [  400/ 3383]
loss: 0.005047  [  500/ 3383]
loss: 0.006498  [  600/ 3383]
loss: 0.011872  [  700/ 3383]
loss: 0.007824  [  800/ 3383]
loss: 0.001024  [  900/ 3383]
loss: 0.092314  [ 1000/ 3383]
loss: 0.057705  [ 1100/ 3383]
loss: 0.023788  [ 1200/ 3383]
loss: 0.008831  [ 1300/ 3383]
loss: 0.004501  [ 1400/ 3383]
loss: 0.015934  [ 1500/ 3383]
loss: 0.004530  [ 1600/ 3383]
loss: 0.001788  [ 1700/ 3383]
loss: 0.012981  [ 1800/ 3383]
loss: 0.015464  [ 1900/ 3383]
loss: 0.002149  [ 2000/ 3383]
loss: 0.003844  [ 2100/ 3383]
loss: 0.008699  [ 2200/ 3383]
loss: 0.001481  [ 2300/ 3383]
loss: 0.003998  [ 2400/ 3383]
loss: 0.028487  [ 2500/ 3383]
loss: 0.002011  [ 2600/ 3383]
loss: 0.003027  [ 2700/ 3383]
loss: 0.006394  [ 2800/ 3383]
loss: 0.005428  [ 2900/ 3383]
loss: 0.004120  [ 3000/ 3383]
loss: 0.004878  [ 3100/ 3383]
loss: 0.065928  [ 3200/ 3383]
loss: 0.002426  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.003933  [    0/ 3383]
loss: 0.005898  [  100/ 3383]
loss: 0.006168  [  200/ 3383]
loss: 0.002569  [  300/ 3383]
loss: 0.002599  [  400/ 3383]
loss: 0.004588  [  500/ 3383]
loss: 0.001056  [  600/ 3383]
loss: 0.002298  [  700/ 3383]
loss: 0.007499  [  800/ 3383]
loss: 0.001582  [  900/ 3383]
loss: 0.091082  [ 1000/ 3383]
loss: 0.057709  [ 1100/ 3383]
loss: 0.024052  [ 1200/ 3383]
loss: 0.009251  [ 1300/ 3383]
loss: 0.003966  [ 1400/ 3383]
loss: 0.015073  [ 1500/ 3383]
loss: 0.002539  [ 1600/ 3383]
loss: 0.001664  [ 1700/ 3383]
loss: 0.011933  [ 1800/ 3383]
loss: 0.014508  [ 1900/ 3383]
loss: 0.002862  [ 2000/ 3383]
loss: 0.003555  [ 2100/ 3383]
loss: 0.008865  [ 2200/ 3383]
loss: 0.001751  [ 2300/ 3383]
loss: 0.003928  [ 2400/ 3383]
loss: 0.026900  [ 2500/ 3383]
loss: 0.001438  [ 2600/ 3383]
loss: 0.002783  [ 2700/ 3383]
loss: 0.006455  [ 2800/ 3383]
loss: 0.005598  [ 2900/ 3383]
loss: 0.003986  [ 3000/ 3383]
loss: 0.004628  [ 3100/ 3383]
loss: 0.065332  [ 3200/ 3383]
loss: 0.002506  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.003957  [    0/ 3383]
loss: 0.006068  [  100/ 3383]
loss: 0.005944  [  200/ 3383]
loss: 0.002689  [  300/ 3383]
loss: 0.002694  [  400/ 3383]
loss: 0.004645  [  500/ 3383]
loss: 0.001240  [  600/ 3383]
loss: 0.002292  [  700/ 3383]
loss: 0.007152  [  800/ 3383]
loss: 0.001598  [  900/ 3383]
loss: 0.091153  [ 1000/ 3383]
loss: 0.057815  [ 1100/ 3383]
loss: 0.023718  [ 1200/ 3383]
loss: 0.009366  [ 1300/ 3383]
loss: 0.003855  [ 1400/ 3383]
loss: 0.015204  [ 1500/ 3383]
loss: 0.002527  [ 1600/ 3383]
loss: 0.001593  [ 1700/ 3383]
loss: 0.011467  [ 1800/ 3383]
loss: 0.014287  [ 1900/ 3383]
loss: 0.002874  [ 2000/ 3383]
loss: 0.003562  [ 2100/ 3383]
loss: 0.009049  [ 2200/ 3383]
loss: 0.001772  [ 2300/ 3383]
loss: 0.003838  [ 2400/ 3383]
loss: 0.027373  [ 2500/ 3383]
loss: 0.001329  [ 2600/ 3383]
loss: 0.002573  [ 2700/ 3383]
loss: 0.006404  [ 2800/ 3383]
loss: 0.005761  [ 2900/ 3383]
loss: 0.003625  [ 3000/ 3383]
loss: 0.004559  [ 3100/ 3383]
loss: 0.065279  [ 3200/ 3383]
loss: 0.002618  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.004137  [    0/ 3383]
loss: 0.006357  [  100/ 3383]
loss: 0.005735  [  200/ 3383]
loss: 0.002826  [  300/ 3383]
loss: 0.002675  [  400/ 3383]
loss: 0.004558  [  500/ 3383]
loss: 0.001281  [  600/ 3383]
loss: 0.002041  [  700/ 3383]
loss: 0.006534  [  800/ 3383]
loss: 0.001732  [  900/ 3383]
loss: 0.090788  [ 1000/ 3383]
loss: 0.057897  [ 1100/ 3383]
loss: 0.023841  [ 1200/ 3383]
loss: 0.009404  [ 1300/ 3383]
loss: 0.003300  [ 1400/ 3383]
loss: 0.015337  [ 1500/ 3383]
loss: 0.002434  [ 1600/ 3383]
loss: 0.001548  [ 1700/ 3383]
loss: 0.010715  [ 1800/ 3383]
loss: 0.014367  [ 1900/ 3383]
loss: 0.002755  [ 2000/ 3383]
loss: 0.003749  [ 2100/ 3383]
loss: 0.009030  [ 2200/ 3383]
loss: 0.001792  [ 2300/ 3383]
loss: 0.003909  [ 2400/ 3383]
loss: 0.027979  [ 2500/ 3383]
loss: 0.001236  [ 2600/ 3383]
loss: 0.002474  [ 2700/ 3383]
loss: 0.006347  [ 2800/ 3383]
loss: 0.005887  [ 2900/ 3383]
loss: 0.003474  [ 3000/ 3383]
loss: 0.004657  [ 3100/ 3383]
loss: 0.065678  [ 3200/ 3383]
loss: 0.002576  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.004294  [    0/ 3383]
loss: 0.006504  [  100/ 3383]
loss: 0.005518  [  200/ 3383]
loss: 0.002989  [  300/ 3383]
loss: 0.002585  [  400/ 3383]
loss: 0.004468  [  500/ 3383]
loss: 0.001350  [  600/ 3383]
loss: 0.001918  [  700/ 3383]
loss: 0.006063  [  800/ 3383]
loss: 0.001768  [  900/ 3383]
loss: 0.090692  [ 1000/ 3383]
loss: 0.057794  [ 1100/ 3383]
loss: 0.024039  [ 1200/ 3383]
loss: 0.009382  [ 1300/ 3383]
loss: 0.002755  [ 1400/ 3383]
loss: 0.015133  [ 1500/ 3383]
loss: 0.002198  [ 1600/ 3383]
loss: 0.001553  [ 1700/ 3383]
loss: 0.010075  [ 1800/ 3383]
loss: 0.014379  [ 1900/ 3383]
loss: 0.002626  [ 2000/ 3383]
loss: 0.003933  [ 2100/ 3383]
loss: 0.008590  [ 2200/ 3383]
loss: 0.001761  [ 2300/ 3383]
loss: 0.003995  [ 2400/ 3383]
loss: 0.027165  [ 2500/ 3383]
loss: 0.001188  [ 2600/ 3383]
loss: 0.002442  [ 2700/ 3383]
loss: 0.006357  [ 2800/ 3383]
loss: 0.006095  [ 2900/ 3383]
loss: 0.003351  [ 3000/ 3383]
loss: 0.004615  [ 3100/ 3383]
loss: 0.066308  [ 3200/ 3383]
loss: 0.002466  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.004474  [    0/ 3383]
loss: 0.006426  [  100/ 3383]
loss: 0.005133  [  200/ 3383]
loss: 0.003008  [  300/ 3383]
loss: 0.002502  [  400/ 3383]
loss: 0.004253  [  500/ 3383]
loss: 0.001341  [  600/ 3383]
loss: 0.001979  [  700/ 3383]
loss: 0.005753  [  800/ 3383]
loss: 0.001885  [  900/ 3383]
loss: 0.092010  [ 1000/ 3383]
loss: 0.057689  [ 1100/ 3383]
loss: 0.024164  [ 1200/ 3383]
loss: 0.009223  [ 1300/ 3383]
loss: 0.002503  [ 1400/ 3383]
loss: 0.014634  [ 1500/ 3383]
loss: 0.002094  [ 1600/ 3383]
loss: 0.001558  [ 1700/ 3383]
loss: 0.009579  [ 1800/ 3383]
loss: 0.014332  [ 1900/ 3383]
loss: 0.002445  [ 2000/ 3383]
loss: 0.004088  [ 2100/ 3383]
loss: 0.007637  [ 2200/ 3383]
loss: 0.001830  [ 2300/ 3383]
loss: 0.003924  [ 2400/ 3383]
loss: 0.026710  [ 2500/ 3383]
loss: 0.001150  [ 2600/ 3383]
loss: 0.002315  [ 2700/ 3383]
loss: 0.006479  [ 2800/ 3383]
loss: 0.006179  [ 2900/ 3383]
loss: 0.003147  [ 3000/ 3383]
loss: 0.004656  [ 3100/ 3383]
loss: 0.066502  [ 3200/ 3383]
loss: 0.002431  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.004509  [    0/ 3383]
loss: 0.006092  [  100/ 3383]
loss: 0.004529  [  200/ 3383]
loss: 0.003041  [  300/ 3383]
loss: 0.002365  [  400/ 3383]
loss: 0.003930  [  500/ 3383]
loss: 0.001240  [  600/ 3383]
loss: 0.001806  [  700/ 3383]
loss: 0.005581  [  800/ 3383]
loss: 0.001885  [  900/ 3383]
loss: 0.094843  [ 1000/ 3383]
loss: 0.057689  [ 1100/ 3383]
loss: 0.024534  [ 1200/ 3383]
loss: 0.008897  [ 1300/ 3383]
loss: 0.002241  [ 1400/ 3383]
loss: 0.014266  [ 1500/ 3383]
loss: 0.001877  [ 1600/ 3383]
loss: 0.001551  [ 1700/ 3383]
loss: 0.008934  [ 1800/ 3383]
loss: 0.014356  [ 1900/ 3383]
loss: 0.002292  [ 2000/ 3383]
loss: 0.004165  [ 2100/ 3383]
loss: 0.007385  [ 2200/ 3383]
loss: 0.001877  [ 2300/ 3383]
loss: 0.004049  [ 2400/ 3383]
loss: 0.026524  [ 2500/ 3383]
loss: 0.001273  [ 2600/ 3383]
loss: 0.002224  [ 2700/ 3383]
loss: 0.006405  [ 2800/ 3383]
loss: 0.006200  [ 2900/ 3383]
loss: 0.002892  [ 3000/ 3383]
loss: 0.004703  [ 3100/ 3383]
loss: 0.067014  [ 3200/ 3383]
loss: 0.002327  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [0.30738387 0.5753467 ]
[2 1 2 ... 0 1 2]
[0 2 0 ... 1 2 0]
Cluster 0 Occurrences: 1115; KMEANS: 1191
Cluster 1 Occurrences: 1113; KMEANS: 1119
Cluster 2 Occurrences: 1155; KMEANS: 1073
Centroids: [[-0.19790392, 0.17838371], [0.61654884, -0.049252827], [0.5885559, 0.58069944]]
Centroids: [[0.603748, 0.5856939], [-0.21820422, 0.17755578], [0.62483203, -0.07591701]]
Contingency Matrix: 
[[  18 1091    6]
 [  33   18 1062]
 [1140   10    5]]
[[-1, 1091, 6], [-1, 18, 1062], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1062], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1091    6   18]
 [  18 1062   33]
 [  10    5 1140]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1091, 1062, 1140], Sum: 3293
All_Elements: [1091, 6, 18, 18, 1062, 33, 10, 5, 1140], Sum: 3383
Accuracy: 0.9733963937333727
Done!
