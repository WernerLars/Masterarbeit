Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise040.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise040.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Easy1_noise040.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_50_08
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017452E13B00>
Sampling rate: 24000.0
Raw: [ 0.09290294  0.20189621  0.33053674 ... -0.20677271 -0.1502611
 -0.11999569]
Times: [    239     439     824 ... 1439203 1439286 1439464]
Cluster: [1 3 1 ... 3 1 2]
Number of different clusters:  3
Number of Spikes: 3386
First aligned Spike Frame: [ 0.35272875  0.22782651  0.09804678  0.0330907   0.01763465 -0.00716808
 -0.07676483 -0.17393839 -0.25156268 -0.27611297 -0.26424986 -0.2572748
 -0.14070033  0.3091543   0.84618672  0.8657919   0.33633627 -0.19287563
 -0.36620283 -0.28464978 -0.16625656 -0.0936908  -0.03935964  0.02291416
  0.0699242   0.05739865 -0.02453232 -0.1465012  -0.24130255 -0.27021376
 -0.25598501 -0.22429694 -0.17333633 -0.09081612  0.03499496  0.1799287
  0.31672358  0.42401557  0.47266498  0.4416574   0.34587776  0.22594898
  0.10664098 -0.02537482 -0.17575272 -0.29850509 -0.34589514]
Cluster 0, Occurrences: 1079
Cluster 1, Occurrences: 1158
Cluster 2, Occurrences: 1149
<torch.utils.data.dataloader.DataLoader object at 0x0000017452F74F60>
Epoch 1
-------------------------------
loss: 0.140888  [    0/ 3386]
loss: 0.251886  [  100/ 3386]
loss: 0.185018  [  200/ 3386]
loss: 0.173065  [  300/ 3386]
loss: 0.266084  [  400/ 3386]
loss: 0.074259  [  500/ 3386]
loss: 0.165747  [  600/ 3386]
loss: 0.080435  [  700/ 3386]
loss: 0.135197  [  800/ 3386]
loss: 0.095116  [  900/ 3386]
loss: 0.281644  [ 1000/ 3386]
loss: 0.323711  [ 1100/ 3386]
loss: 0.233827  [ 1200/ 3386]
loss: 0.026318  [ 1300/ 3386]
loss: 0.060461  [ 1400/ 3386]
loss: 0.119474  [ 1500/ 3386]
loss: 0.039799  [ 1600/ 3386]
loss: 0.022999  [ 1700/ 3386]
loss: 0.203919  [ 1800/ 3386]
loss: 0.570501  [ 1900/ 3386]
loss: 0.035322  [ 2000/ 3386]
loss: 0.130765  [ 2100/ 3386]
loss: 0.564090  [ 2200/ 3386]
loss: 0.090886  [ 2300/ 3386]
loss: 0.135312  [ 2400/ 3386]
loss: 0.046025  [ 2500/ 3386]
loss: 0.191887  [ 2600/ 3386]
loss: 0.228207  [ 2700/ 3386]
loss: 0.070372  [ 2800/ 3386]
loss: 0.065485  [ 2900/ 3386]
loss: 0.015628  [ 3000/ 3386]
loss: 0.119061  [ 3100/ 3386]
loss: 0.122665  [ 3200/ 3386]
loss: 0.102676  [ 3300/ 3386]
Epoch 2
-------------------------------
loss: 0.055155  [    0/ 3386]
loss: 0.120705  [  100/ 3386]
loss: 0.089051  [  200/ 3386]
loss: 0.184918  [  300/ 3386]
loss: 0.193482  [  400/ 3386]
loss: 0.067751  [  500/ 3386]
loss: 0.157987  [  600/ 3386]
loss: 0.044399  [  700/ 3386]
loss: 0.110811  [  800/ 3386]
loss: 0.055331  [  900/ 3386]
loss: 0.154353  [ 1000/ 3386]
loss: 0.301497  [ 1100/ 3386]
loss: 0.163805  [ 1200/ 3386]
loss: 0.023828  [ 1300/ 3386]
loss: 0.048212  [ 1400/ 3386]
loss: 0.061772  [ 1500/ 3386]
loss: 0.035181  [ 1600/ 3386]
loss: 0.028687  [ 1700/ 3386]
loss: 0.272531  [ 1800/ 3386]
loss: 0.506542  [ 1900/ 3386]
loss: 0.026118  [ 2000/ 3386]
loss: 0.089159  [ 2100/ 3386]
loss: 0.694385  [ 2200/ 3386]
loss: 0.074191  [ 2300/ 3386]
loss: 0.102093  [ 2400/ 3386]
loss: 0.042637  [ 2500/ 3386]
loss: 0.154416  [ 2600/ 3386]
loss: 0.213350  [ 2700/ 3386]
loss: 0.066787  [ 2800/ 3386]
loss: 0.058244  [ 2900/ 3386]
loss: 0.015423  [ 3000/ 3386]
loss: 0.117767  [ 3100/ 3386]
loss: 0.100072  [ 3200/ 3386]
loss: 0.100710  [ 3300/ 3386]
Epoch 3
-------------------------------
loss: 0.050896  [    0/ 3386]
loss: 0.119014  [  100/ 3386]
loss: 0.092861  [  200/ 3386]
loss: 0.210742  [  300/ 3386]
loss: 0.186497  [  400/ 3386]
loss: 0.070333  [  500/ 3386]
loss: 0.158991  [  600/ 3386]
loss: 0.043333  [  700/ 3386]
loss: 0.110526  [  800/ 3386]
loss: 0.052336  [  900/ 3386]
loss: 0.141166  [ 1000/ 3386]
loss: 0.284910  [ 1100/ 3386]
loss: 0.156183  [ 1200/ 3386]
loss: 0.026083  [ 1300/ 3386]
loss: 0.048062  [ 1400/ 3386]
loss: 0.058133  [ 1500/ 3386]
loss: 0.034262  [ 1600/ 3386]
loss: 0.031385  [ 1700/ 3386]
loss: 0.276291  [ 1800/ 3386]
loss: 0.482730  [ 1900/ 3386]
loss: 0.026201  [ 2000/ 3386]
loss: 0.083169  [ 2100/ 3386]
loss: 0.669987  [ 2200/ 3386]
loss: 0.071799  [ 2300/ 3386]
loss: 0.096265  [ 2400/ 3386]
loss: 0.043652  [ 2500/ 3386]
loss: 0.154955  [ 2600/ 3386]
loss: 0.211541  [ 2700/ 3386]
loss: 0.066315  [ 2800/ 3386]
loss: 0.055842  [ 2900/ 3386]
loss: 0.014972  [ 3000/ 3386]
loss: 0.117030  [ 3100/ 3386]
loss: 0.091788  [ 3200/ 3386]
loss: 0.100745  [ 3300/ 3386]
Epoch 4
-------------------------------
loss: 0.050247  [    0/ 3386]
loss: 0.116899  [  100/ 3386]
loss: 0.091587  [  200/ 3386]
loss: 0.203814  [  300/ 3386]
loss: 0.185310  [  400/ 3386]
loss: 0.073185  [  500/ 3386]
loss: 0.159750  [  600/ 3386]
loss: 0.043383  [  700/ 3386]
loss: 0.113082  [  800/ 3386]
loss: 0.050691  [  900/ 3386]
loss: 0.138659  [ 1000/ 3386]
loss: 0.275084  [ 1100/ 3386]
loss: 0.151441  [ 1200/ 3386]
loss: 0.028149  [ 1300/ 3386]
loss: 0.047981  [ 1400/ 3386]
loss: 0.056305  [ 1500/ 3386]
loss: 0.034731  [ 1600/ 3386]
loss: 0.032904  [ 1700/ 3386]
loss: 0.252972  [ 1800/ 3386]
loss: 0.476676  [ 1900/ 3386]
loss: 0.025435  [ 2000/ 3386]
loss: 0.080478  [ 2100/ 3386]
loss: 0.602721  [ 2200/ 3386]
loss: 0.070201  [ 2300/ 3386]
loss: 0.092502  [ 2400/ 3386]
loss: 0.044769  [ 2500/ 3386]
loss: 0.172270  [ 2600/ 3386]
loss: 0.215068  [ 2700/ 3386]
loss: 0.068216  [ 2800/ 3386]
loss: 0.055235  [ 2900/ 3386]
loss: 0.014922  [ 3000/ 3386]
loss: 0.117615  [ 3100/ 3386]
loss: 0.092064  [ 3200/ 3386]
loss: 0.099727  [ 3300/ 3386]
Epoch 5
-------------------------------
loss: 0.050418  [    0/ 3386]
loss: 0.116286  [  100/ 3386]
loss: 0.080827  [  200/ 3386]
loss: 0.174956  [  300/ 3386]
loss: 0.185592  [  400/ 3386]
loss: 0.074708  [  500/ 3386]
loss: 0.159168  [  600/ 3386]
loss: 0.042178  [  700/ 3386]
loss: 0.112166  [  800/ 3386]
loss: 0.051582  [  900/ 3386]
loss: 0.144047  [ 1000/ 3386]
loss: 0.268008  [ 1100/ 3386]
loss: 0.154527  [ 1200/ 3386]
loss: 0.027804  [ 1300/ 3386]
loss: 0.050234  [ 1400/ 3386]
loss: 0.060010  [ 1500/ 3386]
loss: 0.035640  [ 1600/ 3386]
loss: 0.033287  [ 1700/ 3386]
loss: 0.180745  [ 1800/ 3386]
loss: 0.449085  [ 1900/ 3386]
loss: 0.025646  [ 2000/ 3386]
loss: 0.081074  [ 2100/ 3386]
loss: 0.537407  [ 2200/ 3386]
loss: 0.070511  [ 2300/ 3386]
loss: 0.085775  [ 2400/ 3386]
loss: 0.045862  [ 2500/ 3386]
loss: 0.147617  [ 2600/ 3386]
loss: 0.210444  [ 2700/ 3386]
loss: 0.061641  [ 2800/ 3386]
loss: 0.057344  [ 2900/ 3386]
loss: 0.015210  [ 3000/ 3386]
loss: 0.118022  [ 3100/ 3386]
loss: 0.084138  [ 3200/ 3386]
loss: 0.097776  [ 3300/ 3386]
Epoch 6
-------------------------------
loss: 0.048914  [    0/ 3386]
loss: 0.116898  [  100/ 3386]
loss: 0.073368  [  200/ 3386]
loss: 0.151401  [  300/ 3386]
loss: 0.189325  [  400/ 3386]
loss: 0.073986  [  500/ 3386]
loss: 0.158905  [  600/ 3386]
loss: 0.042269  [  700/ 3386]
loss: 0.112221  [  800/ 3386]
loss: 0.053390  [  900/ 3386]
loss: 0.144673  [ 1000/ 3386]
loss: 0.248120  [ 1100/ 3386]
loss: 0.158347  [ 1200/ 3386]
loss: 0.026695  [ 1300/ 3386]
loss: 0.051612  [ 1400/ 3386]
loss: 0.059489  [ 1500/ 3386]
loss: 0.035196  [ 1600/ 3386]
loss: 0.033233  [ 1700/ 3386]
loss: 0.140328  [ 1800/ 3386]
loss: 0.414011  [ 1900/ 3386]
loss: 0.029646  [ 2000/ 3386]
loss: 0.083286  [ 2100/ 3386]
loss: 0.492655  [ 2200/ 3386]
loss: 0.072259  [ 2300/ 3386]
loss: 0.078903  [ 2400/ 3386]
loss: 0.047777  [ 2500/ 3386]
loss: 0.120322  [ 2600/ 3386]
loss: 0.203322  [ 2700/ 3386]
loss: 0.060534  [ 2800/ 3386]
loss: 0.059701  [ 2900/ 3386]
loss: 0.015048  [ 3000/ 3386]
loss: 0.117534  [ 3100/ 3386]
loss: 0.075910  [ 3200/ 3386]
loss: 0.097010  [ 3300/ 3386]
Epoch 7
-------------------------------
loss: 0.049324  [    0/ 3386]
loss: 0.114779  [  100/ 3386]
loss: 0.078627  [  200/ 3386]
loss: 0.121835  [  300/ 3386]
loss: 0.189779  [  400/ 3386]
loss: 0.071854  [  500/ 3386]
loss: 0.158781  [  600/ 3386]
loss: 0.042277  [  700/ 3386]
loss: 0.114615  [  800/ 3386]
loss: 0.054654  [  900/ 3386]
loss: 0.143819  [ 1000/ 3386]
loss: 0.228390  [ 1100/ 3386]
loss: 0.162673  [ 1200/ 3386]
loss: 0.026423  [ 1300/ 3386]
loss: 0.049618  [ 1400/ 3386]
loss: 0.056992  [ 1500/ 3386]
loss: 0.034569  [ 1600/ 3386]
loss: 0.029665  [ 1700/ 3386]
loss: 0.151197  [ 1800/ 3386]
loss: 0.597086  [ 1900/ 3386]
loss: 0.038444  [ 2000/ 3386]
loss: 0.094247  [ 2100/ 3386]
loss: 0.428761  [ 2200/ 3386]
loss: 0.087767  [ 2300/ 3386]
loss: 0.078919  [ 2400/ 3386]
loss: 0.062303  [ 2500/ 3386]
loss: 0.089002  [ 2600/ 3386]
loss: 0.198501  [ 2700/ 3386]
loss: 0.073978  [ 2800/ 3386]
loss: 0.062498  [ 2900/ 3386]
loss: 0.014786  [ 3000/ 3386]
loss: 0.120113  [ 3100/ 3386]
loss: 0.065299  [ 3200/ 3386]
loss: 0.096700  [ 3300/ 3386]
Epoch 8
-------------------------------
loss: 0.049348  [    0/ 3386]
loss: 0.113048  [  100/ 3386]
loss: 0.082058  [  200/ 3386]
loss: 0.082776  [  300/ 3386]
loss: 0.190453  [  400/ 3386]
loss: 0.071642  [  500/ 3386]
loss: 0.157161  [  600/ 3386]
loss: 0.042665  [  700/ 3386]
loss: 0.113415  [  800/ 3386]
loss: 0.055291  [  900/ 3386]
loss: 0.140381  [ 1000/ 3386]
loss: 0.211029  [ 1100/ 3386]
loss: 0.158392  [ 1200/ 3386]
loss: 0.025842  [ 1300/ 3386]
loss: 0.050297  [ 1400/ 3386]
loss: 0.053100  [ 1500/ 3386]
loss: 0.032937  [ 1600/ 3386]
loss: 0.030869  [ 1700/ 3386]
loss: 0.142536  [ 1800/ 3386]
loss: 0.359534  [ 1900/ 3386]
loss: 0.033797  [ 2000/ 3386]
loss: 0.092396  [ 2100/ 3386]
loss: 0.428824  [ 2200/ 3386]
loss: 0.086062  [ 2300/ 3386]
loss: 0.071468  [ 2400/ 3386]
loss: 0.059438  [ 2500/ 3386]
loss: 0.078496  [ 2600/ 3386]
loss: 0.198991  [ 2700/ 3386]
loss: 0.076130  [ 2800/ 3386]
loss: 0.059883  [ 2900/ 3386]
loss: 0.014952  [ 3000/ 3386]
loss: 0.118827  [ 3100/ 3386]
loss: 0.058712  [ 3200/ 3386]
loss: 0.096748  [ 3300/ 3386]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3386
First Spike after testing: [0.13642956 0.19057727]
[0 2 0 ... 2 0 1]
[1 1 1 ... 1 1 2]
Cluster 0 Occurrences: 1079; KMEANS: 620
Cluster 1 Occurrences: 1158; KMEANS: 2252
Cluster 2 Occurrences: 1149; KMEANS: 514
Centroids: [[0.17754419, 0.48008025], [-4.199361, -3.4224384], [1.0277642, 1.0516815]]
Centroids: [[-3.2964396, -2.6026108], [0.6093434, 0.7697283], [-5.4841194, -4.584833]]
Contingency Matrix: 
[[   0 1079    0]
 [ 613   32  513]
 [   7 1141    1]]
[[0, -1, 0], [613, -1, 513], [-1, -1, -1]]
[[-1, -1, 0], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 1: 0, 0: 2}
New Contingency Matrix: 
[[   0    0 1079]
 [ 513  613   32]
 [   1    7 1141]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [0, 613, 1141], Sum: 1754
All_Elements: [0, 0, 1079, 513, 613, 32, 1, 7, 1141], Sum: 3386
Accuracy: 0.5180153573538098
Done!
