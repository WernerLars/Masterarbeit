Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Difficult1_noise020.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_02_00
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000174879CB780>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
<torch.utils.data.dataloader.DataLoader object at 0x00000174870F24A8>
Epoch 1
-------------------------------
loss: 0.206832  [    0/ 3414]
loss: 0.079657  [  100/ 3414]
loss: 0.027302  [  200/ 3414]
loss: 0.044827  [  300/ 3414]
loss: 0.055977  [  400/ 3414]
loss: 0.063534  [  500/ 3414]
loss: 0.040745  [  600/ 3414]
loss: 0.053491  [  700/ 3414]
loss: 0.063681  [  800/ 3414]
loss: 0.041698  [  900/ 3414]
loss: 0.022006  [ 1000/ 3414]
loss: 0.023237  [ 1100/ 3414]
loss: 0.034456  [ 1200/ 3414]
loss: 0.033349  [ 1300/ 3414]
loss: 0.020280  [ 1400/ 3414]
loss: 0.031907  [ 1500/ 3414]
loss: 0.021933  [ 1600/ 3414]
loss: 0.015482  [ 1700/ 3414]
loss: 0.031408  [ 1800/ 3414]
loss: 0.034868  [ 1900/ 3414]
loss: 0.023117  [ 2000/ 3414]
loss: 0.046127  [ 2100/ 3414]
loss: 0.041074  [ 2200/ 3414]
loss: 0.035180  [ 2300/ 3414]
loss: 0.008002  [ 2400/ 3414]
loss: 0.164122  [ 2500/ 3414]
loss: 0.022092  [ 2600/ 3414]
loss: 0.011814  [ 2700/ 3414]
loss: 0.019489  [ 2800/ 3414]
loss: 0.041800  [ 2900/ 3414]
loss: 0.052531  [ 3000/ 3414]
loss: 0.039333  [ 3100/ 3414]
loss: 0.018718  [ 3200/ 3414]
loss: 0.012238  [ 3300/ 3414]
loss: 0.027438  [ 3400/ 3414]
Epoch 2
-------------------------------
loss: 0.062354  [    0/ 3414]
loss: 0.029126  [  100/ 3414]
loss: 0.008380  [  200/ 3414]
loss: 0.048971  [  300/ 3414]
loss: 0.018319  [  400/ 3414]
loss: 0.042315  [  500/ 3414]
loss: 0.025019  [  600/ 3414]
loss: 0.042635  [  700/ 3414]
loss: 0.050226  [  800/ 3414]
loss: 0.027198  [  900/ 3414]
loss: 0.016272  [ 1000/ 3414]
loss: 0.022874  [ 1100/ 3414]
loss: 0.006501  [ 1200/ 3414]
loss: 0.031198  [ 1300/ 3414]
loss: 0.018676  [ 1400/ 3414]
loss: 0.026967  [ 1500/ 3414]
loss: 0.010322  [ 1600/ 3414]
loss: 0.009903  [ 1700/ 3414]
loss: 0.030245  [ 1800/ 3414]
loss: 0.022161  [ 1900/ 3414]
loss: 0.031347  [ 2000/ 3414]
loss: 0.036450  [ 2100/ 3414]
loss: 0.040018  [ 2200/ 3414]
loss: 0.035761  [ 2300/ 3414]
loss: 0.008127  [ 2400/ 3414]
loss: 0.164458  [ 2500/ 3414]
loss: 0.024337  [ 2600/ 3414]
loss: 0.013376  [ 2700/ 3414]
loss: 0.014023  [ 2800/ 3414]
loss: 0.041321  [ 2900/ 3414]
loss: 0.047084  [ 3000/ 3414]
loss: 0.036010  [ 3100/ 3414]
loss: 0.020136  [ 3200/ 3414]
loss: 0.012122  [ 3300/ 3414]
loss: 0.026237  [ 3400/ 3414]
Epoch 3
-------------------------------
loss: 0.049078  [    0/ 3414]
loss: 0.029800  [  100/ 3414]
loss: 0.008279  [  200/ 3414]
loss: 0.048689  [  300/ 3414]
loss: 0.015916  [  400/ 3414]
loss: 0.043178  [  500/ 3414]
loss: 0.027501  [  600/ 3414]
loss: 0.036935  [  700/ 3414]
loss: 0.051402  [  800/ 3414]
loss: 0.024295  [  900/ 3414]
loss: 0.016516  [ 1000/ 3414]
loss: 0.023134  [ 1100/ 3414]
loss: 0.006403  [ 1200/ 3414]
loss: 0.031766  [ 1300/ 3414]
loss: 0.018677  [ 1400/ 3414]
loss: 0.026785  [ 1500/ 3414]
loss: 0.010315  [ 1600/ 3414]
loss: 0.010730  [ 1700/ 3414]
loss: 0.029583  [ 1800/ 3414]
loss: 0.021439  [ 1900/ 3414]
loss: 0.032427  [ 2000/ 3414]
loss: 0.035114  [ 2100/ 3414]
loss: 0.039659  [ 2200/ 3414]
loss: 0.036047  [ 2300/ 3414]
loss: 0.008182  [ 2400/ 3414]
loss: 0.163001  [ 2500/ 3414]
loss: 0.024255  [ 2600/ 3414]
loss: 0.013455  [ 2700/ 3414]
loss: 0.013166  [ 2800/ 3414]
loss: 0.041274  [ 2900/ 3414]
loss: 0.046418  [ 3000/ 3414]
loss: 0.034822  [ 3100/ 3414]
loss: 0.020418  [ 3200/ 3414]
loss: 0.011946  [ 3300/ 3414]
loss: 0.025609  [ 3400/ 3414]
Epoch 4
-------------------------------
loss: 0.045888  [    0/ 3414]
loss: 0.030113  [  100/ 3414]
loss: 0.008256  [  200/ 3414]
loss: 0.048428  [  300/ 3414]
loss: 0.015602  [  400/ 3414]
loss: 0.043684  [  500/ 3414]
loss: 0.028141  [  600/ 3414]
loss: 0.035367  [  700/ 3414]
loss: 0.052079  [  800/ 3414]
loss: 0.023748  [  900/ 3414]
loss: 0.016467  [ 1000/ 3414]
loss: 0.022885  [ 1100/ 3414]
loss: 0.006301  [ 1200/ 3414]
loss: 0.031961  [ 1300/ 3414]
loss: 0.018714  [ 1400/ 3414]
loss: 0.026646  [ 1500/ 3414]
loss: 0.010276  [ 1600/ 3414]
loss: 0.011011  [ 1700/ 3414]
loss: 0.029294  [ 1800/ 3414]
loss: 0.021248  [ 1900/ 3414]
loss: 0.032774  [ 2000/ 3414]
loss: 0.034600  [ 2100/ 3414]
loss: 0.038754  [ 2200/ 3414]
loss: 0.036333  [ 2300/ 3414]
loss: 0.008169  [ 2400/ 3414]
loss: 0.161462  [ 2500/ 3414]
loss: 0.024079  [ 2600/ 3414]
loss: 0.013357  [ 2700/ 3414]
loss: 0.012862  [ 2800/ 3414]
loss: 0.041605  [ 2900/ 3414]
loss: 0.046312  [ 3000/ 3414]
loss: 0.034178  [ 3100/ 3414]
loss: 0.020768  [ 3200/ 3414]
loss: 0.011840  [ 3300/ 3414]
loss: 0.025512  [ 3400/ 3414]
Epoch 5
-------------------------------
loss: 0.043359  [    0/ 3414]
loss: 0.030255  [  100/ 3414]
loss: 0.008257  [  200/ 3414]
loss: 0.048259  [  300/ 3414]
loss: 0.015501  [  400/ 3414]
loss: 0.043920  [  500/ 3414]
loss: 0.028604  [  600/ 3414]
loss: 0.034572  [  700/ 3414]
loss: 0.052372  [  800/ 3414]
loss: 0.023629  [  900/ 3414]
loss: 0.016344  [ 1000/ 3414]
loss: 0.022730  [ 1100/ 3414]
loss: 0.006100  [ 1200/ 3414]
loss: 0.031958  [ 1300/ 3414]
loss: 0.018828  [ 1400/ 3414]
loss: 0.026589  [ 1500/ 3414]
loss: 0.010211  [ 1600/ 3414]
loss: 0.010456  [ 1700/ 3414]
loss: 0.029003  [ 1800/ 3414]
loss: 0.021046  [ 1900/ 3414]
loss: 0.032830  [ 2000/ 3414]
loss: 0.034730  [ 2100/ 3414]
loss: 0.038222  [ 2200/ 3414]
loss: 0.036525  [ 2300/ 3414]
loss: 0.008204  [ 2400/ 3414]
loss: 0.160434  [ 2500/ 3414]
loss: 0.023893  [ 2600/ 3414]
loss: 0.013278  [ 2700/ 3414]
loss: 0.012799  [ 2800/ 3414]
loss: 0.041597  [ 2900/ 3414]
loss: 0.046503  [ 3000/ 3414]
loss: 0.033582  [ 3100/ 3414]
loss: 0.021062  [ 3200/ 3414]
loss: 0.011784  [ 3300/ 3414]
loss: 0.025237  [ 3400/ 3414]
Epoch 6
-------------------------------
loss: 0.043376  [    0/ 3414]
loss: 0.030431  [  100/ 3414]
loss: 0.008270  [  200/ 3414]
loss: 0.048271  [  300/ 3414]
loss: 0.015406  [  400/ 3414]
loss: 0.044146  [  500/ 3414]
loss: 0.028804  [  600/ 3414]
loss: 0.034227  [  700/ 3414]
loss: 0.052600  [  800/ 3414]
loss: 0.023674  [  900/ 3414]
loss: 0.016202  [ 1000/ 3414]
loss: 0.022537  [ 1100/ 3414]
loss: 0.005965  [ 1200/ 3414]
loss: 0.031906  [ 1300/ 3414]
loss: 0.018826  [ 1400/ 3414]
loss: 0.026463  [ 1500/ 3414]
loss: 0.010176  [ 1600/ 3414]
loss: 0.010226  [ 1700/ 3414]
loss: 0.028767  [ 1800/ 3414]
loss: 0.020713  [ 1900/ 3414]
loss: 0.032936  [ 2000/ 3414]
loss: 0.034826  [ 2100/ 3414]
loss: 0.037434  [ 2200/ 3414]
loss: 0.036779  [ 2300/ 3414]
loss: 0.008132  [ 2400/ 3414]
loss: 0.159857  [ 2500/ 3414]
loss: 0.023739  [ 2600/ 3414]
loss: 0.013290  [ 2700/ 3414]
loss: 0.012696  [ 2800/ 3414]
loss: 0.041727  [ 2900/ 3414]
loss: 0.046279  [ 3000/ 3414]
loss: 0.032997  [ 3100/ 3414]
loss: 0.020852  [ 3200/ 3414]
loss: 0.011608  [ 3300/ 3414]
loss: 0.025144  [ 3400/ 3414]
Epoch 7
-------------------------------
loss: 0.043367  [    0/ 3414]
loss: 0.030756  [  100/ 3414]
loss: 0.008230  [  200/ 3414]
loss: 0.048275  [  300/ 3414]
loss: 0.015500  [  400/ 3414]
loss: 0.044318  [  500/ 3414]
loss: 0.028919  [  600/ 3414]
loss: 0.033787  [  700/ 3414]
loss: 0.052916  [  800/ 3414]
loss: 0.023996  [  900/ 3414]
loss: 0.016060  [ 1000/ 3414]
loss: 0.022353  [ 1100/ 3414]
loss: 0.005957  [ 1200/ 3414]
loss: 0.031702  [ 1300/ 3414]
loss: 0.018853  [ 1400/ 3414]
loss: 0.026234  [ 1500/ 3414]
loss: 0.010053  [ 1600/ 3414]
loss: 0.010162  [ 1700/ 3414]
loss: 0.028545  [ 1800/ 3414]
loss: 0.020487  [ 1900/ 3414]
loss: 0.032780  [ 2000/ 3414]
loss: 0.035193  [ 2100/ 3414]
loss: 0.037884  [ 2200/ 3414]
loss: 0.036878  [ 2300/ 3414]
loss: 0.008066  [ 2400/ 3414]
loss: 0.159687  [ 2500/ 3414]
loss: 0.023763  [ 2600/ 3414]
loss: 0.013199  [ 2700/ 3414]
loss: 0.012905  [ 2800/ 3414]
loss: 0.042787  [ 2900/ 3414]
loss: 0.047186  [ 3000/ 3414]
loss: 0.032561  [ 3100/ 3414]
loss: 0.021163  [ 3200/ 3414]
loss: 0.011478  [ 3300/ 3414]
loss: 0.025002  [ 3400/ 3414]
Epoch 8
-------------------------------
loss: 0.040547  [    0/ 3414]
loss: 0.030946  [  100/ 3414]
loss: 0.008186  [  200/ 3414]
loss: 0.048141  [  300/ 3414]
loss: 0.015635  [  400/ 3414]
loss: 0.044349  [  500/ 3414]
loss: 0.029161  [  600/ 3414]
loss: 0.033101  [  700/ 3414]
loss: 0.051981  [  800/ 3414]
loss: 0.023951  [  900/ 3414]
loss: 0.015875  [ 1000/ 3414]
loss: 0.022179  [ 1100/ 3414]
loss: 0.006248  [ 1200/ 3414]
loss: 0.031573  [ 1300/ 3414]
loss: 0.018892  [ 1400/ 3414]
loss: 0.026106  [ 1500/ 3414]
loss: 0.009999  [ 1600/ 3414]
loss: 0.009719  [ 1700/ 3414]
loss: 0.028420  [ 1800/ 3414]
loss: 0.020024  [ 1900/ 3414]
loss: 0.032866  [ 2000/ 3414]
loss: 0.035185  [ 2100/ 3414]
loss: 0.037438  [ 2200/ 3414]
loss: 0.036906  [ 2300/ 3414]
loss: 0.008041  [ 2400/ 3414]
loss: 0.159399  [ 2500/ 3414]
loss: 0.023931  [ 2600/ 3414]
loss: 0.013307  [ 2700/ 3414]
loss: 0.012528  [ 2800/ 3414]
loss: 0.042820  [ 2900/ 3414]
loss: 0.047191  [ 3000/ 3414]
loss: 0.031858  [ 3100/ 3414]
loss: 0.021111  [ 3200/ 3414]
loss: 0.011259  [ 3300/ 3414]
loss: 0.024579  [ 3400/ 3414]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3414
First Spike after testing: [-0.63349235 -0.91971564]
[1 1 0 ... 0 0 2]
[0 0 2 ... 1 0 2]
Cluster 0 Occurrences: 1136; KMEANS: 1234
Cluster 1 Occurrences: 1099; KMEANS: 1157
Cluster 2 Occurrences: 1179; KMEANS: 1023
Centroids: [[-0.119654804, -0.16036789], [0.027534783, -0.20308779], [0.17179538, 0.24122941]]
Centroids: [[0.12920931, -0.40630513], [-0.24586636, -0.02472194], [0.21691369, 0.39982584]]
Contingency Matrix: 
[[444 567 125]
 [572 375 152]
 [218 215 746]]
[[444, 567, -1], [572, 375, -1], [-1, -1, -1]]
[[-1, 567, -1], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 1: 0, 0: 1}
New Contingency Matrix: 
[[567 444 125]
 [375 572 152]
 [215 218 746]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [567, 572, 746], Sum: 1885
All_Elements: [567, 444, 125, 375, 572, 152, 215, 218, 746], Sum: 3414
Accuracy: 0.5521382542472173
Done!
