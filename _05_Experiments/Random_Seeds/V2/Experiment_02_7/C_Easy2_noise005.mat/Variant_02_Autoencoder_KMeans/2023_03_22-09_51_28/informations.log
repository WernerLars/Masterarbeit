Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Easy2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_51_28
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000174526722E8>
Sampling rate: 24000.0
Raw: [ 0.11862069  0.1123084   0.10401825 ... -0.10219323 -0.10268373
 -0.08956559]
Times: [    346     799    1005 ... 1436867 1437273 1437800]
Cluster: [3 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3410
First aligned Spike Frame: [ 2.05661766e-03  8.27536867e-03  1.66427268e-02  2.31246655e-02
  2.28936935e-02  1.99169368e-02  2.25281834e-02  3.37605443e-02
  4.94182133e-02  6.24484568e-02  8.42111946e-02  1.71357846e-01
  3.88441746e-01  6.99052305e-01  9.59509287e-01  1.03608873e+00
  9.29169963e-01  7.55567481e-01  6.10726415e-01  5.06818519e-01
  4.23878029e-01  3.55610047e-01  3.01970228e-01  2.53702042e-01
  1.98274486e-01  1.32802904e-01  6.40690121e-02  7.96454927e-04
 -5.66201776e-02 -1.11669131e-01 -1.62581026e-01 -2.01746625e-01
 -2.23071447e-01 -2.29516190e-01 -2.30160694e-01 -2.27148529e-01
 -2.18080531e-01 -2.04276810e-01 -1.90750996e-01 -1.81098693e-01
 -1.72421418e-01 -1.61640218e-01 -1.48460304e-01 -1.32332846e-01
 -1.13338953e-01 -9.43725979e-02 -7.56249106e-02]
Cluster 0, Occurrences: 1130
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1167
<torch.utils.data.dataloader.DataLoader object at 0x0000017452F2BEF0>
Epoch 1
-------------------------------
loss: 0.137586  [    0/ 3410]
loss: 0.061714  [  100/ 3410]
loss: 0.011648  [  200/ 3410]
loss: 0.021744  [  300/ 3410]
loss: 0.003079  [  400/ 3410]
loss: 0.003095  [  500/ 3410]
loss: 0.001389  [  600/ 3410]
loss: 0.004959  [  700/ 3410]
loss: 0.010536  [  800/ 3410]
loss: 0.013325  [  900/ 3410]
loss: 0.020427  [ 1000/ 3410]
loss: 0.004039  [ 1100/ 3410]
loss: 0.004171  [ 1200/ 3410]
loss: 0.006304  [ 1300/ 3410]
loss: 0.004957  [ 1400/ 3410]
loss: 0.002211  [ 1500/ 3410]
loss: 0.001960  [ 1600/ 3410]
loss: 0.008147  [ 1700/ 3410]
loss: 0.006167  [ 1800/ 3410]
loss: 0.001461  [ 1900/ 3410]
loss: 0.050267  [ 2000/ 3410]
loss: 0.004413  [ 2100/ 3410]
loss: 0.027716  [ 2200/ 3410]
loss: 0.002305  [ 2300/ 3410]
loss: 0.002774  [ 2400/ 3410]
loss: 0.088073  [ 2500/ 3410]
loss: 0.003789  [ 2600/ 3410]
loss: 0.003850  [ 2700/ 3410]
loss: 0.001063  [ 2800/ 3410]
loss: 0.005851  [ 2900/ 3410]
loss: 0.002424  [ 3000/ 3410]
loss: 0.000631  [ 3100/ 3410]
loss: 0.003561  [ 3200/ 3410]
loss: 0.001593  [ 3300/ 3410]
loss: 0.001210  [ 3400/ 3410]
Epoch 2
-------------------------------
loss: 0.000428  [    0/ 3410]
loss: 0.001696  [  100/ 3410]
loss: 0.004514  [  200/ 3410]
loss: 0.003170  [  300/ 3410]
loss: 0.002358  [  400/ 3410]
loss: 0.003228  [  500/ 3410]
loss: 0.000787  [  600/ 3410]
loss: 0.005963  [  700/ 3410]
loss: 0.005039  [  800/ 3410]
loss: 0.002532  [  900/ 3410]
loss: 0.004393  [ 1000/ 3410]
loss: 0.002236  [ 1100/ 3410]
loss: 0.002463  [ 1200/ 3410]
loss: 0.005396  [ 1300/ 3410]
loss: 0.001235  [ 1400/ 3410]
loss: 0.000824  [ 1500/ 3410]
loss: 0.001493  [ 1600/ 3410]
loss: 0.002661  [ 1700/ 3410]
loss: 0.006267  [ 1800/ 3410]
loss: 0.001044  [ 1900/ 3410]
loss: 0.049980  [ 2000/ 3410]
loss: 0.003276  [ 2100/ 3410]
loss: 0.025384  [ 2200/ 3410]
loss: 0.003687  [ 2300/ 3410]
loss: 0.003620  [ 2400/ 3410]
loss: 0.045842  [ 2500/ 3410]
loss: 0.004700  [ 2600/ 3410]
loss: 0.003876  [ 2700/ 3410]
loss: 0.000667  [ 2800/ 3410]
loss: 0.005231  [ 2900/ 3410]
loss: 0.002497  [ 3000/ 3410]
loss: 0.000547  [ 3100/ 3410]
loss: 0.003069  [ 3200/ 3410]
loss: 0.001379  [ 3300/ 3410]
loss: 0.001460  [ 3400/ 3410]
Epoch 3
-------------------------------
loss: 0.000479  [    0/ 3410]
loss: 0.001932  [  100/ 3410]
loss: 0.005770  [  200/ 3410]
loss: 0.003455  [  300/ 3410]
loss: 0.002206  [  400/ 3410]
loss: 0.004512  [  500/ 3410]
loss: 0.000636  [  600/ 3410]
loss: 0.005854  [  700/ 3410]
loss: 0.004286  [  800/ 3410]
loss: 0.002643  [  900/ 3410]
loss: 0.003224  [ 1000/ 3410]
loss: 0.002138  [ 1100/ 3410]
loss: 0.002019  [ 1200/ 3410]
loss: 0.004961  [ 1300/ 3410]
loss: 0.001411  [ 1400/ 3410]
loss: 0.000692  [ 1500/ 3410]
loss: 0.001495  [ 1600/ 3410]
loss: 0.002875  [ 1700/ 3410]
loss: 0.005440  [ 1800/ 3410]
loss: 0.001082  [ 1900/ 3410]
loss: 0.048172  [ 2000/ 3410]
loss: 0.003236  [ 2100/ 3410]
loss: 0.023230  [ 2200/ 3410]
loss: 0.003690  [ 2300/ 3410]
loss: 0.002927  [ 2400/ 3410]
loss: 0.046255  [ 2500/ 3410]
loss: 0.005937  [ 2600/ 3410]
loss: 0.004095  [ 2700/ 3410]
loss: 0.000565  [ 2800/ 3410]
loss: 0.004767  [ 2900/ 3410]
loss: 0.002625  [ 3000/ 3410]
loss: 0.000589  [ 3100/ 3410]
loss: 0.002776  [ 3200/ 3410]
loss: 0.001354  [ 3300/ 3410]
loss: 0.001523  [ 3400/ 3410]
Epoch 4
-------------------------------
loss: 0.000426  [    0/ 3410]
loss: 0.002137  [  100/ 3410]
loss: 0.005167  [  200/ 3410]
loss: 0.003441  [  300/ 3410]
loss: 0.002141  [  400/ 3410]
loss: 0.004302  [  500/ 3410]
loss: 0.000630  [  600/ 3410]
loss: 0.005641  [  700/ 3410]
loss: 0.003525  [  800/ 3410]
loss: 0.002142  [  900/ 3410]
loss: 0.003231  [ 1000/ 3410]
loss: 0.001946  [ 1100/ 3410]
loss: 0.002039  [ 1200/ 3410]
loss: 0.004575  [ 1300/ 3410]
loss: 0.001621  [ 1400/ 3410]
loss: 0.000552  [ 1500/ 3410]
loss: 0.001517  [ 1600/ 3410]
loss: 0.003415  [ 1700/ 3410]
loss: 0.004706  [ 1800/ 3410]
loss: 0.001158  [ 1900/ 3410]
loss: 0.046752  [ 2000/ 3410]
loss: 0.003105  [ 2100/ 3410]
loss: 0.022641  [ 2200/ 3410]
loss: 0.002983  [ 2300/ 3410]
loss: 0.002577  [ 2400/ 3410]
loss: 0.049642  [ 2500/ 3410]
loss: 0.006068  [ 2600/ 3410]
loss: 0.004110  [ 2700/ 3410]
loss: 0.000567  [ 2800/ 3410]
loss: 0.005111  [ 2900/ 3410]
loss: 0.002474  [ 3000/ 3410]
loss: 0.000594  [ 3100/ 3410]
loss: 0.001937  [ 3200/ 3410]
loss: 0.001507  [ 3300/ 3410]
loss: 0.001457  [ 3400/ 3410]
Epoch 5
-------------------------------
loss: 0.000406  [    0/ 3410]
loss: 0.002631  [  100/ 3410]
loss: 0.004505  [  200/ 3410]
loss: 0.003528  [  300/ 3410]
loss: 0.002105  [  400/ 3410]
loss: 0.004844  [  500/ 3410]
loss: 0.000684  [  600/ 3410]
loss: 0.005294  [  700/ 3410]
loss: 0.003160  [  800/ 3410]
loss: 0.001619  [  900/ 3410]
loss: 0.004134  [ 1000/ 3410]
loss: 0.002061  [ 1100/ 3410]
loss: 0.002310  [ 1200/ 3410]
loss: 0.004557  [ 1300/ 3410]
loss: 0.001804  [ 1400/ 3410]
loss: 0.000493  [ 1500/ 3410]
loss: 0.001382  [ 1600/ 3410]
loss: 0.003329  [ 1700/ 3410]
loss: 0.004567  [ 1800/ 3410]
loss: 0.001187  [ 1900/ 3410]
loss: 0.046171  [ 2000/ 3410]
loss: 0.002893  [ 2100/ 3410]
loss: 0.021558  [ 2200/ 3410]
loss: 0.002777  [ 2300/ 3410]
loss: 0.002253  [ 2400/ 3410]
loss: 0.049701  [ 2500/ 3410]
loss: 0.006248  [ 2600/ 3410]
loss: 0.004040  [ 2700/ 3410]
loss: 0.000607  [ 2800/ 3410]
loss: 0.005283  [ 2900/ 3410]
loss: 0.002324  [ 3000/ 3410]
loss: 0.000543  [ 3100/ 3410]
loss: 0.001369  [ 3200/ 3410]
loss: 0.001404  [ 3300/ 3410]
loss: 0.001416  [ 3400/ 3410]
Epoch 6
-------------------------------
loss: 0.000349  [    0/ 3410]
loss: 0.003347  [  100/ 3410]
loss: 0.004257  [  200/ 3410]
loss: 0.003704  [  300/ 3410]
loss: 0.002106  [  400/ 3410]
loss: 0.004267  [  500/ 3410]
loss: 0.000758  [  600/ 3410]
loss: 0.005100  [  700/ 3410]
loss: 0.003583  [  800/ 3410]
loss: 0.001544  [  900/ 3410]
loss: 0.004017  [ 1000/ 3410]
loss: 0.001915  [ 1100/ 3410]
loss: 0.001698  [ 1200/ 3410]
loss: 0.004572  [ 1300/ 3410]
loss: 0.001682  [ 1400/ 3410]
loss: 0.000563  [ 1500/ 3410]
loss: 0.001350  [ 1600/ 3410]
loss: 0.002888  [ 1700/ 3410]
loss: 0.004702  [ 1800/ 3410]
loss: 0.001217  [ 1900/ 3410]
loss: 0.045874  [ 2000/ 3410]
loss: 0.003223  [ 2100/ 3410]
loss: 0.020296  [ 2200/ 3410]
loss: 0.002822  [ 2300/ 3410]
loss: 0.002279  [ 2400/ 3410]
loss: 0.052760  [ 2500/ 3410]
loss: 0.005490  [ 2600/ 3410]
loss: 0.003957  [ 2700/ 3410]
loss: 0.000627  [ 2800/ 3410]
loss: 0.005062  [ 2900/ 3410]
loss: 0.002047  [ 3000/ 3410]
loss: 0.000583  [ 3100/ 3410]
loss: 0.001631  [ 3200/ 3410]
loss: 0.001331  [ 3300/ 3410]
loss: 0.001416  [ 3400/ 3410]
Epoch 7
-------------------------------
loss: 0.000335  [    0/ 3410]
loss: 0.002830  [  100/ 3410]
loss: 0.004313  [  200/ 3410]
loss: 0.003623  [  300/ 3410]
loss: 0.002120  [  400/ 3410]
loss: 0.004375  [  500/ 3410]
loss: 0.000784  [  600/ 3410]
loss: 0.004664  [  700/ 3410]
loss: 0.003726  [  800/ 3410]
loss: 0.001833  [  900/ 3410]
loss: 0.003876  [ 1000/ 3410]
loss: 0.001789  [ 1100/ 3410]
loss: 0.001372  [ 1200/ 3410]
loss: 0.004548  [ 1300/ 3410]
loss: 0.001635  [ 1400/ 3410]
loss: 0.000558  [ 1500/ 3410]
loss: 0.001339  [ 1600/ 3410]
loss: 0.002480  [ 1700/ 3410]
loss: 0.004792  [ 1800/ 3410]
loss: 0.001251  [ 1900/ 3410]
loss: 0.045593  [ 2000/ 3410]
loss: 0.003344  [ 2100/ 3410]
loss: 0.019212  [ 2200/ 3410]
loss: 0.002800  [ 2300/ 3410]
loss: 0.002055  [ 2400/ 3410]
loss: 0.055356  [ 2500/ 3410]
loss: 0.004566  [ 2600/ 3410]
loss: 0.003898  [ 2700/ 3410]
loss: 0.000645  [ 2800/ 3410]
loss: 0.005051  [ 2900/ 3410]
loss: 0.001975  [ 3000/ 3410]
loss: 0.000580  [ 3100/ 3410]
loss: 0.001879  [ 3200/ 3410]
loss: 0.001386  [ 3300/ 3410]
loss: 0.001373  [ 3400/ 3410]
Epoch 8
-------------------------------
loss: 0.000254  [    0/ 3410]
loss: 0.002927  [  100/ 3410]
loss: 0.004434  [  200/ 3410]
loss: 0.003623  [  300/ 3410]
loss: 0.002141  [  400/ 3410]
loss: 0.004698  [  500/ 3410]
loss: 0.000781  [  600/ 3410]
loss: 0.004370  [  700/ 3410]
loss: 0.003617  [  800/ 3410]
loss: 0.001855  [  900/ 3410]
loss: 0.003635  [ 1000/ 3410]
loss: 0.001737  [ 1100/ 3410]
loss: 0.001143  [ 1200/ 3410]
loss: 0.004411  [ 1300/ 3410]
loss: 0.001675  [ 1400/ 3410]
loss: 0.000540  [ 1500/ 3410]
loss: 0.001338  [ 1600/ 3410]
loss: 0.002500  [ 1700/ 3410]
loss: 0.004911  [ 1800/ 3410]
loss: 0.001237  [ 1900/ 3410]
loss: 0.045339  [ 2000/ 3410]
loss: 0.003428  [ 2100/ 3410]
loss: 0.018254  [ 2200/ 3410]
loss: 0.002782  [ 2300/ 3410]
loss: 0.002019  [ 2400/ 3410]
loss: 0.044443  [ 2500/ 3410]
loss: 0.004267  [ 2600/ 3410]
loss: 0.004000  [ 2700/ 3410]
loss: 0.000676  [ 2800/ 3410]
loss: 0.005152  [ 2900/ 3410]
loss: 0.002100  [ 3000/ 3410]
loss: 0.000593  [ 3100/ 3410]
loss: 0.002238  [ 3200/ 3410]
loss: 0.001457  [ 3300/ 3410]
loss: 0.001346  [ 3400/ 3410]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3410
First Spike after testing: [1.4454454  0.41765454]
[2 2 2 ... 2 0 2]
[0 0 0 ... 0 1 0]
Cluster 0 Occurrences: 1130; KMEANS: 1170
Cluster 1 Occurrences: 1113; KMEANS: 1155
Cluster 2 Occurrences: 1167; KMEANS: 1085
Centroids: [[-0.757709, -1.408794], [-0.100195855, -0.5855988], [1.3698765, 0.44914082]]
Centroids: [[1.3706969, 0.44574246], [-0.78652596, -1.409333], [-0.05931907, -0.565254]]
Contingency Matrix: 
[[   0 1113   17]
 [   6   42 1065]
 [1164    0    3]]
[[-1, 1113, 17], [-1, 42, 1065], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1065], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1113   17    0]
 [  42 1065    6]
 [   0    3 1164]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1113, 1065, 1164], Sum: 3342
All_Elements: [1113, 17, 0, 42, 1065, 6, 0, 3, 1164], Sum: 3410
Accuracy: 0.980058651026393
Done!
