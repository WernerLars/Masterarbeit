Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Easy1_noise035.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_48_57
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001741A082EB8>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
<torch.utils.data.dataloader.DataLoader object at 0x0000017452F74128>
Epoch 1
-------------------------------
loss: 0.311126  [    0/ 3534]
loss: 0.354360  [  100/ 3534]
loss: 0.150575  [  200/ 3534]
loss: 0.271444  [  300/ 3534]
loss: 0.164625  [  400/ 3534]
loss: 0.179662  [  500/ 3534]
loss: 0.055363  [  600/ 3534]
loss: 0.060282  [  700/ 3534]
loss: 0.131146  [  800/ 3534]
loss: 0.043747  [  900/ 3534]
loss: 0.114263  [ 1000/ 3534]
loss: 0.025853  [ 1100/ 3534]
loss: 0.042459  [ 1200/ 3534]
loss: 0.064748  [ 1300/ 3534]
loss: 0.018979  [ 1400/ 3534]
loss: 0.045616  [ 1500/ 3534]
loss: 0.146934  [ 1600/ 3534]
loss: 0.055338  [ 1700/ 3534]
loss: 0.167253  [ 1800/ 3534]
loss: 0.040216  [ 1900/ 3534]
loss: 0.047106  [ 2000/ 3534]
loss: 0.031817  [ 2100/ 3534]
loss: 0.044034  [ 2200/ 3534]
loss: 0.121668  [ 2300/ 3534]
loss: 0.058756  [ 2400/ 3534]
loss: 0.098671  [ 2500/ 3534]
loss: 0.059036  [ 2600/ 3534]
loss: 0.045361  [ 2700/ 3534]
loss: 0.067141  [ 2800/ 3534]
loss: 0.022485  [ 2900/ 3534]
loss: 0.135608  [ 3000/ 3534]
loss: 0.068179  [ 3100/ 3534]
loss: 0.122242  [ 3200/ 3534]
loss: 0.180888  [ 3300/ 3534]
loss: 0.042077  [ 3400/ 3534]
loss: 0.071485  [ 3500/ 3534]
Epoch 2
-------------------------------
loss: 0.126309  [    0/ 3534]
loss: 0.058742  [  100/ 3534]
loss: 0.029308  [  200/ 3534]
loss: 0.107096  [  300/ 3534]
loss: 0.215329  [  400/ 3534]
loss: 0.072550  [  500/ 3534]
loss: 0.091127  [  600/ 3534]
loss: 0.073608  [  700/ 3534]
loss: 0.039985  [  800/ 3534]
loss: 0.026032  [  900/ 3534]
loss: 0.045997  [ 1000/ 3534]
loss: 0.022618  [ 1100/ 3534]
loss: 0.056171  [ 1200/ 3534]
loss: 0.054645  [ 1300/ 3534]
loss: 0.008914  [ 1400/ 3534]
loss: 0.028650  [ 1500/ 3534]
loss: 0.158087  [ 1600/ 3534]
loss: 0.063450  [ 1700/ 3534]
loss: 0.055659  [ 1800/ 3534]
loss: 0.031045  [ 1900/ 3534]
loss: 0.036559  [ 2000/ 3534]
loss: 0.035280  [ 2100/ 3534]
loss: 0.054182  [ 2200/ 3534]
loss: 0.119379  [ 2300/ 3534]
loss: 0.056361  [ 2400/ 3534]
loss: 0.096617  [ 2500/ 3534]
loss: 0.057443  [ 2600/ 3534]
loss: 0.034721  [ 2700/ 3534]
loss: 0.065283  [ 2800/ 3534]
loss: 0.021719  [ 2900/ 3534]
loss: 0.130329  [ 3000/ 3534]
loss: 0.061796  [ 3100/ 3534]
loss: 0.123252  [ 3200/ 3534]
loss: 0.154228  [ 3300/ 3534]
loss: 0.039270  [ 3400/ 3534]
loss: 0.071231  [ 3500/ 3534]
Epoch 3
-------------------------------
loss: 0.128484  [    0/ 3534]
loss: 0.063062  [  100/ 3534]
loss: 0.028195  [  200/ 3534]
loss: 0.109858  [  300/ 3534]
loss: 0.214157  [  400/ 3534]
loss: 0.063821  [  500/ 3534]
loss: 0.096599  [  600/ 3534]
loss: 0.074274  [  700/ 3534]
loss: 0.039133  [  800/ 3534]
loss: 0.027615  [  900/ 3534]
loss: 0.045280  [ 1000/ 3534]
loss: 0.022354  [ 1100/ 3534]
loss: 0.044771  [ 1200/ 3534]
loss: 0.054058  [ 1300/ 3534]
loss: 0.008047  [ 1400/ 3534]
loss: 0.026519  [ 1500/ 3534]
loss: 0.160473  [ 1600/ 3534]
loss: 0.060502  [ 1700/ 3534]
loss: 0.044334  [ 1800/ 3534]
loss: 0.030367  [ 1900/ 3534]
loss: 0.037585  [ 2000/ 3534]
loss: 0.035803  [ 2100/ 3534]
loss: 0.055207  [ 2200/ 3534]
loss: 0.120359  [ 2300/ 3534]
loss: 0.057456  [ 2400/ 3534]
loss: 0.093439  [ 2500/ 3534]
loss: 0.057179  [ 2600/ 3534]
loss: 0.034661  [ 2700/ 3534]
loss: 0.056280  [ 2800/ 3534]
loss: 0.023629  [ 2900/ 3534]
loss: 0.129628  [ 3000/ 3534]
loss: 0.061450  [ 3100/ 3534]
loss: 0.124830  [ 3200/ 3534]
loss: 0.150013  [ 3300/ 3534]
loss: 0.039745  [ 3400/ 3534]
loss: 0.071613  [ 3500/ 3534]
Epoch 4
-------------------------------
loss: 0.129494  [    0/ 3534]
loss: 0.064046  [  100/ 3534]
loss: 0.027752  [  200/ 3534]
loss: 0.109990  [  300/ 3534]
loss: 0.213733  [  400/ 3534]
loss: 0.064411  [  500/ 3534]
loss: 0.097490  [  600/ 3534]
loss: 0.075826  [  700/ 3534]
loss: 0.038652  [  800/ 3534]
loss: 0.027621  [  900/ 3534]
loss: 0.044945  [ 1000/ 3534]
loss: 0.022222  [ 1100/ 3534]
loss: 0.043190  [ 1200/ 3534]
loss: 0.053129  [ 1300/ 3534]
loss: 0.007135  [ 1400/ 3534]
loss: 0.025503  [ 1500/ 3534]
loss: 0.163317  [ 1600/ 3534]
loss: 0.058582  [ 1700/ 3534]
loss: 0.037569  [ 1800/ 3534]
loss: 0.030379  [ 1900/ 3534]
loss: 0.038168  [ 2000/ 3534]
loss: 0.036266  [ 2100/ 3534]
loss: 0.054486  [ 2200/ 3534]
loss: 0.121765  [ 2300/ 3534]
loss: 0.058085  [ 2400/ 3534]
loss: 0.092637  [ 2500/ 3534]
loss: 0.055409  [ 2600/ 3534]
loss: 0.034513  [ 2700/ 3534]
loss: 0.048898  [ 2800/ 3534]
loss: 0.022349  [ 2900/ 3534]
loss: 0.130424  [ 3000/ 3534]
loss: 0.061136  [ 3100/ 3534]
loss: 0.126382  [ 3200/ 3534]
loss: 0.141917  [ 3300/ 3534]
loss: 0.039963  [ 3400/ 3534]
loss: 0.071804  [ 3500/ 3534]
Epoch 5
-------------------------------
loss: 0.130571  [    0/ 3534]
loss: 0.062221  [  100/ 3534]
loss: 0.026854  [  200/ 3534]
loss: 0.108644  [  300/ 3534]
loss: 0.209759  [  400/ 3534]
loss: 0.064429  [  500/ 3534]
loss: 0.097603  [  600/ 3534]
loss: 0.076973  [  700/ 3534]
loss: 0.038137  [  800/ 3534]
loss: 0.026961  [  900/ 3534]
loss: 0.044932  [ 1000/ 3534]
loss: 0.022226  [ 1100/ 3534]
loss: 0.039214  [ 1200/ 3534]
loss: 0.052003  [ 1300/ 3534]
loss: 0.007018  [ 1400/ 3534]
loss: 0.024946  [ 1500/ 3534]
loss: 0.165552  [ 1600/ 3534]
loss: 0.056902  [ 1700/ 3534]
loss: 0.035666  [ 1800/ 3534]
loss: 0.029729  [ 1900/ 3534]
loss: 0.038431  [ 2000/ 3534]
loss: 0.036541  [ 2100/ 3534]
loss: 0.053008  [ 2200/ 3534]
loss: 0.123410  [ 2300/ 3534]
loss: 0.057880  [ 2400/ 3534]
loss: 0.091486  [ 2500/ 3534]
loss: 0.053358  [ 2600/ 3534]
loss: 0.034119  [ 2700/ 3534]
loss: 0.042180  [ 2800/ 3534]
loss: 0.023852  [ 2900/ 3534]
loss: 0.127197  [ 3000/ 3534]
loss: 0.060268  [ 3100/ 3534]
loss: 0.126835  [ 3200/ 3534]
loss: 0.134794  [ 3300/ 3534]
loss: 0.040581  [ 3400/ 3534]
loss: 0.071948  [ 3500/ 3534]
Epoch 6
-------------------------------
loss: 0.131044  [    0/ 3534]
loss: 0.059274  [  100/ 3534]
loss: 0.026959  [  200/ 3534]
loss: 0.107083  [  300/ 3534]
loss: 0.208863  [  400/ 3534]
loss: 0.064928  [  500/ 3534]
loss: 0.098399  [  600/ 3534]
loss: 0.077763  [  700/ 3534]
loss: 0.037609  [  800/ 3534]
loss: 0.026488  [  900/ 3534]
loss: 0.043508  [ 1000/ 3534]
loss: 0.022804  [ 1100/ 3534]
loss: 0.037092  [ 1200/ 3534]
loss: 0.050606  [ 1300/ 3534]
loss: 0.007597  [ 1400/ 3534]
loss: 0.024612  [ 1500/ 3534]
loss: 0.169379  [ 1600/ 3534]
loss: 0.055540  [ 1700/ 3534]
loss: 0.037829  [ 1800/ 3534]
loss: 0.029074  [ 1900/ 3534]
loss: 0.039569  [ 2000/ 3534]
loss: 0.036504  [ 2100/ 3534]
loss: 0.050456  [ 2200/ 3534]
loss: 0.125906  [ 2300/ 3534]
loss: 0.057315  [ 2400/ 3534]
loss: 0.091238  [ 2500/ 3534]
loss: 0.050905  [ 2600/ 3534]
loss: 0.033316  [ 2700/ 3534]
loss: 0.035964  [ 2800/ 3534]
loss: 0.025295  [ 2900/ 3534]
loss: 0.122013  [ 3000/ 3534]
loss: 0.059298  [ 3100/ 3534]
loss: 0.125695  [ 3200/ 3534]
loss: 0.123889  [ 3300/ 3534]
loss: 0.040480  [ 3400/ 3534]
loss: 0.071945  [ 3500/ 3534]
Epoch 7
-------------------------------
loss: 0.131152  [    0/ 3534]
loss: 0.045063  [  100/ 3534]
loss: 0.026965  [  200/ 3534]
loss: 0.106888  [  300/ 3534]
loss: 0.201194  [  400/ 3534]
loss: 0.065319  [  500/ 3534]
loss: 0.095669  [  600/ 3534]
loss: 0.079166  [  700/ 3534]
loss: 0.037199  [  800/ 3534]
loss: 0.026326  [  900/ 3534]
loss: 0.041761  [ 1000/ 3534]
loss: 0.023424  [ 1100/ 3534]
loss: 0.034930  [ 1200/ 3534]
loss: 0.050232  [ 1300/ 3534]
loss: 0.008348  [ 1400/ 3534]
loss: 0.025604  [ 1500/ 3534]
loss: 0.169364  [ 1600/ 3534]
loss: 0.054198  [ 1700/ 3534]
loss: 0.037919  [ 1800/ 3534]
loss: 0.028573  [ 1900/ 3534]
loss: 0.040259  [ 2000/ 3534]
loss: 0.036510  [ 2100/ 3534]
loss: 0.044853  [ 2200/ 3534]
loss: 0.130094  [ 2300/ 3534]
loss: 0.056992  [ 2400/ 3534]
loss: 0.091489  [ 2500/ 3534]
loss: 0.050902  [ 2600/ 3534]
loss: 0.031903  [ 2700/ 3534]
loss: 0.032905  [ 2800/ 3534]
loss: 0.027381  [ 2900/ 3534]
loss: 0.119920  [ 3000/ 3534]
loss: 0.056080  [ 3100/ 3534]
loss: 0.125316  [ 3200/ 3534]
loss: 0.113596  [ 3300/ 3534]
loss: 0.040420  [ 3400/ 3534]
loss: 0.071811  [ 3500/ 3534]
Epoch 8
-------------------------------
loss: 0.130669  [    0/ 3534]
loss: 0.031346  [  100/ 3534]
loss: 0.026652  [  200/ 3534]
loss: 0.106962  [  300/ 3534]
loss: 0.193946  [  400/ 3534]
loss: 0.061955  [  500/ 3534]
loss: 0.086143  [  600/ 3534]
loss: 0.078844  [  700/ 3534]
loss: 0.037124  [  800/ 3534]
loss: 0.026581  [  900/ 3534]
loss: 0.040728  [ 1000/ 3534]
loss: 0.022584  [ 1100/ 3534]
loss: 0.032080  [ 1200/ 3534]
loss: 0.052283  [ 1300/ 3534]
loss: 0.008636  [ 1400/ 3534]
loss: 0.027420  [ 1500/ 3534]
loss: 0.171786  [ 1600/ 3534]
loss: 0.052540  [ 1700/ 3534]
loss: 0.035292  [ 1800/ 3534]
loss: 0.028747  [ 1900/ 3534]
loss: 0.040027  [ 2000/ 3534]
loss: 0.036401  [ 2100/ 3534]
loss: 0.039664  [ 2200/ 3534]
loss: 0.133944  [ 2300/ 3534]
loss: 0.056851  [ 2400/ 3534]
loss: 0.090945  [ 2500/ 3534]
loss: 0.052761  [ 2600/ 3534]
loss: 0.031555  [ 2700/ 3534]
loss: 0.031832  [ 2800/ 3534]
loss: 0.027865  [ 2900/ 3534]
loss: 0.124595  [ 3000/ 3534]
loss: 0.053765  [ 3100/ 3534]
loss: 0.125883  [ 3200/ 3534]
loss: 0.106143  [ 3300/ 3534]
loss: 0.040041  [ 3400/ 3534]
loss: 0.071376  [ 3500/ 3534]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3534
First Spike after testing: [0.09085875 0.6220845 ]
[0 1 2 ... 2 2 1]
[0 1 0 ... 0 0 2]
Cluster 0 Occurrences: 1208; KMEANS: 2373
Cluster 1 Occurrences: 1137; KMEANS: 587
Cluster 2 Occurrences: 1189; KMEANS: 574
Centroids: [[0.12694305, 0.5505203], [-3.3859663, -3.529626], [1.0493087, 1.3413817]]
Centroids: [[0.6211829, 0.9859587], [-4.2006063, -4.3486476], [-2.5386415, -2.6834095]]
Contingency Matrix: 
[[1208    0    0]
 [  16  587  534]
 [1149    0   40]]
[[-1, -1, -1], [-1, 587, 534], [-1, 0, 40]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 40]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[1208    0    0]
 [  16  587  534]
 [1149    0   40]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1208, 587, 40], Sum: 1835
All_Elements: [1208, 0, 0, 16, 587, 534, 1149, 0, 40], Sum: 3534
Accuracy: 0.5192416525183927
Done!
