Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_39_38
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000174525FD4A8>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x0000017452F74F98>
Epoch 1
-------------------------------
loss: 0.138055  [    0/ 3514]
loss: 0.184072  [  100/ 3514]
loss: 0.061796  [  200/ 3514]
loss: 0.078171  [  300/ 3514]
loss: 0.010204  [  400/ 3514]
loss: 0.009113  [  500/ 3514]
loss: 0.008643  [  600/ 3514]
loss: 0.003266  [  700/ 3514]
loss: 0.006835  [  800/ 3514]
loss: 0.007385  [  900/ 3514]
loss: 0.006636  [ 1000/ 3514]
loss: 0.094130  [ 1100/ 3514]
loss: 0.004737  [ 1200/ 3514]
loss: 0.002087  [ 1300/ 3514]
loss: 0.096183  [ 1400/ 3514]
loss: 0.000943  [ 1500/ 3514]
loss: 0.006451  [ 1600/ 3514]
loss: 0.005167  [ 1700/ 3514]
loss: 0.243912  [ 1800/ 3514]
loss: 0.007369  [ 1900/ 3514]
loss: 0.003615  [ 2000/ 3514]
loss: 0.006156  [ 2100/ 3514]
loss: 0.001190  [ 2200/ 3514]
loss: 0.001366  [ 2300/ 3514]
loss: 0.002555  [ 2400/ 3514]
loss: 0.007136  [ 2500/ 3514]
loss: 0.004491  [ 2600/ 3514]
loss: 0.003806  [ 2700/ 3514]
loss: 0.007142  [ 2800/ 3514]
loss: 0.002898  [ 2900/ 3514]
loss: 0.010529  [ 3000/ 3514]
loss: 0.002249  [ 3100/ 3514]
loss: 0.001629  [ 3200/ 3514]
loss: 0.005312  [ 3300/ 3514]
loss: 0.006281  [ 3400/ 3514]
loss: 0.003559  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.006608  [    0/ 3514]
loss: 0.003621  [  100/ 3514]
loss: 0.006939  [  200/ 3514]
loss: 0.003523  [  300/ 3514]
loss: 0.004535  [  400/ 3514]
loss: 0.005887  [  500/ 3514]
loss: 0.009338  [  600/ 3514]
loss: 0.002453  [  700/ 3514]
loss: 0.001430  [  800/ 3514]
loss: 0.003715  [  900/ 3514]
loss: 0.005910  [ 1000/ 3514]
loss: 0.094601  [ 1100/ 3514]
loss: 0.003239  [ 1200/ 3514]
loss: 0.001928  [ 1300/ 3514]
loss: 0.075190  [ 1400/ 3514]
loss: 0.000738  [ 1500/ 3514]
loss: 0.005472  [ 1600/ 3514]
loss: 0.005070  [ 1700/ 3514]
loss: 0.242914  [ 1800/ 3514]
loss: 0.007646  [ 1900/ 3514]
loss: 0.002809  [ 2000/ 3514]
loss: 0.006237  [ 2100/ 3514]
loss: 0.000982  [ 2200/ 3514]
loss: 0.001337  [ 2300/ 3514]
loss: 0.002644  [ 2400/ 3514]
loss: 0.007479  [ 2500/ 3514]
loss: 0.004078  [ 2600/ 3514]
loss: 0.003346  [ 2700/ 3514]
loss: 0.007405  [ 2800/ 3514]
loss: 0.002206  [ 2900/ 3514]
loss: 0.004271  [ 3000/ 3514]
loss: 0.002009  [ 3100/ 3514]
loss: 0.001765  [ 3200/ 3514]
loss: 0.005261  [ 3300/ 3514]
loss: 0.006335  [ 3400/ 3514]
loss: 0.002302  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.005832  [    0/ 3514]
loss: 0.003436  [  100/ 3514]
loss: 0.007259  [  200/ 3514]
loss: 0.003442  [  300/ 3514]
loss: 0.004014  [  400/ 3514]
loss: 0.004693  [  500/ 3514]
loss: 0.006709  [  600/ 3514]
loss: 0.002700  [  700/ 3514]
loss: 0.001287  [  800/ 3514]
loss: 0.003538  [  900/ 3514]
loss: 0.005620  [ 1000/ 3514]
loss: 0.093231  [ 1100/ 3514]
loss: 0.003017  [ 1200/ 3514]
loss: 0.002326  [ 1300/ 3514]
loss: 0.072591  [ 1400/ 3514]
loss: 0.000644  [ 1500/ 3514]
loss: 0.006301  [ 1600/ 3514]
loss: 0.006576  [ 1700/ 3514]
loss: 0.235302  [ 1800/ 3514]
loss: 0.003272  [ 1900/ 3514]
loss: 0.002509  [ 2000/ 3514]
loss: 0.005540  [ 2100/ 3514]
loss: 0.000766  [ 2200/ 3514]
loss: 0.001278  [ 2300/ 3514]
loss: 0.002635  [ 2400/ 3514]
loss: 0.006346  [ 2500/ 3514]
loss: 0.004312  [ 2600/ 3514]
loss: 0.002680  [ 2700/ 3514]
loss: 0.007465  [ 2800/ 3514]
loss: 0.002543  [ 2900/ 3514]
loss: 0.002830  [ 3000/ 3514]
loss: 0.002440  [ 3100/ 3514]
loss: 0.001823  [ 3200/ 3514]
loss: 0.005136  [ 3300/ 3514]
loss: 0.006598  [ 3400/ 3514]
loss: 0.002304  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.005287  [    0/ 3514]
loss: 0.003183  [  100/ 3514]
loss: 0.007110  [  200/ 3514]
loss: 0.003420  [  300/ 3514]
loss: 0.004023  [  400/ 3514]
loss: 0.004103  [  500/ 3514]
loss: 0.006287  [  600/ 3514]
loss: 0.003134  [  700/ 3514]
loss: 0.001315  [  800/ 3514]
loss: 0.003596  [  900/ 3514]
loss: 0.005494  [ 1000/ 3514]
loss: 0.092875  [ 1100/ 3514]
loss: 0.003074  [ 1200/ 3514]
loss: 0.002273  [ 1300/ 3514]
loss: 0.074998  [ 1400/ 3514]
loss: 0.000586  [ 1500/ 3514]
loss: 0.006400  [ 1600/ 3514]
loss: 0.006509  [ 1700/ 3514]
loss: 0.228142  [ 1800/ 3514]
loss: 0.003273  [ 1900/ 3514]
loss: 0.002339  [ 2000/ 3514]
loss: 0.005402  [ 2100/ 3514]
loss: 0.000735  [ 2200/ 3514]
loss: 0.001339  [ 2300/ 3514]
loss: 0.002499  [ 2400/ 3514]
loss: 0.005794  [ 2500/ 3514]
loss: 0.004392  [ 2600/ 3514]
loss: 0.002501  [ 2700/ 3514]
loss: 0.007618  [ 2800/ 3514]
loss: 0.001892  [ 2900/ 3514]
loss: 0.002365  [ 3000/ 3514]
loss: 0.001347  [ 3100/ 3514]
loss: 0.001884  [ 3200/ 3514]
loss: 0.004816  [ 3300/ 3514]
loss: 0.006005  [ 3400/ 3514]
loss: 0.002389  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.005076  [    0/ 3514]
loss: 0.002975  [  100/ 3514]
loss: 0.007062  [  200/ 3514]
loss: 0.003287  [  300/ 3514]
loss: 0.003958  [  400/ 3514]
loss: 0.004145  [  500/ 3514]
loss: 0.005839  [  600/ 3514]
loss: 0.003469  [  700/ 3514]
loss: 0.001312  [  800/ 3514]
loss: 0.003647  [  900/ 3514]
loss: 0.005401  [ 1000/ 3514]
loss: 0.092359  [ 1100/ 3514]
loss: 0.002900  [ 1200/ 3514]
loss: 0.002165  [ 1300/ 3514]
loss: 0.078363  [ 1400/ 3514]
loss: 0.000596  [ 1500/ 3514]
loss: 0.007063  [ 1600/ 3514]
loss: 0.006211  [ 1700/ 3514]
loss: 0.222740  [ 1800/ 3514]
loss: 0.003047  [ 1900/ 3514]
loss: 0.002207  [ 2000/ 3514]
loss: 0.005338  [ 2100/ 3514]
loss: 0.000655  [ 2200/ 3514]
loss: 0.001385  [ 2300/ 3514]
loss: 0.002446  [ 2400/ 3514]
loss: 0.005725  [ 2500/ 3514]
loss: 0.004428  [ 2600/ 3514]
loss: 0.002465  [ 2700/ 3514]
loss: 0.007855  [ 2800/ 3514]
loss: 0.001816  [ 2900/ 3514]
loss: 0.002237  [ 3000/ 3514]
loss: 0.001442  [ 3100/ 3514]
loss: 0.001888  [ 3200/ 3514]
loss: 0.004735  [ 3300/ 3514]
loss: 0.005996  [ 3400/ 3514]
loss: 0.002459  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.005146  [    0/ 3514]
loss: 0.002958  [  100/ 3514]
loss: 0.007216  [  200/ 3514]
loss: 0.003156  [  300/ 3514]
loss: 0.003824  [  400/ 3514]
loss: 0.003974  [  500/ 3514]
loss: 0.005644  [  600/ 3514]
loss: 0.003852  [  700/ 3514]
loss: 0.001348  [  800/ 3514]
loss: 0.003626  [  900/ 3514]
loss: 0.005520  [ 1000/ 3514]
loss: 0.092063  [ 1100/ 3514]
loss: 0.002638  [ 1200/ 3514]
loss: 0.002168  [ 1300/ 3514]
loss: 0.080774  [ 1400/ 3514]
loss: 0.000653  [ 1500/ 3514]
loss: 0.006884  [ 1600/ 3514]
loss: 0.005613  [ 1700/ 3514]
loss: 0.220477  [ 1800/ 3514]
loss: 0.002935  [ 1900/ 3514]
loss: 0.002225  [ 2000/ 3514]
loss: 0.005518  [ 2100/ 3514]
loss: 0.000620  [ 2200/ 3514]
loss: 0.001480  [ 2300/ 3514]
loss: 0.002349  [ 2400/ 3514]
loss: 0.005743  [ 2500/ 3514]
loss: 0.004420  [ 2600/ 3514]
loss: 0.002460  [ 2700/ 3514]
loss: 0.007986  [ 2800/ 3514]
loss: 0.001756  [ 2900/ 3514]
loss: 0.001838  [ 3000/ 3514]
loss: 0.001541  [ 3100/ 3514]
loss: 0.001901  [ 3200/ 3514]
loss: 0.004680  [ 3300/ 3514]
loss: 0.005732  [ 3400/ 3514]
loss: 0.002520  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.005123  [    0/ 3514]
loss: 0.002978  [  100/ 3514]
loss: 0.007330  [  200/ 3514]
loss: 0.003073  [  300/ 3514]
loss: 0.003627  [  400/ 3514]
loss: 0.004184  [  500/ 3514]
loss: 0.005329  [  600/ 3514]
loss: 0.003428  [  700/ 3514]
loss: 0.001308  [  800/ 3514]
loss: 0.003599  [  900/ 3514]
loss: 0.005266  [ 1000/ 3514]
loss: 0.091693  [ 1100/ 3514]
loss: 0.002408  [ 1200/ 3514]
loss: 0.002023  [ 1300/ 3514]
loss: 0.081166  [ 1400/ 3514]
loss: 0.000661  [ 1500/ 3514]
loss: 0.006433  [ 1600/ 3514]
loss: 0.004543  [ 1700/ 3514]
loss: 0.219582  [ 1800/ 3514]
loss: 0.003299  [ 1900/ 3514]
loss: 0.002272  [ 2000/ 3514]
loss: 0.004769  [ 2100/ 3514]
loss: 0.000602  [ 2200/ 3514]
loss: 0.001495  [ 2300/ 3514]
loss: 0.002376  [ 2400/ 3514]
loss: 0.005811  [ 2500/ 3514]
loss: 0.004305  [ 2600/ 3514]
loss: 0.002422  [ 2700/ 3514]
loss: 0.007910  [ 2800/ 3514]
loss: 0.001788  [ 2900/ 3514]
loss: 0.001785  [ 3000/ 3514]
loss: 0.001650  [ 3100/ 3514]
loss: 0.001921  [ 3200/ 3514]
loss: 0.004615  [ 3300/ 3514]
loss: 0.005626  [ 3400/ 3514]
loss: 0.002523  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.004930  [    0/ 3514]
loss: 0.002326  [  100/ 3514]
loss: 0.007195  [  200/ 3514]
loss: 0.002875  [  300/ 3514]
loss: 0.003502  [  400/ 3514]
loss: 0.002951  [  500/ 3514]
loss: 0.005487  [  600/ 3514]
loss: 0.003659  [  700/ 3514]
loss: 0.001285  [  800/ 3514]
loss: 0.003765  [  900/ 3514]
loss: 0.005065  [ 1000/ 3514]
loss: 0.091145  [ 1100/ 3514]
loss: 0.002263  [ 1200/ 3514]
loss: 0.001904  [ 1300/ 3514]
loss: 0.079427  [ 1400/ 3514]
loss: 0.000470  [ 1500/ 3514]
loss: 0.005847  [ 1600/ 3514]
loss: 0.003848  [ 1700/ 3514]
loss: 0.215855  [ 1800/ 3514]
loss: 0.003834  [ 1900/ 3514]
loss: 0.001604  [ 2000/ 3514]
loss: 0.004221  [ 2100/ 3514]
loss: 0.000560  [ 2200/ 3514]
loss: 0.001513  [ 2300/ 3514]
loss: 0.001981  [ 2400/ 3514]
loss: 0.005794  [ 2500/ 3514]
loss: 0.004301  [ 2600/ 3514]
loss: 0.002393  [ 2700/ 3514]
loss: 0.007818  [ 2800/ 3514]
loss: 0.001660  [ 2900/ 3514]
loss: 0.001665  [ 3000/ 3514]
loss: 0.001826  [ 3100/ 3514]
loss: 0.001900  [ 3200/ 3514]
loss: 0.004385  [ 3300/ 3514]
loss: 0.006078  [ 3400/ 3514]
loss: 0.002389  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [-1.3097206  -0.32745287]
[1 0 2 ... 1 0 1]
[0 2 1 ... 0 2 0]
Cluster 0 Occurrences: 1165; KMEANS: 1145
Cluster 1 Occurrences: 1157; KMEANS: 1216
Cluster 2 Occurrences: 1192; KMEANS: 1153
Centroids: [[1.1225032, -0.46359926], [-1.2427783, -0.34200594], [1.676328, 1.5693696]]
Centroids: [[-1.2591271, -0.35704213], [1.6762471, 1.5637344], [1.1026787, -0.48377576]]
Contingency Matrix: 
[[   2   15 1148]
 [1141   11    5]
 [   2 1190    0]]
[[2, -1, 1148], [1141, -1, 5], [-1, -1, -1]]
[[-1, -1, -1], [1141, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 2, 1: 0}
New Contingency Matrix: 
[[1148    2   15]
 [   5 1141   11]
 [   0    2 1190]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1148, 1141, 1190], Sum: 3479
All_Elements: [1148, 2, 15, 5, 1141, 11, 0, 2, 1190], Sum: 3514
Accuracy: 0.9900398406374502
Done!
