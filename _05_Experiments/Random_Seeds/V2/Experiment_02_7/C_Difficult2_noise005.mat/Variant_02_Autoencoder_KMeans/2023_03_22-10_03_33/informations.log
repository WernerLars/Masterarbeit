Experiment_path: Random_Seeds//V2/Experiment_02_7
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_7/C_Difficult2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_03_33
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000017453B1A518>
Sampling rate: 24000.0
Raw: [ 0.02085333  0.02043967  0.02052644 ... -0.02218732 -0.02150573
 -0.01811243]
Times: [   1583    1934    2430 ... 1439313 1439656 1439854]
Cluster: [3 3 3 ... 2 2 1]
Number of different clusters:  3
Number of Spikes: 3364
First aligned Spike Frame: [-0.05170878 -0.0548761  -0.06029554 -0.06053219 -0.04807119 -0.02780025
 -0.01550543 -0.01702494 -0.02945104 -0.04493807 -0.07056858 -0.07003585
  0.07629654  0.43081562  0.80470191  0.96319627  0.89198123  0.73643948
  0.58987232  0.46714337  0.36345495  0.2828462   0.22743292  0.182731
  0.13931053  0.09524506  0.05136602  0.01367166 -0.01393093 -0.03985679
 -0.07387102 -0.11218435 -0.1444455  -0.16672578 -0.17809238 -0.18020802
 -0.17953732 -0.18246903 -0.18617363 -0.18205375 -0.17299738 -0.16958427
 -0.17248955 -0.17516876 -0.1727246  -0.16696514 -0.15993314]
Cluster 0, Occurrences: 1120
Cluster 1, Occurrences: 1109
Cluster 2, Occurrences: 1135
<torch.utils.data.dataloader.DataLoader object at 0x00000174870F2588>
Epoch 1
-------------------------------
loss: 0.120154  [    0/ 3364]
loss: 0.081510  [  100/ 3364]
loss: 0.027965  [  200/ 3364]
loss: 0.018038  [  300/ 3364]
loss: 0.001126  [  400/ 3364]
loss: 0.045925  [  500/ 3364]
loss: 0.004954  [  600/ 3364]
loss: 0.007716  [  700/ 3364]
loss: 0.002892  [  800/ 3364]
loss: 0.007412  [  900/ 3364]
loss: 0.004236  [ 1000/ 3364]
loss: 0.003660  [ 1100/ 3364]
loss: 0.003834  [ 1200/ 3364]
loss: 0.006380  [ 1300/ 3364]
loss: 0.086109  [ 1400/ 3364]
loss: 0.002980  [ 1500/ 3364]
loss: 0.006432  [ 1600/ 3364]
loss: 0.003497  [ 1700/ 3364]
loss: 0.001279  [ 1800/ 3364]
loss: 0.003667  [ 1900/ 3364]
loss: 0.003395  [ 2000/ 3364]
loss: 0.004606  [ 2100/ 3364]
loss: 0.004492  [ 2200/ 3364]
loss: 0.007702  [ 2300/ 3364]
loss: 0.001029  [ 2400/ 3364]
loss: 0.002633  [ 2500/ 3364]
loss: 0.002830  [ 2600/ 3364]
loss: 0.002686  [ 2700/ 3364]
loss: 0.003279  [ 2800/ 3364]
loss: 0.001662  [ 2900/ 3364]
loss: 0.004115  [ 3000/ 3364]
loss: 0.006240  [ 3100/ 3364]
loss: 0.001510  [ 3200/ 3364]
loss: 0.001021  [ 3300/ 3364]
Epoch 2
-------------------------------
loss: 0.001650  [    0/ 3364]
loss: 0.002455  [  100/ 3364]
loss: 0.004179  [  200/ 3364]
loss: 0.001216  [  300/ 3364]
loss: 0.000619  [  400/ 3364]
loss: 0.034737  [  500/ 3364]
loss: 0.004188  [  600/ 3364]
loss: 0.007486  [  700/ 3364]
loss: 0.002415  [  800/ 3364]
loss: 0.004468  [  900/ 3364]
loss: 0.003242  [ 1000/ 3364]
loss: 0.003245  [ 1100/ 3364]
loss: 0.002356  [ 1200/ 3364]
loss: 0.005646  [ 1300/ 3364]
loss: 0.085995  [ 1400/ 3364]
loss: 0.002966  [ 1500/ 3364]
loss: 0.006302  [ 1600/ 3364]
loss: 0.003342  [ 1700/ 3364]
loss: 0.001004  [ 1800/ 3364]
loss: 0.003434  [ 1900/ 3364]
loss: 0.002942  [ 2000/ 3364]
loss: 0.004309  [ 2100/ 3364]
loss: 0.004449  [ 2200/ 3364]
loss: 0.007767  [ 2300/ 3364]
loss: 0.000926  [ 2400/ 3364]
loss: 0.002553  [ 2500/ 3364]
loss: 0.002482  [ 2600/ 3364]
loss: 0.002975  [ 2700/ 3364]
loss: 0.003262  [ 2800/ 3364]
loss: 0.001456  [ 2900/ 3364]
loss: 0.004081  [ 3000/ 3364]
loss: 0.006243  [ 3100/ 3364]
loss: 0.001514  [ 3200/ 3364]
loss: 0.000689  [ 3300/ 3364]
Epoch 3
-------------------------------
loss: 0.001486  [    0/ 3364]
loss: 0.002377  [  100/ 3364]
loss: 0.004079  [  200/ 3364]
loss: 0.000911  [  300/ 3364]
loss: 0.000652  [  400/ 3364]
loss: 0.030050  [  500/ 3364]
loss: 0.003645  [  600/ 3364]
loss: 0.009313  [  700/ 3364]
loss: 0.002343  [  800/ 3364]
loss: 0.003497  [  900/ 3364]
loss: 0.002701  [ 1000/ 3364]
loss: 0.003453  [ 1100/ 3364]
loss: 0.002290  [ 1200/ 3364]
loss: 0.005442  [ 1300/ 3364]
loss: 0.086229  [ 1400/ 3364]
loss: 0.002999  [ 1500/ 3364]
loss: 0.006250  [ 1600/ 3364]
loss: 0.003548  [ 1700/ 3364]
loss: 0.000961  [ 1800/ 3364]
loss: 0.003695  [ 1900/ 3364]
loss: 0.002882  [ 2000/ 3364]
loss: 0.003973  [ 2100/ 3364]
loss: 0.004706  [ 2200/ 3364]
loss: 0.007788  [ 2300/ 3364]
loss: 0.000924  [ 2400/ 3364]
loss: 0.002535  [ 2500/ 3364]
loss: 0.002461  [ 2600/ 3364]
loss: 0.003403  [ 2700/ 3364]
loss: 0.003289  [ 2800/ 3364]
loss: 0.001481  [ 2900/ 3364]
loss: 0.004189  [ 3000/ 3364]
loss: 0.006206  [ 3100/ 3364]
loss: 0.001498  [ 3200/ 3364]
loss: 0.000905  [ 3300/ 3364]
Epoch 4
-------------------------------
loss: 0.001484  [    0/ 3364]
loss: 0.002486  [  100/ 3364]
loss: 0.004249  [  200/ 3364]
loss: 0.000908  [  300/ 3364]
loss: 0.000702  [  400/ 3364]
loss: 0.028895  [  500/ 3364]
loss: 0.003660  [  600/ 3364]
loss: 0.007295  [  700/ 3364]
loss: 0.002251  [  800/ 3364]
loss: 0.003060  [  900/ 3364]
loss: 0.002368  [ 1000/ 3364]
loss: 0.003460  [ 1100/ 3364]
loss: 0.002211  [ 1200/ 3364]
loss: 0.005319  [ 1300/ 3364]
loss: 0.086230  [ 1400/ 3364]
loss: 0.002918  [ 1500/ 3364]
loss: 0.006297  [ 1600/ 3364]
loss: 0.003575  [ 1700/ 3364]
loss: 0.000932  [ 1800/ 3364]
loss: 0.003752  [ 1900/ 3364]
loss: 0.002793  [ 2000/ 3364]
loss: 0.003880  [ 2100/ 3364]
loss: 0.004813  [ 2200/ 3364]
loss: 0.007880  [ 2300/ 3364]
loss: 0.000902  [ 2400/ 3364]
loss: 0.002581  [ 2500/ 3364]
loss: 0.002323  [ 2600/ 3364]
loss: 0.003623  [ 2700/ 3364]
loss: 0.002907  [ 2800/ 3364]
loss: 0.001425  [ 2900/ 3364]
loss: 0.004280  [ 3000/ 3364]
loss: 0.006171  [ 3100/ 3364]
loss: 0.001521  [ 3200/ 3364]
loss: 0.001295  [ 3300/ 3364]
Epoch 5
-------------------------------
loss: 0.001414  [    0/ 3364]
loss: 0.002581  [  100/ 3364]
loss: 0.004051  [  200/ 3364]
loss: 0.001023  [  300/ 3364]
loss: 0.000746  [  400/ 3364]
loss: 0.027672  [  500/ 3364]
loss: 0.003563  [  600/ 3364]
loss: 0.005997  [  700/ 3364]
loss: 0.002242  [  800/ 3364]
loss: 0.002804  [  900/ 3364]
loss: 0.002074  [ 1000/ 3364]
loss: 0.003371  [ 1100/ 3364]
loss: 0.002142  [ 1200/ 3364]
loss: 0.005231  [ 1300/ 3364]
loss: 0.086189  [ 1400/ 3364]
loss: 0.002801  [ 1500/ 3364]
loss: 0.006286  [ 1600/ 3364]
loss: 0.003759  [ 1700/ 3364]
loss: 0.000941  [ 1800/ 3364]
loss: 0.003718  [ 1900/ 3364]
loss: 0.002704  [ 2000/ 3364]
loss: 0.003722  [ 2100/ 3364]
loss: 0.004947  [ 2200/ 3364]
loss: 0.007997  [ 2300/ 3364]
loss: 0.000939  [ 2400/ 3364]
loss: 0.002620  [ 2500/ 3364]
loss: 0.002224  [ 2600/ 3364]
loss: 0.003861  [ 2700/ 3364]
loss: 0.002822  [ 2800/ 3364]
loss: 0.001509  [ 2900/ 3364]
loss: 0.004356  [ 3000/ 3364]
loss: 0.006219  [ 3100/ 3364]
loss: 0.001468  [ 3200/ 3364]
loss: 0.001529  [ 3300/ 3364]
Epoch 6
-------------------------------
loss: 0.001357  [    0/ 3364]
loss: 0.002206  [  100/ 3364]
loss: 0.003903  [  200/ 3364]
loss: 0.001037  [  300/ 3364]
loss: 0.000819  [  400/ 3364]
loss: 0.026874  [  500/ 3364]
loss: 0.003330  [  600/ 3364]
loss: 0.006048  [  700/ 3364]
loss: 0.002214  [  800/ 3364]
loss: 0.002849  [  900/ 3364]
loss: 0.001758  [ 1000/ 3364]
loss: 0.003320  [ 1100/ 3364]
loss: 0.002069  [ 1200/ 3364]
loss: 0.005195  [ 1300/ 3364]
loss: 0.083829  [ 1400/ 3364]
loss: 0.002622  [ 1500/ 3364]
loss: 0.006400  [ 1600/ 3364]
loss: 0.004083  [ 1700/ 3364]
loss: 0.001015  [ 1800/ 3364]
loss: 0.003654  [ 1900/ 3364]
loss: 0.002837  [ 2000/ 3364]
loss: 0.003566  [ 2100/ 3364]
loss: 0.004831  [ 2200/ 3364]
loss: 0.008100  [ 2300/ 3364]
loss: 0.000924  [ 2400/ 3364]
loss: 0.002659  [ 2500/ 3364]
loss: 0.002102  [ 2600/ 3364]
loss: 0.003803  [ 2700/ 3364]
loss: 0.002822  [ 2800/ 3364]
loss: 0.001603  [ 2900/ 3364]
loss: 0.004337  [ 3000/ 3364]
loss: 0.006315  [ 3100/ 3364]
loss: 0.001446  [ 3200/ 3364]
loss: 0.001581  [ 3300/ 3364]
Epoch 7
-------------------------------
loss: 0.001298  [    0/ 3364]
loss: 0.002230  [  100/ 3364]
loss: 0.004000  [  200/ 3364]
loss: 0.001069  [  300/ 3364]
loss: 0.000792  [  400/ 3364]
loss: 0.025974  [  500/ 3364]
loss: 0.003279  [  600/ 3364]
loss: 0.005722  [  700/ 3364]
loss: 0.002203  [  800/ 3364]
loss: 0.003235  [  900/ 3364]
loss: 0.001738  [ 1000/ 3364]
loss: 0.003257  [ 1100/ 3364]
loss: 0.002040  [ 1200/ 3364]
loss: 0.005198  [ 1300/ 3364]
loss: 0.081607  [ 1400/ 3364]
loss: 0.002514  [ 1500/ 3364]
loss: 0.006436  [ 1600/ 3364]
loss: 0.003953  [ 1700/ 3364]
loss: 0.001043  [ 1800/ 3364]
loss: 0.003496  [ 1900/ 3364]
loss: 0.002833  [ 2000/ 3364]
loss: 0.003714  [ 2100/ 3364]
loss: 0.004742  [ 2200/ 3364]
loss: 0.008228  [ 2300/ 3364]
loss: 0.000914  [ 2400/ 3364]
loss: 0.002662  [ 2500/ 3364]
loss: 0.001999  [ 2600/ 3364]
loss: 0.003726  [ 2700/ 3364]
loss: 0.002725  [ 2800/ 3364]
loss: 0.001650  [ 2900/ 3364]
loss: 0.004305  [ 3000/ 3364]
loss: 0.006425  [ 3100/ 3364]
loss: 0.001440  [ 3200/ 3364]
loss: 0.001975  [ 3300/ 3364]
Epoch 8
-------------------------------
loss: 0.001267  [    0/ 3364]
loss: 0.002363  [  100/ 3364]
loss: 0.003982  [  200/ 3364]
loss: 0.001118  [  300/ 3364]
loss: 0.000856  [  400/ 3364]
loss: 0.026026  [  500/ 3364]
loss: 0.003186  [  600/ 3364]
loss: 0.004988  [  700/ 3364]
loss: 0.002182  [  800/ 3364]
loss: 0.003197  [  900/ 3364]
loss: 0.001596  [ 1000/ 3364]
loss: 0.003246  [ 1100/ 3364]
loss: 0.001925  [ 1200/ 3364]
loss: 0.005179  [ 1300/ 3364]
loss: 0.077891  [ 1400/ 3364]
loss: 0.002387  [ 1500/ 3364]
loss: 0.006530  [ 1600/ 3364]
loss: 0.003852  [ 1700/ 3364]
loss: 0.001057  [ 1800/ 3364]
loss: 0.003060  [ 1900/ 3364]
loss: 0.002720  [ 2000/ 3364]
loss: 0.003645  [ 2100/ 3364]
loss: 0.004650  [ 2200/ 3364]
loss: 0.008390  [ 2300/ 3364]
loss: 0.000984  [ 2400/ 3364]
loss: 0.002589  [ 2500/ 3364]
loss: 0.001928  [ 2600/ 3364]
loss: 0.003655  [ 2700/ 3364]
loss: 0.002681  [ 2800/ 3364]
loss: 0.001593  [ 2900/ 3364]
loss: 0.004250  [ 3000/ 3364]
loss: 0.006498  [ 3100/ 3364]
loss: 0.001437  [ 3200/ 3364]
loss: 0.002174  [ 3300/ 3364]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3364
First Spike after testing: [ 0.29613718 -0.47413474]
[2 2 2 ... 1 1 0]
[2 2 2 ... 1 1 0]
Cluster 0 Occurrences: 1120; KMEANS: 1143
Cluster 1 Occurrences: 1109; KMEANS: 1106
Cluster 2 Occurrences: 1135; KMEANS: 1115
Centroids: [[0.56818783, 0.29365158], [-1.0139254, -0.7877035], [0.29623592, -0.41452762]]
Centroids: [[0.57418364, 0.31733817], [-1.0210298, -0.7937294], [0.28800163, -0.44844398]]
Contingency Matrix: 
[[1108    3    9]
 [   3 1101    5]
 [  32    2 1101]]
[[-1, -1, -1], [-1, 1101, 5], [-1, 2, 1101]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 1101]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[1108    3    9]
 [   3 1101    5]
 [  32    2 1101]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1108, 1101, 1101], Sum: 3310
All_Elements: [1108, 3, 9, 3, 1101, 5, 32, 2, 1101], Sum: 3364
Accuracy: 0.9839476813317479
Done!
