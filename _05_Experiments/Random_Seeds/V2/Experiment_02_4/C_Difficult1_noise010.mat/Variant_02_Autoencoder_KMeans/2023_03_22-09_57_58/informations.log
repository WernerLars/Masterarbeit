Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Difficult1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_57_58
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000021209AC4860>
Sampling rate: 24000.0
Raw: [-0.08093593 -0.05766541 -0.01986255 ... -0.05525448 -0.03568967
 -0.02908211]
Times: [   1054    1166    1249 ... 1439165 1439229 1439456]
Cluster: [3 3 3 ... 2 1 3]
Number of different clusters:  3
Number of Spikes: 3448
First aligned Spike Frame: [-4.79707202e-02 -8.83141277e-02 -1.14477415e-01 -1.20070620e-01
 -1.07771810e-01 -8.38316152e-02 -5.31944576e-02 -2.65798100e-02
 -6.71143520e-03  2.42590968e-02  6.29914810e-02  1.33638321e-01
  3.34948892e-01  7.06515114e-01  1.07966210e+00  1.10962398e+00
  6.55362247e-01 -7.19265760e-04 -4.64310305e-01 -6.23655437e-01
 -6.27154873e-01 -6.07058236e-01 -5.79298390e-01 -5.10136794e-01
 -4.12813198e-01 -3.36153681e-01 -2.86889156e-01 -2.38391657e-01
 -1.98571332e-01 -1.83172365e-01 -1.85707124e-01 -1.94134424e-01
 -2.08249204e-01 -2.33590971e-01 -2.49276546e-01 -2.46246400e-01
 -2.44939654e-01 -2.59799331e-01 -2.74706204e-01 -2.68658955e-01
 -2.53059716e-01 -2.46742300e-01 -2.46057086e-01 -2.38944634e-01
 -2.31254619e-01 -2.20748865e-01 -1.79535377e-01]
Cluster 0, Occurrences: 1164
Cluster 1, Occurrences: 1155
Cluster 2, Occurrences: 1129
<torch.utils.data.dataloader.DataLoader object at 0x0000021209B12828>
Epoch 1
-------------------------------
loss: 0.176010  [    0/ 3448]
loss: 0.038484  [  100/ 3448]
loss: 0.032004  [  200/ 3448]
loss: 0.034269  [  300/ 3448]
loss: 0.021158  [  400/ 3448]
loss: 0.015261  [  500/ 3448]
loss: 0.021178  [  600/ 3448]
loss: 0.009055  [  700/ 3448]
loss: 0.013292  [  800/ 3448]
loss: 0.017520  [  900/ 3448]
loss: 0.089263  [ 1000/ 3448]
loss: 0.013575  [ 1100/ 3448]
loss: 0.010368  [ 1200/ 3448]
loss: 0.131121  [ 1300/ 3448]
loss: 0.005818  [ 1400/ 3448]
loss: 0.023734  [ 1500/ 3448]
loss: 0.004649  [ 1600/ 3448]
loss: 0.009842  [ 1700/ 3448]
loss: 0.006385  [ 1800/ 3448]
loss: 0.018212  [ 1900/ 3448]
loss: 0.007986  [ 2000/ 3448]
loss: 0.003228  [ 2100/ 3448]
loss: 0.007174  [ 2200/ 3448]
loss: 0.005479  [ 2300/ 3448]
loss: 0.010061  [ 2400/ 3448]
loss: 0.008625  [ 2500/ 3448]
loss: 0.012440  [ 2600/ 3448]
loss: 0.008953  [ 2700/ 3448]
loss: 0.005967  [ 2800/ 3448]
loss: 0.002568  [ 2900/ 3448]
loss: 0.004140  [ 3000/ 3448]
loss: 0.012901  [ 3100/ 3448]
loss: 0.012677  [ 3200/ 3448]
loss: 0.011821  [ 3300/ 3448]
loss: 0.006721  [ 3400/ 3448]
Epoch 2
-------------------------------
loss: 0.020562  [    0/ 3448]
loss: 0.008302  [  100/ 3448]
loss: 0.001945  [  200/ 3448]
loss: 0.004005  [  300/ 3448]
loss: 0.006745  [  400/ 3448]
loss: 0.013719  [  500/ 3448]
loss: 0.006858  [  600/ 3448]
loss: 0.007742  [  700/ 3448]
loss: 0.004231  [  800/ 3448]
loss: 0.006911  [  900/ 3448]
loss: 0.087002  [ 1000/ 3448]
loss: 0.015056  [ 1100/ 3448]
loss: 0.008988  [ 1200/ 3448]
loss: 0.127097  [ 1300/ 3448]
loss: 0.006534  [ 1400/ 3448]
loss: 0.020850  [ 1500/ 3448]
loss: 0.005125  [ 1600/ 3448]
loss: 0.010933  [ 1700/ 3448]
loss: 0.006271  [ 1800/ 3448]
loss: 0.018150  [ 1900/ 3448]
loss: 0.008557  [ 2000/ 3448]
loss: 0.003300  [ 2100/ 3448]
loss: 0.005693  [ 2200/ 3448]
loss: 0.005743  [ 2300/ 3448]
loss: 0.007827  [ 2400/ 3448]
loss: 0.008338  [ 2500/ 3448]
loss: 0.012453  [ 2600/ 3448]
loss: 0.009234  [ 2700/ 3448]
loss: 0.006222  [ 2800/ 3448]
loss: 0.002524  [ 2900/ 3448]
loss: 0.003964  [ 3000/ 3448]
loss: 0.012796  [ 3100/ 3448]
loss: 0.013519  [ 3200/ 3448]
loss: 0.011299  [ 3300/ 3448]
loss: 0.006885  [ 3400/ 3448]
Epoch 3
-------------------------------
loss: 0.020456  [    0/ 3448]
loss: 0.007747  [  100/ 3448]
loss: 0.003269  [  200/ 3448]
loss: 0.004198  [  300/ 3448]
loss: 0.007138  [  400/ 3448]
loss: 0.013217  [  500/ 3448]
loss: 0.006475  [  600/ 3448]
loss: 0.008043  [  700/ 3448]
loss: 0.004518  [  800/ 3448]
loss: 0.005905  [  900/ 3448]
loss: 0.086108  [ 1000/ 3448]
loss: 0.015253  [ 1100/ 3448]
loss: 0.009034  [ 1200/ 3448]
loss: 0.125857  [ 1300/ 3448]
loss: 0.006603  [ 1400/ 3448]
loss: 0.020468  [ 1500/ 3448]
loss: 0.005744  [ 1600/ 3448]
loss: 0.010995  [ 1700/ 3448]
loss: 0.006761  [ 1800/ 3448]
loss: 0.017796  [ 1900/ 3448]
loss: 0.008470  [ 2000/ 3448]
loss: 0.003102  [ 2100/ 3448]
loss: 0.005455  [ 2200/ 3448]
loss: 0.005803  [ 2300/ 3448]
loss: 0.007273  [ 2400/ 3448]
loss: 0.008458  [ 2500/ 3448]
loss: 0.012022  [ 2600/ 3448]
loss: 0.009635  [ 2700/ 3448]
loss: 0.005954  [ 2800/ 3448]
loss: 0.002342  [ 2900/ 3448]
loss: 0.003874  [ 3000/ 3448]
loss: 0.012277  [ 3100/ 3448]
loss: 0.013324  [ 3200/ 3448]
loss: 0.011366  [ 3300/ 3448]
loss: 0.007004  [ 3400/ 3448]
Epoch 4
-------------------------------
loss: 0.020841  [    0/ 3448]
loss: 0.007900  [  100/ 3448]
loss: 0.002986  [  200/ 3448]
loss: 0.004042  [  300/ 3448]
loss: 0.007185  [  400/ 3448]
loss: 0.012808  [  500/ 3448]
loss: 0.006307  [  600/ 3448]
loss: 0.008332  [  700/ 3448]
loss: 0.004678  [  800/ 3448]
loss: 0.005957  [  900/ 3448]
loss: 0.085776  [ 1000/ 3448]
loss: 0.015424  [ 1100/ 3448]
loss: 0.008802  [ 1200/ 3448]
loss: 0.125440  [ 1300/ 3448]
loss: 0.006636  [ 1400/ 3448]
loss: 0.020169  [ 1500/ 3448]
loss: 0.006101  [ 1600/ 3448]
loss: 0.011415  [ 1700/ 3448]
loss: 0.006887  [ 1800/ 3448]
loss: 0.017637  [ 1900/ 3448]
loss: 0.008194  [ 2000/ 3448]
loss: 0.003009  [ 2100/ 3448]
loss: 0.005154  [ 2200/ 3448]
loss: 0.005824  [ 2300/ 3448]
loss: 0.007286  [ 2400/ 3448]
loss: 0.008720  [ 2500/ 3448]
loss: 0.011787  [ 2600/ 3448]
loss: 0.009509  [ 2700/ 3448]
loss: 0.005870  [ 2800/ 3448]
loss: 0.002290  [ 2900/ 3448]
loss: 0.003861  [ 3000/ 3448]
loss: 0.012176  [ 3100/ 3448]
loss: 0.013117  [ 3200/ 3448]
loss: 0.011446  [ 3300/ 3448]
loss: 0.007081  [ 3400/ 3448]
Epoch 5
-------------------------------
loss: 0.020949  [    0/ 3448]
loss: 0.008054  [  100/ 3448]
loss: 0.003378  [  200/ 3448]
loss: 0.004087  [  300/ 3448]
loss: 0.007070  [  400/ 3448]
loss: 0.012636  [  500/ 3448]
loss: 0.006132  [  600/ 3448]
loss: 0.008597  [  700/ 3448]
loss: 0.004745  [  800/ 3448]
loss: 0.006046  [  900/ 3448]
loss: 0.085475  [ 1000/ 3448]
loss: 0.015660  [ 1100/ 3448]
loss: 0.008584  [ 1200/ 3448]
loss: 0.125444  [ 1300/ 3448]
loss: 0.006754  [ 1400/ 3448]
loss: 0.019620  [ 1500/ 3448]
loss: 0.005981  [ 1600/ 3448]
loss: 0.011877  [ 1700/ 3448]
loss: 0.007061  [ 1800/ 3448]
loss: 0.017736  [ 1900/ 3448]
loss: 0.008039  [ 2000/ 3448]
loss: 0.002932  [ 2100/ 3448]
loss: 0.004920  [ 2200/ 3448]
loss: 0.005866  [ 2300/ 3448]
loss: 0.007283  [ 2400/ 3448]
loss: 0.008805  [ 2500/ 3448]
loss: 0.011669  [ 2600/ 3448]
loss: 0.009551  [ 2700/ 3448]
loss: 0.005736  [ 2800/ 3448]
loss: 0.002267  [ 2900/ 3448]
loss: 0.003854  [ 3000/ 3448]
loss: 0.011985  [ 3100/ 3448]
loss: 0.012782  [ 3200/ 3448]
loss: 0.011490  [ 3300/ 3448]
loss: 0.007102  [ 3400/ 3448]
Epoch 6
-------------------------------
loss: 0.021199  [    0/ 3448]
loss: 0.008420  [  100/ 3448]
loss: 0.003733  [  200/ 3448]
loss: 0.004044  [  300/ 3448]
loss: 0.006888  [  400/ 3448]
loss: 0.012481  [  500/ 3448]
loss: 0.005995  [  600/ 3448]
loss: 0.008809  [  700/ 3448]
loss: 0.004773  [  800/ 3448]
loss: 0.006137  [  900/ 3448]
loss: 0.085294  [ 1000/ 3448]
loss: 0.015973  [ 1100/ 3448]
loss: 0.008383  [ 1200/ 3448]
loss: 0.125414  [ 1300/ 3448]
loss: 0.006881  [ 1400/ 3448]
loss: 0.019102  [ 1500/ 3448]
loss: 0.005801  [ 1600/ 3448]
loss: 0.012121  [ 1700/ 3448]
loss: 0.007245  [ 1800/ 3448]
loss: 0.017750  [ 1900/ 3448]
loss: 0.007861  [ 2000/ 3448]
loss: 0.002830  [ 2100/ 3448]
loss: 0.004669  [ 2200/ 3448]
loss: 0.005968  [ 2300/ 3448]
loss: 0.007432  [ 2400/ 3448]
loss: 0.008802  [ 2500/ 3448]
loss: 0.011518  [ 2600/ 3448]
loss: 0.009558  [ 2700/ 3448]
loss: 0.005638  [ 2800/ 3448]
loss: 0.002227  [ 2900/ 3448]
loss: 0.003883  [ 3000/ 3448]
loss: 0.011932  [ 3100/ 3448]
loss: 0.012339  [ 3200/ 3448]
loss: 0.011525  [ 3300/ 3448]
loss: 0.007022  [ 3400/ 3448]
Epoch 7
-------------------------------
loss: 0.021848  [    0/ 3448]
loss: 0.008630  [  100/ 3448]
loss: 0.004065  [  200/ 3448]
loss: 0.004077  [  300/ 3448]
loss: 0.006562  [  400/ 3448]
loss: 0.012305  [  500/ 3448]
loss: 0.005918  [  600/ 3448]
loss: 0.009045  [  700/ 3448]
loss: 0.004787  [  800/ 3448]
loss: 0.006124  [  900/ 3448]
loss: 0.084950  [ 1000/ 3448]
loss: 0.016128  [ 1100/ 3448]
loss: 0.008160  [ 1200/ 3448]
loss: 0.125486  [ 1300/ 3448]
loss: 0.006906  [ 1400/ 3448]
loss: 0.018340  [ 1500/ 3448]
loss: 0.005756  [ 1600/ 3448]
loss: 0.012327  [ 1700/ 3448]
loss: 0.007431  [ 1800/ 3448]
loss: 0.017808  [ 1900/ 3448]
loss: 0.007746  [ 2000/ 3448]
loss: 0.002793  [ 2100/ 3448]
loss: 0.004424  [ 2200/ 3448]
loss: 0.006142  [ 2300/ 3448]
loss: 0.007574  [ 2400/ 3448]
loss: 0.008914  [ 2500/ 3448]
loss: 0.011308  [ 2600/ 3448]
loss: 0.009460  [ 2700/ 3448]
loss: 0.005546  [ 2800/ 3448]
loss: 0.002188  [ 2900/ 3448]
loss: 0.003902  [ 3000/ 3448]
loss: 0.011887  [ 3100/ 3448]
loss: 0.011871  [ 3200/ 3448]
loss: 0.011517  [ 3300/ 3448]
loss: 0.006977  [ 3400/ 3448]
Epoch 8
-------------------------------
loss: 0.022274  [    0/ 3448]
loss: 0.008924  [  100/ 3448]
loss: 0.004853  [  200/ 3448]
loss: 0.004125  [  300/ 3448]
loss: 0.006373  [  400/ 3448]
loss: 0.012064  [  500/ 3448]
loss: 0.005848  [  600/ 3448]
loss: 0.009198  [  700/ 3448]
loss: 0.004979  [  800/ 3448]
loss: 0.006381  [  900/ 3448]
loss: 0.084353  [ 1000/ 3448]
loss: 0.016252  [ 1100/ 3448]
loss: 0.007836  [ 1200/ 3448]
loss: 0.125748  [ 1300/ 3448]
loss: 0.007056  [ 1400/ 3448]
loss: 0.017621  [ 1500/ 3448]
loss: 0.006001  [ 1600/ 3448]
loss: 0.012515  [ 1700/ 3448]
loss: 0.007682  [ 1800/ 3448]
loss: 0.017983  [ 1900/ 3448]
loss: 0.007640  [ 2000/ 3448]
loss: 0.002747  [ 2100/ 3448]
loss: 0.004365  [ 2200/ 3448]
loss: 0.006344  [ 2300/ 3448]
loss: 0.007658  [ 2400/ 3448]
loss: 0.008961  [ 2500/ 3448]
loss: 0.011252  [ 2600/ 3448]
loss: 0.009468  [ 2700/ 3448]
loss: 0.005388  [ 2800/ 3448]
loss: 0.002161  [ 2900/ 3448]
loss: 0.003925  [ 3000/ 3448]
loss: 0.011607  [ 3100/ 3448]
loss: 0.011112  [ 3200/ 3448]
loss: 0.011549  [ 3300/ 3448]
loss: 0.006766  [ 3400/ 3448]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3448
First Spike after testing: [-1.0126547   0.00577271]
[2 2 2 ... 1 0 2]
[1 1 1 ... 2 0 1]
Cluster 0 Occurrences: 1164; KMEANS: 1076
Cluster 1 Occurrences: 1155; KMEANS: 1161
Cluster 2 Occurrences: 1129; KMEANS: 1211
Centroids: [[-0.5385313, 0.23337778], [-0.88760835, 0.4263981], [-1.2915021, -0.095562756]]
Centroids: [[-0.47030625, 0.3285801], [-1.3058897, -0.11727148], [-0.8983952, 0.36238748]]
Contingency Matrix: 
[[ 944   54  166]
 [ 130   65  960]
 [   2 1042   85]]
[[944, -1, 166], [130, -1, 960], [-1, -1, -1]]
[[944, -1, -1], [-1, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 1: 2, 0: 0}
New Contingency Matrix: 
[[ 944  166   54]
 [ 130  960   65]
 [   2   85 1042]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [944, 960, 1042], Sum: 2946
All_Elements: [944, 166, 54, 130, 960, 65, 2, 85, 1042], Sum: 3448
Accuracy: 0.8544083526682135
Done!
