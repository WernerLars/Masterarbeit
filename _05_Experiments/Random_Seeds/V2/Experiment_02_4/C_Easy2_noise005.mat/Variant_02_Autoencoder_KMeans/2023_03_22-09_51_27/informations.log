Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Easy2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_51_27
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211F2C3B0F0>
Sampling rate: 24000.0
Raw: [ 0.11862069  0.1123084   0.10401825 ... -0.10219323 -0.10268373
 -0.08956559]
Times: [    346     799    1005 ... 1436867 1437273 1437800]
Cluster: [3 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3410
First aligned Spike Frame: [ 2.05661766e-03  8.27536867e-03  1.66427268e-02  2.31246655e-02
  2.28936935e-02  1.99169368e-02  2.25281834e-02  3.37605443e-02
  4.94182133e-02  6.24484568e-02  8.42111946e-02  1.71357846e-01
  3.88441746e-01  6.99052305e-01  9.59509287e-01  1.03608873e+00
  9.29169963e-01  7.55567481e-01  6.10726415e-01  5.06818519e-01
  4.23878029e-01  3.55610047e-01  3.01970228e-01  2.53702042e-01
  1.98274486e-01  1.32802904e-01  6.40690121e-02  7.96454927e-04
 -5.66201776e-02 -1.11669131e-01 -1.62581026e-01 -2.01746625e-01
 -2.23071447e-01 -2.29516190e-01 -2.30160694e-01 -2.27148529e-01
 -2.18080531e-01 -2.04276810e-01 -1.90750996e-01 -1.81098693e-01
 -1.72421418e-01 -1.61640218e-01 -1.48460304e-01 -1.32332846e-01
 -1.13338953e-01 -9.43725979e-02 -7.56249106e-02]
Cluster 0, Occurrences: 1130
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1167
<torch.utils.data.dataloader.DataLoader object at 0x00000211E96DA7F0>
Epoch 1
-------------------------------
loss: 0.172206  [    0/ 3410]
loss: 0.078494  [  100/ 3410]
loss: 0.016815  [  200/ 3410]
loss: 0.034244  [  300/ 3410]
loss: 0.003459  [  400/ 3410]
loss: 0.004940  [  500/ 3410]
loss: 0.001945  [  600/ 3410]
loss: 0.004568  [  700/ 3410]
loss: 0.007729  [  800/ 3410]
loss: 0.009080  [  900/ 3410]
loss: 0.015384  [ 1000/ 3410]
loss: 0.003485  [ 1100/ 3410]
loss: 0.003491  [ 1200/ 3410]
loss: 0.006377  [ 1300/ 3410]
loss: 0.001886  [ 1400/ 3410]
loss: 0.002108  [ 1500/ 3410]
loss: 0.001589  [ 1600/ 3410]
loss: 0.005569  [ 1700/ 3410]
loss: 0.013556  [ 1800/ 3410]
loss: 0.001472  [ 1900/ 3410]
loss: 0.054395  [ 2000/ 3410]
loss: 0.003077  [ 2100/ 3410]
loss: 0.028902  [ 2200/ 3410]
loss: 0.002912  [ 2300/ 3410]
loss: 0.002978  [ 2400/ 3410]
loss: 0.099609  [ 2500/ 3410]
loss: 0.008880  [ 2600/ 3410]
loss: 0.003954  [ 2700/ 3410]
loss: 0.001154  [ 2800/ 3410]
loss: 0.006002  [ 2900/ 3410]
loss: 0.002404  [ 3000/ 3410]
loss: 0.001117  [ 3100/ 3410]
loss: 0.002562  [ 3200/ 3410]
loss: 0.001601  [ 3300/ 3410]
loss: 0.001232  [ 3400/ 3410]
Epoch 2
-------------------------------
loss: 0.000467  [    0/ 3410]
loss: 0.003618  [  100/ 3410]
loss: 0.006570  [  200/ 3410]
loss: 0.003078  [  300/ 3410]
loss: 0.002873  [  400/ 3410]
loss: 0.005541  [  500/ 3410]
loss: 0.001296  [  600/ 3410]
loss: 0.005168  [  700/ 3410]
loss: 0.004844  [  800/ 3410]
loss: 0.002178  [  900/ 3410]
loss: 0.005328  [ 1000/ 3410]
loss: 0.003264  [ 1100/ 3410]
loss: 0.002222  [ 1200/ 3410]
loss: 0.006471  [ 1300/ 3410]
loss: 0.001449  [ 1400/ 3410]
loss: 0.001558  [ 1500/ 3410]
loss: 0.001421  [ 1600/ 3410]
loss: 0.003759  [ 1700/ 3410]
loss: 0.010313  [ 1800/ 3410]
loss: 0.001262  [ 1900/ 3410]
loss: 0.056841  [ 2000/ 3410]
loss: 0.003103  [ 2100/ 3410]
loss: 0.028181  [ 2200/ 3410]
loss: 0.002626  [ 2300/ 3410]
loss: 0.002534  [ 2400/ 3410]
loss: 0.081164  [ 2500/ 3410]
loss: 0.006414  [ 2600/ 3410]
loss: 0.003977  [ 2700/ 3410]
loss: 0.001159  [ 2800/ 3410]
loss: 0.005437  [ 2900/ 3410]
loss: 0.002562  [ 3000/ 3410]
loss: 0.001002  [ 3100/ 3410]
loss: 0.001903  [ 3200/ 3410]
loss: 0.001489  [ 3300/ 3410]
loss: 0.001428  [ 3400/ 3410]
Epoch 3
-------------------------------
loss: 0.000354  [    0/ 3410]
loss: 0.003763  [  100/ 3410]
loss: 0.005199  [  200/ 3410]
loss: 0.002766  [  300/ 3410]
loss: 0.002721  [  400/ 3410]
loss: 0.005419  [  500/ 3410]
loss: 0.000986  [  600/ 3410]
loss: 0.005149  [  700/ 3410]
loss: 0.004732  [  800/ 3410]
loss: 0.002206  [  900/ 3410]
loss: 0.004246  [ 1000/ 3410]
loss: 0.002799  [ 1100/ 3410]
loss: 0.001619  [ 1200/ 3410]
loss: 0.006117  [ 1300/ 3410]
loss: 0.001603  [ 1400/ 3410]
loss: 0.001407  [ 1500/ 3410]
loss: 0.001140  [ 1600/ 3410]
loss: 0.003271  [ 1700/ 3410]
loss: 0.009150  [ 1800/ 3410]
loss: 0.001205  [ 1900/ 3410]
loss: 0.056754  [ 2000/ 3410]
loss: 0.003079  [ 2100/ 3410]
loss: 0.027237  [ 2200/ 3410]
loss: 0.002554  [ 2300/ 3410]
loss: 0.002417  [ 2400/ 3410]
loss: 0.069711  [ 2500/ 3410]
loss: 0.004867  [ 2600/ 3410]
loss: 0.004022  [ 2700/ 3410]
loss: 0.000880  [ 2800/ 3410]
loss: 0.005197  [ 2900/ 3410]
loss: 0.002481  [ 3000/ 3410]
loss: 0.000875  [ 3100/ 3410]
loss: 0.001675  [ 3200/ 3410]
loss: 0.001068  [ 3300/ 3410]
loss: 0.001401  [ 3400/ 3410]
Epoch 4
-------------------------------
loss: 0.000413  [    0/ 3410]
loss: 0.003480  [  100/ 3410]
loss: 0.004859  [  200/ 3410]
loss: 0.002830  [  300/ 3410]
loss: 0.002665  [  400/ 3410]
loss: 0.004474  [  500/ 3410]
loss: 0.000722  [  600/ 3410]
loss: 0.005281  [  700/ 3410]
loss: 0.004824  [  800/ 3410]
loss: 0.002219  [  900/ 3410]
loss: 0.003975  [ 1000/ 3410]
loss: 0.002437  [ 1100/ 3410]
loss: 0.001622  [ 1200/ 3410]
loss: 0.005792  [ 1300/ 3410]
loss: 0.001430  [ 1400/ 3410]
loss: 0.001313  [ 1500/ 3410]
loss: 0.001241  [ 1600/ 3410]
loss: 0.002922  [ 1700/ 3410]
loss: 0.008715  [ 1800/ 3410]
loss: 0.001180  [ 1900/ 3410]
loss: 0.056147  [ 2000/ 3410]
loss: 0.003044  [ 2100/ 3410]
loss: 0.026184  [ 2200/ 3410]
loss: 0.002537  [ 2300/ 3410]
loss: 0.002338  [ 2400/ 3410]
loss: 0.063719  [ 2500/ 3410]
loss: 0.003703  [ 2600/ 3410]
loss: 0.004105  [ 2700/ 3410]
loss: 0.000675  [ 2800/ 3410]
loss: 0.005056  [ 2900/ 3410]
loss: 0.002640  [ 3000/ 3410]
loss: 0.000748  [ 3100/ 3410]
loss: 0.001626  [ 3200/ 3410]
loss: 0.001024  [ 3300/ 3410]
loss: 0.001400  [ 3400/ 3410]
Epoch 5
-------------------------------
loss: 0.000437  [    0/ 3410]
loss: 0.003255  [  100/ 3410]
loss: 0.004803  [  200/ 3410]
loss: 0.002888  [  300/ 3410]
loss: 0.002467  [  400/ 3410]
loss: 0.003546  [  500/ 3410]
loss: 0.000721  [  600/ 3410]
loss: 0.005308  [  700/ 3410]
loss: 0.004706  [  800/ 3410]
loss: 0.002111  [  900/ 3410]
loss: 0.003633  [ 1000/ 3410]
loss: 0.002277  [ 1100/ 3410]
loss: 0.001683  [ 1200/ 3410]
loss: 0.005525  [ 1300/ 3410]
loss: 0.001556  [ 1400/ 3410]
loss: 0.001219  [ 1500/ 3410]
loss: 0.001265  [ 1600/ 3410]
loss: 0.002711  [ 1700/ 3410]
loss: 0.008006  [ 1800/ 3410]
loss: 0.001203  [ 1900/ 3410]
loss: 0.055250  [ 2000/ 3410]
loss: 0.003118  [ 2100/ 3410]
loss: 0.025417  [ 2200/ 3410]
loss: 0.002737  [ 2300/ 3410]
loss: 0.002271  [ 2400/ 3410]
loss: 0.059989  [ 2500/ 3410]
loss: 0.003830  [ 2600/ 3410]
loss: 0.004112  [ 2700/ 3410]
loss: 0.000560  [ 2800/ 3410]
loss: 0.004806  [ 2900/ 3410]
loss: 0.002703  [ 3000/ 3410]
loss: 0.000737  [ 3100/ 3410]
loss: 0.001619  [ 3200/ 3410]
loss: 0.001156  [ 3300/ 3410]
loss: 0.001296  [ 3400/ 3410]
Epoch 6
-------------------------------
loss: 0.000352  [    0/ 3410]
loss: 0.003286  [  100/ 3410]
loss: 0.005268  [  200/ 3410]
loss: 0.002924  [  300/ 3410]
loss: 0.002303  [  400/ 3410]
loss: 0.003202  [  500/ 3410]
loss: 0.000695  [  600/ 3410]
loss: 0.005220  [  700/ 3410]
loss: 0.004142  [  800/ 3410]
loss: 0.001919  [  900/ 3410]
loss: 0.003482  [ 1000/ 3410]
loss: 0.002200  [ 1100/ 3410]
loss: 0.002951  [ 1200/ 3410]
loss: 0.005089  [ 1300/ 3410]
loss: 0.001695  [ 1400/ 3410]
loss: 0.001193  [ 1500/ 3410]
loss: 0.001449  [ 1600/ 3410]
loss: 0.002849  [ 1700/ 3410]
loss: 0.006064  [ 1800/ 3410]
loss: 0.001193  [ 1900/ 3410]
loss: 0.054496  [ 2000/ 3410]
loss: 0.003122  [ 2100/ 3410]
loss: 0.024901  [ 2200/ 3410]
loss: 0.003268  [ 2300/ 3410]
loss: 0.002134  [ 2400/ 3410]
loss: 0.056722  [ 2500/ 3410]
loss: 0.003931  [ 2600/ 3410]
loss: 0.004099  [ 2700/ 3410]
loss: 0.000515  [ 2800/ 3410]
loss: 0.004509  [ 2900/ 3410]
loss: 0.002726  [ 3000/ 3410]
loss: 0.000897  [ 3100/ 3410]
loss: 0.001551  [ 3200/ 3410]
loss: 0.001414  [ 3300/ 3410]
loss: 0.001451  [ 3400/ 3410]
Epoch 7
-------------------------------
loss: 0.000360  [    0/ 3410]
loss: 0.003422  [  100/ 3410]
loss: 0.004800  [  200/ 3410]
loss: 0.002748  [  300/ 3410]
loss: 0.002230  [  400/ 3410]
loss: 0.003004  [  500/ 3410]
loss: 0.000748  [  600/ 3410]
loss: 0.005200  [  700/ 3410]
loss: 0.003588  [  800/ 3410]
loss: 0.001803  [  900/ 3410]
loss: 0.003372  [ 1000/ 3410]
loss: 0.001999  [ 1100/ 3410]
loss: 0.002346  [ 1200/ 3410]
loss: 0.004739  [ 1300/ 3410]
loss: 0.001830  [ 1400/ 3410]
loss: 0.001096  [ 1500/ 3410]
loss: 0.001618  [ 1600/ 3410]
loss: 0.002712  [ 1700/ 3410]
loss: 0.005127  [ 1800/ 3410]
loss: 0.001180  [ 1900/ 3410]
loss: 0.054983  [ 2000/ 3410]
loss: 0.003103  [ 2100/ 3410]
loss: 0.024010  [ 2200/ 3410]
loss: 0.003060  [ 2300/ 3410]
loss: 0.001904  [ 2400/ 3410]
loss: 0.054800  [ 2500/ 3410]
loss: 0.003259  [ 2600/ 3410]
loss: 0.004039  [ 2700/ 3410]
loss: 0.000568  [ 2800/ 3410]
loss: 0.004786  [ 2900/ 3410]
loss: 0.002659  [ 3000/ 3410]
loss: 0.000855  [ 3100/ 3410]
loss: 0.001704  [ 3200/ 3410]
loss: 0.001398  [ 3300/ 3410]
loss: 0.001484  [ 3400/ 3410]
Epoch 8
-------------------------------
loss: 0.000375  [    0/ 3410]
loss: 0.003350  [  100/ 3410]
loss: 0.004558  [  200/ 3410]
loss: 0.002593  [  300/ 3410]
loss: 0.002192  [  400/ 3410]
loss: 0.003357  [  500/ 3410]
loss: 0.000773  [  600/ 3410]
loss: 0.004973  [  700/ 3410]
loss: 0.003249  [  800/ 3410]
loss: 0.001823  [  900/ 3410]
loss: 0.003174  [ 1000/ 3410]
loss: 0.001936  [ 1100/ 3410]
loss: 0.002068  [ 1200/ 3410]
loss: 0.004428  [ 1300/ 3410]
loss: 0.001937  [ 1400/ 3410]
loss: 0.001081  [ 1500/ 3410]
loss: 0.001616  [ 1600/ 3410]
loss: 0.002597  [ 1700/ 3410]
loss: 0.004830  [ 1800/ 3410]
loss: 0.001171  [ 1900/ 3410]
loss: 0.055443  [ 2000/ 3410]
loss: 0.003043  [ 2100/ 3410]
loss: 0.023189  [ 2200/ 3410]
loss: 0.002840  [ 2300/ 3410]
loss: 0.001710  [ 2400/ 3410]
loss: 0.055199  [ 2500/ 3410]
loss: 0.002660  [ 2600/ 3410]
loss: 0.003962  [ 2700/ 3410]
loss: 0.000588  [ 2800/ 3410]
loss: 0.004865  [ 2900/ 3410]
loss: 0.002762  [ 3000/ 3410]
loss: 0.000793  [ 3100/ 3410]
loss: 0.002916  [ 3200/ 3410]
loss: 0.001472  [ 3300/ 3410]
loss: 0.001512  [ 3400/ 3410]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3410
First Spike after testing: [-1.7200351  -0.46708065]
[2 2 2 ... 2 0 2]
[1 1 1 ... 1 0 1]
Cluster 0 Occurrences: 1130; KMEANS: 1158
Cluster 1 Occurrences: 1113; KMEANS: 1163
Cluster 2 Occurrences: 1167; KMEANS: 1089
Centroids: [[0.6913287, 1.5631256], [0.06662578, 0.96933657], [-1.6736985, -0.51086575]]
Centroids: [[0.69951224, 1.569085], [-1.67604, -0.5171316], [0.037969835, 0.94898707]]
Contingency Matrix: 
[[1119    0   11]
 [  39    1 1073]
 [   0 1162    5]]
[[1119, -1, 11], [39, -1, 1073], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1073], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 1, 0: 0, 1: 2}
New Contingency Matrix: 
[[1119   11    0]
 [  39 1073    1]
 [   0    5 1162]]
New Clustered Label Sequence: [0, 2, 1]
Diagonal_Elements: [1119, 1073, 1162], Sum: 3354
All_Elements: [1119, 11, 0, 39, 1073, 1, 0, 5, 1162], Sum: 3410
Accuracy: 0.9835777126099706
Done!
