Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise020.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise020.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Difficult1_noise020.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_01_28
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211E800D1D0>
Sampling rate: 24000.0
Raw: [0.07805807 0.0565915  0.02594138 ... 0.2738422  0.26036418 0.26764671]
Times: [    368     630     648 ... 1439484 1439672 1439764]
Cluster: [2 2 1 ... 1 1 3]
Number of different clusters:  3
Number of Spikes: 3414
First aligned Spike Frame: [-0.38605838 -0.38126768 -0.38226316 -0.39416749 -0.41080739 -0.41171959
 -0.38717544 -0.35786686 -0.38107535 -0.49467824 -0.61843181 -0.58172559
 -0.24572387  0.35672948  0.89024247  1.0117557   0.76459666  0.43756704
  0.20139815  0.0394919  -0.09249478 -0.19279146 -0.23446076 -0.21807174
 -0.17478611 -0.12910555 -0.08593802 -0.03628316  0.029471    0.09510752
  0.13901987  0.15819091  0.1762069   0.21560464  0.27527193  0.33233202
  0.36740003  0.38309659  0.39850514  0.42031497  0.43304033  0.41207346
  0.35038997  0.26929981  0.20084763  0.15457014  0.10809812]
Cluster 0, Occurrences: 1136
Cluster 1, Occurrences: 1099
Cluster 2, Occurrences: 1179
<torch.utils.data.dataloader.DataLoader object at 0x0000021209B12358>
Epoch 1
-------------------------------
loss: 0.217900  [    0/ 3414]
loss: 0.077968  [  100/ 3414]
loss: 0.032099  [  200/ 3414]
loss: 0.049506  [  300/ 3414]
loss: 0.042414  [  400/ 3414]
loss: 0.054807  [  500/ 3414]
loss: 0.035721  [  600/ 3414]
loss: 0.038914  [  700/ 3414]
loss: 0.043181  [  800/ 3414]
loss: 0.037739  [  900/ 3414]
loss: 0.017603  [ 1000/ 3414]
loss: 0.024350  [ 1100/ 3414]
loss: 0.006398  [ 1200/ 3414]
loss: 0.030918  [ 1300/ 3414]
loss: 0.019226  [ 1400/ 3414]
loss: 0.023204  [ 1500/ 3414]
loss: 0.009914  [ 1600/ 3414]
loss: 0.009178  [ 1700/ 3414]
loss: 0.028976  [ 1800/ 3414]
loss: 0.020461  [ 1900/ 3414]
loss: 0.033106  [ 2000/ 3414]
loss: 0.036384  [ 2100/ 3414]
loss: 0.046794  [ 2200/ 3414]
loss: 0.037826  [ 2300/ 3414]
loss: 0.008193  [ 2400/ 3414]
loss: 0.166186  [ 2500/ 3414]
loss: 0.024636  [ 2600/ 3414]
loss: 0.014482  [ 2700/ 3414]
loss: 0.015467  [ 2800/ 3414]
loss: 0.040617  [ 2900/ 3414]
loss: 0.049166  [ 3000/ 3414]
loss: 0.035985  [ 3100/ 3414]
loss: 0.021396  [ 3200/ 3414]
loss: 0.011927  [ 3300/ 3414]
loss: 0.025145  [ 3400/ 3414]
Epoch 2
-------------------------------
loss: 0.048469  [    0/ 3414]
loss: 0.029662  [  100/ 3414]
loss: 0.008385  [  200/ 3414]
loss: 0.050993  [  300/ 3414]
loss: 0.014065  [  400/ 3414]
loss: 0.045739  [  500/ 3414]
loss: 0.028458  [  600/ 3414]
loss: 0.033751  [  700/ 3414]
loss: 0.052900  [  800/ 3414]
loss: 0.024369  [  900/ 3414]
loss: 0.017136  [ 1000/ 3414]
loss: 0.023636  [ 1100/ 3414]
loss: 0.007417  [ 1200/ 3414]
loss: 0.032121  [ 1300/ 3414]
loss: 0.018923  [ 1400/ 3414]
loss: 0.026775  [ 1500/ 3414]
loss: 0.011008  [ 1600/ 3414]
loss: 0.009800  [ 1700/ 3414]
loss: 0.029715  [ 1800/ 3414]
loss: 0.020751  [ 1900/ 3414]
loss: 0.032917  [ 2000/ 3414]
loss: 0.034634  [ 2100/ 3414]
loss: 0.042193  [ 2200/ 3414]
loss: 0.034737  [ 2300/ 3414]
loss: 0.008090  [ 2400/ 3414]
loss: 0.159111  [ 2500/ 3414]
loss: 0.024264  [ 2600/ 3414]
loss: 0.014045  [ 2700/ 3414]
loss: 0.013810  [ 2800/ 3414]
loss: 0.041294  [ 2900/ 3414]
loss: 0.047414  [ 3000/ 3414]
loss: 0.034814  [ 3100/ 3414]
loss: 0.021158  [ 3200/ 3414]
loss: 0.012015  [ 3300/ 3414]
loss: 0.024641  [ 3400/ 3414]
Epoch 3
-------------------------------
loss: 0.046453  [    0/ 3414]
loss: 0.029568  [  100/ 3414]
loss: 0.008302  [  200/ 3414]
loss: 0.049224  [  300/ 3414]
loss: 0.014004  [  400/ 3414]
loss: 0.045442  [  500/ 3414]
loss: 0.028116  [  600/ 3414]
loss: 0.035209  [  700/ 3414]
loss: 0.052117  [  800/ 3414]
loss: 0.023185  [  900/ 3414]
loss: 0.017039  [ 1000/ 3414]
loss: 0.023130  [ 1100/ 3414]
loss: 0.007047  [ 1200/ 3414]
loss: 0.032420  [ 1300/ 3414]
loss: 0.018752  [ 1400/ 3414]
loss: 0.027137  [ 1500/ 3414]
loss: 0.010880  [ 1600/ 3414]
loss: 0.009925  [ 1700/ 3414]
loss: 0.029797  [ 1800/ 3414]
loss: 0.020945  [ 1900/ 3414]
loss: 0.033071  [ 2000/ 3414]
loss: 0.033686  [ 2100/ 3414]
loss: 0.040915  [ 2200/ 3414]
loss: 0.034860  [ 2300/ 3414]
loss: 0.008465  [ 2400/ 3414]
loss: 0.159121  [ 2500/ 3414]
loss: 0.024007  [ 2600/ 3414]
loss: 0.014183  [ 2700/ 3414]
loss: 0.013383  [ 2800/ 3414]
loss: 0.041955  [ 2900/ 3414]
loss: 0.046754  [ 3000/ 3414]
loss: 0.034622  [ 3100/ 3414]
loss: 0.021570  [ 3200/ 3414]
loss: 0.011989  [ 3300/ 3414]
loss: 0.024433  [ 3400/ 3414]
Epoch 4
-------------------------------
loss: 0.045777  [    0/ 3414]
loss: 0.029662  [  100/ 3414]
loss: 0.008424  [  200/ 3414]
loss: 0.048512  [  300/ 3414]
loss: 0.013840  [  400/ 3414]
loss: 0.044860  [  500/ 3414]
loss: 0.028082  [  600/ 3414]
loss: 0.035893  [  700/ 3414]
loss: 0.051276  [  800/ 3414]
loss: 0.022949  [  900/ 3414]
loss: 0.017021  [ 1000/ 3414]
loss: 0.022776  [ 1100/ 3414]
loss: 0.006948  [ 1200/ 3414]
loss: 0.032479  [ 1300/ 3414]
loss: 0.018860  [ 1400/ 3414]
loss: 0.026944  [ 1500/ 3414]
loss: 0.010832  [ 1600/ 3414]
loss: 0.009950  [ 1700/ 3414]
loss: 0.029715  [ 1800/ 3414]
loss: 0.021013  [ 1900/ 3414]
loss: 0.033068  [ 2000/ 3414]
loss: 0.033184  [ 2100/ 3414]
loss: 0.040073  [ 2200/ 3414]
loss: 0.035418  [ 2300/ 3414]
loss: 0.008343  [ 2400/ 3414]
loss: 0.159228  [ 2500/ 3414]
loss: 0.023830  [ 2600/ 3414]
loss: 0.013879  [ 2700/ 3414]
loss: 0.013115  [ 2800/ 3414]
loss: 0.042726  [ 2900/ 3414]
loss: 0.046033  [ 3000/ 3414]
loss: 0.034553  [ 3100/ 3414]
loss: 0.021705  [ 3200/ 3414]
loss: 0.011793  [ 3300/ 3414]
loss: 0.024187  [ 3400/ 3414]
Epoch 5
-------------------------------
loss: 0.045265  [    0/ 3414]
loss: 0.029845  [  100/ 3414]
loss: 0.008367  [  200/ 3414]
loss: 0.048136  [  300/ 3414]
loss: 0.013729  [  400/ 3414]
loss: 0.044385  [  500/ 3414]
loss: 0.028071  [  600/ 3414]
loss: 0.036542  [  700/ 3414]
loss: 0.050763  [  800/ 3414]
loss: 0.022864  [  900/ 3414]
loss: 0.016843  [ 1000/ 3414]
loss: 0.022509  [ 1100/ 3414]
loss: 0.006981  [ 1200/ 3414]
loss: 0.032543  [ 1300/ 3414]
loss: 0.018950  [ 1400/ 3414]
loss: 0.026746  [ 1500/ 3414]
loss: 0.010673  [ 1600/ 3414]
loss: 0.009949  [ 1700/ 3414]
loss: 0.029609  [ 1800/ 3414]
loss: 0.021080  [ 1900/ 3414]
loss: 0.032990  [ 2000/ 3414]
loss: 0.032994  [ 2100/ 3414]
loss: 0.039735  [ 2200/ 3414]
loss: 0.035912  [ 2300/ 3414]
loss: 0.008363  [ 2400/ 3414]
loss: 0.158407  [ 2500/ 3414]
loss: 0.023663  [ 2600/ 3414]
loss: 0.013822  [ 2700/ 3414]
loss: 0.012990  [ 2800/ 3414]
loss: 0.043186  [ 2900/ 3414]
loss: 0.045570  [ 3000/ 3414]
loss: 0.034441  [ 3100/ 3414]
loss: 0.021817  [ 3200/ 3414]
loss: 0.011639  [ 3300/ 3414]
loss: 0.024055  [ 3400/ 3414]
Epoch 6
-------------------------------
loss: 0.044698  [    0/ 3414]
loss: 0.030022  [  100/ 3414]
loss: 0.008353  [  200/ 3414]
loss: 0.047970  [  300/ 3414]
loss: 0.013720  [  400/ 3414]
loss: 0.044103  [  500/ 3414]
loss: 0.028079  [  600/ 3414]
loss: 0.036971  [  700/ 3414]
loss: 0.050357  [  800/ 3414]
loss: 0.023205  [  900/ 3414]
loss: 0.016658  [ 1000/ 3414]
loss: 0.022217  [ 1100/ 3414]
loss: 0.007029  [ 1200/ 3414]
loss: 0.032683  [ 1300/ 3414]
loss: 0.019042  [ 1400/ 3414]
loss: 0.026568  [ 1500/ 3414]
loss: 0.010612  [ 1600/ 3414]
loss: 0.009862  [ 1700/ 3414]
loss: 0.029501  [ 1800/ 3414]
loss: 0.021124  [ 1900/ 3414]
loss: 0.032946  [ 2000/ 3414]
loss: 0.032651  [ 2100/ 3414]
loss: 0.039612  [ 2200/ 3414]
loss: 0.036324  [ 2300/ 3414]
loss: 0.008315  [ 2400/ 3414]
loss: 0.158680  [ 2500/ 3414]
loss: 0.023430  [ 2600/ 3414]
loss: 0.013764  [ 2700/ 3414]
loss: 0.012759  [ 2800/ 3414]
loss: 0.043490  [ 2900/ 3414]
loss: 0.045071  [ 3000/ 3414]
loss: 0.034293  [ 3100/ 3414]
loss: 0.021968  [ 3200/ 3414]
loss: 0.011501  [ 3300/ 3414]
loss: 0.023933  [ 3400/ 3414]
Epoch 7
-------------------------------
loss: 0.044231  [    0/ 3414]
loss: 0.030168  [  100/ 3414]
loss: 0.008405  [  200/ 3414]
loss: 0.047744  [  300/ 3414]
loss: 0.013774  [  400/ 3414]
loss: 0.043912  [  500/ 3414]
loss: 0.028252  [  600/ 3414]
loss: 0.037086  [  700/ 3414]
loss: 0.050155  [  800/ 3414]
loss: 0.023620  [  900/ 3414]
loss: 0.016585  [ 1000/ 3414]
loss: 0.022042  [ 1100/ 3414]
loss: 0.007124  [ 1200/ 3414]
loss: 0.032695  [ 1300/ 3414]
loss: 0.019124  [ 1400/ 3414]
loss: 0.026320  [ 1500/ 3414]
loss: 0.010450  [ 1600/ 3414]
loss: 0.009792  [ 1700/ 3414]
loss: 0.029389  [ 1800/ 3414]
loss: 0.021096  [ 1900/ 3414]
loss: 0.032954  [ 2000/ 3414]
loss: 0.032344  [ 2100/ 3414]
loss: 0.039483  [ 2200/ 3414]
loss: 0.036566  [ 2300/ 3414]
loss: 0.008252  [ 2400/ 3414]
loss: 0.158634  [ 2500/ 3414]
loss: 0.023219  [ 2600/ 3414]
loss: 0.013620  [ 2700/ 3414]
loss: 0.012534  [ 2800/ 3414]
loss: 0.043733  [ 2900/ 3414]
loss: 0.044511  [ 3000/ 3414]
loss: 0.034205  [ 3100/ 3414]
loss: 0.021716  [ 3200/ 3414]
loss: 0.011396  [ 3300/ 3414]
loss: 0.023812  [ 3400/ 3414]
Epoch 8
-------------------------------
loss: 0.044104  [    0/ 3414]
loss: 0.030270  [  100/ 3414]
loss: 0.008437  [  200/ 3414]
loss: 0.047647  [  300/ 3414]
loss: 0.013797  [  400/ 3414]
loss: 0.043737  [  500/ 3414]
loss: 0.028184  [  600/ 3414]
loss: 0.037130  [  700/ 3414]
loss: 0.050117  [  800/ 3414]
loss: 0.023558  [  900/ 3414]
loss: 0.016439  [ 1000/ 3414]
loss: 0.021919  [ 1100/ 3414]
loss: 0.007205  [ 1200/ 3414]
loss: 0.032687  [ 1300/ 3414]
loss: 0.019141  [ 1400/ 3414]
loss: 0.026138  [ 1500/ 3414]
loss: 0.010306  [ 1600/ 3414]
loss: 0.009736  [ 1700/ 3414]
loss: 0.029313  [ 1800/ 3414]
loss: 0.021107  [ 1900/ 3414]
loss: 0.032916  [ 2000/ 3414]
loss: 0.032034  [ 2100/ 3414]
loss: 0.039422  [ 2200/ 3414]
loss: 0.036900  [ 2300/ 3414]
loss: 0.008223  [ 2400/ 3414]
loss: 0.158819  [ 2500/ 3414]
loss: 0.023128  [ 2600/ 3414]
loss: 0.013535  [ 2700/ 3414]
loss: 0.012342  [ 2800/ 3414]
loss: 0.043795  [ 2900/ 3414]
loss: 0.044003  [ 3000/ 3414]
loss: 0.034163  [ 3100/ 3414]
loss: 0.021905  [ 3200/ 3414]
loss: 0.011320  [ 3300/ 3414]
loss: 0.023756  [ 3400/ 3414]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3414
First Spike after testing: [0.16090944 0.7028661 ]
[1 1 0 ... 0 0 2]
[2 1 0 ... 1 1 0]
Cluster 0 Occurrences: 1136; KMEANS: 1022
Cluster 1 Occurrences: 1099; KMEANS: 1681
Cluster 2 Occurrences: 1179; KMEANS: 711
Centroids: [[-0.54265743, 0.41883644], [-0.61967, 0.4966374], [-0.93652683, 0.15794519]]
Centroids: [[-1.0213856, -0.00011375039], [-0.6193769, 0.35080793], [-0.4453061, 0.8695192]]
Contingency Matrix: 
[[144 683 309]
 [144 613 342]
 [734 385  60]]
[[-1, 683, 309], [-1, 613, 342], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 342], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[683 309 144]
 [613 342 144]
 [385  60 734]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [683, 342, 734], Sum: 1759
All_Elements: [683, 309, 144, 613, 342, 144, 385, 60, 734], Sum: 3414
Accuracy: 0.5152314001171646
Done!
