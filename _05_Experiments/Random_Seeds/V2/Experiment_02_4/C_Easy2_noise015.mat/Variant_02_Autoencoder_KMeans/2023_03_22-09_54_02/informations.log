Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_54_02
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211EE996F60>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x00000211E96DAA20>
Epoch 1
-------------------------------
loss: 0.323118  [    0/ 3411]
loss: 0.159749  [  100/ 3411]
loss: 0.129705  [  200/ 3411]
loss: 0.019837  [  300/ 3411]
loss: 0.039801  [  400/ 3411]
loss: 0.030188  [  500/ 3411]
loss: 0.012548  [  600/ 3411]
loss: 0.026055  [  700/ 3411]
loss: 0.033939  [  800/ 3411]
loss: 0.042488  [  900/ 3411]
loss: 0.003473  [ 1000/ 3411]
loss: 0.046011  [ 1100/ 3411]
loss: 0.019422  [ 1200/ 3411]
loss: 0.029128  [ 1300/ 3411]
loss: 0.025810  [ 1400/ 3411]
loss: 0.064462  [ 1500/ 3411]
loss: 0.036534  [ 1600/ 3411]
loss: 0.021725  [ 1700/ 3411]
loss: 0.019824  [ 1800/ 3411]
loss: 0.004710  [ 1900/ 3411]
loss: 0.036096  [ 2000/ 3411]
loss: 0.009446  [ 2100/ 3411]
loss: 0.007640  [ 2200/ 3411]
loss: 0.153440  [ 2300/ 3411]
loss: 0.015739  [ 2400/ 3411]
loss: 0.010558  [ 2500/ 3411]
loss: 0.015622  [ 2600/ 3411]
loss: 0.007967  [ 2700/ 3411]
loss: 0.026847  [ 2800/ 3411]
loss: 0.010821  [ 2900/ 3411]
loss: 0.007232  [ 3000/ 3411]
loss: 0.006292  [ 3100/ 3411]
loss: 0.025626  [ 3200/ 3411]
loss: 0.012899  [ 3300/ 3411]
loss: 0.010367  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.022656  [    0/ 3411]
loss: 0.013827  [  100/ 3411]
loss: 0.009956  [  200/ 3411]
loss: 0.013060  [  300/ 3411]
loss: 0.031890  [  400/ 3411]
loss: 0.009868  [  500/ 3411]
loss: 0.004069  [  600/ 3411]
loss: 0.018487  [  700/ 3411]
loss: 0.020301  [  800/ 3411]
loss: 0.015390  [  900/ 3411]
loss: 0.003036  [ 1000/ 3411]
loss: 0.014032  [ 1100/ 3411]
loss: 0.019485  [ 1200/ 3411]
loss: 0.012147  [ 1300/ 3411]
loss: 0.020608  [ 1400/ 3411]
loss: 0.058965  [ 1500/ 3411]
loss: 0.019165  [ 1600/ 3411]
loss: 0.017209  [ 1700/ 3411]
loss: 0.019552  [ 1800/ 3411]
loss: 0.005116  [ 1900/ 3411]
loss: 0.033851  [ 2000/ 3411]
loss: 0.007546  [ 2100/ 3411]
loss: 0.007277  [ 2200/ 3411]
loss: 0.149743  [ 2300/ 3411]
loss: 0.015829  [ 2400/ 3411]
loss: 0.008356  [ 2500/ 3411]
loss: 0.012364  [ 2600/ 3411]
loss: 0.008252  [ 2700/ 3411]
loss: 0.027132  [ 2800/ 3411]
loss: 0.011545  [ 2900/ 3411]
loss: 0.008353  [ 3000/ 3411]
loss: 0.006318  [ 3100/ 3411]
loss: 0.024211  [ 3200/ 3411]
loss: 0.013174  [ 3300/ 3411]
loss: 0.010355  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.021402  [    0/ 3411]
loss: 0.013697  [  100/ 3411]
loss: 0.009616  [  200/ 3411]
loss: 0.012444  [  300/ 3411]
loss: 0.033769  [  400/ 3411]
loss: 0.010086  [  500/ 3411]
loss: 0.003455  [  600/ 3411]
loss: 0.011827  [  700/ 3411]
loss: 0.020183  [  800/ 3411]
loss: 0.015999  [  900/ 3411]
loss: 0.003175  [ 1000/ 3411]
loss: 0.009997  [ 1100/ 3411]
loss: 0.019241  [ 1200/ 3411]
loss: 0.011991  [ 1300/ 3411]
loss: 0.020006  [ 1400/ 3411]
loss: 0.059516  [ 1500/ 3411]
loss: 0.017869  [ 1600/ 3411]
loss: 0.018731  [ 1700/ 3411]
loss: 0.017813  [ 1800/ 3411]
loss: 0.005268  [ 1900/ 3411]
loss: 0.033592  [ 2000/ 3411]
loss: 0.006944  [ 2100/ 3411]
loss: 0.007341  [ 2200/ 3411]
loss: 0.149539  [ 2300/ 3411]
loss: 0.016530  [ 2400/ 3411]
loss: 0.007687  [ 2500/ 3411]
loss: 0.009767  [ 2600/ 3411]
loss: 0.008363  [ 2700/ 3411]
loss: 0.026627  [ 2800/ 3411]
loss: 0.011521  [ 2900/ 3411]
loss: 0.010275  [ 3000/ 3411]
loss: 0.006133  [ 3100/ 3411]
loss: 0.023348  [ 3200/ 3411]
loss: 0.013377  [ 3300/ 3411]
loss: 0.009787  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.020965  [    0/ 3411]
loss: 0.013704  [  100/ 3411]
loss: 0.010309  [  200/ 3411]
loss: 0.012407  [  300/ 3411]
loss: 0.033697  [  400/ 3411]
loss: 0.009893  [  500/ 3411]
loss: 0.003275  [  600/ 3411]
loss: 0.007118  [  700/ 3411]
loss: 0.019992  [  800/ 3411]
loss: 0.016345  [  900/ 3411]
loss: 0.003301  [ 1000/ 3411]
loss: 0.008888  [ 1100/ 3411]
loss: 0.019154  [ 1200/ 3411]
loss: 0.011966  [ 1300/ 3411]
loss: 0.019855  [ 1400/ 3411]
loss: 0.061331  [ 1500/ 3411]
loss: 0.018116  [ 1600/ 3411]
loss: 0.018190  [ 1700/ 3411]
loss: 0.015833  [ 1800/ 3411]
loss: 0.005558  [ 1900/ 3411]
loss: 0.033822  [ 2000/ 3411]
loss: 0.006641  [ 2100/ 3411]
loss: 0.007512  [ 2200/ 3411]
loss: 0.150038  [ 2300/ 3411]
loss: 0.016937  [ 2400/ 3411]
loss: 0.007465  [ 2500/ 3411]
loss: 0.008406  [ 2600/ 3411]
loss: 0.008309  [ 2700/ 3411]
loss: 0.026624  [ 2800/ 3411]
loss: 0.011310  [ 2900/ 3411]
loss: 0.011995  [ 3000/ 3411]
loss: 0.005983  [ 3100/ 3411]
loss: 0.023059  [ 3200/ 3411]
loss: 0.013460  [ 3300/ 3411]
loss: 0.009027  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.020902  [    0/ 3411]
loss: 0.013753  [  100/ 3411]
loss: 0.011337  [  200/ 3411]
loss: 0.012377  [  300/ 3411]
loss: 0.033159  [  400/ 3411]
loss: 0.009553  [  500/ 3411]
loss: 0.003194  [  600/ 3411]
loss: 0.004850  [  700/ 3411]
loss: 0.019756  [  800/ 3411]
loss: 0.016711  [  900/ 3411]
loss: 0.003392  [ 1000/ 3411]
loss: 0.008455  [ 1100/ 3411]
loss: 0.019174  [ 1200/ 3411]
loss: 0.011778  [ 1300/ 3411]
loss: 0.019867  [ 1400/ 3411]
loss: 0.063775  [ 1500/ 3411]
loss: 0.018862  [ 1600/ 3411]
loss: 0.016880  [ 1700/ 3411]
loss: 0.014543  [ 1800/ 3411]
loss: 0.005707  [ 1900/ 3411]
loss: 0.033958  [ 2000/ 3411]
loss: 0.006391  [ 2100/ 3411]
loss: 0.007686  [ 2200/ 3411]
loss: 0.150558  [ 2300/ 3411]
loss: 0.017284  [ 2400/ 3411]
loss: 0.007417  [ 2500/ 3411]
loss: 0.007862  [ 2600/ 3411]
loss: 0.008239  [ 2700/ 3411]
loss: 0.026441  [ 2800/ 3411]
loss: 0.011248  [ 2900/ 3411]
loss: 0.012338  [ 3000/ 3411]
loss: 0.006126  [ 3100/ 3411]
loss: 0.023049  [ 3200/ 3411]
loss: 0.013432  [ 3300/ 3411]
loss: 0.008315  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.020752  [    0/ 3411]
loss: 0.013728  [  100/ 3411]
loss: 0.012368  [  200/ 3411]
loss: 0.012374  [  300/ 3411]
loss: 0.032821  [  400/ 3411]
loss: 0.009487  [  500/ 3411]
loss: 0.003145  [  600/ 3411]
loss: 0.003834  [  700/ 3411]
loss: 0.019427  [  800/ 3411]
loss: 0.016703  [  900/ 3411]
loss: 0.003468  [ 1000/ 3411]
loss: 0.008198  [ 1100/ 3411]
loss: 0.019234  [ 1200/ 3411]
loss: 0.011830  [ 1300/ 3411]
loss: 0.019979  [ 1400/ 3411]
loss: 0.065384  [ 1500/ 3411]
loss: 0.019539  [ 1600/ 3411]
loss: 0.015718  [ 1700/ 3411]
loss: 0.013802  [ 1800/ 3411]
loss: 0.005852  [ 1900/ 3411]
loss: 0.034076  [ 2000/ 3411]
loss: 0.006362  [ 2100/ 3411]
loss: 0.007956  [ 2200/ 3411]
loss: 0.150932  [ 2300/ 3411]
loss: 0.017089  [ 2400/ 3411]
loss: 0.007250  [ 2500/ 3411]
loss: 0.007271  [ 2600/ 3411]
loss: 0.008160  [ 2700/ 3411]
loss: 0.026425  [ 2800/ 3411]
loss: 0.011276  [ 2900/ 3411]
loss: 0.012441  [ 3000/ 3411]
loss: 0.005972  [ 3100/ 3411]
loss: 0.023127  [ 3200/ 3411]
loss: 0.013513  [ 3300/ 3411]
loss: 0.007995  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.020674  [    0/ 3411]
loss: 0.013724  [  100/ 3411]
loss: 0.013235  [  200/ 3411]
loss: 0.012367  [  300/ 3411]
loss: 0.032488  [  400/ 3411]
loss: 0.009522  [  500/ 3411]
loss: 0.003094  [  600/ 3411]
loss: 0.003414  [  700/ 3411]
loss: 0.019338  [  800/ 3411]
loss: 0.016834  [  900/ 3411]
loss: 0.003524  [ 1000/ 3411]
loss: 0.008232  [ 1100/ 3411]
loss: 0.019351  [ 1200/ 3411]
loss: 0.011816  [ 1300/ 3411]
loss: 0.019946  [ 1400/ 3411]
loss: 0.066997  [ 1500/ 3411]
loss: 0.020251  [ 1600/ 3411]
loss: 0.014978  [ 1700/ 3411]
loss: 0.013467  [ 1800/ 3411]
loss: 0.005841  [ 1900/ 3411]
loss: 0.034241  [ 2000/ 3411]
loss: 0.006417  [ 2100/ 3411]
loss: 0.007956  [ 2200/ 3411]
loss: 0.150960  [ 2300/ 3411]
loss: 0.017089  [ 2400/ 3411]
loss: 0.007127  [ 2500/ 3411]
loss: 0.006983  [ 2600/ 3411]
loss: 0.008039  [ 2700/ 3411]
loss: 0.026378  [ 2800/ 3411]
loss: 0.011241  [ 2900/ 3411]
loss: 0.012370  [ 3000/ 3411]
loss: 0.005783  [ 3100/ 3411]
loss: 0.023106  [ 3200/ 3411]
loss: 0.013467  [ 3300/ 3411]
loss: 0.007584  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.020384  [    0/ 3411]
loss: 0.013759  [  100/ 3411]
loss: 0.013884  [  200/ 3411]
loss: 0.012366  [  300/ 3411]
loss: 0.032339  [  400/ 3411]
loss: 0.009502  [  500/ 3411]
loss: 0.003069  [  600/ 3411]
loss: 0.003170  [  700/ 3411]
loss: 0.019169  [  800/ 3411]
loss: 0.016797  [  900/ 3411]
loss: 0.003569  [ 1000/ 3411]
loss: 0.008106  [ 1100/ 3411]
loss: 0.019397  [ 1200/ 3411]
loss: 0.011774  [ 1300/ 3411]
loss: 0.019938  [ 1400/ 3411]
loss: 0.068065  [ 1500/ 3411]
loss: 0.020664  [ 1600/ 3411]
loss: 0.014283  [ 1700/ 3411]
loss: 0.013243  [ 1800/ 3411]
loss: 0.005946  [ 1900/ 3411]
loss: 0.034289  [ 2000/ 3411]
loss: 0.006311  [ 2100/ 3411]
loss: 0.008081  [ 2200/ 3411]
loss: 0.151111  [ 2300/ 3411]
loss: 0.016980  [ 2400/ 3411]
loss: 0.007032  [ 2500/ 3411]
loss: 0.006652  [ 2600/ 3411]
loss: 0.007890  [ 2700/ 3411]
loss: 0.026481  [ 2800/ 3411]
loss: 0.011128  [ 2900/ 3411]
loss: 0.012500  [ 3000/ 3411]
loss: 0.005736  [ 3100/ 3411]
loss: 0.023072  [ 3200/ 3411]
loss: 0.013383  [ 3300/ 3411]
loss: 0.007455  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [0.37739995 1.8760531 ]
[0 2 0 ... 1 1 2]
[2 1 0 ... 0 0 1]
Cluster 0 Occurrences: 1181; KMEANS: 1092
Cluster 1 Occurrences: 1098; KMEANS: 1111
Cluster 2 Occurrences: 1132; KMEANS: 1208
Centroids: [[0.47911966, 1.7568591], [0.1370892, 1.1314961], [-2.1948493, -0.8363436]]
Centroids: [[0.100879446, 1.0907496], [-2.221661, -0.866416], [0.48832795, 1.7731638]]
Contingency Matrix: 
[[  61    0 1120]
 [1012    0   86]
 [  19 1111    2]]
[[-1, -1, -1], [1012, 0, -1], [19, 1111, -1]]
[[-1, -1, -1], [1012, -1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 2: 1, 1: 0}
New Contingency Matrix: 
[[1120   61    0]
 [  86 1012    0]
 [   2   19 1111]]
New Clustered Label Sequence: [2, 0, 1]
Diagonal_Elements: [1120, 1012, 1111], Sum: 3243
All_Elements: [1120, 61, 0, 86, 1012, 0, 2, 19, 1111], Sum: 3411
Accuracy: 0.9507475813544415
Done!
