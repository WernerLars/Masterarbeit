Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_04_30
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211EE996F60>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x0000021209B12828>
Epoch 1
-------------------------------
loss: 0.144623  [    0/ 3462]
loss: 0.090627  [  100/ 3462]
loss: 0.065603  [  200/ 3462]
loss: 0.065008  [  300/ 3462]
loss: 0.040659  [  400/ 3462]
loss: 0.013992  [  500/ 3462]
loss: 0.014973  [  600/ 3462]
loss: 0.021820  [  700/ 3462]
loss: 0.010911  [  800/ 3462]
loss: 0.014401  [  900/ 3462]
loss: 0.013490  [ 1000/ 3462]
loss: 0.059751  [ 1100/ 3462]
loss: 0.012762  [ 1200/ 3462]
loss: 0.005722  [ 1300/ 3462]
loss: 0.008159  [ 1400/ 3462]
loss: 0.007484  [ 1500/ 3462]
loss: 0.007897  [ 1600/ 3462]
loss: 0.005471  [ 1700/ 3462]
loss: 0.015021  [ 1800/ 3462]
loss: 0.007098  [ 1900/ 3462]
loss: 0.010867  [ 2000/ 3462]
loss: 0.057555  [ 2100/ 3462]
loss: 0.002427  [ 2200/ 3462]
loss: 0.007299  [ 2300/ 3462]
loss: 0.012226  [ 2400/ 3462]
loss: 0.005052  [ 2500/ 3462]
loss: 0.013859  [ 2600/ 3462]
loss: 0.007043  [ 2700/ 3462]
loss: 0.004407  [ 2800/ 3462]
loss: 0.014121  [ 2900/ 3462]
loss: 0.115434  [ 3000/ 3462]
loss: 0.007179  [ 3100/ 3462]
loss: 0.007926  [ 3200/ 3462]
loss: 0.132953  [ 3300/ 3462]
loss: 0.012086  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.001703  [    0/ 3462]
loss: 0.012357  [  100/ 3462]
loss: 0.011610  [  200/ 3462]
loss: 0.008246  [  300/ 3462]
loss: 0.008555  [  400/ 3462]
loss: 0.005665  [  500/ 3462]
loss: 0.001802  [  600/ 3462]
loss: 0.017479  [  700/ 3462]
loss: 0.008906  [  800/ 3462]
loss: 0.017379  [  900/ 3462]
loss: 0.009893  [ 1000/ 3462]
loss: 0.037436  [ 1100/ 3462]
loss: 0.020556  [ 1200/ 3462]
loss: 0.003382  [ 1300/ 3462]
loss: 0.004764  [ 1400/ 3462]
loss: 0.007497  [ 1500/ 3462]
loss: 0.008337  [ 1600/ 3462]
loss: 0.004824  [ 1700/ 3462]
loss: 0.017886  [ 1800/ 3462]
loss: 0.005193  [ 1900/ 3462]
loss: 0.006404  [ 2000/ 3462]
loss: 0.051905  [ 2100/ 3462]
loss: 0.002041  [ 2200/ 3462]
loss: 0.007942  [ 2300/ 3462]
loss: 0.012417  [ 2400/ 3462]
loss: 0.004526  [ 2500/ 3462]
loss: 0.013235  [ 2600/ 3462]
loss: 0.006889  [ 2700/ 3462]
loss: 0.003721  [ 2800/ 3462]
loss: 0.012768  [ 2900/ 3462]
loss: 0.116802  [ 3000/ 3462]
loss: 0.007549  [ 3100/ 3462]
loss: 0.007967  [ 3200/ 3462]
loss: 0.123907  [ 3300/ 3462]
loss: 0.011193  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.001729  [    0/ 3462]
loss: 0.012117  [  100/ 3462]
loss: 0.010206  [  200/ 3462]
loss: 0.007732  [  300/ 3462]
loss: 0.009380  [  400/ 3462]
loss: 0.004064  [  500/ 3462]
loss: 0.000907  [  600/ 3462]
loss: 0.018661  [  700/ 3462]
loss: 0.008292  [  800/ 3462]
loss: 0.016344  [  900/ 3462]
loss: 0.009427  [ 1000/ 3462]
loss: 0.034012  [ 1100/ 3462]
loss: 0.015215  [ 1200/ 3462]
loss: 0.003472  [ 1300/ 3462]
loss: 0.004051  [ 1400/ 3462]
loss: 0.007627  [ 1500/ 3462]
loss: 0.007918  [ 1600/ 3462]
loss: 0.004713  [ 1700/ 3462]
loss: 0.017320  [ 1800/ 3462]
loss: 0.004712  [ 1900/ 3462]
loss: 0.005416  [ 2000/ 3462]
loss: 0.052194  [ 2100/ 3462]
loss: 0.002049  [ 2200/ 3462]
loss: 0.008262  [ 2300/ 3462]
loss: 0.012099  [ 2400/ 3462]
loss: 0.004126  [ 2500/ 3462]
loss: 0.013252  [ 2600/ 3462]
loss: 0.006770  [ 2700/ 3462]
loss: 0.003356  [ 2800/ 3462]
loss: 0.012509  [ 2900/ 3462]
loss: 0.116522  [ 3000/ 3462]
loss: 0.007788  [ 3100/ 3462]
loss: 0.007796  [ 3200/ 3462]
loss: 0.119630  [ 3300/ 3462]
loss: 0.010964  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.001726  [    0/ 3462]
loss: 0.012119  [  100/ 3462]
loss: 0.009531  [  200/ 3462]
loss: 0.008025  [  300/ 3462]
loss: 0.009598  [  400/ 3462]
loss: 0.003268  [  500/ 3462]
loss: 0.000731  [  600/ 3462]
loss: 0.018978  [  700/ 3462]
loss: 0.007721  [  800/ 3462]
loss: 0.015582  [  900/ 3462]
loss: 0.009299  [ 1000/ 3462]
loss: 0.033005  [ 1100/ 3462]
loss: 0.014401  [ 1200/ 3462]
loss: 0.003430  [ 1300/ 3462]
loss: 0.003822  [ 1400/ 3462]
loss: 0.007872  [ 1500/ 3462]
loss: 0.007682  [ 1600/ 3462]
loss: 0.004740  [ 1700/ 3462]
loss: 0.016588  [ 1800/ 3462]
loss: 0.004544  [ 1900/ 3462]
loss: 0.005001  [ 2000/ 3462]
loss: 0.053097  [ 2100/ 3462]
loss: 0.002041  [ 2200/ 3462]
loss: 0.008258  [ 2300/ 3462]
loss: 0.011910  [ 2400/ 3462]
loss: 0.003950  [ 2500/ 3462]
loss: 0.013064  [ 2600/ 3462]
loss: 0.006643  [ 2700/ 3462]
loss: 0.003006  [ 2800/ 3462]
loss: 0.012273  [ 2900/ 3462]
loss: 0.116199  [ 3000/ 3462]
loss: 0.007905  [ 3100/ 3462]
loss: 0.007723  [ 3200/ 3462]
loss: 0.115919  [ 3300/ 3462]
loss: 0.010786  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.001718  [    0/ 3462]
loss: 0.012154  [  100/ 3462]
loss: 0.009098  [  200/ 3462]
loss: 0.008621  [  300/ 3462]
loss: 0.009628  [  400/ 3462]
loss: 0.002770  [  500/ 3462]
loss: 0.000683  [  600/ 3462]
loss: 0.019073  [  700/ 3462]
loss: 0.007250  [  800/ 3462]
loss: 0.015060  [  900/ 3462]
loss: 0.009061  [ 1000/ 3462]
loss: 0.032784  [ 1100/ 3462]
loss: 0.016667  [ 1200/ 3462]
loss: 0.003349  [ 1300/ 3462]
loss: 0.003664  [ 1400/ 3462]
loss: 0.008102  [ 1500/ 3462]
loss: 0.007454  [ 1600/ 3462]
loss: 0.004782  [ 1700/ 3462]
loss: 0.016120  [ 1800/ 3462]
loss: 0.004522  [ 1900/ 3462]
loss: 0.004921  [ 2000/ 3462]
loss: 0.053680  [ 2100/ 3462]
loss: 0.002061  [ 2200/ 3462]
loss: 0.008163  [ 2300/ 3462]
loss: 0.012021  [ 2400/ 3462]
loss: 0.003844  [ 2500/ 3462]
loss: 0.012676  [ 2600/ 3462]
loss: 0.006523  [ 2700/ 3462]
loss: 0.002711  [ 2800/ 3462]
loss: 0.011946  [ 2900/ 3462]
loss: 0.115899  [ 3000/ 3462]
loss: 0.007900  [ 3100/ 3462]
loss: 0.007632  [ 3200/ 3462]
loss: 0.107707  [ 3300/ 3462]
loss: 0.010576  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.001711  [    0/ 3462]
loss: 0.012194  [  100/ 3462]
loss: 0.008630  [  200/ 3462]
loss: 0.009102  [  300/ 3462]
loss: 0.009370  [  400/ 3462]
loss: 0.002560  [  500/ 3462]
loss: 0.000713  [  600/ 3462]
loss: 0.018910  [  700/ 3462]
loss: 0.006876  [  800/ 3462]
loss: 0.014464  [  900/ 3462]
loss: 0.008822  [ 1000/ 3462]
loss: 0.033022  [ 1100/ 3462]
loss: 0.013803  [ 1200/ 3462]
loss: 0.003255  [ 1300/ 3462]
loss: 0.003617  [ 1400/ 3462]
loss: 0.008549  [ 1500/ 3462]
loss: 0.007204  [ 1600/ 3462]
loss: 0.004772  [ 1700/ 3462]
loss: 0.015526  [ 1800/ 3462]
loss: 0.004689  [ 1900/ 3462]
loss: 0.004717  [ 2000/ 3462]
loss: 0.054126  [ 2100/ 3462]
loss: 0.002034  [ 2200/ 3462]
loss: 0.008079  [ 2300/ 3462]
loss: 0.011915  [ 2400/ 3462]
loss: 0.003834  [ 2500/ 3462]
loss: 0.012239  [ 2600/ 3462]
loss: 0.006477  [ 2700/ 3462]
loss: 0.002523  [ 2800/ 3462]
loss: 0.011510  [ 2900/ 3462]
loss: 0.115682  [ 3000/ 3462]
loss: 0.007910  [ 3100/ 3462]
loss: 0.007552  [ 3200/ 3462]
loss: 0.103110  [ 3300/ 3462]
loss: 0.010443  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.001695  [    0/ 3462]
loss: 0.012254  [  100/ 3462]
loss: 0.007991  [  200/ 3462]
loss: 0.009719  [  300/ 3462]
loss: 0.009726  [  400/ 3462]
loss: 0.002447  [  500/ 3462]
loss: 0.000720  [  600/ 3462]
loss: 0.018815  [  700/ 3462]
loss: 0.006459  [  800/ 3462]
loss: 0.013894  [  900/ 3462]
loss: 0.008628  [ 1000/ 3462]
loss: 0.033385  [ 1100/ 3462]
loss: 0.012142  [ 1200/ 3462]
loss: 0.003252  [ 1300/ 3462]
loss: 0.003520  [ 1400/ 3462]
loss: 0.008862  [ 1500/ 3462]
loss: 0.006936  [ 1600/ 3462]
loss: 0.004805  [ 1700/ 3462]
loss: 0.015094  [ 1800/ 3462]
loss: 0.004798  [ 1900/ 3462]
loss: 0.004641  [ 2000/ 3462]
loss: 0.054575  [ 2100/ 3462]
loss: 0.002018  [ 2200/ 3462]
loss: 0.007979  [ 2300/ 3462]
loss: 0.011756  [ 2400/ 3462]
loss: 0.003910  [ 2500/ 3462]
loss: 0.011818  [ 2600/ 3462]
loss: 0.006434  [ 2700/ 3462]
loss: 0.002360  [ 2800/ 3462]
loss: 0.011094  [ 2900/ 3462]
loss: 0.115543  [ 3000/ 3462]
loss: 0.007826  [ 3100/ 3462]
loss: 0.007475  [ 3200/ 3462]
loss: 0.096963  [ 3300/ 3462]
loss: 0.010299  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.001683  [    0/ 3462]
loss: 0.012227  [  100/ 3462]
loss: 0.007455  [  200/ 3462]
loss: 0.010352  [  300/ 3462]
loss: 0.009955  [  400/ 3462]
loss: 0.002190  [  500/ 3462]
loss: 0.000843  [  600/ 3462]
loss: 0.018703  [  700/ 3462]
loss: 0.006140  [  800/ 3462]
loss: 0.013264  [  900/ 3462]
loss: 0.008696  [ 1000/ 3462]
loss: 0.033389  [ 1100/ 3462]
loss: 0.011901  [ 1200/ 3462]
loss: 0.003112  [ 1300/ 3462]
loss: 0.003374  [ 1400/ 3462]
loss: 0.009233  [ 1500/ 3462]
loss: 0.006660  [ 1600/ 3462]
loss: 0.004807  [ 1700/ 3462]
loss: 0.014496  [ 1800/ 3462]
loss: 0.004501  [ 1900/ 3462]
loss: 0.004660  [ 2000/ 3462]
loss: 0.055195  [ 2100/ 3462]
loss: 0.002065  [ 2200/ 3462]
loss: 0.007858  [ 2300/ 3462]
loss: 0.011497  [ 2400/ 3462]
loss: 0.003914  [ 2500/ 3462]
loss: 0.011204  [ 2600/ 3462]
loss: 0.006368  [ 2700/ 3462]
loss: 0.002278  [ 2800/ 3462]
loss: 0.010681  [ 2900/ 3462]
loss: 0.114979  [ 3000/ 3462]
loss: 0.007721  [ 3100/ 3462]
loss: 0.007594  [ 3200/ 3462]
loss: 0.097213  [ 3300/ 3462]
loss: 0.010288  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [-1.0742135  -0.21787813]
[0 2 2 ... 0 1 2]
[0 2 2 ... 0 1 2]
Cluster 0 Occurrences: 1187; KMEANS: 1197
Cluster 1 Occurrences: 1136; KMEANS: 1127
Cluster 2 Occurrences: 1139; KMEANS: 1138
Centroids: [[-1.0003428, -0.25747097], [0.3922738, 2.3098965], [-0.9598287, 0.20205218]]
Centroids: [[-1.0115273, -0.27181226], [0.40171674, 2.3280587], [-0.94636697, 0.21985878]]
Contingency Matrix: 
[[1155    1   31]
 [   4 1124    8]
 [  38    2 1099]]
[[-1, -1, -1], [-1, 1124, 8], [-1, 2, 1099]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 1099]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[1155    1   31]
 [   4 1124    8]
 [  38    2 1099]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1155, 1124, 1099], Sum: 3378
All_Elements: [1155, 1, 31, 4, 1124, 8, 38, 2, 1099], Sum: 3462
Accuracy: 0.975736568457539
Done!
