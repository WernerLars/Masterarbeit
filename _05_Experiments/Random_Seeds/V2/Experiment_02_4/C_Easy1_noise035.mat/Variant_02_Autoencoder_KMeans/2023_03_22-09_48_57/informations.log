Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise035.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise035.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Easy1_noise035.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_48_57
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211E80D1EF0>
Sampling rate: 24000.0
Raw: [-0.01748803 -0.01945498 -0.02011069 ... -0.20744344 -0.24709427
 -0.25077586]
Times: [    662    1043    2861 ... 1439172 1439620 1439793]
Cluster: [1 2 3 ... 3 3 2]
Number of different clusters:  3
Number of Spikes: 3534
First aligned Spike Frame: [ 0.43999329  0.4839933   0.52909327  0.52642944  0.43496308  0.26335103
  0.0652557  -0.09376199 -0.19786698 -0.28302287 -0.39101775 -0.51215993
 -0.44771361  0.07217119  0.76700554  0.91966677  0.38465989 -0.27458603
 -0.59813837 -0.63307973 -0.5997719  -0.60009658 -0.61792931 -0.61010846
 -0.56778745 -0.50195254 -0.4233035  -0.35404397 -0.29120082 -0.20969116
 -0.09592158  0.02951377  0.1302449   0.18393993  0.21396859  0.24968719
  0.25635801  0.17294061 -0.01474948 -0.24084414 -0.43698551 -0.59191978
 -0.72153644 -0.80995398 -0.82451785 -0.75320979 -0.64145157]
Cluster 0, Occurrences: 1208
Cluster 1, Occurrences: 1137
Cluster 2, Occurrences: 1189
<torch.utils.data.dataloader.DataLoader object at 0x00000211E96DAE80>
Epoch 1
-------------------------------
loss: 0.258062  [    0/ 3534]
loss: 0.362536  [  100/ 3534]
loss: 0.140146  [  200/ 3534]
loss: 0.201274  [  300/ 3534]
loss: 0.163432  [  400/ 3534]
loss: 0.159993  [  500/ 3534]
loss: 0.047095  [  600/ 3534]
loss: 0.081061  [  700/ 3534]
loss: 0.080316  [  800/ 3534]
loss: 0.027754  [  900/ 3534]
loss: 0.082301  [ 1000/ 3534]
loss: 0.026352  [ 1100/ 3534]
loss: 0.044408  [ 1200/ 3534]
loss: 0.050832  [ 1300/ 3534]
loss: 0.019221  [ 1400/ 3534]
loss: 0.023881  [ 1500/ 3534]
loss: 0.152544  [ 1600/ 3534]
loss: 0.048637  [ 1700/ 3534]
loss: 0.181941  [ 1800/ 3534]
loss: 0.039108  [ 1900/ 3534]
loss: 0.047386  [ 2000/ 3534]
loss: 0.032829  [ 2100/ 3534]
loss: 0.035175  [ 2200/ 3534]
loss: 0.120550  [ 2300/ 3534]
loss: 0.071027  [ 2400/ 3534]
loss: 0.100754  [ 2500/ 3534]
loss: 0.058039  [ 2600/ 3534]
loss: 0.035359  [ 2700/ 3534]
loss: 0.092273  [ 2800/ 3534]
loss: 0.036928  [ 2900/ 3534]
loss: 0.135208  [ 3000/ 3534]
loss: 0.073230  [ 3100/ 3534]
loss: 0.122578  [ 3200/ 3534]
loss: 0.112947  [ 3300/ 3534]
loss: 0.041018  [ 3400/ 3534]
loss: 0.072729  [ 3500/ 3534]
Epoch 2
-------------------------------
loss: 0.127648  [    0/ 3534]
loss: 0.047640  [  100/ 3534]
loss: 0.040146  [  200/ 3534]
loss: 0.110848  [  300/ 3534]
loss: 0.202224  [  400/ 3534]
loss: 0.075109  [  500/ 3534]
loss: 0.075242  [  600/ 3534]
loss: 0.072810  [  700/ 3534]
loss: 0.038576  [  800/ 3534]
loss: 0.027766  [  900/ 3534]
loss: 0.044357  [ 1000/ 3534]
loss: 0.023218  [ 1100/ 3534]
loss: 0.040119  [ 1200/ 3534]
loss: 0.055272  [ 1300/ 3534]
loss: 0.012028  [ 1400/ 3534]
loss: 0.027862  [ 1500/ 3534]
loss: 0.153431  [ 1600/ 3534]
loss: 0.061107  [ 1700/ 3534]
loss: 0.080242  [ 1800/ 3534]
loss: 0.029627  [ 1900/ 3534]
loss: 0.034249  [ 2000/ 3534]
loss: 0.036574  [ 2100/ 3534]
loss: 0.040855  [ 2200/ 3534]
loss: 0.122410  [ 2300/ 3534]
loss: 0.060224  [ 2400/ 3534]
loss: 0.099244  [ 2500/ 3534]
loss: 0.046567  [ 2600/ 3534]
loss: 0.030356  [ 2700/ 3534]
loss: 0.072666  [ 2800/ 3534]
loss: 0.026124  [ 2900/ 3534]
loss: 0.124918  [ 3000/ 3534]
loss: 0.060909  [ 3100/ 3534]
loss: 0.123754  [ 3200/ 3534]
loss: 0.098583  [ 3300/ 3534]
loss: 0.044502  [ 3400/ 3534]
loss: 0.072178  [ 3500/ 3534]
Epoch 3
-------------------------------
loss: 0.127336  [    0/ 3534]
loss: 0.035630  [  100/ 3534]
loss: 0.028814  [  200/ 3534]
loss: 0.109998  [  300/ 3534]
loss: 0.191531  [  400/ 3534]
loss: 0.064848  [  500/ 3534]
loss: 0.079165  [  600/ 3534]
loss: 0.074323  [  700/ 3534]
loss: 0.038238  [  800/ 3534]
loss: 0.027922  [  900/ 3534]
loss: 0.044506  [ 1000/ 3534]
loss: 0.022831  [ 1100/ 3534]
loss: 0.034329  [ 1200/ 3534]
loss: 0.053213  [ 1300/ 3534]
loss: 0.012092  [ 1400/ 3534]
loss: 0.030239  [ 1500/ 3534]
loss: 0.155268  [ 1600/ 3534]
loss: 0.059542  [ 1700/ 3534]
loss: 0.066001  [ 1800/ 3534]
loss: 0.030081  [ 1900/ 3534]
loss: 0.032892  [ 2000/ 3534]
loss: 0.036149  [ 2100/ 3534]
loss: 0.040636  [ 2200/ 3534]
loss: 0.124635  [ 2300/ 3534]
loss: 0.060983  [ 2400/ 3534]
loss: 0.097771  [ 2500/ 3534]
loss: 0.037499  [ 2600/ 3534]
loss: 0.029843  [ 2700/ 3534]
loss: 0.048277  [ 2800/ 3534]
loss: 0.023702  [ 2900/ 3534]
loss: 0.123705  [ 3000/ 3534]
loss: 0.060628  [ 3100/ 3534]
loss: 0.123181  [ 3200/ 3534]
loss: 0.094418  [ 3300/ 3534]
loss: 0.043443  [ 3400/ 3534]
loss: 0.070416  [ 3500/ 3534]
Epoch 4
-------------------------------
loss: 0.126716  [    0/ 3534]
loss: 0.031252  [  100/ 3534]
loss: 0.026435  [  200/ 3534]
loss: 0.109449  [  300/ 3534]
loss: 0.183784  [  400/ 3534]
loss: 0.059075  [  500/ 3534]
loss: 0.073666  [  600/ 3534]
loss: 0.074802  [  700/ 3534]
loss: 0.037806  [  800/ 3534]
loss: 0.026944  [  900/ 3534]
loss: 0.044345  [ 1000/ 3534]
loss: 0.022638  [ 1100/ 3534]
loss: 0.030021  [ 1200/ 3534]
loss: 0.053768  [ 1300/ 3534]
loss: 0.012523  [ 1400/ 3534]
loss: 0.029812  [ 1500/ 3534]
loss: 0.157682  [ 1600/ 3534]
loss: 0.057478  [ 1700/ 3534]
loss: 0.061506  [ 1800/ 3534]
loss: 0.030286  [ 1900/ 3534]
loss: 0.033220  [ 2000/ 3534]
loss: 0.036267  [ 2100/ 3534]
loss: 0.039047  [ 2200/ 3534]
loss: 0.125890  [ 2300/ 3534]
loss: 0.061223  [ 2400/ 3534]
loss: 0.096985  [ 2500/ 3534]
loss: 0.034709  [ 2600/ 3534]
loss: 0.030113  [ 2700/ 3534]
loss: 0.031329  [ 2800/ 3534]
loss: 0.022777  [ 2900/ 3534]
loss: 0.129452  [ 3000/ 3534]
loss: 0.059207  [ 3100/ 3534]
loss: 0.124045  [ 3200/ 3534]
loss: 0.097386  [ 3300/ 3534]
loss: 0.041974  [ 3400/ 3534]
loss: 0.070583  [ 3500/ 3534]
Epoch 5
-------------------------------
loss: 0.125770  [    0/ 3534]
loss: 0.055764  [  100/ 3534]
loss: 0.026332  [  200/ 3534]
loss: 0.108940  [  300/ 3534]
loss: 0.180717  [  400/ 3534]
loss: 0.057493  [  500/ 3534]
loss: 0.059020  [  600/ 3534]
loss: 0.073617  [  700/ 3534]
loss: 0.037216  [  800/ 3534]
loss: 0.026210  [  900/ 3534]
loss: 0.042941  [ 1000/ 3534]
loss: 0.023102  [ 1100/ 3534]
loss: 0.029119  [ 1200/ 3534]
loss: 0.055778  [ 1300/ 3534]
loss: 0.012923  [ 1400/ 3534]
loss: 0.030270  [ 1500/ 3534]
loss: 0.159489  [ 1600/ 3534]
loss: 0.058077  [ 1700/ 3534]
loss: 0.058351  [ 1800/ 3534]
loss: 0.029960  [ 1900/ 3534]
loss: 0.033188  [ 2000/ 3534]
loss: 0.036339  [ 2100/ 3534]
loss: 0.036790  [ 2200/ 3534]
loss: 0.125860  [ 2300/ 3534]
loss: 0.060373  [ 2400/ 3534]
loss: 0.094975  [ 2500/ 3534]
loss: 0.038427  [ 2600/ 3534]
loss: 0.029893  [ 2700/ 3534]
loss: 0.022128  [ 2800/ 3534]
loss: 0.022458  [ 2900/ 3534]
loss: 0.126424  [ 3000/ 3534]
loss: 0.057908  [ 3100/ 3534]
loss: 0.123091  [ 3200/ 3534]
loss: 0.094969  [ 3300/ 3534]
loss: 0.040990  [ 3400/ 3534]
loss: 0.070397  [ 3500/ 3534]
Epoch 6
-------------------------------
loss: 0.126305  [    0/ 3534]
loss: 0.063552  [  100/ 3534]
loss: 0.025430  [  200/ 3534]
loss: 0.109062  [  300/ 3534]
loss: 0.175835  [  400/ 3534]
loss: 0.052912  [  500/ 3534]
loss: 0.052614  [  600/ 3534]
loss: 0.073783  [  700/ 3534]
loss: 0.036841  [  800/ 3534]
loss: 0.025896  [  900/ 3534]
loss: 0.041427  [ 1000/ 3534]
loss: 0.022858  [ 1100/ 3534]
loss: 0.028515  [ 1200/ 3534]
loss: 0.056175  [ 1300/ 3534]
loss: 0.012735  [ 1400/ 3534]
loss: 0.031283  [ 1500/ 3534]
loss: 0.159918  [ 1600/ 3534]
loss: 0.057039  [ 1700/ 3534]
loss: 0.054079  [ 1800/ 3534]
loss: 0.029631  [ 1900/ 3534]
loss: 0.033166  [ 2000/ 3534]
loss: 0.035997  [ 2100/ 3534]
loss: 0.035258  [ 2200/ 3534]
loss: 0.127011  [ 2300/ 3534]
loss: 0.060390  [ 2400/ 3534]
loss: 0.095382  [ 2500/ 3534]
loss: 0.039640  [ 2600/ 3534]
loss: 0.030722  [ 2700/ 3534]
loss: 0.020517  [ 2800/ 3534]
loss: 0.022594  [ 2900/ 3534]
loss: 0.142990  [ 3000/ 3534]
loss: 0.056685  [ 3100/ 3534]
loss: 0.127144  [ 3200/ 3534]
loss: 0.090789  [ 3300/ 3534]
loss: 0.041442  [ 3400/ 3534]
loss: 0.070557  [ 3500/ 3534]
Epoch 7
-------------------------------
loss: 0.126280  [    0/ 3534]
loss: 0.072616  [  100/ 3534]
loss: 0.024136  [  200/ 3534]
loss: 0.109469  [  300/ 3534]
loss: 0.221119  [  400/ 3534]
loss: 0.050233  [  500/ 3534]
loss: 0.039020  [  600/ 3534]
loss: 0.073012  [  700/ 3534]
loss: 0.036828  [  800/ 3534]
loss: 0.025989  [  900/ 3534]
loss: 0.040046  [ 1000/ 3534]
loss: 0.023409  [ 1100/ 3534]
loss: 0.028168  [ 1200/ 3534]
loss: 0.056722  [ 1300/ 3534]
loss: 0.012058  [ 1400/ 3534]
loss: 0.031362  [ 1500/ 3534]
loss: 0.160815  [ 1600/ 3534]
loss: 0.056448  [ 1700/ 3534]
loss: 0.049315  [ 1800/ 3534]
loss: 0.029210  [ 1900/ 3534]
loss: 0.033451  [ 2000/ 3534]
loss: 0.035603  [ 2100/ 3534]
loss: 0.031444  [ 2200/ 3534]
loss: 0.127930  [ 2300/ 3534]
loss: 0.060597  [ 2400/ 3534]
loss: 0.094888  [ 2500/ 3534]
loss: 0.043387  [ 2600/ 3534]
loss: 0.030873  [ 2700/ 3534]
loss: 0.020155  [ 2800/ 3534]
loss: 0.023286  [ 2900/ 3534]
loss: 0.150374  [ 3000/ 3534]
loss: 0.054034  [ 3100/ 3534]
loss: 0.127909  [ 3200/ 3534]
loss: 0.086768  [ 3300/ 3534]
loss: 0.041069  [ 3400/ 3534]
loss: 0.070442  [ 3500/ 3534]
Epoch 8
-------------------------------
loss: 0.127064  [    0/ 3534]
loss: 0.078934  [  100/ 3534]
loss: 0.025190  [  200/ 3534]
loss: 0.108613  [  300/ 3534]
loss: 0.221580  [  400/ 3534]
loss: 0.045372  [  500/ 3534]
loss: 0.037075  [  600/ 3534]
loss: 0.073751  [  700/ 3534]
loss: 0.036693  [  800/ 3534]
loss: 0.026026  [  900/ 3534]
loss: 0.038827  [ 1000/ 3534]
loss: 0.023079  [ 1100/ 3534]
loss: 0.025894  [ 1200/ 3534]
loss: 0.057880  [ 1300/ 3534]
loss: 0.012666  [ 1400/ 3534]
loss: 0.031811  [ 1500/ 3534]
loss: 0.161732  [ 1600/ 3534]
loss: 0.054763  [ 1700/ 3534]
loss: 0.044918  [ 1800/ 3534]
loss: 0.028837  [ 1900/ 3534]
loss: 0.033510  [ 2000/ 3534]
loss: 0.035228  [ 2100/ 3534]
loss: 0.032609  [ 2200/ 3534]
loss: 0.128322  [ 2300/ 3534]
loss: 0.060454  [ 2400/ 3534]
loss: 0.094847  [ 2500/ 3534]
loss: 0.045627  [ 2600/ 3534]
loss: 0.031095  [ 2700/ 3534]
loss: 0.021932  [ 2800/ 3534]
loss: 0.023133  [ 2900/ 3534]
loss: 0.146105  [ 3000/ 3534]
loss: 0.052008  [ 3100/ 3534]
loss: 0.128788  [ 3200/ 3534]
loss: 0.084783  [ 3300/ 3534]
loss: 0.040419  [ 3400/ 3534]
loss: 0.070376  [ 3500/ 3534]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3534
First Spike after testing: [-0.5975525   0.02853569]
[0 1 2 ... 2 2 1]
[1 2 1 ... 1 1 0]
Cluster 0 Occurrences: 1208; KMEANS: 642
Cluster 1 Occurrences: 1137; KMEANS: 2411
Cluster 2 Occurrences: 1189; KMEANS: 481
Centroids: [[-0.59442985, 0.107193336], [1.8655391, 4.463299], [-1.530987, -0.041456815]]
Centroids: [[1.4731388, 3.5879788], [-1.0595214, 0.024646029], [2.4770355, 5.804708]]
Contingency Matrix: 
[[   1 1207    0]
 [ 628   28  481]
 [  13 1176    0]]
[[-1, -1, -1], [628, -1, 481], [13, -1, 0]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 0]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 1, 1: 0, 2: 2}
New Contingency Matrix: 
[[1207    1    0]
 [  28  628  481]
 [1176   13    0]]
New Clustered Label Sequence: [1, 0, 2]
Diagonal_Elements: [1207, 628, 0], Sum: 1835
All_Elements: [1207, 1, 0, 28, 628, 481, 1176, 13, 0], Sum: 3534
Accuracy: 0.5192416525183927
Done!
