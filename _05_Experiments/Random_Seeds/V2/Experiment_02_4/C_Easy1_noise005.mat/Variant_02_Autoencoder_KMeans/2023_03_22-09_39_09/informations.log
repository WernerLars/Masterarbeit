Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_39_09
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211E80DF2E8>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x00000211E96DAFD0>
Epoch 1
-------------------------------
loss: 0.152677  [    0/ 3514]
loss: 0.202786  [  100/ 3514]
loss: 0.087265  [  200/ 3514]
loss: 0.063021  [  300/ 3514]
loss: 0.008524  [  400/ 3514]
loss: 0.007608  [  500/ 3514]
loss: 0.009013  [  600/ 3514]
loss: 0.003507  [  700/ 3514]
loss: 0.010833  [  800/ 3514]
loss: 0.014371  [  900/ 3514]
loss: 0.006259  [ 1000/ 3514]
loss: 0.094070  [ 1100/ 3514]
loss: 0.007278  [ 1200/ 3514]
loss: 0.002187  [ 1300/ 3514]
loss: 0.094861  [ 1400/ 3514]
loss: 0.000741  [ 1500/ 3514]
loss: 0.005321  [ 1600/ 3514]
loss: 0.005292  [ 1700/ 3514]
loss: 0.237680  [ 1800/ 3514]
loss: 0.007320  [ 1900/ 3514]
loss: 0.003739  [ 2000/ 3514]
loss: 0.006468  [ 2100/ 3514]
loss: 0.001131  [ 2200/ 3514]
loss: 0.001355  [ 2300/ 3514]
loss: 0.002606  [ 2400/ 3514]
loss: 0.006678  [ 2500/ 3514]
loss: 0.003790  [ 2600/ 3514]
loss: 0.003193  [ 2700/ 3514]
loss: 0.007412  [ 2800/ 3514]
loss: 0.005897  [ 2900/ 3514]
loss: 0.013195  [ 3000/ 3514]
loss: 0.002167  [ 3100/ 3514]
loss: 0.001714  [ 3200/ 3514]
loss: 0.007948  [ 3300/ 3514]
loss: 0.007834  [ 3400/ 3514]
loss: 0.002752  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.005762  [    0/ 3514]
loss: 0.002951  [  100/ 3514]
loss: 0.008308  [  200/ 3514]
loss: 0.003200  [  300/ 3514]
loss: 0.003926  [  400/ 3514]
loss: 0.007009  [  500/ 3514]
loss: 0.009456  [  600/ 3514]
loss: 0.001825  [  700/ 3514]
loss: 0.001029  [  800/ 3514]
loss: 0.004588  [  900/ 3514]
loss: 0.005805  [ 1000/ 3514]
loss: 0.091287  [ 1100/ 3514]
loss: 0.002298  [ 1200/ 3514]
loss: 0.001855  [ 1300/ 3514]
loss: 0.097919  [ 1400/ 3514]
loss: 0.000522  [ 1500/ 3514]
loss: 0.005203  [ 1600/ 3514]
loss: 0.005337  [ 1700/ 3514]
loss: 0.171768  [ 1800/ 3514]
loss: 0.006840  [ 1900/ 3514]
loss: 0.002110  [ 2000/ 3514]
loss: 0.006140  [ 2100/ 3514]
loss: 0.000981  [ 2200/ 3514]
loss: 0.001332  [ 2300/ 3514]
loss: 0.002313  [ 2400/ 3514]
loss: 0.006953  [ 2500/ 3514]
loss: 0.003962  [ 2600/ 3514]
loss: 0.001777  [ 2700/ 3514]
loss: 0.007582  [ 2800/ 3514]
loss: 0.002192  [ 2900/ 3514]
loss: 0.012275  [ 3000/ 3514]
loss: 0.001653  [ 3100/ 3514]
loss: 0.001780  [ 3200/ 3514]
loss: 0.009590  [ 3300/ 3514]
loss: 0.007576  [ 3400/ 3514]
loss: 0.003842  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.002327  [    0/ 3514]
loss: 0.001769  [  100/ 3514]
loss: 0.008034  [  200/ 3514]
loss: 0.003173  [  300/ 3514]
loss: 0.004182  [  400/ 3514]
loss: 0.005092  [  500/ 3514]
loss: 0.010106  [  600/ 3514]
loss: 0.002292  [  700/ 3514]
loss: 0.001104  [  800/ 3514]
loss: 0.004475  [  900/ 3514]
loss: 0.006532  [ 1000/ 3514]
loss: 0.092243  [ 1100/ 3514]
loss: 0.001499  [ 1200/ 3514]
loss: 0.001809  [ 1300/ 3514]
loss: 0.094064  [ 1400/ 3514]
loss: 0.000488  [ 1500/ 3514]
loss: 0.005642  [ 1600/ 3514]
loss: 0.005271  [ 1700/ 3514]
loss: 0.153983  [ 1800/ 3514]
loss: 0.006467  [ 1900/ 3514]
loss: 0.001650  [ 2000/ 3514]
loss: 0.006010  [ 2100/ 3514]
loss: 0.000851  [ 2200/ 3514]
loss: 0.001338  [ 2300/ 3514]
loss: 0.002096  [ 2400/ 3514]
loss: 0.006716  [ 2500/ 3514]
loss: 0.003905  [ 2600/ 3514]
loss: 0.001742  [ 2700/ 3514]
loss: 0.007703  [ 2800/ 3514]
loss: 0.001545  [ 2900/ 3514]
loss: 0.009864  [ 3000/ 3514]
loss: 0.002000  [ 3100/ 3514]
loss: 0.001829  [ 3200/ 3514]
loss: 0.007667  [ 3300/ 3514]
loss: 0.006832  [ 3400/ 3514]
loss: 0.003539  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.001512  [    0/ 3514]
loss: 0.001664  [  100/ 3514]
loss: 0.008082  [  200/ 3514]
loss: 0.003304  [  300/ 3514]
loss: 0.004327  [  400/ 3514]
loss: 0.004086  [  500/ 3514]
loss: 0.009272  [  600/ 3514]
loss: 0.002841  [  700/ 3514]
loss: 0.001260  [  800/ 3514]
loss: 0.004437  [  900/ 3514]
loss: 0.006501  [ 1000/ 3514]
loss: 0.092696  [ 1100/ 3514]
loss: 0.001116  [ 1200/ 3514]
loss: 0.001532  [ 1300/ 3514]
loss: 0.094411  [ 1400/ 3514]
loss: 0.000522  [ 1500/ 3514]
loss: 0.006512  [ 1600/ 3514]
loss: 0.005330  [ 1700/ 3514]
loss: 0.150594  [ 1800/ 3514]
loss: 0.005208  [ 1900/ 3514]
loss: 0.001573  [ 2000/ 3514]
loss: 0.005554  [ 2100/ 3514]
loss: 0.000872  [ 2200/ 3514]
loss: 0.001476  [ 2300/ 3514]
loss: 0.002183  [ 2400/ 3514]
loss: 0.006742  [ 2500/ 3514]
loss: 0.003860  [ 2600/ 3514]
loss: 0.001756  [ 2700/ 3514]
loss: 0.007623  [ 2800/ 3514]
loss: 0.001404  [ 2900/ 3514]
loss: 0.006268  [ 3000/ 3514]
loss: 0.002474  [ 3100/ 3514]
loss: 0.001889  [ 3200/ 3514]
loss: 0.007223  [ 3300/ 3514]
loss: 0.006352  [ 3400/ 3514]
loss: 0.002971  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.001628  [    0/ 3514]
loss: 0.001644  [  100/ 3514]
loss: 0.008014  [  200/ 3514]
loss: 0.003426  [  300/ 3514]
loss: 0.004785  [  400/ 3514]
loss: 0.003481  [  500/ 3514]
loss: 0.008713  [  600/ 3514]
loss: 0.002306  [  700/ 3514]
loss: 0.001477  [  800/ 3514]
loss: 0.004553  [  900/ 3514]
loss: 0.006360  [ 1000/ 3514]
loss: 0.093815  [ 1100/ 3514]
loss: 0.000975  [ 1200/ 3514]
loss: 0.001319  [ 1300/ 3514]
loss: 0.089190  [ 1400/ 3514]
loss: 0.000575  [ 1500/ 3514]
loss: 0.007400  [ 1600/ 3514]
loss: 0.005843  [ 1700/ 3514]
loss: 0.148775  [ 1800/ 3514]
loss: 0.003593  [ 1900/ 3514]
loss: 0.001552  [ 2000/ 3514]
loss: 0.005443  [ 2100/ 3514]
loss: 0.000927  [ 2200/ 3514]
loss: 0.001560  [ 2300/ 3514]
loss: 0.002263  [ 2400/ 3514]
loss: 0.007064  [ 2500/ 3514]
loss: 0.003821  [ 2600/ 3514]
loss: 0.001857  [ 2700/ 3514]
loss: 0.007468  [ 2800/ 3514]
loss: 0.001362  [ 2900/ 3514]
loss: 0.004542  [ 3000/ 3514]
loss: 0.003062  [ 3100/ 3514]
loss: 0.001746  [ 3200/ 3514]
loss: 0.006541  [ 3300/ 3514]
loss: 0.006097  [ 3400/ 3514]
loss: 0.002730  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.001827  [    0/ 3514]
loss: 0.001586  [  100/ 3514]
loss: 0.007954  [  200/ 3514]
loss: 0.003544  [  300/ 3514]
loss: 0.004550  [  400/ 3514]
loss: 0.003539  [  500/ 3514]
loss: 0.007803  [  600/ 3514]
loss: 0.001889  [  700/ 3514]
loss: 0.001422  [  800/ 3514]
loss: 0.004583  [  900/ 3514]
loss: 0.006297  [ 1000/ 3514]
loss: 0.093007  [ 1100/ 3514]
loss: 0.000983  [ 1200/ 3514]
loss: 0.001332  [ 1300/ 3514]
loss: 0.089463  [ 1400/ 3514]
loss: 0.000597  [ 1500/ 3514]
loss: 0.007269  [ 1600/ 3514]
loss: 0.005736  [ 1700/ 3514]
loss: 0.147562  [ 1800/ 3514]
loss: 0.003326  [ 1900/ 3514]
loss: 0.001544  [ 2000/ 3514]
loss: 0.005587  [ 2100/ 3514]
loss: 0.000841  [ 2200/ 3514]
loss: 0.001519  [ 2300/ 3514]
loss: 0.002216  [ 2400/ 3514]
loss: 0.007225  [ 2500/ 3514]
loss: 0.004047  [ 2600/ 3514]
loss: 0.001870  [ 2700/ 3514]
loss: 0.007320  [ 2800/ 3514]
loss: 0.001384  [ 2900/ 3514]
loss: 0.004142  [ 3000/ 3514]
loss: 0.003271  [ 3100/ 3514]
loss: 0.001704  [ 3200/ 3514]
loss: 0.006278  [ 3300/ 3514]
loss: 0.005870  [ 3400/ 3514]
loss: 0.002624  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.001621  [    0/ 3514]
loss: 0.001560  [  100/ 3514]
loss: 0.007992  [  200/ 3514]
loss: 0.003565  [  300/ 3514]
loss: 0.004611  [  400/ 3514]
loss: 0.003781  [  500/ 3514]
loss: 0.007762  [  600/ 3514]
loss: 0.001667  [  700/ 3514]
loss: 0.001384  [  800/ 3514]
loss: 0.004478  [  900/ 3514]
loss: 0.006208  [ 1000/ 3514]
loss: 0.092626  [ 1100/ 3514]
loss: 0.000999  [ 1200/ 3514]
loss: 0.001328  [ 1300/ 3514]
loss: 0.087713  [ 1400/ 3514]
loss: 0.000623  [ 1500/ 3514]
loss: 0.006713  [ 1600/ 3514]
loss: 0.005635  [ 1700/ 3514]
loss: 0.146647  [ 1800/ 3514]
loss: 0.003232  [ 1900/ 3514]
loss: 0.001517  [ 2000/ 3514]
loss: 0.005608  [ 2100/ 3514]
loss: 0.000849  [ 2200/ 3514]
loss: 0.001491  [ 2300/ 3514]
loss: 0.002230  [ 2400/ 3514]
loss: 0.007212  [ 2500/ 3514]
loss: 0.003940  [ 2600/ 3514]
loss: 0.001838  [ 2700/ 3514]
loss: 0.007248  [ 2800/ 3514]
loss: 0.001398  [ 2900/ 3514]
loss: 0.004276  [ 3000/ 3514]
loss: 0.004282  [ 3100/ 3514]
loss: 0.001675  [ 3200/ 3514]
loss: 0.006163  [ 3300/ 3514]
loss: 0.005674  [ 3400/ 3514]
loss: 0.002810  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.001460  [    0/ 3514]
loss: 0.001580  [  100/ 3514]
loss: 0.008072  [  200/ 3514]
loss: 0.003608  [  300/ 3514]
loss: 0.004318  [  400/ 3514]
loss: 0.003723  [  500/ 3514]
loss: 0.007570  [  600/ 3514]
loss: 0.001566  [  700/ 3514]
loss: 0.001353  [  800/ 3514]
loss: 0.004408  [  900/ 3514]
loss: 0.006110  [ 1000/ 3514]
loss: 0.092170  [ 1100/ 3514]
loss: 0.000987  [ 1200/ 3514]
loss: 0.001328  [ 1300/ 3514]
loss: 0.087288  [ 1400/ 3514]
loss: 0.000636  [ 1500/ 3514]
loss: 0.005985  [ 1600/ 3514]
loss: 0.005614  [ 1700/ 3514]
loss: 0.146547  [ 1800/ 3514]
loss: 0.003192  [ 1900/ 3514]
loss: 0.001526  [ 2000/ 3514]
loss: 0.005648  [ 2100/ 3514]
loss: 0.000855  [ 2200/ 3514]
loss: 0.001438  [ 2300/ 3514]
loss: 0.002359  [ 2400/ 3514]
loss: 0.007191  [ 2500/ 3514]
loss: 0.003773  [ 2600/ 3514]
loss: 0.001801  [ 2700/ 3514]
loss: 0.007259  [ 2800/ 3514]
loss: 0.001374  [ 2900/ 3514]
loss: 0.004384  [ 3000/ 3514]
loss: 0.004138  [ 3100/ 3514]
loss: 0.001665  [ 3200/ 3514]
loss: 0.006180  [ 3300/ 3514]
loss: 0.005576  [ 3400/ 3514]
loss: 0.003024  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [0.9892966 0.4664266]
[1 0 2 ... 1 0 1]
[2 1 0 ... 2 1 2]
Cluster 0 Occurrences: 1165; KMEANS: 1213
Cluster 1 Occurrences: 1157; KMEANS: 1163
Cluster 2 Occurrences: 1192; KMEANS: 1138
Centroids: [[-1.2265172, 0.7506728], [1.0754868, 0.7660171], [-3.0333252, -0.73922455]]
Centroids: [[-3.0293918, -0.7376628], [-1.1996882, 0.7582112], [1.1156515, 0.7843983]]
Contingency Matrix: 
[[  12 1153    0]
 [  10    9 1138]
 [1191    1    0]]
[[-1, 1153, 0], [-1, 9, 1138], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1138], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1153    0   12]
 [   9 1138   10]
 [   1    0 1191]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1153, 1138, 1191], Sum: 3482
All_Elements: [1153, 0, 12, 9, 1138, 10, 1, 0, 1191], Sum: 3514
Accuracy: 0.9908935685828116
Done!
