Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Easy2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_52_37
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211F02DB208>
Sampling rate: 24000.0
Raw: [-0.04397287 -0.05368168 -0.05753576 ... -0.17707654 -0.14968225
 -0.12084286]
Times: [   1077    1809    2216 ... 1439324 1439736 1439818]
Cluster: [1 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3520
First aligned Spike Frame: [-5.66507481e-02 -6.59320228e-02 -6.70701971e-02 -7.19520617e-02
 -7.89243788e-02 -8.44863120e-02 -9.23204981e-02 -9.75387283e-02
 -7.89589716e-02 -3.66949571e-02  2.34965171e-04 -2.60677777e-03
 -8.36059782e-02 -2.16751250e-01 -3.29544857e-01 -3.35165947e-01
 -2.03449552e-01  7.47840458e-02  4.22419255e-01  7.09409540e-01
  8.78002642e-01  9.55364309e-01  9.77809330e-01  9.55005143e-01
  8.85120577e-01  8.00574977e-01  7.20670596e-01  6.49598354e-01
  5.48520603e-01  4.27922886e-01  3.27637830e-01  2.50259973e-01
  1.79725440e-01  1.08182425e-01  5.15669298e-02  1.18971249e-02
 -1.33865595e-02 -3.45955406e-02 -6.81150537e-02 -1.12799097e-01
 -1.58924383e-01 -1.84417551e-01 -2.01640893e-01 -2.18864546e-01
 -2.16773696e-01 -2.09095391e-01 -1.81456244e-01]
Cluster 0, Occurrences: 1160
Cluster 1, Occurrences: 1146
Cluster 2, Occurrences: 1214
<torch.utils.data.dataloader.DataLoader object at 0x00000211E96DA550>
Epoch 1
-------------------------------
loss: 0.261586  [    0/ 3520]
loss: 0.097380  [  100/ 3520]
loss: 0.194795  [  200/ 3520]
loss: 0.018497  [  300/ 3520]
loss: 0.088030  [  400/ 3520]
loss: 0.145999  [  500/ 3520]
loss: 0.013520  [  600/ 3520]
loss: 0.008432  [  700/ 3520]
loss: 0.005719  [  800/ 3520]
loss: 0.014122  [  900/ 3520]
loss: 0.003836  [ 1000/ 3520]
loss: 0.013781  [ 1100/ 3520]
loss: 0.012528  [ 1200/ 3520]
loss: 0.016538  [ 1300/ 3520]
loss: 0.011560  [ 1400/ 3520]
loss: 0.003345  [ 1500/ 3520]
loss: 0.003484  [ 1600/ 3520]
loss: 0.003042  [ 1700/ 3520]
loss: 0.109946  [ 1800/ 3520]
loss: 0.007970  [ 1900/ 3520]
loss: 0.013358  [ 2000/ 3520]
loss: 0.007580  [ 2100/ 3520]
loss: 0.006722  [ 2200/ 3520]
loss: 0.047271  [ 2300/ 3520]
loss: 0.008415  [ 2400/ 3520]
loss: 0.008629  [ 2500/ 3520]
loss: 0.016116  [ 2600/ 3520]
loss: 0.002600  [ 2700/ 3520]
loss: 0.012896  [ 2800/ 3520]
loss: 0.003703  [ 2900/ 3520]
loss: 0.012047  [ 3000/ 3520]
loss: 0.006931  [ 3100/ 3520]
loss: 0.005704  [ 3200/ 3520]
loss: 0.004601  [ 3300/ 3520]
loss: 0.005684  [ 3400/ 3520]
loss: 0.011417  [ 3500/ 3520]
Epoch 2
-------------------------------
loss: 0.009401  [    0/ 3520]
loss: 0.004450  [  100/ 3520]
loss: 0.131847  [  200/ 3520]
loss: 0.005345  [  300/ 3520]
loss: 0.052063  [  400/ 3520]
loss: 0.068850  [  500/ 3520]
loss: 0.006641  [  600/ 3520]
loss: 0.007351  [  700/ 3520]
loss: 0.005599  [  800/ 3520]
loss: 0.002218  [  900/ 3520]
loss: 0.003186  [ 1000/ 3520]
loss: 0.008464  [ 1100/ 3520]
loss: 0.010143  [ 1200/ 3520]
loss: 0.004905  [ 1300/ 3520]
loss: 0.005677  [ 1400/ 3520]
loss: 0.001870  [ 1500/ 3520]
loss: 0.002980  [ 1600/ 3520]
loss: 0.004336  [ 1700/ 3520]
loss: 0.111127  [ 1800/ 3520]
loss: 0.006496  [ 1900/ 3520]
loss: 0.012493  [ 2000/ 3520]
loss: 0.007648  [ 2100/ 3520]
loss: 0.006074  [ 2200/ 3520]
loss: 0.052058  [ 2300/ 3520]
loss: 0.007951  [ 2400/ 3520]
loss: 0.009355  [ 2500/ 3520]
loss: 0.013890  [ 2600/ 3520]
loss: 0.002663  [ 2700/ 3520]
loss: 0.014381  [ 2800/ 3520]
loss: 0.003197  [ 2900/ 3520]
loss: 0.012241  [ 3000/ 3520]
loss: 0.003438  [ 3100/ 3520]
loss: 0.005699  [ 3200/ 3520]
loss: 0.004445  [ 3300/ 3520]
loss: 0.006404  [ 3400/ 3520]
loss: 0.011103  [ 3500/ 3520]
Epoch 3
-------------------------------
loss: 0.011283  [    0/ 3520]
loss: 0.003901  [  100/ 3520]
loss: 0.102902  [  200/ 3520]
loss: 0.004954  [  300/ 3520]
loss: 0.053885  [  400/ 3520]
loss: 0.061508  [  500/ 3520]
loss: 0.005990  [  600/ 3520]
loss: 0.007936  [  700/ 3520]
loss: 0.005934  [  800/ 3520]
loss: 0.001982  [  900/ 3520]
loss: 0.003386  [ 1000/ 3520]
loss: 0.008583  [ 1100/ 3520]
loss: 0.010775  [ 1200/ 3520]
loss: 0.004175  [ 1300/ 3520]
loss: 0.005309  [ 1400/ 3520]
loss: 0.001831  [ 1500/ 3520]
loss: 0.003238  [ 1600/ 3520]
loss: 0.004264  [ 1700/ 3520]
loss: 0.110189  [ 1800/ 3520]
loss: 0.006140  [ 1900/ 3520]
loss: 0.012374  [ 2000/ 3520]
loss: 0.007489  [ 2100/ 3520]
loss: 0.006245  [ 2200/ 3520]
loss: 0.055816  [ 2300/ 3520]
loss: 0.007881  [ 2400/ 3520]
loss: 0.009419  [ 2500/ 3520]
loss: 0.013127  [ 2600/ 3520]
loss: 0.002762  [ 2700/ 3520]
loss: 0.015001  [ 2800/ 3520]
loss: 0.003304  [ 2900/ 3520]
loss: 0.012037  [ 3000/ 3520]
loss: 0.003107  [ 3100/ 3520]
loss: 0.005602  [ 3200/ 3520]
loss: 0.004290  [ 3300/ 3520]
loss: 0.006658  [ 3400/ 3520]
loss: 0.011127  [ 3500/ 3520]
Epoch 4
-------------------------------
loss: 0.011830  [    0/ 3520]
loss: 0.003711  [  100/ 3520]
loss: 0.092504  [  200/ 3520]
loss: 0.004840  [  300/ 3520]
loss: 0.052288  [  400/ 3520]
loss: 0.059850  [  500/ 3520]
loss: 0.005792  [  600/ 3520]
loss: 0.007841  [  700/ 3520]
loss: 0.005887  [  800/ 3520]
loss: 0.002006  [  900/ 3520]
loss: 0.003327  [ 1000/ 3520]
loss: 0.008640  [ 1100/ 3520]
loss: 0.010679  [ 1200/ 3520]
loss: 0.003487  [ 1300/ 3520]
loss: 0.005557  [ 1400/ 3520]
loss: 0.001837  [ 1500/ 3520]
loss: 0.003161  [ 1600/ 3520]
loss: 0.004296  [ 1700/ 3520]
loss: 0.111047  [ 1800/ 3520]
loss: 0.005993  [ 1900/ 3520]
loss: 0.012271  [ 2000/ 3520]
loss: 0.007335  [ 2100/ 3520]
loss: 0.006561  [ 2200/ 3520]
loss: 0.058099  [ 2300/ 3520]
loss: 0.008108  [ 2400/ 3520]
loss: 0.009420  [ 2500/ 3520]
loss: 0.012775  [ 2600/ 3520]
loss: 0.002810  [ 2700/ 3520]
loss: 0.015092  [ 2800/ 3520]
loss: 0.003096  [ 2900/ 3520]
loss: 0.012085  [ 3000/ 3520]
loss: 0.002605  [ 3100/ 3520]
loss: 0.005485  [ 3200/ 3520]
loss: 0.004105  [ 3300/ 3520]
loss: 0.006807  [ 3400/ 3520]
loss: 0.009939  [ 3500/ 3520]
Epoch 5
-------------------------------
loss: 0.011529  [    0/ 3520]
loss: 0.003421  [  100/ 3520]
loss: 0.090072  [  200/ 3520]
loss: 0.004926  [  300/ 3520]
loss: 0.052093  [  400/ 3520]
loss: 0.059052  [  500/ 3520]
loss: 0.005543  [  600/ 3520]
loss: 0.007973  [  700/ 3520]
loss: 0.005650  [  800/ 3520]
loss: 0.001958  [  900/ 3520]
loss: 0.003399  [ 1000/ 3520]
loss: 0.008531  [ 1100/ 3520]
loss: 0.010086  [ 1200/ 3520]
loss: 0.002311  [ 1300/ 3520]
loss: 0.006092  [ 1400/ 3520]
loss: 0.001943  [ 1500/ 3520]
loss: 0.003026  [ 1600/ 3520]
loss: 0.004405  [ 1700/ 3520]
loss: 0.112384  [ 1800/ 3520]
loss: 0.005989  [ 1900/ 3520]
loss: 0.012683  [ 2000/ 3520]
loss: 0.007060  [ 2100/ 3520]
loss: 0.006554  [ 2200/ 3520]
loss: 0.057850  [ 2300/ 3520]
loss: 0.008256  [ 2400/ 3520]
loss: 0.009566  [ 2500/ 3520]
loss: 0.012694  [ 2600/ 3520]
loss: 0.002866  [ 2700/ 3520]
loss: 0.014870  [ 2800/ 3520]
loss: 0.002707  [ 2900/ 3520]
loss: 0.012353  [ 3000/ 3520]
loss: 0.002677  [ 3100/ 3520]
loss: 0.005564  [ 3200/ 3520]
loss: 0.004190  [ 3300/ 3520]
loss: 0.006693  [ 3400/ 3520]
loss: 0.008842  [ 3500/ 3520]
Epoch 6
-------------------------------
loss: 0.010366  [    0/ 3520]
loss: 0.002895  [  100/ 3520]
loss: 0.089673  [  200/ 3520]
loss: 0.005290  [  300/ 3520]
loss: 0.051485  [  400/ 3520]
loss: 0.059442  [  500/ 3520]
loss: 0.005284  [  600/ 3520]
loss: 0.008061  [  700/ 3520]
loss: 0.005037  [  800/ 3520]
loss: 0.001807  [  900/ 3520]
loss: 0.003503  [ 1000/ 3520]
loss: 0.008222  [ 1100/ 3520]
loss: 0.010080  [ 1200/ 3520]
loss: 0.001708  [ 1300/ 3520]
loss: 0.006985  [ 1400/ 3520]
loss: 0.002198  [ 1500/ 3520]
loss: 0.002877  [ 1600/ 3520]
loss: 0.004439  [ 1700/ 3520]
loss: 0.110930  [ 1800/ 3520]
loss: 0.006140  [ 1900/ 3520]
loss: 0.013404  [ 2000/ 3520]
loss: 0.006189  [ 2100/ 3520]
loss: 0.006267  [ 2200/ 3520]
loss: 0.056599  [ 2300/ 3520]
loss: 0.008592  [ 2400/ 3520]
loss: 0.010018  [ 2500/ 3520]
loss: 0.012449  [ 2600/ 3520]
loss: 0.002924  [ 2700/ 3520]
loss: 0.013761  [ 2800/ 3520]
loss: 0.002238  [ 2900/ 3520]
loss: 0.012426  [ 3000/ 3520]
loss: 0.002819  [ 3100/ 3520]
loss: 0.005856  [ 3200/ 3520]
loss: 0.004066  [ 3300/ 3520]
loss: 0.006530  [ 3400/ 3520]
loss: 0.008050  [ 3500/ 3520]
Epoch 7
-------------------------------
loss: 0.010278  [    0/ 3520]
loss: 0.002425  [  100/ 3520]
loss: 0.086099  [  200/ 3520]
loss: 0.005981  [  300/ 3520]
loss: 0.050581  [  400/ 3520]
loss: 0.061439  [  500/ 3520]
loss: 0.004659  [  600/ 3520]
loss: 0.008024  [  700/ 3520]
loss: 0.005180  [  800/ 3520]
loss: 0.002339  [  900/ 3520]
loss: 0.003705  [ 1000/ 3520]
loss: 0.007569  [ 1100/ 3520]
loss: 0.011119  [ 1200/ 3520]
loss: 0.003237  [ 1300/ 3520]
loss: 0.006023  [ 1400/ 3520]
loss: 0.003149  [ 1500/ 3520]
loss: 0.002773  [ 1600/ 3520]
loss: 0.004317  [ 1700/ 3520]
loss: 0.111189  [ 1800/ 3520]
loss: 0.005996  [ 1900/ 3520]
loss: 0.014405  [ 2000/ 3520]
loss: 0.006187  [ 2100/ 3520]
loss: 0.006391  [ 2200/ 3520]
loss: 0.057028  [ 2300/ 3520]
loss: 0.008419  [ 2400/ 3520]
loss: 0.009652  [ 2500/ 3520]
loss: 0.011773  [ 2600/ 3520]
loss: 0.002979  [ 2700/ 3520]
loss: 0.013783  [ 2800/ 3520]
loss: 0.002598  [ 2900/ 3520]
loss: 0.011562  [ 3000/ 3520]
loss: 0.003738  [ 3100/ 3520]
loss: 0.006152  [ 3200/ 3520]
loss: 0.003722  [ 3300/ 3520]
loss: 0.007586  [ 3400/ 3520]
loss: 0.008048  [ 3500/ 3520]
Epoch 8
-------------------------------
loss: 0.010641  [    0/ 3520]
loss: 0.002644  [  100/ 3520]
loss: 0.076166  [  200/ 3520]
loss: 0.004941  [  300/ 3520]
loss: 0.050636  [  400/ 3520]
loss: 0.063229  [  500/ 3520]
loss: 0.004176  [  600/ 3520]
loss: 0.007766  [  700/ 3520]
loss: 0.005345  [  800/ 3520]
loss: 0.002627  [  900/ 3520]
loss: 0.003428  [ 1000/ 3520]
loss: 0.007872  [ 1100/ 3520]
loss: 0.009171  [ 1200/ 3520]
loss: 0.004152  [ 1300/ 3520]
loss: 0.005405  [ 1400/ 3520]
loss: 0.002949  [ 1500/ 3520]
loss: 0.002842  [ 1600/ 3520]
loss: 0.004338  [ 1700/ 3520]
loss: 0.111055  [ 1800/ 3520]
loss: 0.005829  [ 1900/ 3520]
loss: 0.015137  [ 2000/ 3520]
loss: 0.006461  [ 2100/ 3520]
loss: 0.006944  [ 2200/ 3520]
loss: 0.056916  [ 2300/ 3520]
loss: 0.008568  [ 2400/ 3520]
loss: 0.009524  [ 2500/ 3520]
loss: 0.011221  [ 2600/ 3520]
loss: 0.003019  [ 2700/ 3520]
loss: 0.014071  [ 2800/ 3520]
loss: 0.002918  [ 2900/ 3520]
loss: 0.011348  [ 3000/ 3520]
loss: 0.004311  [ 3100/ 3520]
loss: 0.006100  [ 3200/ 3520]
loss: 0.003603  [ 3300/ 3520]
loss: 0.008268  [ 3400/ 3520]
loss: 0.007768  [ 3500/ 3520]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3520
First Spike after testing: [0.44294542 1.2368112 ]
[0 1 2 ... 0 1 2]
[1 2 0 ... 1 2 0]
Cluster 0 Occurrences: 1160; KMEANS: 1210
Cluster 1 Occurrences: 1146; KMEANS: 1209
Cluster 2 Occurrences: 1214; KMEANS: 1101
Centroids: [[0.69743866, 1.2142415], [0.0993796, 0.7419346], [-1.6735258, 0.1173067]]
Centroids: [[-1.6776363, 0.11382412], [0.70540065, 1.2058824], [0.062096357, 0.73165166]]
Contingency Matrix: 
[[   0 1154    6]
 [   0   54 1092]
 [1210    1    3]]
[[-1, 1154, 6], [-1, 54, 1092], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1092], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1154    6    0]
 [  54 1092    0]
 [   1    3 1210]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1154, 1092, 1210], Sum: 3456
All_Elements: [1154, 6, 0, 54, 1092, 0, 1, 3, 1210], Sum: 3520
Accuracy: 0.9818181818181818
Done!
