Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Difficult2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-10_02_56
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211AFAEB080>
Sampling rate: 24000.0
Raw: [ 0.02085333  0.02043967  0.02052644 ... -0.02218732 -0.02150573
 -0.01811243]
Times: [   1583    1934    2430 ... 1439313 1439656 1439854]
Cluster: [3 3 3 ... 2 2 1]
Number of different clusters:  3
Number of Spikes: 3364
First aligned Spike Frame: [-0.05170878 -0.0548761  -0.06029554 -0.06053219 -0.04807119 -0.02780025
 -0.01550543 -0.01702494 -0.02945104 -0.04493807 -0.07056858 -0.07003585
  0.07629654  0.43081562  0.80470191  0.96319627  0.89198123  0.73643948
  0.58987232  0.46714337  0.36345495  0.2828462   0.22743292  0.182731
  0.13931053  0.09524506  0.05136602  0.01367166 -0.01393093 -0.03985679
 -0.07387102 -0.11218435 -0.1444455  -0.16672578 -0.17809238 -0.18020802
 -0.17953732 -0.18246903 -0.18617363 -0.18205375 -0.17299738 -0.16958427
 -0.17248955 -0.17516876 -0.1727246  -0.16696514 -0.15993314]
Cluster 0, Occurrences: 1120
Cluster 1, Occurrences: 1109
Cluster 2, Occurrences: 1135
<torch.utils.data.dataloader.DataLoader object at 0x0000021209B12C18>
Epoch 1
-------------------------------
loss: 0.147895  [    0/ 3364]
loss: 0.080764  [  100/ 3364]
loss: 0.044878  [  200/ 3364]
loss: 0.037303  [  300/ 3364]
loss: 0.005763  [  400/ 3364]
loss: 0.041197  [  500/ 3364]
loss: 0.005934  [  600/ 3364]
loss: 0.005939  [  700/ 3364]
loss: 0.003438  [  800/ 3364]
loss: 0.008703  [  900/ 3364]
loss: 0.006489  [ 1000/ 3364]
loss: 0.003080  [ 1100/ 3364]
loss: 0.003779  [ 1200/ 3364]
loss: 0.006145  [ 1300/ 3364]
loss: 0.092275  [ 1400/ 3364]
loss: 0.003609  [ 1500/ 3364]
loss: 0.006752  [ 1600/ 3364]
loss: 0.004109  [ 1700/ 3364]
loss: 0.002096  [ 1800/ 3364]
loss: 0.003878  [ 1900/ 3364]
loss: 0.002806  [ 2000/ 3364]
loss: 0.004589  [ 2100/ 3364]
loss: 0.005060  [ 2200/ 3364]
loss: 0.007099  [ 2300/ 3364]
loss: 0.000974  [ 2400/ 3364]
loss: 0.002297  [ 2500/ 3364]
loss: 0.001998  [ 2600/ 3364]
loss: 0.003558  [ 2700/ 3364]
loss: 0.003721  [ 2800/ 3364]
loss: 0.001690  [ 2900/ 3364]
loss: 0.003739  [ 3000/ 3364]
loss: 0.006423  [ 3100/ 3364]
loss: 0.001854  [ 3200/ 3364]
loss: 0.000859  [ 3300/ 3364]
Epoch 2
-------------------------------
loss: 0.001420  [    0/ 3364]
loss: 0.002076  [  100/ 3364]
loss: 0.004963  [  200/ 3364]
loss: 0.000836  [  300/ 3364]
loss: 0.000763  [  400/ 3364]
loss: 0.032716  [  500/ 3364]
loss: 0.003900  [  600/ 3364]
loss: 0.006207  [  700/ 3364]
loss: 0.002587  [  800/ 3364]
loss: 0.003019  [  900/ 3364]
loss: 0.002480  [ 1000/ 3364]
loss: 0.003898  [ 1100/ 3364]
loss: 0.002117  [ 1200/ 3364]
loss: 0.005721  [ 1300/ 3364]
loss: 0.086507  [ 1400/ 3364]
loss: 0.002674  [ 1500/ 3364]
loss: 0.007616  [ 1600/ 3364]
loss: 0.002662  [ 1700/ 3364]
loss: 0.001557  [ 1800/ 3364]
loss: 0.003486  [ 1900/ 3364]
loss: 0.002554  [ 2000/ 3364]
loss: 0.004077  [ 2100/ 3364]
loss: 0.005179  [ 2200/ 3364]
loss: 0.006871  [ 2300/ 3364]
loss: 0.000900  [ 2400/ 3364]
loss: 0.002344  [ 2500/ 3364]
loss: 0.001902  [ 2600/ 3364]
loss: 0.003702  [ 2700/ 3364]
loss: 0.003785  [ 2800/ 3364]
loss: 0.001526  [ 2900/ 3364]
loss: 0.003782  [ 3000/ 3364]
loss: 0.006669  [ 3100/ 3364]
loss: 0.001687  [ 3200/ 3364]
loss: 0.001110  [ 3300/ 3364]
Epoch 3
-------------------------------
loss: 0.001397  [    0/ 3364]
loss: 0.002124  [  100/ 3364]
loss: 0.005102  [  200/ 3364]
loss: 0.000745  [  300/ 3364]
loss: 0.000777  [  400/ 3364]
loss: 0.029127  [  500/ 3364]
loss: 0.003693  [  600/ 3364]
loss: 0.006077  [  700/ 3364]
loss: 0.002616  [  800/ 3364]
loss: 0.002929  [  900/ 3364]
loss: 0.002545  [ 1000/ 3364]
loss: 0.003784  [ 1100/ 3364]
loss: 0.001939  [ 1200/ 3364]
loss: 0.005666  [ 1300/ 3364]
loss: 0.082843  [ 1400/ 3364]
loss: 0.002649  [ 1500/ 3364]
loss: 0.007199  [ 1600/ 3364]
loss: 0.002914  [ 1700/ 3364]
loss: 0.001505  [ 1800/ 3364]
loss: 0.003519  [ 1900/ 3364]
loss: 0.002647  [ 2000/ 3364]
loss: 0.004074  [ 2100/ 3364]
loss: 0.005157  [ 2200/ 3364]
loss: 0.006832  [ 2300/ 3364]
loss: 0.000986  [ 2400/ 3364]
loss: 0.002290  [ 2500/ 3364]
loss: 0.001778  [ 2600/ 3364]
loss: 0.003574  [ 2700/ 3364]
loss: 0.003692  [ 2800/ 3364]
loss: 0.001673  [ 2900/ 3364]
loss: 0.003779  [ 3000/ 3364]
loss: 0.006827  [ 3100/ 3364]
loss: 0.001563  [ 3200/ 3364]
loss: 0.001194  [ 3300/ 3364]
Epoch 4
-------------------------------
loss: 0.001327  [    0/ 3364]
loss: 0.002374  [  100/ 3364]
loss: 0.005085  [  200/ 3364]
loss: 0.000701  [  300/ 3364]
loss: 0.000902  [  400/ 3364]
loss: 0.028870  [  500/ 3364]
loss: 0.003689  [  600/ 3364]
loss: 0.006008  [  700/ 3364]
loss: 0.002732  [  800/ 3364]
loss: 0.003004  [  900/ 3364]
loss: 0.002424  [ 1000/ 3364]
loss: 0.003748  [ 1100/ 3364]
loss: 0.001890  [ 1200/ 3364]
loss: 0.005606  [ 1300/ 3364]
loss: 0.080453  [ 1400/ 3364]
loss: 0.002669  [ 1500/ 3364]
loss: 0.007084  [ 1600/ 3364]
loss: 0.003103  [ 1700/ 3364]
loss: 0.001460  [ 1800/ 3364]
loss: 0.003533  [ 1900/ 3364]
loss: 0.002770  [ 2000/ 3364]
loss: 0.004030  [ 2100/ 3364]
loss: 0.005341  [ 2200/ 3364]
loss: 0.006806  [ 2300/ 3364]
loss: 0.001036  [ 2400/ 3364]
loss: 0.002267  [ 2500/ 3364]
loss: 0.001751  [ 2600/ 3364]
loss: 0.003731  [ 2700/ 3364]
loss: 0.003562  [ 2800/ 3364]
loss: 0.001791  [ 2900/ 3364]
loss: 0.003771  [ 3000/ 3364]
loss: 0.006831  [ 3100/ 3364]
loss: 0.001456  [ 3200/ 3364]
loss: 0.001405  [ 3300/ 3364]
Epoch 5
-------------------------------
loss: 0.001353  [    0/ 3364]
loss: 0.002967  [  100/ 3364]
loss: 0.004971  [  200/ 3364]
loss: 0.000774  [  300/ 3364]
loss: 0.000856  [  400/ 3364]
loss: 0.029607  [  500/ 3364]
loss: 0.003669  [  600/ 3364]
loss: 0.006018  [  700/ 3364]
loss: 0.002791  [  800/ 3364]
loss: 0.003158  [  900/ 3364]
loss: 0.002402  [ 1000/ 3364]
loss: 0.003708  [ 1100/ 3364]
loss: 0.001890  [ 1200/ 3364]
loss: 0.005486  [ 1300/ 3364]
loss: 0.079427  [ 1400/ 3364]
loss: 0.002677  [ 1500/ 3364]
loss: 0.006921  [ 1600/ 3364]
loss: 0.002995  [ 1700/ 3364]
loss: 0.001427  [ 1800/ 3364]
loss: 0.003525  [ 1900/ 3364]
loss: 0.002691  [ 2000/ 3364]
loss: 0.003996  [ 2100/ 3364]
loss: 0.005430  [ 2200/ 3364]
loss: 0.006733  [ 2300/ 3364]
loss: 0.001098  [ 2400/ 3364]
loss: 0.002182  [ 2500/ 3364]
loss: 0.001726  [ 2600/ 3364]
loss: 0.003698  [ 2700/ 3364]
loss: 0.003602  [ 2800/ 3364]
loss: 0.001764  [ 2900/ 3364]
loss: 0.003681  [ 3000/ 3364]
loss: 0.006814  [ 3100/ 3364]
loss: 0.001360  [ 3200/ 3364]
loss: 0.001048  [ 3300/ 3364]
Epoch 6
-------------------------------
loss: 0.001342  [    0/ 3364]
loss: 0.003186  [  100/ 3364]
loss: 0.004955  [  200/ 3364]
loss: 0.000871  [  300/ 3364]
loss: 0.000824  [  400/ 3364]
loss: 0.030201  [  500/ 3364]
loss: 0.003504  [  600/ 3364]
loss: 0.006320  [  700/ 3364]
loss: 0.002575  [  800/ 3364]
loss: 0.003282  [  900/ 3364]
loss: 0.002469  [ 1000/ 3364]
loss: 0.003687  [ 1100/ 3364]
loss: 0.001942  [ 1200/ 3364]
loss: 0.005496  [ 1300/ 3364]
loss: 0.076620  [ 1400/ 3364]
loss: 0.002654  [ 1500/ 3364]
loss: 0.006926  [ 1600/ 3364]
loss: 0.002906  [ 1700/ 3364]
loss: 0.001417  [ 1800/ 3364]
loss: 0.003501  [ 1900/ 3364]
loss: 0.002707  [ 2000/ 3364]
loss: 0.004023  [ 2100/ 3364]
loss: 0.005811  [ 2200/ 3364]
loss: 0.006708  [ 2300/ 3364]
loss: 0.001160  [ 2400/ 3364]
loss: 0.002119  [ 2500/ 3364]
loss: 0.001631  [ 2600/ 3364]
loss: 0.003748  [ 2700/ 3364]
loss: 0.003723  [ 2800/ 3364]
loss: 0.001714  [ 2900/ 3364]
loss: 0.003594  [ 3000/ 3364]
loss: 0.006834  [ 3100/ 3364]
loss: 0.001273  [ 3200/ 3364]
loss: 0.001232  [ 3300/ 3364]
Epoch 7
-------------------------------
loss: 0.001275  [    0/ 3364]
loss: 0.003234  [  100/ 3364]
loss: 0.004832  [  200/ 3364]
loss: 0.000933  [  300/ 3364]
loss: 0.000758  [  400/ 3364]
loss: 0.030641  [  500/ 3364]
loss: 0.003335  [  600/ 3364]
loss: 0.006166  [  700/ 3364]
loss: 0.002562  [  800/ 3364]
loss: 0.003297  [  900/ 3364]
loss: 0.002535  [ 1000/ 3364]
loss: 0.003743  [ 1100/ 3364]
loss: 0.001988  [ 1200/ 3364]
loss: 0.005547  [ 1300/ 3364]
loss: 0.073535  [ 1400/ 3364]
loss: 0.002654  [ 1500/ 3364]
loss: 0.006763  [ 1600/ 3364]
loss: 0.002678  [ 1700/ 3364]
loss: 0.001389  [ 1800/ 3364]
loss: 0.003495  [ 1900/ 3364]
loss: 0.002867  [ 2000/ 3364]
loss: 0.004132  [ 2100/ 3364]
loss: 0.005828  [ 2200/ 3364]
loss: 0.006415  [ 2300/ 3364]
loss: 0.001184  [ 2400/ 3364]
loss: 0.002078  [ 2500/ 3364]
loss: 0.001558  [ 2600/ 3364]
loss: 0.003730  [ 2700/ 3364]
loss: 0.003448  [ 2800/ 3364]
loss: 0.001678  [ 2900/ 3364]
loss: 0.003435  [ 3000/ 3364]
loss: 0.006500  [ 3100/ 3364]
loss: 0.001277  [ 3200/ 3364]
loss: 0.001348  [ 3300/ 3364]
Epoch 8
-------------------------------
loss: 0.001275  [    0/ 3364]
loss: 0.003039  [  100/ 3364]
loss: 0.004715  [  200/ 3364]
loss: 0.000867  [  300/ 3364]
loss: 0.000827  [  400/ 3364]
loss: 0.031099  [  500/ 3364]
loss: 0.003191  [  600/ 3364]
loss: 0.006188  [  700/ 3364]
loss: 0.002439  [  800/ 3364]
loss: 0.003285  [  900/ 3364]
loss: 0.002372  [ 1000/ 3364]
loss: 0.003752  [ 1100/ 3364]
loss: 0.001999  [ 1200/ 3364]
loss: 0.004496  [ 1300/ 3364]
loss: 0.070955  [ 1400/ 3364]
loss: 0.002756  [ 1500/ 3364]
loss: 0.006672  [ 1600/ 3364]
loss: 0.002640  [ 1700/ 3364]
loss: 0.001378  [ 1800/ 3364]
loss: 0.003467  [ 1900/ 3364]
loss: 0.002902  [ 2000/ 3364]
loss: 0.004257  [ 2100/ 3364]
loss: 0.005641  [ 2200/ 3364]
loss: 0.006462  [ 2300/ 3364]
loss: 0.001206  [ 2400/ 3364]
loss: 0.002092  [ 2500/ 3364]
loss: 0.001600  [ 2600/ 3364]
loss: 0.003696  [ 2700/ 3364]
loss: 0.003351  [ 2800/ 3364]
loss: 0.001674  [ 2900/ 3364]
loss: 0.003402  [ 3000/ 3364]
loss: 0.006545  [ 3100/ 3364]
loss: 0.001247  [ 3200/ 3364]
loss: 0.001349  [ 3300/ 3364]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3364
First Spike after testing: [-1.0979112   0.34698632]
[2 2 2 ... 1 1 0]
[0 0 0 ... 1 1 2]
Cluster 0 Occurrences: 1120; KMEANS: 1124
Cluster 1 Occurrences: 1109; KMEANS: 1096
Cluster 2 Occurrences: 1135; KMEANS: 1144
Centroids: [[-1.1017364, -0.28338385], [-0.46440026, 1.8649055], [-1.0793877, 0.30641425]]
Centroids: [[-1.0733849, 0.33689907], [-0.44929907, 1.8858651], [-1.1146445, -0.3033324]]
Contingency Matrix: 
[[  13    0 1107]
 [   7 1095    7]
 [1104    1   30]]
[[-1, -1, -1], [7, 1095, -1], [1104, 1, -1]]
[[-1, -1, -1], [-1, 1095, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 2, 2: 0, 1: 1}
New Contingency Matrix: 
[[1107    0   13]
 [   7 1095    7]
 [  30    1 1104]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1107, 1095, 1104], Sum: 3306
All_Elements: [1107, 0, 13, 7, 1095, 7, 30, 1, 1104], Sum: 3364
Accuracy: 0.9827586206896551
Done!
