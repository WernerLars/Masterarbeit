Experiment_path: Random_Seeds//V2/Experiment_02_4
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Random_Seeds//V2/Experiment_02_4/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_22-09_56_32
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211EE996F60>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x00000211E96DA5C0>
Epoch 1
-------------------------------
loss: 0.177996  [    0/ 3383]
loss: 0.040060  [  100/ 3383]
loss: 0.019004  [  200/ 3383]
loss: 0.008710  [  300/ 3383]
loss: 0.006901  [  400/ 3383]
loss: 0.011094  [  500/ 3383]
loss: 0.009544  [  600/ 3383]
loss: 0.013678  [  700/ 3383]
loss: 0.008223  [  800/ 3383]
loss: 0.006661  [  900/ 3383]
loss: 0.097207  [ 1000/ 3383]
loss: 0.054438  [ 1100/ 3383]
loss: 0.026415  [ 1200/ 3383]
loss: 0.010498  [ 1300/ 3383]
loss: 0.005400  [ 1400/ 3383]
loss: 0.015822  [ 1500/ 3383]
loss: 0.003218  [ 1600/ 3383]
loss: 0.001861  [ 1700/ 3383]
loss: 0.012134  [ 1800/ 3383]
loss: 0.014687  [ 1900/ 3383]
loss: 0.003266  [ 2000/ 3383]
loss: 0.003452  [ 2100/ 3383]
loss: 0.009307  [ 2200/ 3383]
loss: 0.001681  [ 2300/ 3383]
loss: 0.004046  [ 2400/ 3383]
loss: 0.031725  [ 2500/ 3383]
loss: 0.001480  [ 2600/ 3383]
loss: 0.004281  [ 2700/ 3383]
loss: 0.006423  [ 2800/ 3383]
loss: 0.005631  [ 2900/ 3383]
loss: 0.004096  [ 3000/ 3383]
loss: 0.004485  [ 3100/ 3383]
loss: 0.064401  [ 3200/ 3383]
loss: 0.002500  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.004038  [    0/ 3383]
loss: 0.006102  [  100/ 3383]
loss: 0.005991  [  200/ 3383]
loss: 0.002173  [  300/ 3383]
loss: 0.003098  [  400/ 3383]
loss: 0.005069  [  500/ 3383]
loss: 0.001239  [  600/ 3383]
loss: 0.001837  [  700/ 3383]
loss: 0.007561  [  800/ 3383]
loss: 0.001477  [  900/ 3383]
loss: 0.091647  [ 1000/ 3383]
loss: 0.057683  [ 1100/ 3383]
loss: 0.022805  [ 1200/ 3383]
loss: 0.009323  [ 1300/ 3383]
loss: 0.004251  [ 1400/ 3383]
loss: 0.015074  [ 1500/ 3383]
loss: 0.002639  [ 1600/ 3383]
loss: 0.001552  [ 1700/ 3383]
loss: 0.011975  [ 1800/ 3383]
loss: 0.014311  [ 1900/ 3383]
loss: 0.003025  [ 2000/ 3383]
loss: 0.003399  [ 2100/ 3383]
loss: 0.008875  [ 2200/ 3383]
loss: 0.001504  [ 2300/ 3383]
loss: 0.004071  [ 2400/ 3383]
loss: 0.029598  [ 2500/ 3383]
loss: 0.001322  [ 2600/ 3383]
loss: 0.003859  [ 2700/ 3383]
loss: 0.006439  [ 2800/ 3383]
loss: 0.005844  [ 2900/ 3383]
loss: 0.003715  [ 3000/ 3383]
loss: 0.004473  [ 3100/ 3383]
loss: 0.064169  [ 3200/ 3383]
loss: 0.002365  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.004051  [    0/ 3383]
loss: 0.005967  [  100/ 3383]
loss: 0.005764  [  200/ 3383]
loss: 0.002172  [  300/ 3383]
loss: 0.003046  [  400/ 3383]
loss: 0.004872  [  500/ 3383]
loss: 0.001200  [  600/ 3383]
loss: 0.001807  [  700/ 3383]
loss: 0.007539  [  800/ 3383]
loss: 0.001452  [  900/ 3383]
loss: 0.091945  [ 1000/ 3383]
loss: 0.057712  [ 1100/ 3383]
loss: 0.022948  [ 1200/ 3383]
loss: 0.009330  [ 1300/ 3383]
loss: 0.004188  [ 1400/ 3383]
loss: 0.015071  [ 1500/ 3383]
loss: 0.002576  [ 1600/ 3383]
loss: 0.001541  [ 1700/ 3383]
loss: 0.011786  [ 1800/ 3383]
loss: 0.014196  [ 1900/ 3383]
loss: 0.003018  [ 2000/ 3383]
loss: 0.003401  [ 2100/ 3383]
loss: 0.008891  [ 2200/ 3383]
loss: 0.001540  [ 2300/ 3383]
loss: 0.003994  [ 2400/ 3383]
loss: 0.027040  [ 2500/ 3383]
loss: 0.001280  [ 2600/ 3383]
loss: 0.003672  [ 2700/ 3383]
loss: 0.006433  [ 2800/ 3383]
loss: 0.005986  [ 2900/ 3383]
loss: 0.003495  [ 3000/ 3383]
loss: 0.004427  [ 3100/ 3383]
loss: 0.063882  [ 3200/ 3383]
loss: 0.002425  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.004231  [    0/ 3383]
loss: 0.006170  [  100/ 3383]
loss: 0.005683  [  200/ 3383]
loss: 0.002168  [  300/ 3383]
loss: 0.003013  [  400/ 3383]
loss: 0.004836  [  500/ 3383]
loss: 0.001294  [  600/ 3383]
loss: 0.001500  [  700/ 3383]
loss: 0.007322  [  800/ 3383]
loss: 0.001482  [  900/ 3383]
loss: 0.092442  [ 1000/ 3383]
loss: 0.057949  [ 1100/ 3383]
loss: 0.023301  [ 1200/ 3383]
loss: 0.009395  [ 1300/ 3383]
loss: 0.003893  [ 1400/ 3383]
loss: 0.015155  [ 1500/ 3383]
loss: 0.002639  [ 1600/ 3383]
loss: 0.001535  [ 1700/ 3383]
loss: 0.011297  [ 1800/ 3383]
loss: 0.014210  [ 1900/ 3383]
loss: 0.003015  [ 2000/ 3383]
loss: 0.003506  [ 2100/ 3383]
loss: 0.009153  [ 2200/ 3383]
loss: 0.001557  [ 2300/ 3383]
loss: 0.003898  [ 2400/ 3383]
loss: 0.027127  [ 2500/ 3383]
loss: 0.000936  [ 2600/ 3383]
loss: 0.003230  [ 2700/ 3383]
loss: 0.006426  [ 2800/ 3383]
loss: 0.006145  [ 2900/ 3383]
loss: 0.003278  [ 3000/ 3383]
loss: 0.004383  [ 3100/ 3383]
loss: 0.063880  [ 3200/ 3383]
loss: 0.002487  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.004703  [    0/ 3383]
loss: 0.006269  [  100/ 3383]
loss: 0.005428  [  200/ 3383]
loss: 0.002315  [  300/ 3383]
loss: 0.002971  [  400/ 3383]
loss: 0.004679  [  500/ 3383]
loss: 0.001124  [  600/ 3383]
loss: 0.001304  [  700/ 3383]
loss: 0.006670  [  800/ 3383]
loss: 0.001683  [  900/ 3383]
loss: 0.092988  [ 1000/ 3383]
loss: 0.057997  [ 1100/ 3383]
loss: 0.023633  [ 1200/ 3383]
loss: 0.009302  [ 1300/ 3383]
loss: 0.003040  [ 1400/ 3383]
loss: 0.015203  [ 1500/ 3383]
loss: 0.002055  [ 1600/ 3383]
loss: 0.001521  [ 1700/ 3383]
loss: 0.010246  [ 1800/ 3383]
loss: 0.014273  [ 1900/ 3383]
loss: 0.003029  [ 2000/ 3383]
loss: 0.003752  [ 2100/ 3383]
loss: 0.008960  [ 2200/ 3383]
loss: 0.001571  [ 2300/ 3383]
loss: 0.003904  [ 2400/ 3383]
loss: 0.026904  [ 2500/ 3383]
loss: 0.000943  [ 2600/ 3383]
loss: 0.002977  [ 2700/ 3383]
loss: 0.006485  [ 2800/ 3383]
loss: 0.006274  [ 2900/ 3383]
loss: 0.003200  [ 3000/ 3383]
loss: 0.004380  [ 3100/ 3383]
loss: 0.063269  [ 3200/ 3383]
loss: 0.002523  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.004948  [    0/ 3383]
loss: 0.005909  [  100/ 3383]
loss: 0.005072  [  200/ 3383]
loss: 0.002342  [  300/ 3383]
loss: 0.003016  [  400/ 3383]
loss: 0.004402  [  500/ 3383]
loss: 0.001265  [  600/ 3383]
loss: 0.001447  [  700/ 3383]
loss: 0.006205  [  800/ 3383]
loss: 0.001730  [  900/ 3383]
loss: 0.092232  [ 1000/ 3383]
loss: 0.058165  [ 1100/ 3383]
loss: 0.023749  [ 1200/ 3383]
loss: 0.009136  [ 1300/ 3383]
loss: 0.002376  [ 1400/ 3383]
loss: 0.014087  [ 1500/ 3383]
loss: 0.001765  [ 1600/ 3383]
loss: 0.001507  [ 1700/ 3383]
loss: 0.009579  [ 1800/ 3383]
loss: 0.014210  [ 1900/ 3383]
loss: 0.002871  [ 2000/ 3383]
loss: 0.003890  [ 2100/ 3383]
loss: 0.008647  [ 2200/ 3383]
loss: 0.001689  [ 2300/ 3383]
loss: 0.003852  [ 2400/ 3383]
loss: 0.027212  [ 2500/ 3383]
loss: 0.000908  [ 2600/ 3383]
loss: 0.002813  [ 2700/ 3383]
loss: 0.006945  [ 2800/ 3383]
loss: 0.006571  [ 2900/ 3383]
loss: 0.003253  [ 3000/ 3383]
loss: 0.004524  [ 3100/ 3383]
loss: 0.061742  [ 3200/ 3383]
loss: 0.002236  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.005284  [    0/ 3383]
loss: 0.005800  [  100/ 3383]
loss: 0.004453  [  200/ 3383]
loss: 0.002307  [  300/ 3383]
loss: 0.002856  [  400/ 3383]
loss: 0.004110  [  500/ 3383]
loss: 0.001226  [  600/ 3383]
loss: 0.001650  [  700/ 3383]
loss: 0.005866  [  800/ 3383]
loss: 0.002025  [  900/ 3383]
loss: 0.092830  [ 1000/ 3383]
loss: 0.057663  [ 1100/ 3383]
loss: 0.024140  [ 1200/ 3383]
loss: 0.009130  [ 1300/ 3383]
loss: 0.002098  [ 1400/ 3383]
loss: 0.013114  [ 1500/ 3383]
loss: 0.001620  [ 1600/ 3383]
loss: 0.001527  [ 1700/ 3383]
loss: 0.008734  [ 1800/ 3383]
loss: 0.014214  [ 1900/ 3383]
loss: 0.002864  [ 2000/ 3383]
loss: 0.004041  [ 2100/ 3383]
loss: 0.008171  [ 2200/ 3383]
loss: 0.001759  [ 2300/ 3383]
loss: 0.003791  [ 2400/ 3383]
loss: 0.027838  [ 2500/ 3383]
loss: 0.000863  [ 2600/ 3383]
loss: 0.002869  [ 2700/ 3383]
loss: 0.007075  [ 2800/ 3383]
loss: 0.006503  [ 2900/ 3383]
loss: 0.003289  [ 3000/ 3383]
loss: 0.004677  [ 3100/ 3383]
loss: 0.060666  [ 3200/ 3383]
loss: 0.002114  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.005361  [    0/ 3383]
loss: 0.005778  [  100/ 3383]
loss: 0.004044  [  200/ 3383]
loss: 0.002288  [  300/ 3383]
loss: 0.002811  [  400/ 3383]
loss: 0.003811  [  500/ 3383]
loss: 0.001172  [  600/ 3383]
loss: 0.001747  [  700/ 3383]
loss: 0.005499  [  800/ 3383]
loss: 0.002116  [  900/ 3383]
loss: 0.093383  [ 1000/ 3383]
loss: 0.057424  [ 1100/ 3383]
loss: 0.024355  [ 1200/ 3383]
loss: 0.009159  [ 1300/ 3383]
loss: 0.001858  [ 1400/ 3383]
loss: 0.012370  [ 1500/ 3383]
loss: 0.001461  [ 1600/ 3383]
loss: 0.001527  [ 1700/ 3383]
loss: 0.007909  [ 1800/ 3383]
loss: 0.014269  [ 1900/ 3383]
loss: 0.002847  [ 2000/ 3383]
loss: 0.004206  [ 2100/ 3383]
loss: 0.007469  [ 2200/ 3383]
loss: 0.001776  [ 2300/ 3383]
loss: 0.003816  [ 2400/ 3383]
loss: 0.028808  [ 2500/ 3383]
loss: 0.000886  [ 2600/ 3383]
loss: 0.002727  [ 2700/ 3383]
loss: 0.007035  [ 2800/ 3383]
loss: 0.006259  [ 2900/ 3383]
loss: 0.003229  [ 3000/ 3383]
loss: 0.004751  [ 3100/ 3383]
loss: 0.059473  [ 3200/ 3383]
loss: 0.002093  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [-1.2941797  -0.14585823]
[2 1 2 ... 0 1 2]
[0 2 0 ... 1 2 0]
Cluster 0 Occurrences: 1115; KMEANS: 1233
Cluster 1 Occurrences: 1113; KMEANS: 1081
Cluster 2 Occurrences: 1155; KMEANS: 1069
Centroids: [[-0.43356934, -0.0141136255], [-0.91821355, 0.4726183], [-1.4535226, -0.09376063]]
Centroids: [[-1.4613509, -0.09516887], [-0.4016256, -0.006791332], [-0.887013, 0.49268344]]
Contingency Matrix: 
[[  34 1079    2]
 [  46    2 1065]
 [1153    0    2]]
[[-1, 1079, 2], [-1, 2, 1065], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, 1065], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[1079    2   34]
 [   2 1065   46]
 [   0    2 1153]]
New Clustered Label Sequence: [1, 2, 0]
Diagonal_Elements: [1079, 1065, 1153], Sum: 3297
All_Elements: [1079, 2, 34, 2, 1065, 46, 0, 2, 1153], Sum: 3383
Accuracy: 0.9745787762341117
Done!
