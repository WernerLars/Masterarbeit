Experiment_path: Base_Line_W_PC_0.6/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Base_Line_W_PC_0.6/Experiment_02/C_Difficult2_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_21-00_09_57
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000018283F7A630>
Sampling rate: 24000.0
Raw: [ 0.15602285  0.13816666  0.12280393 ... -0.08081559 -0.08529616
 -0.09321123]
Times: [    182     667     748 ... 1438018 1438700 1439563]
Cluster: [1 3 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3462
First aligned Spike Frame: [ 0.0569593   0.06304523  0.0540705   0.04226901  0.04435466  0.07367561
  0.11842591  0.15581396  0.18051202  0.20464622  0.25110595  0.34905547
  0.52973433  0.78604807  1.00019855  1.02993402  0.87276972  0.64136808
  0.42542707  0.24213728  0.08732396 -0.0251061  -0.08440505 -0.1076534
 -0.12386236 -0.14599821 -0.16968468 -0.19109174 -0.20831529 -0.21879359
 -0.21563414 -0.19606358 -0.16928275 -0.14859233 -0.13954347 -0.13618571
 -0.12902379 -0.12127763 -0.12365015 -0.13615822 -0.14611472 -0.13936073
 -0.11885552 -0.10582878 -0.11163038 -0.12511067 -0.12700369]
Cluster 0, Occurrences: 1187
Cluster 1, Occurrences: 1136
Cluster 2, Occurrences: 1139
<torch.utils.data.dataloader.DataLoader object at 0x000001829408A198>
Epoch 1
-------------------------------
loss: 0.152823  [    0/ 3462]
loss: 0.082848  [  100/ 3462]
loss: 0.033372  [  200/ 3462]
loss: 0.013430  [  300/ 3462]
loss: 0.026009  [  400/ 3462]
loss: 0.012460  [  500/ 3462]
loss: 0.019613  [  600/ 3462]
loss: 0.029694  [  700/ 3462]
loss: 0.012313  [  800/ 3462]
loss: 0.016296  [  900/ 3462]
loss: 0.015367  [ 1000/ 3462]
loss: 0.047923  [ 1100/ 3462]
loss: 0.015669  [ 1200/ 3462]
loss: 0.005553  [ 1300/ 3462]
loss: 0.007712  [ 1400/ 3462]
loss: 0.012371  [ 1500/ 3462]
loss: 0.007944  [ 1600/ 3462]
loss: 0.004809  [ 1700/ 3462]
loss: 0.014448  [ 1800/ 3462]
loss: 0.007930  [ 1900/ 3462]
loss: 0.011669  [ 2000/ 3462]
loss: 0.058141  [ 2100/ 3462]
loss: 0.001814  [ 2200/ 3462]
loss: 0.007328  [ 2300/ 3462]
loss: 0.012669  [ 2400/ 3462]
loss: 0.006350  [ 2500/ 3462]
loss: 0.015834  [ 2600/ 3462]
loss: 0.006569  [ 2700/ 3462]
loss: 0.005290  [ 2800/ 3462]
loss: 0.015845  [ 2900/ 3462]
loss: 0.116022  [ 3000/ 3462]
loss: 0.007684  [ 3100/ 3462]
loss: 0.007328  [ 3200/ 3462]
loss: 0.135029  [ 3300/ 3462]
loss: 0.011884  [ 3400/ 3462]
Epoch 2
-------------------------------
loss: 0.001956  [    0/ 3462]
loss: 0.012133  [  100/ 3462]
loss: 0.012833  [  200/ 3462]
loss: 0.010061  [  300/ 3462]
loss: 0.010603  [  400/ 3462]
loss: 0.007705  [  500/ 3462]
loss: 0.004586  [  600/ 3462]
loss: 0.015920  [  700/ 3462]
loss: 0.008220  [  800/ 3462]
loss: 0.017102  [  900/ 3462]
loss: 0.010277  [ 1000/ 3462]
loss: 0.037064  [ 1100/ 3462]
loss: 0.016310  [ 1200/ 3462]
loss: 0.003142  [ 1300/ 3462]
loss: 0.006106  [ 1400/ 3462]
loss: 0.008154  [ 1500/ 3462]
loss: 0.008330  [ 1600/ 3462]
loss: 0.004878  [ 1700/ 3462]
loss: 0.017342  [ 1800/ 3462]
loss: 0.007050  [ 1900/ 3462]
loss: 0.009341  [ 2000/ 3462]
loss: 0.049986  [ 2100/ 3462]
loss: 0.001899  [ 2200/ 3462]
loss: 0.007301  [ 2300/ 3462]
loss: 0.012017  [ 2400/ 3462]
loss: 0.005996  [ 2500/ 3462]
loss: 0.013854  [ 2600/ 3462]
loss: 0.006308  [ 2700/ 3462]
loss: 0.003891  [ 2800/ 3462]
loss: 0.015736  [ 2900/ 3462]
loss: 0.116381  [ 3000/ 3462]
loss: 0.006828  [ 3100/ 3462]
loss: 0.007711  [ 3200/ 3462]
loss: 0.136804  [ 3300/ 3462]
loss: 0.011658  [ 3400/ 3462]
Epoch 3
-------------------------------
loss: 0.001776  [    0/ 3462]
loss: 0.012999  [  100/ 3462]
loss: 0.011770  [  200/ 3462]
loss: 0.007975  [  300/ 3462]
loss: 0.009299  [  400/ 3462]
loss: 0.006737  [  500/ 3462]
loss: 0.002189  [  600/ 3462]
loss: 0.016715  [  700/ 3462]
loss: 0.008306  [  800/ 3462]
loss: 0.017205  [  900/ 3462]
loss: 0.009935  [ 1000/ 3462]
loss: 0.035077  [ 1100/ 3462]
loss: 0.014748  [ 1200/ 3462]
loss: 0.003156  [ 1300/ 3462]
loss: 0.004794  [ 1400/ 3462]
loss: 0.007889  [ 1500/ 3462]
loss: 0.007748  [ 1600/ 3462]
loss: 0.005154  [ 1700/ 3462]
loss: 0.016810  [ 1800/ 3462]
loss: 0.006954  [ 1900/ 3462]
loss: 0.007009  [ 2000/ 3462]
loss: 0.050116  [ 2100/ 3462]
loss: 0.001972  [ 2200/ 3462]
loss: 0.007580  [ 2300/ 3462]
loss: 0.012065  [ 2400/ 3462]
loss: 0.006151  [ 2500/ 3462]
loss: 0.012813  [ 2600/ 3462]
loss: 0.006188  [ 2700/ 3462]
loss: 0.003749  [ 2800/ 3462]
loss: 0.015146  [ 2900/ 3462]
loss: 0.116040  [ 3000/ 3462]
loss: 0.006984  [ 3100/ 3462]
loss: 0.007922  [ 3200/ 3462]
loss: 0.136224  [ 3300/ 3462]
loss: 0.011954  [ 3400/ 3462]
Epoch 4
-------------------------------
loss: 0.001691  [    0/ 3462]
loss: 0.013332  [  100/ 3462]
loss: 0.010065  [  200/ 3462]
loss: 0.009401  [  300/ 3462]
loss: 0.008798  [  400/ 3462]
loss: 0.005118  [  500/ 3462]
loss: 0.001063  [  600/ 3462]
loss: 0.017424  [  700/ 3462]
loss: 0.009066  [  800/ 3462]
loss: 0.017193  [  900/ 3462]
loss: 0.009311  [ 1000/ 3462]
loss: 0.035218  [ 1100/ 3462]
loss: 0.013727  [ 1200/ 3462]
loss: 0.003140  [ 1300/ 3462]
loss: 0.003572  [ 1400/ 3462]
loss: 0.008475  [ 1500/ 3462]
loss: 0.006888  [ 1600/ 3462]
loss: 0.005321  [ 1700/ 3462]
loss: 0.015340  [ 1800/ 3462]
loss: 0.006590  [ 1900/ 3462]
loss: 0.005445  [ 2000/ 3462]
loss: 0.053260  [ 2100/ 3462]
loss: 0.001939  [ 2200/ 3462]
loss: 0.007754  [ 2300/ 3462]
loss: 0.012443  [ 2400/ 3462]
loss: 0.006258  [ 2500/ 3462]
loss: 0.011594  [ 2600/ 3462]
loss: 0.006134  [ 2700/ 3462]
loss: 0.004043  [ 2800/ 3462]
loss: 0.014397  [ 2900/ 3462]
loss: 0.115429  [ 3000/ 3462]
loss: 0.007083  [ 3100/ 3462]
loss: 0.008048  [ 3200/ 3462]
loss: 0.131893  [ 3300/ 3462]
loss: 0.012166  [ 3400/ 3462]
Epoch 5
-------------------------------
loss: 0.001635  [    0/ 3462]
loss: 0.013030  [  100/ 3462]
loss: 0.008996  [  200/ 3462]
loss: 0.011892  [  300/ 3462]
loss: 0.008879  [  400/ 3462]
loss: 0.003975  [  500/ 3462]
loss: 0.001097  [  600/ 3462]
loss: 0.017747  [  700/ 3462]
loss: 0.009640  [  800/ 3462]
loss: 0.017252  [  900/ 3462]
loss: 0.008573  [ 1000/ 3462]
loss: 0.036108  [ 1100/ 3462]
loss: 0.012548  [ 1200/ 3462]
loss: 0.002997  [ 1300/ 3462]
loss: 0.002920  [ 1400/ 3462]
loss: 0.009458  [ 1500/ 3462]
loss: 0.005955  [ 1600/ 3462]
loss: 0.005336  [ 1700/ 3462]
loss: 0.013388  [ 1800/ 3462]
loss: 0.006257  [ 1900/ 3462]
loss: 0.004610  [ 2000/ 3462]
loss: 0.056887  [ 2100/ 3462]
loss: 0.001866  [ 2200/ 3462]
loss: 0.007716  [ 2300/ 3462]
loss: 0.012230  [ 2400/ 3462]
loss: 0.006331  [ 2500/ 3462]
loss: 0.010590  [ 2600/ 3462]
loss: 0.005973  [ 2700/ 3462]
loss: 0.004502  [ 2800/ 3462]
loss: 0.013504  [ 2900/ 3462]
loss: 0.114205  [ 3000/ 3462]
loss: 0.007011  [ 3100/ 3462]
loss: 0.008136  [ 3200/ 3462]
loss: 0.127404  [ 3300/ 3462]
loss: 0.012398  [ 3400/ 3462]
Epoch 6
-------------------------------
loss: 0.001593  [    0/ 3462]
loss: 0.012713  [  100/ 3462]
loss: 0.008746  [  200/ 3462]
loss: 0.013532  [  300/ 3462]
loss: 0.008988  [  400/ 3462]
loss: 0.003361  [  500/ 3462]
loss: 0.001303  [  600/ 3462]
loss: 0.017823  [  700/ 3462]
loss: 0.010006  [  800/ 3462]
loss: 0.017092  [  900/ 3462]
loss: 0.008215  [ 1000/ 3462]
loss: 0.037341  [ 1100/ 3462]
loss: 0.011406  [ 1200/ 3462]
loss: 0.002804  [ 1300/ 3462]
loss: 0.002479  [ 1400/ 3462]
loss: 0.010285  [ 1500/ 3462]
loss: 0.005148  [ 1600/ 3462]
loss: 0.005242  [ 1700/ 3462]
loss: 0.011634  [ 1800/ 3462]
loss: 0.005924  [ 1900/ 3462]
loss: 0.004288  [ 2000/ 3462]
loss: 0.059401  [ 2100/ 3462]
loss: 0.001818  [ 2200/ 3462]
loss: 0.007567  [ 2300/ 3462]
loss: 0.012174  [ 2400/ 3462]
loss: 0.006362  [ 2500/ 3462]
loss: 0.009736  [ 2600/ 3462]
loss: 0.005813  [ 2700/ 3462]
loss: 0.004851  [ 2800/ 3462]
loss: 0.012768  [ 2900/ 3462]
loss: 0.113135  [ 3000/ 3462]
loss: 0.006778  [ 3100/ 3462]
loss: 0.008159  [ 3200/ 3462]
loss: 0.123040  [ 3300/ 3462]
loss: 0.012415  [ 3400/ 3462]
Epoch 7
-------------------------------
loss: 0.001562  [    0/ 3462]
loss: 0.012644  [  100/ 3462]
loss: 0.008626  [  200/ 3462]
loss: 0.014960  [  300/ 3462]
loss: 0.009267  [  400/ 3462]
loss: 0.002985  [  500/ 3462]
loss: 0.001788  [  600/ 3462]
loss: 0.017859  [  700/ 3462]
loss: 0.010215  [  800/ 3462]
loss: 0.016933  [  900/ 3462]
loss: 0.007917  [ 1000/ 3462]
loss: 0.038623  [ 1100/ 3462]
loss: 0.010465  [ 1200/ 3462]
loss: 0.002602  [ 1300/ 3462]
loss: 0.002157  [ 1400/ 3462]
loss: 0.010731  [ 1500/ 3462]
loss: 0.004551  [ 1600/ 3462]
loss: 0.005103  [ 1700/ 3462]
loss: 0.010320  [ 1800/ 3462]
loss: 0.005570  [ 1900/ 3462]
loss: 0.004227  [ 2000/ 3462]
loss: 0.061117  [ 2100/ 3462]
loss: 0.001772  [ 2200/ 3462]
loss: 0.007338  [ 2300/ 3462]
loss: 0.012151  [ 2400/ 3462]
loss: 0.006348  [ 2500/ 3462]
loss: 0.009282  [ 2600/ 3462]
loss: 0.005722  [ 2700/ 3462]
loss: 0.005102  [ 2800/ 3462]
loss: 0.012375  [ 2900/ 3462]
loss: 0.111957  [ 3000/ 3462]
loss: 0.006591  [ 3100/ 3462]
loss: 0.008121  [ 3200/ 3462]
loss: 0.120445  [ 3300/ 3462]
loss: 0.012419  [ 3400/ 3462]
Epoch 8
-------------------------------
loss: 0.001572  [    0/ 3462]
loss: 0.012614  [  100/ 3462]
loss: 0.007902  [  200/ 3462]
loss: 0.015705  [  300/ 3462]
loss: 0.009266  [  400/ 3462]
loss: 0.002735  [  500/ 3462]
loss: 0.002184  [  600/ 3462]
loss: 0.017752  [  700/ 3462]
loss: 0.010348  [  800/ 3462]
loss: 0.016657  [  900/ 3462]
loss: 0.007763  [ 1000/ 3462]
loss: 0.039347  [ 1100/ 3462]
loss: 0.009962  [ 1200/ 3462]
loss: 0.002492  [ 1300/ 3462]
loss: 0.002005  [ 1400/ 3462]
loss: 0.011041  [ 1500/ 3462]
loss: 0.004131  [ 1600/ 3462]
loss: 0.005089  [ 1700/ 3462]
loss: 0.009498  [ 1800/ 3462]
loss: 0.005424  [ 1900/ 3462]
loss: 0.004299  [ 2000/ 3462]
loss: 0.062059  [ 2100/ 3462]
loss: 0.001750  [ 2200/ 3462]
loss: 0.007182  [ 2300/ 3462]
loss: 0.012139  [ 2400/ 3462]
loss: 0.006335  [ 2500/ 3462]
loss: 0.009032  [ 2600/ 3462]
loss: 0.005632  [ 2700/ 3462]
loss: 0.005258  [ 2800/ 3462]
loss: 0.012125  [ 2900/ 3462]
loss: 0.111637  [ 3000/ 3462]
loss: 0.006365  [ 3100/ 3462]
loss: 0.008089  [ 3200/ 3462]
loss: 0.118846  [ 3300/ 3462]
loss: 0.012342  [ 3400/ 3462]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3462
First Spike after testing: [0.3236702  0.37156862]
[0 2 2 ... 0 1 2]
[0 2 2 ... 0 1 2]
Cluster 0 Occurrences: 1187; KMEANS: 1191
Cluster 1 Occurrences: 1136; KMEANS: 1136
Cluster 2 Occurrences: 1139; KMEANS: 1135
Centroids: [[0.20941007, 0.43859503], [-0.42966217, -0.89600396], [0.17047922, -0.06748172]]
Centroids: [[0.21441263, 0.4546669], [-0.43051243, -0.90175533], [0.1659437, -0.08037366]]
Contingency Matrix: 
[[1158    1   28]
 [   3 1129    4]
 [  30    6 1103]]
[[-1, -1, -1], [-1, 1129, 4], [-1, 6, 1103]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, 1103]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 1: 1, 2: 2}
New Contingency Matrix: 
[[1158    1   28]
 [   3 1129    4]
 [  30    6 1103]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1158, 1129, 1103], Sum: 3390
All_Elements: [1158, 1, 28, 3, 1129, 4, 30, 6, 1103], Sum: 3462
Accuracy: 0.9792027729636048
Done!
