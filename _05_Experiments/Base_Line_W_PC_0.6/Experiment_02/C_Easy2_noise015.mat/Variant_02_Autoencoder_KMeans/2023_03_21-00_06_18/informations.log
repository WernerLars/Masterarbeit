Experiment_path: Base_Line_W_PC_0.6/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Base_Line_W_PC_0.6/Experiment_02/C_Easy2_noise015.mat/Variant_02_Autoencoder_KMeans/2023_03_21-00_06_18
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000018283F7A630>
Sampling rate: 24000.0
Raw: [0.10609669 0.12118301 0.13260104 ... 0.04210554 0.02260723 0.01955233]
Times: [    280    1061    1071 ... 1439631 1439716 1439810]
Cluster: [1 3 1 ... 2 2 3]
Number of different clusters:  3
Number of Spikes: 3411
First aligned Spike Frame: [ 2.02686231e-02  4.10226375e-02  5.47302833e-02  6.75455965e-02
  7.31110476e-02  7.55341824e-02  6.24087212e-02  3.48405580e-02
  4.67612510e-03  3.11249190e-03  8.94324356e-03  4.24616810e-04
 -6.85644094e-02 -1.88193358e-01 -2.95062164e-01 -3.04804993e-01
 -1.80968869e-01  9.08445140e-02  4.69281397e-01  8.12588139e-01
  1.01247328e+00  1.07477323e+00  1.05264776e+00  9.80941312e-01
  8.59493136e-01  7.23747425e-01  6.30635083e-01  6.09810792e-01
  6.21566307e-01  6.10615318e-01  5.92057940e-01  5.70062731e-01
  5.39545035e-01  4.88086979e-01  4.33332627e-01  3.78964556e-01
  3.25819622e-01  2.83509204e-01  2.65213838e-01  2.75311674e-01
  2.95781207e-01  3.01368080e-01  2.86879888e-01  2.42452837e-01
  1.98600507e-01  1.34431645e-01  5.92612532e-02]
Cluster 0, Occurrences: 1181
Cluster 1, Occurrences: 1098
Cluster 2, Occurrences: 1132
<torch.utils.data.dataloader.DataLoader object at 0x0000018214CFABA8>
Epoch 1
-------------------------------
loss: 0.271194  [    0/ 3411]
loss: 0.138522  [  100/ 3411]
loss: 0.085354  [  200/ 3411]
loss: 0.017968  [  300/ 3411]
loss: 0.037286  [  400/ 3411]
loss: 0.029404  [  500/ 3411]
loss: 0.013217  [  600/ 3411]
loss: 0.025381  [  700/ 3411]
loss: 0.035785  [  800/ 3411]
loss: 0.047357  [  900/ 3411]
loss: 0.003854  [ 1000/ 3411]
loss: 0.051069  [ 1100/ 3411]
loss: 0.022669  [ 1200/ 3411]
loss: 0.031317  [ 1300/ 3411]
loss: 0.029185  [ 1400/ 3411]
loss: 0.068619  [ 1500/ 3411]
loss: 0.039886  [ 1600/ 3411]
loss: 0.026584  [ 1700/ 3411]
loss: 0.018481  [ 1800/ 3411]
loss: 0.004582  [ 1900/ 3411]
loss: 0.037294  [ 2000/ 3411]
loss: 0.011023  [ 2100/ 3411]
loss: 0.007750  [ 2200/ 3411]
loss: 0.151491  [ 2300/ 3411]
loss: 0.015586  [ 2400/ 3411]
loss: 0.013117  [ 2500/ 3411]
loss: 0.020701  [ 2600/ 3411]
loss: 0.008647  [ 2700/ 3411]
loss: 0.026665  [ 2800/ 3411]
loss: 0.011497  [ 2900/ 3411]
loss: 0.009924  [ 3000/ 3411]
loss: 0.004957  [ 3100/ 3411]
loss: 0.024854  [ 3200/ 3411]
loss: 0.012990  [ 3300/ 3411]
loss: 0.006827  [ 3400/ 3411]
Epoch 2
-------------------------------
loss: 0.022141  [    0/ 3411]
loss: 0.014497  [  100/ 3411]
loss: 0.014112  [  200/ 3411]
loss: 0.013035  [  300/ 3411]
loss: 0.032735  [  400/ 3411]
loss: 0.008215  [  500/ 3411]
loss: 0.005880  [  600/ 3411]
loss: 0.030349  [  700/ 3411]
loss: 0.021062  [  800/ 3411]
loss: 0.016487  [  900/ 3411]
loss: 0.003735  [ 1000/ 3411]
loss: 0.034620  [ 1100/ 3411]
loss: 0.021427  [ 1200/ 3411]
loss: 0.014063  [ 1300/ 3411]
loss: 0.019965  [ 1400/ 3411]
loss: 0.064456  [ 1500/ 3411]
loss: 0.034226  [ 1600/ 3411]
loss: 0.013679  [ 1700/ 3411]
loss: 0.018274  [ 1800/ 3411]
loss: 0.004751  [ 1900/ 3411]
loss: 0.033167  [ 2000/ 3411]
loss: 0.010529  [ 2100/ 3411]
loss: 0.007131  [ 2200/ 3411]
loss: 0.148902  [ 2300/ 3411]
loss: 0.016313  [ 2400/ 3411]
loss: 0.009769  [ 2500/ 3411]
loss: 0.018569  [ 2600/ 3411]
loss: 0.008196  [ 2700/ 3411]
loss: 0.026369  [ 2800/ 3411]
loss: 0.011754  [ 2900/ 3411]
loss: 0.006930  [ 3000/ 3411]
loss: 0.005382  [ 3100/ 3411]
loss: 0.023260  [ 3200/ 3411]
loss: 0.012614  [ 3300/ 3411]
loss: 0.009675  [ 3400/ 3411]
Epoch 3
-------------------------------
loss: 0.020942  [    0/ 3411]
loss: 0.014160  [  100/ 3411]
loss: 0.012312  [  200/ 3411]
loss: 0.012737  [  300/ 3411]
loss: 0.033502  [  400/ 3411]
loss: 0.008927  [  500/ 3411]
loss: 0.004042  [  600/ 3411]
loss: 0.020831  [  700/ 3411]
loss: 0.021048  [  800/ 3411]
loss: 0.016201  [  900/ 3411]
loss: 0.003608  [ 1000/ 3411]
loss: 0.014757  [ 1100/ 3411]
loss: 0.021139  [ 1200/ 3411]
loss: 0.012841  [ 1300/ 3411]
loss: 0.018946  [ 1400/ 3411]
loss: 0.063331  [ 1500/ 3411]
loss: 0.027413  [ 1600/ 3411]
loss: 0.015493  [ 1700/ 3411]
loss: 0.020166  [ 1800/ 3411]
loss: 0.004566  [ 1900/ 3411]
loss: 0.032023  [ 2000/ 3411]
loss: 0.008954  [ 2100/ 3411]
loss: 0.007519  [ 2200/ 3411]
loss: 0.147176  [ 2300/ 3411]
loss: 0.016449  [ 2400/ 3411]
loss: 0.007841  [ 2500/ 3411]
loss: 0.012827  [ 2600/ 3411]
loss: 0.008166  [ 2700/ 3411]
loss: 0.026002  [ 2800/ 3411]
loss: 0.011797  [ 2900/ 3411]
loss: 0.007509  [ 3000/ 3411]
loss: 0.005127  [ 3100/ 3411]
loss: 0.022002  [ 3200/ 3411]
loss: 0.012430  [ 3300/ 3411]
loss: 0.010329  [ 3400/ 3411]
Epoch 4
-------------------------------
loss: 0.020155  [    0/ 3411]
loss: 0.013550  [  100/ 3411]
loss: 0.011840  [  200/ 3411]
loss: 0.012847  [  300/ 3411]
loss: 0.034015  [  400/ 3411]
loss: 0.009837  [  500/ 3411]
loss: 0.003894  [  600/ 3411]
loss: 0.015240  [  700/ 3411]
loss: 0.020962  [  800/ 3411]
loss: 0.015899  [  900/ 3411]
loss: 0.003649  [ 1000/ 3411]
loss: 0.010090  [ 1100/ 3411]
loss: 0.020838  [ 1200/ 3411]
loss: 0.012319  [ 1300/ 3411]
loss: 0.018696  [ 1400/ 3411]
loss: 0.061305  [ 1500/ 3411]
loss: 0.023522  [ 1600/ 3411]
loss: 0.016421  [ 1700/ 3411]
loss: 0.019200  [ 1800/ 3411]
loss: 0.004909  [ 1900/ 3411]
loss: 0.031655  [ 2000/ 3411]
loss: 0.008713  [ 2100/ 3411]
loss: 0.008058  [ 2200/ 3411]
loss: 0.147111  [ 2300/ 3411]
loss: 0.016677  [ 2400/ 3411]
loss: 0.007668  [ 2500/ 3411]
loss: 0.010748  [ 2600/ 3411]
loss: 0.008143  [ 2700/ 3411]
loss: 0.025762  [ 2800/ 3411]
loss: 0.011692  [ 2900/ 3411]
loss: 0.009003  [ 3000/ 3411]
loss: 0.005273  [ 3100/ 3411]
loss: 0.021122  [ 3200/ 3411]
loss: 0.012299  [ 3300/ 3411]
loss: 0.009303  [ 3400/ 3411]
Epoch 5
-------------------------------
loss: 0.019954  [    0/ 3411]
loss: 0.013524  [  100/ 3411]
loss: 0.011625  [  200/ 3411]
loss: 0.012926  [  300/ 3411]
loss: 0.033963  [  400/ 3411]
loss: 0.010013  [  500/ 3411]
loss: 0.003946  [  600/ 3411]
loss: 0.010279  [  700/ 3411]
loss: 0.020843  [  800/ 3411]
loss: 0.016002  [  900/ 3411]
loss: 0.003760  [ 1000/ 3411]
loss: 0.008390  [ 1100/ 3411]
loss: 0.020807  [ 1200/ 3411]
loss: 0.012356  [ 1300/ 3411]
loss: 0.018877  [ 1400/ 3411]
loss: 0.061159  [ 1500/ 3411]
loss: 0.021681  [ 1600/ 3411]
loss: 0.015489  [ 1700/ 3411]
loss: 0.016338  [ 1800/ 3411]
loss: 0.005801  [ 1900/ 3411]
loss: 0.031878  [ 2000/ 3411]
loss: 0.008434  [ 2100/ 3411]
loss: 0.007668  [ 2200/ 3411]
loss: 0.148465  [ 2300/ 3411]
loss: 0.016865  [ 2400/ 3411]
loss: 0.007972  [ 2500/ 3411]
loss: 0.009407  [ 2600/ 3411]
loss: 0.008101  [ 2700/ 3411]
loss: 0.025753  [ 2800/ 3411]
loss: 0.011375  [ 2900/ 3411]
loss: 0.010289  [ 3000/ 3411]
loss: 0.005132  [ 3100/ 3411]
loss: 0.020857  [ 3200/ 3411]
loss: 0.012291  [ 3300/ 3411]
loss: 0.007309  [ 3400/ 3411]
Epoch 6
-------------------------------
loss: 0.019845  [    0/ 3411]
loss: 0.013784  [  100/ 3411]
loss: 0.012508  [  200/ 3411]
loss: 0.012981  [  300/ 3411]
loss: 0.033512  [  400/ 3411]
loss: 0.010023  [  500/ 3411]
loss: 0.004004  [  600/ 3411]
loss: 0.007137  [  700/ 3411]
loss: 0.020554  [  800/ 3411]
loss: 0.016242  [  900/ 3411]
loss: 0.003940  [ 1000/ 3411]
loss: 0.008218  [ 1100/ 3411]
loss: 0.020863  [ 1200/ 3411]
loss: 0.012460  [ 1300/ 3411]
loss: 0.019029  [ 1400/ 3411]
loss: 0.063490  [ 1500/ 3411]
loss: 0.020130  [ 1600/ 3411]
loss: 0.014507  [ 1700/ 3411]
loss: 0.013212  [ 1800/ 3411]
loss: 0.006431  [ 1900/ 3411]
loss: 0.032363  [ 2000/ 3411]
loss: 0.007201  [ 2100/ 3411]
loss: 0.007907  [ 2200/ 3411]
loss: 0.149939  [ 2300/ 3411]
loss: 0.017072  [ 2400/ 3411]
loss: 0.008484  [ 2500/ 3411]
loss: 0.008422  [ 2600/ 3411]
loss: 0.007918  [ 2700/ 3411]
loss: 0.025940  [ 2800/ 3411]
loss: 0.011042  [ 2900/ 3411]
loss: 0.010699  [ 3000/ 3411]
loss: 0.005091  [ 3100/ 3411]
loss: 0.020735  [ 3200/ 3411]
loss: 0.012302  [ 3300/ 3411]
loss: 0.006259  [ 3400/ 3411]
Epoch 7
-------------------------------
loss: 0.019700  [    0/ 3411]
loss: 0.013855  [  100/ 3411]
loss: 0.013572  [  200/ 3411]
loss: 0.012926  [  300/ 3411]
loss: 0.032896  [  400/ 3411]
loss: 0.009818  [  500/ 3411]
loss: 0.003765  [  600/ 3411]
loss: 0.005211  [  700/ 3411]
loss: 0.020063  [  800/ 3411]
loss: 0.016294  [  900/ 3411]
loss: 0.003978  [ 1000/ 3411]
loss: 0.008077  [ 1100/ 3411]
loss: 0.020834  [ 1200/ 3411]
loss: 0.012434  [ 1300/ 3411]
loss: 0.019188  [ 1400/ 3411]
loss: 0.065779  [ 1500/ 3411]
loss: 0.019459  [ 1600/ 3411]
loss: 0.013960  [ 1700/ 3411]
loss: 0.012205  [ 1800/ 3411]
loss: 0.006563  [ 1900/ 3411]
loss: 0.032717  [ 2000/ 3411]
loss: 0.006907  [ 2100/ 3411]
loss: 0.008223  [ 2200/ 3411]
loss: 0.150778  [ 2300/ 3411]
loss: 0.017330  [ 2400/ 3411]
loss: 0.007566  [ 2500/ 3411]
loss: 0.007674  [ 2600/ 3411]
loss: 0.007745  [ 2700/ 3411]
loss: 0.026090  [ 2800/ 3411]
loss: 0.010912  [ 2900/ 3411]
loss: 0.010541  [ 3000/ 3411]
loss: 0.005100  [ 3100/ 3411]
loss: 0.020555  [ 3200/ 3411]
loss: 0.012343  [ 3300/ 3411]
loss: 0.005711  [ 3400/ 3411]
Epoch 8
-------------------------------
loss: 0.019766  [    0/ 3411]
loss: 0.013922  [  100/ 3411]
loss: 0.014382  [  200/ 3411]
loss: 0.012806  [  300/ 3411]
loss: 0.032620  [  400/ 3411]
loss: 0.009659  [  500/ 3411]
loss: 0.003611  [  600/ 3411]
loss: 0.004083  [  700/ 3411]
loss: 0.019876  [  800/ 3411]
loss: 0.016434  [  900/ 3411]
loss: 0.004017  [ 1000/ 3411]
loss: 0.007890  [ 1100/ 3411]
loss: 0.020756  [ 1200/ 3411]
loss: 0.012414  [ 1300/ 3411]
loss: 0.019194  [ 1400/ 3411]
loss: 0.067396  [ 1500/ 3411]
loss: 0.019173  [ 1600/ 3411]
loss: 0.013566  [ 1700/ 3411]
loss: 0.011948  [ 1800/ 3411]
loss: 0.006865  [ 1900/ 3411]
loss: 0.032853  [ 2000/ 3411]
loss: 0.006738  [ 2100/ 3411]
loss: 0.008502  [ 2200/ 3411]
loss: 0.151137  [ 2300/ 3411]
loss: 0.017415  [ 2400/ 3411]
loss: 0.007307  [ 2500/ 3411]
loss: 0.007463  [ 2600/ 3411]
loss: 0.007715  [ 2700/ 3411]
loss: 0.026178  [ 2800/ 3411]
loss: 0.011074  [ 2900/ 3411]
loss: 0.010583  [ 3000/ 3411]
loss: 0.005082  [ 3100/ 3411]
loss: 0.020035  [ 3200/ 3411]
loss: 0.012340  [ 3300/ 3411]
loss: 0.005186  [ 3400/ 3411]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3411
First Spike after testing: [ 1.0867438 -0.8547653]
[0 2 0 ... 1 1 2]
[0 1 0 ... 0 0 2]
Cluster 0 Occurrences: 1181; KMEANS: 2284
Cluster 1 Occurrences: 1098; KMEANS: 562
Cluster 2 Occurrences: 1132; KMEANS: 565
Centroids: [[0.9561907, -0.934366], [0.52386624, -0.52705234], [-0.4814743, 1.9913613]]
Centroids: [[0.7487668, -0.7368443], [-0.2859814, 1.5499543], [-0.6903086, 2.4493968]]
Contingency Matrix: 
[[1180    1    0]
 [1097    1    0]
 [   7  560  565]]
[[-1, -1, -1], [-1, 1, 0], [-1, 560, 565]]
[[-1, -1, -1], [-1, 1, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 2: 2, 1: 1}
New Contingency Matrix: 
[[1180    1    0]
 [1097    1    0]
 [   7  560  565]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1180, 1, 565], Sum: 1746
All_Elements: [1180, 1, 0, 1097, 1, 0, 7, 560, 565], Sum: 3411
Accuracy: 0.5118733509234829
Done!
