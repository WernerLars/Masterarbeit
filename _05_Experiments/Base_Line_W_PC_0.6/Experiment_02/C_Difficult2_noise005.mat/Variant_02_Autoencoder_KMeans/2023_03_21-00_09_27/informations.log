Experiment_path: Base_Line_W_PC_0.6/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult2_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult2_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Base_Line_W_PC_0.6/Experiment_02/C_Difficult2_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_21-00_09_27
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001825AFCB198>
Sampling rate: 24000.0
Raw: [ 0.02085333  0.02043967  0.02052644 ... -0.02218732 -0.02150573
 -0.01811243]
Times: [   1583    1934    2430 ... 1439313 1439656 1439854]
Cluster: [3 3 3 ... 2 2 1]
Number of different clusters:  3
Number of Spikes: 3364
First aligned Spike Frame: [-0.05170878 -0.0548761  -0.06029554 -0.06053219 -0.04807119 -0.02780025
 -0.01550543 -0.01702494 -0.02945104 -0.04493807 -0.07056858 -0.07003585
  0.07629654  0.43081562  0.80470191  0.96319627  0.89198123  0.73643948
  0.58987232  0.46714337  0.36345495  0.2828462   0.22743292  0.182731
  0.13931053  0.09524506  0.05136602  0.01367166 -0.01393093 -0.03985679
 -0.07387102 -0.11218435 -0.1444455  -0.16672578 -0.17809238 -0.18020802
 -0.17953732 -0.18246903 -0.18617363 -0.18205375 -0.17299738 -0.16958427
 -0.17248955 -0.17516876 -0.1727246  -0.16696514 -0.15993314]
Cluster 0, Occurrences: 1120
Cluster 1, Occurrences: 1109
Cluster 2, Occurrences: 1135
<torch.utils.data.dataloader.DataLoader object at 0x00000182864F5CC0>
Epoch 1
-------------------------------
loss: 0.113777  [    0/ 3364]
loss: 0.085791  [  100/ 3364]
loss: 0.023911  [  200/ 3364]
loss: 0.017481  [  300/ 3364]
loss: 0.010481  [  400/ 3364]
loss: 0.040162  [  500/ 3364]
loss: 0.006620  [  600/ 3364]
loss: 0.009832  [  700/ 3364]
loss: 0.003692  [  800/ 3364]
loss: 0.013092  [  900/ 3364]
loss: 0.013208  [ 1000/ 3364]
loss: 0.003577  [ 1100/ 3364]
loss: 0.007811  [ 1200/ 3364]
loss: 0.006245  [ 1300/ 3364]
loss: 0.086339  [ 1400/ 3364]
loss: 0.003498  [ 1500/ 3364]
loss: 0.006704  [ 1600/ 3364]
loss: 0.004581  [ 1700/ 3364]
loss: 0.001767  [ 1800/ 3364]
loss: 0.003868  [ 1900/ 3364]
loss: 0.004335  [ 2000/ 3364]
loss: 0.005597  [ 2100/ 3364]
loss: 0.003992  [ 2200/ 3364]
loss: 0.007630  [ 2300/ 3364]
loss: 0.001387  [ 2400/ 3364]
loss: 0.002771  [ 2500/ 3364]
loss: 0.002265  [ 2600/ 3364]
loss: 0.003372  [ 2700/ 3364]
loss: 0.003749  [ 2800/ 3364]
loss: 0.001247  [ 2900/ 3364]
loss: 0.004157  [ 3000/ 3364]
loss: 0.006125  [ 3100/ 3364]
loss: 0.001529  [ 3200/ 3364]
loss: 0.001919  [ 3300/ 3364]
Epoch 2
-------------------------------
loss: 0.001389  [    0/ 3364]
loss: 0.002013  [  100/ 3364]
loss: 0.004995  [  200/ 3364]
loss: 0.001182  [  300/ 3364]
loss: 0.000609  [  400/ 3364]
loss: 0.033201  [  500/ 3364]
loss: 0.004170  [  600/ 3364]
loss: 0.008996  [  700/ 3364]
loss: 0.002541  [  800/ 3364]
loss: 0.002731  [  900/ 3364]
loss: 0.003504  [ 1000/ 3364]
loss: 0.003514  [ 1100/ 3364]
loss: 0.002401  [ 1200/ 3364]
loss: 0.005489  [ 1300/ 3364]
loss: 0.085535  [ 1400/ 3364]
loss: 0.002670  [ 1500/ 3364]
loss: 0.006782  [ 1600/ 3364]
loss: 0.003155  [ 1700/ 3364]
loss: 0.001123  [ 1800/ 3364]
loss: 0.003903  [ 1900/ 3364]
loss: 0.002505  [ 2000/ 3364]
loss: 0.004012  [ 2100/ 3364]
loss: 0.004392  [ 2200/ 3364]
loss: 0.007312  [ 2300/ 3364]
loss: 0.001121  [ 2400/ 3364]
loss: 0.002316  [ 2500/ 3364]
loss: 0.001739  [ 2600/ 3364]
loss: 0.003765  [ 2700/ 3364]
loss: 0.003851  [ 2800/ 3364]
loss: 0.001580  [ 2900/ 3364]
loss: 0.003819  [ 3000/ 3364]
loss: 0.005945  [ 3100/ 3364]
loss: 0.001412  [ 3200/ 3364]
loss: 0.001498  [ 3300/ 3364]
Epoch 3
-------------------------------
loss: 0.001504  [    0/ 3364]
loss: 0.002216  [  100/ 3364]
loss: 0.004946  [  200/ 3364]
loss: 0.000880  [  300/ 3364]
loss: 0.000769  [  400/ 3364]
loss: 0.030280  [  500/ 3364]
loss: 0.004071  [  600/ 3364]
loss: 0.008927  [  700/ 3364]
loss: 0.002318  [  800/ 3364]
loss: 0.002810  [  900/ 3364]
loss: 0.003098  [ 1000/ 3364]
loss: 0.003482  [ 1100/ 3364]
loss: 0.002195  [ 1200/ 3364]
loss: 0.005782  [ 1300/ 3364]
loss: 0.084866  [ 1400/ 3364]
loss: 0.002647  [ 1500/ 3364]
loss: 0.006552  [ 1600/ 3364]
loss: 0.003189  [ 1700/ 3364]
loss: 0.001007  [ 1800/ 3364]
loss: 0.003455  [ 1900/ 3364]
loss: 0.002516  [ 2000/ 3364]
loss: 0.004016  [ 2100/ 3364]
loss: 0.004578  [ 2200/ 3364]
loss: 0.007077  [ 2300/ 3364]
loss: 0.001113  [ 2400/ 3364]
loss: 0.002203  [ 2500/ 3364]
loss: 0.001528  [ 2600/ 3364]
loss: 0.003816  [ 2700/ 3364]
loss: 0.003719  [ 2800/ 3364]
loss: 0.001268  [ 2900/ 3364]
loss: 0.003751  [ 3000/ 3364]
loss: 0.005886  [ 3100/ 3364]
loss: 0.001085  [ 3200/ 3364]
loss: 0.002085  [ 3300/ 3364]
Epoch 4
-------------------------------
loss: 0.001431  [    0/ 3364]
loss: 0.002160  [  100/ 3364]
loss: 0.005087  [  200/ 3364]
loss: 0.000894  [  300/ 3364]
loss: 0.000776  [  400/ 3364]
loss: 0.029961  [  500/ 3364]
loss: 0.003991  [  600/ 3364]
loss: 0.007014  [  700/ 3364]
loss: 0.002252  [  800/ 3364]
loss: 0.003187  [  900/ 3364]
loss: 0.002528  [ 1000/ 3364]
loss: 0.003375  [ 1100/ 3364]
loss: 0.002257  [ 1200/ 3364]
loss: 0.006251  [ 1300/ 3364]
loss: 0.084375  [ 1400/ 3364]
loss: 0.002876  [ 1500/ 3364]
loss: 0.006453  [ 1600/ 3364]
loss: 0.003390  [ 1700/ 3364]
loss: 0.000996  [ 1800/ 3364]
loss: 0.003595  [ 1900/ 3364]
loss: 0.002422  [ 2000/ 3364]
loss: 0.003872  [ 2100/ 3364]
loss: 0.005038  [ 2200/ 3364]
loss: 0.006996  [ 2300/ 3364]
loss: 0.001255  [ 2400/ 3364]
loss: 0.001981  [ 2500/ 3364]
loss: 0.001548  [ 2600/ 3364]
loss: 0.003968  [ 2700/ 3364]
loss: 0.004004  [ 2800/ 3364]
loss: 0.001313  [ 2900/ 3364]
loss: 0.003600  [ 3000/ 3364]
loss: 0.005908  [ 3100/ 3364]
loss: 0.000972  [ 3200/ 3364]
loss: 0.002382  [ 3300/ 3364]
Epoch 5
-------------------------------
loss: 0.001499  [    0/ 3364]
loss: 0.001860  [  100/ 3364]
loss: 0.004785  [  200/ 3364]
loss: 0.000772  [  300/ 3364]
loss: 0.000618  [  400/ 3364]
loss: 0.031212  [  500/ 3364]
loss: 0.003623  [  600/ 3364]
loss: 0.004977  [  700/ 3364]
loss: 0.002344  [  800/ 3364]
loss: 0.003723  [  900/ 3364]
loss: 0.001863  [ 1000/ 3364]
loss: 0.003535  [ 1100/ 3364]
loss: 0.002384  [ 1200/ 3364]
loss: 0.006170  [ 1300/ 3364]
loss: 0.083781  [ 1400/ 3364]
loss: 0.002980  [ 1500/ 3364]
loss: 0.006516  [ 1600/ 3364]
loss: 0.002906  [ 1700/ 3364]
loss: 0.001045  [ 1800/ 3364]
loss: 0.003662  [ 1900/ 3364]
loss: 0.002539  [ 2000/ 3364]
loss: 0.003740  [ 2100/ 3364]
loss: 0.004943  [ 2200/ 3364]
loss: 0.007181  [ 2300/ 3364]
loss: 0.001159  [ 2400/ 3364]
loss: 0.002226  [ 2500/ 3364]
loss: 0.001834  [ 2600/ 3364]
loss: 0.003745  [ 2700/ 3364]
loss: 0.004340  [ 2800/ 3364]
loss: 0.001350  [ 2900/ 3364]
loss: 0.003697  [ 3000/ 3364]
loss: 0.006012  [ 3100/ 3364]
loss: 0.001037  [ 3200/ 3364]
loss: 0.002042  [ 3300/ 3364]
Epoch 6
-------------------------------
loss: 0.001294  [    0/ 3364]
loss: 0.001740  [  100/ 3364]
loss: 0.004496  [  200/ 3364]
loss: 0.000866  [  300/ 3364]
loss: 0.000708  [  400/ 3364]
loss: 0.031622  [  500/ 3364]
loss: 0.003322  [  600/ 3364]
loss: 0.004278  [  700/ 3364]
loss: 0.002354  [  800/ 3364]
loss: 0.004112  [  900/ 3364]
loss: 0.001674  [ 1000/ 3364]
loss: 0.003620  [ 1100/ 3364]
loss: 0.002287  [ 1200/ 3364]
loss: 0.006082  [ 1300/ 3364]
loss: 0.082301  [ 1400/ 3364]
loss: 0.002978  [ 1500/ 3364]
loss: 0.006447  [ 1600/ 3364]
loss: 0.002865  [ 1700/ 3364]
loss: 0.000981  [ 1800/ 3364]
loss: 0.003646  [ 1900/ 3364]
loss: 0.002587  [ 2000/ 3364]
loss: 0.003713  [ 2100/ 3364]
loss: 0.005027  [ 2200/ 3364]
loss: 0.007356  [ 2300/ 3364]
loss: 0.001169  [ 2400/ 3364]
loss: 0.002127  [ 2500/ 3364]
loss: 0.001931  [ 2600/ 3364]
loss: 0.003639  [ 2700/ 3364]
loss: 0.004376  [ 2800/ 3364]
loss: 0.001351  [ 2900/ 3364]
loss: 0.003600  [ 3000/ 3364]
loss: 0.006065  [ 3100/ 3364]
loss: 0.001031  [ 3200/ 3364]
loss: 0.002025  [ 3300/ 3364]
Epoch 7
-------------------------------
loss: 0.001205  [    0/ 3364]
loss: 0.001820  [  100/ 3364]
loss: 0.004424  [  200/ 3364]
loss: 0.000850  [  300/ 3364]
loss: 0.000731  [  400/ 3364]
loss: 0.033070  [  500/ 3364]
loss: 0.003264  [  600/ 3364]
loss: 0.004066  [  700/ 3364]
loss: 0.002266  [  800/ 3364]
loss: 0.004367  [  900/ 3364]
loss: 0.001532  [ 1000/ 3364]
loss: 0.003732  [ 1100/ 3364]
loss: 0.002277  [ 1200/ 3364]
loss: 0.006043  [ 1300/ 3364]
loss: 0.081464  [ 1400/ 3364]
loss: 0.003104  [ 1500/ 3364]
loss: 0.006428  [ 1600/ 3364]
loss: 0.002999  [ 1700/ 3364]
loss: 0.000938  [ 1800/ 3364]
loss: 0.003530  [ 1900/ 3364]
loss: 0.002611  [ 2000/ 3364]
loss: 0.003646  [ 2100/ 3364]
loss: 0.005138  [ 2200/ 3364]
loss: 0.007508  [ 2300/ 3364]
loss: 0.001304  [ 2400/ 3364]
loss: 0.001896  [ 2500/ 3364]
loss: 0.002155  [ 2600/ 3364]
loss: 0.003586  [ 2700/ 3364]
loss: 0.004202  [ 2800/ 3364]
loss: 0.001399  [ 2900/ 3364]
loss: 0.003326  [ 3000/ 3364]
loss: 0.006036  [ 3100/ 3364]
loss: 0.001004  [ 3200/ 3364]
loss: 0.002950  [ 3300/ 3364]
Epoch 8
-------------------------------
loss: 0.001107  [    0/ 3364]
loss: 0.002046  [  100/ 3364]
loss: 0.004384  [  200/ 3364]
loss: 0.000873  [  300/ 3364]
loss: 0.000679  [  400/ 3364]
loss: 0.034920  [  500/ 3364]
loss: 0.003148  [  600/ 3364]
loss: 0.004056  [  700/ 3364]
loss: 0.002323  [  800/ 3364]
loss: 0.004498  [  900/ 3364]
loss: 0.001490  [ 1000/ 3364]
loss: 0.003765  [ 1100/ 3364]
loss: 0.002255  [ 1200/ 3364]
loss: 0.006026  [ 1300/ 3364]
loss: 0.080158  [ 1400/ 3364]
loss: 0.003235  [ 1500/ 3364]
loss: 0.006389  [ 1600/ 3364]
loss: 0.003091  [ 1700/ 3364]
loss: 0.000887  [ 1800/ 3364]
loss: 0.003653  [ 1900/ 3364]
loss: 0.002513  [ 2000/ 3364]
loss: 0.003177  [ 2100/ 3364]
loss: 0.005477  [ 2200/ 3364]
loss: 0.007635  [ 2300/ 3364]
loss: 0.001420  [ 2400/ 3364]
loss: 0.001681  [ 2500/ 3364]
loss: 0.002484  [ 2600/ 3364]
loss: 0.003507  [ 2700/ 3364]
loss: 0.004082  [ 2800/ 3364]
loss: 0.001441  [ 2900/ 3364]
loss: 0.003026  [ 3000/ 3364]
loss: 0.006068  [ 3100/ 3364]
loss: 0.000991  [ 3200/ 3364]
loss: 0.002449  [ 3300/ 3364]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3364
First Spike after testing: [ 0.6232693  -0.02782508]
[2 2 2 ... 1 1 0]
[2 2 2 ... 1 1 0]
Cluster 0 Occurrences: 1120; KMEANS: 1142
Cluster 1 Occurrences: 1109; KMEANS: 1104
Cluster 2 Occurrences: 1135; KMEANS: 1118
Centroids: [[0.69670814, 0.57328904], [-0.20954126, -0.8981316], [0.6120244, 0.022213208]]
Centroids: [[0.692547, 0.59457254], [-0.22418652, -0.90301424], [0.6253961, -0.009665763]]
Contingency Matrix: 
[[1107    1   12]
 [   4 1096    9]
 [  31    7 1097]]
[[-1, -1, -1], [-1, 1096, 9], [-1, 7, 1097]]
[[-1, -1, -1], [-1, 1096, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {0: 0, 2: 2, 1: 1}
New Contingency Matrix: 
[[1107    1   12]
 [   4 1096    9]
 [  31    7 1097]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1107, 1096, 1097], Sum: 3300
All_Elements: [1107, 1, 12, 4, 1096, 9, 31, 7, 1097], Sum: 3364
Accuracy: 0.9809750297265161
Done!
