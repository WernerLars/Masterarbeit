Seed: 6
Experiment_path: Random_Seeds_DV5//V5_3/Experiment_05_6_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: Random_Seeds_DV5//V5_3/Experiment_05_6_opt_temp_noisy/C_Drift_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_05-10_15_11
Normalisation: False
Template Matching: True
Optimising Autoencoder: True
Update Factor: 100
Noisy Batches: True
Noisy Factor: 0.1
Epochs: 8
Batch Size: 1
maximal Spikes for Autoencoder Training : 700
maximal Spikes for Training: 1000
Input Size: 47
Chosen Model: Autoencoder
Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=47, out_features=12, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=12, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=2, out_features=12, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=12, out_features=47, bias=True)
  )
)
MSELoss()
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0
)
---Q Learning Parameters---
Normalisation: False
Punishment Coefficient: 0.6
Alpha: 0.8
Epsilon: 0.01
Gamma: 0.97
Initial Episode Number: 0
Episode Number Coefficient: 1.4
Number of Random Features: 20
Planning Number: 20
Max Random Features: 60
New Episode Number: 72
New Episode Number: 143
New Episode Number: 215
New Episode Number: 286
New Episode Number: 358
New Episode Number: 429
New Episode Number: 500
New Episode Number: 572
New Episode Number: 643
New Episode Number: 715
New Episode Number: 786
New Episode Number: 858
New Episode Number: 929
New Episode Number: 1000
New Episode Number: 1072
New Episode Number: 1143
New Episode Number: 1215
New Episode Number: 1286
New Episode Number: 1358
New Episode Number: 1429
New Episode Number: 1501
New Episode Number: 1572
               0     1      2     3     4   ...     18     19     20    21     22
new_cluster -3.72 -2.35 -14.91 -2.95 -3.72  ... -48.11 -10.95 -23.39 -5.90 -13.49
c1          -3.72 -2.46 -13.58 -2.94 -4.24  ... -48.14 -11.00 -23.69 -6.23 -13.07
c2          -3.72 -2.41 -13.90 -3.13 -3.96  ... -48.14 -10.70 -23.75 -4.75 -12.27
c3          -3.63 -2.36 -13.69 -2.95 -4.06  ... -48.14 -10.87 -23.76 -4.80 -13.44
c4          -3.72 -2.44 -14.19 -2.97 -3.78  ... -48.14 -10.54 -23.82 -4.75 -12.54
c5          -3.60 -2.29 -13.64 -3.03 -3.71  ... -48.14 -10.47 -22.93 -4.88 -13.20
c6          -3.70 -2.30 -13.98 -3.02 -3.86  ... -48.14 -10.70 -23.89 -4.63 -12.91
c7          -3.70 -2.36 -13.77 -3.05 -3.91  ... -48.13 -10.16 -23.18 -4.91 -12.61
c8          -3.67 -2.38 -14.47 -2.81 -4.39  ... -48.14 -10.39 -23.79 -5.67 -12.72
c9          -3.72 -2.37 -14.44 -3.10 -3.72  ... -48.14 -10.42 -24.34 -5.54 -13.02
c10         -3.72 -2.37 -14.11 -3.19 -3.78  ... -48.14 -11.11 -23.23 -5.57 -13.39
c11         -3.72 -2.20 -14.32 -2.95 -3.95  ... -48.12 -10.50 -23.02 -4.93 -13.14
c12         -3.72 -2.38 -14.05 -2.99 -3.73  ... -48.14 -10.93 -23.32 -6.21 -12.43
c13         -3.70 -2.37 -13.83 -2.84 -3.82  ... -48.11 -11.17 -23.97 -4.73 -13.02
c14         -3.60 -2.45 -13.39 -3.17 -3.89  ... -48.12 -11.13 -23.25 -4.21 -12.95
c15         -3.70 -2.34 -14.15 -3.11 -4.16  ... -48.15 -11.25 -23.71 -4.26 -12.84
c16         -3.70 -2.41 -14.49 -3.02 -3.84  ... -48.12 -10.41 -22.69 -4.68 -13.30
c17         -3.70 -2.36 -13.96 -3.00 -4.11  ... -48.12 -10.40 -23.06 -3.90 -12.74
c18         -3.72 -2.41 -13.96 -3.03 -3.76  ... -48.14 -11.51 -23.58 -4.94 -12.69
c19         -3.60 -2.22 -14.41 -2.81 -3.80  ... -48.14 -10.47 -23.53 -5.30 -12.81
c20         -3.72 -2.26 -14.64 -2.93 -3.74  ... -48.14 -10.82 -23.57 -5.53 -12.90
c21         -3.70 -2.37 -14.28 -2.98 -3.73  ... -48.13 -11.10 -23.12 -4.46 -12.81
c22         -3.61 -2.46 -14.17 -2.96 -4.06  ... -48.14 -11.61 -23.66 -4.81   0.00

[23 rows x 23 columns]
                               0            1   ...            21             22
new_cluster  [-1.44, new_cluster]  [-0.07, c1]  ...  [-3.61, c21]  [-13.49, c22]
c1           [-1.44, new_cluster]  [-0.11, c1]  ...  [-3.93, c21]  [-13.07, c22]
c2           [-1.44, new_cluster]  [-0.06, c1]  ...  [-2.48, c21]  [-12.27, c22]
c3           [-1.44, new_cluster]  [-0.05, c1]  ...  [-2.64, c21]  [-13.44, c22]
c4           [-1.44, new_cluster]  [-0.08, c1]  ...  [-2.48, c21]  [-12.54, c22]
c5           [-1.44, new_cluster]  [-0.11, c1]  ...  [-2.72, c21]   [-13.2, c22]
c6           [-1.44, new_cluster]  [-0.06, c1]  ...  [-2.33, c21]  [-12.91, c22]
c7           [-1.44, new_cluster]  [-0.08, c1]  ...  [-2.61, c21]  [-12.61, c22]
c8           [-1.44, new_cluster]   [-0.1, c1]  ...  [-3.38, c21]  [-12.72, c22]
c9           [-1.44, new_cluster]  [-0.04, c1]  ...  [-3.27, c21]  [-13.02, c22]
c10          [-1.44, new_cluster]  [-0.08, c1]  ...  [-3.28, c21]  [-13.39, c22]
c11          [-1.44, new_cluster]  [-0.03, c1]  ...  [-2.65, c21]  [-13.14, c22]
c12          [-1.44, new_cluster]  [-0.07, c1]  ...  [-3.91, c21]  [-12.43, c22]
c13          [-1.44, new_cluster]   [-0.1, c1]  ...  [-2.57, c21]  [-13.02, c22]
c14          [-1.44, new_cluster]  [-0.15, c1]  ...  [-1.91, c21]  [-12.95, c22]
c15          [-1.44, new_cluster]  [-0.07, c1]  ...   [-2.1, c21]  [-12.84, c22]
c16          [-1.44, new_cluster]  [-0.03, c1]  ...  [-2.41, c21]   [-13.3, c22]
c17          [-1.44, new_cluster]   [-0.1, c1]  ...  [-1.56, c21]  [-12.74, c22]
c18          [-1.44, new_cluster]  [-0.08, c1]  ...  [-2.67, c21]  [-12.69, c22]
c19          [-1.44, new_cluster]  [-0.03, c1]  ...   [-3.0, c21]  [-12.81, c22]
c20          [-1.44, new_cluster]  [-0.06, c1]  ...  [-3.23, c21]   [-12.9, c22]
c21          [-1.44, new_cluster]  [-0.06, c1]  ...   [-2.3, c21]  [-12.81, c22]
c22          [-1.44, new_cluster]   [-0.2, c1]  ...  [-2.51, c21]          [0, ]

[23 rows x 23 columns]
