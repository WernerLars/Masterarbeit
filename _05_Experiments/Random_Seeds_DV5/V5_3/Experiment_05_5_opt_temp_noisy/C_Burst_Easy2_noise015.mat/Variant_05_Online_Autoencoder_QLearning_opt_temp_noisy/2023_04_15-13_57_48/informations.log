Experiment_path: Random_Seeds_DV5//V5_3/Experiment_05_5_opt_temp_noisy
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy
Visualisation_Path: Random_Seeds_DV5//V5_3/Experiment_05_5_opt_temp_noisy/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp_noisy/2023_04_15-13_57_48
Punishment_Coefficient: 0.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000024FF8800470>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.21446209587156773
Online_Training [2/700]: mean_loss=0.2656676210463047
Online_Training [3/700]: mean_loss=0.22124778293073177
Online_Training [4/700]: mean_loss=0.07900287117809057
Online_Training [5/700]: mean_loss=0.28181271627545357
Online_Training [6/700]: mean_loss=0.1267377082258463
Online_Training [7/700]: mean_loss=0.1420174203813076
Online_Training [8/700]: mean_loss=0.09056398365646601
Online_Training [9/700]: mean_loss=0.26109662279486656
Online_Training [10/700]: mean_loss=0.16425010561943054
Online_Training [11/700]: mean_loss=0.11069129500538111
Online_Training [12/700]: mean_loss=0.08398168813437223
Online_Training [13/700]: mean_loss=0.12335714604705572
Online_Training [14/700]: mean_loss=0.12195328529924154
Online_Training [15/700]: mean_loss=0.10395912360399961
Online_Training [16/700]: mean_loss=0.1340184547007084
Online_Training [17/700]: mean_loss=0.20365087501704693
Online_Training [18/700]: mean_loss=0.1795315258204937
Online_Training [19/700]: mean_loss=0.050306097604334354
Online_Training [20/700]: mean_loss=0.14842702075839043
Online_Training [21/700]: mean_loss=0.12053344305604696
Online_Training [22/700]: mean_loss=0.07152203377336264
Online_Training [23/700]: mean_loss=0.03701980831101537
Online_Training [24/700]: mean_loss=0.08236352447420359
Online_Training [25/700]: mean_loss=0.047254868783056736
Online_Training [26/700]: mean_loss=0.08526788000017405
Online_Training [27/700]: mean_loss=0.08051360491663218
Online_Training [28/700]: mean_loss=0.057416200172156096
Online_Training [29/700]: mean_loss=0.046645456459373236
Online_Training [30/700]: mean_loss=0.03708930313587189
Online_Training [31/700]: mean_loss=0.032359441043809056
Online_Training [32/700]: mean_loss=0.05615419242531061
Online_Training [33/700]: mean_loss=0.03013809327967465
Online_Training [34/700]: mean_loss=0.16178003512322903
Online_Training [35/700]: mean_loss=0.05122646735981107
Online_Training [36/700]: mean_loss=0.06897038128226995
Online_Training [37/700]: mean_loss=0.05313521157950163
Online_Training [38/700]: mean_loss=0.04277496924623847
Online_Training [39/700]: mean_loss=0.09360512997955084
Online_Training [40/700]: mean_loss=0.03030384425073862
Online_Training [41/700]: mean_loss=0.024997169617563486
Online_Training [42/700]: mean_loss=0.049821626394987106
Online_Training [43/700]: mean_loss=0.08539003506302834
Online_Training [44/700]: mean_loss=0.12138242926448584
Online_Training [45/700]: mean_loss=0.07041371613740921
Online_Training [46/700]: mean_loss=0.0446581756696105
Online_Training [47/700]: mean_loss=0.055410766042768955
Online_Training [48/700]: mean_loss=0.07229562010616064
Online_Training [49/700]: mean_loss=0.04316549701616168
Online_Training [50/700]: mean_loss=0.08520821947604418
Online_Training [51/700]: mean_loss=0.030182137619704008
Online_Training [52/700]: mean_loss=0.0866345688700676
Online_Training [53/700]: mean_loss=0.02518357476219535
Online_Training [54/700]: mean_loss=0.04026672337204218
Online_Training [55/700]: mean_loss=0.03291450021788478
Online_Training [56/700]: mean_loss=0.04212210886180401
Online_Training [57/700]: mean_loss=0.07784487633034587
Online_Training [58/700]: mean_loss=0.1649793079122901
Online_Training [59/700]: mean_loss=0.05879538971930742
Online_Training [60/700]: mean_loss=0.0696248565800488
Online_Training [61/700]: mean_loss=0.04146007588133216
Online_Training [62/700]: mean_loss=0.06103228032588959
Online_Training [63/700]: mean_loss=0.04909872217103839
Online_Training [64/700]: mean_loss=0.006237288529518992
Online_Training [65/700]: mean_loss=0.06646272633224726
Online_Training [66/700]: mean_loss=0.0488362773321569
Online_Training [67/700]: mean_loss=0.05059447605162859
Online_Training [68/700]: mean_loss=0.021636996883898973
Online_Training [69/700]: mean_loss=0.04811032069846988
Online_Training [70/700]: mean_loss=0.04522345121949911
Online_Training [71/700]: mean_loss=0.07047873362898827
Online_Training [72/700]: mean_loss=0.09798464272171259
Online_Training [73/700]: mean_loss=0.04399073263630271
Online_Training [74/700]: mean_loss=0.039330795872956514
Online_Training [75/700]: mean_loss=0.024483461631461978
Online_Training [76/700]: mean_loss=0.020012327702715993
Online_Training [77/700]: mean_loss=0.04179317643865943
Online_Training [78/700]: mean_loss=0.019780145026743412
Online_Training [79/700]: mean_loss=0.0521420300938189
Online_Training [80/700]: mean_loss=0.03849610732868314
Online_Training [81/700]: mean_loss=0.01634094340261072
Online_Training [82/700]: mean_loss=0.03179092984646559
Online_Training [83/700]: mean_loss=0.04024841682985425
Online_Training [84/700]: mean_loss=0.03238677536137402
Online_Training [85/700]: mean_loss=0.023846409749239683
Online_Training [86/700]: mean_loss=0.030574244679883122
Online_Training [87/700]: mean_loss=0.021063718479126692
Online_Training [88/700]: mean_loss=0.02318539610132575
Online_Training [89/700]: mean_loss=0.04551489744335413
Online_Training [90/700]: mean_loss=0.0203380286693573
Online_Training [91/700]: mean_loss=0.03562836209312081
Online_Training [92/700]: mean_loss=0.03545178472995758
Online_Training [93/700]: mean_loss=0.024588159751147032
Online_Training [94/700]: mean_loss=0.03563865344040096
Online_Training [95/700]: mean_loss=0.03168870368972421
Online_Training [96/700]: mean_loss=0.023350748931989074
Online_Training [97/700]: mean_loss=0.04414262203499675
Online_Training [98/700]: mean_loss=0.04079589759930968
Online_Training [99/700]: mean_loss=0.024503281340003014
Online_Training [100/700]: mean_loss=0.04094821959733963
Online_Training [101/700]: mean_loss=0.015219204011373222
Online_Training [102/700]: mean_loss=0.0570214344188571
Online_Training [103/700]: mean_loss=0.04656972410157323
Online_Training [104/700]: mean_loss=0.029756381642073393
Online_Training [105/700]: mean_loss=0.042193427216261625
Online_Training [106/700]: mean_loss=0.019378719152882695
Online_Training [107/700]: mean_loss=0.019268721574917436
Online_Training [108/700]: mean_loss=0.02749704639427364
Online_Training [109/700]: mean_loss=0.025520315626636147
Online_Training [110/700]: mean_loss=0.028994035674259067
Online_Training [111/700]: mean_loss=0.02870178106240928
Online_Training [112/700]: mean_loss=0.14895668625831604
Online_Training [113/700]: mean_loss=0.01469844754319638
Online_Training [114/700]: mean_loss=0.032481541857123375
Online_Training [115/700]: mean_loss=0.0334545134101063
Online_Training [116/700]: mean_loss=0.027152605121955276
Online_Training [117/700]: mean_loss=0.0470699411816895
Online_Training [118/700]: mean_loss=0.04320034198462963
Online_Training [119/700]: mean_loss=0.1359043288975954
Online_Training [120/700]: mean_loss=0.05934148235246539
Online_Training [121/700]: mean_loss=0.04854958551004529
Online_Training [122/700]: mean_loss=0.05901931645348668
Online_Training [123/700]: mean_loss=0.03663397976197302
Online_Training [124/700]: mean_loss=0.012343281181529164
Online_Training [125/700]: mean_loss=0.05940313870087266
Online_Training [126/700]: mean_loss=0.05451510241255164
Online_Training [127/700]: mean_loss=0.038048189133405685
Online_Training [128/700]: mean_loss=0.026724214432761073
Online_Training [129/700]: mean_loss=0.03402605513110757
Online_Training [130/700]: mean_loss=0.020628921105526388
Online_Training [131/700]: mean_loss=0.020923926262184978
Online_Training [132/700]: mean_loss=0.01805565704125911
Online_Training [133/700]: mean_loss=0.02482131472788751
Online_Training [134/700]: mean_loss=0.012981765787117183
Online_Training [135/700]: mean_loss=0.1192568950355053
Online_Training [136/700]: mean_loss=0.02391672064550221
Online_Training [137/700]: mean_loss=0.01935595623217523
Online_Training [138/700]: mean_loss=0.01019361219368875
Online_Training [139/700]: mean_loss=0.018499699071981013
Online_Training [140/700]: mean_loss=0.02931331587024033
Online_Training [141/700]: mean_loss=0.03271224210038781
Online_Training [142/700]: mean_loss=0.01219889975618571
Online_Training [143/700]: mean_loss=0.02579158404842019
Online_Training [144/700]: mean_loss=0.010381325613707304
Online_Training [145/700]: mean_loss=0.03340397379361093
Online_Training [146/700]: mean_loss=0.022190534742549062
Online_Training [147/700]: mean_loss=0.016243890509940684
Online_Training [148/700]: mean_loss=0.034538885578513145
Online_Training [149/700]: mean_loss=0.07034455519169569
Online_Training [150/700]: mean_loss=0.054193584714084864
Online_Training [151/700]: mean_loss=0.03792248177342117
Online_Training [152/700]: mean_loss=0.021567945135757327
Online_Training [153/700]: mean_loss=0.024038161616772413
Online_Training [154/700]: mean_loss=0.0199021699372679
Online_Training [155/700]: mean_loss=0.013033031369559467
Online_Training [156/700]: mean_loss=0.017273167381063104
Online_Training [157/700]: mean_loss=0.13752947933971882
Online_Training [158/700]: mean_loss=0.006237066350877285
Online_Training [159/700]: mean_loss=0.02442031679674983
Online_Training [160/700]: mean_loss=0.025780606782063842
Online_Training [161/700]: mean_loss=0.0381019776687026
Online_Training [162/700]: mean_loss=0.022607441060245037
Online_Training [163/700]: mean_loss=0.05348861310631037
Online_Training [164/700]: mean_loss=0.017476399894803762
Online_Training [165/700]: mean_loss=0.010288869147188962
Online_Training [166/700]: mean_loss=0.014843483921140432
Online_Training [167/700]: mean_loss=0.04152662493288517
Online_Training [168/700]: mean_loss=0.03387882141396403
Online_Training [169/700]: mean_loss=0.05520861363038421
Online_Training [170/700]: mean_loss=0.16666849330067635
Online_Training [171/700]: mean_loss=0.022552598966285586
Online_Training [172/700]: mean_loss=0.014105792855843902
Online_Training [173/700]: mean_loss=0.027000057278200984
Online_Training [174/700]: mean_loss=0.012069220189005136
Online_Training [175/700]: mean_loss=0.011304617277346551
Online_Training [176/700]: mean_loss=0.008894247119314969
Online_Training [177/700]: mean_loss=0.020975300576537848
Online_Training [178/700]: mean_loss=0.04009158629924059
Online_Training [179/700]: mean_loss=0.01471330423373729
Online_Training [180/700]: mean_loss=0.01677884324453771
Online_Training [181/700]: mean_loss=0.022703726775944233
Online_Training [182/700]: mean_loss=0.030126595171168447
Online_Training [183/700]: mean_loss=0.013157506589777768
Online_Training [184/700]: mean_loss=0.00653785519534722
Online_Training [185/700]: mean_loss=0.03571099555119872
Online_Training [186/700]: mean_loss=0.03140162071213126
Online_Training [187/700]: mean_loss=0.025345900561660528
Online_Training [188/700]: mean_loss=0.014597721863538027
Online_Training [189/700]: mean_loss=0.04993403051048517
Online_Training [190/700]: mean_loss=0.023264692397788167
Online_Training [191/700]: mean_loss=0.15760493278503418
Online_Training [192/700]: mean_loss=0.024656112305819988
Online_Training [193/700]: mean_loss=0.02326264325529337
Online_Training [194/700]: mean_loss=0.010566807584837079
Online_Training [195/700]: mean_loss=0.030624722596257925
Online_Training [196/700]: mean_loss=0.011045887600630522
Online_Training [197/700]: mean_loss=0.03601212380453944
Online_Training [198/700]: mean_loss=0.01742019969969988
Online_Training [199/700]: mean_loss=0.083767494186759
Online_Training [200/700]: mean_loss=0.02517382544465363
Online_Training [201/700]: mean_loss=0.028633201261982322
Online_Training [202/700]: mean_loss=0.02380517218261957
Online_Training [203/700]: mean_loss=0.011381870368495584
Online_Training [204/700]: mean_loss=0.010277121211402118
Online_Training [205/700]: mean_loss=0.07079900335520506
Online_Training [206/700]: mean_loss=0.014249134925194085
Online_Training [207/700]: mean_loss=0.04915580339729786
Online_Training [208/700]: mean_loss=0.04189488664269447
Online_Training [209/700]: mean_loss=0.05166181642562151
Online_Training [210/700]: mean_loss=0.0302472822368145
Online_Training [211/700]: mean_loss=0.01642005646135658
Online_Training [212/700]: mean_loss=0.09483366552740335
Online_Training [213/700]: mean_loss=0.055941933300346136
Online_Training [214/700]: mean_loss=0.01557536469772458
Online_Training [215/700]: mean_loss=0.03640137054026127
Online_Training [216/700]: mean_loss=0.03705105884000659
Online_Training [217/700]: mean_loss=0.011098696268163621
Online_Training [218/700]: mean_loss=0.0068515416933223605
Online_Training [219/700]: mean_loss=0.04691573791205883
Online_Training [220/700]: mean_loss=0.01729634217917919
Online_Training [221/700]: mean_loss=0.028688120422884822
Online_Training [222/700]: mean_loss=0.016274790512397885
Online_Training [223/700]: mean_loss=0.02987246518023312
Online_Training [224/700]: mean_loss=0.009590288856998086
Online_Training [225/700]: mean_loss=0.027399044251069427
Online_Training [226/700]: mean_loss=0.026569072157144547
Online_Training [227/700]: mean_loss=0.01847743079997599
Online_Training [228/700]: mean_loss=0.03429587138816714
Online_Training [229/700]: mean_loss=0.04442045837640762
Online_Training [230/700]: mean_loss=0.0173898886423558
Online_Training [231/700]: mean_loss=0.02444679825566709
Online_Training [232/700]: mean_loss=0.026386281475424767
Online_Training [233/700]: mean_loss=0.020121250534430146
Online_Training [234/700]: mean_loss=0.03382537071593106
Online_Training [235/700]: mean_loss=0.1043373066931963
Online_Training [236/700]: mean_loss=0.05968645308166742
Online_Training [237/700]: mean_loss=0.022454217774793506
Online_Training [238/700]: mean_loss=0.11051844991743565
Online_Training [239/700]: mean_loss=0.0867303516715765
Online_Training [240/700]: mean_loss=0.03287943219766021
Online_Training [241/700]: mean_loss=0.028239514445886016
Online_Training [242/700]: mean_loss=0.022387734847143292
Online_Training [243/700]: mean_loss=0.0331020881421864
Online_Training [244/700]: mean_loss=0.023376229917630553
Online_Training [245/700]: mean_loss=0.03819497209042311
Online_Training [246/700]: mean_loss=0.02492629666812718
Online_Training [247/700]: mean_loss=0.012128338101319969
Online_Training [248/700]: mean_loss=0.07402694970369339
Online_Training [249/700]: mean_loss=0.007764903421048075
Online_Training [250/700]: mean_loss=0.016775841009803116
Online_Training [251/700]: mean_loss=0.014986753230914474
Online_Training [252/700]: mean_loss=0.02140039694495499
Online_Training [253/700]: mean_loss=0.017805966548621655
Online_Training [254/700]: mean_loss=0.014618627727031708
Online_Training [255/700]: mean_loss=0.03366095619276166
Online_Training [256/700]: mean_loss=0.01444389671087265
Online_Training [257/700]: mean_loss=0.02302888361737132
Online_Training [258/700]: mean_loss=0.018099583918228745
Online_Training [259/700]: mean_loss=0.011622197111137211
Online_Training [260/700]: mean_loss=0.010424767970107496
Online_Training [261/700]: mean_loss=0.026382894720882177
Online_Training [262/700]: mean_loss=0.031039046123623848
Online_Training [263/700]: mean_loss=0.012342537636868656
Online_Training [264/700]: mean_loss=0.017067461740225554
Online_Training [265/700]: mean_loss=0.016287991194985807
Online_Training [266/700]: mean_loss=0.012880412046797574
Online_Training [267/700]: mean_loss=0.024910329608246684
Online_Training [268/700]: mean_loss=0.007705722528044134
Online_Training [269/700]: mean_loss=0.02112756809219718
Online_Training [270/700]: mean_loss=0.011422507930546999
Online_Training [271/700]: mean_loss=0.02463305927813053
Online_Training [272/700]: mean_loss=0.007147611991968006
Online_Training [273/700]: mean_loss=0.013612548587843776
Online_Training [274/700]: mean_loss=0.009959166985936463
Online_Training [275/700]: mean_loss=0.013674020185135305
Online_Training [276/700]: mean_loss=0.014903879025951028
Online_Training [277/700]: mean_loss=0.024726347299292684
Online_Training [278/700]: mean_loss=0.018506172113120556
Online_Training [279/700]: mean_loss=0.015667272149585187
Online_Training [280/700]: mean_loss=0.01753512443974614
Online_Training [281/700]: mean_loss=0.020001975120976567
Online_Training [282/700]: mean_loss=0.026159187080338597
Online_Training [283/700]: mean_loss=0.02311820723116398
Online_Training [284/700]: mean_loss=0.011076572816818953
Online_Training [285/700]: mean_loss=0.014813218847848475
Online_Training [286/700]: mean_loss=0.02301192283630371
Online_Training [287/700]: mean_loss=0.014628458069637418
Online_Training [288/700]: mean_loss=0.013449089950881898
Online_Training [289/700]: mean_loss=0.04393540881574154
Online_Training [290/700]: mean_loss=0.007312764064408839
Online_Training [291/700]: mean_loss=0.013324578176252544
Online_Training [292/700]: mean_loss=0.0070180342881940305
Online_Training [293/700]: mean_loss=0.01243270211853087
Online_Training [294/700]: mean_loss=0.01324344368185848
Online_Training [295/700]: mean_loss=0.03227542480453849
Online_Training [296/700]: mean_loss=0.03604091191664338
Online_Training [297/700]: mean_loss=0.019658496137708426
Online_Training [298/700]: mean_loss=0.010362789500504732
Online_Training [299/700]: mean_loss=0.021715953247621655
Online_Training [300/700]: mean_loss=0.03650828916579485
Online_Training [301/700]: mean_loss=0.01261729677207768
Online_Training [302/700]: mean_loss=0.0208907185588032
Online_Training [303/700]: mean_loss=0.022770484443753958
Online_Training [304/700]: mean_loss=0.014323126175440848
Online_Training [305/700]: mean_loss=0.050476830918341875
Online_Training [306/700]: mean_loss=0.060517902020365
Online_Training [307/700]: mean_loss=0.07094355393201113
Online_Training [308/700]: mean_loss=0.027788482373580337
Online_Training [309/700]: mean_loss=0.01289928937330842
Online_Training [310/700]: mean_loss=0.009218948311172426
Online_Training [311/700]: mean_loss=0.013534420751966536
Online_Training [312/700]: mean_loss=0.04686799272894859
Online_Training [313/700]: mean_loss=0.01775979553349316
Online_Training [314/700]: mean_loss=0.007871798297856003
Online_Training [315/700]: mean_loss=0.006936343677807599
Online_Training [316/700]: mean_loss=0.018933624029159546
Online_Training [317/700]: mean_loss=0.007283623097464442
Online_Training [318/700]: mean_loss=0.0161355200689286
Online_Training [319/700]: mean_loss=0.026014761300757527
Online_Training [320/700]: mean_loss=0.011707133322488517
Online_Training [321/700]: mean_loss=0.017647999804466963
Online_Training [322/700]: mean_loss=0.029652054887264967
Online_Training [323/700]: mean_loss=0.011671813786961138
Online_Training [324/700]: mean_loss=0.0267205317504704
Online_Training [325/700]: mean_loss=0.027467256877571344
Online_Training [326/700]: mean_loss=0.00954522576648742
Online_Training [327/700]: mean_loss=0.023396898061037064
Online_Training [328/700]: mean_loss=0.02118906914256513
Online_Training [329/700]: mean_loss=0.011853093048557639
Online_Training [330/700]: mean_loss=0.027648636139929295
Online_Training [331/700]: mean_loss=0.01890158443711698
Online_Training [332/700]: mean_loss=0.030983110424131155
Online_Training [333/700]: mean_loss=0.011996470973826945
Online_Training [334/700]: mean_loss=0.00648676318814978
Online_Training [335/700]: mean_loss=0.05529050622135401
Online_Training [336/700]: mean_loss=0.062482827343046665
Online_Training [337/700]: mean_loss=0.09725764207541943
Online_Training [338/700]: mean_loss=0.016354791237972677
Online_Training [339/700]: mean_loss=0.015422470401972532
Online_Training [340/700]: mean_loss=0.008787231636233628
Online_Training [341/700]: mean_loss=0.016542644938454032
Online_Training [342/700]: mean_loss=0.045299286022782326
Online_Training [343/700]: mean_loss=0.009664061246439815
Online_Training [344/700]: mean_loss=0.016304900869727135
Online_Training [345/700]: mean_loss=0.029990688897669315
Online_Training [346/700]: mean_loss=0.021328405244275928
Online_Training [347/700]: mean_loss=0.132212795317173
Online_Training [348/700]: mean_loss=0.020559477619826794
Online_Training [349/700]: mean_loss=0.024475343991070986
Online_Training [350/700]: mean_loss=0.010343278991058469
Online_Training [351/700]: mean_loss=0.00738412665668875
Online_Training [352/700]: mean_loss=0.011200743727385998
Online_Training [353/700]: mean_loss=0.017823963658884168
Online_Training [354/700]: mean_loss=0.01883366471156478
Online_Training [355/700]: mean_loss=0.015718739363364875
Online_Training [356/700]: mean_loss=0.012841886840760708
Online_Training [357/700]: mean_loss=0.08668224047869444
Online_Training [358/700]: mean_loss=0.06944621866568923
Online_Training [359/700]: mean_loss=0.09890063107013702
Online_Training [360/700]: mean_loss=0.032352079171687365
Online_Training [361/700]: mean_loss=0.031201813369989395
Online_Training [362/700]: mean_loss=0.030854207929223776
Online_Training [363/700]: mean_loss=0.0117077516624704
Online_Training [364/700]: mean_loss=0.011258928687311709
Online_Training [365/700]: mean_loss=0.016365423565730453
Online_Training [366/700]: mean_loss=0.02497882442548871
Online_Training [367/700]: mean_loss=0.01734180806670338
Online_Training [368/700]: mean_loss=0.012708201538771391
Online_Training [369/700]: mean_loss=0.012932150973938406
Online_Training [370/700]: mean_loss=0.039226656313985586
Online_Training [371/700]: mean_loss=0.007635212503373623
Online_Training [372/700]: mean_loss=0.021536436630412936
Online_Training [373/700]: mean_loss=0.014196971198543906
Online_Training [374/700]: mean_loss=0.01413207093719393
Online_Training [375/700]: mean_loss=0.01884608273394406
Online_Training [376/700]: mean_loss=0.008960705483332276
Online_Training [377/700]: mean_loss=0.01753952424041927
Online_Training [378/700]: mean_loss=0.011414453270845115
Online_Training [379/700]: mean_loss=0.013885247171856463
Online_Training [380/700]: mean_loss=0.013104289886541665
Online_Training [381/700]: mean_loss=0.023604286834597588
Online_Training [382/700]: mean_loss=0.008402277424465865
Online_Training [383/700]: mean_loss=0.00802847178420052
Online_Training [384/700]: mean_loss=0.10420203767716885
Online_Training [385/700]: mean_loss=0.009449714212678373
Online_Training [386/700]: mean_loss=0.024246714310720563
Online_Training [387/700]: mean_loss=0.019016737584024668
Online_Training [388/700]: mean_loss=0.02099513611756265
Online_Training [389/700]: mean_loss=0.006373694399371743
Online_Training [390/700]: mean_loss=0.018956626299768686
Online_Training [391/700]: mean_loss=0.010526543017476797
Online_Training [392/700]: mean_loss=0.015622625476680696
Online_Training [393/700]: mean_loss=0.019221711670979857
Online_Training [394/700]: mean_loss=0.02389541524462402
Online_Training [395/700]: mean_loss=0.00912292452994734
Online_Training [396/700]: mean_loss=0.020010314416140318
Online_Training [397/700]: mean_loss=0.011828167247585952
Online_Training [398/700]: mean_loss=0.018784000305458903
Online_Training [399/700]: mean_loss=0.0198591947555542
Online_Training [400/700]: mean_loss=0.024518030462786555
Online_Training [401/700]: mean_loss=0.016318449866957963
Online_Training [402/700]: mean_loss=0.012780249118804932
Online_Training [403/700]: mean_loss=0.01866493606939912
Online_Training [404/700]: mean_loss=0.04609787603840232
Online_Training [405/700]: mean_loss=0.06592234270647168
Online_Training [406/700]: mean_loss=0.02081820578314364
Online_Training [407/700]: mean_loss=0.028651376022025943
Online_Training [408/700]: mean_loss=0.015676212846301496
Online_Training [409/700]: mean_loss=0.006379684724379331
Online_Training [410/700]: mean_loss=0.01951608550734818
Online_Training [411/700]: mean_loss=0.01807098090648651
Online_Training [412/700]: mean_loss=0.10753991734236479
Online_Training [413/700]: mean_loss=0.0443012872710824
Online_Training [414/700]: mean_loss=0.032101468881592155
Online_Training [415/700]: mean_loss=0.02472928143106401
Online_Training [416/700]: mean_loss=0.013758941902779043
Online_Training [417/700]: mean_loss=0.0582315600477159
Online_Training [418/700]: mean_loss=0.013373382156714797
Online_Training [419/700]: mean_loss=0.009462360641919076
Online_Training [420/700]: mean_loss=0.050954552832990885
Online_Training [421/700]: mean_loss=0.03543332125991583
Online_Training [422/700]: mean_loss=0.017903883010149002
Online_Training [423/700]: mean_loss=0.03655801247805357
Online_Training [424/700]: mean_loss=0.04998387489467859
Online_Training [425/700]: mean_loss=0.02059062896296382
Online_Training [426/700]: mean_loss=0.009492673154454678
Online_Training [427/700]: mean_loss=0.012529511121101677
Online_Training [428/700]: mean_loss=0.03006321331486106
Online_Training [429/700]: mean_loss=0.01285638299304992
Online_Training [430/700]: mean_loss=0.006140772893559188
Online_Training [431/700]: mean_loss=0.013350260793231428
Online_Training [432/700]: mean_loss=0.077604821883142
Online_Training [433/700]: mean_loss=0.016657391213811934
Online_Training [434/700]: mean_loss=0.015085257706232369
Online_Training [435/700]: mean_loss=0.010045976960100234
Online_Training [436/700]: mean_loss=0.05702749406918883
Online_Training [437/700]: mean_loss=0.01301601727027446
Online_Training [438/700]: mean_loss=0.09889842104166746
Online_Training [439/700]: mean_loss=0.05381734576076269
Online_Training [440/700]: mean_loss=0.03237705584615469
Online_Training [441/700]: mean_loss=0.03162925969809294
Online_Training [442/700]: mean_loss=0.013015649397857487
Online_Training [443/700]: mean_loss=0.01877710036933422
Online_Training [444/700]: mean_loss=0.009652469540014863
Online_Training [445/700]: mean_loss=0.020608884748071432
Online_Training [446/700]: mean_loss=0.02441518590785563
Online_Training [447/700]: mean_loss=0.010756885400041938
Online_Training [448/700]: mean_loss=0.024854021845385432
Online_Training [449/700]: mean_loss=0.021667846711352468
Online_Training [450/700]: mean_loss=0.02410027151927352
Online_Training [451/700]: mean_loss=0.022932002553716302
Online_Training [452/700]: mean_loss=0.037496909499168396
Online_Training [453/700]: mean_loss=0.06144142942503095
Online_Training [454/700]: mean_loss=0.01962047629058361
Online_Training [455/700]: mean_loss=0.024824457010254264
Online_Training [456/700]: mean_loss=0.006063402979634702
Online_Training [457/700]: mean_loss=0.017063396750018
Online_Training [458/700]: mean_loss=0.009103122167289257
Online_Training [459/700]: mean_loss=0.010038381558842957
Online_Training [460/700]: mean_loss=0.027948378585278988
Online_Training [461/700]: mean_loss=0.026549767004325986
Online_Training [462/700]: mean_loss=0.00781903212191537
Online_Training [463/700]: mean_loss=0.00813069916330278
Online_Training [464/700]: mean_loss=0.013455525739118457
Online_Training [465/700]: mean_loss=0.0633254973217845
Online_Training [466/700]: mean_loss=0.024847080931067467
Online_Training [467/700]: mean_loss=0.026320528704673052
Online_Training [468/700]: mean_loss=0.01239268493372947
Online_Training [469/700]: mean_loss=0.014086020761169493
Online_Training [470/700]: mean_loss=0.03665589680895209
Online_Training [471/700]: mean_loss=0.020306245423853397
Online_Training [472/700]: mean_loss=0.031801345059648156
Online_Training [473/700]: mean_loss=0.004864241054747254
Online_Training [474/700]: mean_loss=0.014148730086162686
Online_Training [475/700]: mean_loss=0.01261660095769912
Online_Training [476/700]: mean_loss=0.21027216129004955
Online_Training [477/700]: mean_loss=0.08812079299241304
Online_Training [478/700]: mean_loss=0.041969758458435535
Online_Training [479/700]: mean_loss=0.011351566528901458
Online_Training [480/700]: mean_loss=0.007655664812773466
Online_Training [481/700]: mean_loss=0.014009932172484696
Online_Training [482/700]: mean_loss=0.02237138827331364
Online_Training [483/700]: mean_loss=0.014895917498506606
Online_Training [484/700]: mean_loss=0.012354565318673849
Online_Training [485/700]: mean_loss=0.006082499981857836
Online_Training [486/700]: mean_loss=0.011118436115793884
Online_Training [487/700]: mean_loss=0.030323658604174852
Online_Training [488/700]: mean_loss=0.017212954349815845
Online_Training [489/700]: mean_loss=0.012851638603024185
Online_Training [490/700]: mean_loss=0.024740245658904314
Online_Training [491/700]: mean_loss=0.030954379122704268
Online_Training [492/700]: mean_loss=0.012262159027159214
Online_Training [493/700]: mean_loss=0.015606275293976068
Online_Training [494/700]: mean_loss=0.05892695765942335
Online_Training [495/700]: mean_loss=0.00740028714062646
Online_Training [496/700]: mean_loss=0.02350578084588051
Online_Training [497/700]: mean_loss=0.015552724013105035
Online_Training [498/700]: mean_loss=0.012882110080681741
Online_Training [499/700]: mean_loss=0.013474213308654726
Online_Training [500/700]: mean_loss=0.009444444789551198
Online_Training [501/700]: mean_loss=0.01014575397130102
Online_Training [502/700]: mean_loss=0.012765061110258102
Online_Training [503/700]: mean_loss=0.018979156855493784
Online_Training [504/700]: mean_loss=0.008402293839026242
Online_Training [505/700]: mean_loss=0.010330959339626133
Online_Training [506/700]: mean_loss=0.11558339279145002
Online_Training [507/700]: mean_loss=0.12141106463968754
Online_Training [508/700]: mean_loss=0.02373435371555388
Online_Training [509/700]: mean_loss=0.015443563926964998
Online_Training [510/700]: mean_loss=0.026823902735486627
Online_Training [511/700]: mean_loss=0.005667001998517662
Online_Training [512/700]: mean_loss=0.00774129101773724
Online_Training [513/700]: mean_loss=0.03429179289378226
Online_Training [514/700]: mean_loss=0.032802869798615575
Online_Training [515/700]: mean_loss=0.02784931706264615
Online_Training [516/700]: mean_loss=0.02068677614443004
Online_Training [517/700]: mean_loss=0.033329325495287776
Online_Training [518/700]: mean_loss=0.015098414616659284
Online_Training [519/700]: mean_loss=0.008328349678777158
Online_Training [520/700]: mean_loss=0.010455326875671744
Online_Training [521/700]: mean_loss=0.030146859702654183
Online_Training [522/700]: mean_loss=0.010930895572528243
Online_Training [523/700]: mean_loss=0.021538325119763613
Online_Training [524/700]: mean_loss=0.0864907456561923
Online_Training [525/700]: mean_loss=0.02329853270202875
Online_Training [526/700]: mean_loss=0.011394944740459323
Online_Training [527/700]: mean_loss=0.01794482348486781
Online_Training [528/700]: mean_loss=0.028646019287407398
Online_Training [529/700]: mean_loss=0.022618040442466736
Online_Training [530/700]: mean_loss=0.021651471499353647
Online_Training [531/700]: mean_loss=0.010152223403565586
Online_Training [532/700]: mean_loss=0.02541101910173893
Online_Training [533/700]: mean_loss=0.01564648374915123
Online_Training [534/700]: mean_loss=0.014271023101173341
Online_Training [535/700]: mean_loss=0.025113411946222186
Online_Training [536/700]: mean_loss=0.11095090862363577
Online_Training [537/700]: mean_loss=0.010598610853776336
Online_Training [538/700]: mean_loss=0.01834374468307942
Online_Training [539/700]: mean_loss=0.005534299183636904
Online_Training [540/700]: mean_loss=0.04491082951426506
Online_Training [541/700]: mean_loss=0.11633974779397249
Online_Training [542/700]: mean_loss=0.009754867060109973
Online_Training [543/700]: mean_loss=0.028396664885804057
Online_Training [544/700]: mean_loss=0.009208975359797478
Online_Training [545/700]: mean_loss=0.02567664021626115
Online_Training [546/700]: mean_loss=0.009106838144361973
Online_Training [547/700]: mean_loss=0.019573662662878633
Online_Training [548/700]: mean_loss=0.016561037627980113
Online_Training [549/700]: mean_loss=0.005319500400219113
Online_Training [550/700]: mean_loss=0.01791377435438335
Online_Training [551/700]: mean_loss=0.018256634939461946
Online_Training [552/700]: mean_loss=0.01744676544331014
Online_Training [553/700]: mean_loss=0.03521961928345263
Online_Training [554/700]: mean_loss=0.012422590050846338
Online_Training [555/700]: mean_loss=0.029256121488288045
Online_Training [556/700]: mean_loss=0.015530010685324669
Online_Training [557/700]: mean_loss=0.022429341450333595
Online_Training [558/700]: mean_loss=0.007572010683361441
Online_Training [559/700]: mean_loss=0.001553754394990392
Online_Training [560/700]: mean_loss=0.006805537093896419
Online_Training [561/700]: mean_loss=0.018505137879401445
Online_Training [562/700]: mean_loss=0.036687578074634075
Online_Training [563/700]: mean_loss=0.032613893039524555
Online_Training [564/700]: mean_loss=0.01261278463061899
Online_Training [565/700]: mean_loss=0.027870744233950973
Online_Training [566/700]: mean_loss=0.015940581215545535
Online_Training [567/700]: mean_loss=0.019461171701550484
Online_Training [568/700]: mean_loss=0.017732809064909816
Online_Training [569/700]: mean_loss=0.024877339834347367
Online_Training [570/700]: mean_loss=0.012210657587274909
Online_Training [571/700]: mean_loss=0.009373903507366776
Online_Training [572/700]: mean_loss=0.017115712631493807
Online_Training [573/700]: mean_loss=0.022237788187339902
Online_Training [574/700]: mean_loss=0.03686985420063138
Online_Training [575/700]: mean_loss=0.04255983978509903
Online_Training [576/700]: mean_loss=0.008241749717853963
Online_Training [577/700]: mean_loss=0.014011691091582179
Online_Training [578/700]: mean_loss=0.007508677197620273
Online_Training [579/700]: mean_loss=0.01446194713935256
Online_Training [580/700]: mean_loss=0.026866848580539227
Online_Training [581/700]: mean_loss=0.011418604874052107
Online_Training [582/700]: mean_loss=0.006703126709908247
Online_Training [583/700]: mean_loss=0.004085593012860045
Online_Training [584/700]: mean_loss=0.012417746125720441
Online_Training [585/700]: mean_loss=0.017920121550559998
Online_Training [586/700]: mean_loss=0.10532435216009617
Online_Training [587/700]: mean_loss=0.024723635520786047
Online_Training [588/700]: mean_loss=0.009199766791425645
Online_Training [589/700]: mean_loss=0.023115471238270402
Online_Training [590/700]: mean_loss=0.028190811863169074
Online_Training [591/700]: mean_loss=0.014591277576982975
Online_Training [592/700]: mean_loss=0.0128916249377653
Online_Training [593/700]: mean_loss=0.047684415709227324
Online_Training [594/700]: mean_loss=0.009855285985395312
Online_Training [595/700]: mean_loss=0.032730895560234785
Online_Training [596/700]: mean_loss=0.009813406853936613
Online_Training [597/700]: mean_loss=0.009355097310617566
Online_Training [598/700]: mean_loss=0.014866411336697638
Online_Training [599/700]: mean_loss=0.02056742529384792
Online_Training [600/700]: mean_loss=0.012477154727093875
Online_Training [601/700]: mean_loss=0.029459082521498203
Online_Training [602/700]: mean_loss=0.00754945760127157
Online_Training [603/700]: mean_loss=0.007548936933744699
Online_Training [604/700]: mean_loss=0.020273610949516296
Online_Training [605/700]: mean_loss=0.010173172107897699
Online_Training [606/700]: mean_loss=0.009432929975446314
Online_Training [607/700]: mean_loss=0.007993901206646115
Online_Training [608/700]: mean_loss=0.012658221181482077
Online_Training [609/700]: mean_loss=0.012781381141394377
Online_Training [610/700]: mean_loss=0.01971095777116716
Online_Training [611/700]: mean_loss=0.009350908803753555
Online_Training [612/700]: mean_loss=0.14597134478390217
Online_Training [613/700]: mean_loss=0.04209920018911362
Online_Training [614/700]: mean_loss=0.008563120441976935
Online_Training [615/700]: mean_loss=0.00984120147768408
Online_Training [616/700]: mean_loss=0.012863474199548364
Online_Training [617/700]: mean_loss=0.0034607093257363886
Online_Training [618/700]: mean_loss=0.018152614473365247
Online_Training [619/700]: mean_loss=0.008685264503583312
Online_Training [620/700]: mean_loss=0.06332350056618452
Online_Training [621/700]: mean_loss=0.009512931923381984
Online_Training [622/700]: mean_loss=0.042278717271983624
Online_Training [623/700]: mean_loss=0.029276923974975944
Online_Training [624/700]: mean_loss=0.011398273636586964
Online_Training [625/700]: mean_loss=0.010808202321641147
Online_Training [626/700]: mean_loss=0.01168562297243625
Online_Training [627/700]: mean_loss=0.008167356834746897
Online_Training [628/700]: mean_loss=0.011532050557434559
Online_Training [629/700]: mean_loss=0.012881228933110833
Online_Training [630/700]: mean_loss=0.043299905490130186
Online_Training [631/700]: mean_loss=0.014154802658595145
Online_Training [632/700]: mean_loss=0.030317708617076278
Online_Training [633/700]: mean_loss=0.010674485005438328
Online_Training [634/700]: mean_loss=0.014403288019821048
Online_Training [635/700]: mean_loss=0.019426417886279523
Online_Training [636/700]: mean_loss=0.005453980702441186
Online_Training [637/700]: mean_loss=0.009240818326361477
Online_Training [638/700]: mean_loss=0.014799512573517859
Online_Training [639/700]: mean_loss=0.019160037860274315
Online_Training [640/700]: mean_loss=0.006730087450705469
Online_Training [641/700]: mean_loss=0.014624640229158103
Online_Training [642/700]: mean_loss=0.012544952449388802
Online_Training [643/700]: mean_loss=0.0061232849839143455
Online_Training [644/700]: mean_loss=0.0042444786231499165
Online_Training [645/700]: mean_loss=0.013012073002755642
Online_Training [646/700]: mean_loss=0.0242650443688035
Online_Training [647/700]: mean_loss=0.010824970086105168
Online_Training [648/700]: mean_loss=0.011149121914058924
Online_Training [649/700]: mean_loss=0.01077932899352163
Online_Training [650/700]: mean_loss=0.012366563198156655
Online_Training [651/700]: mean_loss=0.008760326076298952
Online_Training [652/700]: mean_loss=0.004431019799085334
Online_Training [653/700]: mean_loss=0.09838555008172989
Online_Training [654/700]: mean_loss=0.01204049086663872
Online_Training [655/700]: mean_loss=0.01639915956184268
Online_Training [656/700]: mean_loss=0.01939344103448093
Online_Training [657/700]: mean_loss=0.025920618092641234
Online_Training [658/700]: mean_loss=0.012453712755814195
Online_Training [659/700]: mean_loss=0.01197527430485934
Online_Training [660/700]: mean_loss=0.013811616692692041
Online_Training [661/700]: mean_loss=0.044848496560007334
Online_Training [662/700]: mean_loss=0.05297624692320824
Online_Training [663/700]: mean_loss=0.021305682137608528
Online_Training [664/700]: mean_loss=0.00940359861124307
Online_Training [665/700]: mean_loss=0.04652773402631283
Online_Training [666/700]: mean_loss=0.0161020050290972
Online_Training [667/700]: mean_loss=0.009992856706958264
Online_Training [668/700]: mean_loss=0.010522960685193539
Online_Training [669/700]: mean_loss=0.007303681049961597
Online_Training [670/700]: mean_loss=0.0111142888199538
Online_Training [671/700]: mean_loss=0.010001268237829208
Online_Training [672/700]: mean_loss=0.00998934474773705
Online_Training [673/700]: mean_loss=0.011206776252947748
Online_Training [674/700]: mean_loss=0.005337803973816335
Online_Training [675/700]: mean_loss=0.008694885356817394
Online_Training [676/700]: mean_loss=0.025262416573241353
Online_Training [677/700]: mean_loss=0.031875719083473086
Online_Training [678/700]: mean_loss=0.020046270918101072
Online_Training [679/700]: mean_loss=0.011979606468230486
Online_Training [680/700]: mean_loss=0.00693131797015667
Online_Training [681/700]: mean_loss=0.020492859766818583
Online_Training [682/700]: mean_loss=0.012527992948889732
Online_Training [683/700]: mean_loss=0.007036758528556675
Online_Training [684/700]: mean_loss=0.008212912711314857
Online_Training [685/700]: mean_loss=0.02903410652652383
Online_Training [686/700]: mean_loss=0.013181421905755997
Online_Training [687/700]: mean_loss=0.013227628660388291
Online_Training [688/700]: mean_loss=0.05842613708227873
Online_Training [689/700]: mean_loss=0.012688816408626735
Online_Training [690/700]: mean_loss=0.005687353608664125
Online_Training [691/700]: mean_loss=0.01993110461626202
Online_Training [692/700]: mean_loss=0.023964018560945988
Online_Training [693/700]: mean_loss=0.013182870927266777
Online_Training [694/700]: mean_loss=0.03329627215862274
Online_Training [695/700]: mean_loss=0.008577830682042986
Online_Training [696/700]: mean_loss=0.04469387559220195
Online_Training [697/700]: mean_loss=0.006863650283776224
Online_Training [698/700]: mean_loss=0.005698483204469085
Online_Training [699/700]: mean_loss=0.05816935608163476
Online_Training [700/700]: mean_loss=0.004453627509064972
Q_Learning [1/300]: mean_loss=0.21446209587156773
Q_Learning [2/300]: mean_loss=0.2656676210463047
Q_Learning [3/300]: mean_loss=0.22124778293073177
Q_Learning [4/300]: mean_loss=0.07900287117809057
Q_Learning [5/300]: mean_loss=0.28181271627545357
Q_Learning [6/300]: mean_loss=0.1267377082258463
Q_Learning [7/300]: mean_loss=0.1420174203813076
Q_Learning [8/300]: mean_loss=0.09056398365646601
Q_Learning [9/300]: mean_loss=0.26109662279486656
Q_Learning [10/300]: mean_loss=0.16425010561943054
Q_Learning [11/300]: mean_loss=0.11069129500538111
Q_Learning [12/300]: mean_loss=0.08398168813437223
Q_Learning [13/300]: mean_loss=0.12335714604705572
Q_Learning [14/300]: mean_loss=0.12195328529924154
Q_Learning [15/300]: mean_loss=0.10395912360399961
Q_Learning [16/300]: mean_loss=0.1340184547007084
Q_Learning [17/300]: mean_loss=0.20365087501704693
Q_Learning [18/300]: mean_loss=0.1795315258204937
Q_Learning [19/300]: mean_loss=0.050306097604334354
Q_Learning [20/300]: mean_loss=0.14842702075839043
Q_Learning [21/300]: mean_loss=0.12053344305604696
Q_Learning [22/300]: mean_loss=0.07152203377336264
Q_Learning [23/300]: mean_loss=0.03701980831101537
Q_Learning [24/300]: mean_loss=0.08236352447420359
Q_Learning [25/300]: mean_loss=0.047254868783056736
Q_Learning [26/300]: mean_loss=0.08526788000017405
Q_Learning [27/300]: mean_loss=0.08051360491663218
Q_Learning [28/300]: mean_loss=0.057416200172156096
Q_Learning [29/300]: mean_loss=0.046645456459373236
Q_Learning [30/300]: mean_loss=0.03708930313587189
Q_Learning [31/300]: mean_loss=0.032359441043809056
Q_Learning [32/300]: mean_loss=0.05615419242531061
Q_Learning [33/300]: mean_loss=0.03013809327967465
Q_Learning [34/300]: mean_loss=0.16178003512322903
Q_Learning [35/300]: mean_loss=0.05122646735981107
Q_Learning [36/300]: mean_loss=0.06897038128226995
Q_Learning [37/300]: mean_loss=0.05313521157950163
Q_Learning [38/300]: mean_loss=0.04277496924623847
Q_Learning [39/300]: mean_loss=0.09360512997955084
Q_Learning [40/300]: mean_loss=0.03030384425073862
Q_Learning [41/300]: mean_loss=0.024997169617563486
Q_Learning [42/300]: mean_loss=0.049821626394987106
Q_Learning [43/300]: mean_loss=0.08539003506302834
Q_Learning [44/300]: mean_loss=0.12138242926448584
Q_Learning [45/300]: mean_loss=0.07041371613740921
Q_Learning [46/300]: mean_loss=0.0446581756696105
Q_Learning [47/300]: mean_loss=0.055410766042768955
Q_Learning [48/300]: mean_loss=0.07229562010616064
Q_Learning [49/300]: mean_loss=0.04316549701616168
Q_Learning [50/300]: mean_loss=0.08520821947604418
Q_Learning [51/300]: mean_loss=0.030182137619704008
Q_Learning [52/300]: mean_loss=0.0866345688700676
Q_Learning [53/300]: mean_loss=0.02518357476219535
Q_Learning [54/300]: mean_loss=0.04026672337204218
Q_Learning [55/300]: mean_loss=0.03291450021788478
Q_Learning [56/300]: mean_loss=0.04212210886180401
Q_Learning [57/300]: mean_loss=0.07784487633034587
Q_Learning [58/300]: mean_loss=0.1649793079122901
Q_Learning [59/300]: mean_loss=0.05879538971930742
Q_Learning [60/300]: mean_loss=0.0696248565800488
Q_Learning [61/300]: mean_loss=0.04146007588133216
Q_Learning [62/300]: mean_loss=0.06103228032588959
Q_Learning [63/300]: mean_loss=0.04909872217103839
Q_Learning [64/300]: mean_loss=0.006237288529518992
Q_Learning [65/300]: mean_loss=0.06646272633224726
Q_Learning [66/300]: mean_loss=0.0488362773321569
Q_Learning [67/300]: mean_loss=0.05059447605162859
Q_Learning [68/300]: mean_loss=0.021636996883898973
Q_Learning [69/300]: mean_loss=0.04811032069846988
Q_Learning [70/300]: mean_loss=0.04522345121949911
Q_Learning [71/300]: mean_loss=0.07047873362898827
Q_Learning [72/300]: mean_loss=0.09798464272171259
Q_Learning [73/300]: mean_loss=0.04399073263630271
Q_Learning [74/300]: mean_loss=0.039330795872956514
Q_Learning [75/300]: mean_loss=0.024483461631461978
Q_Learning [76/300]: mean_loss=0.020012327702715993
Q_Learning [77/300]: mean_loss=0.04179317643865943
Q_Learning [78/300]: mean_loss=0.019780145026743412
Q_Learning [79/300]: mean_loss=0.0521420300938189
Q_Learning [80/300]: mean_loss=0.03849610732868314
Q_Learning [81/300]: mean_loss=0.01634094340261072
Q_Learning [82/300]: mean_loss=0.03179092984646559
Q_Learning [83/300]: mean_loss=0.04024841682985425
Q_Learning [84/300]: mean_loss=0.03238677536137402
Q_Learning [85/300]: mean_loss=0.023846409749239683
Q_Learning [86/300]: mean_loss=0.030574244679883122
Q_Learning [87/300]: mean_loss=0.021063718479126692
Q_Learning [88/300]: mean_loss=0.02318539610132575
Q_Learning [89/300]: mean_loss=0.04551489744335413
Q_Learning [90/300]: mean_loss=0.0203380286693573
Q_Learning [91/300]: mean_loss=0.03562836209312081
Q_Learning [92/300]: mean_loss=0.03545178472995758
Q_Learning [93/300]: mean_loss=0.024588159751147032
Q_Learning [94/300]: mean_loss=0.03563865344040096
Q_Learning [95/300]: mean_loss=0.03168870368972421
Q_Learning [96/300]: mean_loss=0.023350748931989074
Q_Learning [97/300]: mean_loss=0.04414262203499675
Q_Learning [98/300]: mean_loss=0.04079589759930968
Q_Learning [99/300]: mean_loss=0.024503281340003014
Q_Learning [100/300]: mean_loss=0.04094821959733963
Q_Learning [101/300]: mean_loss=0.015219204011373222
Q_Learning [102/300]: mean_loss=0.0570214344188571
Q_Learning [103/300]: mean_loss=0.04656972410157323
Q_Learning [104/300]: mean_loss=0.029756381642073393
Q_Learning [105/300]: mean_loss=0.042193427216261625
Q_Learning [106/300]: mean_loss=0.019378719152882695
Q_Learning [107/300]: mean_loss=0.019268721574917436
Q_Learning [108/300]: mean_loss=0.02749704639427364
Q_Learning [109/300]: mean_loss=0.025520315626636147
Q_Learning [110/300]: mean_loss=0.028994035674259067
Q_Learning [111/300]: mean_loss=0.02870178106240928
Q_Learning [112/300]: mean_loss=0.14895668625831604
Q_Learning [113/300]: mean_loss=0.01469844754319638
Q_Learning [114/300]: mean_loss=0.032481541857123375
Q_Learning [115/300]: mean_loss=0.0334545134101063
Q_Learning [116/300]: mean_loss=0.027152605121955276
Q_Learning [117/300]: mean_loss=0.0470699411816895
Q_Learning [118/300]: mean_loss=0.04320034198462963
Q_Learning [119/300]: mean_loss=0.1359043288975954
Q_Learning [120/300]: mean_loss=0.05934148235246539
Q_Learning [121/300]: mean_loss=0.04854958551004529
Q_Learning [122/300]: mean_loss=0.05901931645348668
Q_Learning [123/300]: mean_loss=0.03663397976197302
Q_Learning [124/300]: mean_loss=0.012343281181529164
Q_Learning [125/300]: mean_loss=0.05940313870087266
Q_Learning [126/300]: mean_loss=0.05451510241255164
Q_Learning [127/300]: mean_loss=0.038048189133405685
Q_Learning [128/300]: mean_loss=0.026724214432761073
Q_Learning [129/300]: mean_loss=0.03402605513110757
Q_Learning [130/300]: mean_loss=0.020628921105526388
Q_Learning [131/300]: mean_loss=0.020923926262184978
Q_Learning [132/300]: mean_loss=0.01805565704125911
Q_Learning [133/300]: mean_loss=0.02482131472788751
Q_Learning [134/300]: mean_loss=0.012981765787117183
Q_Learning [135/300]: mean_loss=0.1192568950355053
Q_Learning [136/300]: mean_loss=0.02391672064550221
Q_Learning [137/300]: mean_loss=0.01935595623217523
Q_Learning [138/300]: mean_loss=0.01019361219368875
Q_Learning [139/300]: mean_loss=0.018499699071981013
Q_Learning [140/300]: mean_loss=0.02931331587024033
Q_Learning [141/300]: mean_loss=0.03271224210038781
Q_Learning [142/300]: mean_loss=0.01219889975618571
Q_Learning [143/300]: mean_loss=0.02579158404842019
Q_Learning [144/300]: mean_loss=0.010381325613707304
Q_Learning [145/300]: mean_loss=0.03340397379361093
Q_Learning [146/300]: mean_loss=0.022190534742549062
Q_Learning [147/300]: mean_loss=0.016243890509940684
Q_Learning [148/300]: mean_loss=0.034538885578513145
Q_Learning [149/300]: mean_loss=0.07034455519169569
Q_Learning [150/300]: mean_loss=0.054193584714084864
Q_Learning [151/300]: mean_loss=0.03792248177342117
Q_Learning [152/300]: mean_loss=0.021567945135757327
Q_Learning [153/300]: mean_loss=0.024038161616772413
Q_Learning [154/300]: mean_loss=0.0199021699372679
Q_Learning [155/300]: mean_loss=0.013033031369559467
Q_Learning [156/300]: mean_loss=0.017273167381063104
Q_Learning [157/300]: mean_loss=0.13752947933971882
Q_Learning [158/300]: mean_loss=0.006237066350877285
Q_Learning [159/300]: mean_loss=0.02442031679674983
Q_Learning [160/300]: mean_loss=0.025780606782063842
Q_Learning [161/300]: mean_loss=0.0381019776687026
Q_Learning [162/300]: mean_loss=0.022607441060245037
Q_Learning [163/300]: mean_loss=0.05348861310631037
Q_Learning [164/300]: mean_loss=0.017476399894803762
Q_Learning [165/300]: mean_loss=0.010288869147188962
Q_Learning [166/300]: mean_loss=0.014843483921140432
Q_Learning [167/300]: mean_loss=0.04152662493288517
Q_Learning [168/300]: mean_loss=0.03387882141396403
Q_Learning [169/300]: mean_loss=0.05520861363038421
Q_Learning [170/300]: mean_loss=0.16666849330067635
Q_Learning [171/300]: mean_loss=0.022552598966285586
Q_Learning [172/300]: mean_loss=0.014105792855843902
Q_Learning [173/300]: mean_loss=0.027000057278200984
Q_Learning [174/300]: mean_loss=0.012069220189005136
Q_Learning [175/300]: mean_loss=0.011304617277346551
Q_Learning [176/300]: mean_loss=0.008894247119314969
Q_Learning [177/300]: mean_loss=0.020975300576537848
Q_Learning [178/300]: mean_loss=0.04009158629924059
Q_Learning [179/300]: mean_loss=0.01471330423373729
Q_Learning [180/300]: mean_loss=0.01677884324453771
Q_Learning [181/300]: mean_loss=0.022703726775944233
Q_Learning [182/300]: mean_loss=0.030126595171168447
Q_Learning [183/300]: mean_loss=0.013157506589777768
Q_Learning [184/300]: mean_loss=0.00653785519534722
Q_Learning [185/300]: mean_loss=0.03571099555119872
Q_Learning [186/300]: mean_loss=0.03140162071213126
Q_Learning [187/300]: mean_loss=0.025345900561660528
Q_Learning [188/300]: mean_loss=0.014597721863538027
Q_Learning [189/300]: mean_loss=0.04993403051048517
Q_Learning [190/300]: mean_loss=0.023264692397788167
Q_Learning [191/300]: mean_loss=0.15760493278503418
Q_Learning [192/300]: mean_loss=0.024656112305819988
Q_Learning [193/300]: mean_loss=0.02326264325529337
Q_Learning [194/300]: mean_loss=0.010566807584837079
Q_Learning [195/300]: mean_loss=0.030624722596257925
Q_Learning [196/300]: mean_loss=0.011045887600630522
Q_Learning [197/300]: mean_loss=0.03601212380453944
Q_Learning [198/300]: mean_loss=0.01742019969969988
Q_Learning [199/300]: mean_loss=0.083767494186759
Q_Learning [200/300]: mean_loss=0.02517382544465363
Q_Learning [201/300]: mean_loss=0.028633201261982322
Q_Learning [202/300]: mean_loss=0.02380517218261957
Q_Learning [203/300]: mean_loss=0.011381870368495584
Q_Learning [204/300]: mean_loss=0.010277121211402118
Q_Learning [205/300]: mean_loss=0.07079900335520506
Q_Learning [206/300]: mean_loss=0.014249134925194085
Q_Learning [207/300]: mean_loss=0.04915580339729786
Q_Learning [208/300]: mean_loss=0.04189488664269447
Q_Learning [209/300]: mean_loss=0.05166181642562151
Q_Learning [210/300]: mean_loss=0.0302472822368145
Q_Learning [211/300]: mean_loss=0.01642005646135658
Q_Learning [212/300]: mean_loss=0.09483366552740335
Q_Learning [213/300]: mean_loss=0.055941933300346136
Q_Learning [214/300]: mean_loss=0.01557536469772458
Q_Learning [215/300]: mean_loss=0.03640137054026127
Q_Learning [216/300]: mean_loss=0.03705105884000659
Q_Learning [217/300]: mean_loss=0.011098696268163621
Q_Learning [218/300]: mean_loss=0.0068515416933223605
Q_Learning [219/300]: mean_loss=0.04691573791205883
Q_Learning [220/300]: mean_loss=0.01729634217917919
Q_Learning [221/300]: mean_loss=0.028688120422884822
Q_Learning [222/300]: mean_loss=0.016274790512397885
Q_Learning [223/300]: mean_loss=0.02987246518023312
Q_Learning [224/300]: mean_loss=0.009590288856998086
Q_Learning [225/300]: mean_loss=0.027399044251069427
Q_Learning [226/300]: mean_loss=0.026569072157144547
Q_Learning [227/300]: mean_loss=0.01847743079997599
Q_Learning [228/300]: mean_loss=0.03429587138816714
Q_Learning [229/300]: mean_loss=0.04442045837640762
Q_Learning [230/300]: mean_loss=0.0173898886423558
Q_Learning [231/300]: mean_loss=0.02444679825566709
Q_Learning [232/300]: mean_loss=0.026386281475424767
Q_Learning [233/300]: mean_loss=0.020121250534430146
Q_Learning [234/300]: mean_loss=0.03382537071593106
Q_Learning [235/300]: mean_loss=0.1043373066931963
Q_Learning [236/300]: mean_loss=0.05968645308166742
Q_Learning [237/300]: mean_loss=0.022454217774793506
Q_Learning [238/300]: mean_loss=0.11051844991743565
Q_Learning [239/300]: mean_loss=0.0867303516715765
Q_Learning [240/300]: mean_loss=0.03287943219766021
Q_Learning [241/300]: mean_loss=0.028239514445886016
Q_Learning [242/300]: mean_loss=0.022387734847143292
Q_Learning [243/300]: mean_loss=0.0331020881421864
Q_Learning [244/300]: mean_loss=0.023376229917630553
Q_Learning [245/300]: mean_loss=0.03819497209042311
Q_Learning [246/300]: mean_loss=0.02492629666812718
Q_Learning [247/300]: mean_loss=0.012128338101319969
Q_Learning [248/300]: mean_loss=0.07402694970369339
Q_Learning [249/300]: mean_loss=0.007764903421048075
Q_Learning [250/300]: mean_loss=0.016775841009803116
Q_Learning [251/300]: mean_loss=0.014986753230914474
Q_Learning [252/300]: mean_loss=0.02140039694495499
Q_Learning [253/300]: mean_loss=0.017805966548621655
Q_Learning [254/300]: mean_loss=0.014618627727031708
Q_Learning [255/300]: mean_loss=0.03366095619276166
Q_Learning [256/300]: mean_loss=0.01444389671087265
Q_Learning [257/300]: mean_loss=0.02302888361737132
Q_Learning [258/300]: mean_loss=0.018099583918228745
Q_Learning [259/300]: mean_loss=0.011622197111137211
Q_Learning [260/300]: mean_loss=0.010424767970107496
Q_Learning [261/300]: mean_loss=0.026382894720882177
Q_Learning [262/300]: mean_loss=0.031039046123623848
Q_Learning [263/300]: mean_loss=0.012342537636868656
Q_Learning [264/300]: mean_loss=0.017067461740225554
Q_Learning [265/300]: mean_loss=0.016287991194985807
Q_Learning [266/300]: mean_loss=0.012880412046797574
Q_Learning [267/300]: mean_loss=0.024910329608246684
Q_Learning [268/300]: mean_loss=0.007705722528044134
Q_Learning [269/300]: mean_loss=0.02112756809219718
Q_Learning [270/300]: mean_loss=0.011422507930546999
Q_Learning [271/300]: mean_loss=0.02463305927813053
Q_Learning [272/300]: mean_loss=0.007147611991968006
Q_Learning [273/300]: mean_loss=0.013612548587843776
Q_Learning [274/300]: mean_loss=0.009959166985936463
Q_Learning [275/300]: mean_loss=0.013674020185135305
Q_Learning [276/300]: mean_loss=0.014903879025951028
Q_Learning [277/300]: mean_loss=0.024726347299292684
Q_Learning [278/300]: mean_loss=0.018506172113120556
Q_Learning [279/300]: mean_loss=0.015667272149585187
Q_Learning [280/300]: mean_loss=0.01753512443974614
Q_Learning [281/300]: mean_loss=0.020001975120976567
Q_Learning [282/300]: mean_loss=0.026159187080338597
Q_Learning [283/300]: mean_loss=0.02311820723116398
Q_Learning [284/300]: mean_loss=0.011076572816818953
Q_Learning [285/300]: mean_loss=0.014813218847848475
Q_Learning [286/300]: mean_loss=0.02301192283630371
Q_Learning [287/300]: mean_loss=0.014628458069637418
Q_Learning [288/300]: mean_loss=0.013449089950881898
Q_Learning [289/300]: mean_loss=0.04393540881574154
Q_Learning [290/300]: mean_loss=0.007312764064408839
Q_Learning [291/300]: mean_loss=0.013324578176252544
Q_Learning [292/300]: mean_loss=0.0070180342881940305
Q_Learning [293/300]: mean_loss=0.01243270211853087
Q_Learning [294/300]: mean_loss=0.01324344368185848
Q_Learning [295/300]: mean_loss=0.03227542480453849
Q_Learning [296/300]: mean_loss=0.03604091191664338
Q_Learning [297/300]: mean_loss=0.019658496137708426
Q_Learning [298/300]: mean_loss=0.010362789500504732
Q_Learning [299/300]: mean_loss=0.021715953247621655
Q_Learning [300/300]: mean_loss=0.03650828916579485
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.94475496  0.4759548 ]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 2, 0, 1, 1, 0, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 2, 2, 0, 1, 1, 1, 0, 3, 2, 1, 1, 1, 2, 0, 3, 2, 0, 1, 3, 2, 0, 0, 1, 2, 1, 0, 1, 1, 3, 2, 1, 0, 2, 1, 1, 0, 3, 1, 2, 1, 2, 1, 1, 3, 1, 1, 2, 0, 2, 0, 0, 0, 2, 1, 1, 1, 0, 2, 2, 0, 1, 4, 0, 2, 2, 2, 1, 2, 0, 2, 1, 1, 4, 2, 1, 0, 1, 2, 2, 1, 2, 0, 2, 2, 1, 2, 0, 2, 0, 0, 2, 2, 2, 1, 3, 2, 1, 3, 2, 1, 4, 1, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 1, 1, 2, 0, 2, 2, 2, 5, 2, 2, 0, 5, 1, 0, 1, 1, 0, 2, 1, 2, 5, 4, 2, 4, 4, 2, 2, 1, 2, 5, 1, 0, 1, 1, 1, 2, 2, 4, 4, 1, 3, 0, 2, 0, 1, 0, 1, 4, 1, 2, 0, 2, 1, 0, 5, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 1, 5, 2, 1, 4, 1, 2, 2, 1, 0, 1, 5, 2, 1, 4, 4, 2, 5, 5, 5, 1, 2, 0, 0, 3, 1, 0, 4, 1, 1, 2, 1, 0, 4, 2, 1, 2, 4, 1, 1, 0, 2, 1, 1, 5, 6, 1, 2, 1, 2, 1, 0, 2, 0, 0, 4, 4, 2, 4, 4, 4, 2, 1, 1, 2, 5, 4, 3, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 3, 0, 1, 5, 3, 0, 4, 1, 5, 5, 3, 5, 2, 4, 0, 1, 2, 5, 7, 1, 2, 4, 0, 2, 1, 5, 1, 5]
Centroids: [[1.2402031, -1.0562279], [0.5743636, -0.27434644], [-0.87996215, 0.26327884]]
Centroids: [[-0.82408524, 0.17357495], [0.5494417, -0.21763499], [1.2135179, -1.0050364], [-0.8071228, -0.50443465], [-1.0186088, 0.94360995], [1.5038118, -1.5160242], [-1.8130515, -0.1138535], [0.2746162, -1.4527436]]
Contingency Matrix: 
[[ 0  9 76  0  0 17  0  1]
 [ 0 90  8  0  0  2  0  0]
 [58  0  0 14 24  0  1  0]]
[[0, 9, 76, 0, 0, 17, 0, 1], [0, 90, 8, 0, 0, 2, 0, 0], [58, 0, 0, 14, 24, 0, 1, 0]]
[[0, 9, 76, 0, 0, 17, 0, 1], [0, 90, 8, 0, 0, 2, 0, 0], [58, 0, 0, 14, 24, 0, 1, 0]]
[0, 1, 2, 3, 4, 5, 6, 7]
[[0, -1, 76, 0, 0, 17, 0, 1], [-1, -1, -1, -1, -1, -1, -1, -1], [58, -1, 0, 14, 24, 0, 1, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1], [58, -1, -1, 14, 24, 0, 1, 0]]
[[-1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 1, 0: 2, 2: 0}
New Contingency Matrix: 
[[76  9  0  0  0 17  0  1]
 [ 8 90  0  0  0  2  0  0]
 [ 0  0 58 14 24  0  1  0]]
New Clustered Label Sequence: [2, 1, 0, 3, 4, 5, 6, 7]
Diagonal_Elements: [76, 90, 58], Sum: 224
All_Elements: [76, 9, 0, 0, 0, 17, 0, 1, 8, 90, 0, 0, 0, 2, 0, 0, 0, 0, 58, 14, 24, 0, 1, 0], Sum: 300
Accuracy: 0.7466666666666667
