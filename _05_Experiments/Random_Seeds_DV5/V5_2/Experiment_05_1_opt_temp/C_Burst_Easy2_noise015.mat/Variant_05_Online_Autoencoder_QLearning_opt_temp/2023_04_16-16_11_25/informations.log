Experiment_path: Random_Seeds_DV5//V5_2/Experiment_05_1_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: Random_Seeds_DV5//V5_2/Experiment_05_1_opt_temp/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_04_16-16_11_25
Punishment_Coefficient: 0.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000002725C4854A8>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.2552883978933096
Online_Training [2/700]: mean_loss=0.22976662032306194
Online_Training [3/700]: mean_loss=0.22506971843540668
Online_Training [4/700]: mean_loss=0.12122792750597
Online_Training [5/700]: mean_loss=0.28704076260328293
Online_Training [6/700]: mean_loss=0.12845708336681128
Online_Training [7/700]: mean_loss=0.12091985438019037
Online_Training [8/700]: mean_loss=0.08688705042004585
Online_Training [9/700]: mean_loss=0.15946980379521847
Online_Training [10/700]: mean_loss=0.16399996913969517
Online_Training [11/700]: mean_loss=0.10814343858510256
Online_Training [12/700]: mean_loss=0.09953154064714909
Online_Training [13/700]: mean_loss=0.09514246694743633
Online_Training [14/700]: mean_loss=0.04934797575697303
Online_Training [15/700]: mean_loss=0.08022840414196253
Online_Training [16/700]: mean_loss=0.13064605183899403
Online_Training [17/700]: mean_loss=0.08908908814191818
Online_Training [18/700]: mean_loss=0.04687974322587252
Online_Training [19/700]: mean_loss=0.031451452523469925
Online_Training [20/700]: mean_loss=0.14545702561736107
Online_Training [21/700]: mean_loss=0.1395593024790287
Online_Training [22/700]: mean_loss=0.012646196992136538
Online_Training [23/700]: mean_loss=0.021824572002515197
Online_Training [24/700]: mean_loss=0.07959788292646408
Online_Training [25/700]: mean_loss=0.03292748099192977
Online_Training [26/700]: mean_loss=0.05174430459737778
Online_Training [27/700]: mean_loss=0.10374625585973263
Online_Training [28/700]: mean_loss=0.03885330259799957
Online_Training [29/700]: mean_loss=0.046401276253163815
Online_Training [30/700]: mean_loss=0.031450042966753244
Online_Training [31/700]: mean_loss=0.024241893086582422
Online_Training [32/700]: mean_loss=0.04139364184811711
Online_Training [33/700]: mean_loss=0.023631445365026593
Online_Training [34/700]: mean_loss=0.1469589602202177
Online_Training [35/700]: mean_loss=0.05197482882067561
Online_Training [36/700]: mean_loss=0.0814158609136939
Online_Training [37/700]: mean_loss=0.05412867618724704
Online_Training [38/700]: mean_loss=0.036111867520958185
Online_Training [39/700]: mean_loss=0.12070315983146429
Online_Training [40/700]: mean_loss=0.03277387865819037
Online_Training [41/700]: mean_loss=0.027623641537502408
Online_Training [42/700]: mean_loss=0.05250585777685046
Online_Training [43/700]: mean_loss=0.11907144077122211
Online_Training [44/700]: mean_loss=0.14509517326951027
Online_Training [45/700]: mean_loss=0.07270545419305563
Online_Training [46/700]: mean_loss=0.046979626175016165
Online_Training [47/700]: mean_loss=0.078167580999434
Online_Training [48/700]: mean_loss=0.0676924204453826
Online_Training [49/700]: mean_loss=0.08494355622678995
Online_Training [50/700]: mean_loss=0.10668423119932413
Online_Training [51/700]: mean_loss=0.028199052205309272
Online_Training [52/700]: mean_loss=0.1459998581558466
Online_Training [53/700]: mean_loss=0.018891135463491082
Online_Training [54/700]: mean_loss=0.06790526304394007
Online_Training [55/700]: mean_loss=0.04443673603236675
Online_Training [56/700]: mean_loss=0.035335867665708065
Online_Training [57/700]: mean_loss=0.09183742105960846
Online_Training [58/700]: mean_loss=0.2970467135310173
Online_Training [59/700]: mean_loss=0.053709684405475855
Online_Training [60/700]: mean_loss=0.05562354018911719
Online_Training [61/700]: mean_loss=0.03326039016246796
Online_Training [62/700]: mean_loss=0.06800908921286464
Online_Training [63/700]: mean_loss=0.057296188082545996
Online_Training [64/700]: mean_loss=0.004832714446820319
Online_Training [65/700]: mean_loss=0.06398387812077999
Online_Training [66/700]: mean_loss=0.035841130651533604
Online_Training [67/700]: mean_loss=0.056338606402277946
Online_Training [68/700]: mean_loss=0.05534483306109905
Online_Training [69/700]: mean_loss=0.11380200367420912
Online_Training [70/700]: mean_loss=0.042010541539639235
Online_Training [71/700]: mean_loss=0.07121909316629171
Online_Training [72/700]: mean_loss=0.07938765361905098
Online_Training [73/700]: mean_loss=0.03813335159793496
Online_Training [74/700]: mean_loss=0.037845435086637735
Online_Training [75/700]: mean_loss=0.03229547757655382
Online_Training [76/700]: mean_loss=0.024661474162712693
Online_Training [77/700]: mean_loss=0.04625905677676201
Online_Training [78/700]: mean_loss=0.03691170457750559
Online_Training [79/700]: mean_loss=0.04037239961326122
Online_Training [80/700]: mean_loss=0.03740033321082592
Online_Training [81/700]: mean_loss=0.01629210775718093
Online_Training [82/700]: mean_loss=0.028069075429812074
Online_Training [83/700]: mean_loss=0.054627795703709126
Online_Training [84/700]: mean_loss=0.0358822587877512
Online_Training [85/700]: mean_loss=0.026314881164580584
Online_Training [86/700]: mean_loss=0.03796132607385516
Online_Training [87/700]: mean_loss=0.019582994980737567
Online_Training [88/700]: mean_loss=0.029509012354537845
Online_Training [89/700]: mean_loss=0.044738228898495436
Online_Training [90/700]: mean_loss=0.019064915366470814
Online_Training [91/700]: mean_loss=0.03619997017085552
Online_Training [92/700]: mean_loss=0.03481025900691748
Online_Training [93/700]: mean_loss=0.03158431872725487
Online_Training [94/700]: mean_loss=0.04711929056793451
Online_Training [95/700]: mean_loss=0.04287401167675853
Online_Training [96/700]: mean_loss=0.02009435452055186
Online_Training [97/700]: mean_loss=0.042708320543169975
Online_Training [98/700]: mean_loss=0.05406240466982126
Online_Training [99/700]: mean_loss=0.02001871168613434
Online_Training [100/700]: mean_loss=0.06689232448115945
Online_Training [101/700]: mean_loss=0.022942880867049098
Online_Training [102/700]: mean_loss=0.04996134154498577
Online_Training [103/700]: mean_loss=0.03877719957381487
Online_Training [104/700]: mean_loss=0.0464032250456512
Online_Training [105/700]: mean_loss=0.031880850438028574
Online_Training [106/700]: mean_loss=0.012905290815979242
Online_Training [107/700]: mean_loss=0.01347701286431402
Online_Training [108/700]: mean_loss=0.02350634103640914
Online_Training [109/700]: mean_loss=0.037583790719509125
Online_Training [110/700]: mean_loss=0.022689100820571184
Online_Training [111/700]: mean_loss=0.03760930569842458
Online_Training [112/700]: mean_loss=0.16229057125747204
Online_Training [113/700]: mean_loss=0.0211934766266495
Online_Training [114/700]: mean_loss=0.027394537581130862
Online_Training [115/700]: mean_loss=0.05872568069025874
Online_Training [116/700]: mean_loss=0.027764646103605628
Online_Training [117/700]: mean_loss=0.07434019446372986
Online_Training [118/700]: mean_loss=0.04149142326787114
Online_Training [119/700]: mean_loss=0.12653230782598257
Online_Training [120/700]: mean_loss=0.07040953123942018
Online_Training [121/700]: mean_loss=0.047227027360349894
Online_Training [122/700]: mean_loss=0.06731678498908877
Online_Training [123/700]: mean_loss=0.05009429808706045
Online_Training [124/700]: mean_loss=0.025838227476924658
Online_Training [125/700]: mean_loss=0.08240267727524042
Online_Training [126/700]: mean_loss=0.051920919213443995
Online_Training [127/700]: mean_loss=0.054394956678152084
Online_Training [128/700]: mean_loss=0.03300378331914544
Online_Training [129/700]: mean_loss=0.03388466825708747
Online_Training [130/700]: mean_loss=0.01888988632708788
Online_Training [131/700]: mean_loss=0.03154331166297197
Online_Training [132/700]: mean_loss=0.018322194810025394
Online_Training [133/700]: mean_loss=0.024226349079981446
Online_Training [134/700]: mean_loss=0.022796672536060214
Online_Training [135/700]: mean_loss=0.12368512712419033
Online_Training [136/700]: mean_loss=0.018010842381045222
Online_Training [137/700]: mean_loss=0.023844508454203606
Online_Training [138/700]: mean_loss=0.014445340377278626
Online_Training [139/700]: mean_loss=0.020608540158718824
Online_Training [140/700]: mean_loss=0.03173992573283613
Online_Training [141/700]: mean_loss=0.028948391787707806
Online_Training [142/700]: mean_loss=0.010180251323617995
Online_Training [143/700]: mean_loss=0.019242471316829324
Online_Training [144/700]: mean_loss=0.0170979913091287
Online_Training [145/700]: mean_loss=0.027049827156588435
Online_Training [146/700]: mean_loss=0.02183999167755246
Online_Training [147/700]: mean_loss=0.01947544072754681
Online_Training [148/700]: mean_loss=0.047912666108459234
Online_Training [149/700]: mean_loss=0.11068938206881285
Online_Training [150/700]: mean_loss=0.08900416642427444
Online_Training [151/700]: mean_loss=0.05243745120242238
Online_Training [152/700]: mean_loss=0.022847232641652226
Online_Training [153/700]: mean_loss=0.022137587191537023
Online_Training [154/700]: mean_loss=0.017125439830124378
Online_Training [155/700]: mean_loss=0.015570280607789755
Online_Training [156/700]: mean_loss=0.017774978070519865
Online_Training [157/700]: mean_loss=0.09243614319711924
Online_Training [158/700]: mean_loss=0.0062699923873879015
Online_Training [159/700]: mean_loss=0.022088923025876284
Online_Training [160/700]: mean_loss=0.019906396744772792
Online_Training [161/700]: mean_loss=0.022535095689818263
Online_Training [162/700]: mean_loss=0.017381656332872808
Online_Training [163/700]: mean_loss=0.058676311280578375
Online_Training [164/700]: mean_loss=0.014190204092301428
Online_Training [165/700]: mean_loss=0.012024549534544349
Online_Training [166/700]: mean_loss=0.02266444033011794
Online_Training [167/700]: mean_loss=0.03844613954424858
Online_Training [168/700]: mean_loss=0.04323932249099016
Online_Training [169/700]: mean_loss=0.05555486539378762
Online_Training [170/700]: mean_loss=0.16704891435801983
Online_Training [171/700]: mean_loss=0.021092277951538563
Online_Training [172/700]: mean_loss=0.017243578797206283
Online_Training [173/700]: mean_loss=0.01718871109187603
Online_Training [174/700]: mean_loss=0.013382073142565787
Online_Training [175/700]: mean_loss=0.011711670085787773
Online_Training [176/700]: mean_loss=0.009306109335739166
Online_Training [177/700]: mean_loss=0.031511085806414485
Online_Training [178/700]: mean_loss=0.04220095416530967
Online_Training [179/700]: mean_loss=0.015321797924116254
Online_Training [180/700]: mean_loss=0.030836620135232806
Online_Training [181/700]: mean_loss=0.03183895815163851
Online_Training [182/700]: mean_loss=0.03035757807083428
Online_Training [183/700]: mean_loss=0.012804914964362979
Online_Training [184/700]: mean_loss=0.006967096880543977
Online_Training [185/700]: mean_loss=0.032156379194930196
Online_Training [186/700]: mean_loss=0.025225196266546845
Online_Training [187/700]: mean_loss=0.028931478038430214
Online_Training [188/700]: mean_loss=0.02221557917073369
Online_Training [189/700]: mean_loss=0.048450042493641376
Online_Training [190/700]: mean_loss=0.025713206734508276
Online_Training [191/700]: mean_loss=0.14275296032428741
Online_Training [192/700]: mean_loss=0.025348234688863158
Online_Training [193/700]: mean_loss=0.023102912353351712
Online_Training [194/700]: mean_loss=0.018283806857652962
Online_Training [195/700]: mean_loss=0.023937822552397847
Online_Training [196/700]: mean_loss=0.012777274241670966
Online_Training [197/700]: mean_loss=0.045838531106710434
Online_Training [198/700]: mean_loss=0.014079205342568457
Online_Training [199/700]: mean_loss=0.08319109678268433
Online_Training [200/700]: mean_loss=0.013351524015888572
Online_Training [201/700]: mean_loss=0.03437918238341808
Online_Training [202/700]: mean_loss=0.012721158214844763
Online_Training [203/700]: mean_loss=0.012249193852767348
Online_Training [204/700]: mean_loss=0.009608971944544464
Online_Training [205/700]: mean_loss=0.07304266840219498
Online_Training [206/700]: mean_loss=0.015900178696028888
Online_Training [207/700]: mean_loss=0.03785746870562434
Online_Training [208/700]: mean_loss=0.03986602649092674
Online_Training [209/700]: mean_loss=0.05094029847532511
Online_Training [210/700]: mean_loss=0.01992702088318765
Online_Training [211/700]: mean_loss=0.024974243016913533
Online_Training [212/700]: mean_loss=0.09191734902560711
Online_Training [213/700]: mean_loss=0.05058034183457494
Online_Training [214/700]: mean_loss=0.013330625020898879
Online_Training [215/700]: mean_loss=0.03005445539020002
Online_Training [216/700]: mean_loss=0.034542267909273505
Online_Training [217/700]: mean_loss=0.013258405146189034
Online_Training [218/700]: mean_loss=0.009023215039633214
Online_Training [219/700]: mean_loss=0.056548445019870996
Online_Training [220/700]: mean_loss=0.011194653809070587
Online_Training [221/700]: mean_loss=0.03170457459054887
Online_Training [222/700]: mean_loss=0.02148700342513621
Online_Training [223/700]: mean_loss=0.033546541817486286
Online_Training [224/700]: mean_loss=0.00761348835658282
Online_Training [225/700]: mean_loss=0.030196363339200616
Online_Training [226/700]: mean_loss=0.027919747168198228
Online_Training [227/700]: mean_loss=0.01458032091613859
Online_Training [228/700]: mean_loss=0.02801833557896316
Online_Training [229/700]: mean_loss=0.050250232219696045
Online_Training [230/700]: mean_loss=0.0217470598872751
Online_Training [231/700]: mean_loss=0.021394897950813174
Online_Training [232/700]: mean_loss=0.02415493200533092
Online_Training [233/700]: mean_loss=0.021695253206416965
Online_Training [234/700]: mean_loss=0.05416404129937291
Online_Training [235/700]: mean_loss=0.1044804286211729
Online_Training [236/700]: mean_loss=0.05876186955720186
Online_Training [237/700]: mean_loss=0.018580940319225192
Online_Training [238/700]: mean_loss=0.1136702224612236
Online_Training [239/700]: mean_loss=0.10712888278067112
Online_Training [240/700]: mean_loss=0.07298769569024444
Online_Training [241/700]: mean_loss=0.04666984640061855
Online_Training [242/700]: mean_loss=0.02559027192182839
Online_Training [243/700]: mean_loss=0.040986467618495226
Online_Training [244/700]: mean_loss=0.038605859968811274
Online_Training [245/700]: mean_loss=0.053151128347963095
Online_Training [246/700]: mean_loss=0.03161409986205399
Online_Training [247/700]: mean_loss=0.013340933830477297
Online_Training [248/700]: mean_loss=0.07132890820503235
Online_Training [249/700]: mean_loss=0.0219427146948874
Online_Training [250/700]: mean_loss=0.014827769715338945
Online_Training [251/700]: mean_loss=0.02242153394035995
Online_Training [252/700]: mean_loss=0.011109266895800829
Online_Training [253/700]: mean_loss=0.016264253994449973
Online_Training [254/700]: mean_loss=0.024303963407874107
Online_Training [255/700]: mean_loss=0.04162244452163577
Online_Training [256/700]: mean_loss=0.01372297597117722
Online_Training [257/700]: mean_loss=0.026543043786659837
Online_Training [258/700]: mean_loss=0.011457644868642092
Online_Training [259/700]: mean_loss=0.012402786873281002
Online_Training [260/700]: mean_loss=0.017234964994713664
Online_Training [261/700]: mean_loss=0.027843499556183815
Online_Training [262/700]: mean_loss=0.03076352016068995
Online_Training [263/700]: mean_loss=0.012228063424117863
Online_Training [264/700]: mean_loss=0.012124946806579828
Online_Training [265/700]: mean_loss=0.020865051541477442
Online_Training [266/700]: mean_loss=0.01601539447437972
Online_Training [267/700]: mean_loss=0.015160539420321584
Online_Training [268/700]: mean_loss=0.009594444301910698
Online_Training [269/700]: mean_loss=0.01954023726284504
Online_Training [270/700]: mean_loss=0.009395002736710012
Online_Training [271/700]: mean_loss=0.02866403223015368
Online_Training [272/700]: mean_loss=0.005913364642765373
Online_Training [273/700]: mean_loss=0.011513469042256474
Online_Training [274/700]: mean_loss=0.018134953686967492
Online_Training [275/700]: mean_loss=0.01492672972381115
Online_Training [276/700]: mean_loss=0.021164578152820468
Online_Training [277/700]: mean_loss=0.03655027993954718
Online_Training [278/700]: mean_loss=0.015482785529457033
Online_Training [279/700]: mean_loss=0.022399025037884712
Online_Training [280/700]: mean_loss=0.02149715879932046
Online_Training [281/700]: mean_loss=0.024373096181079745
Online_Training [282/700]: mean_loss=0.03379183844663203
Online_Training [283/700]: mean_loss=0.01972681563347578
Online_Training [284/700]: mean_loss=0.02175714331679046
Online_Training [285/700]: mean_loss=0.016340026864781976
Online_Training [286/700]: mean_loss=0.023402366088703275
Online_Training [287/700]: mean_loss=0.013581721461378038
Online_Training [288/700]: mean_loss=0.012245155638083816
Online_Training [289/700]: mean_loss=0.0432213107123971
Online_Training [290/700]: mean_loss=0.005125489813508466
Online_Training [291/700]: mean_loss=0.006762516277376562
Online_Training [292/700]: mean_loss=0.0070576457073912024
Online_Training [293/700]: mean_loss=0.012831259984523058
Online_Training [294/700]: mean_loss=0.019795219646766782
Online_Training [295/700]: mean_loss=0.03377704066224396
Online_Training [296/700]: mean_loss=0.03919263789430261
Online_Training [297/700]: mean_loss=0.01906369929201901
Online_Training [298/700]: mean_loss=0.015732458559796214
Online_Training [299/700]: mean_loss=0.032854815013706684
Online_Training [300/700]: mean_loss=0.04528001416474581
Online_Training [301/700]: mean_loss=0.011674854904413223
Online_Training [302/700]: mean_loss=0.025471345987170935
Online_Training [303/700]: mean_loss=0.0253260952886194
Online_Training [304/700]: mean_loss=0.022177533246576786
Online_Training [305/700]: mean_loss=0.038236403139308095
Online_Training [306/700]: mean_loss=0.06542160315439105
Online_Training [307/700]: mean_loss=0.0670566875487566
Online_Training [308/700]: mean_loss=0.04540782980620861
Online_Training [309/700]: mean_loss=0.021472074557095766
Online_Training [310/700]: mean_loss=0.016573821427300572
Online_Training [311/700]: mean_loss=0.014734859811142087
Online_Training [312/700]: mean_loss=0.04791805986315012
Online_Training [313/700]: mean_loss=0.027827931800857186
Online_Training [314/700]: mean_loss=0.008740357880014926
Online_Training [315/700]: mean_loss=0.007800616847816855
Online_Training [316/700]: mean_loss=0.01837611966766417
Online_Training [317/700]: mean_loss=0.004823003720957786
Online_Training [318/700]: mean_loss=0.024556300835683942
Online_Training [319/700]: mean_loss=0.03942555235698819
Online_Training [320/700]: mean_loss=0.009016756433993578
Online_Training [321/700]: mean_loss=0.023575349943712354
Online_Training [322/700]: mean_loss=0.027598897460848093
Online_Training [323/700]: mean_loss=0.012274246546439826
Online_Training [324/700]: mean_loss=0.018202672246843576
Online_Training [325/700]: mean_loss=0.023095249896869063
Online_Training [326/700]: mean_loss=0.01166560163255781
Online_Training [327/700]: mean_loss=0.030137995956465602
Online_Training [328/700]: mean_loss=0.03469246719032526
Online_Training [329/700]: mean_loss=0.009747608215548098
Online_Training [330/700]: mean_loss=0.024753102334216237
Online_Training [331/700]: mean_loss=0.0401652732398361
Online_Training [332/700]: mean_loss=0.022616068134084344
Online_Training [333/700]: mean_loss=0.028346128179691732
Online_Training [334/700]: mean_loss=0.007358682225458324
Online_Training [335/700]: mean_loss=0.06759665906429291
Online_Training [336/700]: mean_loss=0.06765270372852683
Online_Training [337/700]: mean_loss=0.11271558422595263
Online_Training [338/700]: mean_loss=0.018113964470103383
Online_Training [339/700]: mean_loss=0.009819769533351064
Online_Training [340/700]: mean_loss=0.008298337168525904
Online_Training [341/700]: mean_loss=0.02364485035650432
Online_Training [342/700]: mean_loss=0.07384206913411617
Online_Training [343/700]: mean_loss=0.016220602672547102
Online_Training [344/700]: mean_loss=0.02033646497875452
Online_Training [345/700]: mean_loss=0.038639933336526155
Online_Training [346/700]: mean_loss=0.02550104516558349
Online_Training [347/700]: mean_loss=0.13318940717726946
Online_Training [348/700]: mean_loss=0.021833876380696893
Online_Training [349/700]: mean_loss=0.02234517061151564
Online_Training [350/700]: mean_loss=0.011772870901040733
Online_Training [351/700]: mean_loss=0.010223507648333907
Online_Training [352/700]: mean_loss=0.008219574694521725
Online_Training [353/700]: mean_loss=0.027785653481259942
Online_Training [354/700]: mean_loss=0.021594674326479435
Online_Training [355/700]: mean_loss=0.01952094561420381
Online_Training [356/700]: mean_loss=0.01567359420005232
Online_Training [357/700]: mean_loss=0.07777992077171803
Online_Training [358/700]: mean_loss=0.062203341629356146
Online_Training [359/700]: mean_loss=0.0937063405290246
Online_Training [360/700]: mean_loss=0.02549841464497149
Online_Training [361/700]: mean_loss=0.029179523466154933
Online_Training [362/700]: mean_loss=0.053329647053033113
Online_Training [363/700]: mean_loss=0.01745294942520559
Online_Training [364/700]: mean_loss=0.010456257965415716
Online_Training [365/700]: mean_loss=0.016872703447006643
Online_Training [366/700]: mean_loss=0.0257743822876364
Online_Training [367/700]: mean_loss=0.022836743853986263
Online_Training [368/700]: mean_loss=0.0167856722837314
Online_Training [369/700]: mean_loss=0.015657859621569514
Online_Training [370/700]: mean_loss=0.03720247792080045
Online_Training [371/700]: mean_loss=0.008576676365919411
Online_Training [372/700]: mean_loss=0.022156366612762213
Online_Training [373/700]: mean_loss=0.010145032429136336
Online_Training [374/700]: mean_loss=0.014639067579992115
Online_Training [375/700]: mean_loss=0.018003774574026465
Online_Training [376/700]: mean_loss=0.01060926984064281
Online_Training [377/700]: mean_loss=0.018210694659501314
Online_Training [378/700]: mean_loss=0.01530765916686505
Online_Training [379/700]: mean_loss=0.01693069259636104
Online_Training [380/700]: mean_loss=0.012476730509661138
Online_Training [381/700]: mean_loss=0.017027704510837793
Online_Training [382/700]: mean_loss=0.010986729175783694
Online_Training [383/700]: mean_loss=0.007854290655814111
Online_Training [384/700]: mean_loss=0.13514600694179535
Online_Training [385/700]: mean_loss=0.010473303962498903
Online_Training [386/700]: mean_loss=0.02857255470007658
Online_Training [387/700]: mean_loss=0.016811123001389205
Online_Training [388/700]: mean_loss=0.026814231649041176
Online_Training [389/700]: mean_loss=0.011755201499909163
Online_Training [390/700]: mean_loss=0.024169054115191102
Online_Training [391/700]: mean_loss=0.013324053958058357
Online_Training [392/700]: mean_loss=0.01498859201092273
Online_Training [393/700]: mean_loss=0.023743155412375927
Online_Training [394/700]: mean_loss=0.02401866647414863
Online_Training [395/700]: mean_loss=0.00886553293094039
Online_Training [396/700]: mean_loss=0.02179636526852846
Online_Training [397/700]: mean_loss=0.012484389008022845
Online_Training [398/700]: mean_loss=0.02332925028167665
Online_Training [399/700]: mean_loss=0.01856754650361836
Online_Training [400/700]: mean_loss=0.036402031779289246
Online_Training [401/700]: mean_loss=0.009405079821590334
Online_Training [402/700]: mean_loss=0.011740901623852551
Online_Training [403/700]: mean_loss=0.023772012908011675
Online_Training [404/700]: mean_loss=0.03698094794526696
Online_Training [405/700]: mean_loss=0.06446525268256664
Online_Training [406/700]: mean_loss=0.03010657778941095
Online_Training [407/700]: mean_loss=0.03260036348365247
Online_Training [408/700]: mean_loss=0.022301167948171496
Online_Training [409/700]: mean_loss=0.008247210993431509
Online_Training [410/700]: mean_loss=0.021146195475012064
Online_Training [411/700]: mean_loss=0.024573685601353645
Online_Training [412/700]: mean_loss=0.10101604927331209
Online_Training [413/700]: mean_loss=0.048071309458464384
Online_Training [414/700]: mean_loss=0.026483328081667423
Online_Training [415/700]: mean_loss=0.021745362784713507
Online_Training [416/700]: mean_loss=0.021585082868114114
Online_Training [417/700]: mean_loss=0.06764528527855873
Online_Training [418/700]: mean_loss=0.015871115494519472
Online_Training [419/700]: mean_loss=0.012302511488087475
Online_Training [420/700]: mean_loss=0.050596504006534815
Online_Training [421/700]: mean_loss=0.03292753454297781
Online_Training [422/700]: mean_loss=0.017605848843231797
Online_Training [423/700]: mean_loss=0.04068817524239421
Online_Training [424/700]: mean_loss=0.05129863880574703
Online_Training [425/700]: mean_loss=0.020773217314854264
Online_Training [426/700]: mean_loss=0.007548309222329408
Online_Training [427/700]: mean_loss=0.0153105374192819
Online_Training [428/700]: mean_loss=0.030207077972590923
Online_Training [429/700]: mean_loss=0.01379379688296467
Online_Training [430/700]: mean_loss=0.0098192353034392
Online_Training [431/700]: mean_loss=0.015259174280799925
Online_Training [432/700]: mean_loss=0.09881052281707525
Online_Training [433/700]: mean_loss=0.01824716362170875
Online_Training [434/700]: mean_loss=0.0214788313023746
Online_Training [435/700]: mean_loss=0.010638779262080789
Online_Training [436/700]: mean_loss=0.0709840152412653
Online_Training [437/700]: mean_loss=0.011412498308345675
Online_Training [438/700]: mean_loss=0.07410276168957353
Online_Training [439/700]: mean_loss=0.033349340315908194
Online_Training [440/700]: mean_loss=0.03782348753884435
Online_Training [441/700]: mean_loss=0.027370166266337037
Online_Training [442/700]: mean_loss=0.014436736411880702
Online_Training [443/700]: mean_loss=0.011965883895754814
Online_Training [444/700]: mean_loss=0.02722807414829731
Online_Training [445/700]: mean_loss=0.023661685874685645
Online_Training [446/700]: mean_loss=0.024584323866292834
Online_Training [447/700]: mean_loss=0.008773580426350236
Online_Training [448/700]: mean_loss=0.02247338881716132
Online_Training [449/700]: mean_loss=0.019352342234924436
Online_Training [450/700]: mean_loss=0.02751204837113619
Online_Training [451/700]: mean_loss=0.022754491539672017
Online_Training [452/700]: mean_loss=0.039042542688548565
Online_Training [453/700]: mean_loss=0.0650175753980875
Online_Training [454/700]: mean_loss=0.020502093713730574
Online_Training [455/700]: mean_loss=0.03264427627436817
Online_Training [456/700]: mean_loss=0.005627580801956356
Online_Training [457/700]: mean_loss=0.009584691259078681
Online_Training [458/700]: mean_loss=0.012802615063264966
Online_Training [459/700]: mean_loss=0.01172146201133728
Online_Training [460/700]: mean_loss=0.02077835681848228
Online_Training [461/700]: mean_loss=0.02428581635467708
Online_Training [462/700]: mean_loss=0.00692632474238053
Online_Training [463/700]: mean_loss=0.006402011960744858
Online_Training [464/700]: mean_loss=0.016763686202466488
Online_Training [465/700]: mean_loss=0.059995442163199186
Online_Training [466/700]: mean_loss=0.026110027451068163
Online_Training [467/700]: mean_loss=0.022982068127021194
Online_Training [468/700]: mean_loss=0.013439420494250953
Online_Training [469/700]: mean_loss=0.033033317187801
Online_Training [470/700]: mean_loss=0.043626075610518456
Online_Training [471/700]: mean_loss=0.019273280631750822
Online_Training [472/700]: mean_loss=0.02284854673780501
Online_Training [473/700]: mean_loss=0.005738464999012649
Online_Training [474/700]: mean_loss=0.012663692934438586
Online_Training [475/700]: mean_loss=0.012906598392874002
Online_Training [476/700]: mean_loss=0.22673917748034
Online_Training [477/700]: mean_loss=0.10841271840035915
Online_Training [478/700]: mean_loss=0.04523795284330845
Online_Training [479/700]: mean_loss=0.013852708390913904
Online_Training [480/700]: mean_loss=0.008138769830111414
Online_Training [481/700]: mean_loss=0.016465476364828646
Online_Training [482/700]: mean_loss=0.0294958867598325
Online_Training [483/700]: mean_loss=0.02019863179884851
Online_Training [484/700]: mean_loss=0.01546804013196379
Online_Training [485/700]: mean_loss=0.0071583392564207315
Online_Training [486/700]: mean_loss=0.0167516894871369
Online_Training [487/700]: mean_loss=0.025549775222316384
Online_Training [488/700]: mean_loss=0.02098077000118792
Online_Training [489/700]: mean_loss=0.01158465666230768
Online_Training [490/700]: mean_loss=0.02582272468134761
Online_Training [491/700]: mean_loss=0.04360152408480644
Online_Training [492/700]: mean_loss=0.013212037039920688
Online_Training [493/700]: mean_loss=0.011396970599889755
Online_Training [494/700]: mean_loss=0.05323459627106786
Online_Training [495/700]: mean_loss=0.00782390683889389
Online_Training [496/700]: mean_loss=0.02836126135662198
Online_Training [497/700]: mean_loss=0.021525728283450007
Online_Training [498/700]: mean_loss=0.0133426213869825
Online_Training [499/700]: mean_loss=0.014640095760114491
Online_Training [500/700]: mean_loss=0.009547063964419067
Online_Training [501/700]: mean_loss=0.013064510771073401
Online_Training [502/700]: mean_loss=0.018872366286814213
Online_Training [503/700]: mean_loss=0.0172906129155308
Online_Training [504/700]: mean_loss=0.014924115967005491
Online_Training [505/700]: mean_loss=0.013055390794761479
Online_Training [506/700]: mean_loss=0.10250441078096628
Online_Training [507/700]: mean_loss=0.12524388078600168
Online_Training [508/700]: mean_loss=0.02885390887968242
Online_Training [509/700]: mean_loss=0.013753769220784307
Online_Training [510/700]: mean_loss=0.030559152830392122
Online_Training [511/700]: mean_loss=0.009812293923459947
Online_Training [512/700]: mean_loss=0.013751650578342378
Online_Training [513/700]: mean_loss=0.031454897951334715
Online_Training [514/700]: mean_loss=0.029929934768006206
Online_Training [515/700]: mean_loss=0.024963790317997336
Online_Training [516/700]: mean_loss=0.01739726820960641
Online_Training [517/700]: mean_loss=0.027752553345635533
Online_Training [518/700]: mean_loss=0.01711110444739461
Online_Training [519/700]: mean_loss=0.0118442791281268
Online_Training [520/700]: mean_loss=0.011314405594021082
Online_Training [521/700]: mean_loss=0.02499332232400775
Online_Training [522/700]: mean_loss=0.006962584797292948
Online_Training [523/700]: mean_loss=0.018381389090791345
Online_Training [524/700]: mean_loss=0.07878533657640219
Online_Training [525/700]: mean_loss=0.020454562501981854
Online_Training [526/700]: mean_loss=0.01290945301298052
Online_Training [527/700]: mean_loss=0.01837344653904438
Online_Training [528/700]: mean_loss=0.029035880463197827
Online_Training [529/700]: mean_loss=0.01911193726118654
Online_Training [530/700]: mean_loss=0.019783811876550317
Online_Training [531/700]: mean_loss=0.023918553721159697
Online_Training [532/700]: mean_loss=0.024822603911161423
Online_Training [533/700]: mean_loss=0.014987126225605607
Online_Training [534/700]: mean_loss=0.012716205324977636
Online_Training [535/700]: mean_loss=0.02867761650122702
Online_Training [536/700]: mean_loss=0.10467474535107613
Online_Training [537/700]: mean_loss=0.018031201791018248
Online_Training [538/700]: mean_loss=0.01438149088062346
Online_Training [539/700]: mean_loss=0.010650675045326352
Online_Training [540/700]: mean_loss=0.025823460891842842
Online_Training [541/700]: mean_loss=0.11510342266410589
Online_Training [542/700]: mean_loss=0.010835030872840434
Online_Training [543/700]: mean_loss=0.026227043010294437
Online_Training [544/700]: mean_loss=0.011294856667518616
Online_Training [545/700]: mean_loss=0.019277862273156643
Online_Training [546/700]: mean_loss=0.009848788264207542
Online_Training [547/700]: mean_loss=0.01519848417956382
Online_Training [548/700]: mean_loss=0.02234164229594171
Online_Training [549/700]: mean_loss=0.005147146992385387
Online_Training [550/700]: mean_loss=0.03252181154675782
Online_Training [551/700]: mean_loss=0.02332139411009848
Online_Training [552/700]: mean_loss=0.02080916869454086
Online_Training [553/700]: mean_loss=0.03210637788288295
Online_Training [554/700]: mean_loss=0.017445149831473827
Online_Training [555/700]: mean_loss=0.031941886991262436
Online_Training [556/700]: mean_loss=0.016712072072550654
Online_Training [557/700]: mean_loss=0.016222953447140753
Online_Training [558/700]: mean_loss=0.006701662379782647
Online_Training [559/700]: mean_loss=0.0016159151709871367
Online_Training [560/700]: mean_loss=0.007697833818383515
Online_Training [561/700]: mean_loss=0.014978762483224273
Online_Training [562/700]: mean_loss=0.03478421759791672
Online_Training [563/700]: mean_loss=0.03364136326126754
Online_Training [564/700]: mean_loss=0.012715379474684596
Online_Training [565/700]: mean_loss=0.02497867727652192
Online_Training [566/700]: mean_loss=0.01699623907916248
Online_Training [567/700]: mean_loss=0.022281224373728037
Online_Training [568/700]: mean_loss=0.021160524804145098
Online_Training [569/700]: mean_loss=0.02561784815043211
Online_Training [570/700]: mean_loss=0.011348105734214187
Online_Training [571/700]: mean_loss=0.013693112065084279
Online_Training [572/700]: mean_loss=0.016647830372676253
Online_Training [573/700]: mean_loss=0.027099422877654433
Online_Training [574/700]: mean_loss=0.04619671497493982
Online_Training [575/700]: mean_loss=0.044050862081348896
Online_Training [576/700]: mean_loss=0.009822608320973814
Online_Training [577/700]: mean_loss=0.016506319399923086
Online_Training [578/700]: mean_loss=0.006987686676438898
Online_Training [579/700]: mean_loss=0.0191987210419029
Online_Training [580/700]: mean_loss=0.032333992421627045
Online_Training [581/700]: mean_loss=0.012711180839687586
Online_Training [582/700]: mean_loss=0.012181898695416749
Online_Training [583/700]: mean_loss=0.009454383922275156
Online_Training [584/700]: mean_loss=0.015310802147723734
Online_Training [585/700]: mean_loss=0.024020206183195114
Online_Training [586/700]: mean_loss=0.10229455400258303
Online_Training [587/700]: mean_loss=0.031090277014300227
Online_Training [588/700]: mean_loss=0.01110826211515814
Online_Training [589/700]: mean_loss=0.025870940880849957
Online_Training [590/700]: mean_loss=0.01966318115592003
Online_Training [591/700]: mean_loss=0.015322588966228068
Online_Training [592/700]: mean_loss=0.013436326058581471
Online_Training [593/700]: mean_loss=0.03996132407337427
Online_Training [594/700]: mean_loss=0.0186075062956661
Online_Training [595/700]: mean_loss=0.038716367445886135
Online_Training [596/700]: mean_loss=0.010605863179080188
Online_Training [597/700]: mean_loss=0.008398268837481737
Online_Training [598/700]: mean_loss=0.015649965847842395
Online_Training [599/700]: mean_loss=0.018059415044263005
Online_Training [600/700]: mean_loss=0.013020708225667477
Online_Training [601/700]: mean_loss=0.029548593098297715
Online_Training [602/700]: mean_loss=0.008299480192363262
Online_Training [603/700]: mean_loss=0.008640307351015508
Online_Training [604/700]: mean_loss=0.02704736962914467
Online_Training [605/700]: mean_loss=0.010826811892911792
Online_Training [606/700]: mean_loss=0.0058157256280537695
Online_Training [607/700]: mean_loss=0.009005681611597538
Online_Training [608/700]: mean_loss=0.014633510378189385
Online_Training [609/700]: mean_loss=0.01122323574963957
Online_Training [610/700]: mean_loss=0.019318338250741363
Online_Training [611/700]: mean_loss=0.009370225016027689
Online_Training [612/700]: mean_loss=0.12554441578686237
Online_Training [613/700]: mean_loss=0.03640304505825043
Online_Training [614/700]: mean_loss=0.007218352577183396
Online_Training [615/700]: mean_loss=0.012035810912493616
Online_Training [616/700]: mean_loss=0.02223813976161182
Online_Training [617/700]: mean_loss=0.009619822318200022
Online_Training [618/700]: mean_loss=0.019830174278467894
Online_Training [619/700]: mean_loss=0.010293220402672887
Online_Training [620/700]: mean_loss=0.07292749965563416
Online_Training [621/700]: mean_loss=0.007383787247817963
Online_Training [622/700]: mean_loss=0.05432328162714839
Online_Training [623/700]: mean_loss=0.037696759682148695
Online_Training [624/700]: mean_loss=0.014634932391345501
Online_Training [625/700]: mean_loss=0.012964930734597147
Online_Training [626/700]: mean_loss=0.014399385428987443
Online_Training [627/700]: mean_loss=0.007263750536367297
Online_Training [628/700]: mean_loss=0.009930067928507924
Online_Training [629/700]: mean_loss=0.024057228351011872
Online_Training [630/700]: mean_loss=0.04673726297914982
Online_Training [631/700]: mean_loss=0.014109289739280939
Online_Training [632/700]: mean_loss=0.02643156098201871
Online_Training [633/700]: mean_loss=0.010535170673392713
Online_Training [634/700]: mean_loss=0.018051837687380612
Online_Training [635/700]: mean_loss=0.014640940236859024
Online_Training [636/700]: mean_loss=0.010662525368388742
Online_Training [637/700]: mean_loss=0.011250752257183194
Online_Training [638/700]: mean_loss=0.01685754698701203
Online_Training [639/700]: mean_loss=0.017177992267534137
Online_Training [640/700]: mean_loss=0.007521653431467712
Online_Training [641/700]: mean_loss=0.020417875261045992
Online_Training [642/700]: mean_loss=0.010832883650436997
Online_Training [643/700]: mean_loss=0.005042439850512892
Online_Training [644/700]: mean_loss=0.014341665548272431
Online_Training [645/700]: mean_loss=0.01495478639844805
Online_Training [646/700]: mean_loss=0.02775992057286203
Online_Training [647/700]: mean_loss=0.008855943218804896
Online_Training [648/700]: mean_loss=0.010927791357971728
Online_Training [649/700]: mean_loss=0.01071000297088176
Online_Training [650/700]: mean_loss=0.011516081518493593
Online_Training [651/700]: mean_loss=0.008394516655243933
Online_Training [652/700]: mean_loss=0.004709375149104744
Online_Training [653/700]: mean_loss=0.11271318141371012
Online_Training [654/700]: mean_loss=0.01590947003569454
Online_Training [655/700]: mean_loss=0.0209531020373106
Online_Training [656/700]: mean_loss=0.023191995918750763
Online_Training [657/700]: mean_loss=0.019393912865780294
Online_Training [658/700]: mean_loss=0.0141556829912588
Online_Training [659/700]: mean_loss=0.01149815006647259
Online_Training [660/700]: mean_loss=0.014586265082471073
Online_Training [661/700]: mean_loss=0.04128675349056721
Online_Training [662/700]: mean_loss=0.04638594901189208
Online_Training [663/700]: mean_loss=0.02173520950600505
Online_Training [664/700]: mean_loss=0.004487368278205395
Online_Training [665/700]: mean_loss=0.03676591580733657
Online_Training [666/700]: mean_loss=0.016452496172860265
Online_Training [667/700]: mean_loss=0.0053599702077917755
Online_Training [668/700]: mean_loss=0.010965301655232906
Online_Training [669/700]: mean_loss=0.009439851972274482
Online_Training [670/700]: mean_loss=0.013603300554677844
Online_Training [671/700]: mean_loss=0.011597991338931024
Online_Training [672/700]: mean_loss=0.013653835281729698
Online_Training [673/700]: mean_loss=0.012387052993290126
Online_Training [674/700]: mean_loss=0.009085485595278442
Online_Training [675/700]: mean_loss=0.009384128090459853
Online_Training [676/700]: mean_loss=0.029593664687126875
Online_Training [677/700]: mean_loss=0.04082140093669295
Online_Training [678/700]: mean_loss=0.02150526479817927
Online_Training [679/700]: mean_loss=0.01328608428593725
Online_Training [680/700]: mean_loss=0.015920338686555624
Online_Training [681/700]: mean_loss=0.017667109612375498
Online_Training [682/700]: mean_loss=0.011159986606799066
Online_Training [683/700]: mean_loss=0.006105430540628731
Online_Training [684/700]: mean_loss=0.008221111609600484
Online_Training [685/700]: mean_loss=0.028027219930663705
Online_Training [686/700]: mean_loss=0.01736367167904973
Online_Training [687/700]: mean_loss=0.012720439000986516
Online_Training [688/700]: mean_loss=0.055828222539275885
Online_Training [689/700]: mean_loss=0.010682394378818572
Online_Training [690/700]: mean_loss=0.006708814820740372
Online_Training [691/700]: mean_loss=0.010153032839298248
Online_Training [692/700]: mean_loss=0.02300298842601478
Online_Training [693/700]: mean_loss=0.0140357919735834
Online_Training [694/700]: mean_loss=0.03166688629426062
Online_Training [695/700]: mean_loss=0.011506529175676405
Online_Training [696/700]: mean_loss=0.03602662868797779
Online_Training [697/700]: mean_loss=0.004215235298033804
Online_Training [698/700]: mean_loss=0.006492763466667384
Online_Training [699/700]: mean_loss=0.0688932966440916
Online_Training [700/700]: mean_loss=0.005294394621159881
Q_Learning [1/300]: mean_loss=0.2552883978933096
Q_Learning [2/300]: mean_loss=0.22976662032306194
Q_Learning [3/300]: mean_loss=0.22506971843540668
Q_Learning [4/300]: mean_loss=0.12122792750597
Q_Learning [5/300]: mean_loss=0.28704076260328293
Q_Learning [6/300]: mean_loss=0.12845708336681128
Q_Learning [7/300]: mean_loss=0.12091985438019037
Q_Learning [8/300]: mean_loss=0.08688705042004585
Q_Learning [9/300]: mean_loss=0.15946980379521847
Q_Learning [10/300]: mean_loss=0.16399996913969517
Q_Learning [11/300]: mean_loss=0.10814343858510256
Q_Learning [12/300]: mean_loss=0.09953154064714909
Q_Learning [13/300]: mean_loss=0.09514246694743633
Q_Learning [14/300]: mean_loss=0.04934797575697303
Q_Learning [15/300]: mean_loss=0.08022840414196253
Q_Learning [16/300]: mean_loss=0.13064605183899403
Q_Learning [17/300]: mean_loss=0.08908908814191818
Q_Learning [18/300]: mean_loss=0.04687974322587252
Q_Learning [19/300]: mean_loss=0.031451452523469925
Q_Learning [20/300]: mean_loss=0.14545702561736107
Q_Learning [21/300]: mean_loss=0.1395593024790287
Q_Learning [22/300]: mean_loss=0.012646196992136538
Q_Learning [23/300]: mean_loss=0.021824572002515197
Q_Learning [24/300]: mean_loss=0.07959788292646408
Q_Learning [25/300]: mean_loss=0.03292748099192977
Q_Learning [26/300]: mean_loss=0.05174430459737778
Q_Learning [27/300]: mean_loss=0.10374625585973263
Q_Learning [28/300]: mean_loss=0.03885330259799957
Q_Learning [29/300]: mean_loss=0.046401276253163815
Q_Learning [30/300]: mean_loss=0.031450042966753244
Q_Learning [31/300]: mean_loss=0.024241893086582422
Q_Learning [32/300]: mean_loss=0.04139364184811711
Q_Learning [33/300]: mean_loss=0.023631445365026593
Q_Learning [34/300]: mean_loss=0.1469589602202177
Q_Learning [35/300]: mean_loss=0.05197482882067561
Q_Learning [36/300]: mean_loss=0.0814158609136939
Q_Learning [37/300]: mean_loss=0.05412867618724704
Q_Learning [38/300]: mean_loss=0.036111867520958185
Q_Learning [39/300]: mean_loss=0.12070315983146429
Q_Learning [40/300]: mean_loss=0.03277387865819037
Q_Learning [41/300]: mean_loss=0.027623641537502408
Q_Learning [42/300]: mean_loss=0.05250585777685046
Q_Learning [43/300]: mean_loss=0.11907144077122211
Q_Learning [44/300]: mean_loss=0.14509517326951027
Q_Learning [45/300]: mean_loss=0.07270545419305563
Q_Learning [46/300]: mean_loss=0.046979626175016165
Q_Learning [47/300]: mean_loss=0.078167580999434
Q_Learning [48/300]: mean_loss=0.0676924204453826
Q_Learning [49/300]: mean_loss=0.08494355622678995
Q_Learning [50/300]: mean_loss=0.10668423119932413
Q_Learning [51/300]: mean_loss=0.028199052205309272
Q_Learning [52/300]: mean_loss=0.1459998581558466
Q_Learning [53/300]: mean_loss=0.018891135463491082
Q_Learning [54/300]: mean_loss=0.06790526304394007
Q_Learning [55/300]: mean_loss=0.04443673603236675
Q_Learning [56/300]: mean_loss=0.035335867665708065
Q_Learning [57/300]: mean_loss=0.09183742105960846
Q_Learning [58/300]: mean_loss=0.2970467135310173
Q_Learning [59/300]: mean_loss=0.053709684405475855
Q_Learning [60/300]: mean_loss=0.05562354018911719
Q_Learning [61/300]: mean_loss=0.03326039016246796
Q_Learning [62/300]: mean_loss=0.06800908921286464
Q_Learning [63/300]: mean_loss=0.057296188082545996
Q_Learning [64/300]: mean_loss=0.004832714446820319
Q_Learning [65/300]: mean_loss=0.06398387812077999
Q_Learning [66/300]: mean_loss=0.035841130651533604
Q_Learning [67/300]: mean_loss=0.056338606402277946
Q_Learning [68/300]: mean_loss=0.05534483306109905
Q_Learning [69/300]: mean_loss=0.11380200367420912
Q_Learning [70/300]: mean_loss=0.042010541539639235
Q_Learning [71/300]: mean_loss=0.07121909316629171
Q_Learning [72/300]: mean_loss=0.07938765361905098
Q_Learning [73/300]: mean_loss=0.03813335159793496
Q_Learning [74/300]: mean_loss=0.037845435086637735
Q_Learning [75/300]: mean_loss=0.03229547757655382
Q_Learning [76/300]: mean_loss=0.024661474162712693
Q_Learning [77/300]: mean_loss=0.04625905677676201
Q_Learning [78/300]: mean_loss=0.03691170457750559
Q_Learning [79/300]: mean_loss=0.04037239961326122
Q_Learning [80/300]: mean_loss=0.03740033321082592
Q_Learning [81/300]: mean_loss=0.01629210775718093
Q_Learning [82/300]: mean_loss=0.028069075429812074
Q_Learning [83/300]: mean_loss=0.054627795703709126
Q_Learning [84/300]: mean_loss=0.0358822587877512
Q_Learning [85/300]: mean_loss=0.026314881164580584
Q_Learning [86/300]: mean_loss=0.03796132607385516
Q_Learning [87/300]: mean_loss=0.019582994980737567
Q_Learning [88/300]: mean_loss=0.029509012354537845
Q_Learning [89/300]: mean_loss=0.044738228898495436
Q_Learning [90/300]: mean_loss=0.019064915366470814
Q_Learning [91/300]: mean_loss=0.03619997017085552
Q_Learning [92/300]: mean_loss=0.03481025900691748
Q_Learning [93/300]: mean_loss=0.03158431872725487
Q_Learning [94/300]: mean_loss=0.04711929056793451
Q_Learning [95/300]: mean_loss=0.04287401167675853
Q_Learning [96/300]: mean_loss=0.02009435452055186
Q_Learning [97/300]: mean_loss=0.042708320543169975
Q_Learning [98/300]: mean_loss=0.05406240466982126
Q_Learning [99/300]: mean_loss=0.02001871168613434
Q_Learning [100/300]: mean_loss=0.06689232448115945
Q_Learning [101/300]: mean_loss=0.022942880867049098
Q_Learning [102/300]: mean_loss=0.04996134154498577
Q_Learning [103/300]: mean_loss=0.03877719957381487
Q_Learning [104/300]: mean_loss=0.0464032250456512
Q_Learning [105/300]: mean_loss=0.031880850438028574
Q_Learning [106/300]: mean_loss=0.012905290815979242
Q_Learning [107/300]: mean_loss=0.01347701286431402
Q_Learning [108/300]: mean_loss=0.02350634103640914
Q_Learning [109/300]: mean_loss=0.037583790719509125
Q_Learning [110/300]: mean_loss=0.022689100820571184
Q_Learning [111/300]: mean_loss=0.03760930569842458
Q_Learning [112/300]: mean_loss=0.16229057125747204
Q_Learning [113/300]: mean_loss=0.0211934766266495
Q_Learning [114/300]: mean_loss=0.027394537581130862
Q_Learning [115/300]: mean_loss=0.05872568069025874
Q_Learning [116/300]: mean_loss=0.027764646103605628
Q_Learning [117/300]: mean_loss=0.07434019446372986
Q_Learning [118/300]: mean_loss=0.04149142326787114
Q_Learning [119/300]: mean_loss=0.12653230782598257
Q_Learning [120/300]: mean_loss=0.07040953123942018
Q_Learning [121/300]: mean_loss=0.047227027360349894
Q_Learning [122/300]: mean_loss=0.06731678498908877
Q_Learning [123/300]: mean_loss=0.05009429808706045
Q_Learning [124/300]: mean_loss=0.025838227476924658
Q_Learning [125/300]: mean_loss=0.08240267727524042
Q_Learning [126/300]: mean_loss=0.051920919213443995
Q_Learning [127/300]: mean_loss=0.054394956678152084
Q_Learning [128/300]: mean_loss=0.03300378331914544
Q_Learning [129/300]: mean_loss=0.03388466825708747
Q_Learning [130/300]: mean_loss=0.01888988632708788
Q_Learning [131/300]: mean_loss=0.03154331166297197
Q_Learning [132/300]: mean_loss=0.018322194810025394
Q_Learning [133/300]: mean_loss=0.024226349079981446
Q_Learning [134/300]: mean_loss=0.022796672536060214
Q_Learning [135/300]: mean_loss=0.12368512712419033
Q_Learning [136/300]: mean_loss=0.018010842381045222
Q_Learning [137/300]: mean_loss=0.023844508454203606
Q_Learning [138/300]: mean_loss=0.014445340377278626
Q_Learning [139/300]: mean_loss=0.020608540158718824
Q_Learning [140/300]: mean_loss=0.03173992573283613
Q_Learning [141/300]: mean_loss=0.028948391787707806
Q_Learning [142/300]: mean_loss=0.010180251323617995
Q_Learning [143/300]: mean_loss=0.019242471316829324
Q_Learning [144/300]: mean_loss=0.0170979913091287
Q_Learning [145/300]: mean_loss=0.027049827156588435
Q_Learning [146/300]: mean_loss=0.02183999167755246
Q_Learning [147/300]: mean_loss=0.01947544072754681
Q_Learning [148/300]: mean_loss=0.047912666108459234
Q_Learning [149/300]: mean_loss=0.11068938206881285
Q_Learning [150/300]: mean_loss=0.08900416642427444
Q_Learning [151/300]: mean_loss=0.05243745120242238
Q_Learning [152/300]: mean_loss=0.022847232641652226
Q_Learning [153/300]: mean_loss=0.022137587191537023
Q_Learning [154/300]: mean_loss=0.017125439830124378
Q_Learning [155/300]: mean_loss=0.015570280607789755
Q_Learning [156/300]: mean_loss=0.017774978070519865
Q_Learning [157/300]: mean_loss=0.09243614319711924
Q_Learning [158/300]: mean_loss=0.0062699923873879015
Q_Learning [159/300]: mean_loss=0.022088923025876284
Q_Learning [160/300]: mean_loss=0.019906396744772792
Q_Learning [161/300]: mean_loss=0.022535095689818263
Q_Learning [162/300]: mean_loss=0.017381656332872808
Q_Learning [163/300]: mean_loss=0.058676311280578375
Q_Learning [164/300]: mean_loss=0.014190204092301428
Q_Learning [165/300]: mean_loss=0.012024549534544349
Q_Learning [166/300]: mean_loss=0.02266444033011794
Q_Learning [167/300]: mean_loss=0.03844613954424858
Q_Learning [168/300]: mean_loss=0.04323932249099016
Q_Learning [169/300]: mean_loss=0.05555486539378762
Q_Learning [170/300]: mean_loss=0.16704891435801983
Q_Learning [171/300]: mean_loss=0.021092277951538563
Q_Learning [172/300]: mean_loss=0.017243578797206283
Q_Learning [173/300]: mean_loss=0.01718871109187603
Q_Learning [174/300]: mean_loss=0.013382073142565787
Q_Learning [175/300]: mean_loss=0.011711670085787773
Q_Learning [176/300]: mean_loss=0.009306109335739166
Q_Learning [177/300]: mean_loss=0.031511085806414485
Q_Learning [178/300]: mean_loss=0.04220095416530967
Q_Learning [179/300]: mean_loss=0.015321797924116254
Q_Learning [180/300]: mean_loss=0.030836620135232806
Q_Learning [181/300]: mean_loss=0.03183895815163851
Q_Learning [182/300]: mean_loss=0.03035757807083428
Q_Learning [183/300]: mean_loss=0.012804914964362979
Q_Learning [184/300]: mean_loss=0.006967096880543977
Q_Learning [185/300]: mean_loss=0.032156379194930196
Q_Learning [186/300]: mean_loss=0.025225196266546845
Q_Learning [187/300]: mean_loss=0.028931478038430214
Q_Learning [188/300]: mean_loss=0.02221557917073369
Q_Learning [189/300]: mean_loss=0.048450042493641376
Q_Learning [190/300]: mean_loss=0.025713206734508276
Q_Learning [191/300]: mean_loss=0.14275296032428741
Q_Learning [192/300]: mean_loss=0.025348234688863158
Q_Learning [193/300]: mean_loss=0.023102912353351712
Q_Learning [194/300]: mean_loss=0.018283806857652962
Q_Learning [195/300]: mean_loss=0.023937822552397847
Q_Learning [196/300]: mean_loss=0.012777274241670966
Q_Learning [197/300]: mean_loss=0.045838531106710434
Q_Learning [198/300]: mean_loss=0.014079205342568457
Q_Learning [199/300]: mean_loss=0.08319109678268433
Q_Learning [200/300]: mean_loss=0.013351524015888572
Q_Learning [201/300]: mean_loss=0.03437918238341808
Q_Learning [202/300]: mean_loss=0.012721158214844763
Q_Learning [203/300]: mean_loss=0.012249193852767348
Q_Learning [204/300]: mean_loss=0.009608971944544464
Q_Learning [205/300]: mean_loss=0.07304266840219498
Q_Learning [206/300]: mean_loss=0.015900178696028888
Q_Learning [207/300]: mean_loss=0.03785746870562434
Q_Learning [208/300]: mean_loss=0.03986602649092674
Q_Learning [209/300]: mean_loss=0.05094029847532511
Q_Learning [210/300]: mean_loss=0.01992702088318765
Q_Learning [211/300]: mean_loss=0.024974243016913533
Q_Learning [212/300]: mean_loss=0.09191734902560711
Q_Learning [213/300]: mean_loss=0.05058034183457494
Q_Learning [214/300]: mean_loss=0.013330625020898879
Q_Learning [215/300]: mean_loss=0.03005445539020002
Q_Learning [216/300]: mean_loss=0.034542267909273505
Q_Learning [217/300]: mean_loss=0.013258405146189034
Q_Learning [218/300]: mean_loss=0.009023215039633214
Q_Learning [219/300]: mean_loss=0.056548445019870996
Q_Learning [220/300]: mean_loss=0.011194653809070587
Q_Learning [221/300]: mean_loss=0.03170457459054887
Q_Learning [222/300]: mean_loss=0.02148700342513621
Q_Learning [223/300]: mean_loss=0.033546541817486286
Q_Learning [224/300]: mean_loss=0.00761348835658282
Q_Learning [225/300]: mean_loss=0.030196363339200616
Q_Learning [226/300]: mean_loss=0.027919747168198228
Q_Learning [227/300]: mean_loss=0.01458032091613859
Q_Learning [228/300]: mean_loss=0.02801833557896316
Q_Learning [229/300]: mean_loss=0.050250232219696045
Q_Learning [230/300]: mean_loss=0.0217470598872751
Q_Learning [231/300]: mean_loss=0.021394897950813174
Q_Learning [232/300]: mean_loss=0.02415493200533092
Q_Learning [233/300]: mean_loss=0.021695253206416965
Q_Learning [234/300]: mean_loss=0.05416404129937291
Q_Learning [235/300]: mean_loss=0.1044804286211729
Q_Learning [236/300]: mean_loss=0.05876186955720186
Q_Learning [237/300]: mean_loss=0.018580940319225192
Q_Learning [238/300]: mean_loss=0.1136702224612236
Q_Learning [239/300]: mean_loss=0.10712888278067112
Q_Learning [240/300]: mean_loss=0.07298769569024444
Q_Learning [241/300]: mean_loss=0.04666984640061855
Q_Learning [242/300]: mean_loss=0.02559027192182839
Q_Learning [243/300]: mean_loss=0.040986467618495226
Q_Learning [244/300]: mean_loss=0.038605859968811274
Q_Learning [245/300]: mean_loss=0.053151128347963095
Q_Learning [246/300]: mean_loss=0.03161409986205399
Q_Learning [247/300]: mean_loss=0.013340933830477297
Q_Learning [248/300]: mean_loss=0.07132890820503235
Q_Learning [249/300]: mean_loss=0.0219427146948874
Q_Learning [250/300]: mean_loss=0.014827769715338945
Q_Learning [251/300]: mean_loss=0.02242153394035995
Q_Learning [252/300]: mean_loss=0.011109266895800829
Q_Learning [253/300]: mean_loss=0.016264253994449973
Q_Learning [254/300]: mean_loss=0.024303963407874107
Q_Learning [255/300]: mean_loss=0.04162244452163577
Q_Learning [256/300]: mean_loss=0.01372297597117722
Q_Learning [257/300]: mean_loss=0.026543043786659837
Q_Learning [258/300]: mean_loss=0.011457644868642092
Q_Learning [259/300]: mean_loss=0.012402786873281002
Q_Learning [260/300]: mean_loss=0.017234964994713664
Q_Learning [261/300]: mean_loss=0.027843499556183815
Q_Learning [262/300]: mean_loss=0.03076352016068995
Q_Learning [263/300]: mean_loss=0.012228063424117863
Q_Learning [264/300]: mean_loss=0.012124946806579828
Q_Learning [265/300]: mean_loss=0.020865051541477442
Q_Learning [266/300]: mean_loss=0.01601539447437972
Q_Learning [267/300]: mean_loss=0.015160539420321584
Q_Learning [268/300]: mean_loss=0.009594444301910698
Q_Learning [269/300]: mean_loss=0.01954023726284504
Q_Learning [270/300]: mean_loss=0.009395002736710012
Q_Learning [271/300]: mean_loss=0.02866403223015368
Q_Learning [272/300]: mean_loss=0.005913364642765373
Q_Learning [273/300]: mean_loss=0.011513469042256474
Q_Learning [274/300]: mean_loss=0.018134953686967492
Q_Learning [275/300]: mean_loss=0.01492672972381115
Q_Learning [276/300]: mean_loss=0.021164578152820468
Q_Learning [277/300]: mean_loss=0.03655027993954718
Q_Learning [278/300]: mean_loss=0.015482785529457033
Q_Learning [279/300]: mean_loss=0.022399025037884712
Q_Learning [280/300]: mean_loss=0.02149715879932046
Q_Learning [281/300]: mean_loss=0.024373096181079745
Q_Learning [282/300]: mean_loss=0.03379183844663203
Q_Learning [283/300]: mean_loss=0.01972681563347578
Q_Learning [284/300]: mean_loss=0.02175714331679046
Q_Learning [285/300]: mean_loss=0.016340026864781976
Q_Learning [286/300]: mean_loss=0.023402366088703275
Q_Learning [287/300]: mean_loss=0.013581721461378038
Q_Learning [288/300]: mean_loss=0.012245155638083816
Q_Learning [289/300]: mean_loss=0.0432213107123971
Q_Learning [290/300]: mean_loss=0.005125489813508466
Q_Learning [291/300]: mean_loss=0.006762516277376562
Q_Learning [292/300]: mean_loss=0.0070576457073912024
Q_Learning [293/300]: mean_loss=0.012831259984523058
Q_Learning [294/300]: mean_loss=0.019795219646766782
Q_Learning [295/300]: mean_loss=0.03377704066224396
Q_Learning [296/300]: mean_loss=0.03919263789430261
Q_Learning [297/300]: mean_loss=0.01906369929201901
Q_Learning [298/300]: mean_loss=0.015732458559796214
Q_Learning [299/300]: mean_loss=0.032854815013706684
Q_Learning [300/300]: mean_loss=0.04528001416474581
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 0.79512143 -0.20776814]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 2, 2, 0, 1, 1, 0, 2, 2, 2, 0, 0, 1, 2, 1, 2, 1, 0, 0, 1, 0, 2, 0, 1, 0, 0, 1, 2, 2, 0, 1, 2, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 0, 2, 2, 1, 2, 1, 0, 0, 0, 1, 2, 1, 2, 0, 2, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 0, 2, 2, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2, 0, 1, 2, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 0, 2, 1, 2, 2, 1, 0, 2, 1, 1, 3, 1, 1, 0, 1, 2, 0, 2, 2, 0, 1, 2, 2, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 2, 0, 2, 2, 2, 1, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 2, 1, 1, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 2, 1, 2, 1, 0, 0, 1, 1, 3, 3, 2, 3, 0, 0, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 1, 2, 1, 0, 2, 2, 0, 3, 2, 2, 4, 5, 2, 2, 2, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 0, 5, 2, 2, 1, 2, 1, 2, 2, 1, 0, 1, 0, 0, 2, 3, 5, 0, 0, 2, 4, 3, 0, 4, 1, 0, 5, 2, 3, 3, 0, 1, 1, 0, 0, 1, 2, 3, 2, 3]
Centroids: [[0.09825854, 1.6414669], [0.13235542, 0.95176524], [0.81133217, -0.22562909]]
Centroids: [[0.7970637, -0.20673484], [-0.03740811, 1.5874946], [0.28521678, 0.8463093], [-0.2416326, 2.3035038], [0.81397074, 1.6672543], [1.4972947, -0.44257784]]
Contingency Matrix: 
[[ 2 74 15  9  3  0]
 [ 0 26 72  2  0  0]
 [92  0  1  0  0  4]]
[[2, 74, 15, 9, 3, 0], [0, 26, 72, 2, 0, 0], [92, 0, 1, 0, 0, 4]]
[[2, 74, 15, 9, 3, 0], [0, 26, 72, 2, 0, 0], [92, 0, 1, 0, 0, 4]]
[0, 1, 2, 3, 4, 5]
[[-1, 74, 15, 9, 3, 0], [-1, 26, 72, 2, 0, 0], [-1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, 72, 2, 0, 0], [-1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
Match_Labels: {2: 0, 0: 1, 1: 2}
New Contingency Matrix: 
[[74 15  2  9  3  0]
 [26 72  0  2  0  0]
 [ 0  1 92  0  0  4]]
New Clustered Label Sequence: [1, 2, 0, 3, 4, 5]
Diagonal_Elements: [74, 72, 92], Sum: 238
All_Elements: [74, 15, 2, 9, 3, 0, 26, 72, 0, 2, 0, 0, 0, 1, 92, 0, 0, 4], Sum: 300
Accuracy: 0.7933333333333333
