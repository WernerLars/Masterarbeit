Experiment_path: Random_Seeds_DV5//V5_2/Experiment_05_6_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: Random_Seeds_DV5//V5_2/Experiment_05_6_opt_temp/C_Difficult1_noise005.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_04_16-16_17_00
Punishment_Coefficient: 0.3
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001B55FF507B8>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.18021232448518276
Online_Training [2/700]: mean_loss=0.10341162886470556
Online_Training [3/700]: mean_loss=0.19971590489149094
Online_Training [4/700]: mean_loss=0.15200127847492695
Online_Training [5/700]: mean_loss=0.10667937435209751
Online_Training [6/700]: mean_loss=0.18411065079271793
Online_Training [7/700]: mean_loss=0.08881805557757616
Online_Training [8/700]: mean_loss=0.08341440185904503
Online_Training [9/700]: mean_loss=0.09850034024566412
Online_Training [10/700]: mean_loss=0.08075298741459846
Online_Training [11/700]: mean_loss=0.07892259117215872
Online_Training [12/700]: mean_loss=0.0808995645493269
Online_Training [13/700]: mean_loss=0.07965847291052341
Online_Training [14/700]: mean_loss=0.07483293674886227
Online_Training [15/700]: mean_loss=0.1458062157034874
Online_Training [16/700]: mean_loss=0.06433899700641632
Online_Training [17/700]: mean_loss=0.1466954629868269
Online_Training [18/700]: mean_loss=0.05696294503286481
Online_Training [19/700]: mean_loss=0.06666036881506443
Online_Training [20/700]: mean_loss=0.05722567206248641
Online_Training [21/700]: mean_loss=0.05308885034173727
Online_Training [22/700]: mean_loss=0.19097109511494637
Online_Training [23/700]: mean_loss=0.22030334547162056
Online_Training [24/700]: mean_loss=0.059434106573462486
Online_Training [25/700]: mean_loss=0.09911301545798779
Online_Training [26/700]: mean_loss=0.04438965627923608
Online_Training [27/700]: mean_loss=0.10564241744577885
Online_Training [28/700]: mean_loss=0.0391640355810523
Online_Training [29/700]: mean_loss=0.05009417003020644
Online_Training [30/700]: mean_loss=0.042259661480784416
Online_Training [31/700]: mean_loss=0.04972227616235614
Online_Training [32/700]: mean_loss=0.037011707201600075
Online_Training [33/700]: mean_loss=0.034201203379780054
Online_Training [34/700]: mean_loss=0.042105776723474264
Online_Training [35/700]: mean_loss=0.13598265685141087
Online_Training [36/700]: mean_loss=0.09907681215554476
Online_Training [37/700]: mean_loss=0.027373338118195534
Online_Training [38/700]: mean_loss=0.05790393287315965
Online_Training [39/700]: mean_loss=0.03703470854088664
Online_Training [40/700]: mean_loss=0.01838541286997497
Online_Training [41/700]: mean_loss=0.027051578275859356
Online_Training [42/700]: mean_loss=0.05474056350067258
Online_Training [43/700]: mean_loss=0.02360197645612061
Online_Training [44/700]: mean_loss=0.019136497052386403
Online_Training [45/700]: mean_loss=0.029516967944800854
Online_Training [46/700]: mean_loss=0.04943325975909829
Online_Training [47/700]: mean_loss=0.2239616084843874
Online_Training [48/700]: mean_loss=0.17600279301404953
Online_Training [49/700]: mean_loss=0.28495488688349724
Online_Training [50/700]: mean_loss=0.021162816556170583
Online_Training [51/700]: mean_loss=0.028023005230352283
Online_Training [52/700]: mean_loss=0.03629739675670862
Online_Training [53/700]: mean_loss=0.014502700068987906
Online_Training [54/700]: mean_loss=0.017291065771132708
Online_Training [55/700]: mean_loss=0.015654698945581913
Online_Training [56/700]: mean_loss=0.016781947808340192
Online_Training [57/700]: mean_loss=0.012680815067142248
Online_Training [58/700]: mean_loss=0.04790715826675296
Online_Training [59/700]: mean_loss=0.024837369564920664
Online_Training [60/700]: mean_loss=0.009365454432554543
Online_Training [61/700]: mean_loss=0.026854787953197956
Online_Training [62/700]: mean_loss=0.008649516967125237
Online_Training [63/700]: mean_loss=0.013159775990061462
Online_Training [64/700]: mean_loss=0.00588131818221882
Online_Training [65/700]: mean_loss=0.017491614446043968
Online_Training [66/700]: mean_loss=0.00621173222316429
Online_Training [67/700]: mean_loss=0.011026927037164569
Online_Training [68/700]: mean_loss=0.01805384852923453
Online_Training [69/700]: mean_loss=0.016086993273347616
Online_Training [70/700]: mean_loss=0.011407707585021853
Online_Training [71/700]: mean_loss=0.005654377106111497
Online_Training [72/700]: mean_loss=0.0034855697595048696
Online_Training [73/700]: mean_loss=0.01005581149365753
Online_Training [74/700]: mean_loss=0.011192487785592675
Online_Training [75/700]: mean_loss=0.017651770962402225
Online_Training [76/700]: mean_loss=0.013674817746505141
Online_Training [77/700]: mean_loss=0.01020326477009803
Online_Training [78/700]: mean_loss=0.01445514929946512
Online_Training [79/700]: mean_loss=0.005366325844079256
Online_Training [80/700]: mean_loss=0.008396242512390018
Online_Training [81/700]: mean_loss=0.00802833162015304
Online_Training [82/700]: mean_loss=0.004931313975248486
Online_Training [83/700]: mean_loss=0.018783305771648884
Online_Training [84/700]: mean_loss=0.01940053142607212
Online_Training [85/700]: mean_loss=0.04183902870863676
Online_Training [86/700]: mean_loss=0.028125681914389133
Online_Training [87/700]: mean_loss=0.012865319149568677
Online_Training [88/700]: mean_loss=0.009102601557970047
Online_Training [89/700]: mean_loss=0.01974943862296641
Online_Training [90/700]: mean_loss=0.02249572635628283
Online_Training [91/700]: mean_loss=0.019614620367065072
Online_Training [92/700]: mean_loss=0.009404786163941026
Online_Training [93/700]: mean_loss=0.013508914038538933
Online_Training [94/700]: mean_loss=0.007286144013050944
Online_Training [95/700]: mean_loss=0.011447300668805838
Online_Training [96/700]: mean_loss=0.009063020930625498
Online_Training [97/700]: mean_loss=0.014755528420209885
Online_Training [98/700]: mean_loss=0.05846384074538946
Online_Training [99/700]: mean_loss=0.013078261050395668
Online_Training [100/700]: mean_loss=0.009573645773343742
Online_Training [101/700]: mean_loss=0.013696919195353985
Online_Training [102/700]: mean_loss=0.008966137771494687
Online_Training [103/700]: mean_loss=0.020419850246980786
Online_Training [104/700]: mean_loss=0.010161206242628396
Online_Training [105/700]: mean_loss=0.015140781062655151
Online_Training [106/700]: mean_loss=0.012686894508078694
Online_Training [107/700]: mean_loss=0.006823212490417063
Online_Training [108/700]: mean_loss=0.0067222361685708165
Online_Training [109/700]: mean_loss=0.00678451859857887
Online_Training [110/700]: mean_loss=0.014286128687672317
Online_Training [111/700]: mean_loss=0.00807819067267701
Online_Training [112/700]: mean_loss=0.008306571224238724
Online_Training [113/700]: mean_loss=0.013091938104480505
Online_Training [114/700]: mean_loss=0.016886676428839564
Online_Training [115/700]: mean_loss=0.009835562319494784
Online_Training [116/700]: mean_loss=0.00993594597093761
Online_Training [117/700]: mean_loss=0.008442496065981686
Online_Training [118/700]: mean_loss=0.015832879929803312
Online_Training [119/700]: mean_loss=0.013352737994864583
Online_Training [120/700]: mean_loss=0.020343300187960267
Online_Training [121/700]: mean_loss=0.0058683271636255085
Online_Training [122/700]: mean_loss=0.015594976139254868
Online_Training [123/700]: mean_loss=0.008904441026970744
Online_Training [124/700]: mean_loss=0.011574337957426906
Online_Training [125/700]: mean_loss=0.01080671779345721
Online_Training [126/700]: mean_loss=0.015758931753225625
Online_Training [127/700]: mean_loss=0.009302621590904891
Online_Training [128/700]: mean_loss=0.00799498672131449
Online_Training [129/700]: mean_loss=0.005575954623054713
Online_Training [130/700]: mean_loss=0.007422110938932747
Online_Training [131/700]: mean_loss=0.01267135830130428
Online_Training [132/700]: mean_loss=0.017450839281082153
Online_Training [133/700]: mean_loss=0.0856594992801547
Online_Training [134/700]: mean_loss=0.07792921178042889
Online_Training [135/700]: mean_loss=0.006593988859094679
Online_Training [136/700]: mean_loss=0.017671352019533515
Online_Training [137/700]: mean_loss=0.012771758018061519
Online_Training [138/700]: mean_loss=0.01571004162542522
Online_Training [139/700]: mean_loss=0.019736363319680095
Online_Training [140/700]: mean_loss=0.01838401099666953
Online_Training [141/700]: mean_loss=0.012868740479461849
Online_Training [142/700]: mean_loss=0.009333572466857731
Online_Training [143/700]: mean_loss=0.013936558039858937
Online_Training [144/700]: mean_loss=0.013784307753667235
Online_Training [145/700]: mean_loss=0.01342438394203782
Online_Training [146/700]: mean_loss=0.014163083862513304
Online_Training [147/700]: mean_loss=0.01964378892444074
Online_Training [148/700]: mean_loss=0.033770994283258915
Online_Training [149/700]: mean_loss=0.009484173264354467
Online_Training [150/700]: mean_loss=0.018078405410051346
Online_Training [151/700]: mean_loss=0.005954720138106495
Online_Training [152/700]: mean_loss=0.01541518501471728
Online_Training [153/700]: mean_loss=0.013605373911559582
Online_Training [154/700]: mean_loss=0.013176335953176022
Online_Training [155/700]: mean_loss=0.010821192874573171
Online_Training [156/700]: mean_loss=0.0066454599145799875
Online_Training [157/700]: mean_loss=0.007520063722040504
Online_Training [158/700]: mean_loss=0.009333763387985528
Online_Training [159/700]: mean_loss=0.015732345287688076
Online_Training [160/700]: mean_loss=0.00798360537737608
Online_Training [161/700]: mean_loss=0.012715969467535615
Online_Training [162/700]: mean_loss=0.006279485183767974
Online_Training [163/700]: mean_loss=0.022293918067589402
Online_Training [164/700]: mean_loss=0.0071995307225733995
Online_Training [165/700]: mean_loss=0.009370214771479368
Online_Training [166/700]: mean_loss=0.024982244009152055
Online_Training [167/700]: mean_loss=0.013335120282135904
Online_Training [168/700]: mean_loss=0.012330542551353574
Online_Training [169/700]: mean_loss=0.009357117465697229
Online_Training [170/700]: mean_loss=0.009855866199359298
Online_Training [171/700]: mean_loss=0.005717977648600936
Online_Training [172/700]: mean_loss=0.009619261720217764
Online_Training [173/700]: mean_loss=0.013775462750345469
Online_Training [174/700]: mean_loss=0.004717089585028589
Online_Training [175/700]: mean_loss=0.005585215403698385
Online_Training [176/700]: mean_loss=0.014184164465405047
Online_Training [177/700]: mean_loss=0.005049457133281976
Online_Training [178/700]: mean_loss=0.0606786054559052
Online_Training [179/700]: mean_loss=0.04021246964111924
Online_Training [180/700]: mean_loss=0.02710756892338395
Online_Training [181/700]: mean_loss=0.06312032463029027
Online_Training [182/700]: mean_loss=0.04455539118498564
Online_Training [183/700]: mean_loss=0.012142485822550952
Online_Training [184/700]: mean_loss=0.008677811361849308
Online_Training [185/700]: mean_loss=0.011954594869166613
Online_Training [186/700]: mean_loss=0.005064089898951352
Online_Training [187/700]: mean_loss=0.012926840572617948
Online_Training [188/700]: mean_loss=0.018212083261460066
Online_Training [189/700]: mean_loss=0.009384827455505729
Online_Training [190/700]: mean_loss=0.006027803348843008
Online_Training [191/700]: mean_loss=0.09122754912823439
Online_Training [192/700]: mean_loss=0.022971372352913022
Online_Training [193/700]: mean_loss=0.006591029814444482
Online_Training [194/700]: mean_loss=0.034032643074169755
Online_Training [195/700]: mean_loss=0.019715142203494906
Online_Training [196/700]: mean_loss=0.02132317377254367
Online_Training [197/700]: mean_loss=0.015499180881306529
Online_Training [198/700]: mean_loss=0.009634720510803163
Online_Training [199/700]: mean_loss=0.019036487210541964
Online_Training [200/700]: mean_loss=0.006374180200509727
Online_Training [201/700]: mean_loss=0.009420400601811707
Online_Training [202/700]: mean_loss=0.010337744024582207
Online_Training [203/700]: mean_loss=0.010102310916408896
Online_Training [204/700]: mean_loss=0.011899666744284332
Online_Training [205/700]: mean_loss=0.021139180986210704
Online_Training [206/700]: mean_loss=0.007604071230161935
Online_Training [207/700]: mean_loss=0.007233086682390422
Online_Training [208/700]: mean_loss=0.0025978418125305325
Online_Training [209/700]: mean_loss=0.00248336503864266
Online_Training [210/700]: mean_loss=0.011408920050598681
Online_Training [211/700]: mean_loss=0.020221201237291098
Online_Training [212/700]: mean_loss=0.012548734317533672
Online_Training [213/700]: mean_loss=0.007531773648224771
Online_Training [214/700]: mean_loss=0.009996662614867091
Online_Training [215/700]: mean_loss=0.006463101657573134
Online_Training [216/700]: mean_loss=0.007157781219575554
Online_Training [217/700]: mean_loss=0.010225880541838706
Online_Training [218/700]: mean_loss=0.010920273372903466
Online_Training [219/700]: mean_loss=0.010234216344542801
Online_Training [220/700]: mean_loss=0.017632232513278723
Online_Training [221/700]: mean_loss=0.0213085375726223
Online_Training [222/700]: mean_loss=0.010311939753592014
Online_Training [223/700]: mean_loss=0.022851467365399003
Online_Training [224/700]: mean_loss=0.08974862843751907
Online_Training [225/700]: mean_loss=0.12868556194007397
Online_Training [226/700]: mean_loss=0.01103446667548269
Online_Training [227/700]: mean_loss=0.014779549557715654
Online_Training [228/700]: mean_loss=0.01614263723604381
Online_Training [229/700]: mean_loss=0.009623859892599285
Online_Training [230/700]: mean_loss=0.012371797463856637
Online_Training [231/700]: mean_loss=0.07527509424835443
Online_Training [232/700]: mean_loss=0.03931577783077955
Online_Training [233/700]: mean_loss=0.0849011866375804
Online_Training [234/700]: mean_loss=0.14197920076549053
Online_Training [235/700]: mean_loss=0.01421434711664915
Online_Training [236/700]: mean_loss=0.014457594021223485
Online_Training [237/700]: mean_loss=0.021404074039310217
Online_Training [238/700]: mean_loss=0.015410819556564093
Online_Training [239/700]: mean_loss=0.01676850114017725
Online_Training [240/700]: mean_loss=0.0064253731979988515
Online_Training [241/700]: mean_loss=0.014186687651090324
Online_Training [242/700]: mean_loss=0.016756029799580574
Online_Training [243/700]: mean_loss=0.014206737629137933
Online_Training [244/700]: mean_loss=0.018790509784594178
Online_Training [245/700]: mean_loss=0.006014714250341058
Online_Training [246/700]: mean_loss=0.005064877157565206
Online_Training [247/700]: mean_loss=0.007821230101399124
Online_Training [248/700]: mean_loss=0.019973498536273837
Online_Training [249/700]: mean_loss=0.009576845681294799
Online_Training [250/700]: mean_loss=0.011905686114914715
Online_Training [251/700]: mean_loss=0.069158049300313
Online_Training [252/700]: mean_loss=0.04611649177968502
Online_Training [253/700]: mean_loss=0.0084677969571203
Online_Training [254/700]: mean_loss=0.00674940092721954
Online_Training [255/700]: mean_loss=0.008437257842160761
Online_Training [256/700]: mean_loss=0.017277485225349665
Online_Training [257/700]: mean_loss=0.00487540423637256
Online_Training [258/700]: mean_loss=0.006808284670114517
Online_Training [259/700]: mean_loss=0.006719535333104432
Online_Training [260/700]: mean_loss=0.01662755198776722
Online_Training [261/700]: mean_loss=0.012858857517130673
Online_Training [262/700]: mean_loss=0.0088875851361081
Online_Training [263/700]: mean_loss=0.009493146440945566
Online_Training [264/700]: mean_loss=0.011977485148236156
Online_Training [265/700]: mean_loss=0.1454027947038412
Online_Training [266/700]: mean_loss=0.10986300278455019
Online_Training [267/700]: mean_loss=0.010497242910787463
Online_Training [268/700]: mean_loss=0.010862195631489158
Online_Training [269/700]: mean_loss=0.004046623886097223
Online_Training [270/700]: mean_loss=0.010681114392355084
Online_Training [271/700]: mean_loss=0.017509230179712176
Online_Training [272/700]: mean_loss=0.006950643379241228
Online_Training [273/700]: mean_loss=0.008381528896279633
Online_Training [274/700]: mean_loss=0.066679697483778
Online_Training [275/700]: mean_loss=0.007584809907712042
Online_Training [276/700]: mean_loss=0.01487825543154031
Online_Training [277/700]: mean_loss=0.012393872486427426
Online_Training [278/700]: mean_loss=0.007950399594847113
Online_Training [279/700]: mean_loss=0.00989491946529597
Online_Training [280/700]: mean_loss=0.03923507407307625
Online_Training [281/700]: mean_loss=0.007153898826800287
Online_Training [282/700]: mean_loss=0.013707240228541195
Online_Training [283/700]: mean_loss=0.006459974742028862
Online_Training [284/700]: mean_loss=0.012472687987610698
Online_Training [285/700]: mean_loss=0.004213519918266684
Online_Training [286/700]: mean_loss=0.007170889293774962
Online_Training [287/700]: mean_loss=0.015603892970830202
Online_Training [288/700]: mean_loss=0.0028439573652576655
Online_Training [289/700]: mean_loss=0.0031704895955044776
Online_Training [290/700]: mean_loss=0.010094296070747077
Online_Training [291/700]: mean_loss=0.0008419674340984784
Online_Training [292/700]: mean_loss=0.010418300749734044
Online_Training [293/700]: mean_loss=0.005849316599778831
Online_Training [294/700]: mean_loss=0.005698783206753433
Online_Training [295/700]: mean_loss=0.00954189442563802
Online_Training [296/700]: mean_loss=0.0078025785041972995
Online_Training [297/700]: mean_loss=0.0035977356019429862
Online_Training [298/700]: mean_loss=0.021178456488996744
Online_Training [299/700]: mean_loss=0.008573155733756721
Online_Training [300/700]: mean_loss=0.013032606220804155
Online_Training [301/700]: mean_loss=0.0070045291213318706
Online_Training [302/700]: mean_loss=0.0022293697111308575
Online_Training [303/700]: mean_loss=0.011733694700524211
Online_Training [304/700]: mean_loss=0.005680785397998989
Online_Training [305/700]: mean_loss=0.012050085584633052
Online_Training [306/700]: mean_loss=0.006369245005771518
Online_Training [307/700]: mean_loss=0.008975536795333028
Online_Training [308/700]: mean_loss=0.007394062005914748
Online_Training [309/700]: mean_loss=0.003058810601942241
Online_Training [310/700]: mean_loss=0.0058381815906614065
Online_Training [311/700]: mean_loss=0.008345147245563567
Online_Training [312/700]: mean_loss=0.012042582733556628
Online_Training [313/700]: mean_loss=0.02200081362389028
Online_Training [314/700]: mean_loss=0.0038323936169035733
Online_Training [315/700]: mean_loss=0.005267305648885667
Online_Training [316/700]: mean_loss=0.01482624898198992
Online_Training [317/700]: mean_loss=0.009870605077594519
Online_Training [318/700]: mean_loss=0.004875956801697612
Online_Training [319/700]: mean_loss=0.01367417850997299
Online_Training [320/700]: mean_loss=0.004793456988409162
Online_Training [321/700]: mean_loss=0.008392159012146294
Online_Training [322/700]: mean_loss=0.006190653366502374
Online_Training [323/700]: mean_loss=0.018031179439276457
Online_Training [324/700]: mean_loss=0.012000953895039856
Online_Training [325/700]: mean_loss=0.004709739936515689
Online_Training [326/700]: mean_loss=0.03380248276516795
Online_Training [327/700]: mean_loss=0.019786807242780924
Online_Training [328/700]: mean_loss=0.008034142490942031
Online_Training [329/700]: mean_loss=0.014895374537445605
Online_Training [330/700]: mean_loss=0.011354033602401614
Online_Training [331/700]: mean_loss=0.010311452788300812
Online_Training [332/700]: mean_loss=0.004909226903691888
Online_Training [333/700]: mean_loss=0.0073625523946247995
Online_Training [334/700]: mean_loss=0.006945163942873478
Online_Training [335/700]: mean_loss=0.0034030424430966377
Online_Training [336/700]: mean_loss=0.007241758867166936
Online_Training [337/700]: mean_loss=0.0025844314659480006
Online_Training [338/700]: mean_loss=0.008973315241746604
Online_Training [339/700]: mean_loss=0.006515475281048566
Online_Training [340/700]: mean_loss=0.009747194708324969
Online_Training [341/700]: mean_loss=0.016609344398602843
Online_Training [342/700]: mean_loss=0.013524093315936625
Online_Training [343/700]: mean_loss=0.00549965410027653
Online_Training [344/700]: mean_loss=0.004880958062130958
Online_Training [345/700]: mean_loss=0.004847084928769618
Online_Training [346/700]: mean_loss=0.011433877982199192
Online_Training [347/700]: mean_loss=0.013699656818062067
Online_Training [348/700]: mean_loss=0.008601214154623449
Online_Training [349/700]: mean_loss=0.006592100951820612
Online_Training [350/700]: mean_loss=0.006863370072096586
Online_Training [351/700]: mean_loss=0.012406029389239848
Online_Training [352/700]: mean_loss=0.0040209495346061885
Online_Training [353/700]: mean_loss=0.009237540187314153
Online_Training [354/700]: mean_loss=0.010351782897487283
Online_Training [355/700]: mean_loss=0.008603667723946273
Online_Training [356/700]: mean_loss=0.0060747797251679
Online_Training [357/700]: mean_loss=0.010744631639681756
Online_Training [358/700]: mean_loss=0.0059907056274823844
Online_Training [359/700]: mean_loss=0.10184089466929436
Online_Training [360/700]: mean_loss=0.14214998483657837
Online_Training [361/700]: mean_loss=0.012028689379803836
Online_Training [362/700]: mean_loss=0.012542793294414878
Online_Training [363/700]: mean_loss=0.009029846405610442
Online_Training [364/700]: mean_loss=0.010766478721052408
Online_Training [365/700]: mean_loss=0.010472363559529185
Online_Training [366/700]: mean_loss=0.0924367792904377
Online_Training [367/700]: mean_loss=0.10314441844820976
Online_Training [368/700]: mean_loss=0.0121942397672683
Online_Training [369/700]: mean_loss=0.011451657395809889
Online_Training [370/700]: mean_loss=0.013362075784243643
Online_Training [371/700]: mean_loss=0.00858235196210444
Online_Training [372/700]: mean_loss=0.01297729613725096
Online_Training [373/700]: mean_loss=0.06023888569325209
Online_Training [374/700]: mean_loss=0.008167108404450119
Online_Training [375/700]: mean_loss=0.005597410548944026
Online_Training [376/700]: mean_loss=0.007316225324757397
Online_Training [377/700]: mean_loss=0.007006431929767132
Online_Training [378/700]: mean_loss=0.011444437899626791
Online_Training [379/700]: mean_loss=0.005786499998066574
Online_Training [380/700]: mean_loss=0.006320965359918773
Online_Training [381/700]: mean_loss=0.012377394828945398
Online_Training [382/700]: mean_loss=0.008554423227906227
Online_Training [383/700]: mean_loss=0.006076272577047348
Online_Training [384/700]: mean_loss=0.009468459291383624
Online_Training [385/700]: mean_loss=0.021299546817317605
Online_Training [386/700]: mean_loss=0.01343285629991442
Online_Training [387/700]: mean_loss=0.007978417386766523
Online_Training [388/700]: mean_loss=0.012169695342890918
Online_Training [389/700]: mean_loss=0.006135492061730474
Online_Training [390/700]: mean_loss=0.08705426007509232
Online_Training [391/700]: mean_loss=0.06811224017292261
Online_Training [392/700]: mean_loss=0.006171711429487914
Online_Training [393/700]: mean_loss=0.014640695415437222
Online_Training [394/700]: mean_loss=0.008914024801924825
Online_Training [395/700]: mean_loss=0.019198390655219555
Online_Training [396/700]: mean_loss=0.004450357402674854
Online_Training [397/700]: mean_loss=0.009927826235070825
Online_Training [398/700]: mean_loss=0.017348739318549633
Online_Training [399/700]: mean_loss=0.01706905593164265
Online_Training [400/700]: mean_loss=0.006411520414985716
Online_Training [401/700]: mean_loss=0.002703298261621967
Online_Training [402/700]: mean_loss=0.006613683537580073
Online_Training [403/700]: mean_loss=0.013310924754478037
Online_Training [404/700]: mean_loss=0.003991446748841554
Online_Training [405/700]: mean_loss=0.004307657189201564
Online_Training [406/700]: mean_loss=0.0030288388079497963
Online_Training [407/700]: mean_loss=0.01981650642119348
Online_Training [408/700]: mean_loss=0.07913522236049175
Online_Training [409/700]: mean_loss=0.031026288168504834
Online_Training [410/700]: mean_loss=0.013227870222181082
Online_Training [411/700]: mean_loss=0.004821201786398888
Online_Training [412/700]: mean_loss=0.008250990998931229
Online_Training [413/700]: mean_loss=0.009966076235286891
Online_Training [414/700]: mean_loss=0.013803320936858654
Online_Training [415/700]: mean_loss=0.014707270660437644
Online_Training [416/700]: mean_loss=0.007241451530717313
Online_Training [417/700]: mean_loss=0.007797699538059533
Online_Training [418/700]: mean_loss=0.013206641655415297
Online_Training [419/700]: mean_loss=0.009316108073107898
Online_Training [420/700]: mean_loss=0.010347664821892977
Online_Training [421/700]: mean_loss=0.007740084722172469
Online_Training [422/700]: mean_loss=0.012470747693441808
Online_Training [423/700]: mean_loss=0.013442868017591536
Online_Training [424/700]: mean_loss=0.004637607024051249
Online_Training [425/700]: mean_loss=0.003181418200256303
Online_Training [426/700]: mean_loss=0.008084529777988791
Online_Training [427/700]: mean_loss=0.0075165953021496534
Online_Training [428/700]: mean_loss=0.010216741706244648
Online_Training [429/700]: mean_loss=0.02096158592030406
Online_Training [430/700]: mean_loss=0.003918153757695109
Online_Training [431/700]: mean_loss=0.004557810083497316
Online_Training [432/700]: mean_loss=0.010033773840405047
Online_Training [433/700]: mean_loss=0.009437739616259933
Online_Training [434/700]: mean_loss=0.009755339357070625
Online_Training [435/700]: mean_loss=0.01979072391986847
Online_Training [436/700]: mean_loss=0.0013368889485718682
Online_Training [437/700]: mean_loss=0.0011030847817892209
Online_Training [438/700]: mean_loss=0.0030537873681169003
Online_Training [439/700]: mean_loss=0.005372753017581999
Online_Training [440/700]: mean_loss=0.008073696051724255
Online_Training [441/700]: mean_loss=0.00945986749138683
Online_Training [442/700]: mean_loss=0.007699533132836223
Online_Training [443/700]: mean_loss=0.015512663987465203
Online_Training [444/700]: mean_loss=0.009361185017041862
Online_Training [445/700]: mean_loss=0.011592900031246245
Online_Training [446/700]: mean_loss=0.001549707245430909
Online_Training [447/700]: mean_loss=0.01865210523828864
Online_Training [448/700]: mean_loss=0.005990653648041189
Online_Training [449/700]: mean_loss=0.010304110473953187
Online_Training [450/700]: mean_loss=0.00774288282264024
Online_Training [451/700]: mean_loss=0.010611927835270762
Online_Training [452/700]: mean_loss=0.006731758534442633
Online_Training [453/700]: mean_loss=0.007858783530537039
Online_Training [454/700]: mean_loss=0.00997744023334235
Online_Training [455/700]: mean_loss=0.004952239745762199
Online_Training [456/700]: mean_loss=0.0031997176411096007
Online_Training [457/700]: mean_loss=0.007552040449809283
Online_Training [458/700]: mean_loss=0.007017035270109773
Online_Training [459/700]: mean_loss=0.011629722779616714
Online_Training [460/700]: mean_loss=0.007203400367870927
Online_Training [461/700]: mean_loss=0.011568534770049155
Online_Training [462/700]: mean_loss=0.12181751243770123
Online_Training [463/700]: mean_loss=0.027308420278131962
Online_Training [464/700]: mean_loss=0.008942245040088892
Online_Training [465/700]: mean_loss=0.010220227297395468
Online_Training [466/700]: mean_loss=0.00453254661988467
Online_Training [467/700]: mean_loss=0.006642272754106671
Online_Training [468/700]: mean_loss=0.007030596432741731
Online_Training [469/700]: mean_loss=0.016649572178721428
Online_Training [470/700]: mean_loss=0.10080945584923029
Online_Training [471/700]: mean_loss=0.16444564424455166
Online_Training [472/700]: mean_loss=0.0048984920722432435
Online_Training [473/700]: mean_loss=0.01059228042140603
Online_Training [474/700]: mean_loss=0.008656955091282725
Online_Training [475/700]: mean_loss=0.007311655790545046
Online_Training [476/700]: mean_loss=0.004721121804323047
Online_Training [477/700]: mean_loss=0.005147981515619904
Online_Training [478/700]: mean_loss=0.014538432820700109
Online_Training [479/700]: mean_loss=0.011268102331086993
Online_Training [480/700]: mean_loss=0.009003929561004043
Online_Training [481/700]: mean_loss=0.007540452643297613
Online_Training [482/700]: mean_loss=0.09360314533114433
Online_Training [483/700]: mean_loss=0.04576199548318982
Online_Training [484/700]: mean_loss=0.013211907004006207
Online_Training [485/700]: mean_loss=0.006608555559068918
Online_Training [486/700]: mean_loss=0.07069185096770525
Online_Training [487/700]: mean_loss=0.1767636239528656
Online_Training [488/700]: mean_loss=0.00988482276443392
Online_Training [489/700]: mean_loss=0.009752107900567353
Online_Training [490/700]: mean_loss=0.009178554639220238
Online_Training [491/700]: mean_loss=0.007902294746600091
Online_Training [492/700]: mean_loss=0.012139508966356516
Online_Training [493/700]: mean_loss=0.010613130405545235
Online_Training [494/700]: mean_loss=0.012732378207147121
Online_Training [495/700]: mean_loss=0.016759709687903523
Online_Training [496/700]: mean_loss=0.010462122620083392
Online_Training [497/700]: mean_loss=0.0099174699280411
Online_Training [498/700]: mean_loss=0.010296628694050014
Online_Training [499/700]: mean_loss=0.008443771745078266
Online_Training [500/700]: mean_loss=0.0053281564032658935
Online_Training [501/700]: mean_loss=0.00826243928167969
Online_Training [502/700]: mean_loss=0.010636083083227277
Online_Training [503/700]: mean_loss=0.006810662453062832
Online_Training [504/700]: mean_loss=0.005858880060259253
Online_Training [505/700]: mean_loss=0.09520422574132681
Online_Training [506/700]: mean_loss=0.11657001543790102
Online_Training [507/700]: mean_loss=0.007876076910179108
Online_Training [508/700]: mean_loss=0.014040865004062653
Online_Training [509/700]: mean_loss=0.01234764326363802
Online_Training [510/700]: mean_loss=0.017189856385812163
Online_Training [511/700]: mean_loss=0.00606035633245483
Online_Training [512/700]: mean_loss=0.011734039057046175
Online_Training [513/700]: mean_loss=0.002609224582556635
Online_Training [514/700]: mean_loss=0.008668759022839367
Online_Training [515/700]: mean_loss=0.0032997593516483903
Online_Training [516/700]: mean_loss=0.013883675215765834
Online_Training [517/700]: mean_loss=0.008496221853420138
Online_Training [518/700]: mean_loss=0.00390835345024243
Online_Training [519/700]: mean_loss=0.005954396445304155
Online_Training [520/700]: mean_loss=0.01339664135593921
Online_Training [521/700]: mean_loss=0.007379621150903404
Online_Training [522/700]: mean_loss=0.009360570809803903
Online_Training [523/700]: mean_loss=0.00935241742990911
Online_Training [524/700]: mean_loss=0.005256782111246139
Online_Training [525/700]: mean_loss=0.004334219382144511
Online_Training [526/700]: mean_loss=0.009700514143332839
Online_Training [527/700]: mean_loss=0.0029365170339588076
Online_Training [528/700]: mean_loss=0.005962802330031991
Online_Training [529/700]: mean_loss=0.0015050216752570122
Online_Training [530/700]: mean_loss=0.007194917125161737
Online_Training [531/700]: mean_loss=0.006626307324040681
Online_Training [532/700]: mean_loss=0.002147990686353296
Online_Training [533/700]: mean_loss=0.007257875520735979
Online_Training [534/700]: mean_loss=0.013930787215940654
Online_Training [535/700]: mean_loss=0.007481990440282971
Online_Training [536/700]: mean_loss=0.01241119229234755
Online_Training [537/700]: mean_loss=0.07816365640610456
Online_Training [538/700]: mean_loss=0.023040368454530835
Online_Training [539/700]: mean_loss=0.0029150825284887105
Online_Training [540/700]: mean_loss=0.0033399352978449315
Online_Training [541/700]: mean_loss=0.005962434806860983
Online_Training [542/700]: mean_loss=0.010807474027387798
Online_Training [543/700]: mean_loss=0.008018581196665764
Online_Training [544/700]: mean_loss=0.015947933890856802
Online_Training [545/700]: mean_loss=0.008624230395071208
Online_Training [546/700]: mean_loss=0.004551340593025088
Online_Training [547/700]: mean_loss=0.005771526484750211
Online_Training [548/700]: mean_loss=0.012805058737285435
Online_Training [549/700]: mean_loss=0.006871054123621434
Online_Training [550/700]: mean_loss=0.012506159720942378
Online_Training [551/700]: mean_loss=0.07262520864605904
Online_Training [552/700]: mean_loss=0.06586018670350313
Online_Training [553/700]: mean_loss=0.010937453364022076
Online_Training [554/700]: mean_loss=0.0044027871917933226
Online_Training [555/700]: mean_loss=0.0037887328362558037
Online_Training [556/700]: mean_loss=0.010282114148139954
Online_Training [557/700]: mean_loss=0.005550845933612436
Online_Training [558/700]: mean_loss=0.004747155006043613
Online_Training [559/700]: mean_loss=0.0037558427138719708
Online_Training [560/700]: mean_loss=0.013834209414198995
Online_Training [561/700]: mean_loss=0.009560635895468295
Online_Training [562/700]: mean_loss=0.006998878205195069
Online_Training [563/700]: mean_loss=0.005561962025240064
Online_Training [564/700]: mean_loss=0.11880445294082165
Online_Training [565/700]: mean_loss=0.022678246721625328
Online_Training [566/700]: mean_loss=0.005012472800444812
Online_Training [567/700]: mean_loss=0.0035595398512668908
Online_Training [568/700]: mean_loss=0.007556581811513752
Online_Training [569/700]: mean_loss=0.010582387913018465
Online_Training [570/700]: mean_loss=0.0024635797017253935
Online_Training [571/700]: mean_loss=0.010214632144197822
Online_Training [572/700]: mean_loss=0.005877988471183926
Online_Training [573/700]: mean_loss=0.009155676001682878
Online_Training [574/700]: mean_loss=0.013704561162739992
Online_Training [575/700]: mean_loss=0.005036849703174084
Online_Training [576/700]: mean_loss=0.002602096850750968
Online_Training [577/700]: mean_loss=0.011369684827513993
Online_Training [578/700]: mean_loss=0.007837039942387491
Online_Training [579/700]: mean_loss=0.0042300751083530486
Online_Training [580/700]: mean_loss=0.008514430606737733
Online_Training [581/700]: mean_loss=0.012134697055444121
Online_Training [582/700]: mean_loss=0.01321390038356185
Online_Training [583/700]: mean_loss=0.006011927500367165
Online_Training [584/700]: mean_loss=0.011207898380234838
Online_Training [585/700]: mean_loss=0.010128135909326375
Online_Training [586/700]: mean_loss=0.0054562094155699015
Online_Training [587/700]: mean_loss=0.018789424328133464
Online_Training [588/700]: mean_loss=0.00841900275554508
Online_Training [589/700]: mean_loss=0.007331999426241964
Online_Training [590/700]: mean_loss=0.0046649634605273604
Online_Training [591/700]: mean_loss=0.0076524337055161595
Online_Training [592/700]: mean_loss=0.002663435065187514
Online_Training [593/700]: mean_loss=0.013995480258017778
Online_Training [594/700]: mean_loss=0.0021209590777289122
Online_Training [595/700]: mean_loss=0.00518895237473771
Online_Training [596/700]: mean_loss=0.007617733906954527
Online_Training [597/700]: mean_loss=0.007181331573519856
Online_Training [598/700]: mean_loss=0.004071734903845936
Online_Training [599/700]: mean_loss=0.008279164438135922
Online_Training [600/700]: mean_loss=0.00544256780995056
Online_Training [601/700]: mean_loss=0.005557581258472055
Online_Training [602/700]: mean_loss=0.004440243821591139
Online_Training [603/700]: mean_loss=0.007820340513717383
Online_Training [604/700]: mean_loss=0.0017641197773627937
Online_Training [605/700]: mean_loss=0.01139567350037396
Online_Training [606/700]: mean_loss=0.004642146464902908
Online_Training [607/700]: mean_loss=0.00414796348195523
Online_Training [608/700]: mean_loss=0.06270161317661405
Online_Training [609/700]: mean_loss=0.008406685898080468
Online_Training [610/700]: mean_loss=0.008674563956446946
Online_Training [611/700]: mean_loss=0.004356028279289603
Online_Training [612/700]: mean_loss=0.021333248587325215
Online_Training [613/700]: mean_loss=0.10526064410805702
Online_Training [614/700]: mean_loss=0.11212553922086954
Online_Training [615/700]: mean_loss=0.006409310852177441
Online_Training [616/700]: mean_loss=0.0028054660360794514
Online_Training [617/700]: mean_loss=0.013557908707298338
Online_Training [618/700]: mean_loss=0.010710457572713494
Online_Training [619/700]: mean_loss=0.006394435476977378
Online_Training [620/700]: mean_loss=0.00871334585826844
Online_Training [621/700]: mean_loss=0.0067932665115222335
Online_Training [622/700]: mean_loss=0.0034941267513204366
Online_Training [623/700]: mean_loss=0.004390847752802074
Online_Training [624/700]: mean_loss=0.05805813241750002
Online_Training [625/700]: mean_loss=0.013823749963194132
Online_Training [626/700]: mean_loss=0.007869813067372888
Online_Training [627/700]: mean_loss=0.01966362865641713
Online_Training [628/700]: mean_loss=0.004878597275819629
Online_Training [629/700]: mean_loss=0.002292237215442583
Online_Training [630/700]: mean_loss=0.006913522840477526
Online_Training [631/700]: mean_loss=0.00906697812024504
Online_Training [632/700]: mean_loss=0.008061661384999752
Online_Training [633/700]: mean_loss=0.0019283670699223876
Online_Training [634/700]: mean_loss=0.0015419029077747837
Online_Training [635/700]: mean_loss=0.011023625498637557
Online_Training [636/700]: mean_loss=0.0015119946328923106
Online_Training [637/700]: mean_loss=0.0005981449066894129
Online_Training [638/700]: mean_loss=0.005274399998597801
Online_Training [639/700]: mean_loss=0.005972733662929386
Online_Training [640/700]: mean_loss=0.010749317123554647
Online_Training [641/700]: mean_loss=0.00959950196556747
Online_Training [642/700]: mean_loss=0.00492684927303344
Online_Training [643/700]: mean_loss=0.00994571961928159
Online_Training [644/700]: mean_loss=0.00613256252836436
Online_Training [645/700]: mean_loss=0.0047703785239718854
Online_Training [646/700]: mean_loss=0.008033902500756085
Online_Training [647/700]: mean_loss=0.013870493625290692
Online_Training [648/700]: mean_loss=0.01937919482588768
Online_Training [649/700]: mean_loss=0.008136477088555694
Online_Training [650/700]: mean_loss=0.009175768354907632
Online_Training [651/700]: mean_loss=0.004396244999952614
Online_Training [652/700]: mean_loss=0.004929372458718717
Online_Training [653/700]: mean_loss=0.06126194912940264
Online_Training [654/700]: mean_loss=0.02150950883515179
Online_Training [655/700]: mean_loss=0.007980685564689338
Online_Training [656/700]: mean_loss=0.006440571800339967
Online_Training [657/700]: mean_loss=0.004645279259420931
Online_Training [658/700]: mean_loss=0.016766092972829938
Online_Training [659/700]: mean_loss=0.0054643789771944284
Online_Training [660/700]: mean_loss=0.0031123029184527695
Online_Training [661/700]: mean_loss=0.008641918888315558
Online_Training [662/700]: mean_loss=0.00680497259600088
Online_Training [663/700]: mean_loss=0.006393312243744731
Online_Training [664/700]: mean_loss=0.0016922934737522155
Online_Training [665/700]: mean_loss=0.0042611523531377316
Online_Training [666/700]: mean_loss=0.018865616526454687
Online_Training [667/700]: mean_loss=0.004362650273833424
Online_Training [668/700]: mean_loss=0.006279685301706195
Online_Training [669/700]: mean_loss=0.001338352434686385
Online_Training [670/700]: mean_loss=0.004812791710719466
Online_Training [671/700]: mean_loss=0.006485047750174999
Online_Training [672/700]: mean_loss=0.0074410163215361536
Online_Training [673/700]: mean_loss=0.06569683831185102
Online_Training [674/700]: mean_loss=0.05361000681295991
Online_Training [675/700]: mean_loss=0.00856638583354652
Online_Training [676/700]: mean_loss=0.005888507410418242
Online_Training [677/700]: mean_loss=0.002715420472668484
Online_Training [678/700]: mean_loss=0.004351369338110089
Online_Training [679/700]: mean_loss=0.0027206945815123618
Online_Training [680/700]: mean_loss=0.007405477750580758
Online_Training [681/700]: mean_loss=0.002035815210547298
Online_Training [682/700]: mean_loss=0.002163879806175828
Online_Training [683/700]: mean_loss=0.005188031762372702
Online_Training [684/700]: mean_loss=0.005150925251655281
Online_Training [685/700]: mean_loss=0.005493179138284177
Online_Training [686/700]: mean_loss=0.007309809559956193
Online_Training [687/700]: mean_loss=0.0014651516830781475
Online_Training [688/700]: mean_loss=0.00685686431825161
Online_Training [689/700]: mean_loss=0.004695778130553663
Online_Training [690/700]: mean_loss=0.012702439446002245
Online_Training [691/700]: mean_loss=0.0006527058576466516
Online_Training [692/700]: mean_loss=0.0066694775014184415
Online_Training [693/700]: mean_loss=0.0054564650054089725
Online_Training [694/700]: mean_loss=0.07439120393246412
Online_Training [695/700]: mean_loss=0.01715818769298494
Online_Training [696/700]: mean_loss=0.0051778340712189674
Online_Training [697/700]: mean_loss=0.0027279525820631534
Online_Training [698/700]: mean_loss=0.017375856637954712
Online_Training [699/700]: mean_loss=0.006852983962744474
Online_Training [700/700]: mean_loss=0.006868344557005912
Q_Learning [1/300]: mean_loss=0.18021232448518276
Q_Learning [2/300]: mean_loss=0.10341162886470556
Q_Learning [3/300]: mean_loss=0.19971590489149094
Q_Learning [4/300]: mean_loss=0.15200127847492695
Q_Learning [5/300]: mean_loss=0.10667937435209751
Q_Learning [6/300]: mean_loss=0.18411065079271793
Q_Learning [7/300]: mean_loss=0.08881805557757616
Q_Learning [8/300]: mean_loss=0.08341440185904503
Q_Learning [9/300]: mean_loss=0.09850034024566412
Q_Learning [10/300]: mean_loss=0.08075298741459846
Q_Learning [11/300]: mean_loss=0.07892259117215872
Q_Learning [12/300]: mean_loss=0.0808995645493269
Q_Learning [13/300]: mean_loss=0.07965847291052341
Q_Learning [14/300]: mean_loss=0.07483293674886227
Q_Learning [15/300]: mean_loss=0.1458062157034874
Q_Learning [16/300]: mean_loss=0.06433899700641632
Q_Learning [17/300]: mean_loss=0.1466954629868269
Q_Learning [18/300]: mean_loss=0.05696294503286481
Q_Learning [19/300]: mean_loss=0.06666036881506443
Q_Learning [20/300]: mean_loss=0.05722567206248641
Q_Learning [21/300]: mean_loss=0.05308885034173727
Q_Learning [22/300]: mean_loss=0.19097109511494637
Q_Learning [23/300]: mean_loss=0.22030334547162056
Q_Learning [24/300]: mean_loss=0.059434106573462486
Q_Learning [25/300]: mean_loss=0.09911301545798779
Q_Learning [26/300]: mean_loss=0.04438965627923608
Q_Learning [27/300]: mean_loss=0.10564241744577885
Q_Learning [28/300]: mean_loss=0.0391640355810523
Q_Learning [29/300]: mean_loss=0.05009417003020644
Q_Learning [30/300]: mean_loss=0.042259661480784416
Q_Learning [31/300]: mean_loss=0.04972227616235614
Q_Learning [32/300]: mean_loss=0.037011707201600075
Q_Learning [33/300]: mean_loss=0.034201203379780054
Q_Learning [34/300]: mean_loss=0.042105776723474264
Q_Learning [35/300]: mean_loss=0.13598265685141087
Q_Learning [36/300]: mean_loss=0.09907681215554476
Q_Learning [37/300]: mean_loss=0.027373338118195534
Q_Learning [38/300]: mean_loss=0.05790393287315965
Q_Learning [39/300]: mean_loss=0.03703470854088664
Q_Learning [40/300]: mean_loss=0.01838541286997497
Q_Learning [41/300]: mean_loss=0.027051578275859356
Q_Learning [42/300]: mean_loss=0.05474056350067258
Q_Learning [43/300]: mean_loss=0.02360197645612061
Q_Learning [44/300]: mean_loss=0.019136497052386403
Q_Learning [45/300]: mean_loss=0.029516967944800854
Q_Learning [46/300]: mean_loss=0.04943325975909829
Q_Learning [47/300]: mean_loss=0.2239616084843874
Q_Learning [48/300]: mean_loss=0.17600279301404953
Q_Learning [49/300]: mean_loss=0.28495488688349724
Q_Learning [50/300]: mean_loss=0.021162816556170583
Q_Learning [51/300]: mean_loss=0.028023005230352283
Q_Learning [52/300]: mean_loss=0.03629739675670862
Q_Learning [53/300]: mean_loss=0.014502700068987906
Q_Learning [54/300]: mean_loss=0.017291065771132708
Q_Learning [55/300]: mean_loss=0.015654698945581913
Q_Learning [56/300]: mean_loss=0.016781947808340192
Q_Learning [57/300]: mean_loss=0.012680815067142248
Q_Learning [58/300]: mean_loss=0.04790715826675296
Q_Learning [59/300]: mean_loss=0.024837369564920664
Q_Learning [60/300]: mean_loss=0.009365454432554543
Q_Learning [61/300]: mean_loss=0.026854787953197956
Q_Learning [62/300]: mean_loss=0.008649516967125237
Q_Learning [63/300]: mean_loss=0.013159775990061462
Q_Learning [64/300]: mean_loss=0.00588131818221882
Q_Learning [65/300]: mean_loss=0.017491614446043968
Q_Learning [66/300]: mean_loss=0.00621173222316429
Q_Learning [67/300]: mean_loss=0.011026927037164569
Q_Learning [68/300]: mean_loss=0.01805384852923453
Q_Learning [69/300]: mean_loss=0.016086993273347616
Q_Learning [70/300]: mean_loss=0.011407707585021853
Q_Learning [71/300]: mean_loss=0.005654377106111497
Q_Learning [72/300]: mean_loss=0.0034855697595048696
Q_Learning [73/300]: mean_loss=0.01005581149365753
Q_Learning [74/300]: mean_loss=0.011192487785592675
Q_Learning [75/300]: mean_loss=0.017651770962402225
Q_Learning [76/300]: mean_loss=0.013674817746505141
Q_Learning [77/300]: mean_loss=0.01020326477009803
Q_Learning [78/300]: mean_loss=0.01445514929946512
Q_Learning [79/300]: mean_loss=0.005366325844079256
Q_Learning [80/300]: mean_loss=0.008396242512390018
Q_Learning [81/300]: mean_loss=0.00802833162015304
Q_Learning [82/300]: mean_loss=0.004931313975248486
Q_Learning [83/300]: mean_loss=0.018783305771648884
Q_Learning [84/300]: mean_loss=0.01940053142607212
Q_Learning [85/300]: mean_loss=0.04183902870863676
Q_Learning [86/300]: mean_loss=0.028125681914389133
Q_Learning [87/300]: mean_loss=0.012865319149568677
Q_Learning [88/300]: mean_loss=0.009102601557970047
Q_Learning [89/300]: mean_loss=0.01974943862296641
Q_Learning [90/300]: mean_loss=0.02249572635628283
Q_Learning [91/300]: mean_loss=0.019614620367065072
Q_Learning [92/300]: mean_loss=0.009404786163941026
Q_Learning [93/300]: mean_loss=0.013508914038538933
Q_Learning [94/300]: mean_loss=0.007286144013050944
Q_Learning [95/300]: mean_loss=0.011447300668805838
Q_Learning [96/300]: mean_loss=0.009063020930625498
Q_Learning [97/300]: mean_loss=0.014755528420209885
Q_Learning [98/300]: mean_loss=0.05846384074538946
Q_Learning [99/300]: mean_loss=0.013078261050395668
Q_Learning [100/300]: mean_loss=0.009573645773343742
Q_Learning [101/300]: mean_loss=0.013696919195353985
Q_Learning [102/300]: mean_loss=0.008966137771494687
Q_Learning [103/300]: mean_loss=0.020419850246980786
Q_Learning [104/300]: mean_loss=0.010161206242628396
Q_Learning [105/300]: mean_loss=0.015140781062655151
Q_Learning [106/300]: mean_loss=0.012686894508078694
Q_Learning [107/300]: mean_loss=0.006823212490417063
Q_Learning [108/300]: mean_loss=0.0067222361685708165
Q_Learning [109/300]: mean_loss=0.00678451859857887
Q_Learning [110/300]: mean_loss=0.014286128687672317
Q_Learning [111/300]: mean_loss=0.00807819067267701
Q_Learning [112/300]: mean_loss=0.008306571224238724
Q_Learning [113/300]: mean_loss=0.013091938104480505
Q_Learning [114/300]: mean_loss=0.016886676428839564
Q_Learning [115/300]: mean_loss=0.009835562319494784
Q_Learning [116/300]: mean_loss=0.00993594597093761
Q_Learning [117/300]: mean_loss=0.008442496065981686
Q_Learning [118/300]: mean_loss=0.015832879929803312
Q_Learning [119/300]: mean_loss=0.013352737994864583
Q_Learning [120/300]: mean_loss=0.020343300187960267
Q_Learning [121/300]: mean_loss=0.0058683271636255085
Q_Learning [122/300]: mean_loss=0.015594976139254868
Q_Learning [123/300]: mean_loss=0.008904441026970744
Q_Learning [124/300]: mean_loss=0.011574337957426906
Q_Learning [125/300]: mean_loss=0.01080671779345721
Q_Learning [126/300]: mean_loss=0.015758931753225625
Q_Learning [127/300]: mean_loss=0.009302621590904891
Q_Learning [128/300]: mean_loss=0.00799498672131449
Q_Learning [129/300]: mean_loss=0.005575954623054713
Q_Learning [130/300]: mean_loss=0.007422110938932747
Q_Learning [131/300]: mean_loss=0.01267135830130428
Q_Learning [132/300]: mean_loss=0.017450839281082153
Q_Learning [133/300]: mean_loss=0.0856594992801547
Q_Learning [134/300]: mean_loss=0.07792921178042889
Q_Learning [135/300]: mean_loss=0.006593988859094679
Q_Learning [136/300]: mean_loss=0.017671352019533515
Q_Learning [137/300]: mean_loss=0.012771758018061519
Q_Learning [138/300]: mean_loss=0.01571004162542522
Q_Learning [139/300]: mean_loss=0.019736363319680095
Q_Learning [140/300]: mean_loss=0.01838401099666953
Q_Learning [141/300]: mean_loss=0.012868740479461849
Q_Learning [142/300]: mean_loss=0.009333572466857731
Q_Learning [143/300]: mean_loss=0.013936558039858937
Q_Learning [144/300]: mean_loss=0.013784307753667235
Q_Learning [145/300]: mean_loss=0.01342438394203782
Q_Learning [146/300]: mean_loss=0.014163083862513304
Q_Learning [147/300]: mean_loss=0.01964378892444074
Q_Learning [148/300]: mean_loss=0.033770994283258915
Q_Learning [149/300]: mean_loss=0.009484173264354467
Q_Learning [150/300]: mean_loss=0.018078405410051346
Q_Learning [151/300]: mean_loss=0.005954720138106495
Q_Learning [152/300]: mean_loss=0.01541518501471728
Q_Learning [153/300]: mean_loss=0.013605373911559582
Q_Learning [154/300]: mean_loss=0.013176335953176022
Q_Learning [155/300]: mean_loss=0.010821192874573171
Q_Learning [156/300]: mean_loss=0.0066454599145799875
Q_Learning [157/300]: mean_loss=0.007520063722040504
Q_Learning [158/300]: mean_loss=0.009333763387985528
Q_Learning [159/300]: mean_loss=0.015732345287688076
Q_Learning [160/300]: mean_loss=0.00798360537737608
Q_Learning [161/300]: mean_loss=0.012715969467535615
Q_Learning [162/300]: mean_loss=0.006279485183767974
Q_Learning [163/300]: mean_loss=0.022293918067589402
Q_Learning [164/300]: mean_loss=0.0071995307225733995
Q_Learning [165/300]: mean_loss=0.009370214771479368
Q_Learning [166/300]: mean_loss=0.024982244009152055
Q_Learning [167/300]: mean_loss=0.013335120282135904
Q_Learning [168/300]: mean_loss=0.012330542551353574
Q_Learning [169/300]: mean_loss=0.009357117465697229
Q_Learning [170/300]: mean_loss=0.009855866199359298
Q_Learning [171/300]: mean_loss=0.005717977648600936
Q_Learning [172/300]: mean_loss=0.009619261720217764
Q_Learning [173/300]: mean_loss=0.013775462750345469
Q_Learning [174/300]: mean_loss=0.004717089585028589
Q_Learning [175/300]: mean_loss=0.005585215403698385
Q_Learning [176/300]: mean_loss=0.014184164465405047
Q_Learning [177/300]: mean_loss=0.005049457133281976
Q_Learning [178/300]: mean_loss=0.0606786054559052
Q_Learning [179/300]: mean_loss=0.04021246964111924
Q_Learning [180/300]: mean_loss=0.02710756892338395
Q_Learning [181/300]: mean_loss=0.06312032463029027
Q_Learning [182/300]: mean_loss=0.04455539118498564
Q_Learning [183/300]: mean_loss=0.012142485822550952
Q_Learning [184/300]: mean_loss=0.008677811361849308
Q_Learning [185/300]: mean_loss=0.011954594869166613
Q_Learning [186/300]: mean_loss=0.005064089898951352
Q_Learning [187/300]: mean_loss=0.012926840572617948
Q_Learning [188/300]: mean_loss=0.018212083261460066
Q_Learning [189/300]: mean_loss=0.009384827455505729
Q_Learning [190/300]: mean_loss=0.006027803348843008
Q_Learning [191/300]: mean_loss=0.09122754912823439
Q_Learning [192/300]: mean_loss=0.022971372352913022
Q_Learning [193/300]: mean_loss=0.006591029814444482
Q_Learning [194/300]: mean_loss=0.034032643074169755
Q_Learning [195/300]: mean_loss=0.019715142203494906
Q_Learning [196/300]: mean_loss=0.02132317377254367
Q_Learning [197/300]: mean_loss=0.015499180881306529
Q_Learning [198/300]: mean_loss=0.009634720510803163
Q_Learning [199/300]: mean_loss=0.019036487210541964
Q_Learning [200/300]: mean_loss=0.006374180200509727
Q_Learning [201/300]: mean_loss=0.009420400601811707
Q_Learning [202/300]: mean_loss=0.010337744024582207
Q_Learning [203/300]: mean_loss=0.010102310916408896
Q_Learning [204/300]: mean_loss=0.011899666744284332
Q_Learning [205/300]: mean_loss=0.021139180986210704
Q_Learning [206/300]: mean_loss=0.007604071230161935
Q_Learning [207/300]: mean_loss=0.007233086682390422
Q_Learning [208/300]: mean_loss=0.0025978418125305325
Q_Learning [209/300]: mean_loss=0.00248336503864266
Q_Learning [210/300]: mean_loss=0.011408920050598681
Q_Learning [211/300]: mean_loss=0.020221201237291098
Q_Learning [212/300]: mean_loss=0.012548734317533672
Q_Learning [213/300]: mean_loss=0.007531773648224771
Q_Learning [214/300]: mean_loss=0.009996662614867091
Q_Learning [215/300]: mean_loss=0.006463101657573134
Q_Learning [216/300]: mean_loss=0.007157781219575554
Q_Learning [217/300]: mean_loss=0.010225880541838706
Q_Learning [218/300]: mean_loss=0.010920273372903466
Q_Learning [219/300]: mean_loss=0.010234216344542801
Q_Learning [220/300]: mean_loss=0.017632232513278723
Q_Learning [221/300]: mean_loss=0.0213085375726223
Q_Learning [222/300]: mean_loss=0.010311939753592014
Q_Learning [223/300]: mean_loss=0.022851467365399003
Q_Learning [224/300]: mean_loss=0.08974862843751907
Q_Learning [225/300]: mean_loss=0.12868556194007397
Q_Learning [226/300]: mean_loss=0.01103446667548269
Q_Learning [227/300]: mean_loss=0.014779549557715654
Q_Learning [228/300]: mean_loss=0.01614263723604381
Q_Learning [229/300]: mean_loss=0.009623859892599285
Q_Learning [230/300]: mean_loss=0.012371797463856637
Q_Learning [231/300]: mean_loss=0.07527509424835443
Q_Learning [232/300]: mean_loss=0.03931577783077955
Q_Learning [233/300]: mean_loss=0.0849011866375804
Q_Learning [234/300]: mean_loss=0.14197920076549053
Q_Learning [235/300]: mean_loss=0.01421434711664915
Q_Learning [236/300]: mean_loss=0.014457594021223485
Q_Learning [237/300]: mean_loss=0.021404074039310217
Q_Learning [238/300]: mean_loss=0.015410819556564093
Q_Learning [239/300]: mean_loss=0.01676850114017725
Q_Learning [240/300]: mean_loss=0.0064253731979988515
Q_Learning [241/300]: mean_loss=0.014186687651090324
Q_Learning [242/300]: mean_loss=0.016756029799580574
Q_Learning [243/300]: mean_loss=0.014206737629137933
Q_Learning [244/300]: mean_loss=0.018790509784594178
Q_Learning [245/300]: mean_loss=0.006014714250341058
Q_Learning [246/300]: mean_loss=0.005064877157565206
Q_Learning [247/300]: mean_loss=0.007821230101399124
Q_Learning [248/300]: mean_loss=0.019973498536273837
Q_Learning [249/300]: mean_loss=0.009576845681294799
Q_Learning [250/300]: mean_loss=0.011905686114914715
Q_Learning [251/300]: mean_loss=0.069158049300313
Q_Learning [252/300]: mean_loss=0.04611649177968502
Q_Learning [253/300]: mean_loss=0.0084677969571203
Q_Learning [254/300]: mean_loss=0.00674940092721954
Q_Learning [255/300]: mean_loss=0.008437257842160761
Q_Learning [256/300]: mean_loss=0.017277485225349665
Q_Learning [257/300]: mean_loss=0.00487540423637256
Q_Learning [258/300]: mean_loss=0.006808284670114517
Q_Learning [259/300]: mean_loss=0.006719535333104432
Q_Learning [260/300]: mean_loss=0.01662755198776722
Q_Learning [261/300]: mean_loss=0.012858857517130673
Q_Learning [262/300]: mean_loss=0.0088875851361081
Q_Learning [263/300]: mean_loss=0.009493146440945566
Q_Learning [264/300]: mean_loss=0.011977485148236156
Q_Learning [265/300]: mean_loss=0.1454027947038412
Q_Learning [266/300]: mean_loss=0.10986300278455019
Q_Learning [267/300]: mean_loss=0.010497242910787463
Q_Learning [268/300]: mean_loss=0.010862195631489158
Q_Learning [269/300]: mean_loss=0.004046623886097223
Q_Learning [270/300]: mean_loss=0.010681114392355084
Q_Learning [271/300]: mean_loss=0.017509230179712176
Q_Learning [272/300]: mean_loss=0.006950643379241228
Q_Learning [273/300]: mean_loss=0.008381528896279633
Q_Learning [274/300]: mean_loss=0.066679697483778
Q_Learning [275/300]: mean_loss=0.007584809907712042
Q_Learning [276/300]: mean_loss=0.01487825543154031
Q_Learning [277/300]: mean_loss=0.012393872486427426
Q_Learning [278/300]: mean_loss=0.007950399594847113
Q_Learning [279/300]: mean_loss=0.00989491946529597
Q_Learning [280/300]: mean_loss=0.03923507407307625
Q_Learning [281/300]: mean_loss=0.007153898826800287
Q_Learning [282/300]: mean_loss=0.013707240228541195
Q_Learning [283/300]: mean_loss=0.006459974742028862
Q_Learning [284/300]: mean_loss=0.012472687987610698
Q_Learning [285/300]: mean_loss=0.004213519918266684
Q_Learning [286/300]: mean_loss=0.007170889293774962
Q_Learning [287/300]: mean_loss=0.015603892970830202
Q_Learning [288/300]: mean_loss=0.0028439573652576655
Q_Learning [289/300]: mean_loss=0.0031704895955044776
Q_Learning [290/300]: mean_loss=0.010094296070747077
Q_Learning [291/300]: mean_loss=0.0008419674340984784
Q_Learning [292/300]: mean_loss=0.010418300749734044
Q_Learning [293/300]: mean_loss=0.005849316599778831
Q_Learning [294/300]: mean_loss=0.005698783206753433
Q_Learning [295/300]: mean_loss=0.00954189442563802
Q_Learning [296/300]: mean_loss=0.0078025785041972995
Q_Learning [297/300]: mean_loss=0.0035977356019429862
Q_Learning [298/300]: mean_loss=0.021178456488996744
Q_Learning [299/300]: mean_loss=0.008573155733756721
Q_Learning [300/300]: mean_loss=0.013032606220804155
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-1.6112387 -4.1599483]
[0, 0, 0, 1, 1, 0, 2, 2, 0, 1, 0, 2, 1, 1, 0, 2, 2, 1, 2, 2, 1, 1, 1, 0, 2, 2, 1, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 1, 0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 2, 1, 0, 2, 1, 2, 2, 0, 2, 0, 1, 1, 0, 2, 2, 1, 0, 0, 0, 2, 1, 2, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 2, 0, 1, 0, 1, 0, 2, 2, 1, 0, 2, 1, 0, 2, 1, 2, 0, 1, 0, 1, 2, 0, 0, 0, 1, 2, 0, 1, 1, 2, 1, 0, 2, 1, 0, 1, 1, 2, 2, 2, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 2, 1, 2, 0, 1, 1, 2, 1, 0, 2, 1, 0, 2, 0, 2, 1, 1, 2, 0, 0, 2, 1, 1, 0, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 2, 1, 0, 1, 2, 2, 2, 1, 1, 2, 1, 0, 2, 1, 1, 2, 2, 2, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 0, 2, 2, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 2, 1, 0, 0, 0, 1, 1, 2, 0, 1, 0, 1, 1, 2, 2]
[0, 0, 1, 1, 2, 0, 3, 4, 2, 5, 0, 6, 7, 7, 5, 6, 4, 8, 3, 9, 7, 2, 2, 0, 3, 4, 10, 10, 11, 11, 2, 2, 8, 2, 7, 1, 9, 2, 0, 2, 6, 9, 2, 6, 1, 12, 2, 13, 1, 6, 9, 1, 11, 13, 1, 10, 7, 8, 9, 0, 14, 5, 0, 7, 5, 9, 6, 1, 5, 0, 2, 14, 2, 6, 0, 5, 8, 2, 2, 0, 2, 0, 2, 2, 1, 7, 11, 0, 2, 10, 6, 1, 1, 0, 5, 0, 14, 1, 1, 1, 2, 2, 7, 7, 15, 16, 17, 1, 18, 18, 19, 18, 20, 1, 20, 18, 21, 22, 18, 18, 22, 18, 18, 19, 23, 19, 20, 23, 23, 20, 24, 21, 18, 20, 25, 24, 18, 20, 20, 26, 27, 27, 26, 20, 18, 20, 28, 28, 19, 24, 20, 25, 27, 19, 20, 20, 18, 21, 26, 18, 20, 20, 18, 26, 29, 18, 25, 18, 19, 19, 21, 30, 18, 21, 25, 23, 18, 26, 18, 20, 19, 20, 20, 26, 20, 19, 27, 18, 26, 18, 18, 26, 27, 25, 25, 18, 18, 24, 23, 20, 24, 18, 27, 20, 31, 26, 19, 20, 20, 31, 31, 19, 27, 18, 18, 20, 25, 26, 27, 12, 31, 32, 32, 32, 31, 27, 32, 31, 25, 32, 25, 31, 19, 19, 26, 25, 25, 33, 33, 18, 32, 19, 21, 32, 19, 30, 32, 20, 20, 18, 19, 18, 31, 18, 26, 27, 20, 21, 20, 19, 26, 18, 26, 31, 21, 18, 25, 20, 18, 25, 18, 18, 31, 26, 18, 26, 26, 20, 26, 26, 21, 24, 25, 27, 20, 32, 20, 31, 18, 18, 20, 20, 21, 25, 25, 18, 20, 23, 26, 21]
Centroids: [[-0.7361383, -4.023037], [-0.89007723, -4.7958646], [-3.1052399, -9.277438]]
Centroids: [[-1.3909624, -3.9903069], [-0.95356995, -3.547501], [-1.6773206, -4.568285], [-5.4813857, -10.305728], [-5.749964, -10.852474], [-0.7211804, -2.8298054], [-4.524384, -9.258824], [-2.1532907, -5.3923197], [-3.5826855, -7.8415027], [-4.953775, -9.871135], [-4.055306, -8.748135], [-3.961593, -8.322321], [-0.29980505, -1.5303125], [-3.125222, -6.6407013], [-4.5259995, -9.774738], [-2.8616645, -7.488602], [-6.6392374, -12.571173], [-3.4932308, -9.972449], [-0.091720596, -3.7410088], [-2.4098225, -9.189063], [-0.47554913, -4.718578], [-1.8600472, -8.068711], [-3.283784, -10.659404], [-0.9325466, -6.238176], [-2.8282921, -10.390975], [0.20154451, -2.9985642], [-2.0725343, -8.697372], [-0.80386966, -5.4910145], [-3.6750276, -14.4142], [-1.412447, -6.543216], [-1.4804759, -7.6343646], [-0.29447797, -4.2779226], [-2.6096175, -9.644838], [-3.612327, -13.246214]]
Contingency Matrix: 
[[10 11  9  0  0  6  0  3  0  0  0  0  2  0  0  0  0  1 23  0 11  1  0  1
   0 11  0  1  0  0  0  4  0  1]
 [ 5  5 12  0  0  1  0  6  1  0  1  0  0  2  0  1  0  0 17  0 23  0  0  5
   0  5  0 10  1  1  0  7  0  0]
 [ 0  0  0  3  3  0  8  0  3  6  3  4  0  0  3  0  1  0  0 17  0 10  2  0
   6  0 20  0  1  0  2  0  9  1]]
[[10, 11, 9, 0, 0, 6, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 23, 0, 11, 1, 0, 1, 0, 11, 0, 1, 0, 0, 0, 4, 0, 1], [5, 5, 12, 0, 0, 1, 0, 6, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 17, 0, 23, 0, 0, 5, 0, 5, 0, 10, 1, 1, 0, 7, 0, 0], [0, 0, 0, 3, 3, 0, 8, 0, 3, 6, 3, 4, 0, 0, 3, 0, 1, 0, 0, 17, 0, 10, 2, 0, 6, 0, 20, 0, 1, 0, 2, 0, 9, 1]]
[[10, 11, 9, 0, 0, 6, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 23, 0, 11, 1, 0, 1, 0, 11, 0, 1, 0, 0, 0, 4, 0, 1], [5, 5, 12, 0, 0, 1, 0, 6, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 17, 0, 23, 0, 0, 5, 0, 5, 0, 10, 1, 1, 0, 7, 0, 0], [0, 0, 0, 3, 3, 0, 8, 0, 3, 6, 3, 4, 0, 0, 3, 0, 1, 0, 0, 17, 0, 10, 2, 0, 6, 0, 20, 0, 1, 0, 2, 0, 9, 1]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [5, 5, 12, 0, 0, 1, 0, 6, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, -1, 0, 23, 0, 0, 5, 0, 5, 0, 10, 1, 1, 0, 7, 0, 0], [0, 0, 0, 3, 3, 0, 8, 0, 3, 6, 3, 4, 0, 0, 3, 0, 1, 0, -1, 17, 0, 10, 2, 0, 6, 0, 20, 0, 1, 0, 2, 0, 9, 1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 0, 0, 3, 3, 0, 8, 0, 3, 6, 3, 4, 0, 0, 3, 0, 1, 0, -1, 17, -1, 10, 2, 0, 6, 0, 20, 0, 1, 0, 2, 0, 9, 1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {0: 18, 1: 20, 2: 26}
New Contingency Matrix: 
[[23 11  0 10 11  9  0  0  6  0  3  0  0  0  0  2  0  0  0  0  1  0  1  0
   1  0 11  1  0  0  0  4  0  1]
 [17 23  0  5  5 12  0  0  1  0  6  1  0  1  0  0  2  0  1  0  0  0  0  0
   5  0  5 10  1  1  0  7  0  0]
 [ 0  0 20  0  0  0  3  3  0  8  0  3  6  3  4  0  0  3  0  1  0 17 10  2
   0  6  0  0  1  0  2  0  9  1]]
New Clustered Label Sequence: [18, 20, 26, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33]
Diagonal_Elements: [23, 23, 20], Sum: 66
All_Elements: [23, 11, 0, 10, 11, 9, 0, 0, 6, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 11, 1, 0, 0, 0, 4, 0, 1, 17, 23, 0, 5, 5, 12, 0, 0, 1, 0, 6, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 5, 0, 5, 10, 1, 1, 0, 7, 0, 0, 0, 0, 20, 0, 0, 0, 3, 3, 0, 8, 0, 3, 6, 3, 4, 0, 0, 3, 0, 1, 0, 17, 10, 2, 0, 6, 0, 0, 1, 0, 2, 0, 9, 1], Sum: 300
Accuracy: 0.22
