Seed: 6
Experiment_path: Random_Seeds_DV5//V5_2/Experiment_05_6_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: Random_Seeds_DV5//V5_2/Experiment_05_6_opt_temp/C_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_04_05-09_42_53
Normalisation: False
Template Matching: True
Optimising Autoencoder: True
Update Factor: 100
Noisy Batches: False
Noisy Factor: 0.1
Epochs: 8
Batch Size: 1
maximal Spikes for Autoencoder Training : 700
maximal Spikes for Training: 1000
Input Size: 47
Chosen Model: Autoencoder
Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=47, out_features=12, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=12, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=2, out_features=12, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=12, out_features=47, bias=True)
  )
)
MSELoss()
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0
)
---Q Learning Parameters---
Normalisation: False
Punishment Coefficient: 0.59
Alpha: 0.8
Epsilon: 0.01
Gamma: 0.97
Initial Episode Number: 0
Episode Number Coefficient: 1.4
Number of Random Features: 20
Planning Number: 20
Max Random Features: 60
New Episode Number: 72
New Episode Number: 143
New Episode Number: 215
New Episode Number: 286
New Episode Number: 358
New Episode Number: 429
New Episode Number: 500
New Episode Number: 572
New Episode Number: 643
New Episode Number: 715
New Episode Number: 786
New Episode Number: 858
                0      1      2      3   ...     9      10     11     12
new_cluster -17.02 -23.17 -16.11 -16.62  ... -18.44 -25.22 -19.71 -20.93
c1          -17.02 -24.22 -16.81 -16.70  ... -18.01 -25.22 -19.48 -20.44
c2          -17.02 -23.61 -17.03 -16.86  ... -17.66 -25.16 -19.51 -20.44
c3          -17.02 -23.37 -16.93 -16.76  ... -18.74 -25.22 -19.44 -20.86
c4          -17.02 -22.85 -16.58 -16.80  ... -17.91 -25.20 -19.45 -20.83
c5          -17.02 -23.06 -16.73 -16.69  ... -18.58 -25.22 -18.83 -20.78
c6          -17.02 -22.95 -16.86 -16.91  ... -18.62 -25.15 -19.89 -20.43
c7          -17.02 -23.62 -16.43 -16.71  ... -18.45 -25.15 -19.73 -20.56
c8          -17.02 -23.24 -16.83 -16.49  ... -18.29 -25.20 -19.15 -20.44
c9          -17.02 -23.47 -16.80 -16.81  ... -18.61 -25.22 -19.19 -20.42
c10         -17.02 -23.19 -16.38 -16.84  ... -18.43 -24.88 -19.49 -20.75
c11         -17.02 -23.13 -16.60 -16.55  ... -18.10 -25.22 -19.33 -20.75
c12         -17.02 -23.62 -16.79 -16.77  ... -18.44 -25.11 -18.78 -20.44

[13 rows x 13 columns]
                               0            1   ...            11            12
new_cluster  [-1.39, new_cluster]  [-7.28, c1]  ...  [-3.67, c11]  [-4.68, c12]
c1           [-1.39, new_cluster]  [-8.04, c1]  ...  [-3.68, c11]  [-4.68, c12]
c2           [-1.39, new_cluster]  [-7.48, c1]  ...   [-3.5, c11]  [-4.68, c12]
c3           [-1.39, new_cluster]  [-7.57, c1]  ...  [-3.43, c11]  [-4.68, c12]
c4           [-1.39, new_cluster]  [-6.99, c1]  ...  [-3.48, c11]  [-4.68, c12]
c5           [-1.39, new_cluster]  [-7.26, c1]  ...  [-2.79, c11]  [-4.68, c12]
c6           [-1.39, new_cluster]  [-7.07, c1]  ...  [-3.89, c11]  [-4.68, c12]
c7           [-1.39, new_cluster]  [-7.85, c1]  ...  [-3.89, c11]  [-4.68, c12]
c8           [-1.39, new_cluster]   [-7.1, c1]  ...  [-3.36, c11]  [-4.68, c12]
c9           [-1.39, new_cluster]  [-7.29, c1]  ...  [-3.36, c11]  [-4.68, c12]
c10          [-1.39, new_cluster]  [-7.39, c1]  ...   [-3.7, c11]  [-4.68, c12]
c11          [-1.39, new_cluster]  [-7.34, c1]  ...  [-3.32, c11]  [-4.68, c12]
c12          [-1.39, new_cluster]  [-7.51, c1]  ...  [-2.84, c11]  [-4.68, c12]

[13 rows x 13 columns]
