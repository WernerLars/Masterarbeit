Seed: 6
Experiment_path: Random_Seeds_DV5//V5_2/Experiment_05_6_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: Random_Seeds_DV5//V5_2/Experiment_05_6_opt_temp/C_Difficult1_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_04_05-09_52_57
Normalisation: False
Template Matching: True
Optimising Autoencoder: True
Update Factor: 100
Noisy Batches: False
Noisy Factor: 0.1
Epochs: 8
Batch Size: 1
maximal Spikes for Autoencoder Training : 700
maximal Spikes for Training: 1000
Input Size: 47
Chosen Model: Autoencoder
Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=47, out_features=12, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=12, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=2, out_features=12, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=12, out_features=47, bias=True)
  )
)
MSELoss()
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0
)
---Q Learning Parameters---
Normalisation: False
Punishment Coefficient: 0.35
Alpha: 0.8
Epsilon: 0.01
Gamma: 0.97
Initial Episode Number: 0
Episode Number Coefficient: 1.4
Number of Random Features: 20
Planning Number: 20
Max Random Features: 60
New Episode Number: 72
New Episode Number: 143
New Episode Number: 215
New Episode Number: 286
New Episode Number: 358
New Episode Number: 429
New Episode Number: 500
New Episode Number: 572
New Episode Number: 643
New Episode Number: 715
New Episode Number: 786
New Episode Number: 858
New Episode Number: 929
New Episode Number: 1000
New Episode Number: 1072
New Episode Number: 1143
New Episode Number: 1215
New Episode Number: 1286
New Episode Number: 1358
New Episode Number: 1429
New Episode Number: 1501
New Episode Number: 1572
New Episode Number: 1643
New Episode Number: 1715
New Episode Number: 1786
New Episode Number: 1858
New Episode Number: 1929
New Episode Number: 2000
New Episode Number: 2072
               0     1      2      3      4   ...     25    26     27    28    29
new_cluster -2.52 -6.39 -11.17 -10.30 -17.40  ... -15.53 -8.70 -10.73 -2.10 -3.36
c1          -2.52 -6.26 -12.21 -10.53 -16.96  ... -15.53 -8.93 -10.22 -2.05 -3.41
c2          -2.53 -6.55 -12.17 -10.27 -17.56  ... -15.57 -8.54 -11.41 -2.09 -3.41
c3          -2.52 -6.17 -12.45  -9.67 -18.07  ... -15.56 -8.74 -10.07 -2.11 -3.41
c4          -2.57 -6.28 -12.13  -9.79 -17.32  ... -15.57 -8.54 -10.37 -2.12 -3.42
c5          -2.53 -6.73 -12.08 -10.36 -17.10  ... -15.45 -8.69 -11.10 -2.11 -3.40
c6          -2.52 -6.22 -12.29 -10.72 -18.61  ... -15.53 -8.89 -11.30 -2.09 -3.41
c7          -2.52 -5.95 -11.81 -10.04 -17.30  ... -15.53 -8.82 -10.48 -2.08 -3.41
c8          -2.53 -6.09 -11.89 -10.22 -19.08  ... -15.46 -8.78 -10.83 -2.09 -3.36
c9          -2.53 -5.94 -11.90 -10.80 -18.45  ... -15.51 -9.22 -10.15 -2.09 -3.40
c10         -2.52 -5.90 -11.52  -9.82 -17.62  ... -15.53 -8.38 -11.00 -2.10 -3.40
c11         -2.53 -6.28 -11.86 -10.16 -17.04  ... -15.53 -8.68 -10.19 -2.07 -3.43
c12         -2.52 -5.99 -11.95 -10.04 -17.78  ... -15.53 -8.43 -11.10 -2.06 -3.41
c13         -2.53 -5.96 -12.27 -10.57 -18.29  ... -15.53 -8.68 -10.23 -1.99 -3.40
c14         -2.53 -6.23 -12.18 -10.01 -17.98  ... -15.53 -8.72 -11.41 -2.05 -3.40
c15         -2.52 -6.48 -12.32 -10.37 -18.45  ... -15.53 -8.73 -11.84 -2.04 -3.41
c16         -2.53 -6.25 -12.16 -10.07 -18.00  ... -15.53 -8.45 -11.03 -2.13 -3.42
c17         -2.53 -6.07 -12.03 -10.17 -18.27  ... -15.53 -8.59 -10.79 -2.09 -3.41
c18         -2.53 -6.18 -12.37 -10.55 -17.42  ... -15.55 -8.50 -11.30 -2.09 -3.43
c19         -2.52 -6.04 -11.93 -10.26 -18.44  ... -15.57 -9.00 -11.22 -2.10 -3.40
c20         -2.52 -6.13 -12.35 -10.10 -17.66  ... -15.46 -8.86 -11.37 -2.08 -3.42
c21         -2.53 -6.39 -12.05  -9.78 -16.87  ... -15.53 -8.72 -11.76 -2.07 -3.41
c22         -2.52 -6.59 -12.32 -10.43 -18.25  ... -15.54 -8.86 -10.83 -2.09 -3.40
c23         -2.52 -6.31 -11.85  -9.89 -17.15  ... -15.53 -8.56  -9.65 -2.14 -3.39
c24         -2.53 -6.04 -12.14 -10.23 -17.95  ... -15.53 -8.42 -11.40 -2.12 -3.41
c25         -2.53 -6.52 -11.65 -10.04 -17.15  ... -15.53 -8.84 -11.49 -2.05 -3.40
c26         -2.52 -6.35 -12.14  -9.98 -17.87  ... -15.53 -8.72 -11.32 -2.09 -3.41
c27         -2.52 -6.27 -12.06 -10.32 -18.10  ... -15.53 -8.74 -12.91 -2.04 -3.41
c28         -2.53 -6.27 -12.59 -10.13 -17.74  ... -15.57 -8.62 -11.36 -2.08 -3.40
c29         -2.53 -6.32 -12.04 -10.25 -16.89  ... -15.47 -8.77  -9.91 -2.10 -3.42

[30 rows x 30 columns]
                               0            1   ...            28            29
new_cluster  [-0.49, new_cluster]   [-4.4, c1]  ...  [-0.05, c28]  [-1.39, c29]
c1           [-0.49, new_cluster]  [-4.27, c1]  ...  [-0.05, c28]  [-1.39, c29]
c2           [-0.49, new_cluster]  [-4.61, c1]  ...  [-0.07, c28]  [-1.39, c29]
c3           [-0.49, new_cluster]  [-4.18, c1]  ...  [-0.07, c28]  [-1.39, c29]
c4           [-0.49, new_cluster]  [-4.29, c1]  ...   [-0.1, c28]  [-1.39, c29]
c5           [-0.49, new_cluster]  [-4.82, c1]  ...  [-0.06, c28]  [-1.39, c29]
c6           [-0.49, new_cluster]  [-4.23, c1]  ...  [-0.07, c28]  [-1.39, c29]
c7           [-0.49, new_cluster]  [-3.96, c1]  ...  [-0.04, c28]  [-1.39, c29]
c8           [-0.49, new_cluster]   [-4.1, c1]  ...  [-0.09, c28]  [-1.39, c29]
c9           [-0.49, new_cluster]  [-3.96, c1]  ...  [-0.04, c28]  [-1.39, c29]
c10          [-0.49, new_cluster]  [-3.91, c1]  ...  [-0.07, c28]  [-1.39, c29]
c11          [-0.49, new_cluster]  [-4.29, c1]  ...  [-0.07, c28]  [-1.39, c29]
c12          [-0.49, new_cluster]   [-4.0, c1]  ...  [-0.06, c28]  [-1.39, c29]
c13          [-0.49, new_cluster]  [-3.97, c1]  ...  [-0.04, c28]  [-1.39, c29]
c14          [-0.49, new_cluster]  [-4.25, c1]  ...  [-0.06, c28]  [-1.39, c29]
c15          [-0.49, new_cluster]  [-4.49, c1]  ...  [-0.04, c28]  [-1.39, c29]
c16          [-0.49, new_cluster]  [-4.26, c1]  ...  [-0.08, c28]  [-1.39, c29]
c17          [-0.49, new_cluster]  [-4.08, c1]  ...   [-0.1, c28]  [-1.39, c29]
c18          [-0.49, new_cluster]  [-4.19, c1]  ...  [-0.06, c28]  [-1.39, c29]
c19          [-0.49, new_cluster]  [-4.05, c1]  ...  [-0.11, c28]  [-1.39, c29]
c20          [-0.49, new_cluster]  [-4.15, c1]  ...  [-0.05, c28]  [-1.39, c29]
c21          [-0.49, new_cluster]   [-4.4, c1]  ...  [-0.07, c28]  [-1.39, c29]
c22          [-0.49, new_cluster]  [-4.61, c1]  ...  [-0.07, c28]  [-1.39, c29]
c23          [-0.49, new_cluster]  [-4.32, c1]  ...  [-0.07, c28]  [-1.39, c29]
c24          [-0.49, new_cluster]  [-4.05, c1]  ...   [-0.1, c28]  [-1.39, c29]
c25          [-0.49, new_cluster]  [-4.58, c1]  ...  [-0.04, c28]  [-1.39, c29]
c26          [-0.49, new_cluster]  [-4.37, c1]  ...  [-0.06, c28]  [-1.39, c29]
c27          [-0.49, new_cluster]  [-4.28, c1]  ...  [-0.05, c28]  [-1.39, c29]
c28          [-0.49, new_cluster]  [-4.28, c1]  ...  [-0.05, c28]  [-1.39, c29]
c29          [-0.49, new_cluster]  [-4.33, c1]  ...   [-0.1, c28]  [-1.39, c29]

[30 rows x 30 columns]
