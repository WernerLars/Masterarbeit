Experiment_path: Random_Seeds_DV5//V5_2/Experiment_05_5_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: Random_Seeds_DV5//V5_2/Experiment_05_5_opt_temp/C_Easy1_noise005.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_04_16-16_26_01
Punishment_Coefficient: 0.8
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x00000211F1F0E198>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.11378381960093975
Online_Training [2/700]: mean_loss=0.14569642767310143
Online_Training [3/700]: mean_loss=0.3465648368000984
Online_Training [4/700]: mean_loss=0.30821581184864044
Online_Training [5/700]: mean_loss=0.3031958043575287
Online_Training [6/700]: mean_loss=0.10264960024505854
Online_Training [7/700]: mean_loss=0.11891445145010948
Online_Training [8/700]: mean_loss=0.24106628447771072
Online_Training [9/700]: mean_loss=0.1108841085806489
Online_Training [10/700]: mean_loss=0.10161155182868242
Online_Training [11/700]: mean_loss=0.0898919515311718
Online_Training [12/700]: mean_loss=0.08347065933048725
Online_Training [13/700]: mean_loss=0.06383528374135494
Online_Training [14/700]: mean_loss=0.10517256055027246
Online_Training [15/700]: mean_loss=0.16720999777317047
Online_Training [16/700]: mean_loss=0.09873457066714764
Online_Training [17/700]: mean_loss=0.1346427695825696
Online_Training [18/700]: mean_loss=0.10138465743511915
Online_Training [19/700]: mean_loss=0.07790478877723217
Online_Training [20/700]: mean_loss=0.0683499937877059
Online_Training [21/700]: mean_loss=0.12451483961194754
Online_Training [22/700]: mean_loss=0.08019751310348511
Online_Training [23/700]: mean_loss=0.06336079631000757
Online_Training [24/700]: mean_loss=0.02889834577217698
Online_Training [25/700]: mean_loss=0.09824888035655022
Online_Training [26/700]: mean_loss=0.08337032422423363
Online_Training [27/700]: mean_loss=0.07460478320717812
Online_Training [28/700]: mean_loss=0.06427119299769402
Online_Training [29/700]: mean_loss=0.025956159690394998
Online_Training [30/700]: mean_loss=0.013515172991901636
Online_Training [31/700]: mean_loss=0.05634578038007021
Online_Training [32/700]: mean_loss=0.0036392773617990315
Online_Training [33/700]: mean_loss=0.004477213427890092
Online_Training [34/700]: mean_loss=0.0430068732239306
Online_Training [35/700]: mean_loss=0.003896680223988369
Online_Training [36/700]: mean_loss=0.12112633883953094
Online_Training [37/700]: mean_loss=0.03942429181188345
Online_Training [38/700]: mean_loss=0.06386475590988994
Online_Training [39/700]: mean_loss=0.027646030532196164
Online_Training [40/700]: mean_loss=0.046223084442317486
Online_Training [41/700]: mean_loss=0.03945527505129576
Online_Training [42/700]: mean_loss=0.014422473148442805
Online_Training [43/700]: mean_loss=0.03279201127588749
Online_Training [44/700]: mean_loss=0.0054357983462978154
Online_Training [45/700]: mean_loss=0.04014566075056791
Online_Training [46/700]: mean_loss=0.03388096811249852
Online_Training [47/700]: mean_loss=0.12328022625297308
Online_Training [48/700]: mean_loss=0.12173986062407494
Online_Training [49/700]: mean_loss=0.005823952495120466
Online_Training [50/700]: mean_loss=0.026925336802378297
Online_Training [51/700]: mean_loss=0.005742514447774738
Online_Training [52/700]: mean_loss=0.0029296272550709546
Online_Training [53/700]: mean_loss=0.06685317726805806
Online_Training [54/700]: mean_loss=0.23163851909339428
Online_Training [55/700]: mean_loss=0.040016531478613615
Online_Training [56/700]: mean_loss=0.03896057698875666
Online_Training [57/700]: mean_loss=0.03477877774275839
Online_Training [58/700]: mean_loss=0.021796627203002572
Online_Training [59/700]: mean_loss=0.12643650453537703
Online_Training [60/700]: mean_loss=0.021049436880275607
Online_Training [61/700]: mean_loss=0.020224187523126602
Online_Training [62/700]: mean_loss=0.01669733866583556
Online_Training [63/700]: mean_loss=0.0302447575959377
Online_Training [64/700]: mean_loss=0.007767293805954978
Online_Training [65/700]: mean_loss=0.016839124844409525
Online_Training [66/700]: mean_loss=0.00883120036451146
Online_Training [67/700]: mean_loss=0.002639179743709974
Online_Training [68/700]: mean_loss=0.1379548292607069
Online_Training [69/700]: mean_loss=0.00694007589481771
Online_Training [70/700]: mean_loss=0.007688389392569661
Online_Training [71/700]: mean_loss=0.004523785260971636
Online_Training [72/700]: mean_loss=0.00863642303738743
Online_Training [73/700]: mean_loss=0.006656681071035564
Online_Training [74/700]: mean_loss=0.004530370119027793
Online_Training [75/700]: mean_loss=0.006843132490757853
Online_Training [76/700]: mean_loss=0.0015881327854003757
Online_Training [77/700]: mean_loss=0.0011284384818281978
Online_Training [78/700]: mean_loss=0.0059804850607179105
Online_Training [79/700]: mean_loss=0.021095941308885813
Online_Training [80/700]: mean_loss=0.009066440281458199
Online_Training [81/700]: mean_loss=0.004238629771862179
Online_Training [82/700]: mean_loss=0.010614185477606952
Online_Training [83/700]: mean_loss=0.009619259624741971
Online_Training [84/700]: mean_loss=0.003870310145430267
Online_Training [85/700]: mean_loss=0.006695855816360563
Online_Training [86/700]: mean_loss=0.011173600738402456
Online_Training [87/700]: mean_loss=0.0039586837228853256
Online_Training [88/700]: mean_loss=0.012083948473446071
Online_Training [89/700]: mean_loss=0.003375221771420911
Online_Training [90/700]: mean_loss=0.006692660448607057
Online_Training [91/700]: mean_loss=0.006360071012750268
Online_Training [92/700]: mean_loss=0.005908198218094185
Online_Training [93/700]: mean_loss=0.0026007721753558144
Online_Training [94/700]: mean_loss=0.004308858304284513
Online_Training [95/700]: mean_loss=0.0021307508723111823
Online_Training [96/700]: mean_loss=0.005638326314510778
Online_Training [97/700]: mean_loss=0.007091007602866739
Online_Training [98/700]: mean_loss=0.0045183427282609046
Online_Training [99/700]: mean_loss=0.00704635086003691
Online_Training [100/700]: mean_loss=0.0008382177147723269
Online_Training [101/700]: mean_loss=0.0036532851518131793
Online_Training [102/700]: mean_loss=0.0034278151870239526
Online_Training [103/700]: mean_loss=0.006009891338180751
Online_Training [104/700]: mean_loss=0.0020912275358568877
Online_Training [105/700]: mean_loss=0.02852273383177817
Online_Training [106/700]: mean_loss=0.020367871737107635
Online_Training [107/700]: mean_loss=0.003751713637029752
Online_Training [108/700]: mean_loss=0.01116185321006924
Online_Training [109/700]: mean_loss=0.004720610653748736
Online_Training [110/700]: mean_loss=0.004416843847138807
Online_Training [111/700]: mean_loss=0.002621307998197153
Online_Training [112/700]: mean_loss=0.005015082162572071
Online_Training [113/700]: mean_loss=0.008519547816831619
Online_Training [114/700]: mean_loss=0.008824893389828503
Online_Training [115/700]: mean_loss=0.014818043331615627
Online_Training [116/700]: mean_loss=0.0030650332337245345
Online_Training [117/700]: mean_loss=0.0066639899159781635
Online_Training [118/700]: mean_loss=0.0038257840496953577
Online_Training [119/700]: mean_loss=0.004224900418194011
Online_Training [120/700]: mean_loss=0.00764397851889953
Online_Training [121/700]: mean_loss=0.002642429550178349
Online_Training [122/700]: mean_loss=0.00685603340389207
Online_Training [123/700]: mean_loss=0.0012325898569542915
Online_Training [124/700]: mean_loss=0.006199013674631715
Online_Training [125/700]: mean_loss=0.001375205596559681
Online_Training [126/700]: mean_loss=0.0017712757544359192
Online_Training [127/700]: mean_loss=0.005139496643096209
Online_Training [128/700]: mean_loss=0.008670606941450387
Online_Training [129/700]: mean_loss=0.0028632140019908547
Online_Training [130/700]: mean_loss=0.004077653255080804
Online_Training [131/700]: mean_loss=0.003680830239318311
Online_Training [132/700]: mean_loss=0.0026969888858729973
Online_Training [133/700]: mean_loss=0.004076244775205851
Online_Training [134/700]: mean_loss=0.0058758028608281165
Online_Training [135/700]: mean_loss=0.0025493456923868507
Online_Training [136/700]: mean_loss=0.0008580955254728906
Online_Training [137/700]: mean_loss=0.004060837236465886
Online_Training [138/700]: mean_loss=0.0032189814373850822
Online_Training [139/700]: mean_loss=0.0025579198336345144
Online_Training [140/700]: mean_loss=0.002777855785097927
Online_Training [141/700]: mean_loss=0.003576757895643823
Online_Training [142/700]: mean_loss=0.00507017585914582
Online_Training [143/700]: mean_loss=0.232892582193017
Online_Training [144/700]: mean_loss=0.08423824608325958
Online_Training [145/700]: mean_loss=0.1540049696341157
Online_Training [146/700]: mean_loss=0.20604431256651878
Online_Training [147/700]: mean_loss=0.011294421157799661
Online_Training [148/700]: mean_loss=0.007740897010080516
Online_Training [149/700]: mean_loss=0.01156171690672636
Online_Training [150/700]: mean_loss=0.16648542135953903
Online_Training [151/700]: mean_loss=0.25448198057711124
Online_Training [152/700]: mean_loss=0.016828362829983234
Online_Training [153/700]: mean_loss=0.008841614588163793
Online_Training [154/700]: mean_loss=0.0074221568065695465
Online_Training [155/700]: mean_loss=0.060919263400137424
Online_Training [156/700]: mean_loss=0.016288741258904338
Online_Training [157/700]: mean_loss=0.006445634411647916
Online_Training [158/700]: mean_loss=0.02676629228517413
Online_Training [159/700]: mean_loss=0.006638501130510122
Online_Training [160/700]: mean_loss=0.019423441728577018
Online_Training [161/700]: mean_loss=0.003130506578600034
Online_Training [162/700]: mean_loss=0.052125255577266216
Online_Training [163/700]: mean_loss=0.17720889672636986
Online_Training [164/700]: mean_loss=0.01804020954295993
Online_Training [165/700]: mean_loss=0.008503059740178287
Online_Training [166/700]: mean_loss=0.020686706760898232
Online_Training [167/700]: mean_loss=0.007210750423837453
Online_Training [168/700]: mean_loss=0.009323140373453498
Online_Training [169/700]: mean_loss=0.0019846200302708894
Online_Training [170/700]: mean_loss=0.004188444145256653
Online_Training [171/700]: mean_loss=0.017564886598847806
Online_Training [172/700]: mean_loss=0.02445235406048596
Online_Training [173/700]: mean_loss=0.02690748800523579
Online_Training [174/700]: mean_loss=0.01163200126029551
Online_Training [175/700]: mean_loss=0.019718393683433533
Online_Training [176/700]: mean_loss=0.001299829687923193
Online_Training [177/700]: mean_loss=0.006021750770742074
Online_Training [178/700]: mean_loss=0.0037408798234537244
Online_Training [179/700]: mean_loss=0.005423784430604428
Online_Training [180/700]: mean_loss=0.00918440253008157
Online_Training [181/700]: mean_loss=0.0035348576202522963
Online_Training [182/700]: mean_loss=0.002358555211685598
Online_Training [183/700]: mean_loss=0.006536435277666897
Online_Training [184/700]: mean_loss=0.0034022122563328594
Online_Training [185/700]: mean_loss=0.003585572529118508
Online_Training [186/700]: mean_loss=0.002742555661825463
Online_Training [187/700]: mean_loss=0.0016559527721256018
Online_Training [188/700]: mean_loss=0.087472815066576
Online_Training [189/700]: mean_loss=0.0939863882958889
Online_Training [190/700]: mean_loss=0.014437754638493061
Online_Training [191/700]: mean_loss=0.03825535997748375
Online_Training [192/700]: mean_loss=0.007346369151491672
Online_Training [193/700]: mean_loss=0.01203676057048142
Online_Training [194/700]: mean_loss=0.03751215455122292
Online_Training [195/700]: mean_loss=0.010530850267969072
Online_Training [196/700]: mean_loss=0.007966732315253466
Online_Training [197/700]: mean_loss=0.0031613124738214538
Online_Training [198/700]: mean_loss=0.005868360924068838
Online_Training [199/700]: mean_loss=0.007339539297390729
Online_Training [200/700]: mean_loss=0.00884359993506223
Online_Training [201/700]: mean_loss=0.010324737406335771
Online_Training [202/700]: mean_loss=0.007765653484966606
Online_Training [203/700]: mean_loss=0.002216233449871652
Online_Training [204/700]: mean_loss=0.007140406058169901
Online_Training [205/700]: mean_loss=0.0030602964689023793
Online_Training [206/700]: mean_loss=0.007836904667783529
Online_Training [207/700]: mean_loss=0.005057744303485379
Online_Training [208/700]: mean_loss=0.003930913168005645
Online_Training [209/700]: mean_loss=0.006657181074842811
Online_Training [210/700]: mean_loss=0.007989711361005902
Online_Training [211/700]: mean_loss=0.004194034729152918
Online_Training [212/700]: mean_loss=0.004399640834890306
Online_Training [213/700]: mean_loss=0.004628392052836716
Online_Training [214/700]: mean_loss=0.003753426222829148
Online_Training [215/700]: mean_loss=0.004888262366876006
Online_Training [216/700]: mean_loss=0.0021148325176909566
Online_Training [217/700]: mean_loss=0.0022963393421377987
Online_Training [218/700]: mean_loss=0.00251974692218937
Online_Training [219/700]: mean_loss=0.00702630402520299
Online_Training [220/700]: mean_loss=0.007831336057279259
Online_Training [221/700]: mean_loss=0.007097334135323763
Online_Training [222/700]: mean_loss=0.0026223461027257144
Online_Training [223/700]: mean_loss=0.000650430767564103
Online_Training [224/700]: mean_loss=0.004928916459903121
Online_Training [225/700]: mean_loss=0.00111700998240849
Online_Training [226/700]: mean_loss=0.0018327974248677492
Online_Training [227/700]: mean_loss=0.009358133189380169
Online_Training [228/700]: mean_loss=0.006307220435701311
Online_Training [229/700]: mean_loss=0.004364815889857709
Online_Training [230/700]: mean_loss=0.0033403131819795817
Online_Training [231/700]: mean_loss=0.0015892383962636814
Online_Training [232/700]: mean_loss=0.002845591341610998
Online_Training [233/700]: mean_loss=0.004716362163890153
Online_Training [234/700]: mean_loss=0.006356388330459595
Online_Training [235/700]: mean_loss=0.005384986172430217
Online_Training [236/700]: mean_loss=0.01051547157112509
Online_Training [237/700]: mean_loss=0.0020999460539314896
Online_Training [238/700]: mean_loss=0.0041448575793765485
Online_Training [239/700]: mean_loss=0.0016789575456641614
Online_Training [240/700]: mean_loss=0.007265750027727336
Online_Training [241/700]: mean_loss=0.010124713997356594
Online_Training [242/700]: mean_loss=0.004054831137182191
Online_Training [243/700]: mean_loss=0.008128808229230344
Online_Training [244/700]: mean_loss=0.002890591829782352
Online_Training [245/700]: mean_loss=0.0019182762480340898
Online_Training [246/700]: mean_loss=0.003826087398920208
Online_Training [247/700]: mean_loss=0.0016931171412579715
Online_Training [248/700]: mean_loss=0.020147958304733038
Online_Training [249/700]: mean_loss=0.011215437203645706
Online_Training [250/700]: mean_loss=0.004060051607666537
Online_Training [251/700]: mean_loss=0.01393909053876996
Online_Training [252/700]: mean_loss=0.004153102374402806
Online_Training [253/700]: mean_loss=0.0015332011244026944
Online_Training [254/700]: mean_loss=0.003675067506264895
Online_Training [255/700]: mean_loss=0.002856093386071734
Online_Training [256/700]: mean_loss=0.09796388074755669
Online_Training [257/700]: mean_loss=0.08234456926584244
Online_Training [258/700]: mean_loss=0.010041516274213791
Online_Training [259/700]: mean_loss=0.0016497103351866826
Online_Training [260/700]: mean_loss=0.002932189905550331
Online_Training [261/700]: mean_loss=0.013633297756314278
Online_Training [262/700]: mean_loss=0.011346634244546294
Online_Training [263/700]: mean_loss=0.004285441158572212
Online_Training [264/700]: mean_loss=0.005453611142002046
Online_Training [265/700]: mean_loss=0.001623116637347266
Online_Training [266/700]: mean_loss=0.001638486617594026
Online_Training [267/700]: mean_loss=0.0026353175344411284
Online_Training [268/700]: mean_loss=0.010748975328169763
Online_Training [269/700]: mean_loss=0.010137799079529941
Online_Training [270/700]: mean_loss=0.003610531333833933
Online_Training [271/700]: mean_loss=0.004863157373620197
Online_Training [272/700]: mean_loss=0.0026060885575134307
Online_Training [273/700]: mean_loss=0.0047194313374347985
Online_Training [274/700]: mean_loss=0.0018517647113185376
Online_Training [275/700]: mean_loss=0.19184214249253273
Online_Training [276/700]: mean_loss=0.058139719534665346
Online_Training [277/700]: mean_loss=0.017643170314840972
Online_Training [278/700]: mean_loss=0.014106677728705108
Online_Training [279/700]: mean_loss=0.0017644476174609736
Online_Training [280/700]: mean_loss=0.00773140590172261
Online_Training [281/700]: mean_loss=0.00507810537237674
Online_Training [282/700]: mean_loss=0.007421135203912854
Online_Training [283/700]: mean_loss=0.009392966632731259
Online_Training [284/700]: mean_loss=0.005389284197008237
Online_Training [285/700]: mean_loss=0.009709400357678533
Online_Training [286/700]: mean_loss=0.006878130079712719
Online_Training [287/700]: mean_loss=0.0025765043683350086
Online_Training [288/700]: mean_loss=0.001785552900400944
Online_Training [289/700]: mean_loss=0.003978232300141826
Online_Training [290/700]: mean_loss=0.002406209649052471
Online_Training [291/700]: mean_loss=0.005720421788282692
Online_Training [292/700]: mean_loss=0.0018253527086926624
Online_Training [293/700]: mean_loss=0.004817392269615084
Online_Training [294/700]: mean_loss=0.002684680715901777
Online_Training [295/700]: mean_loss=0.001481628802139312
Online_Training [296/700]: mean_loss=0.176914531737566
Online_Training [297/700]: mean_loss=0.084306126460433
Online_Training [298/700]: mean_loss=0.017649690620601177
Online_Training [299/700]: mean_loss=0.015366556472145021
Online_Training [300/700]: mean_loss=0.00680446409387514
Online_Training [301/700]: mean_loss=0.010557135450653732
Online_Training [302/700]: mean_loss=0.00730573880719021
Online_Training [303/700]: mean_loss=0.0033150930830743164
Online_Training [304/700]: mean_loss=0.005459423991851509
Online_Training [305/700]: mean_loss=0.0073122354806400836
Online_Training [306/700]: mean_loss=0.009728271397762
Online_Training [307/700]: mean_loss=0.003915383626008406
Online_Training [308/700]: mean_loss=0.002544370654504746
Online_Training [309/700]: mean_loss=0.0036722041404573247
Online_Training [310/700]: mean_loss=0.00283142295666039
Online_Training [311/700]: mean_loss=0.007013134192675352
Online_Training [312/700]: mean_loss=0.003120416367892176
Online_Training [313/700]: mean_loss=0.003053384949453175
Online_Training [314/700]: mean_loss=0.00893852609442547
Online_Training [315/700]: mean_loss=0.008743621408939362
Online_Training [316/700]: mean_loss=0.003234578383853659
Online_Training [317/700]: mean_loss=0.005785131070297211
Online_Training [318/700]: mean_loss=0.005803461972391233
Online_Training [319/700]: mean_loss=0.003443479596171528
Online_Training [320/700]: mean_loss=0.005506271088961512
Online_Training [321/700]: mean_loss=0.0025802918971749023
Online_Training [322/700]: mean_loss=0.0011437945649959147
Online_Training [323/700]: mean_loss=0.10883031971752644
Online_Training [324/700]: mean_loss=0.10462530050426722
Online_Training [325/700]: mean_loss=0.012025352683849633
Online_Training [326/700]: mean_loss=0.002194121349020861
Online_Training [327/700]: mean_loss=0.029033382423222065
Online_Training [328/700]: mean_loss=0.014088037074543536
Online_Training [329/700]: mean_loss=0.002952629030914977
Online_Training [330/700]: mean_loss=0.012527838116511703
Online_Training [331/700]: mean_loss=0.0030636946321465075
Online_Training [332/700]: mean_loss=0.006631241994909942
Online_Training [333/700]: mean_loss=0.007962906616739929
Online_Training [334/700]: mean_loss=0.011084221070632339
Online_Training [335/700]: mean_loss=0.006401828897651285
Online_Training [336/700]: mean_loss=0.0050639998516999185
Online_Training [337/700]: mean_loss=0.013902170030632988
Online_Training [338/700]: mean_loss=0.005288063490297645
Online_Training [339/700]: mean_loss=0.014016166576766409
Online_Training [340/700]: mean_loss=0.0019434754940448329
Online_Training [341/700]: mean_loss=0.003263186023104936
Online_Training [342/700]: mean_loss=0.008039308595471084
Online_Training [343/700]: mean_loss=0.012926488765515387
Online_Training [344/700]: mean_loss=0.003674941079225391
Online_Training [345/700]: mean_loss=0.0033129792427644134
Online_Training [346/700]: mean_loss=0.009608223801478744
Online_Training [347/700]: mean_loss=0.027063292218372226
Online_Training [348/700]: mean_loss=0.0038081762904766947
Online_Training [349/700]: mean_loss=0.00286770160892047
Online_Training [350/700]: mean_loss=0.019928914756746963
Online_Training [351/700]: mean_loss=0.006017262174282223
Online_Training [352/700]: mean_loss=0.007069270533975214
Online_Training [353/700]: mean_loss=0.004715076007414609
Online_Training [354/700]: mean_loss=0.026180344924796373
Online_Training [355/700]: mean_loss=0.00446602089505177
Online_Training [356/700]: mean_loss=0.0072109566535800695
Online_Training [357/700]: mean_loss=0.00263372779591009
Online_Training [358/700]: mean_loss=0.004087545850779861
Online_Training [359/700]: mean_loss=0.0095406403997913
Online_Training [360/700]: mean_loss=0.003247797620133497
Online_Training [361/700]: mean_loss=0.00908552051987499
Online_Training [362/700]: mean_loss=0.22143534384667873
Online_Training [363/700]: mean_loss=0.08297970658168197
Online_Training [364/700]: mean_loss=0.012212461209855974
Online_Training [365/700]: mean_loss=0.013459859415888786
Online_Training [366/700]: mean_loss=0.03758512972854078
Online_Training [367/700]: mean_loss=0.004629774310160428
Online_Training [368/700]: mean_loss=0.0035593633947428316
Online_Training [369/700]: mean_loss=0.012940128915943205
Online_Training [370/700]: mean_loss=0.005568108696024865
Online_Training [371/700]: mean_loss=0.0127541912952438
Online_Training [372/700]: mean_loss=0.0037758784601464868
Online_Training [373/700]: mean_loss=0.004776104498887435
Online_Training [374/700]: mean_loss=0.06833334220573306
Online_Training [375/700]: mean_loss=0.011695758905261755
Online_Training [376/700]: mean_loss=0.007427925360389054
Online_Training [377/700]: mean_loss=0.009614841779693961
Online_Training [378/700]: mean_loss=0.011662391247227788
Online_Training [379/700]: mean_loss=0.005009428015910089
Online_Training [380/700]: mean_loss=0.0036281106586102396
Online_Training [381/700]: mean_loss=0.006016069673933089
Online_Training [382/700]: mean_loss=0.007479395251721144
Online_Training [383/700]: mean_loss=0.007796806719852611
Online_Training [384/700]: mean_loss=0.004741735057905316
Online_Training [385/700]: mean_loss=0.004563640977721661
Online_Training [386/700]: mean_loss=0.008760349883232266
Online_Training [387/700]: mean_loss=0.010471355286426842
Online_Training [388/700]: mean_loss=0.0741457692347467
Online_Training [389/700]: mean_loss=0.31905391067266464
Online_Training [390/700]: mean_loss=0.08112566359341145
Online_Training [391/700]: mean_loss=0.013908962602727115
Online_Training [392/700]: mean_loss=0.011789696058258414
Online_Training [393/700]: mean_loss=0.014327107928693295
Online_Training [394/700]: mean_loss=0.0066262135514989495
Online_Training [395/700]: mean_loss=0.007946347119286656
Online_Training [396/700]: mean_loss=0.022563925595022738
Online_Training [397/700]: mean_loss=0.012473971699364483
Online_Training [398/700]: mean_loss=0.005787468748167157
Online_Training [399/700]: mean_loss=0.013087917119264603
Online_Training [400/700]: mean_loss=0.003235850279452279
Online_Training [401/700]: mean_loss=0.005957099434453994
Online_Training [402/700]: mean_loss=0.004380109487101436
Online_Training [403/700]: mean_loss=0.0062161228561308235
Online_Training [404/700]: mean_loss=0.003969296289142221
Online_Training [405/700]: mean_loss=0.004991767345927656
Online_Training [406/700]: mean_loss=0.004880142747424543
Online_Training [407/700]: mean_loss=0.004833347629755735
Online_Training [408/700]: mean_loss=0.00447570372489281
Online_Training [409/700]: mean_loss=0.0049431719235144556
Online_Training [410/700]: mean_loss=0.006258469715248793
Online_Training [411/700]: mean_loss=0.004171702166786417
Online_Training [412/700]: mean_loss=0.003928312042262405
Online_Training [413/700]: mean_loss=0.0022561999212484807
Online_Training [414/700]: mean_loss=0.004891975549980998
Online_Training [415/700]: mean_loss=0.010518656461499631
Online_Training [416/700]: mean_loss=0.008237009169533849
Online_Training [417/700]: mean_loss=0.005273807219055016
Online_Training [418/700]: mean_loss=0.0037417474668473005
Online_Training [419/700]: mean_loss=0.0041564464481780306
Online_Training [420/700]: mean_loss=0.002205170865636319
Online_Training [421/700]: mean_loss=0.013021021382883191
Online_Training [422/700]: mean_loss=0.002580637577921152
Online_Training [423/700]: mean_loss=0.00327979915891774
Online_Training [424/700]: mean_loss=0.006666843459242955
Online_Training [425/700]: mean_loss=0.006848481367342174
Online_Training [426/700]: mean_loss=0.07095273584127426
Online_Training [427/700]: mean_loss=0.0867256224155426
Online_Training [428/700]: mean_loss=0.01246668049134314
Online_Training [429/700]: mean_loss=0.010207080282270908
Online_Training [430/700]: mean_loss=0.007320312957745045
Online_Training [431/700]: mean_loss=0.03596089594066143
Online_Training [432/700]: mean_loss=0.027934022014960647
Online_Training [433/700]: mean_loss=0.00923950260039419
Online_Training [434/700]: mean_loss=0.011178767425008118
Online_Training [435/700]: mean_loss=0.007682752329856157
Online_Training [436/700]: mean_loss=0.009538528538541868
Online_Training [437/700]: mean_loss=0.006835340172983706
Online_Training [438/700]: mean_loss=0.0066530086332932115
Online_Training [439/700]: mean_loss=0.009616173338145018
Online_Training [440/700]: mean_loss=0.00632272002985701
Online_Training [441/700]: mean_loss=0.005244163214229047
Online_Training [442/700]: mean_loss=0.005284887622110546
Online_Training [443/700]: mean_loss=0.06632267637178302
Online_Training [444/700]: mean_loss=0.0035405851085670292
Online_Training [445/700]: mean_loss=0.0034661382669582963
Online_Training [446/700]: mean_loss=0.0047382491757161915
Online_Training [447/700]: mean_loss=0.009243258740752935
Online_Training [448/700]: mean_loss=0.0047964440018404275
Online_Training [449/700]: mean_loss=0.003910742321750149
Online_Training [450/700]: mean_loss=0.005510626651812345
Online_Training [451/700]: mean_loss=0.0034955744340550154
Online_Training [452/700]: mean_loss=0.01000177173409611
Online_Training [453/700]: mean_loss=0.00504816067405045
Online_Training [454/700]: mean_loss=0.0020033861801493913
Online_Training [455/700]: mean_loss=0.007272734248545021
Online_Training [456/700]: mean_loss=0.007507962174713612
Online_Training [457/700]: mean_loss=0.005682001472450793
Online_Training [458/700]: mean_loss=0.0005747125906054862
Online_Training [459/700]: mean_loss=0.002076688557281159
Online_Training [460/700]: mean_loss=0.012838607421144843
Online_Training [461/700]: mean_loss=0.006756595859769732
Online_Training [462/700]: mean_loss=0.07769203558564186
Online_Training [463/700]: mean_loss=0.07698352728039026
Online_Training [464/700]: mean_loss=0.011173782870173454
Online_Training [465/700]: mean_loss=0.008852664032019675
Online_Training [466/700]: mean_loss=0.006542619317770004
Online_Training [467/700]: mean_loss=0.002710634929826483
Online_Training [468/700]: mean_loss=0.007225302746519446
Online_Training [469/700]: mean_loss=0.010293528204783797
Online_Training [470/700]: mean_loss=0.008861802809406072
Online_Training [471/700]: mean_loss=0.005230900482274592
Online_Training [472/700]: mean_loss=0.002495766297215596
Online_Training [473/700]: mean_loss=0.007633314089616761
Online_Training [474/700]: mean_loss=0.001938486413564533
Online_Training [475/700]: mean_loss=0.001654383959248662
Online_Training [476/700]: mean_loss=0.007000564888585359
Online_Training [477/700]: mean_loss=0.0036570734228007495
Online_Training [478/700]: mean_loss=0.004950367932906374
Online_Training [479/700]: mean_loss=0.004074262542417273
Online_Training [480/700]: mean_loss=0.004460551077499986
Online_Training [481/700]: mean_loss=0.007735770253930241
Online_Training [482/700]: mean_loss=0.0117824588669464
Online_Training [483/700]: mean_loss=0.009592066169716418
Online_Training [484/700]: mean_loss=0.006283614071435295
Online_Training [485/700]: mean_loss=0.002639799495227635
Online_Training [486/700]: mean_loss=0.006139045173767954
Online_Training [487/700]: mean_loss=0.009845684631727636
Online_Training [488/700]: mean_loss=0.005255470692645758
Online_Training [489/700]: mean_loss=0.009999028232414275
Online_Training [490/700]: mean_loss=0.00350010342663154
Online_Training [491/700]: mean_loss=0.0056021210621111095
Online_Training [492/700]: mean_loss=0.014518413372570649
Online_Training [493/700]: mean_loss=0.0025257851812057197
Online_Training [494/700]: mean_loss=0.0876252162270248
Online_Training [495/700]: mean_loss=0.20234579779207706
Online_Training [496/700]: mean_loss=0.006810355000197887
Online_Training [497/700]: mean_loss=0.029256169218569994
Online_Training [498/700]: mean_loss=0.015476146596483886
Online_Training [499/700]: mean_loss=0.012550017912872136
Online_Training [500/700]: mean_loss=0.007493166136555374
Online_Training [501/700]: mean_loss=0.010164119419641793
Online_Training [502/700]: mean_loss=0.008456589537672698
Online_Training [503/700]: mean_loss=0.005472247605212033
Online_Training [504/700]: mean_loss=0.01637064851820469
Online_Training [505/700]: mean_loss=0.01659859891515225
Online_Training [506/700]: mean_loss=0.010023479000665247
Online_Training [507/700]: mean_loss=0.005707760516088456
Online_Training [508/700]: mean_loss=0.0028198623040225357
Online_Training [509/700]: mean_loss=0.20129567757248878
Online_Training [510/700]: mean_loss=0.019889264716766775
Online_Training [511/700]: mean_loss=0.0069587077596224844
Online_Training [512/700]: mean_loss=0.1855474542826414
Online_Training [513/700]: mean_loss=0.5192199014127254
Online_Training [514/700]: mean_loss=0.36440610885620117
Online_Training [515/700]: mean_loss=0.11362817697227001
Online_Training [516/700]: mean_loss=0.08371129352599382
Online_Training [517/700]: mean_loss=0.022780996514484286
Online_Training [518/700]: mean_loss=0.09284991025924683
Online_Training [519/700]: mean_loss=0.010797018418088555
Online_Training [520/700]: mean_loss=0.019652923452667892
Online_Training [521/700]: mean_loss=0.011569451075047255
Online_Training [522/700]: mean_loss=0.01793478662148118
Online_Training [523/700]: mean_loss=0.011189717683009803
Online_Training [524/700]: mean_loss=0.008642378787044436
Online_Training [525/700]: mean_loss=0.01053363352548331
Online_Training [526/700]: mean_loss=0.010443350824061781
Online_Training [527/700]: mean_loss=0.06651451764628291
Online_Training [528/700]: mean_loss=0.1394105963408947
Online_Training [529/700]: mean_loss=0.008038737054448575
Online_Training [530/700]: mean_loss=0.09793299250304699
Online_Training [531/700]: mean_loss=0.010749092441983521
Online_Training [532/700]: mean_loss=0.004699106328189373
Online_Training [533/700]: mean_loss=0.056341600604355335
Online_Training [534/700]: mean_loss=0.009450303739868104
Online_Training [535/700]: mean_loss=0.005329894076567143
Online_Training [536/700]: mean_loss=0.005483320448547602
Online_Training [537/700]: mean_loss=0.008720977115444839
Online_Training [538/700]: mean_loss=0.01803248201031238
Online_Training [539/700]: mean_loss=0.006066435889806598
Online_Training [540/700]: mean_loss=0.00796849379548803
Online_Training [541/700]: mean_loss=0.000736029032850638
Online_Training [542/700]: mean_loss=0.009522673150058836
Online_Training [543/700]: mean_loss=0.008390060975216329
Online_Training [544/700]: mean_loss=0.0017780040070647374
Online_Training [545/700]: mean_loss=0.0033084179740399122
Online_Training [546/700]: mean_loss=0.014111832133494318
Online_Training [547/700]: mean_loss=0.005101442337036133
Online_Training [548/700]: mean_loss=0.00558287714375183
Online_Training [549/700]: mean_loss=0.005179997009690851
Online_Training [550/700]: mean_loss=0.0027626378869172186
Online_Training [551/700]: mean_loss=0.004120874596992508
Online_Training [552/700]: mean_loss=0.07749359589070082
Online_Training [553/700]: mean_loss=0.007982384180650115
Online_Training [554/700]: mean_loss=0.001301981945289299
Online_Training [555/700]: mean_loss=0.0012218469200888649
Online_Training [556/700]: mean_loss=0.006092195049859583
Online_Training [557/700]: mean_loss=0.0035490311274770647
Online_Training [558/700]: mean_loss=0.007496229780372232
Online_Training [559/700]: mean_loss=0.001999546046135947
Online_Training [560/700]: mean_loss=0.009290899150073528
Online_Training [561/700]: mean_loss=0.0035531943140085787
Online_Training [562/700]: mean_loss=0.005594848014879972
Online_Training [563/700]: mean_loss=0.004098830570001155
Online_Training [564/700]: mean_loss=0.00496309669688344
Online_Training [565/700]: mean_loss=0.0047131109749898314
Online_Training [566/700]: mean_loss=0.005424393923021853
Online_Training [567/700]: mean_loss=0.006941081723198295
Online_Training [568/700]: mean_loss=0.007672631531022489
Online_Training [569/700]: mean_loss=0.005055237328633666
Online_Training [570/700]: mean_loss=0.010862118331715465
Online_Training [571/700]: mean_loss=0.07547091413289309
Online_Training [572/700]: mean_loss=0.08493037428706884
Online_Training [573/700]: mean_loss=0.007858333992771804
Online_Training [574/700]: mean_loss=0.005043000681325793
Online_Training [575/700]: mean_loss=0.008138692297507077
Online_Training [576/700]: mean_loss=0.00496554869459942
Online_Training [577/700]: mean_loss=0.0067151772091165185
Online_Training [578/700]: mean_loss=0.004212462838040665
Online_Training [579/700]: mean_loss=0.006853666098322719
Online_Training [580/700]: mean_loss=0.0012854556262027472
Online_Training [581/700]: mean_loss=0.005181277811061591
Online_Training [582/700]: mean_loss=0.003272500936873257
Online_Training [583/700]: mean_loss=0.002250640231068246
Online_Training [584/700]: mean_loss=0.0032762935443315655
Online_Training [585/700]: mean_loss=0.005815879558213055
Online_Training [586/700]: mean_loss=0.002238840432255529
Online_Training [587/700]: mean_loss=0.0042357121128588915
Online_Training [588/700]: mean_loss=0.005957875982858241
Online_Training [589/700]: mean_loss=0.007372278778348118
Online_Training [590/700]: mean_loss=0.004851575824432075
Online_Training [591/700]: mean_loss=0.001899659211630933
Online_Training [592/700]: mean_loss=0.006198442890308797
Online_Training [593/700]: mean_loss=0.0028757579857483506
Online_Training [594/700]: mean_loss=0.0014046443975530565
Online_Training [595/700]: mean_loss=0.008289402234368026
Online_Training [596/700]: mean_loss=0.005174750345759094
Online_Training [597/700]: mean_loss=0.005606085294857621
Online_Training [598/700]: mean_loss=0.004066662193508819
Online_Training [599/700]: mean_loss=0.0018441303982399404
Online_Training [600/700]: mean_loss=0.007136839965824038
Online_Training [601/700]: mean_loss=0.0105268822517246
Online_Training [602/700]: mean_loss=0.0025044192880159244
Online_Training [603/700]: mean_loss=0.003466297494014725
Online_Training [604/700]: mean_loss=0.00502938061254099
Online_Training [605/700]: mean_loss=0.006567444303072989
Online_Training [606/700]: mean_loss=0.0032183308503590524
Online_Training [607/700]: mean_loss=0.0016474779549753293
Online_Training [608/700]: mean_loss=0.009527011192403734
Online_Training [609/700]: mean_loss=0.0018253934977110475
Online_Training [610/700]: mean_loss=0.0012254800967639312
Online_Training [611/700]: mean_loss=0.07693768944591284
Online_Training [612/700]: mean_loss=0.017859398620203137
Online_Training [613/700]: mean_loss=0.014921490219421685
Online_Training [614/700]: mean_loss=0.00444382440764457
Online_Training [615/700]: mean_loss=0.011591909336857498
Online_Training [616/700]: mean_loss=0.004119519755477086
Online_Training [617/700]: mean_loss=0.005045429395977408
Online_Training [618/700]: mean_loss=0.0018962708272738382
Online_Training [619/700]: mean_loss=0.006179173709824681
Online_Training [620/700]: mean_loss=0.0018962707690661773
Online_Training [621/700]: mean_loss=0.12540025543421507
Online_Training [622/700]: mean_loss=0.018879080191254616
Online_Training [623/700]: mean_loss=0.0814975118264556
Online_Training [624/700]: mean_loss=0.08681761845946312
Online_Training [625/700]: mean_loss=0.00419543738826178
Online_Training [626/700]: mean_loss=0.02793729631230235
Online_Training [627/700]: mean_loss=0.012834595865570009
Online_Training [628/700]: mean_loss=0.011377046816051006
Online_Training [629/700]: mean_loss=0.005912181222811341
Online_Training [630/700]: mean_loss=0.0024234804732259363
Online_Training [631/700]: mean_loss=0.007025859667919576
Online_Training [632/700]: mean_loss=0.0029560827824752778
Online_Training [633/700]: mean_loss=0.0025819840375334024
Online_Training [634/700]: mean_loss=0.003565695136785507
Online_Training [635/700]: mean_loss=0.004743729892652482
Online_Training [636/700]: mean_loss=0.0036538213316816837
Online_Training [637/700]: mean_loss=0.007986165641341358
Online_Training [638/700]: mean_loss=0.0015697337075835094
Online_Training [639/700]: mean_loss=0.005225309694651514
Online_Training [640/700]: mean_loss=0.0020220243168296292
Online_Training [641/700]: mean_loss=0.061039790976792574
Online_Training [642/700]: mean_loss=0.006951450603082776
Online_Training [643/700]: mean_loss=0.0024506274494342506
Online_Training [644/700]: mean_loss=0.0023708045773673803
Online_Training [645/700]: mean_loss=0.005194812751142308
Online_Training [646/700]: mean_loss=0.0026494514604564756
Online_Training [647/700]: mean_loss=0.053370518144220114
Online_Training [648/700]: mean_loss=0.003385415649972856
Online_Training [649/700]: mean_loss=0.0043257472570985556
Online_Training [650/700]: mean_loss=0.005781730054877698
Online_Training [651/700]: mean_loss=0.011489165597595274
Online_Training [652/700]: mean_loss=0.002745168545516208
Online_Training [653/700]: mean_loss=0.008132281654980034
Online_Training [654/700]: mean_loss=0.0038891071744728833
Online_Training [655/700]: mean_loss=0.0019759720016736537
Online_Training [656/700]: mean_loss=0.0053596136276610196
Online_Training [657/700]: mean_loss=0.009349229163490236
Online_Training [658/700]: mean_loss=0.00447538064327091
Online_Training [659/700]: mean_loss=0.005155594903044403
Online_Training [660/700]: mean_loss=0.013570155831985176
Online_Training [661/700]: mean_loss=0.011877030367031693
Online_Training [662/700]: mean_loss=0.00463289167964831
Online_Training [663/700]: mean_loss=0.006807537865824997
Online_Training [664/700]: mean_loss=0.014799136406509206
Online_Training [665/700]: mean_loss=0.0059342829044908285
Online_Training [666/700]: mean_loss=0.0073004181031137705
Online_Training [667/700]: mean_loss=0.007696775661315769
Online_Training [668/700]: mean_loss=0.0073490754584781826
Online_Training [669/700]: mean_loss=0.005711700767278671
Online_Training [670/700]: mean_loss=0.001124535483540967
Online_Training [671/700]: mean_loss=0.0047294298419728875
Online_Training [672/700]: mean_loss=0.0031037872831802815
Online_Training [673/700]: mean_loss=0.02152475994080305
Online_Training [674/700]: mean_loss=0.0070140083553269506
Online_Training [675/700]: mean_loss=0.0027975384437013417
Online_Training [676/700]: mean_loss=0.0010377438884461299
Online_Training [677/700]: mean_loss=0.0023278356238733977
Online_Training [678/700]: mean_loss=0.008618287625722587
Online_Training [679/700]: mean_loss=0.004195397355942987
Online_Training [680/700]: mean_loss=0.08279395056888461
Online_Training [681/700]: mean_loss=0.0014117088139755651
Online_Training [682/700]: mean_loss=0.007387593068415299
Online_Training [683/700]: mean_loss=0.0013501663488568738
Online_Training [684/700]: mean_loss=0.00643510342342779
Online_Training [685/700]: mean_loss=0.014629545097704977
Online_Training [686/700]: mean_loss=0.008195075381081551
Online_Training [687/700]: mean_loss=0.0019668624590849504
Online_Training [688/700]: mean_loss=0.003708681499119848
Online_Training [689/700]: mean_loss=0.003805245825788006
Online_Training [690/700]: mean_loss=0.002291961805894971
Online_Training [691/700]: mean_loss=0.0026931397151201963
Online_Training [692/700]: mean_loss=0.0021922829910181463
Online_Training [693/700]: mean_loss=0.0020882214012090117
Online_Training [694/700]: mean_loss=0.009598647709935904
Online_Training [695/700]: mean_loss=0.0065317690605297685
Online_Training [696/700]: mean_loss=0.0013049071640125476
Online_Training [697/700]: mean_loss=0.005803752283100039
Online_Training [698/700]: mean_loss=0.003490567672997713
Online_Training [699/700]: mean_loss=0.0009072465181816369
Online_Training [700/700]: mean_loss=0.008329518896061927
Q_Learning [1/300]: mean_loss=0.11378381960093975
Q_Learning [2/300]: mean_loss=0.14569642767310143
Q_Learning [3/300]: mean_loss=0.3465648368000984
Q_Learning [4/300]: mean_loss=0.30821581184864044
Q_Learning [5/300]: mean_loss=0.3031958043575287
Q_Learning [6/300]: mean_loss=0.10264960024505854
Q_Learning [7/300]: mean_loss=0.11891445145010948
Q_Learning [8/300]: mean_loss=0.24106628447771072
Q_Learning [9/300]: mean_loss=0.1108841085806489
Q_Learning [10/300]: mean_loss=0.10161155182868242
Q_Learning [11/300]: mean_loss=0.0898919515311718
Q_Learning [12/300]: mean_loss=0.08347065933048725
Q_Learning [13/300]: mean_loss=0.06383528374135494
Q_Learning [14/300]: mean_loss=0.10517256055027246
Q_Learning [15/300]: mean_loss=0.16720999777317047
Q_Learning [16/300]: mean_loss=0.09873457066714764
Q_Learning [17/300]: mean_loss=0.1346427695825696
Q_Learning [18/300]: mean_loss=0.10138465743511915
Q_Learning [19/300]: mean_loss=0.07790478877723217
Q_Learning [20/300]: mean_loss=0.0683499937877059
Q_Learning [21/300]: mean_loss=0.12451483961194754
Q_Learning [22/300]: mean_loss=0.08019751310348511
Q_Learning [23/300]: mean_loss=0.06336079631000757
Q_Learning [24/300]: mean_loss=0.02889834577217698
Q_Learning [25/300]: mean_loss=0.09824888035655022
Q_Learning [26/300]: mean_loss=0.08337032422423363
Q_Learning [27/300]: mean_loss=0.07460478320717812
Q_Learning [28/300]: mean_loss=0.06427119299769402
Q_Learning [29/300]: mean_loss=0.025956159690394998
Q_Learning [30/300]: mean_loss=0.013515172991901636
Q_Learning [31/300]: mean_loss=0.05634578038007021
Q_Learning [32/300]: mean_loss=0.0036392773617990315
Q_Learning [33/300]: mean_loss=0.004477213427890092
Q_Learning [34/300]: mean_loss=0.0430068732239306
Q_Learning [35/300]: mean_loss=0.003896680223988369
Q_Learning [36/300]: mean_loss=0.12112633883953094
Q_Learning [37/300]: mean_loss=0.03942429181188345
Q_Learning [38/300]: mean_loss=0.06386475590988994
Q_Learning [39/300]: mean_loss=0.027646030532196164
Q_Learning [40/300]: mean_loss=0.046223084442317486
Q_Learning [41/300]: mean_loss=0.03945527505129576
Q_Learning [42/300]: mean_loss=0.014422473148442805
Q_Learning [43/300]: mean_loss=0.03279201127588749
Q_Learning [44/300]: mean_loss=0.0054357983462978154
Q_Learning [45/300]: mean_loss=0.04014566075056791
Q_Learning [46/300]: mean_loss=0.03388096811249852
Q_Learning [47/300]: mean_loss=0.12328022625297308
Q_Learning [48/300]: mean_loss=0.12173986062407494
Q_Learning [49/300]: mean_loss=0.005823952495120466
Q_Learning [50/300]: mean_loss=0.026925336802378297
Q_Learning [51/300]: mean_loss=0.005742514447774738
Q_Learning [52/300]: mean_loss=0.0029296272550709546
Q_Learning [53/300]: mean_loss=0.06685317726805806
Q_Learning [54/300]: mean_loss=0.23163851909339428
Q_Learning [55/300]: mean_loss=0.040016531478613615
Q_Learning [56/300]: mean_loss=0.03896057698875666
Q_Learning [57/300]: mean_loss=0.03477877774275839
Q_Learning [58/300]: mean_loss=0.021796627203002572
Q_Learning [59/300]: mean_loss=0.12643650453537703
Q_Learning [60/300]: mean_loss=0.021049436880275607
Q_Learning [61/300]: mean_loss=0.020224187523126602
Q_Learning [62/300]: mean_loss=0.01669733866583556
Q_Learning [63/300]: mean_loss=0.0302447575959377
Q_Learning [64/300]: mean_loss=0.007767293805954978
Q_Learning [65/300]: mean_loss=0.016839124844409525
Q_Learning [66/300]: mean_loss=0.00883120036451146
Q_Learning [67/300]: mean_loss=0.002639179743709974
Q_Learning [68/300]: mean_loss=0.1379548292607069
Q_Learning [69/300]: mean_loss=0.00694007589481771
Q_Learning [70/300]: mean_loss=0.007688389392569661
Q_Learning [71/300]: mean_loss=0.004523785260971636
Q_Learning [72/300]: mean_loss=0.00863642303738743
Q_Learning [73/300]: mean_loss=0.006656681071035564
Q_Learning [74/300]: mean_loss=0.004530370119027793
Q_Learning [75/300]: mean_loss=0.006843132490757853
Q_Learning [76/300]: mean_loss=0.0015881327854003757
Q_Learning [77/300]: mean_loss=0.0011284384818281978
Q_Learning [78/300]: mean_loss=0.0059804850607179105
Q_Learning [79/300]: mean_loss=0.021095941308885813
Q_Learning [80/300]: mean_loss=0.009066440281458199
Q_Learning [81/300]: mean_loss=0.004238629771862179
Q_Learning [82/300]: mean_loss=0.010614185477606952
Q_Learning [83/300]: mean_loss=0.009619259624741971
Q_Learning [84/300]: mean_loss=0.003870310145430267
Q_Learning [85/300]: mean_loss=0.006695855816360563
Q_Learning [86/300]: mean_loss=0.011173600738402456
Q_Learning [87/300]: mean_loss=0.0039586837228853256
Q_Learning [88/300]: mean_loss=0.012083948473446071
Q_Learning [89/300]: mean_loss=0.003375221771420911
Q_Learning [90/300]: mean_loss=0.006692660448607057
Q_Learning [91/300]: mean_loss=0.006360071012750268
Q_Learning [92/300]: mean_loss=0.005908198218094185
Q_Learning [93/300]: mean_loss=0.0026007721753558144
Q_Learning [94/300]: mean_loss=0.004308858304284513
Q_Learning [95/300]: mean_loss=0.0021307508723111823
Q_Learning [96/300]: mean_loss=0.005638326314510778
Q_Learning [97/300]: mean_loss=0.007091007602866739
Q_Learning [98/300]: mean_loss=0.0045183427282609046
Q_Learning [99/300]: mean_loss=0.00704635086003691
Q_Learning [100/300]: mean_loss=0.0008382177147723269
Q_Learning [101/300]: mean_loss=0.0036532851518131793
Q_Learning [102/300]: mean_loss=0.0034278151870239526
Q_Learning [103/300]: mean_loss=0.006009891338180751
Q_Learning [104/300]: mean_loss=0.0020912275358568877
Q_Learning [105/300]: mean_loss=0.02852273383177817
Q_Learning [106/300]: mean_loss=0.020367871737107635
Q_Learning [107/300]: mean_loss=0.003751713637029752
Q_Learning [108/300]: mean_loss=0.01116185321006924
Q_Learning [109/300]: mean_loss=0.004720610653748736
Q_Learning [110/300]: mean_loss=0.004416843847138807
Q_Learning [111/300]: mean_loss=0.002621307998197153
Q_Learning [112/300]: mean_loss=0.005015082162572071
Q_Learning [113/300]: mean_loss=0.008519547816831619
Q_Learning [114/300]: mean_loss=0.008824893389828503
Q_Learning [115/300]: mean_loss=0.014818043331615627
Q_Learning [116/300]: mean_loss=0.0030650332337245345
Q_Learning [117/300]: mean_loss=0.0066639899159781635
Q_Learning [118/300]: mean_loss=0.0038257840496953577
Q_Learning [119/300]: mean_loss=0.004224900418194011
Q_Learning [120/300]: mean_loss=0.00764397851889953
Q_Learning [121/300]: mean_loss=0.002642429550178349
Q_Learning [122/300]: mean_loss=0.00685603340389207
Q_Learning [123/300]: mean_loss=0.0012325898569542915
Q_Learning [124/300]: mean_loss=0.006199013674631715
Q_Learning [125/300]: mean_loss=0.001375205596559681
Q_Learning [126/300]: mean_loss=0.0017712757544359192
Q_Learning [127/300]: mean_loss=0.005139496643096209
Q_Learning [128/300]: mean_loss=0.008670606941450387
Q_Learning [129/300]: mean_loss=0.0028632140019908547
Q_Learning [130/300]: mean_loss=0.004077653255080804
Q_Learning [131/300]: mean_loss=0.003680830239318311
Q_Learning [132/300]: mean_loss=0.0026969888858729973
Q_Learning [133/300]: mean_loss=0.004076244775205851
Q_Learning [134/300]: mean_loss=0.0058758028608281165
Q_Learning [135/300]: mean_loss=0.0025493456923868507
Q_Learning [136/300]: mean_loss=0.0008580955254728906
Q_Learning [137/300]: mean_loss=0.004060837236465886
Q_Learning [138/300]: mean_loss=0.0032189814373850822
Q_Learning [139/300]: mean_loss=0.0025579198336345144
Q_Learning [140/300]: mean_loss=0.002777855785097927
Q_Learning [141/300]: mean_loss=0.003576757895643823
Q_Learning [142/300]: mean_loss=0.00507017585914582
Q_Learning [143/300]: mean_loss=0.232892582193017
Q_Learning [144/300]: mean_loss=0.08423824608325958
Q_Learning [145/300]: mean_loss=0.1540049696341157
Q_Learning [146/300]: mean_loss=0.20604431256651878
Q_Learning [147/300]: mean_loss=0.011294421157799661
Q_Learning [148/300]: mean_loss=0.007740897010080516
Q_Learning [149/300]: mean_loss=0.01156171690672636
Q_Learning [150/300]: mean_loss=0.16648542135953903
Q_Learning [151/300]: mean_loss=0.25448198057711124
Q_Learning [152/300]: mean_loss=0.016828362829983234
Q_Learning [153/300]: mean_loss=0.008841614588163793
Q_Learning [154/300]: mean_loss=0.0074221568065695465
Q_Learning [155/300]: mean_loss=0.060919263400137424
Q_Learning [156/300]: mean_loss=0.016288741258904338
Q_Learning [157/300]: mean_loss=0.006445634411647916
Q_Learning [158/300]: mean_loss=0.02676629228517413
Q_Learning [159/300]: mean_loss=0.006638501130510122
Q_Learning [160/300]: mean_loss=0.019423441728577018
Q_Learning [161/300]: mean_loss=0.003130506578600034
Q_Learning [162/300]: mean_loss=0.052125255577266216
Q_Learning [163/300]: mean_loss=0.17720889672636986
Q_Learning [164/300]: mean_loss=0.01804020954295993
Q_Learning [165/300]: mean_loss=0.008503059740178287
Q_Learning [166/300]: mean_loss=0.020686706760898232
Q_Learning [167/300]: mean_loss=0.007210750423837453
Q_Learning [168/300]: mean_loss=0.009323140373453498
Q_Learning [169/300]: mean_loss=0.0019846200302708894
Q_Learning [170/300]: mean_loss=0.004188444145256653
Q_Learning [171/300]: mean_loss=0.017564886598847806
Q_Learning [172/300]: mean_loss=0.02445235406048596
Q_Learning [173/300]: mean_loss=0.02690748800523579
Q_Learning [174/300]: mean_loss=0.01163200126029551
Q_Learning [175/300]: mean_loss=0.019718393683433533
Q_Learning [176/300]: mean_loss=0.001299829687923193
Q_Learning [177/300]: mean_loss=0.006021750770742074
Q_Learning [178/300]: mean_loss=0.0037408798234537244
Q_Learning [179/300]: mean_loss=0.005423784430604428
Q_Learning [180/300]: mean_loss=0.00918440253008157
Q_Learning [181/300]: mean_loss=0.0035348576202522963
Q_Learning [182/300]: mean_loss=0.002358555211685598
Q_Learning [183/300]: mean_loss=0.006536435277666897
Q_Learning [184/300]: mean_loss=0.0034022122563328594
Q_Learning [185/300]: mean_loss=0.003585572529118508
Q_Learning [186/300]: mean_loss=0.002742555661825463
Q_Learning [187/300]: mean_loss=0.0016559527721256018
Q_Learning [188/300]: mean_loss=0.087472815066576
Q_Learning [189/300]: mean_loss=0.0939863882958889
Q_Learning [190/300]: mean_loss=0.014437754638493061
Q_Learning [191/300]: mean_loss=0.03825535997748375
Q_Learning [192/300]: mean_loss=0.007346369151491672
Q_Learning [193/300]: mean_loss=0.01203676057048142
Q_Learning [194/300]: mean_loss=0.03751215455122292
Q_Learning [195/300]: mean_loss=0.010530850267969072
Q_Learning [196/300]: mean_loss=0.007966732315253466
Q_Learning [197/300]: mean_loss=0.0031613124738214538
Q_Learning [198/300]: mean_loss=0.005868360924068838
Q_Learning [199/300]: mean_loss=0.007339539297390729
Q_Learning [200/300]: mean_loss=0.00884359993506223
Q_Learning [201/300]: mean_loss=0.010324737406335771
Q_Learning [202/300]: mean_loss=0.007765653484966606
Q_Learning [203/300]: mean_loss=0.002216233449871652
Q_Learning [204/300]: mean_loss=0.007140406058169901
Q_Learning [205/300]: mean_loss=0.0030602964689023793
Q_Learning [206/300]: mean_loss=0.007836904667783529
Q_Learning [207/300]: mean_loss=0.005057744303485379
Q_Learning [208/300]: mean_loss=0.003930913168005645
Q_Learning [209/300]: mean_loss=0.006657181074842811
Q_Learning [210/300]: mean_loss=0.007989711361005902
Q_Learning [211/300]: mean_loss=0.004194034729152918
Q_Learning [212/300]: mean_loss=0.004399640834890306
Q_Learning [213/300]: mean_loss=0.004628392052836716
Q_Learning [214/300]: mean_loss=0.003753426222829148
Q_Learning [215/300]: mean_loss=0.004888262366876006
Q_Learning [216/300]: mean_loss=0.0021148325176909566
Q_Learning [217/300]: mean_loss=0.0022963393421377987
Q_Learning [218/300]: mean_loss=0.00251974692218937
Q_Learning [219/300]: mean_loss=0.00702630402520299
Q_Learning [220/300]: mean_loss=0.007831336057279259
Q_Learning [221/300]: mean_loss=0.007097334135323763
Q_Learning [222/300]: mean_loss=0.0026223461027257144
Q_Learning [223/300]: mean_loss=0.000650430767564103
Q_Learning [224/300]: mean_loss=0.004928916459903121
Q_Learning [225/300]: mean_loss=0.00111700998240849
Q_Learning [226/300]: mean_loss=0.0018327974248677492
Q_Learning [227/300]: mean_loss=0.009358133189380169
Q_Learning [228/300]: mean_loss=0.006307220435701311
Q_Learning [229/300]: mean_loss=0.004364815889857709
Q_Learning [230/300]: mean_loss=0.0033403131819795817
Q_Learning [231/300]: mean_loss=0.0015892383962636814
Q_Learning [232/300]: mean_loss=0.002845591341610998
Q_Learning [233/300]: mean_loss=0.004716362163890153
Q_Learning [234/300]: mean_loss=0.006356388330459595
Q_Learning [235/300]: mean_loss=0.005384986172430217
Q_Learning [236/300]: mean_loss=0.01051547157112509
Q_Learning [237/300]: mean_loss=0.0020999460539314896
Q_Learning [238/300]: mean_loss=0.0041448575793765485
Q_Learning [239/300]: mean_loss=0.0016789575456641614
Q_Learning [240/300]: mean_loss=0.007265750027727336
Q_Learning [241/300]: mean_loss=0.010124713997356594
Q_Learning [242/300]: mean_loss=0.004054831137182191
Q_Learning [243/300]: mean_loss=0.008128808229230344
Q_Learning [244/300]: mean_loss=0.002890591829782352
Q_Learning [245/300]: mean_loss=0.0019182762480340898
Q_Learning [246/300]: mean_loss=0.003826087398920208
Q_Learning [247/300]: mean_loss=0.0016931171412579715
Q_Learning [248/300]: mean_loss=0.020147958304733038
Q_Learning [249/300]: mean_loss=0.011215437203645706
Q_Learning [250/300]: mean_loss=0.004060051607666537
Q_Learning [251/300]: mean_loss=0.01393909053876996
Q_Learning [252/300]: mean_loss=0.004153102374402806
Q_Learning [253/300]: mean_loss=0.0015332011244026944
Q_Learning [254/300]: mean_loss=0.003675067506264895
Q_Learning [255/300]: mean_loss=0.002856093386071734
Q_Learning [256/300]: mean_loss=0.09796388074755669
Q_Learning [257/300]: mean_loss=0.08234456926584244
Q_Learning [258/300]: mean_loss=0.010041516274213791
Q_Learning [259/300]: mean_loss=0.0016497103351866826
Q_Learning [260/300]: mean_loss=0.002932189905550331
Q_Learning [261/300]: mean_loss=0.013633297756314278
Q_Learning [262/300]: mean_loss=0.011346634244546294
Q_Learning [263/300]: mean_loss=0.004285441158572212
Q_Learning [264/300]: mean_loss=0.005453611142002046
Q_Learning [265/300]: mean_loss=0.001623116637347266
Q_Learning [266/300]: mean_loss=0.001638486617594026
Q_Learning [267/300]: mean_loss=0.0026353175344411284
Q_Learning [268/300]: mean_loss=0.010748975328169763
Q_Learning [269/300]: mean_loss=0.010137799079529941
Q_Learning [270/300]: mean_loss=0.003610531333833933
Q_Learning [271/300]: mean_loss=0.004863157373620197
Q_Learning [272/300]: mean_loss=0.0026060885575134307
Q_Learning [273/300]: mean_loss=0.0047194313374347985
Q_Learning [274/300]: mean_loss=0.0018517647113185376
Q_Learning [275/300]: mean_loss=0.19184214249253273
Q_Learning [276/300]: mean_loss=0.058139719534665346
Q_Learning [277/300]: mean_loss=0.017643170314840972
Q_Learning [278/300]: mean_loss=0.014106677728705108
Q_Learning [279/300]: mean_loss=0.0017644476174609736
Q_Learning [280/300]: mean_loss=0.00773140590172261
Q_Learning [281/300]: mean_loss=0.00507810537237674
Q_Learning [282/300]: mean_loss=0.007421135203912854
Q_Learning [283/300]: mean_loss=0.009392966632731259
Q_Learning [284/300]: mean_loss=0.005389284197008237
Q_Learning [285/300]: mean_loss=0.009709400357678533
Q_Learning [286/300]: mean_loss=0.006878130079712719
Q_Learning [287/300]: mean_loss=0.0025765043683350086
Q_Learning [288/300]: mean_loss=0.001785552900400944
Q_Learning [289/300]: mean_loss=0.003978232300141826
Q_Learning [290/300]: mean_loss=0.002406209649052471
Q_Learning [291/300]: mean_loss=0.005720421788282692
Q_Learning [292/300]: mean_loss=0.0018253527086926624
Q_Learning [293/300]: mean_loss=0.004817392269615084
Q_Learning [294/300]: mean_loss=0.002684680715901777
Q_Learning [295/300]: mean_loss=0.001481628802139312
Q_Learning [296/300]: mean_loss=0.176914531737566
Q_Learning [297/300]: mean_loss=0.084306126460433
Q_Learning [298/300]: mean_loss=0.017649690620601177
Q_Learning [299/300]: mean_loss=0.015366556472145021
Q_Learning [300/300]: mean_loss=0.00680446409387514
Number of Samples after Autoencoder testing: 300
First Spike after testing: [1.1573346  0.11396805]
[1, 2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 0, 2, 1, 1, 1, 2, 0, 1, 2, 0, 0, 2, 0, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 1, 1, 1, 2, 2, 2, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 1, 2, 2, 0, 1, 2, 0, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 1, 2, 1, 2, 0, 2, 1, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 0, 2, 2, 2, 0, 1, 2, 0, 2, 1, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 1, 0, 1, 0, 1, 2, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 0, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 2, 2]
[0, 1, 2, 1, 1, 3, 3, 1, 0, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 1, 3, 3, 1, 3, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 3, 3, 3, 1, 3, 3, 1, 0, 0, 1, 1, 1, 0, 3, 1, 3, 1, 0, 0, 0, 1, 1, 1, 0, 3, 1, 1, 1, 3, 3, 3, 3, 3, 0, 1, 3, 3, 3, 0, 3, 0, 3, 1, 1, 0, 3, 1, 3, 3, 3, 0, 1, 3, 1, 0, 1, 1, 3, 0, 1, 3, 1, 3, 1, 0, 3, 3, 0, 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 1, 0, 0, 3, 0, 1, 1, 0, 0, 3, 3, 0, 1, 3, 3, 0, 3, 0, 1, 1, 3, 0, 3, 1, 3, 3, 0, 3, 3, 1, 1, 3, 3, 0, 1, 0, 1, 3, 1, 0, 1, 3, 1, 3, 1, 0, 3, 0, 3, 0, 0, 1, 3, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 3, 1, 1, 1, 3, 0, 1, 3, 1, 0, 0, 0, 3, 0, 1, 3, 1, 3, 1, 1, 1, 3, 3, 0, 0, 3, 1, 3, 0, 0, 3, 0, 0, 1, 1, 1, 1, 3, 1, 3, 3, 3, 1, 1, 1, 0, 1, 1, 1, 0, 3, 0, 3, 0, 1, 3, 1, 0, 0, 1, 3, 0, 1, 0, 3, 0, 1, 3, 3, 1, 0, 3, 1, 0, 0, 0, 3, 1, 3, 0, 0, 0, 3, 0, 1, 3, 1, 1, 1, 0, 3, 1, 1, 3, 1, 1, 3, 0, 3, 0, 0, 1, 1, 3, 4, 1, 0, 0, 1, 3, 1, 0, 1, 1, 3, 3, 0, 1, 3, 1, 1]
Centroids: [[-0.69243866, 0.7822953], [1.1477467, 0.037939265], [-0.40592548, -1.9547893]]
Centroids: [[1.1700015, 0.07318123], [-0.40926707, -1.9520516], [-0.998768, 2.550711], [-0.67697376, 0.78732574], [1.5128841, -1.5808916]]
Contingency Matrix: 
[[  0   1   1  97   0]
 [ 86   1   0   1   1]
 [  0 112   0   0   0]]
[[0, 1, 1, 97, 0], [86, 1, 0, 1, 1], [0, 112, 0, 0, 0]]
[[0, 1, 1, 97, 0], [86, 1, 0, 1, 1], [0, 112, 0, 0, 0]]
[0, 1, 2, 3, 4]
[[0, -1, 1, 97, 0], [86, -1, 0, 1, 1], [-1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1], [86, -1, 0, -1, 1], [-1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1]]
Match_Labels: {2: 1, 0: 3, 1: 0}
New Contingency Matrix: 
[[ 97   0   1   1   0]
 [  1  86   1   0   1]
 [  0   0 112   0   0]]
New Clustered Label Sequence: [3, 0, 1, 2, 4]
Diagonal_Elements: [97, 86, 112], Sum: 295
All_Elements: [97, 0, 1, 1, 0, 1, 86, 1, 0, 1, 0, 0, 112, 0, 0], Sum: 300
Accuracy: 0.9833333333333333
