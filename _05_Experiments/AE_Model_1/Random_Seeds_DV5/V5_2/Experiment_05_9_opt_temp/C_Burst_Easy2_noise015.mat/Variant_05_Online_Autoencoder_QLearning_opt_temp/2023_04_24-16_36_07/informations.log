Experiment_path: AE_Model_1/Random_Seeds_DV5//V5_2/Experiment_05_9_opt_temp
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt_temp
Visualisation_Path: AE_Model_1/Random_Seeds_DV5//V5_2/Experiment_05_9_opt_temp/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt_temp/2023_04_24-16_36_07
Punishment_Coefficient: 0.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001E9A15936D8>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.22981207445263863
Online_Training [2/700]: mean_loss=0.24756303057074547
Online_Training [3/700]: mean_loss=0.20670911110937595
Online_Training [4/700]: mean_loss=0.07135983277112246
Online_Training [5/700]: mean_loss=0.2329958062618971
Online_Training [6/700]: mean_loss=0.1279845628887415
Online_Training [7/700]: mean_loss=0.13390332646667957
Online_Training [8/700]: mean_loss=0.056354780215770006
Online_Training [9/700]: mean_loss=0.2508658282458782
Online_Training [10/700]: mean_loss=0.12409482523798943
Online_Training [11/700]: mean_loss=0.09200372826308012
Online_Training [12/700]: mean_loss=0.08699403330683708
Online_Training [13/700]: mean_loss=0.08074962813407183
Online_Training [14/700]: mean_loss=0.10310835111886263
Online_Training [15/700]: mean_loss=0.08903836458921432
Online_Training [16/700]: mean_loss=0.10365793574601412
Online_Training [17/700]: mean_loss=0.1912593748420477
Online_Training [18/700]: mean_loss=0.1442017164081335
Online_Training [19/700]: mean_loss=0.042910737451165915
Online_Training [20/700]: mean_loss=0.14590007066726685
Online_Training [21/700]: mean_loss=0.12053583096712828
Online_Training [22/700]: mean_loss=0.05384864518418908
Online_Training [23/700]: mean_loss=0.03186784917488694
Online_Training [24/700]: mean_loss=0.08757246378809214
Online_Training [25/700]: mean_loss=0.05119254346936941
Online_Training [26/700]: mean_loss=0.07463422417640686
Online_Training [27/700]: mean_loss=0.0934888431802392
Online_Training [28/700]: mean_loss=0.06500024441629648
Online_Training [29/700]: mean_loss=0.04505908489227295
Online_Training [30/700]: mean_loss=0.03708885610103607
Online_Training [31/700]: mean_loss=0.02797183790244162
Online_Training [32/700]: mean_loss=0.046479590237140656
Online_Training [33/700]: mean_loss=0.026868477929383516
Online_Training [34/700]: mean_loss=0.1696428805589676
Online_Training [35/700]: mean_loss=0.0626025409437716
Online_Training [36/700]: mean_loss=0.0851799538359046
Online_Training [37/700]: mean_loss=0.05949603021144867
Online_Training [38/700]: mean_loss=0.04326834063977003
Online_Training [39/700]: mean_loss=0.13569374568760395
Online_Training [40/700]: mean_loss=0.02668346813879907
Online_Training [41/700]: mean_loss=0.03149452339857817
Online_Training [42/700]: mean_loss=0.048925100825726986
Online_Training [43/700]: mean_loss=0.13545985519886017
Online_Training [44/700]: mean_loss=0.15892266668379307
Online_Training [45/700]: mean_loss=0.10442653298377991
Online_Training [46/700]: mean_loss=0.06070553557947278
Online_Training [47/700]: mean_loss=0.10490958020091057
Online_Training [48/700]: mean_loss=0.06003241427242756
Online_Training [49/700]: mean_loss=0.10465220361948013
Online_Training [50/700]: mean_loss=0.12410662602633238
Online_Training [51/700]: mean_loss=0.03469630191102624
Online_Training [52/700]: mean_loss=0.17919774167239666
Online_Training [53/700]: mean_loss=0.04024024261161685
Online_Training [54/700]: mean_loss=0.09361130651086569
Online_Training [55/700]: mean_loss=0.08090419415384531
Online_Training [56/700]: mean_loss=0.034687156323343515
Online_Training [57/700]: mean_loss=0.13317538518458605
Online_Training [58/700]: mean_loss=0.24528797902166843
Online_Training [59/700]: mean_loss=0.07139931246638298
Online_Training [60/700]: mean_loss=0.08480892423540354
Online_Training [61/700]: mean_loss=0.07094484101980925
Online_Training [62/700]: mean_loss=0.07363221328705549
Online_Training [63/700]: mean_loss=0.06797661073505878
Online_Training [64/700]: mean_loss=0.01306375628337264
Online_Training [65/700]: mean_loss=0.06981058232486248
Online_Training [66/700]: mean_loss=0.04744833428412676
Online_Training [67/700]: mean_loss=0.05323221767321229
Online_Training [68/700]: mean_loss=0.04612215934321284
Online_Training [69/700]: mean_loss=0.09284457564353943
Online_Training [70/700]: mean_loss=0.03280224232003093
Online_Training [71/700]: mean_loss=0.07417035195976496
Online_Training [72/700]: mean_loss=0.08168407715857029
Online_Training [73/700]: mean_loss=0.04551933519542217
Online_Training [74/700]: mean_loss=0.04330956842750311
Online_Training [75/700]: mean_loss=0.020029449369758368
Online_Training [76/700]: mean_loss=0.043510545045137405
Online_Training [77/700]: mean_loss=0.03453721012920141
Online_Training [78/700]: mean_loss=0.043085915967822075
Online_Training [79/700]: mean_loss=0.033176352735608816
Online_Training [80/700]: mean_loss=0.03926187381148338
Online_Training [81/700]: mean_loss=0.022954869316890836
Online_Training [82/700]: mean_loss=0.03563008410856128
Online_Training [83/700]: mean_loss=0.06549072964116931
Online_Training [84/700]: mean_loss=0.039607842452824116
Online_Training [85/700]: mean_loss=0.02919572778046131
Online_Training [86/700]: mean_loss=0.03942013159394264
Online_Training [87/700]: mean_loss=0.017626587068662047
Online_Training [88/700]: mean_loss=0.01830970693845302
Online_Training [89/700]: mean_loss=0.027164918836206198
Online_Training [90/700]: mean_loss=0.024004769511520863
Online_Training [91/700]: mean_loss=0.03110601776279509
Online_Training [92/700]: mean_loss=0.04390787007287145
Online_Training [93/700]: mean_loss=0.03873668145388365
Online_Training [94/700]: mean_loss=0.050438341684639454
Online_Training [95/700]: mean_loss=0.04549292614683509
Online_Training [96/700]: mean_loss=0.02303168410435319
Online_Training [97/700]: mean_loss=0.04897891916334629
Online_Training [98/700]: mean_loss=0.024781160056591034
Online_Training [99/700]: mean_loss=0.021729525178670883
Online_Training [100/700]: mean_loss=0.04643646581098437
Online_Training [101/700]: mean_loss=0.018935000873170793
Online_Training [102/700]: mean_loss=0.05329828476533294
Online_Training [103/700]: mean_loss=0.04306666739284992
Online_Training [104/700]: mean_loss=0.04658936755731702
Online_Training [105/700]: mean_loss=0.033802802208811045
Online_Training [106/700]: mean_loss=0.017917080549523234
Online_Training [107/700]: mean_loss=0.018550356850028038
Online_Training [108/700]: mean_loss=0.027572800172492862
Online_Training [109/700]: mean_loss=0.027128870598971844
Online_Training [110/700]: mean_loss=0.03787297080270946
Online_Training [111/700]: mean_loss=0.023306705988943577
Online_Training [112/700]: mean_loss=0.12413819786161184
Online_Training [113/700]: mean_loss=0.02562815777491778
Online_Training [114/700]: mean_loss=0.024015369126573205
Online_Training [115/700]: mean_loss=0.03346564946696162
Online_Training [116/700]: mean_loss=0.024487603455781937
Online_Training [117/700]: mean_loss=0.04857110558077693
Online_Training [118/700]: mean_loss=0.03742152592167258
Online_Training [119/700]: mean_loss=0.11937944125384092
Online_Training [120/700]: mean_loss=0.060946252197027206
Online_Training [121/700]: mean_loss=0.04732250235974789
Online_Training [122/700]: mean_loss=0.06136030284687877
Online_Training [123/700]: mean_loss=0.031141108134761453
Online_Training [124/700]: mean_loss=0.010395600460469723
Online_Training [125/700]: mean_loss=0.07391265174373984
Online_Training [126/700]: mean_loss=0.03768066270276904
Online_Training [127/700]: mean_loss=0.03160739201121032
Online_Training [128/700]: mean_loss=0.021550549194216728
Online_Training [129/700]: mean_loss=0.02953526540659368
Online_Training [130/700]: mean_loss=0.018066275282762945
Online_Training [131/700]: mean_loss=0.020169815979897976
Online_Training [132/700]: mean_loss=0.019491546554490924
Online_Training [133/700]: mean_loss=0.02871544100344181
Online_Training [134/700]: mean_loss=0.012164816609583795
Online_Training [135/700]: mean_loss=0.10515869129449129
Online_Training [136/700]: mean_loss=0.019421654986217618
Online_Training [137/700]: mean_loss=0.016392741352319717
Online_Training [138/700]: mean_loss=0.011462793103419244
Online_Training [139/700]: mean_loss=0.017324920394457877
Online_Training [140/700]: mean_loss=0.030843550339341164
Online_Training [141/700]: mean_loss=0.03390608751215041
Online_Training [142/700]: mean_loss=0.012329135090112686
Online_Training [143/700]: mean_loss=0.02621782897040248
Online_Training [144/700]: mean_loss=0.009068770508747548
Online_Training [145/700]: mean_loss=0.025146526284515858
Online_Training [146/700]: mean_loss=0.020671303384006023
Online_Training [147/700]: mean_loss=0.014585916884243488
Online_Training [148/700]: mean_loss=0.04315067920833826
Online_Training [149/700]: mean_loss=0.05265757720917463
Online_Training [150/700]: mean_loss=0.06099599087610841
Online_Training [151/700]: mean_loss=0.02107781497761607
Online_Training [152/700]: mean_loss=0.015016611316241324
Online_Training [153/700]: mean_loss=0.022651325445622206
Online_Training [154/700]: mean_loss=0.01798099873121828
Online_Training [155/700]: mean_loss=0.012288927682675421
Online_Training [156/700]: mean_loss=0.01674767106305808
Online_Training [157/700]: mean_loss=0.10599534772336483
Online_Training [158/700]: mean_loss=0.006010026903823018
Online_Training [159/700]: mean_loss=0.0249071903526783
Online_Training [160/700]: mean_loss=0.016953084617853165
Online_Training [161/700]: mean_loss=0.02504249708727002
Online_Training [162/700]: mean_loss=0.011825893307104707
Online_Training [163/700]: mean_loss=0.039374264888465405
Online_Training [164/700]: mean_loss=0.015465213567949831
Online_Training [165/700]: mean_loss=0.00807259464636445
Online_Training [166/700]: mean_loss=0.01837530266493559
Online_Training [167/700]: mean_loss=0.03148739016614854
Online_Training [168/700]: mean_loss=0.042622416745871305
Online_Training [169/700]: mean_loss=0.052397108636796474
Online_Training [170/700]: mean_loss=0.16565680503845215
Online_Training [171/700]: mean_loss=0.017599148908630013
Online_Training [172/700]: mean_loss=0.02029899600893259
Online_Training [173/700]: mean_loss=0.03415146959014237
Online_Training [174/700]: mean_loss=0.015145390294492245
Online_Training [175/700]: mean_loss=0.010998211917467415
Online_Training [176/700]: mean_loss=0.008905027178116143
Online_Training [177/700]: mean_loss=0.025219849310815334
Online_Training [178/700]: mean_loss=0.03403555927798152
Online_Training [179/700]: mean_loss=0.01542401046026498
Online_Training [180/700]: mean_loss=0.02343897521495819
Online_Training [181/700]: mean_loss=0.02433441113680601
Online_Training [182/700]: mean_loss=0.01899179513566196
Online_Training [183/700]: mean_loss=0.01113222714047879
Online_Training [184/700]: mean_loss=0.006791857595089823
Online_Training [185/700]: mean_loss=0.029469239991158247
Online_Training [186/700]: mean_loss=0.036532405531033874
Online_Training [187/700]: mean_loss=0.02103749313391745
Online_Training [188/700]: mean_loss=0.020884324796497822
Online_Training [189/700]: mean_loss=0.05439797369763255
Online_Training [190/700]: mean_loss=0.017983020981773734
Online_Training [191/700]: mean_loss=0.15058587305247784
Online_Training [192/700]: mean_loss=0.02746923896484077
Online_Training [193/700]: mean_loss=0.02423674985766411
Online_Training [194/700]: mean_loss=0.006211333035025746
Online_Training [195/700]: mean_loss=0.03156834212131798
Online_Training [196/700]: mean_loss=0.013129066675901413
Online_Training [197/700]: mean_loss=0.03119000280275941
Online_Training [198/700]: mean_loss=0.01411853265017271
Online_Training [199/700]: mean_loss=0.09148587938398123
Online_Training [200/700]: mean_loss=0.01809020049404353
Online_Training [201/700]: mean_loss=0.030792340403422713
Online_Training [202/700]: mean_loss=0.027738176519051194
Online_Training [203/700]: mean_loss=0.01377080730162561
Online_Training [204/700]: mean_loss=0.010889837518334389
Online_Training [205/700]: mean_loss=0.05917124915868044
Online_Training [206/700]: mean_loss=0.013124755234457552
Online_Training [207/700]: mean_loss=0.04267576150596142
Online_Training [208/700]: mean_loss=0.03886835649609566
Online_Training [209/700]: mean_loss=0.056686757132411
Online_Training [210/700]: mean_loss=0.014509211177937686
Online_Training [211/700]: mean_loss=0.01183646428398788
Online_Training [212/700]: mean_loss=0.08976535871624947
Online_Training [213/700]: mean_loss=0.054729299154132605
Online_Training [214/700]: mean_loss=0.01302654342725873
Online_Training [215/700]: mean_loss=0.02617013151757419
Online_Training [216/700]: mean_loss=0.05124650150537491
Online_Training [217/700]: mean_loss=0.013881072984077036
Online_Training [218/700]: mean_loss=0.007692814338952303
Online_Training [219/700]: mean_loss=0.04125697398558259
Online_Training [220/700]: mean_loss=0.019430222921073437
Online_Training [221/700]: mean_loss=0.032770826015621424
Online_Training [222/700]: mean_loss=0.015852568321861327
Online_Training [223/700]: mean_loss=0.029801988508552313
Online_Training [224/700]: mean_loss=0.007570522953756154
Online_Training [225/700]: mean_loss=0.018896703841164708
Online_Training [226/700]: mean_loss=0.018083041883073747
Online_Training [227/700]: mean_loss=0.01253788045141846
Online_Training [228/700]: mean_loss=0.028442724840715528
Online_Training [229/700]: mean_loss=0.04341023787856102
Online_Training [230/700]: mean_loss=0.009622706798836589
Online_Training [231/700]: mean_loss=0.01759609393775463
Online_Training [232/700]: mean_loss=0.014898345805704594
Online_Training [233/700]: mean_loss=0.01589031529147178
Online_Training [234/700]: mean_loss=0.013887916225939989
Online_Training [235/700]: mean_loss=0.07950855884701014
Online_Training [236/700]: mean_loss=0.0514780655503273
Online_Training [237/700]: mean_loss=0.021337213460355997
Online_Training [238/700]: mean_loss=0.08215482858940959
Online_Training [239/700]: mean_loss=0.1461372086778283
Online_Training [240/700]: mean_loss=0.05114644719287753
Online_Training [241/700]: mean_loss=0.027304602786898613
Online_Training [242/700]: mean_loss=0.032376037212088704
Online_Training [243/700]: mean_loss=0.03078936692327261
Online_Training [244/700]: mean_loss=0.02682576864026487
Online_Training [245/700]: mean_loss=0.03798876469954848
Online_Training [246/700]: mean_loss=0.018741410924121737
Online_Training [247/700]: mean_loss=0.007453137484844774
Online_Training [248/700]: mean_loss=0.057148225139826536
Online_Training [249/700]: mean_loss=0.01685178850311786
Online_Training [250/700]: mean_loss=0.022306605242192745
Online_Training [251/700]: mean_loss=0.012385350768454373
Online_Training [252/700]: mean_loss=0.011503147892653942
Online_Training [253/700]: mean_loss=0.007764929032418877
Online_Training [254/700]: mean_loss=0.018955084844492376
Online_Training [255/700]: mean_loss=0.043000058736652136
Online_Training [256/700]: mean_loss=0.0159070563968271
Online_Training [257/700]: mean_loss=0.023056957172229886
Online_Training [258/700]: mean_loss=0.013777748099528253
Online_Training [259/700]: mean_loss=0.012593148276209831
Online_Training [260/700]: mean_loss=0.011472398531623185
Online_Training [261/700]: mean_loss=0.025765288388356566
Online_Training [262/700]: mean_loss=0.02568385237827897
Online_Training [263/700]: mean_loss=0.013821725035086274
Online_Training [264/700]: mean_loss=0.020585778867825866
Online_Training [265/700]: mean_loss=0.013666607555933297
Online_Training [266/700]: mean_loss=0.015891583752818406
Online_Training [267/700]: mean_loss=0.021195562556385994
Online_Training [268/700]: mean_loss=0.007146434800233692
Online_Training [269/700]: mean_loss=0.022912256652489305
Online_Training [270/700]: mean_loss=0.017131440923549235
Online_Training [271/700]: mean_loss=0.021391863701865077
Online_Training [272/700]: mean_loss=0.00942082650726661
Online_Training [273/700]: mean_loss=0.013331709196791053
Online_Training [274/700]: mean_loss=0.01280715235043317
Online_Training [275/700]: mean_loss=0.009569730842486024
Online_Training [276/700]: mean_loss=0.014934928971342742
Online_Training [277/700]: mean_loss=0.021775078028440475
Online_Training [278/700]: mean_loss=0.020485909888520837
Online_Training [279/700]: mean_loss=0.013252814300358295
Online_Training [280/700]: mean_loss=0.01612521754577756
Online_Training [281/700]: mean_loss=0.029149426380172372
Online_Training [282/700]: mean_loss=0.02153615257702768
Online_Training [283/700]: mean_loss=0.022633019369095564
Online_Training [284/700]: mean_loss=0.02164338924922049
Online_Training [285/700]: mean_loss=0.01863585924729705
Online_Training [286/700]: mean_loss=0.007762357476167381
Online_Training [287/700]: mean_loss=0.015089996042661369
Online_Training [288/700]: mean_loss=0.01320576190482825
Online_Training [289/700]: mean_loss=0.033129881136119366
Online_Training [290/700]: mean_loss=0.00589261541608721
Online_Training [291/700]: mean_loss=0.011596911703236401
Online_Training [292/700]: mean_loss=0.007775476551614702
Online_Training [293/700]: mean_loss=0.01631195901427418
Online_Training [294/700]: mean_loss=0.02146029588766396
Online_Training [295/700]: mean_loss=0.03293989039957523
Online_Training [296/700]: mean_loss=0.03494008630514145
Online_Training [297/700]: mean_loss=0.01733027515001595
Online_Training [298/700]: mean_loss=0.020638637244701385
Online_Training [299/700]: mean_loss=0.021977445809170604
Online_Training [300/700]: mean_loss=0.040502671618014574
Online_Training [301/700]: mean_loss=0.013704422861337662
Online_Training [302/700]: mean_loss=0.031765112187713385
Online_Training [303/700]: mean_loss=0.018475753255188465
Online_Training [304/700]: mean_loss=0.01108688791282475
Online_Training [305/700]: mean_loss=0.030292279552668333
Online_Training [306/700]: mean_loss=0.052624798845499754
Online_Training [307/700]: mean_loss=0.05842658597975969
Online_Training [308/700]: mean_loss=0.02194588165730238
Online_Training [309/700]: mean_loss=0.01241135154850781
Online_Training [310/700]: mean_loss=0.012956122867763042
Online_Training [311/700]: mean_loss=0.014053042395971715
Online_Training [312/700]: mean_loss=0.046048454474657774
Online_Training [313/700]: mean_loss=0.018720395397394896
Online_Training [314/700]: mean_loss=0.00883251236518845
Online_Training [315/700]: mean_loss=0.007359756506048143
Online_Training [316/700]: mean_loss=0.01568710315041244
Online_Training [317/700]: mean_loss=0.008543620991986245
Online_Training [318/700]: mean_loss=0.01965169352479279
Online_Training [319/700]: mean_loss=0.02571037458255887
Online_Training [320/700]: mean_loss=0.017519824439659715
Online_Training [321/700]: mean_loss=0.018337184330448508
Online_Training [322/700]: mean_loss=0.027872516307979822
Online_Training [323/700]: mean_loss=0.013827061746269464
Online_Training [324/700]: mean_loss=0.02041879971511662
Online_Training [325/700]: mean_loss=0.023309126030653715
Online_Training [326/700]: mean_loss=0.009893587441183627
Online_Training [327/700]: mean_loss=0.02924580150283873
Online_Training [328/700]: mean_loss=0.02592941396869719
Online_Training [329/700]: mean_loss=0.011282962979748845
Online_Training [330/700]: mean_loss=0.028431693324819207
Online_Training [331/700]: mean_loss=0.02957879169844091
Online_Training [332/700]: mean_loss=0.023760812124237418
Online_Training [333/700]: mean_loss=0.017306920373812318
Online_Training [334/700]: mean_loss=0.008550951955839992
Online_Training [335/700]: mean_loss=0.06146021280437708
Online_Training [336/700]: mean_loss=0.07122501730918884
Online_Training [337/700]: mean_loss=0.10574353486299515
Online_Training [338/700]: mean_loss=0.02272478910163045
Online_Training [339/700]: mean_loss=0.013212307007052004
Online_Training [340/700]: mean_loss=0.009591357898898423
Online_Training [341/700]: mean_loss=0.022312410408630967
Online_Training [342/700]: mean_loss=0.057088475208729506
Online_Training [343/700]: mean_loss=0.014568793820217252
Online_Training [344/700]: mean_loss=0.019790329271927476
Online_Training [345/700]: mean_loss=0.03045167215168476
Online_Training [346/700]: mean_loss=0.015792806167155504
Online_Training [347/700]: mean_loss=0.1282806908711791
Online_Training [348/700]: mean_loss=0.01684361486695707
Online_Training [349/700]: mean_loss=0.027909218100830913
Online_Training [350/700]: mean_loss=0.009665496880188584
Online_Training [351/700]: mean_loss=0.009094630600884557
Online_Training [352/700]: mean_loss=0.010008397686760873
Online_Training [353/700]: mean_loss=0.017989142099395394
Online_Training [354/700]: mean_loss=0.014941224595531821
Online_Training [355/700]: mean_loss=0.011585994041524827
Online_Training [356/700]: mean_loss=0.01291899906937033
Online_Training [357/700]: mean_loss=0.08243196364492178
Online_Training [358/700]: mean_loss=0.06548987189307809
Online_Training [359/700]: mean_loss=0.09648586343973875
Online_Training [360/700]: mean_loss=0.025940946536138654
Online_Training [361/700]: mean_loss=0.029702718136832118
Online_Training [362/700]: mean_loss=0.043188242707401514
Online_Training [363/700]: mean_loss=0.014616313390433788
Online_Training [364/700]: mean_loss=0.010156316799111664
Online_Training [365/700]: mean_loss=0.017539680819027126
Online_Training [366/700]: mean_loss=0.013882965431548655
Online_Training [367/700]: mean_loss=0.01983777806162834
Online_Training [368/700]: mean_loss=0.01858979882672429
Online_Training [369/700]: mean_loss=0.012083114706911147
Online_Training [370/700]: mean_loss=0.03952571889385581
Online_Training [371/700]: mean_loss=0.008714159135706723
Online_Training [372/700]: mean_loss=0.021407974418252707
Online_Training [373/700]: mean_loss=0.011502126697450876
Online_Training [374/700]: mean_loss=0.014981298591010273
Online_Training [375/700]: mean_loss=0.019207445671781898
Online_Training [376/700]: mean_loss=0.009463903028517962
Online_Training [377/700]: mean_loss=0.01840479113161564
Online_Training [378/700]: mean_loss=0.015919602708891034
Online_Training [379/700]: mean_loss=0.015188207966275513
Online_Training [380/700]: mean_loss=0.011769640143029392
Online_Training [381/700]: mean_loss=0.01838935841806233
Online_Training [382/700]: mean_loss=0.009493119083344936
Online_Training [383/700]: mean_loss=0.008854739542584866
Online_Training [384/700]: mean_loss=0.1379896430298686
Online_Training [385/700]: mean_loss=0.009294473333284259
Online_Training [386/700]: mean_loss=0.024376247078180313
Online_Training [387/700]: mean_loss=0.017700867378152907
Online_Training [388/700]: mean_loss=0.01833437755703926
Online_Training [389/700]: mean_loss=0.008047814830206335
Online_Training [390/700]: mean_loss=0.025260172551497817
Online_Training [391/700]: mean_loss=0.008255675726104528
Online_Training [392/700]: mean_loss=0.016815029317513108
Online_Training [393/700]: mean_loss=0.01752633391879499
Online_Training [394/700]: mean_loss=0.023954606615006924
Online_Training [395/700]: mean_loss=0.00838377419859171
Online_Training [396/700]: mean_loss=0.020226110005751252
Online_Training [397/700]: mean_loss=0.01393868715967983
Online_Training [398/700]: mean_loss=0.023860243381932378
Online_Training [399/700]: mean_loss=0.01822847221046686
Online_Training [400/700]: mean_loss=0.035002175718545914
Online_Training [401/700]: mean_loss=0.011114602908492088
Online_Training [402/700]: mean_loss=0.01159118046052754
Online_Training [403/700]: mean_loss=0.015759506495669484
Online_Training [404/700]: mean_loss=0.027429418871179223
Online_Training [405/700]: mean_loss=0.06719216657802463
Online_Training [406/700]: mean_loss=0.020507336128503084
Online_Training [407/700]: mean_loss=0.032874150201678276
Online_Training [408/700]: mean_loss=0.02063134335912764
Online_Training [409/700]: mean_loss=0.005809889815282077
Online_Training [410/700]: mean_loss=0.022204533219337463
Online_Training [411/700]: mean_loss=0.015554451383650303
Online_Training [412/700]: mean_loss=0.10243424121290445
Online_Training [413/700]: mean_loss=0.03941974323242903
Online_Training [414/700]: mean_loss=0.016454136231914163
Online_Training [415/700]: mean_loss=0.026681812247261405
Online_Training [416/700]: mean_loss=0.014858315698802471
Online_Training [417/700]: mean_loss=0.05307272309437394
Online_Training [418/700]: mean_loss=0.011557550402358174
Online_Training [419/700]: mean_loss=0.011802828055806458
Online_Training [420/700]: mean_loss=0.05883969645947218
Online_Training [421/700]: mean_loss=0.03866557404398918
Online_Training [422/700]: mean_loss=0.014158092206344008
Online_Training [423/700]: mean_loss=0.03737817378714681
Online_Training [424/700]: mean_loss=0.052830183412879705
Online_Training [425/700]: mean_loss=0.01822882820852101
Online_Training [426/700]: mean_loss=0.0071337452391162515
Online_Training [427/700]: mean_loss=0.013391084154136479
Online_Training [428/700]: mean_loss=0.02651175274513662
Online_Training [429/700]: mean_loss=0.011045251041650772
Online_Training [430/700]: mean_loss=0.00852934323484078
Online_Training [431/700]: mean_loss=0.01462444826029241
Online_Training [432/700]: mean_loss=0.09281627740710974
Online_Training [433/700]: mean_loss=0.01641140680294484
Online_Training [434/700]: mean_loss=0.052160480874590576
Online_Training [435/700]: mean_loss=0.01096057880204171
Online_Training [436/700]: mean_loss=0.08913691155612469
Online_Training [437/700]: mean_loss=0.01637240150012076
Online_Training [438/700]: mean_loss=0.06157036731019616
Online_Training [439/700]: mean_loss=0.02808999246917665
Online_Training [440/700]: mean_loss=0.032194758066907525
Online_Training [441/700]: mean_loss=0.025225447490811348
Online_Training [442/700]: mean_loss=0.009194289508741349
Online_Training [443/700]: mean_loss=0.014440603321418166
Online_Training [444/700]: mean_loss=0.015711800195276737
Online_Training [445/700]: mean_loss=0.023679939098656178
Online_Training [446/700]: mean_loss=0.02367904642596841
Online_Training [447/700]: mean_loss=0.010721212718635798
Online_Training [448/700]: mean_loss=0.02241881424561143
Online_Training [449/700]: mean_loss=0.019776953384280205
Online_Training [450/700]: mean_loss=0.021137770731002092
Online_Training [451/700]: mean_loss=0.02137392433360219
Online_Training [452/700]: mean_loss=0.03803337924182415
Online_Training [453/700]: mean_loss=0.06266697915270925
Online_Training [454/700]: mean_loss=0.017059983918443322
Online_Training [455/700]: mean_loss=0.04029263090342283
Online_Training [456/700]: mean_loss=0.011916106101125479
Online_Training [457/700]: mean_loss=0.007884227205067873
Online_Training [458/700]: mean_loss=0.009612434776499867
Online_Training [459/700]: mean_loss=0.011057635303586721
Online_Training [460/700]: mean_loss=0.020695643266662955
Online_Training [461/700]: mean_loss=0.026157349813729525
Online_Training [462/700]: mean_loss=0.008223837066907436
Online_Training [463/700]: mean_loss=0.005994384235236794
Online_Training [464/700]: mean_loss=0.017104798927903175
Online_Training [465/700]: mean_loss=0.056360100861638784
Online_Training [466/700]: mean_loss=0.023147724336013198
Online_Training [467/700]: mean_loss=0.02919582463800907
Online_Training [468/700]: mean_loss=0.014656182145699859
Online_Training [469/700]: mean_loss=0.023186237318441272
Online_Training [470/700]: mean_loss=0.04063161229714751
Online_Training [471/700]: mean_loss=0.021081803599372506
Online_Training [472/700]: mean_loss=0.026769362622871995
Online_Training [473/700]: mean_loss=0.005154373124241829
Online_Training [474/700]: mean_loss=0.015214786166325212
Online_Training [475/700]: mean_loss=0.009886132320389152
Online_Training [476/700]: mean_loss=0.2140054553747177
Online_Training [477/700]: mean_loss=0.09366059768944979
Online_Training [478/700]: mean_loss=0.037118015345185995
Online_Training [479/700]: mean_loss=0.011636461829766631
Online_Training [480/700]: mean_loss=0.008723706123419106
Online_Training [481/700]: mean_loss=0.01433284068480134
Online_Training [482/700]: mean_loss=0.022942656185477972
Online_Training [483/700]: mean_loss=0.019079093588516116
Online_Training [484/700]: mean_loss=0.014449230628088117
Online_Training [485/700]: mean_loss=0.00684671918861568
Online_Training [486/700]: mean_loss=0.013857064303010702
Online_Training [487/700]: mean_loss=0.03111735568381846
Online_Training [488/700]: mean_loss=0.016743747983127832
Online_Training [489/700]: mean_loss=0.013845316949300468
Online_Training [490/700]: mean_loss=0.025791575433686376
Online_Training [491/700]: mean_loss=0.03419203869998455
Online_Training [492/700]: mean_loss=0.014883526251651347
Online_Training [493/700]: mean_loss=0.013189152465201914
Online_Training [494/700]: mean_loss=0.044391303323209286
Online_Training [495/700]: mean_loss=0.00807052495656535
Online_Training [496/700]: mean_loss=0.027883529663085938
Online_Training [497/700]: mean_loss=0.017453097854740918
Online_Training [498/700]: mean_loss=0.012651559431105852
Online_Training [499/700]: mean_loss=0.012477763229981065
Online_Training [500/700]: mean_loss=0.009212344186380506
Online_Training [501/700]: mean_loss=0.009230780997313559
Online_Training [502/700]: mean_loss=0.01752104621846229
Online_Training [503/700]: mean_loss=0.01593161839991808
Online_Training [504/700]: mean_loss=0.011903419974260032
Online_Training [505/700]: mean_loss=0.011823091306723654
Online_Training [506/700]: mean_loss=0.11689640767872334
Online_Training [507/700]: mean_loss=0.10695407632738352
Online_Training [508/700]: mean_loss=0.029434047872200608
Online_Training [509/700]: mean_loss=0.013885576510801911
Online_Training [510/700]: mean_loss=0.026693379040807486
Online_Training [511/700]: mean_loss=0.006539751659147441
Online_Training [512/700]: mean_loss=0.009149316931143403
Online_Training [513/700]: mean_loss=0.028754464350640774
Online_Training [514/700]: mean_loss=0.03210246982052922
Online_Training [515/700]: mean_loss=0.023950867587700486
Online_Training [516/700]: mean_loss=0.018758129328489304
Online_Training [517/700]: mean_loss=0.02816249430179596
Online_Training [518/700]: mean_loss=0.018755630822852254
Online_Training [519/700]: mean_loss=0.009448831551708281
Online_Training [520/700]: mean_loss=0.0088802290847525
Online_Training [521/700]: mean_loss=0.03671456850133836
Online_Training [522/700]: mean_loss=0.008623087021987885
Online_Training [523/700]: mean_loss=0.020429794443771243
Online_Training [524/700]: mean_loss=0.08138904254883528
Online_Training [525/700]: mean_loss=0.024061112431809306
Online_Training [526/700]: mean_loss=0.01413898984901607
Online_Training [527/700]: mean_loss=0.01580027665477246
Online_Training [528/700]: mean_loss=0.02914080210030079
Online_Training [529/700]: mean_loss=0.019241272704675794
Online_Training [530/700]: mean_loss=0.019389063119888306
Online_Training [531/700]: mean_loss=0.019892952404916286
Online_Training [532/700]: mean_loss=0.023891810327768326
Online_Training [533/700]: mean_loss=0.011809462681412697
Online_Training [534/700]: mean_loss=0.014581611147150397
Online_Training [535/700]: mean_loss=0.023498028283938766
Online_Training [536/700]: mean_loss=0.10296986997127533
Online_Training [537/700]: mean_loss=0.013494431390427053
Online_Training [538/700]: mean_loss=0.01512318814639002
Online_Training [539/700]: mean_loss=0.006771521235350519
Online_Training [540/700]: mean_loss=0.03492223471403122
Online_Training [541/700]: mean_loss=0.11123533453792334
Online_Training [542/700]: mean_loss=0.006207023747265339
Online_Training [543/700]: mean_loss=0.02791157364845276
Online_Training [544/700]: mean_loss=0.010772271547466516
Online_Training [545/700]: mean_loss=0.025531922932714224
Online_Training [546/700]: mean_loss=0.009055301896296442
Online_Training [547/700]: mean_loss=0.015832026139833033
Online_Training [548/700]: mean_loss=0.017811410827562213
Online_Training [549/700]: mean_loss=0.00624370516743511
Online_Training [550/700]: mean_loss=0.028345210012048483
Online_Training [551/700]: mean_loss=0.023142194375395775
Online_Training [552/700]: mean_loss=0.018883887794800103
Online_Training [553/700]: mean_loss=0.032743032556027174
Online_Training [554/700]: mean_loss=0.011366052087396383
Online_Training [555/700]: mean_loss=0.029773282818496227
Online_Training [556/700]: mean_loss=0.014651398523710668
Online_Training [557/700]: mean_loss=0.0177139095030725
Online_Training [558/700]: mean_loss=0.007135313586331904
Online_Training [559/700]: mean_loss=0.0010805176789290272
Online_Training [560/700]: mean_loss=0.007257329532876611
Online_Training [561/700]: mean_loss=0.01840457832440734
Online_Training [562/700]: mean_loss=0.03887050040066242
Online_Training [563/700]: mean_loss=0.03305921098217368
Online_Training [564/700]: mean_loss=0.012389509123750031
Online_Training [565/700]: mean_loss=0.024488930590450764
Online_Training [566/700]: mean_loss=0.01787665393203497
Online_Training [567/700]: mean_loss=0.017775502987205982
Online_Training [568/700]: mean_loss=0.020109608070924878
Online_Training [569/700]: mean_loss=0.027246054727584124
Online_Training [570/700]: mean_loss=0.010742085170932114
Online_Training [571/700]: mean_loss=0.012156608398072422
Online_Training [572/700]: mean_loss=0.016696993494406343
Online_Training [573/700]: mean_loss=0.022689555771648884
Online_Training [574/700]: mean_loss=0.04526460124179721
Online_Training [575/700]: mean_loss=0.04715528432279825
Online_Training [576/700]: mean_loss=0.009781402652151883
Online_Training [577/700]: mean_loss=0.014822723576799035
Online_Training [578/700]: mean_loss=0.007845450134482235
Online_Training [579/700]: mean_loss=0.016561328433454037
Online_Training [580/700]: mean_loss=0.029397260397672653
Online_Training [581/700]: mean_loss=0.01493162801489234
Online_Training [582/700]: mean_loss=0.013154854881577194
Online_Training [583/700]: mean_loss=0.004549058998236433
Online_Training [584/700]: mean_loss=0.01511070178821683
Online_Training [585/700]: mean_loss=0.01894992613233626
Online_Training [586/700]: mean_loss=0.09958535432815552
Online_Training [587/700]: mean_loss=0.023933219257742167
Online_Training [588/700]: mean_loss=0.010554485372267663
Online_Training [589/700]: mean_loss=0.026704980293288827
Online_Training [590/700]: mean_loss=0.020729874027892947
Online_Training [591/700]: mean_loss=0.011255962308496237
Online_Training [592/700]: mean_loss=0.012485214625485241
Online_Training [593/700]: mean_loss=0.0395504510961473
Online_Training [594/700]: mean_loss=0.01873181131668389
Online_Training [595/700]: mean_loss=0.03649988048709929
Online_Training [596/700]: mean_loss=0.009404975920915604
Online_Training [597/700]: mean_loss=0.007625898520927876
Online_Training [598/700]: mean_loss=0.0171325575793162
Online_Training [599/700]: mean_loss=0.01858329714741558
Online_Training [600/700]: mean_loss=0.010646599461324513
Online_Training [601/700]: mean_loss=0.029705181252211332
Online_Training [602/700]: mean_loss=0.0076491087093017995
Online_Training [603/700]: mean_loss=0.007866600877605379
Online_Training [604/700]: mean_loss=0.02244582655839622
Online_Training [605/700]: mean_loss=0.00954145024297759
Online_Training [606/700]: mean_loss=0.005570728913880885
Online_Training [607/700]: mean_loss=0.007218846876639873
Online_Training [608/700]: mean_loss=0.01332287397235632
Online_Training [609/700]: mean_loss=0.011701661976985633
Online_Training [610/700]: mean_loss=0.017926213331520557
Online_Training [611/700]: mean_loss=0.009381442854646593
Online_Training [612/700]: mean_loss=0.1281977789476514
Online_Training [613/700]: mean_loss=0.0395673094317317
Online_Training [614/700]: mean_loss=0.0063292443519458175
Online_Training [615/700]: mean_loss=0.012352807214483619
Online_Training [616/700]: mean_loss=0.019953245762735605
Online_Training [617/700]: mean_loss=0.004337983700679615
Online_Training [618/700]: mean_loss=0.019720557611435652
Online_Training [619/700]: mean_loss=0.01182217278983444
Online_Training [620/700]: mean_loss=0.07129434868693352
Online_Training [621/700]: mean_loss=0.006273314880672842
Online_Training [622/700]: mean_loss=0.048004308715462685
Online_Training [623/700]: mean_loss=0.040735163260251284
Online_Training [624/700]: mean_loss=0.014670946635305882
Online_Training [625/700]: mean_loss=0.010888290242291987
Online_Training [626/700]: mean_loss=0.013232815195806324
Online_Training [627/700]: mean_loss=0.008236442634370178
Online_Training [628/700]: mean_loss=0.009329996071755886
Online_Training [629/700]: mean_loss=0.02429465507157147
Online_Training [630/700]: mean_loss=0.044379329308867455
Online_Training [631/700]: mean_loss=0.014669990865513682
Online_Training [632/700]: mean_loss=0.02679343894124031
Online_Training [633/700]: mean_loss=0.011158942128531635
Online_Training [634/700]: mean_loss=0.018117479048669338
Online_Training [635/700]: mean_loss=0.015562900225631893
Online_Training [636/700]: mean_loss=0.0063716425793245435
Online_Training [637/700]: mean_loss=0.008956512552686036
Online_Training [638/700]: mean_loss=0.015828105621039867
Online_Training [639/700]: mean_loss=0.017041388084180653
Online_Training [640/700]: mean_loss=0.007545559376012534
Online_Training [641/700]: mean_loss=0.019661379512399435
Online_Training [642/700]: mean_loss=0.00994314334820956
Online_Training [643/700]: mean_loss=0.006050595489796251
Online_Training [644/700]: mean_loss=0.01541833346709609
Online_Training [645/700]: mean_loss=0.012549316161312163
Online_Training [646/700]: mean_loss=0.027732124086469412
Online_Training [647/700]: mean_loss=0.008363379281945527
Online_Training [648/700]: mean_loss=0.01119785534683615
Online_Training [649/700]: mean_loss=0.010242979158647358
Online_Training [650/700]: mean_loss=0.010289223399013281
Online_Training [651/700]: mean_loss=0.009472909616306424
Online_Training [652/700]: mean_loss=0.0027114631375297904
Online_Training [653/700]: mean_loss=0.10349810402840376
Online_Training [654/700]: mean_loss=0.013188386685214937
Online_Training [655/700]: mean_loss=0.025376497535035014
Online_Training [656/700]: mean_loss=0.024840330937877297
Online_Training [657/700]: mean_loss=0.01897478208411485
Online_Training [658/700]: mean_loss=0.01519433583598584
Online_Training [659/700]: mean_loss=0.010786858038045466
Online_Training [660/700]: mean_loss=0.014532459783367813
Online_Training [661/700]: mean_loss=0.04448052868247032
Online_Training [662/700]: mean_loss=0.04719531862065196
Online_Training [663/700]: mean_loss=0.01963764405809343
Online_Training [664/700]: mean_loss=0.005017896939534694
Online_Training [665/700]: mean_loss=0.037792196264490485
Online_Training [666/700]: mean_loss=0.011177828651852906
Online_Training [667/700]: mean_loss=0.005392288556322455
Online_Training [668/700]: mean_loss=0.012630890356376767
Online_Training [669/700]: mean_loss=0.01476738229393959
Online_Training [670/700]: mean_loss=0.01457501424010843
Online_Training [671/700]: mean_loss=0.009495718055404723
Online_Training [672/700]: mean_loss=0.011115728528238833
Online_Training [673/700]: mean_loss=0.011823045904748142
Online_Training [674/700]: mean_loss=0.007017636671662331
Online_Training [675/700]: mean_loss=0.007864269136916846
Online_Training [676/700]: mean_loss=0.026193823432549834
Online_Training [677/700]: mean_loss=0.03584282286465168
Online_Training [678/700]: mean_loss=0.020279491553083062
Online_Training [679/700]: mean_loss=0.010781636228784919
Online_Training [680/700]: mean_loss=0.010779887903481722
Online_Training [681/700]: mean_loss=0.021148781524971128
Online_Training [682/700]: mean_loss=0.010847244295291603
Online_Training [683/700]: mean_loss=0.007170788245275617
Online_Training [684/700]: mean_loss=0.009719773021060973
Online_Training [685/700]: mean_loss=0.027649244526401162
Online_Training [686/700]: mean_loss=0.017627213150262833
Online_Training [687/700]: mean_loss=0.009694710723124444
Online_Training [688/700]: mean_loss=0.05334265250712633
Online_Training [689/700]: mean_loss=0.011908475891686976
Online_Training [690/700]: mean_loss=0.00796559633454308
Online_Training [691/700]: mean_loss=0.013296631630510092
Online_Training [692/700]: mean_loss=0.027410777052864432
Online_Training [693/700]: mean_loss=0.012139601982198656
Online_Training [694/700]: mean_loss=0.030699375784024596
Online_Training [695/700]: mean_loss=0.009464164962992072
Online_Training [696/700]: mean_loss=0.04170961258932948
Online_Training [697/700]: mean_loss=0.00549886649241671
Online_Training [698/700]: mean_loss=0.0064066696795634925
Online_Training [699/700]: mean_loss=0.07509197760373354
Online_Training [700/700]: mean_loss=0.006583699258044362
Q_Learning [1/300]: mean_loss=0.22981207445263863
Q_Learning [2/300]: mean_loss=0.24756303057074547
Q_Learning [3/300]: mean_loss=0.20670911110937595
Q_Learning [4/300]: mean_loss=0.07135983277112246
Q_Learning [5/300]: mean_loss=0.2329958062618971
Q_Learning [6/300]: mean_loss=0.1279845628887415
Q_Learning [7/300]: mean_loss=0.13390332646667957
Q_Learning [8/300]: mean_loss=0.056354780215770006
Q_Learning [9/300]: mean_loss=0.2508658282458782
Q_Learning [10/300]: mean_loss=0.12409482523798943
Q_Learning [11/300]: mean_loss=0.09200372826308012
Q_Learning [12/300]: mean_loss=0.08699403330683708
Q_Learning [13/300]: mean_loss=0.08074962813407183
Q_Learning [14/300]: mean_loss=0.10310835111886263
Q_Learning [15/300]: mean_loss=0.08903836458921432
Q_Learning [16/300]: mean_loss=0.10365793574601412
Q_Learning [17/300]: mean_loss=0.1912593748420477
Q_Learning [18/300]: mean_loss=0.1442017164081335
Q_Learning [19/300]: mean_loss=0.042910737451165915
Q_Learning [20/300]: mean_loss=0.14590007066726685
Q_Learning [21/300]: mean_loss=0.12053583096712828
Q_Learning [22/300]: mean_loss=0.05384864518418908
Q_Learning [23/300]: mean_loss=0.03186784917488694
Q_Learning [24/300]: mean_loss=0.08757246378809214
Q_Learning [25/300]: mean_loss=0.05119254346936941
Q_Learning [26/300]: mean_loss=0.07463422417640686
Q_Learning [27/300]: mean_loss=0.0934888431802392
Q_Learning [28/300]: mean_loss=0.06500024441629648
Q_Learning [29/300]: mean_loss=0.04505908489227295
Q_Learning [30/300]: mean_loss=0.03708885610103607
Q_Learning [31/300]: mean_loss=0.02797183790244162
Q_Learning [32/300]: mean_loss=0.046479590237140656
Q_Learning [33/300]: mean_loss=0.026868477929383516
Q_Learning [34/300]: mean_loss=0.1696428805589676
Q_Learning [35/300]: mean_loss=0.0626025409437716
Q_Learning [36/300]: mean_loss=0.0851799538359046
Q_Learning [37/300]: mean_loss=0.05949603021144867
Q_Learning [38/300]: mean_loss=0.04326834063977003
Q_Learning [39/300]: mean_loss=0.13569374568760395
Q_Learning [40/300]: mean_loss=0.02668346813879907
Q_Learning [41/300]: mean_loss=0.03149452339857817
Q_Learning [42/300]: mean_loss=0.048925100825726986
Q_Learning [43/300]: mean_loss=0.13545985519886017
Q_Learning [44/300]: mean_loss=0.15892266668379307
Q_Learning [45/300]: mean_loss=0.10442653298377991
Q_Learning [46/300]: mean_loss=0.06070553557947278
Q_Learning [47/300]: mean_loss=0.10490958020091057
Q_Learning [48/300]: mean_loss=0.06003241427242756
Q_Learning [49/300]: mean_loss=0.10465220361948013
Q_Learning [50/300]: mean_loss=0.12410662602633238
Q_Learning [51/300]: mean_loss=0.03469630191102624
Q_Learning [52/300]: mean_loss=0.17919774167239666
Q_Learning [53/300]: mean_loss=0.04024024261161685
Q_Learning [54/300]: mean_loss=0.09361130651086569
Q_Learning [55/300]: mean_loss=0.08090419415384531
Q_Learning [56/300]: mean_loss=0.034687156323343515
Q_Learning [57/300]: mean_loss=0.13317538518458605
Q_Learning [58/300]: mean_loss=0.24528797902166843
Q_Learning [59/300]: mean_loss=0.07139931246638298
Q_Learning [60/300]: mean_loss=0.08480892423540354
Q_Learning [61/300]: mean_loss=0.07094484101980925
Q_Learning [62/300]: mean_loss=0.07363221328705549
Q_Learning [63/300]: mean_loss=0.06797661073505878
Q_Learning [64/300]: mean_loss=0.01306375628337264
Q_Learning [65/300]: mean_loss=0.06981058232486248
Q_Learning [66/300]: mean_loss=0.04744833428412676
Q_Learning [67/300]: mean_loss=0.05323221767321229
Q_Learning [68/300]: mean_loss=0.04612215934321284
Q_Learning [69/300]: mean_loss=0.09284457564353943
Q_Learning [70/300]: mean_loss=0.03280224232003093
Q_Learning [71/300]: mean_loss=0.07417035195976496
Q_Learning [72/300]: mean_loss=0.08168407715857029
Q_Learning [73/300]: mean_loss=0.04551933519542217
Q_Learning [74/300]: mean_loss=0.04330956842750311
Q_Learning [75/300]: mean_loss=0.020029449369758368
Q_Learning [76/300]: mean_loss=0.043510545045137405
Q_Learning [77/300]: mean_loss=0.03453721012920141
Q_Learning [78/300]: mean_loss=0.043085915967822075
Q_Learning [79/300]: mean_loss=0.033176352735608816
Q_Learning [80/300]: mean_loss=0.03926187381148338
Q_Learning [81/300]: mean_loss=0.022954869316890836
Q_Learning [82/300]: mean_loss=0.03563008410856128
Q_Learning [83/300]: mean_loss=0.06549072964116931
Q_Learning [84/300]: mean_loss=0.039607842452824116
Q_Learning [85/300]: mean_loss=0.02919572778046131
Q_Learning [86/300]: mean_loss=0.03942013159394264
Q_Learning [87/300]: mean_loss=0.017626587068662047
Q_Learning [88/300]: mean_loss=0.01830970693845302
Q_Learning [89/300]: mean_loss=0.027164918836206198
Q_Learning [90/300]: mean_loss=0.024004769511520863
Q_Learning [91/300]: mean_loss=0.03110601776279509
Q_Learning [92/300]: mean_loss=0.04390787007287145
Q_Learning [93/300]: mean_loss=0.03873668145388365
Q_Learning [94/300]: mean_loss=0.050438341684639454
Q_Learning [95/300]: mean_loss=0.04549292614683509
Q_Learning [96/300]: mean_loss=0.02303168410435319
Q_Learning [97/300]: mean_loss=0.04897891916334629
Q_Learning [98/300]: mean_loss=0.024781160056591034
Q_Learning [99/300]: mean_loss=0.021729525178670883
Q_Learning [100/300]: mean_loss=0.04643646581098437
Q_Learning [101/300]: mean_loss=0.018935000873170793
Q_Learning [102/300]: mean_loss=0.05329828476533294
Q_Learning [103/300]: mean_loss=0.04306666739284992
Q_Learning [104/300]: mean_loss=0.04658936755731702
Q_Learning [105/300]: mean_loss=0.033802802208811045
Q_Learning [106/300]: mean_loss=0.017917080549523234
Q_Learning [107/300]: mean_loss=0.018550356850028038
Q_Learning [108/300]: mean_loss=0.027572800172492862
Q_Learning [109/300]: mean_loss=0.027128870598971844
Q_Learning [110/300]: mean_loss=0.03787297080270946
Q_Learning [111/300]: mean_loss=0.023306705988943577
Q_Learning [112/300]: mean_loss=0.12413819786161184
Q_Learning [113/300]: mean_loss=0.02562815777491778
Q_Learning [114/300]: mean_loss=0.024015369126573205
Q_Learning [115/300]: mean_loss=0.03346564946696162
Q_Learning [116/300]: mean_loss=0.024487603455781937
Q_Learning [117/300]: mean_loss=0.04857110558077693
Q_Learning [118/300]: mean_loss=0.03742152592167258
Q_Learning [119/300]: mean_loss=0.11937944125384092
Q_Learning [120/300]: mean_loss=0.060946252197027206
Q_Learning [121/300]: mean_loss=0.04732250235974789
Q_Learning [122/300]: mean_loss=0.06136030284687877
Q_Learning [123/300]: mean_loss=0.031141108134761453
Q_Learning [124/300]: mean_loss=0.010395600460469723
Q_Learning [125/300]: mean_loss=0.07391265174373984
Q_Learning [126/300]: mean_loss=0.03768066270276904
Q_Learning [127/300]: mean_loss=0.03160739201121032
Q_Learning [128/300]: mean_loss=0.021550549194216728
Q_Learning [129/300]: mean_loss=0.02953526540659368
Q_Learning [130/300]: mean_loss=0.018066275282762945
Q_Learning [131/300]: mean_loss=0.020169815979897976
Q_Learning [132/300]: mean_loss=0.019491546554490924
Q_Learning [133/300]: mean_loss=0.02871544100344181
Q_Learning [134/300]: mean_loss=0.012164816609583795
Q_Learning [135/300]: mean_loss=0.10515869129449129
Q_Learning [136/300]: mean_loss=0.019421654986217618
Q_Learning [137/300]: mean_loss=0.016392741352319717
Q_Learning [138/300]: mean_loss=0.011462793103419244
Q_Learning [139/300]: mean_loss=0.017324920394457877
Q_Learning [140/300]: mean_loss=0.030843550339341164
Q_Learning [141/300]: mean_loss=0.03390608751215041
Q_Learning [142/300]: mean_loss=0.012329135090112686
Q_Learning [143/300]: mean_loss=0.02621782897040248
Q_Learning [144/300]: mean_loss=0.009068770508747548
Q_Learning [145/300]: mean_loss=0.025146526284515858
Q_Learning [146/300]: mean_loss=0.020671303384006023
Q_Learning [147/300]: mean_loss=0.014585916884243488
Q_Learning [148/300]: mean_loss=0.04315067920833826
Q_Learning [149/300]: mean_loss=0.05265757720917463
Q_Learning [150/300]: mean_loss=0.06099599087610841
Q_Learning [151/300]: mean_loss=0.02107781497761607
Q_Learning [152/300]: mean_loss=0.015016611316241324
Q_Learning [153/300]: mean_loss=0.022651325445622206
Q_Learning [154/300]: mean_loss=0.01798099873121828
Q_Learning [155/300]: mean_loss=0.012288927682675421
Q_Learning [156/300]: mean_loss=0.01674767106305808
Q_Learning [157/300]: mean_loss=0.10599534772336483
Q_Learning [158/300]: mean_loss=0.006010026903823018
Q_Learning [159/300]: mean_loss=0.0249071903526783
Q_Learning [160/300]: mean_loss=0.016953084617853165
Q_Learning [161/300]: mean_loss=0.02504249708727002
Q_Learning [162/300]: mean_loss=0.011825893307104707
Q_Learning [163/300]: mean_loss=0.039374264888465405
Q_Learning [164/300]: mean_loss=0.015465213567949831
Q_Learning [165/300]: mean_loss=0.00807259464636445
Q_Learning [166/300]: mean_loss=0.01837530266493559
Q_Learning [167/300]: mean_loss=0.03148739016614854
Q_Learning [168/300]: mean_loss=0.042622416745871305
Q_Learning [169/300]: mean_loss=0.052397108636796474
Q_Learning [170/300]: mean_loss=0.16565680503845215
Q_Learning [171/300]: mean_loss=0.017599148908630013
Q_Learning [172/300]: mean_loss=0.02029899600893259
Q_Learning [173/300]: mean_loss=0.03415146959014237
Q_Learning [174/300]: mean_loss=0.015145390294492245
Q_Learning [175/300]: mean_loss=0.010998211917467415
Q_Learning [176/300]: mean_loss=0.008905027178116143
Q_Learning [177/300]: mean_loss=0.025219849310815334
Q_Learning [178/300]: mean_loss=0.03403555927798152
Q_Learning [179/300]: mean_loss=0.01542401046026498
Q_Learning [180/300]: mean_loss=0.02343897521495819
Q_Learning [181/300]: mean_loss=0.02433441113680601
Q_Learning [182/300]: mean_loss=0.01899179513566196
Q_Learning [183/300]: mean_loss=0.01113222714047879
Q_Learning [184/300]: mean_loss=0.006791857595089823
Q_Learning [185/300]: mean_loss=0.029469239991158247
Q_Learning [186/300]: mean_loss=0.036532405531033874
Q_Learning [187/300]: mean_loss=0.02103749313391745
Q_Learning [188/300]: mean_loss=0.020884324796497822
Q_Learning [189/300]: mean_loss=0.05439797369763255
Q_Learning [190/300]: mean_loss=0.017983020981773734
Q_Learning [191/300]: mean_loss=0.15058587305247784
Q_Learning [192/300]: mean_loss=0.02746923896484077
Q_Learning [193/300]: mean_loss=0.02423674985766411
Q_Learning [194/300]: mean_loss=0.006211333035025746
Q_Learning [195/300]: mean_loss=0.03156834212131798
Q_Learning [196/300]: mean_loss=0.013129066675901413
Q_Learning [197/300]: mean_loss=0.03119000280275941
Q_Learning [198/300]: mean_loss=0.01411853265017271
Q_Learning [199/300]: mean_loss=0.09148587938398123
Q_Learning [200/300]: mean_loss=0.01809020049404353
Q_Learning [201/300]: mean_loss=0.030792340403422713
Q_Learning [202/300]: mean_loss=0.027738176519051194
Q_Learning [203/300]: mean_loss=0.01377080730162561
Q_Learning [204/300]: mean_loss=0.010889837518334389
Q_Learning [205/300]: mean_loss=0.05917124915868044
Q_Learning [206/300]: mean_loss=0.013124755234457552
Q_Learning [207/300]: mean_loss=0.04267576150596142
Q_Learning [208/300]: mean_loss=0.03886835649609566
Q_Learning [209/300]: mean_loss=0.056686757132411
Q_Learning [210/300]: mean_loss=0.014509211177937686
Q_Learning [211/300]: mean_loss=0.01183646428398788
Q_Learning [212/300]: mean_loss=0.08976535871624947
Q_Learning [213/300]: mean_loss=0.054729299154132605
Q_Learning [214/300]: mean_loss=0.01302654342725873
Q_Learning [215/300]: mean_loss=0.02617013151757419
Q_Learning [216/300]: mean_loss=0.05124650150537491
Q_Learning [217/300]: mean_loss=0.013881072984077036
Q_Learning [218/300]: mean_loss=0.007692814338952303
Q_Learning [219/300]: mean_loss=0.04125697398558259
Q_Learning [220/300]: mean_loss=0.019430222921073437
Q_Learning [221/300]: mean_loss=0.032770826015621424
Q_Learning [222/300]: mean_loss=0.015852568321861327
Q_Learning [223/300]: mean_loss=0.029801988508552313
Q_Learning [224/300]: mean_loss=0.007570522953756154
Q_Learning [225/300]: mean_loss=0.018896703841164708
Q_Learning [226/300]: mean_loss=0.018083041883073747
Q_Learning [227/300]: mean_loss=0.01253788045141846
Q_Learning [228/300]: mean_loss=0.028442724840715528
Q_Learning [229/300]: mean_loss=0.04341023787856102
Q_Learning [230/300]: mean_loss=0.009622706798836589
Q_Learning [231/300]: mean_loss=0.01759609393775463
Q_Learning [232/300]: mean_loss=0.014898345805704594
Q_Learning [233/300]: mean_loss=0.01589031529147178
Q_Learning [234/300]: mean_loss=0.013887916225939989
Q_Learning [235/300]: mean_loss=0.07950855884701014
Q_Learning [236/300]: mean_loss=0.0514780655503273
Q_Learning [237/300]: mean_loss=0.021337213460355997
Q_Learning [238/300]: mean_loss=0.08215482858940959
Q_Learning [239/300]: mean_loss=0.1461372086778283
Q_Learning [240/300]: mean_loss=0.05114644719287753
Q_Learning [241/300]: mean_loss=0.027304602786898613
Q_Learning [242/300]: mean_loss=0.032376037212088704
Q_Learning [243/300]: mean_loss=0.03078936692327261
Q_Learning [244/300]: mean_loss=0.02682576864026487
Q_Learning [245/300]: mean_loss=0.03798876469954848
Q_Learning [246/300]: mean_loss=0.018741410924121737
Q_Learning [247/300]: mean_loss=0.007453137484844774
Q_Learning [248/300]: mean_loss=0.057148225139826536
Q_Learning [249/300]: mean_loss=0.01685178850311786
Q_Learning [250/300]: mean_loss=0.022306605242192745
Q_Learning [251/300]: mean_loss=0.012385350768454373
Q_Learning [252/300]: mean_loss=0.011503147892653942
Q_Learning [253/300]: mean_loss=0.007764929032418877
Q_Learning [254/300]: mean_loss=0.018955084844492376
Q_Learning [255/300]: mean_loss=0.043000058736652136
Q_Learning [256/300]: mean_loss=0.0159070563968271
Q_Learning [257/300]: mean_loss=0.023056957172229886
Q_Learning [258/300]: mean_loss=0.013777748099528253
Q_Learning [259/300]: mean_loss=0.012593148276209831
Q_Learning [260/300]: mean_loss=0.011472398531623185
Q_Learning [261/300]: mean_loss=0.025765288388356566
Q_Learning [262/300]: mean_loss=0.02568385237827897
Q_Learning [263/300]: mean_loss=0.013821725035086274
Q_Learning [264/300]: mean_loss=0.020585778867825866
Q_Learning [265/300]: mean_loss=0.013666607555933297
Q_Learning [266/300]: mean_loss=0.015891583752818406
Q_Learning [267/300]: mean_loss=0.021195562556385994
Q_Learning [268/300]: mean_loss=0.007146434800233692
Q_Learning [269/300]: mean_loss=0.022912256652489305
Q_Learning [270/300]: mean_loss=0.017131440923549235
Q_Learning [271/300]: mean_loss=0.021391863701865077
Q_Learning [272/300]: mean_loss=0.00942082650726661
Q_Learning [273/300]: mean_loss=0.013331709196791053
Q_Learning [274/300]: mean_loss=0.01280715235043317
Q_Learning [275/300]: mean_loss=0.009569730842486024
Q_Learning [276/300]: mean_loss=0.014934928971342742
Q_Learning [277/300]: mean_loss=0.021775078028440475
Q_Learning [278/300]: mean_loss=0.020485909888520837
Q_Learning [279/300]: mean_loss=0.013252814300358295
Q_Learning [280/300]: mean_loss=0.01612521754577756
Q_Learning [281/300]: mean_loss=0.029149426380172372
Q_Learning [282/300]: mean_loss=0.02153615257702768
Q_Learning [283/300]: mean_loss=0.022633019369095564
Q_Learning [284/300]: mean_loss=0.02164338924922049
Q_Learning [285/300]: mean_loss=0.01863585924729705
Q_Learning [286/300]: mean_loss=0.007762357476167381
Q_Learning [287/300]: mean_loss=0.015089996042661369
Q_Learning [288/300]: mean_loss=0.01320576190482825
Q_Learning [289/300]: mean_loss=0.033129881136119366
Q_Learning [290/300]: mean_loss=0.00589261541608721
Q_Learning [291/300]: mean_loss=0.011596911703236401
Q_Learning [292/300]: mean_loss=0.007775476551614702
Q_Learning [293/300]: mean_loss=0.01631195901427418
Q_Learning [294/300]: mean_loss=0.02146029588766396
Q_Learning [295/300]: mean_loss=0.03293989039957523
Q_Learning [296/300]: mean_loss=0.03494008630514145
Q_Learning [297/300]: mean_loss=0.01733027515001595
Q_Learning [298/300]: mean_loss=0.020638637244701385
Q_Learning [299/300]: mean_loss=0.021977445809170604
Q_Learning [300/300]: mean_loss=0.040502671618014574
Number of Samples after Autoencoder testing: 300
First Spike after testing: [-0.658382 -0.555947]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2, 1, 0, 0, 3, 2, 1, 1, 2, 1, 0, 0, 1, 0, 1, 3, 1, 0, 0, 1, 2, 2, 0, 1, 2, 3, 2, 1, 0, 2, 1, 2, 0, 3, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 2, 1, 0, 2, 4, 0, 1, 5, 2, 1, 2, 4, 2, 2, 1, 4, 2, 2, 4, 2, 1, 2, 2, 2, 0, 2, 2, 1, 1, 0, 1, 3, 0, 2, 1, 2, 1, 3, 1, 1, 0, 1, 1, 4, 1, 1, 5, 0, 3, 0, 2, 5, 0, 1, 5, 1, 1, 5, 0, 2, 2, 5, 5, 1, 1, 3, 5, 1, 3, 2, 2, 0, 1, 1, 2, 5, 0, 1, 0, 4, 2, 5, 1, 5, 5, 2, 0, 2, 2, 1, 1, 1, 0, 0, 1, 0, 3, 2, 3, 2, 0, 1, 4, 1, 1, 4, 1, 2, 0, 1, 1, 1, 0, 0, 2, 1, 1, 3, 1, 3, 2, 5, 2, 1, 0, 2, 2, 2, 2, 3, 2, 1, 2, 1, 4, 3, 2, 5, 5, 5, 1, 5, 3, 0, 0, 2, 0, 0, 2, 2, 1, 2, 3, 4, 1, 2, 2, 0, 2, 1, 0, 1, 2, 1, 6, 3, 2, 2, 2, 2, 2, 0, 1, 0, 0, 4, 0, 1, 4, 0, 4, 1, 2, 1, 2, 2, 4, 3, 2, 2, 1, 2, 2, 2, 1, 2, 6, 2, 0, 0, 2, 5, 7, 0, 4, 1, 2, 1, 0, 6, 1, 0, 0, 2, 1, 1, 6, 1, 2, 4, 4, 2, 2, 2, 2, 5]
Centroids: [[0.3348489, 1.1060411], [0.16192041, 0.54548967], [-0.4712832, -0.6701898]]
Centroids: [[-0.4014246, -0.6575117], [0.4743628, 0.76727355], [-0.05167084, 0.7863376], [-1.0248997, -0.41419703], [0.06705558, -1.0321084], [0.79593, 1.2929983], [-0.7803627, 1.2170624], [-2.2106621, 0.28844872]]
Contingency Matrix: 
[[ 0 43 39  0  0 17  4  0]
 [ 1 48 49  0  0  2  0  0]
 [59  0  0 20 17  0  0  1]]
[[0, 43, 39, 0, 0, 17, 4, 0], [1, 48, 49, 0, 0, 2, 0, 0], [59, 0, 0, 20, 17, 0, 0, 1]]
[[0, 43, 39, 0, 0, 17, 4, 0], [1, 48, 49, 0, 0, 2, 0, 0], [59, 0, 0, 20, 17, 0, 0, 1]]
[0, 1, 2, 3, 4, 5, 6, 7]
[[-1, 43, 39, 0, 0, 17, 4, 0], [-1, 48, 49, 0, 0, 2, 0, 0], [-1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, 43, -1, 0, 0, 17, 4, 0], [-1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {2: 0, 1: 2, 0: 1}
New Contingency Matrix: 
[[43 39  0  0  0 17  4  0]
 [48 49  1  0  0  2  0  0]
 [ 0  0 59 20 17  0  0  1]]
New Clustered Label Sequence: [1, 2, 0, 3, 4, 5, 6, 7]
Diagonal_Elements: [43, 49, 59], Sum: 151
All_Elements: [43, 39, 0, 0, 0, 17, 4, 0, 48, 49, 1, 0, 0, 2, 0, 0, 0, 0, 59, 20, 17, 0, 0, 1], Sum: 300
Accuracy: 0.5033333333333333
