Experiment_path: AE_Model_1/Random_Seeds_DV5//V5_1/Experiment_05_9_opt
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Drift_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Drift_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt
Visualisation_Path: AE_Model_1/Random_Seeds_DV5//V5_1/Experiment_05_9_opt/C_Drift_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt/2023_04_24-16_49_14
Punishment_Coefficient: 0.7
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x0000026B4FCE7D68>
Sampling rate: 24000.0
Raw: [-0.11406566 -0.12673582 -0.13859424 ... -0.1533925  -0.11314303
 -0.07599672]
Times: [    141    1662    1690 ... 1437394 1438167 1439221]
Cluster: [3 3 1 ... 1 3 1]
Number of different clusters:  3
Number of Spikes: 3444
First aligned Spike Frame: [-1.36998177e-01 -1.49794115e-01 -1.51139147e-01 -1.34027918e-01
 -1.09988960e-01 -9.86934846e-02 -1.08483729e-01 -1.27522960e-01
 -1.35591044e-01 -1.26517001e-01 -9.48742956e-02 -8.16393331e-04
  2.25765217e-01  5.72256463e-01  8.98736621e-01  1.04373325e+00
  9.77396764e-01  8.07455467e-01  6.41295597e-01  5.04504644e-01
  3.89667525e-01  2.93991016e-01  2.08446734e-01  1.08695180e-01
 -1.90255699e-02 -1.51076860e-01 -2.47294168e-01 -3.00867038e-01
 -3.38922213e-01 -3.74759690e-01 -3.88805853e-01 -3.48577503e-01
 -2.56264435e-01 -1.52199911e-01 -7.91585816e-02 -5.05132281e-02
 -5.44251469e-02 -6.88811373e-02 -7.02917794e-02 -5.09609752e-02
 -2.91934475e-02 -2.32878628e-02 -2.62245500e-02 -1.24323704e-02
  2.48287815e-02  6.36178972e-02  8.45690766e-02]
Cluster 0, Occurrences: 1142
Cluster 1, Occurrences: 1180
Cluster 2, Occurrences: 1122
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.11833757348358631
Online_Training [2/700]: mean_loss=0.14686627499759197
Online_Training [3/700]: mean_loss=0.2839951664209366
Online_Training [4/700]: mean_loss=0.12085453141480684
Online_Training [5/700]: mean_loss=0.12830413412302732
Online_Training [6/700]: mean_loss=0.11589607782661915
Online_Training [7/700]: mean_loss=0.03346663201227784
Online_Training [8/700]: mean_loss=0.09644392039626837
Online_Training [9/700]: mean_loss=0.13675272651016712
Online_Training [10/700]: mean_loss=0.07645421288907528
Online_Training [11/700]: mean_loss=0.0658262437209487
Online_Training [12/700]: mean_loss=0.03584970720112324
Online_Training [13/700]: mean_loss=0.07911655679345131
Online_Training [14/700]: mean_loss=0.15449640713632107
Online_Training [15/700]: mean_loss=0.09301715716719627
Online_Training [16/700]: mean_loss=0.056949679274111986
Online_Training [17/700]: mean_loss=0.06932222936302423
Online_Training [18/700]: mean_loss=0.15015309490263462
Online_Training [19/700]: mean_loss=0.048410821706056595
Online_Training [20/700]: mean_loss=0.12005084753036499
Online_Training [21/700]: mean_loss=0.04161732969805598
Online_Training [22/700]: mean_loss=0.06161195831373334
Online_Training [23/700]: mean_loss=0.06629588920623064
Online_Training [24/700]: mean_loss=0.12816834170371294
Online_Training [25/700]: mean_loss=0.05572895100340247
Online_Training [26/700]: mean_loss=0.10081421304494143
Online_Training [27/700]: mean_loss=0.1455188561230898
Online_Training [28/700]: mean_loss=0.060375196393579245
Online_Training [29/700]: mean_loss=0.0916881849989295
Online_Training [30/700]: mean_loss=0.0864740926772356
Online_Training [31/700]: mean_loss=0.14247368462383747
Online_Training [32/700]: mean_loss=0.0548551706597209
Online_Training [33/700]: mean_loss=0.06471700128167868
Online_Training [34/700]: mean_loss=0.07106719072908163
Online_Training [35/700]: mean_loss=0.10414784587919712
Online_Training [36/700]: mean_loss=0.0808654734864831
Online_Training [37/700]: mean_loss=0.14637033827602863
Online_Training [38/700]: mean_loss=0.1609783098101616
Online_Training [39/700]: mean_loss=0.0724229346960783
Online_Training [40/700]: mean_loss=0.04442815762013197
Online_Training [41/700]: mean_loss=0.0908120246604085
Online_Training [42/700]: mean_loss=0.06060068216174841
Online_Training [43/700]: mean_loss=0.07926925830543041
Online_Training [44/700]: mean_loss=0.03423850145190954
Online_Training [45/700]: mean_loss=0.05415165098384023
Online_Training [46/700]: mean_loss=0.11688414495438337
Online_Training [47/700]: mean_loss=0.04994121519848704
Online_Training [48/700]: mean_loss=0.03540866635739803
Online_Training [49/700]: mean_loss=0.022630562540143728
Online_Training [50/700]: mean_loss=0.05506811384111643
Online_Training [51/700]: mean_loss=0.08385677449405193
Online_Training [52/700]: mean_loss=0.02310711075551808
Online_Training [53/700]: mean_loss=0.042036109836772084
Online_Training [54/700]: mean_loss=0.023362195817753673
Online_Training [55/700]: mean_loss=0.04167443560436368
Online_Training [56/700]: mean_loss=0.042488574516028166
Online_Training [57/700]: mean_loss=0.03485584072768688
Online_Training [58/700]: mean_loss=0.03973211068660021
Online_Training [59/700]: mean_loss=0.02093339222483337
Online_Training [60/700]: mean_loss=0.03425547783263028
Online_Training [61/700]: mean_loss=0.04423254542052746
Online_Training [62/700]: mean_loss=0.09591320063918829
Online_Training [63/700]: mean_loss=0.058668948244303465
Online_Training [64/700]: mean_loss=0.038223061710596085
Online_Training [65/700]: mean_loss=0.02895591501146555
Online_Training [66/700]: mean_loss=0.030250974697992206
Online_Training [67/700]: mean_loss=0.057545917108654976
Online_Training [68/700]: mean_loss=0.05025102850049734
Online_Training [69/700]: mean_loss=0.0596201429143548
Online_Training [70/700]: mean_loss=0.02915718569420278
Online_Training [71/700]: mean_loss=0.01637231616768986
Online_Training [72/700]: mean_loss=0.04188032145611942
Online_Training [73/700]: mean_loss=0.03319992916658521
Online_Training [74/700]: mean_loss=0.047920614713802934
Online_Training [75/700]: mean_loss=0.015846610418520868
Online_Training [76/700]: mean_loss=0.052962356712669134
Online_Training [77/700]: mean_loss=0.027041157707571983
Online_Training [78/700]: mean_loss=0.06310840277001262
Online_Training [79/700]: mean_loss=0.0959320031106472
Online_Training [80/700]: mean_loss=0.0716081066057086
Online_Training [81/700]: mean_loss=0.013924229773692787
Online_Training [82/700]: mean_loss=0.04543600603938103
Online_Training [83/700]: mean_loss=0.028191451681777835
Online_Training [84/700]: mean_loss=0.01817951293196529
Online_Training [85/700]: mean_loss=0.051300978753715754
Online_Training [86/700]: mean_loss=0.024037661962211132
Online_Training [87/700]: mean_loss=0.09448983427137136
Online_Training [88/700]: mean_loss=0.020001069409772754
Online_Training [89/700]: mean_loss=0.01366895972751081
Online_Training [90/700]: mean_loss=0.06131504522636533
Online_Training [91/700]: mean_loss=0.01565557753201574
Online_Training [92/700]: mean_loss=0.010843987111002207
Online_Training [93/700]: mean_loss=0.052392181009054184
Online_Training [94/700]: mean_loss=0.016027816920541227
Online_Training [95/700]: mean_loss=0.014265284582506865
Online_Training [96/700]: mean_loss=0.05124867241829634
Online_Training [97/700]: mean_loss=0.025472022825852036
Online_Training [98/700]: mean_loss=0.007762168301269412
Online_Training [99/700]: mean_loss=0.1325907800346613
Online_Training [100/700]: mean_loss=0.05155057040974498
Online_Training [101/700]: mean_loss=0.018779716454446316
Online_Training [102/700]: mean_loss=0.0127606246387586
Online_Training [103/700]: mean_loss=0.02323449682444334
Online_Training [104/700]: mean_loss=0.018797444296069443
Online_Training [105/700]: mean_loss=0.015101790893822908
Online_Training [106/700]: mean_loss=0.018372491118498147
Online_Training [107/700]: mean_loss=0.005565203202422708
Online_Training [108/700]: mean_loss=0.01913235941901803
Online_Training [109/700]: mean_loss=0.006344871944747865
Online_Training [110/700]: mean_loss=0.04581941571086645
Online_Training [111/700]: mean_loss=0.026500406442210078
Online_Training [112/700]: mean_loss=0.0074456409201957285
Online_Training [113/700]: mean_loss=0.015964273363351822
Online_Training [114/700]: mean_loss=0.01960585988126695
Online_Training [115/700]: mean_loss=0.03174728457815945
Online_Training [116/700]: mean_loss=0.019143502693623304
Online_Training [117/700]: mean_loss=0.02375494549050927
Online_Training [118/700]: mean_loss=0.024529391201213002
Online_Training [119/700]: mean_loss=0.14779485762119293
Online_Training [120/700]: mean_loss=0.12917264830321074
Online_Training [121/700]: mean_loss=0.0815835827961564
Online_Training [122/700]: mean_loss=0.12008627504110336
Online_Training [123/700]: mean_loss=0.045318837743252516
Online_Training [124/700]: mean_loss=0.040247174911201
Online_Training [125/700]: mean_loss=0.03892332594841719
Online_Training [126/700]: mean_loss=0.012025093426927924
Online_Training [127/700]: mean_loss=0.04755612509325147
Online_Training [128/700]: mean_loss=0.03337321546860039
Online_Training [129/700]: mean_loss=0.08603266812860966
Online_Training [130/700]: mean_loss=0.01841048547066748
Online_Training [131/700]: mean_loss=0.10996352136135101
Online_Training [132/700]: mean_loss=0.012982922955416143
Online_Training [133/700]: mean_loss=0.012260042480193079
Online_Training [134/700]: mean_loss=0.01111556647811085
Online_Training [135/700]: mean_loss=0.024182470981031656
Online_Training [136/700]: mean_loss=0.006570954981725663
Online_Training [137/700]: mean_loss=0.022081474075093865
Online_Training [138/700]: mean_loss=0.029062151443213224
Online_Training [139/700]: mean_loss=0.006596217164769769
Online_Training [140/700]: mean_loss=0.013973452500067651
Online_Training [141/700]: mean_loss=0.011712356354109943
Online_Training [142/700]: mean_loss=0.028847816865891218
Online_Training [143/700]: mean_loss=0.0642983797006309
Online_Training [144/700]: mean_loss=0.034536863677203655
Online_Training [145/700]: mean_loss=0.036567306611686945
Online_Training [146/700]: mean_loss=0.04849298531189561
Online_Training [147/700]: mean_loss=0.030163061572238803
Online_Training [148/700]: mean_loss=0.00853224185993895
Online_Training [149/700]: mean_loss=0.035219458397477865
Online_Training [150/700]: mean_loss=0.020152648212388158
Online_Training [151/700]: mean_loss=0.023001844179816544
Online_Training [152/700]: mean_loss=0.011666352627798915
Online_Training [153/700]: mean_loss=0.016850116895511746
Online_Training [154/700]: mean_loss=0.07726708147674799
Online_Training [155/700]: mean_loss=0.015048854053020477
Online_Training [156/700]: mean_loss=0.04265586752444506
Online_Training [157/700]: mean_loss=0.04483219003304839
Online_Training [158/700]: mean_loss=0.02014941372908652
Online_Training [159/700]: mean_loss=0.006225998920854181
Online_Training [160/700]: mean_loss=0.01594880549237132
Online_Training [161/700]: mean_loss=0.03349303500726819
Online_Training [162/700]: mean_loss=0.020385626587085426
Online_Training [163/700]: mean_loss=0.020919034956023097
Online_Training [164/700]: mean_loss=0.014279618626460433
Online_Training [165/700]: mean_loss=0.014869207749143243
Online_Training [166/700]: mean_loss=0.03492239722982049
Online_Training [167/700]: mean_loss=0.027819426031783223
Online_Training [168/700]: mean_loss=0.022707401076331735
Online_Training [169/700]: mean_loss=0.015854449477046728
Online_Training [170/700]: mean_loss=0.026429286459460855
Online_Training [171/700]: mean_loss=0.009364369325339794
Online_Training [172/700]: mean_loss=0.008624134992714971
Online_Training [173/700]: mean_loss=0.0064976580324582756
Online_Training [174/700]: mean_loss=0.01449033699464053
Online_Training [175/700]: mean_loss=0.009578022989444435
Online_Training [176/700]: mean_loss=0.018013265915215015
Online_Training [177/700]: mean_loss=0.03584321867674589
Online_Training [178/700]: mean_loss=0.022659544367343187
Online_Training [179/700]: mean_loss=0.03809833968989551
Online_Training [180/700]: mean_loss=0.015051803435198963
Online_Training [181/700]: mean_loss=0.018403702415525913
Online_Training [182/700]: mean_loss=0.023353202966973186
Online_Training [183/700]: mean_loss=0.011179437628015876
Online_Training [184/700]: mean_loss=0.015297191101126373
Online_Training [185/700]: mean_loss=0.020180869614705443
Online_Training [186/700]: mean_loss=0.04681749688461423
Online_Training [187/700]: mean_loss=0.014994804630987346
Online_Training [188/700]: mean_loss=0.0665728971362114
Online_Training [189/700]: mean_loss=0.030403820797801018
Online_Training [190/700]: mean_loss=0.010451902518980205
Online_Training [191/700]: mean_loss=0.024979000678285956
Online_Training [192/700]: mean_loss=0.026197471423074603
Online_Training [193/700]: mean_loss=0.03202742827124894
Online_Training [194/700]: mean_loss=0.028463041642680764
Online_Training [195/700]: mean_loss=0.029634463600814342
Online_Training [196/700]: mean_loss=0.03414121153764427
Online_Training [197/700]: mean_loss=0.020125962560996413
Online_Training [198/700]: mean_loss=0.008127677137963474
Online_Training [199/700]: mean_loss=0.013559322687797248
Online_Training [200/700]: mean_loss=0.016548012499697506
Online_Training [201/700]: mean_loss=0.004247569828294218
Online_Training [202/700]: mean_loss=0.08434146270155907
Online_Training [203/700]: mean_loss=0.07866699900478125
Online_Training [204/700]: mean_loss=0.023857938824221492
Online_Training [205/700]: mean_loss=0.026335532777011395
Online_Training [206/700]: mean_loss=0.020971126155927777
Online_Training [207/700]: mean_loss=0.018910194747149944
Online_Training [208/700]: mean_loss=0.03353946725837886
Online_Training [209/700]: mean_loss=0.04219098435714841
Online_Training [210/700]: mean_loss=0.013182320864871144
Online_Training [211/700]: mean_loss=0.04360766522586346
Online_Training [212/700]: mean_loss=0.027817975729703903
Online_Training [213/700]: mean_loss=0.012399894068948925
Online_Training [214/700]: mean_loss=0.014655123581178486
Online_Training [215/700]: mean_loss=0.0185877118492499
Online_Training [216/700]: mean_loss=0.018464914755895734
Online_Training [217/700]: mean_loss=0.010794085683301091
Online_Training [218/700]: mean_loss=0.05402566818520427
Online_Training [219/700]: mean_loss=0.015834808466024697
Online_Training [220/700]: mean_loss=0.03913324559107423
Online_Training [221/700]: mean_loss=0.0250350977294147
Online_Training [222/700]: mean_loss=0.1765976920723915
Online_Training [223/700]: mean_loss=0.029007792472839355
Online_Training [224/700]: mean_loss=0.022488576592877507
Online_Training [225/700]: mean_loss=0.018239396275021136
Online_Training [226/700]: mean_loss=0.02174347499385476
Online_Training [227/700]: mean_loss=0.023077521240338683
Online_Training [228/700]: mean_loss=0.01729599852114916
Online_Training [229/700]: mean_loss=0.014403028413653374
Online_Training [230/700]: mean_loss=0.011912838905118406
Online_Training [231/700]: mean_loss=0.014922298374585807
Online_Training [232/700]: mean_loss=0.02227517426945269
Online_Training [233/700]: mean_loss=0.039579924661666155
Online_Training [234/700]: mean_loss=0.036752209067344666
Online_Training [235/700]: mean_loss=0.012139930040575564
Online_Training [236/700]: mean_loss=0.03868126543238759
Online_Training [237/700]: mean_loss=0.018794572446495295
Online_Training [238/700]: mean_loss=0.009503459965344518
Online_Training [239/700]: mean_loss=0.04396201949566603
Online_Training [240/700]: mean_loss=0.05289522372186184
Online_Training [241/700]: mean_loss=0.02225790871307254
Online_Training [242/700]: mean_loss=0.0283871041610837
Online_Training [243/700]: mean_loss=0.01488963863812387
Online_Training [244/700]: mean_loss=0.03794539766386151
Online_Training [245/700]: mean_loss=0.01249763451050967
Online_Training [246/700]: mean_loss=0.021009416552260518
Online_Training [247/700]: mean_loss=0.02450241264887154
Online_Training [248/700]: mean_loss=0.021537144435569644
Online_Training [249/700]: mean_loss=0.009742358815856278
Online_Training [250/700]: mean_loss=0.01650351332500577
Online_Training [251/700]: mean_loss=0.014618572546169162
Online_Training [252/700]: mean_loss=0.011182018788531423
Online_Training [253/700]: mean_loss=0.01629937335383147
Online_Training [254/700]: mean_loss=0.030578714096918702
Online_Training [255/700]: mean_loss=0.018686300609260798
Online_Training [256/700]: mean_loss=0.01479249750263989
Online_Training [257/700]: mean_loss=0.0298897756729275
Online_Training [258/700]: mean_loss=0.1338363727554679
Online_Training [259/700]: mean_loss=0.14057581685483456
Online_Training [260/700]: mean_loss=0.015999795985408127
Online_Training [261/700]: mean_loss=0.007694871863350272
Online_Training [262/700]: mean_loss=0.01584093808196485
Online_Training [263/700]: mean_loss=0.014356453670188785
Online_Training [264/700]: mean_loss=0.04030215926468372
Online_Training [265/700]: mean_loss=0.025571034755557775
Online_Training [266/700]: mean_loss=0.012766432017087936
Online_Training [267/700]: mean_loss=0.014265374629758298
Online_Training [268/700]: mean_loss=0.07175965886563063
Online_Training [269/700]: mean_loss=0.012240845011547208
Online_Training [270/700]: mean_loss=0.009150746569503099
Online_Training [271/700]: mean_loss=0.016204132931306958
Online_Training [272/700]: mean_loss=0.01994450413621962
Online_Training [273/700]: mean_loss=0.03138659452088177
Online_Training [274/700]: mean_loss=0.015970764914527535
Online_Training [275/700]: mean_loss=0.00820288440445438
Online_Training [276/700]: mean_loss=0.012070325086824596
Online_Training [277/700]: mean_loss=0.0111852684058249
Online_Training [278/700]: mean_loss=0.013538955594412982
Online_Training [279/700]: mean_loss=0.04157171305269003
Online_Training [280/700]: mean_loss=0.004137630690820515
Online_Training [281/700]: mean_loss=0.014895488624460995
Online_Training [282/700]: mean_loss=0.027879004832357168
Online_Training [283/700]: mean_loss=0.02475415146909654
Online_Training [284/700]: mean_loss=0.01297416933812201
Online_Training [285/700]: mean_loss=0.013567311922088265
Online_Training [286/700]: mean_loss=0.012149342685006559
Online_Training [287/700]: mean_loss=0.009152005543000996
Online_Training [288/700]: mean_loss=0.03959769196808338
Online_Training [289/700]: mean_loss=0.014207438100129366
Online_Training [290/700]: mean_loss=0.029907986288890243
Online_Training [291/700]: mean_loss=0.023180139949545264
Online_Training [292/700]: mean_loss=0.006792851781938225
Online_Training [293/700]: mean_loss=0.034792948979884386
Online_Training [294/700]: mean_loss=0.01155025593470782
Online_Training [295/700]: mean_loss=0.009788814466446638
Online_Training [296/700]: mean_loss=0.03767561144195497
Online_Training [297/700]: mean_loss=0.022955052321776748
Online_Training [298/700]: mean_loss=0.02024720166809857
Online_Training [299/700]: mean_loss=0.05558037664741278
Online_Training [300/700]: mean_loss=0.01246976328548044
Online_Training [301/700]: mean_loss=0.014948331285268068
Online_Training [302/700]: mean_loss=0.008918218198232353
Online_Training [303/700]: mean_loss=0.026434869039803743
Online_Training [304/700]: mean_loss=0.050297228153795004
Online_Training [305/700]: mean_loss=0.007318326621316373
Online_Training [306/700]: mean_loss=0.042188302148133516
Online_Training [307/700]: mean_loss=0.019035191275179386
Online_Training [308/700]: mean_loss=0.01977934571914375
Online_Training [309/700]: mean_loss=0.014085768023505807
Online_Training [310/700]: mean_loss=0.020698134787380695
Online_Training [311/700]: mean_loss=0.010360237676650286
Online_Training [312/700]: mean_loss=0.027005459181964397
Online_Training [313/700]: mean_loss=0.016353708924725652
Online_Training [314/700]: mean_loss=0.01799837709404528
Online_Training [315/700]: mean_loss=0.01842405996285379
Online_Training [316/700]: mean_loss=0.027449674205854535
Online_Training [317/700]: mean_loss=0.015238958527334034
Online_Training [318/700]: mean_loss=0.016928049619309604
Online_Training [319/700]: mean_loss=0.00619089521933347
Online_Training [320/700]: mean_loss=0.03234993852674961
Online_Training [321/700]: mean_loss=0.03210272965952754
Online_Training [322/700]: mean_loss=0.06441217614337802
Online_Training [323/700]: mean_loss=0.11363859847187996
Online_Training [324/700]: mean_loss=0.07268906012177467
Online_Training [325/700]: mean_loss=0.08768886141479015
Online_Training [326/700]: mean_loss=0.030562302796170115
Online_Training [327/700]: mean_loss=0.024700944311916828
Online_Training [328/700]: mean_loss=0.015495598781853914
Online_Training [329/700]: mean_loss=0.010958772152662277
Online_Training [330/700]: mean_loss=0.019752701744437218
Online_Training [331/700]: mean_loss=0.13790469337254763
Online_Training [332/700]: mean_loss=0.38955033197999
Online_Training [333/700]: mean_loss=0.03258294751867652
Online_Training [334/700]: mean_loss=0.030596760800108314
Online_Training [335/700]: mean_loss=0.028197314124554396
Online_Training [336/700]: mean_loss=0.01372234954033047
Online_Training [337/700]: mean_loss=0.05301760183647275
Online_Training [338/700]: mean_loss=0.08059264067560434
Online_Training [339/700]: mean_loss=0.025232782820239663
Online_Training [340/700]: mean_loss=0.017153880326077342
Online_Training [341/700]: mean_loss=0.022716087521985173
Online_Training [342/700]: mean_loss=0.018313111504539847
Online_Training [343/700]: mean_loss=0.031208457425236702
Online_Training [344/700]: mean_loss=0.012421472230926156
Online_Training [345/700]: mean_loss=0.03537328587844968
Online_Training [346/700]: mean_loss=0.020572557812556624
Online_Training [347/700]: mean_loss=0.013756083440966904
Online_Training [348/700]: mean_loss=0.010841106530278921
Online_Training [349/700]: mean_loss=0.07870233990252018
Online_Training [350/700]: mean_loss=0.08362779952585697
Online_Training [351/700]: mean_loss=0.0205152768176049
Online_Training [352/700]: mean_loss=0.03911979030817747
Online_Training [353/700]: mean_loss=0.07321059796959162
Online_Training [354/700]: mean_loss=0.0385497163515538
Online_Training [355/700]: mean_loss=0.007527784735430032
Online_Training [356/700]: mean_loss=0.038510806392878294
Online_Training [357/700]: mean_loss=0.026993588777258992
Online_Training [358/700]: mean_loss=0.020148445386439562
Online_Training [359/700]: mean_loss=0.015462283394299448
Online_Training [360/700]: mean_loss=0.018059901660308242
Online_Training [361/700]: mean_loss=0.020978796761482954
Online_Training [362/700]: mean_loss=0.008947600494138896
Online_Training [363/700]: mean_loss=0.01234376011416316
Online_Training [364/700]: mean_loss=0.029229859123006463
Online_Training [365/700]: mean_loss=0.021713266614824533
Online_Training [366/700]: mean_loss=0.012007211102172732
Online_Training [367/700]: mean_loss=0.017451988765969872
Online_Training [368/700]: mean_loss=0.027851358521729708
Online_Training [369/700]: mean_loss=0.010642169625498354
Online_Training [370/700]: mean_loss=0.012472823727875948
Online_Training [371/700]: mean_loss=0.057116986718028784
Online_Training [372/700]: mean_loss=0.014204674400389194
Online_Training [373/700]: mean_loss=0.03531038062646985
Online_Training [374/700]: mean_loss=0.009737974382005632
Online_Training [375/700]: mean_loss=0.019542667316272855
Online_Training [376/700]: mean_loss=0.03670321637764573
Online_Training [377/700]: mean_loss=0.016376782790757716
Online_Training [378/700]: mean_loss=0.014073125319555402
Online_Training [379/700]: mean_loss=0.013515912927687168
Online_Training [380/700]: mean_loss=0.017532934434711933
Online_Training [381/700]: mean_loss=0.01811589184217155
Online_Training [382/700]: mean_loss=0.009848942514508963
Online_Training [383/700]: mean_loss=0.008685064443852752
Online_Training [384/700]: mean_loss=0.029838972492143512
Online_Training [385/700]: mean_loss=0.009096065477933735
Online_Training [386/700]: mean_loss=0.02977802837267518
Online_Training [387/700]: mean_loss=0.020843417150899768
Online_Training [388/700]: mean_loss=0.012458549346774817
Online_Training [389/700]: mean_loss=0.02099722810089588
Online_Training [390/700]: mean_loss=0.018608909798786044
Online_Training [391/700]: mean_loss=0.018291068030521274
Online_Training [392/700]: mean_loss=0.007747955503873527
Online_Training [393/700]: mean_loss=0.01654734357725829
Online_Training [394/700]: mean_loss=0.0201631726231426
Online_Training [395/700]: mean_loss=0.008652555174194276
Online_Training [396/700]: mean_loss=0.024360952666029334
Online_Training [397/700]: mean_loss=0.035900385584682226
Online_Training [398/700]: mean_loss=0.00959240720840171
Online_Training [399/700]: mean_loss=0.012320933863520622
Online_Training [400/700]: mean_loss=0.03927354235202074
Online_Training [401/700]: mean_loss=0.01087834284408018
Online_Training [402/700]: mean_loss=0.028521714499220252
Online_Training [403/700]: mean_loss=0.016882948693819344
Online_Training [404/700]: mean_loss=0.00946868775645271
Online_Training [405/700]: mean_loss=0.04856136627495289
Online_Training [406/700]: mean_loss=0.012717189500108361
Online_Training [407/700]: mean_loss=0.009648918639868498
Online_Training [408/700]: mean_loss=0.014073845697566867
Online_Training [409/700]: mean_loss=0.021902425680309534
Online_Training [410/700]: mean_loss=0.022921900497749448
Online_Training [411/700]: mean_loss=0.021392067661508918
Online_Training [412/700]: mean_loss=0.014781301841139793
Online_Training [413/700]: mean_loss=0.018777235643938184
Online_Training [414/700]: mean_loss=0.008161252655554563
Online_Training [415/700]: mean_loss=0.0145777128636837
Online_Training [416/700]: mean_loss=0.004030459531350061
Online_Training [417/700]: mean_loss=0.008910664007999003
Online_Training [418/700]: mean_loss=0.007958003785461187
Online_Training [419/700]: mean_loss=0.009186215698719025
Online_Training [420/700]: mean_loss=0.018588788574561477
Online_Training [421/700]: mean_loss=0.009527428774163127
Online_Training [422/700]: mean_loss=0.005845870357006788
Online_Training [423/700]: mean_loss=0.003524699015542865
Online_Training [424/700]: mean_loss=0.014043467584997416
Online_Training [425/700]: mean_loss=0.013114952365867794
Online_Training [426/700]: mean_loss=0.02382486150600016
Online_Training [427/700]: mean_loss=0.003473823395324871
Online_Training [428/700]: mean_loss=0.01073938817717135
Online_Training [429/700]: mean_loss=0.02448265184648335
Online_Training [430/700]: mean_loss=0.02727262256667018
Online_Training [431/700]: mean_loss=0.0228186899330467
Online_Training [432/700]: mean_loss=0.020556232193484902
Online_Training [433/700]: mean_loss=0.02478369791060686
Online_Training [434/700]: mean_loss=0.008869243552908301
Online_Training [435/700]: mean_loss=0.01643239101395011
Online_Training [436/700]: mean_loss=0.014143183245323598
Online_Training [437/700]: mean_loss=0.004172768822172657
Online_Training [438/700]: mean_loss=0.017205182695761323
Online_Training [439/700]: mean_loss=0.012907866737805307
Online_Training [440/700]: mean_loss=0.015614563948474824
Online_Training [441/700]: mean_loss=0.02172975172288716
Online_Training [442/700]: mean_loss=0.045660508796572685
Online_Training [443/700]: mean_loss=0.023112273076549172
Online_Training [444/700]: mean_loss=0.012907405965961516
Online_Training [445/700]: mean_loss=0.013611330999992788
Online_Training [446/700]: mean_loss=0.027649272000417113
Online_Training [447/700]: mean_loss=0.009651892469264567
Online_Training [448/700]: mean_loss=0.09654185641556978
Online_Training [449/700]: mean_loss=0.16655930317938328
Online_Training [450/700]: mean_loss=0.019016366684809327
Online_Training [451/700]: mean_loss=0.02144997613504529
Online_Training [452/700]: mean_loss=0.017072996124625206
Online_Training [453/700]: mean_loss=0.05071739526465535
Online_Training [454/700]: mean_loss=0.008284195442683995
Online_Training [455/700]: mean_loss=0.02243750006891787
Online_Training [456/700]: mean_loss=0.037390494253486395
Online_Training [457/700]: mean_loss=0.008705171756446362
Online_Training [458/700]: mean_loss=0.013150238548405468
Online_Training [459/700]: mean_loss=0.0167073787888512
Online_Training [460/700]: mean_loss=0.013294601230882108
Online_Training [461/700]: mean_loss=0.02393724862486124
Online_Training [462/700]: mean_loss=0.014896580250933766
Online_Training [463/700]: mean_loss=0.008974927826784551
Online_Training [464/700]: mean_loss=0.01747534121386707
Online_Training [465/700]: mean_loss=0.010880100540816784
Online_Training [466/700]: mean_loss=0.016373293823562562
Online_Training [467/700]: mean_loss=0.038145944476127625
Online_Training [468/700]: mean_loss=0.021135956281796098
Online_Training [469/700]: mean_loss=0.018815331859514117
Online_Training [470/700]: mean_loss=0.016527889878489077
Online_Training [471/700]: mean_loss=0.011882202816195786
Online_Training [472/700]: mean_loss=0.026251930510625243
Online_Training [473/700]: mean_loss=0.009605423780158162
Online_Training [474/700]: mean_loss=0.005927471735049039
Online_Training [475/700]: mean_loss=0.008906995644792914
Online_Training [476/700]: mean_loss=0.005899840500205755
Online_Training [477/700]: mean_loss=0.02039275737479329
Online_Training [478/700]: mean_loss=0.00658112223027274
Online_Training [479/700]: mean_loss=0.0012981870531802997
Online_Training [480/700]: mean_loss=0.0076752001186832786
Online_Training [481/700]: mean_loss=0.008506419544573873
Online_Training [482/700]: mean_loss=0.008790414780378342
Online_Training [483/700]: mean_loss=0.09268782008439302
Online_Training [484/700]: mean_loss=0.07997811492532492
Online_Training [485/700]: mean_loss=0.07873645517975092
Online_Training [486/700]: mean_loss=0.009985667013097554
Online_Training [487/700]: mean_loss=0.020789888687431812
Online_Training [488/700]: mean_loss=0.009076008689589798
Online_Training [489/700]: mean_loss=0.014898243942297995
Online_Training [490/700]: mean_loss=0.07555713038891554
Online_Training [491/700]: mean_loss=0.010769900982268155
Online_Training [492/700]: mean_loss=0.03019026294350624
Online_Training [493/700]: mean_loss=0.015103183221071959
Online_Training [494/700]: mean_loss=0.03607361810281873
Online_Training [495/700]: mean_loss=0.034097872441634536
Online_Training [496/700]: mean_loss=0.02106272685341537
Online_Training [497/700]: mean_loss=0.010593727231025696
Online_Training [498/700]: mean_loss=0.009496657410636544
Online_Training [499/700]: mean_loss=0.005360423820093274
Online_Training [500/700]: mean_loss=0.028923355042934418
Online_Training [501/700]: mean_loss=0.019068543566390872
Online_Training [502/700]: mean_loss=0.00580705504398793
Online_Training [503/700]: mean_loss=0.029867661651223898
Online_Training [504/700]: mean_loss=0.016397072467952967
Online_Training [505/700]: mean_loss=0.11450293380767107
Online_Training [506/700]: mean_loss=0.10998726356774569
Online_Training [507/700]: mean_loss=0.010765148559585214
Online_Training [508/700]: mean_loss=0.02724695880897343
Online_Training [509/700]: mean_loss=0.013617456541396677
Online_Training [510/700]: mean_loss=0.08772335946559906
Online_Training [511/700]: mean_loss=0.011761421454139054
Online_Training [512/700]: mean_loss=0.02010166784748435
Online_Training [513/700]: mean_loss=0.023615405312739313
Online_Training [514/700]: mean_loss=0.004787383921211585
Online_Training [515/700]: mean_loss=0.011839641025289893
Online_Training [516/700]: mean_loss=0.005319240735843778
Online_Training [517/700]: mean_loss=0.01240302191581577
Online_Training [518/700]: mean_loss=0.013437051908113062
Online_Training [519/700]: mean_loss=0.028812909964472055
Online_Training [520/700]: mean_loss=0.03198541165329516
Online_Training [521/700]: mean_loss=0.017399111529812217
Online_Training [522/700]: mean_loss=0.024100772570818663
Online_Training [523/700]: mean_loss=0.01684796647168696
Online_Training [524/700]: mean_loss=0.01587092864792794
Online_Training [525/700]: mean_loss=0.02072337339632213
Online_Training [526/700]: mean_loss=0.01318968494888395
Online_Training [527/700]: mean_loss=0.0236314560752362
Online_Training [528/700]: mean_loss=0.05569302150979638
Online_Training [529/700]: mean_loss=0.022884723031893373
Online_Training [530/700]: mean_loss=0.008238833397626877
Online_Training [531/700]: mean_loss=0.015674389083869755
Online_Training [532/700]: mean_loss=0.02077855309471488
Online_Training [533/700]: mean_loss=0.022533290786668658
Online_Training [534/700]: mean_loss=0.02706071105785668
Online_Training [535/700]: mean_loss=0.026715528452768922
Online_Training [536/700]: mean_loss=0.0166306693572551
Online_Training [537/700]: mean_loss=0.015068572480231524
Online_Training [538/700]: mean_loss=0.023616382386535406
Online_Training [539/700]: mean_loss=0.01627409749198705
Online_Training [540/700]: mean_loss=0.022715826286002994
Online_Training [541/700]: mean_loss=0.008412772440351546
Online_Training [542/700]: mean_loss=0.017724782577715814
Online_Training [543/700]: mean_loss=0.03606038633733988
Online_Training [544/700]: mean_loss=0.012012082384899259
Online_Training [545/700]: mean_loss=0.02362176892347634
Online_Training [546/700]: mean_loss=0.02016050391830504
Online_Training [547/700]: mean_loss=0.010999605292454362
Online_Training [548/700]: mean_loss=0.013039234559983015
Online_Training [549/700]: mean_loss=0.0471720676869154
Online_Training [550/700]: mean_loss=0.017472123610787094
Online_Training [551/700]: mean_loss=0.027428907458670437
Online_Training [552/700]: mean_loss=0.020336511312052608
Online_Training [553/700]: mean_loss=0.038307090289890766
Online_Training [554/700]: mean_loss=0.0312776614446193
Online_Training [555/700]: mean_loss=0.00894416612572968
Online_Training [556/700]: mean_loss=0.01884539914317429
Online_Training [557/700]: mean_loss=0.015903359395451844
Online_Training [558/700]: mean_loss=0.022128790384158492
Online_Training [559/700]: mean_loss=0.007342225115280598
Online_Training [560/700]: mean_loss=0.017626393120735884
Online_Training [561/700]: mean_loss=0.018617359455674887
Online_Training [562/700]: mean_loss=0.003871440887451172
Online_Training [563/700]: mean_loss=0.009600313263945282
Online_Training [564/700]: mean_loss=0.021052854834124446
Online_Training [565/700]: mean_loss=0.014404734363779426
Online_Training [566/700]: mean_loss=0.016351587371900678
Online_Training [567/700]: mean_loss=0.012548127793706954
Online_Training [568/700]: mean_loss=0.02886784542351961
Online_Training [569/700]: mean_loss=0.034800448920577765
Online_Training [570/700]: mean_loss=0.016421477776020765
Online_Training [571/700]: mean_loss=0.012213458539918065
Online_Training [572/700]: mean_loss=0.038382337894290686
Online_Training [573/700]: mean_loss=0.020277628675103188
Online_Training [574/700]: mean_loss=0.013499250169843435
Online_Training [575/700]: mean_loss=0.02519680792465806
Online_Training [576/700]: mean_loss=0.017706954386085272
Online_Training [577/700]: mean_loss=0.009908089879900217
Online_Training [578/700]: mean_loss=0.013460368616506457
Online_Training [579/700]: mean_loss=0.008809812716208398
Online_Training [580/700]: mean_loss=0.02033382491208613
Online_Training [581/700]: mean_loss=0.003418657521251589
Online_Training [582/700]: mean_loss=0.007423763279803097
Online_Training [583/700]: mean_loss=0.010299864923581481
Online_Training [584/700]: mean_loss=0.008375042874831706
Online_Training [585/700]: mean_loss=0.039352087303996086
Online_Training [586/700]: mean_loss=0.019285049522295594
Online_Training [587/700]: mean_loss=0.02082030731253326
Online_Training [588/700]: mean_loss=0.02526117698289454
Online_Training [589/700]: mean_loss=0.008305707247927785
Online_Training [590/700]: mean_loss=0.015331384260207415
Online_Training [591/700]: mean_loss=0.009586448082700372
Online_Training [592/700]: mean_loss=0.010569743812084198
Online_Training [593/700]: mean_loss=0.024178690742701292
Online_Training [594/700]: mean_loss=0.01366467704065144
Online_Training [595/700]: mean_loss=0.012227960396558046
Online_Training [596/700]: mean_loss=0.00698843935970217
Online_Training [597/700]: mean_loss=0.009034834220074117
Online_Training [598/700]: mean_loss=0.013129315339028835
Online_Training [599/700]: mean_loss=0.010205135447904468
Online_Training [600/700]: mean_loss=0.03336377814412117
Online_Training [601/700]: mean_loss=0.052241741213947535
Online_Training [602/700]: mean_loss=0.00933927611913532
Online_Training [603/700]: mean_loss=0.007170249882619828
Online_Training [604/700]: mean_loss=0.015072423848323524
Online_Training [605/700]: mean_loss=0.00903755408944562
Online_Training [606/700]: mean_loss=0.01899926597252488
Online_Training [607/700]: mean_loss=0.014218653785064816
Online_Training [608/700]: mean_loss=0.007580061792396009
Online_Training [609/700]: mean_loss=0.014981595100834966
Online_Training [610/700]: mean_loss=0.03048905683681369
Online_Training [611/700]: mean_loss=0.020451170159503818
Online_Training [612/700]: mean_loss=0.03188792825676501
Online_Training [613/700]: mean_loss=0.010960512794554234
Online_Training [614/700]: mean_loss=0.02660750993527472
Online_Training [615/700]: mean_loss=0.012768608750775456
Online_Training [616/700]: mean_loss=0.025424693012610078
Online_Training [617/700]: mean_loss=0.01722576469182968
Online_Training [618/700]: mean_loss=0.008874129853211343
Online_Training [619/700]: mean_loss=0.007202773995231837
Online_Training [620/700]: mean_loss=0.008505419711582363
Online_Training [621/700]: mean_loss=0.018447158858180046
Online_Training [622/700]: mean_loss=0.014027163619175553
Online_Training [623/700]: mean_loss=0.021390951704233885
Online_Training [624/700]: mean_loss=0.02320242184214294
Online_Training [625/700]: mean_loss=0.009440672467462718
Online_Training [626/700]: mean_loss=0.0266211093403399
Online_Training [627/700]: mean_loss=0.030809976859018207
Online_Training [628/700]: mean_loss=0.014059476437978446
Online_Training [629/700]: mean_loss=0.03747783089056611
Online_Training [630/700]: mean_loss=0.00559289485681802
Online_Training [631/700]: mean_loss=0.015554310521110892
Online_Training [632/700]: mean_loss=0.01822214713320136
Online_Training [633/700]: mean_loss=0.014186498941853642
Online_Training [634/700]: mean_loss=0.007503138855099678
Online_Training [635/700]: mean_loss=0.008376180427148938
Online_Training [636/700]: mean_loss=0.021708554588258266
Online_Training [637/700]: mean_loss=0.01446522248443216
Online_Training [638/700]: mean_loss=0.020704675931483507
Online_Training [639/700]: mean_loss=0.01616660424042493
Online_Training [640/700]: mean_loss=0.01816198485903442
Online_Training [641/700]: mean_loss=0.02349457424134016
Online_Training [642/700]: mean_loss=0.02489248802885413
Online_Training [643/700]: mean_loss=0.011272909818217158
Online_Training [644/700]: mean_loss=0.0045291827991604805
Online_Training [645/700]: mean_loss=0.018041619332507253
Online_Training [646/700]: mean_loss=0.030629342421889305
Online_Training [647/700]: mean_loss=0.05878150649368763
Online_Training [648/700]: mean_loss=0.011530774063430727
Online_Training [649/700]: mean_loss=0.02418592176400125
Online_Training [650/700]: mean_loss=0.04272538935765624
Online_Training [651/700]: mean_loss=0.013044016086496413
Online_Training [652/700]: mean_loss=0.015757264103740454
Online_Training [653/700]: mean_loss=0.0113488903734833
Online_Training [654/700]: mean_loss=0.016447547706775367
Online_Training [655/700]: mean_loss=0.026726424926891923
Online_Training [656/700]: mean_loss=0.010182148194871843
Online_Training [657/700]: mean_loss=0.05947649199515581
Online_Training [658/700]: mean_loss=0.03821559436619282
Online_Training [659/700]: mean_loss=0.016659802524372935
Online_Training [660/700]: mean_loss=0.031487243017181754
Online_Training [661/700]: mean_loss=0.03442147630266845
Online_Training [662/700]: mean_loss=0.01742609473876655
Online_Training [663/700]: mean_loss=0.03982759825885296
Online_Training [664/700]: mean_loss=0.03272522031329572
Online_Training [665/700]: mean_loss=0.010458073462359607
Online_Training [666/700]: mean_loss=0.035265420097857714
Online_Training [667/700]: mean_loss=0.013342171558178961
Online_Training [668/700]: mean_loss=0.013254476827569306
Online_Training [669/700]: mean_loss=0.14620685204863548
Online_Training [670/700]: mean_loss=0.044206381775438786
Online_Training [671/700]: mean_loss=0.02924615005031228
Online_Training [672/700]: mean_loss=0.02782530151307583
Online_Training [673/700]: mean_loss=0.027635337552055717
Online_Training [674/700]: mean_loss=0.016252417699433863
Online_Training [675/700]: mean_loss=0.012452141963876784
Online_Training [676/700]: mean_loss=0.02462469320744276
Online_Training [677/700]: mean_loss=0.004220757982693613
Online_Training [678/700]: mean_loss=0.00898762879660353
Online_Training [679/700]: mean_loss=0.007372592575848103
Online_Training [680/700]: mean_loss=0.018739240244030952
Online_Training [681/700]: mean_loss=0.012661399901844561
Online_Training [682/700]: mean_loss=0.09779640939086676
Online_Training [683/700]: mean_loss=0.012282816227525473
Online_Training [684/700]: mean_loss=0.010487660765647888
Online_Training [685/700]: mean_loss=0.011230866657570004
Online_Training [686/700]: mean_loss=0.008250459737610072
Online_Training [687/700]: mean_loss=0.047640595119446516
Online_Training [688/700]: mean_loss=0.03294114861637354
Online_Training [689/700]: mean_loss=0.009576248470693827
Online_Training [690/700]: mean_loss=0.015929514192976058
Online_Training [691/700]: mean_loss=0.007147830969188362
Online_Training [692/700]: mean_loss=0.01317716168705374
Online_Training [693/700]: mean_loss=0.01912451337557286
Online_Training [694/700]: mean_loss=0.0076117232092656195
Online_Training [695/700]: mean_loss=0.02614926639944315
Online_Training [696/700]: mean_loss=0.007963460928294808
Online_Training [697/700]: mean_loss=0.023279099259525537
Online_Training [698/700]: mean_loss=0.02313298638910055
Online_Training [699/700]: mean_loss=0.011112838052213192
Online_Training [700/700]: mean_loss=0.015485072042793036
Q_Learning [1/300]: mean_loss=0.11833757348358631
Q_Learning [2/300]: mean_loss=0.14686627499759197
Q_Learning [3/300]: mean_loss=0.2839951664209366
Q_Learning [4/300]: mean_loss=0.12085453141480684
Q_Learning [5/300]: mean_loss=0.12830413412302732
Q_Learning [6/300]: mean_loss=0.11589607782661915
Q_Learning [7/300]: mean_loss=0.03346663201227784
Q_Learning [8/300]: mean_loss=0.09644392039626837
Q_Learning [9/300]: mean_loss=0.13675272651016712
Q_Learning [10/300]: mean_loss=0.07645421288907528
Q_Learning [11/300]: mean_loss=0.0658262437209487
Q_Learning [12/300]: mean_loss=0.03584970720112324
Q_Learning [13/300]: mean_loss=0.07911655679345131
Q_Learning [14/300]: mean_loss=0.15449640713632107
Q_Learning [15/300]: mean_loss=0.09301715716719627
Q_Learning [16/300]: mean_loss=0.056949679274111986
Q_Learning [17/300]: mean_loss=0.06932222936302423
Q_Learning [18/300]: mean_loss=0.15015309490263462
Q_Learning [19/300]: mean_loss=0.048410821706056595
Q_Learning [20/300]: mean_loss=0.12005084753036499
Q_Learning [21/300]: mean_loss=0.04161732969805598
Q_Learning [22/300]: mean_loss=0.06161195831373334
Q_Learning [23/300]: mean_loss=0.06629588920623064
Q_Learning [24/300]: mean_loss=0.12816834170371294
Q_Learning [25/300]: mean_loss=0.05572895100340247
Q_Learning [26/300]: mean_loss=0.10081421304494143
Q_Learning [27/300]: mean_loss=0.1455188561230898
Q_Learning [28/300]: mean_loss=0.060375196393579245
Q_Learning [29/300]: mean_loss=0.0916881849989295
Q_Learning [30/300]: mean_loss=0.0864740926772356
Q_Learning [31/300]: mean_loss=0.14247368462383747
Q_Learning [32/300]: mean_loss=0.0548551706597209
Q_Learning [33/300]: mean_loss=0.06471700128167868
Q_Learning [34/300]: mean_loss=0.07106719072908163
Q_Learning [35/300]: mean_loss=0.10414784587919712
Q_Learning [36/300]: mean_loss=0.0808654734864831
Q_Learning [37/300]: mean_loss=0.14637033827602863
Q_Learning [38/300]: mean_loss=0.1609783098101616
Q_Learning [39/300]: mean_loss=0.0724229346960783
Q_Learning [40/300]: mean_loss=0.04442815762013197
Q_Learning [41/300]: mean_loss=0.0908120246604085
Q_Learning [42/300]: mean_loss=0.06060068216174841
Q_Learning [43/300]: mean_loss=0.07926925830543041
Q_Learning [44/300]: mean_loss=0.03423850145190954
Q_Learning [45/300]: mean_loss=0.05415165098384023
Q_Learning [46/300]: mean_loss=0.11688414495438337
Q_Learning [47/300]: mean_loss=0.04994121519848704
Q_Learning [48/300]: mean_loss=0.03540866635739803
Q_Learning [49/300]: mean_loss=0.022630562540143728
Q_Learning [50/300]: mean_loss=0.05506811384111643
Q_Learning [51/300]: mean_loss=0.08385677449405193
Q_Learning [52/300]: mean_loss=0.02310711075551808
Q_Learning [53/300]: mean_loss=0.042036109836772084
Q_Learning [54/300]: mean_loss=0.023362195817753673
Q_Learning [55/300]: mean_loss=0.04167443560436368
Q_Learning [56/300]: mean_loss=0.042488574516028166
Q_Learning [57/300]: mean_loss=0.03485584072768688
Q_Learning [58/300]: mean_loss=0.03973211068660021
Q_Learning [59/300]: mean_loss=0.02093339222483337
Q_Learning [60/300]: mean_loss=0.03425547783263028
Q_Learning [61/300]: mean_loss=0.04423254542052746
Q_Learning [62/300]: mean_loss=0.09591320063918829
Q_Learning [63/300]: mean_loss=0.058668948244303465
Q_Learning [64/300]: mean_loss=0.038223061710596085
Q_Learning [65/300]: mean_loss=0.02895591501146555
Q_Learning [66/300]: mean_loss=0.030250974697992206
Q_Learning [67/300]: mean_loss=0.057545917108654976
Q_Learning [68/300]: mean_loss=0.05025102850049734
Q_Learning [69/300]: mean_loss=0.0596201429143548
Q_Learning [70/300]: mean_loss=0.02915718569420278
Q_Learning [71/300]: mean_loss=0.01637231616768986
Q_Learning [72/300]: mean_loss=0.04188032145611942
Q_Learning [73/300]: mean_loss=0.03319992916658521
Q_Learning [74/300]: mean_loss=0.047920614713802934
Q_Learning [75/300]: mean_loss=0.015846610418520868
Q_Learning [76/300]: mean_loss=0.052962356712669134
Q_Learning [77/300]: mean_loss=0.027041157707571983
Q_Learning [78/300]: mean_loss=0.06310840277001262
Q_Learning [79/300]: mean_loss=0.0959320031106472
Q_Learning [80/300]: mean_loss=0.0716081066057086
Q_Learning [81/300]: mean_loss=0.013924229773692787
Q_Learning [82/300]: mean_loss=0.04543600603938103
Q_Learning [83/300]: mean_loss=0.028191451681777835
Q_Learning [84/300]: mean_loss=0.01817951293196529
Q_Learning [85/300]: mean_loss=0.051300978753715754
Q_Learning [86/300]: mean_loss=0.024037661962211132
Q_Learning [87/300]: mean_loss=0.09448983427137136
Q_Learning [88/300]: mean_loss=0.020001069409772754
Q_Learning [89/300]: mean_loss=0.01366895972751081
Q_Learning [90/300]: mean_loss=0.06131504522636533
Q_Learning [91/300]: mean_loss=0.01565557753201574
Q_Learning [92/300]: mean_loss=0.010843987111002207
Q_Learning [93/300]: mean_loss=0.052392181009054184
Q_Learning [94/300]: mean_loss=0.016027816920541227
Q_Learning [95/300]: mean_loss=0.014265284582506865
Q_Learning [96/300]: mean_loss=0.05124867241829634
Q_Learning [97/300]: mean_loss=0.025472022825852036
Q_Learning [98/300]: mean_loss=0.007762168301269412
Q_Learning [99/300]: mean_loss=0.1325907800346613
Q_Learning [100/300]: mean_loss=0.05155057040974498
Q_Learning [101/300]: mean_loss=0.018779716454446316
Q_Learning [102/300]: mean_loss=0.0127606246387586
Q_Learning [103/300]: mean_loss=0.02323449682444334
Q_Learning [104/300]: mean_loss=0.018797444296069443
Q_Learning [105/300]: mean_loss=0.015101790893822908
Q_Learning [106/300]: mean_loss=0.018372491118498147
Q_Learning [107/300]: mean_loss=0.005565203202422708
Q_Learning [108/300]: mean_loss=0.01913235941901803
Q_Learning [109/300]: mean_loss=0.006344871944747865
Q_Learning [110/300]: mean_loss=0.04581941571086645
Q_Learning [111/300]: mean_loss=0.026500406442210078
Q_Learning [112/300]: mean_loss=0.0074456409201957285
Q_Learning [113/300]: mean_loss=0.015964273363351822
Q_Learning [114/300]: mean_loss=0.01960585988126695
Q_Learning [115/300]: mean_loss=0.03174728457815945
Q_Learning [116/300]: mean_loss=0.019143502693623304
Q_Learning [117/300]: mean_loss=0.02375494549050927
Q_Learning [118/300]: mean_loss=0.024529391201213002
Q_Learning [119/300]: mean_loss=0.14779485762119293
Q_Learning [120/300]: mean_loss=0.12917264830321074
Q_Learning [121/300]: mean_loss=0.0815835827961564
Q_Learning [122/300]: mean_loss=0.12008627504110336
Q_Learning [123/300]: mean_loss=0.045318837743252516
Q_Learning [124/300]: mean_loss=0.040247174911201
Q_Learning [125/300]: mean_loss=0.03892332594841719
Q_Learning [126/300]: mean_loss=0.012025093426927924
Q_Learning [127/300]: mean_loss=0.04755612509325147
Q_Learning [128/300]: mean_loss=0.03337321546860039
Q_Learning [129/300]: mean_loss=0.08603266812860966
Q_Learning [130/300]: mean_loss=0.01841048547066748
Q_Learning [131/300]: mean_loss=0.10996352136135101
Q_Learning [132/300]: mean_loss=0.012982922955416143
Q_Learning [133/300]: mean_loss=0.012260042480193079
Q_Learning [134/300]: mean_loss=0.01111556647811085
Q_Learning [135/300]: mean_loss=0.024182470981031656
Q_Learning [136/300]: mean_loss=0.006570954981725663
Q_Learning [137/300]: mean_loss=0.022081474075093865
Q_Learning [138/300]: mean_loss=0.029062151443213224
Q_Learning [139/300]: mean_loss=0.006596217164769769
Q_Learning [140/300]: mean_loss=0.013973452500067651
Q_Learning [141/300]: mean_loss=0.011712356354109943
Q_Learning [142/300]: mean_loss=0.028847816865891218
Q_Learning [143/300]: mean_loss=0.0642983797006309
Q_Learning [144/300]: mean_loss=0.034536863677203655
Q_Learning [145/300]: mean_loss=0.036567306611686945
Q_Learning [146/300]: mean_loss=0.04849298531189561
Q_Learning [147/300]: mean_loss=0.030163061572238803
Q_Learning [148/300]: mean_loss=0.00853224185993895
Q_Learning [149/300]: mean_loss=0.035219458397477865
Q_Learning [150/300]: mean_loss=0.020152648212388158
Q_Learning [151/300]: mean_loss=0.023001844179816544
Q_Learning [152/300]: mean_loss=0.011666352627798915
Q_Learning [153/300]: mean_loss=0.016850116895511746
Q_Learning [154/300]: mean_loss=0.07726708147674799
Q_Learning [155/300]: mean_loss=0.015048854053020477
Q_Learning [156/300]: mean_loss=0.04265586752444506
Q_Learning [157/300]: mean_loss=0.04483219003304839
Q_Learning [158/300]: mean_loss=0.02014941372908652
Q_Learning [159/300]: mean_loss=0.006225998920854181
Q_Learning [160/300]: mean_loss=0.01594880549237132
Q_Learning [161/300]: mean_loss=0.03349303500726819
Q_Learning [162/300]: mean_loss=0.020385626587085426
Q_Learning [163/300]: mean_loss=0.020919034956023097
Q_Learning [164/300]: mean_loss=0.014279618626460433
Q_Learning [165/300]: mean_loss=0.014869207749143243
Q_Learning [166/300]: mean_loss=0.03492239722982049
Q_Learning [167/300]: mean_loss=0.027819426031783223
Q_Learning [168/300]: mean_loss=0.022707401076331735
Q_Learning [169/300]: mean_loss=0.015854449477046728
Q_Learning [170/300]: mean_loss=0.026429286459460855
Q_Learning [171/300]: mean_loss=0.009364369325339794
Q_Learning [172/300]: mean_loss=0.008624134992714971
Q_Learning [173/300]: mean_loss=0.0064976580324582756
Q_Learning [174/300]: mean_loss=0.01449033699464053
Q_Learning [175/300]: mean_loss=0.009578022989444435
Q_Learning [176/300]: mean_loss=0.018013265915215015
Q_Learning [177/300]: mean_loss=0.03584321867674589
Q_Learning [178/300]: mean_loss=0.022659544367343187
Q_Learning [179/300]: mean_loss=0.03809833968989551
Q_Learning [180/300]: mean_loss=0.015051803435198963
Q_Learning [181/300]: mean_loss=0.018403702415525913
Q_Learning [182/300]: mean_loss=0.023353202966973186
Q_Learning [183/300]: mean_loss=0.011179437628015876
Q_Learning [184/300]: mean_loss=0.015297191101126373
Q_Learning [185/300]: mean_loss=0.020180869614705443
Q_Learning [186/300]: mean_loss=0.04681749688461423
Q_Learning [187/300]: mean_loss=0.014994804630987346
Q_Learning [188/300]: mean_loss=0.0665728971362114
Q_Learning [189/300]: mean_loss=0.030403820797801018
Q_Learning [190/300]: mean_loss=0.010451902518980205
Q_Learning [191/300]: mean_loss=0.024979000678285956
Q_Learning [192/300]: mean_loss=0.026197471423074603
Q_Learning [193/300]: mean_loss=0.03202742827124894
Q_Learning [194/300]: mean_loss=0.028463041642680764
Q_Learning [195/300]: mean_loss=0.029634463600814342
Q_Learning [196/300]: mean_loss=0.03414121153764427
Q_Learning [197/300]: mean_loss=0.020125962560996413
Q_Learning [198/300]: mean_loss=0.008127677137963474
Q_Learning [199/300]: mean_loss=0.013559322687797248
Q_Learning [200/300]: mean_loss=0.016548012499697506
Q_Learning [201/300]: mean_loss=0.004247569828294218
Q_Learning [202/300]: mean_loss=0.08434146270155907
Q_Learning [203/300]: mean_loss=0.07866699900478125
Q_Learning [204/300]: mean_loss=0.023857938824221492
Q_Learning [205/300]: mean_loss=0.026335532777011395
Q_Learning [206/300]: mean_loss=0.020971126155927777
Q_Learning [207/300]: mean_loss=0.018910194747149944
Q_Learning [208/300]: mean_loss=0.03353946725837886
Q_Learning [209/300]: mean_loss=0.04219098435714841
Q_Learning [210/300]: mean_loss=0.013182320864871144
Q_Learning [211/300]: mean_loss=0.04360766522586346
Q_Learning [212/300]: mean_loss=0.027817975729703903
Q_Learning [213/300]: mean_loss=0.012399894068948925
Q_Learning [214/300]: mean_loss=0.014655123581178486
Q_Learning [215/300]: mean_loss=0.0185877118492499
Q_Learning [216/300]: mean_loss=0.018464914755895734
Q_Learning [217/300]: mean_loss=0.010794085683301091
Q_Learning [218/300]: mean_loss=0.05402566818520427
Q_Learning [219/300]: mean_loss=0.015834808466024697
Q_Learning [220/300]: mean_loss=0.03913324559107423
Q_Learning [221/300]: mean_loss=0.0250350977294147
Q_Learning [222/300]: mean_loss=0.1765976920723915
Q_Learning [223/300]: mean_loss=0.029007792472839355
Q_Learning [224/300]: mean_loss=0.022488576592877507
Q_Learning [225/300]: mean_loss=0.018239396275021136
Q_Learning [226/300]: mean_loss=0.02174347499385476
Q_Learning [227/300]: mean_loss=0.023077521240338683
Q_Learning [228/300]: mean_loss=0.01729599852114916
Q_Learning [229/300]: mean_loss=0.014403028413653374
Q_Learning [230/300]: mean_loss=0.011912838905118406
Q_Learning [231/300]: mean_loss=0.014922298374585807
Q_Learning [232/300]: mean_loss=0.02227517426945269
Q_Learning [233/300]: mean_loss=0.039579924661666155
Q_Learning [234/300]: mean_loss=0.036752209067344666
Q_Learning [235/300]: mean_loss=0.012139930040575564
Q_Learning [236/300]: mean_loss=0.03868126543238759
Q_Learning [237/300]: mean_loss=0.018794572446495295
Q_Learning [238/300]: mean_loss=0.009503459965344518
Q_Learning [239/300]: mean_loss=0.04396201949566603
Q_Learning [240/300]: mean_loss=0.05289522372186184
Q_Learning [241/300]: mean_loss=0.02225790871307254
Q_Learning [242/300]: mean_loss=0.0283871041610837
Q_Learning [243/300]: mean_loss=0.01488963863812387
Q_Learning [244/300]: mean_loss=0.03794539766386151
Q_Learning [245/300]: mean_loss=0.01249763451050967
Q_Learning [246/300]: mean_loss=0.021009416552260518
Q_Learning [247/300]: mean_loss=0.02450241264887154
Q_Learning [248/300]: mean_loss=0.021537144435569644
Q_Learning [249/300]: mean_loss=0.009742358815856278
Q_Learning [250/300]: mean_loss=0.01650351332500577
Q_Learning [251/300]: mean_loss=0.014618572546169162
Q_Learning [252/300]: mean_loss=0.011182018788531423
Q_Learning [253/300]: mean_loss=0.01629937335383147
Q_Learning [254/300]: mean_loss=0.030578714096918702
Q_Learning [255/300]: mean_loss=0.018686300609260798
Q_Learning [256/300]: mean_loss=0.01479249750263989
Q_Learning [257/300]: mean_loss=0.0298897756729275
Q_Learning [258/300]: mean_loss=0.1338363727554679
Q_Learning [259/300]: mean_loss=0.14057581685483456
Q_Learning [260/300]: mean_loss=0.015999795985408127
Q_Learning [261/300]: mean_loss=0.007694871863350272
Q_Learning [262/300]: mean_loss=0.01584093808196485
Q_Learning [263/300]: mean_loss=0.014356453670188785
Q_Learning [264/300]: mean_loss=0.04030215926468372
Q_Learning [265/300]: mean_loss=0.025571034755557775
Q_Learning [266/300]: mean_loss=0.012766432017087936
Q_Learning [267/300]: mean_loss=0.014265374629758298
Q_Learning [268/300]: mean_loss=0.07175965886563063
Q_Learning [269/300]: mean_loss=0.012240845011547208
Q_Learning [270/300]: mean_loss=0.009150746569503099
Q_Learning [271/300]: mean_loss=0.016204132931306958
Q_Learning [272/300]: mean_loss=0.01994450413621962
Q_Learning [273/300]: mean_loss=0.03138659452088177
Q_Learning [274/300]: mean_loss=0.015970764914527535
Q_Learning [275/300]: mean_loss=0.00820288440445438
Q_Learning [276/300]: mean_loss=0.012070325086824596
Q_Learning [277/300]: mean_loss=0.0111852684058249
Q_Learning [278/300]: mean_loss=0.013538955594412982
Q_Learning [279/300]: mean_loss=0.04157171305269003
Q_Learning [280/300]: mean_loss=0.004137630690820515
Q_Learning [281/300]: mean_loss=0.014895488624460995
Q_Learning [282/300]: mean_loss=0.027879004832357168
Q_Learning [283/300]: mean_loss=0.02475415146909654
Q_Learning [284/300]: mean_loss=0.01297416933812201
Q_Learning [285/300]: mean_loss=0.013567311922088265
Q_Learning [286/300]: mean_loss=0.012149342685006559
Q_Learning [287/300]: mean_loss=0.009152005543000996
Q_Learning [288/300]: mean_loss=0.03959769196808338
Q_Learning [289/300]: mean_loss=0.014207438100129366
Q_Learning [290/300]: mean_loss=0.029907986288890243
Q_Learning [291/300]: mean_loss=0.023180139949545264
Q_Learning [292/300]: mean_loss=0.006792851781938225
Q_Learning [293/300]: mean_loss=0.034792948979884386
Q_Learning [294/300]: mean_loss=0.01155025593470782
Q_Learning [295/300]: mean_loss=0.009788814466446638
Q_Learning [296/300]: mean_loss=0.03767561144195497
Q_Learning [297/300]: mean_loss=0.022955052321776748
Q_Learning [298/300]: mean_loss=0.02024720166809857
Q_Learning [299/300]: mean_loss=0.05558037664741278
Q_Learning [300/300]: mean_loss=0.01246976328548044
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 1.0581399  -0.17691407]
[1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 2, 0, 0, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 0, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 2, 2, 1, 2, 0, 1, 1, 1, 0, 1, 2, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 2, 0, 2, 2, 0, 0, 1, 2, 1, 1, 0, 2, 2, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 2, 1, 0, 2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 2, 0, 1, 1, 2, 1, 0, 0, 1, 2, 0, 1, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 0, 0, 2, 0, 1, 2, 1, 1, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 2, 2, 1, 2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 2, 0, 2, 1, 2, 2, 2, 1, 0, 1, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 2, 0, 1, 0, 2, 1]
[0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 2, 0, 1, 1, 2, 1, 2, 1, 2, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 1, 1, 1, 0, 1, 2, 0, 0, 0, 3, 3, 4, 2, 2, 1, 2, 2, 1, 2, 2, 0, 2, 2, 0, 0, 2, 0, 1, 1, 2, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2, 1, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 2, 1, 0, 1, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 1, 1, 0, 1, 0, 2, 0, 1, 0, 1, 2, 0, 2, 4, 0, 2, 2, 0, 1, 2, 0, 1, 1, 1, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 1, 0, 0, 1, 0, 0, 2, 2, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0, 2, 1, 2, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 1, 1, 1, 0, 0, 0, 1, 0, 2, 2, 0, 1, 0, 5, 2, 2, 1, 1, 0, 0, 1, 1, 2, 0, 2, 0, 0, 1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 2, 0, 5, 1, 0]
Centroids: [[1.4061712, 0.22971503], [0.5879195, 0.024413249], [-0.76268625, 0.41684037]]
Centroids: [[0.5971641, -0.03384432], [-0.7412419, 0.38849127], [1.4506232, 0.34197587], [3.1972313, 1.1682551], [-1.6177876, 1.6813145], [1.4076784, -0.9432597]]
Contingency Matrix: 
[[ 20   0  63   1   0   2]
 [100   3  12   1   0   0]
 [  1  95   0   0   2   0]]
[[20, 0, 63, 1, 0, 2], [100, 3, 12, 1, 0, 0], [1, 95, 0, 0, 2, 0]]
[[20, 0, 63, 1, 0, 2], [100, 3, 12, 1, 0, 0], [1, 95, 0, 0, 2, 0]]
[0, 1, 2, 3, 4, 5]
[[-1, 0, 63, 1, 0, 2], [-1, -1, -1, -1, -1, -1], [-1, 95, 0, 0, 2, 0]]
[[-1, -1, 63, 1, 0, 2], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1]]
Match_Labels: {1: 0, 2: 1, 0: 2}
New Contingency Matrix: 
[[ 63  20   0   1   0   2]
 [ 12 100   3   1   0   0]
 [  0   1  95   0   2   0]]
New Clustered Label Sequence: [2, 0, 1, 3, 4, 5]
Diagonal_Elements: [63, 100, 95], Sum: 258
All_Elements: [63, 20, 0, 1, 0, 2, 12, 100, 3, 1, 0, 0, 0, 1, 95, 0, 2, 0], Sum: 300
Accuracy: 0.86
