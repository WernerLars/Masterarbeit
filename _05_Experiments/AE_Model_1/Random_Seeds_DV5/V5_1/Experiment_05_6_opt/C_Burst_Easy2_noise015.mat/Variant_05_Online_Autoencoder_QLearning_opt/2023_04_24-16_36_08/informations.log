Experiment_path: AE_Model_1/Random_Seeds_DV5//V5_1/Experiment_05_6_opt
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Burst_Easy2_noise015.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Burst_Easy2_noise015.mat']
Variant_name: Variant_05_Online_Autoencoder_QLearning_opt
Visualisation_Path: AE_Model_1/Random_Seeds_DV5//V5_1/Experiment_05_6_opt/C_Burst_Easy2_noise015.mat/Variant_05_Online_Autoencoder_QLearning_opt/2023_04_24-16_36_08
Punishment_Coefficient: 0.5
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001A3B83445C0>
Sampling rate: 24000.0
Raw: [ 0.24336953  0.26920333  0.26782334 ... -0.02629827 -0.02223585
 -0.02239043]
Times: [    195     430     737 ... 1439108 1439373 1439782]
Cluster: [2 1 1 ... 2 3 1]
Number of different clusters:  3
Number of Spikes: 3442
First aligned Spike Frame: [-0.01689698 -0.02635498 -0.01562648  0.02897143  0.09419909  0.16126917
  0.22354469  0.27941475  0.32258352  0.34699582  0.35463705  0.34576274
  0.299707    0.15447276 -0.11443537 -0.29135945 -0.02374047  0.60144887
  1.08218794  1.17595279  1.04108946  0.87905736  0.74420278  0.62460764
  0.52287424  0.43951429  0.36219288  0.28506818  0.21680111  0.17041962
  0.1410207   0.12802623  0.13803385  0.16548243  0.19507167  0.22209636
  0.24476727  0.25441697  0.2415664   0.21156445  0.18433246  0.16716092
  0.15280507  0.14158827  0.14947965  0.19464084  0.26501024]
Cluster 0, Occurrences: 1159
Cluster 1, Occurrences: 1156
Cluster 2, Occurrences: 1127
Number of Clusters: 3
Online_Training [1/700]: mean_loss=0.18415740318596363
Online_Training [2/700]: mean_loss=0.21020318754017353
Online_Training [3/700]: mean_loss=0.2120083887130022
Online_Training [4/700]: mean_loss=0.08621179033070803
Online_Training [5/700]: mean_loss=0.25450214371085167
Online_Training [6/700]: mean_loss=0.13196709752082825
Online_Training [7/700]: mean_loss=0.15103518404066563
Online_Training [8/700]: mean_loss=0.08236797247081995
Online_Training [9/700]: mean_loss=0.27335065603256226
Online_Training [10/700]: mean_loss=0.16257077641785145
Online_Training [11/700]: mean_loss=0.13127337396144867
Online_Training [12/700]: mean_loss=0.10991739574819803
Online_Training [13/700]: mean_loss=0.12722821347415447
Online_Training [14/700]: mean_loss=0.1495661325752735
Online_Training [15/700]: mean_loss=0.16194651275873184
Online_Training [16/700]: mean_loss=0.13786480389535427
Online_Training [17/700]: mean_loss=0.25439608469605446
Online_Training [18/700]: mean_loss=0.2547351084649563
Online_Training [19/700]: mean_loss=0.10445571597665548
Online_Training [20/700]: mean_loss=0.14238866977393627
Online_Training [21/700]: mean_loss=0.12156425788998604
Online_Training [22/700]: mean_loss=0.15267547592520714
Online_Training [23/700]: mean_loss=0.10084344912320375
Online_Training [24/700]: mean_loss=0.07363895326852798
Online_Training [25/700]: mean_loss=0.06170267704874277
Online_Training [26/700]: mean_loss=0.15749397687613964
Online_Training [27/700]: mean_loss=0.11306903325021267
Online_Training [28/700]: mean_loss=0.09890285134315491
Online_Training [29/700]: mean_loss=0.06967405136674643
Online_Training [30/700]: mean_loss=0.07628094777464867
Online_Training [31/700]: mean_loss=0.09518424980342388
Online_Training [32/700]: mean_loss=0.12393823731690645
Online_Training [33/700]: mean_loss=0.09497312642633915
Online_Training [34/700]: mean_loss=0.13032128103077412
Online_Training [35/700]: mean_loss=0.09141755569726229
Online_Training [36/700]: mean_loss=0.11781756393611431
Online_Training [37/700]: mean_loss=0.11762383114546537
Online_Training [38/700]: mean_loss=0.07200425583869219
Online_Training [39/700]: mean_loss=0.11890595685690641
Online_Training [40/700]: mean_loss=0.052202648017555475
Online_Training [41/700]: mean_loss=0.04975448874756694
Online_Training [42/700]: mean_loss=0.060292404145002365
Online_Training [43/700]: mean_loss=0.12150669284164906
Online_Training [44/700]: mean_loss=0.1477843876928091
Online_Training [45/700]: mean_loss=0.09110571816563606
Online_Training [46/700]: mean_loss=0.056819253135472536
Online_Training [47/700]: mean_loss=0.0926000876352191
Online_Training [48/700]: mean_loss=0.07324112020432949
Online_Training [49/700]: mean_loss=0.1200017025694251
Online_Training [50/700]: mean_loss=0.38929658848792315
Online_Training [51/700]: mean_loss=0.01973074907436967
Online_Training [52/700]: mean_loss=0.19043386355042458
Online_Training [53/700]: mean_loss=0.02578249853104353
Online_Training [54/700]: mean_loss=0.11648807674646378
Online_Training [55/700]: mean_loss=0.04941078554838896
Online_Training [56/700]: mean_loss=0.04063196573406458
Online_Training [57/700]: mean_loss=0.11055525206029415
Online_Training [58/700]: mean_loss=0.3438953198492527
Online_Training [59/700]: mean_loss=0.04438284831121564
Online_Training [60/700]: mean_loss=0.07829502131789923
Online_Training [61/700]: mean_loss=0.08156503271311522
Online_Training [62/700]: mean_loss=0.08327269554138184
Online_Training [63/700]: mean_loss=0.051042144652456045
Online_Training [64/700]: mean_loss=0.003507135930703953
Online_Training [65/700]: mean_loss=0.05657306686043739
Online_Training [66/700]: mean_loss=0.04865662753582001
Online_Training [67/700]: mean_loss=0.06783516751602292
Online_Training [68/700]: mean_loss=0.06785981077700853
Online_Training [69/700]: mean_loss=0.19095873087644577
Online_Training [70/700]: mean_loss=0.035776982083916664
Online_Training [71/700]: mean_loss=0.08367964159697294
Online_Training [72/700]: mean_loss=0.06979736872017384
Online_Training [73/700]: mean_loss=0.04095356771722436
Online_Training [74/700]: mean_loss=0.039389022160321474
Online_Training [75/700]: mean_loss=0.02623873110860586
Online_Training [76/700]: mean_loss=0.06361054629087448
Online_Training [77/700]: mean_loss=0.04695243947207928
Online_Training [78/700]: mean_loss=0.09916193597018719
Online_Training [79/700]: mean_loss=0.04965669149532914
Online_Training [80/700]: mean_loss=0.03962818393483758
Online_Training [81/700]: mean_loss=0.013742804760113358
Online_Training [82/700]: mean_loss=0.03657637443393469
Online_Training [83/700]: mean_loss=0.1325238086283207
Online_Training [84/700]: mean_loss=0.03927581897005439
Online_Training [85/700]: mean_loss=0.027809470426291227
Online_Training [86/700]: mean_loss=0.09959785360842943
Online_Training [87/700]: mean_loss=0.026292957831174135
Online_Training [88/700]: mean_loss=0.019716688431799412
Online_Training [89/700]: mean_loss=0.04375951737165451
Online_Training [90/700]: mean_loss=0.04757545655593276
Online_Training [91/700]: mean_loss=0.037422402296215296
Online_Training [92/700]: mean_loss=0.04247623821720481
Online_Training [93/700]: mean_loss=0.08731281477957964
Online_Training [94/700]: mean_loss=0.06197208212688565
Online_Training [95/700]: mean_loss=0.09551587980240583
Online_Training [96/700]: mean_loss=0.028984188567847013
Online_Training [97/700]: mean_loss=0.05200827633962035
Online_Training [98/700]: mean_loss=0.05641655111685395
Online_Training [99/700]: mean_loss=0.027812077663838863
Online_Training [100/700]: mean_loss=0.13319982402026653
Online_Training [101/700]: mean_loss=0.0816998640075326
Online_Training [102/700]: mean_loss=0.05379939638078213
Online_Training [103/700]: mean_loss=0.04154793452471495
Online_Training [104/700]: mean_loss=0.05469122063368559
Online_Training [105/700]: mean_loss=0.04305766988545656
Online_Training [106/700]: mean_loss=0.019278874387964606
Online_Training [107/700]: mean_loss=0.022651240462437272
Online_Training [108/700]: mean_loss=0.04317611642181873
Online_Training [109/700]: mean_loss=0.028337674215435982
Online_Training [110/700]: mean_loss=0.09449645597487688
Online_Training [111/700]: mean_loss=0.02958931471221149
Online_Training [112/700]: mean_loss=0.17050674557685852
Online_Training [113/700]: mean_loss=0.09198035579174757
Online_Training [114/700]: mean_loss=0.1266921330243349
Online_Training [115/700]: mean_loss=0.0306284308899194
Online_Training [116/700]: mean_loss=0.07658884208649397
Online_Training [117/700]: mean_loss=0.0598671268671751
Online_Training [118/700]: mean_loss=0.04508984927088022
Online_Training [119/700]: mean_loss=0.11555963847786188
Online_Training [120/700]: mean_loss=0.24165236577391624
Online_Training [121/700]: mean_loss=0.1788093037903309
Online_Training [122/700]: mean_loss=0.07785330433398485
Online_Training [123/700]: mean_loss=0.026285341940820217
Online_Training [124/700]: mean_loss=0.018432630691677332
Online_Training [125/700]: mean_loss=0.3831009678542614
Online_Training [126/700]: mean_loss=0.05548944929614663
Online_Training [127/700]: mean_loss=0.08294092305004597
Online_Training [128/700]: mean_loss=0.030687025748193264
Online_Training [129/700]: mean_loss=0.04347841488197446
Online_Training [130/700]: mean_loss=0.08069045655429363
Online_Training [131/700]: mean_loss=0.02671747747808695
Online_Training [132/700]: mean_loss=0.0872300686314702
Online_Training [133/700]: mean_loss=0.022270104382187128
Online_Training [134/700]: mean_loss=0.021715149749070406
Online_Training [135/700]: mean_loss=0.1368673350661993
Online_Training [136/700]: mean_loss=0.028206097427755594
Online_Training [137/700]: mean_loss=0.03799223294481635
Online_Training [138/700]: mean_loss=0.04832793306559324
Online_Training [139/700]: mean_loss=0.07563101127743721
Online_Training [140/700]: mean_loss=0.027394264237955213
Online_Training [141/700]: mean_loss=0.022247182205319405
Online_Training [142/700]: mean_loss=0.025986476568505168
Online_Training [143/700]: mean_loss=0.02565062139183283
Online_Training [144/700]: mean_loss=0.018987172283232212
Online_Training [145/700]: mean_loss=0.06245507439598441
Online_Training [146/700]: mean_loss=0.02581906388513744
Online_Training [147/700]: mean_loss=0.01965065090917051
Online_Training [148/700]: mean_loss=0.04748529149219394
Online_Training [149/700]: mean_loss=0.10812858399003744
Online_Training [150/700]: mean_loss=0.26286525651812553
Online_Training [151/700]: mean_loss=0.023738981690257788
Online_Training [152/700]: mean_loss=0.018704890040680766
Online_Training [153/700]: mean_loss=0.025004076305776834
Online_Training [154/700]: mean_loss=0.030965629499405622
Online_Training [155/700]: mean_loss=0.07060715928673744
Online_Training [156/700]: mean_loss=0.016436448087915778
Online_Training [157/700]: mean_loss=0.16402109526097775
Online_Training [158/700]: mean_loss=0.0760850291699171
Online_Training [159/700]: mean_loss=0.043242355808615685
Online_Training [160/700]: mean_loss=0.04259243607521057
Online_Training [161/700]: mean_loss=0.03926023421809077
Online_Training [162/700]: mean_loss=0.027952590957283974
Online_Training [163/700]: mean_loss=0.05612594401463866
Online_Training [164/700]: mean_loss=0.027350328397005796
Online_Training [165/700]: mean_loss=0.01247081602923572
Online_Training [166/700]: mean_loss=0.02000560867600143
Online_Training [167/700]: mean_loss=0.04534992063418031
Online_Training [168/700]: mean_loss=0.04662563418969512
Online_Training [169/700]: mean_loss=0.056106236297637224
Online_Training [170/700]: mean_loss=0.19719980284571648
Online_Training [171/700]: mean_loss=0.026363892713561654
Online_Training [172/700]: mean_loss=0.026429722551256418
Online_Training [173/700]: mean_loss=0.05823471490293741
Online_Training [174/700]: mean_loss=0.022891289088875055
Online_Training [175/700]: mean_loss=0.02556531853042543
Online_Training [176/700]: mean_loss=0.01040133647620678
Online_Training [177/700]: mean_loss=0.03776507102884352
Online_Training [178/700]: mean_loss=0.03963142540305853
Online_Training [179/700]: mean_loss=0.03217500261962414
Online_Training [180/700]: mean_loss=0.036293976940214634
Online_Training [181/700]: mean_loss=0.04035315616056323
Online_Training [182/700]: mean_loss=0.032058473909273744
Online_Training [183/700]: mean_loss=0.012385036679916084
Online_Training [184/700]: mean_loss=0.010327705997042358
Online_Training [185/700]: mean_loss=0.15663630329072475
Online_Training [186/700]: mean_loss=0.07768480945378542
Online_Training [187/700]: mean_loss=0.033570620231330395
Online_Training [188/700]: mean_loss=0.033853369764983654
Online_Training [189/700]: mean_loss=0.06704862136393785
Online_Training [190/700]: mean_loss=0.03229457186535001
Online_Training [191/700]: mean_loss=0.14918880350887775
Online_Training [192/700]: mean_loss=0.028483428759500384
Online_Training [193/700]: mean_loss=0.03238546987995505
Online_Training [194/700]: mean_loss=0.01489063142798841
Online_Training [195/700]: mean_loss=0.021316530648618937
Online_Training [196/700]: mean_loss=0.025243994081392884
Online_Training [197/700]: mean_loss=0.06516189593821764
Online_Training [198/700]: mean_loss=0.014967868686653674
Online_Training [199/700]: mean_loss=0.09897407609969378
Online_Training [200/700]: mean_loss=0.02072647539898753
Online_Training [201/700]: mean_loss=0.04141970071941614
Online_Training [202/700]: mean_loss=0.040179778821766376
Online_Training [203/700]: mean_loss=0.010313344420865178
Online_Training [204/700]: mean_loss=0.013106460683047771
Online_Training [205/700]: mean_loss=0.08636308368295431
Online_Training [206/700]: mean_loss=0.023195221787318587
Online_Training [207/700]: mean_loss=0.047885931096971035
Online_Training [208/700]: mean_loss=0.06693768408149481
Online_Training [209/700]: mean_loss=0.051767359022051096
Online_Training [210/700]: mean_loss=0.03150754841044545
Online_Training [211/700]: mean_loss=0.029389566276222467
Online_Training [212/700]: mean_loss=0.11262820474803448
Online_Training [213/700]: mean_loss=0.07295697322115302
Online_Training [214/700]: mean_loss=0.021195807494223118
Online_Training [215/700]: mean_loss=0.04577447334304452
Online_Training [216/700]: mean_loss=0.056463356129825115
Online_Training [217/700]: mean_loss=0.013291709590703249
Online_Training [218/700]: mean_loss=0.009283898863941431
Online_Training [219/700]: mean_loss=0.08146010618656874
Online_Training [220/700]: mean_loss=0.01806727470830083
Online_Training [221/700]: mean_loss=0.052888079546391964
Online_Training [222/700]: mean_loss=0.03436394454911351
Online_Training [223/700]: mean_loss=0.031692855758592486
Online_Training [224/700]: mean_loss=0.005710058496333659
Online_Training [225/700]: mean_loss=0.03553985944017768
Online_Training [226/700]: mean_loss=0.034711613319814205
Online_Training [227/700]: mean_loss=0.018559159245342016
Online_Training [228/700]: mean_loss=0.02848357823677361
Online_Training [229/700]: mean_loss=0.06611433438956738
Online_Training [230/700]: mean_loss=0.016293602879159153
Online_Training [231/700]: mean_loss=0.021017286693677306
Online_Training [232/700]: mean_loss=0.026118582813069224
Online_Training [233/700]: mean_loss=0.04495381098240614
Online_Training [234/700]: mean_loss=0.042643962893635035
Online_Training [235/700]: mean_loss=0.11373152863234282
Online_Training [236/700]: mean_loss=0.11348151415586472
Online_Training [237/700]: mean_loss=0.02276589465327561
Online_Training [238/700]: mean_loss=0.11653109639883041
Online_Training [239/700]: mean_loss=0.2388252206146717
Online_Training [240/700]: mean_loss=0.014412832679226995
Online_Training [241/700]: mean_loss=0.02642323332838714
Online_Training [242/700]: mean_loss=0.015000519575551152
Online_Training [243/700]: mean_loss=0.0320639091078192
Online_Training [244/700]: mean_loss=0.04247637651860714
Online_Training [245/700]: mean_loss=0.06828565895557404
Online_Training [246/700]: mean_loss=0.03765290044248104
Online_Training [247/700]: mean_loss=0.010965306777507067
Online_Training [248/700]: mean_loss=0.0892624482512474
Online_Training [249/700]: mean_loss=0.0826129075139761
Online_Training [250/700]: mean_loss=0.009960348717868328
Online_Training [251/700]: mean_loss=0.015325323212891817
Online_Training [252/700]: mean_loss=0.017801058245822787
Online_Training [253/700]: mean_loss=0.02177732577547431
Online_Training [254/700]: mean_loss=0.02075887005776167
Online_Training [255/700]: mean_loss=0.06121403304859996
Online_Training [256/700]: mean_loss=0.016596695058979094
Online_Training [257/700]: mean_loss=0.04087739810347557
Online_Training [258/700]: mean_loss=0.021700507728382945
Online_Training [259/700]: mean_loss=0.027597478590905666
Online_Training [260/700]: mean_loss=0.03916238620877266
Online_Training [261/700]: mean_loss=0.026385489385575056
Online_Training [262/700]: mean_loss=0.0493724150583148
Online_Training [263/700]: mean_loss=0.012053447659127414
Online_Training [264/700]: mean_loss=0.02975702565163374
Online_Training [265/700]: mean_loss=0.030977202346548438
Online_Training [266/700]: mean_loss=0.013984033954329789
Online_Training [267/700]: mean_loss=0.030386973405256867
Online_Training [268/700]: mean_loss=0.01165759318973869
Online_Training [269/700]: mean_loss=0.03333047730848193
Online_Training [270/700]: mean_loss=0.016573263565078378
Online_Training [271/700]: mean_loss=0.03108109626919031
Online_Training [272/700]: mean_loss=0.005729757132939994
Online_Training [273/700]: mean_loss=0.019794275052845478
Online_Training [274/700]: mean_loss=0.049855971708893776
Online_Training [275/700]: mean_loss=0.019264814211055636
Online_Training [276/700]: mean_loss=0.0350640076212585
Online_Training [277/700]: mean_loss=0.08539539016783237
Online_Training [278/700]: mean_loss=0.0192495237570256
Online_Training [279/700]: mean_loss=0.0349235194735229
Online_Training [280/700]: mean_loss=0.02870017569512129
Online_Training [281/700]: mean_loss=0.03312551509588957
Online_Training [282/700]: mean_loss=0.03155523864552379
Online_Training [283/700]: mean_loss=0.02249749400652945
Online_Training [284/700]: mean_loss=0.018875234527513385
Online_Training [285/700]: mean_loss=0.027905585942789912
Online_Training [286/700]: mean_loss=0.03175269393250346
Online_Training [287/700]: mean_loss=0.01693293801508844
Online_Training [288/700]: mean_loss=0.013602620223537087
Online_Training [289/700]: mean_loss=0.04293343983590603
Online_Training [290/700]: mean_loss=0.008742886944673955
Online_Training [291/700]: mean_loss=0.014036210486665368
Online_Training [292/700]: mean_loss=0.007872082700487226
Online_Training [293/700]: mean_loss=0.023977060336619616
Online_Training [294/700]: mean_loss=0.03693482419475913
Online_Training [295/700]: mean_loss=0.04130682907998562
Online_Training [296/700]: mean_loss=0.040801689960062504
Online_Training [297/700]: mean_loss=0.030335639836266637
Online_Training [298/700]: mean_loss=0.016612554900348186
Online_Training [299/700]: mean_loss=0.050367404241114855
Online_Training [300/700]: mean_loss=0.05758880265057087
Online_Training [301/700]: mean_loss=0.009706928743980825
Online_Training [302/700]: mean_loss=0.030857901088893414
Online_Training [303/700]: mean_loss=0.033778241369873285
Online_Training [304/700]: mean_loss=0.024070559302344918
Online_Training [305/700]: mean_loss=0.07146347034722567
Online_Training [306/700]: mean_loss=0.07566542364656925
Online_Training [307/700]: mean_loss=0.06371302297338843
Online_Training [308/700]: mean_loss=0.045608850196003914
Online_Training [309/700]: mean_loss=0.01879457663744688
Online_Training [310/700]: mean_loss=0.0203947932459414
Online_Training [311/700]: mean_loss=0.014909730874933302
Online_Training [312/700]: mean_loss=0.05282320361584425
Online_Training [313/700]: mean_loss=0.02663311897777021
Online_Training [314/700]: mean_loss=0.018929143203422427
Online_Training [315/700]: mean_loss=0.015206746407784522
Online_Training [316/700]: mean_loss=0.02075036196038127
Online_Training [317/700]: mean_loss=0.008565901080146432
Online_Training [318/700]: mean_loss=0.03862740192562342
Online_Training [319/700]: mean_loss=0.057079717982560396
Online_Training [320/700]: mean_loss=0.011851440998725593
Online_Training [321/700]: mean_loss=0.015677333460189402
Online_Training [322/700]: mean_loss=0.039800099562853575
Online_Training [323/700]: mean_loss=0.02477462380193174
Online_Training [324/700]: mean_loss=0.016850688960403204
Online_Training [325/700]: mean_loss=0.02572234347462654
Online_Training [326/700]: mean_loss=0.04109082231298089
Online_Training [327/700]: mean_loss=0.023626784095540643
Online_Training [328/700]: mean_loss=0.06161793740466237
Online_Training [329/700]: mean_loss=0.013246030430309474
Online_Training [330/700]: mean_loss=0.02252667467109859
Online_Training [331/700]: mean_loss=0.0282914184499532
Online_Training [332/700]: mean_loss=0.028397338464856148
Online_Training [333/700]: mean_loss=0.0210227791685611
Online_Training [334/700]: mean_loss=0.012331540929153562
Online_Training [335/700]: mean_loss=0.06293578026816249
Online_Training [336/700]: mean_loss=0.08035137690603733
Online_Training [337/700]: mean_loss=0.1321699135005474
Online_Training [338/700]: mean_loss=0.04883134551346302
Online_Training [339/700]: mean_loss=0.009491947828792036
Online_Training [340/700]: mean_loss=0.009434541803784668
Online_Training [341/700]: mean_loss=0.03598924679681659
Online_Training [342/700]: mean_loss=0.04785144701600075
Online_Training [343/700]: mean_loss=0.00951687851920724
Online_Training [344/700]: mean_loss=0.018413510406389832
Online_Training [345/700]: mean_loss=0.059697835706174374
Online_Training [346/700]: mean_loss=0.027716702315956354
Online_Training [347/700]: mean_loss=0.13482753187417984
Online_Training [348/700]: mean_loss=0.022970399586483836
Online_Training [349/700]: mean_loss=0.029473852599039674
Online_Training [350/700]: mean_loss=0.011213596095331013
Online_Training [351/700]: mean_loss=0.011206020135432482
Online_Training [352/700]: mean_loss=0.018038293812423944
Online_Training [353/700]: mean_loss=0.07223205920308828
Online_Training [354/700]: mean_loss=0.024901188910007477
Online_Training [355/700]: mean_loss=0.037729294039309025
Online_Training [356/700]: mean_loss=0.01831797230988741
Online_Training [357/700]: mean_loss=0.08106501307338476
Online_Training [358/700]: mean_loss=0.07697911374270916
Online_Training [359/700]: mean_loss=0.08533122483640909
Online_Training [360/700]: mean_loss=0.01771016395650804
Online_Training [361/700]: mean_loss=0.017848472110927105
Online_Training [362/700]: mean_loss=0.04096309235319495
Online_Training [363/700]: mean_loss=0.01571955520194024
Online_Training [364/700]: mean_loss=0.007839318946935236
Online_Training [365/700]: mean_loss=0.018431952223181725
Online_Training [366/700]: mean_loss=0.03852479578927159
Online_Training [367/700]: mean_loss=0.01905736536718905
Online_Training [368/700]: mean_loss=0.024342740420252085
Online_Training [369/700]: mean_loss=0.030646774917840958
Online_Training [370/700]: mean_loss=0.0342573132365942
Online_Training [371/700]: mean_loss=0.012795611866749823
Online_Training [372/700]: mean_loss=0.03235410014167428
Online_Training [373/700]: mean_loss=0.021481028525158763
Online_Training [374/700]: mean_loss=0.014883731724694371
Online_Training [375/700]: mean_loss=0.01862283400259912
Online_Training [376/700]: mean_loss=0.008165622712112963
Online_Training [377/700]: mean_loss=0.018647485645487905
Online_Training [378/700]: mean_loss=0.020044045289978385
Online_Training [379/700]: mean_loss=0.032443183241412044
Online_Training [380/700]: mean_loss=0.013827388407662511
Online_Training [381/700]: mean_loss=0.017123047495260835
Online_Training [382/700]: mean_loss=0.008197834133170545
Online_Training [383/700]: mean_loss=0.007824060914572328
Online_Training [384/700]: mean_loss=0.1493013370782137
Online_Training [385/700]: mean_loss=0.008706445165444165
Online_Training [386/700]: mean_loss=0.04288019798696041
Online_Training [387/700]: mean_loss=0.017326795496046543
Online_Training [388/700]: mean_loss=0.02813817304559052
Online_Training [389/700]: mean_loss=0.022397678112611175
Online_Training [390/700]: mean_loss=0.05244068754836917
Online_Training [391/700]: mean_loss=0.019282764988020062
Online_Training [392/700]: mean_loss=0.014904394745826721
Online_Training [393/700]: mean_loss=0.04768034350126982
Online_Training [394/700]: mean_loss=0.02802840410731733
Online_Training [395/700]: mean_loss=0.012462782789953053
Online_Training [396/700]: mean_loss=0.02341011236421764
Online_Training [397/700]: mean_loss=0.027560429414734244
Online_Training [398/700]: mean_loss=0.04304006788879633
Online_Training [399/700]: mean_loss=0.027374502969905734
Online_Training [400/700]: mean_loss=0.05681356322020292
Online_Training [401/700]: mean_loss=0.03427004022523761
Online_Training [402/700]: mean_loss=0.014716272824443877
Online_Training [403/700]: mean_loss=0.017110729357227683
Online_Training [404/700]: mean_loss=0.07444459665566683
Online_Training [405/700]: mean_loss=0.062445355113595724
Online_Training [406/700]: mean_loss=0.023437517462298274
Online_Training [407/700]: mean_loss=0.03907571453601122
Online_Training [408/700]: mean_loss=0.02772791776806116
Online_Training [409/700]: mean_loss=0.013040884747169912
Online_Training [410/700]: mean_loss=0.040389351546764374
Online_Training [411/700]: mean_loss=0.0278680098708719
Online_Training [412/700]: mean_loss=0.10584361664950848
Online_Training [413/700]: mean_loss=0.044737998861819506
Online_Training [414/700]: mean_loss=0.04382554767653346
Online_Training [415/700]: mean_loss=0.01318026427179575
Online_Training [416/700]: mean_loss=0.026454295963048935
Online_Training [417/700]: mean_loss=0.07034905254840851
Online_Training [418/700]: mean_loss=0.01248642848804593
Online_Training [419/700]: mean_loss=0.014900838257744908
Online_Training [420/700]: mean_loss=0.049778930842876434
Online_Training [421/700]: mean_loss=0.03430698742158711
Online_Training [422/700]: mean_loss=0.037166265305131674
Online_Training [423/700]: mean_loss=0.031927794218063354
Online_Training [424/700]: mean_loss=0.04604684980586171
Online_Training [425/700]: mean_loss=0.02978947013616562
Online_Training [426/700]: mean_loss=0.008477933472022414
Online_Training [427/700]: mean_loss=0.01866101799532771
Online_Training [428/700]: mean_loss=0.04059547884389758
Online_Training [429/700]: mean_loss=0.026153675746172667
Online_Training [430/700]: mean_loss=0.010494166635908186
Online_Training [431/700]: mean_loss=0.013917312142439187
Online_Training [432/700]: mean_loss=0.08388958685100079
Online_Training [433/700]: mean_loss=0.011643716832622886
Online_Training [434/700]: mean_loss=0.028690278995782137
Online_Training [435/700]: mean_loss=0.012963235145434737
Online_Training [436/700]: mean_loss=0.0717244204133749
Online_Training [437/700]: mean_loss=0.009186130831949413
Online_Training [438/700]: mean_loss=0.17907352931797504
Online_Training [439/700]: mean_loss=0.14803238958120346
Online_Training [440/700]: mean_loss=0.05562502657994628
Online_Training [441/700]: mean_loss=0.03482876857742667
Online_Training [442/700]: mean_loss=0.011973425280302763
Online_Training [443/700]: mean_loss=0.014224120764993131
Online_Training [444/700]: mean_loss=0.02367287827655673
Online_Training [445/700]: mean_loss=0.01815753523260355
Online_Training [446/700]: mean_loss=0.03830254217609763
Online_Training [447/700]: mean_loss=0.009475611615926027
Online_Training [448/700]: mean_loss=0.022715925006195903
Online_Training [449/700]: mean_loss=0.01873303740285337
Online_Training [450/700]: mean_loss=0.027052988996729255
Online_Training [451/700]: mean_loss=0.05037358449772
Online_Training [452/700]: mean_loss=0.04393772920593619
Online_Training [453/700]: mean_loss=0.065237688831985
Online_Training [454/700]: mean_loss=0.05016830051317811
Online_Training [455/700]: mean_loss=0.048804051242768764
Online_Training [456/700]: mean_loss=0.012508934596553445
Online_Training [457/700]: mean_loss=0.00960769719677046
Online_Training [458/700]: mean_loss=0.045701437164098024
Online_Training [459/700]: mean_loss=0.030013830168172717
Online_Training [460/700]: mean_loss=0.015964629943482578
Online_Training [461/700]: mean_loss=0.022975233616307378
Online_Training [462/700]: mean_loss=0.02044081292115152
Online_Training [463/700]: mean_loss=0.0364582478068769
Online_Training [464/700]: mean_loss=0.019455194240435958
Online_Training [465/700]: mean_loss=0.04628717852756381
Online_Training [466/700]: mean_loss=0.02645386941730976
Online_Training [467/700]: mean_loss=0.028707414865493774
Online_Training [468/700]: mean_loss=0.01619534380733967
Online_Training [469/700]: mean_loss=0.023551143240183592
Online_Training [470/700]: mean_loss=0.06299404101446271
Online_Training [471/700]: mean_loss=0.01748765865340829
Online_Training [472/700]: mean_loss=0.02612677006982267
Online_Training [473/700]: mean_loss=0.006095546414144337
Online_Training [474/700]: mean_loss=0.016049545723944902
Online_Training [475/700]: mean_loss=0.027095666155219078
Online_Training [476/700]: mean_loss=0.1931147538125515
Online_Training [477/700]: mean_loss=0.15177477151155472
Online_Training [478/700]: mean_loss=0.039537705946713686
Online_Training [479/700]: mean_loss=0.008769663400016725
Online_Training [480/700]: mean_loss=0.010069058742374182
Online_Training [481/700]: mean_loss=0.02776382234878838
Online_Training [482/700]: mean_loss=0.023565183859318495
Online_Training [483/700]: mean_loss=0.014937847037799656
Online_Training [484/700]: mean_loss=0.03447107179090381
Online_Training [485/700]: mean_loss=0.01550334191415459
Online_Training [486/700]: mean_loss=0.02778588724322617
Online_Training [487/700]: mean_loss=0.03588431002572179
Online_Training [488/700]: mean_loss=0.025153950788080692
Online_Training [489/700]: mean_loss=0.01882787887006998
Online_Training [490/700]: mean_loss=0.019160054391250014
Online_Training [491/700]: mean_loss=0.030929791508242488
Online_Training [492/700]: mean_loss=0.020519234472885728
Online_Training [493/700]: mean_loss=0.024847121443599463
Online_Training [494/700]: mean_loss=0.06121086422353983
Online_Training [495/700]: mean_loss=0.011425387347117066
Online_Training [496/700]: mean_loss=0.02839726395905018
Online_Training [497/700]: mean_loss=0.02929143630899489
Online_Training [498/700]: mean_loss=0.02560506504960358
Online_Training [499/700]: mean_loss=0.016397529048845172
Online_Training [500/700]: mean_loss=0.007366559817455709
Online_Training [501/700]: mean_loss=0.019172082422301173
Online_Training [502/700]: mean_loss=0.0372013202868402
Online_Training [503/700]: mean_loss=0.018940200796350837
Online_Training [504/700]: mean_loss=0.04243218572810292
Online_Training [505/700]: mean_loss=0.028269088827073574
Online_Training [506/700]: mean_loss=0.11781155038625002
Online_Training [507/700]: mean_loss=0.15121999382972717
Online_Training [508/700]: mean_loss=0.03489286592230201
Online_Training [509/700]: mean_loss=0.012664278852753341
Online_Training [510/700]: mean_loss=0.043917614966630936
Online_Training [511/700]: mean_loss=0.03399079758673906
Online_Training [512/700]: mean_loss=0.015114079928025603
Online_Training [513/700]: mean_loss=0.02556250593625009
Online_Training [514/700]: mean_loss=0.029266014229506254
Online_Training [515/700]: mean_loss=0.040502716321498156
Online_Training [516/700]: mean_loss=0.015864587854593992
Online_Training [517/700]: mean_loss=0.02605356927961111
Online_Training [518/700]: mean_loss=0.04007933661341667
Online_Training [519/700]: mean_loss=0.009202524088323116
Online_Training [520/700]: mean_loss=0.0321068805642426
Online_Training [521/700]: mean_loss=0.0318902269937098
Online_Training [522/700]: mean_loss=0.0069187411572784185
Online_Training [523/700]: mean_loss=0.018391752848401666
Online_Training [524/700]: mean_loss=0.07936905231326818
Online_Training [525/700]: mean_loss=0.029265527613461018
Online_Training [526/700]: mean_loss=0.011868582107126713
Online_Training [527/700]: mean_loss=0.01806881884112954
Online_Training [528/700]: mean_loss=0.03637215914204717
Online_Training [529/700]: mean_loss=0.02961618802510202
Online_Training [530/700]: mean_loss=0.01574535050895065
Online_Training [531/700]: mean_loss=0.06345047662034631
Online_Training [532/700]: mean_loss=0.023104880703613162
Online_Training [533/700]: mean_loss=0.031237652292475104
Online_Training [534/700]: mean_loss=0.0271027407143265
Online_Training [535/700]: mean_loss=0.026411639293655753
Online_Training [536/700]: mean_loss=0.10631376039236784
Online_Training [537/700]: mean_loss=0.0554515034891665
Online_Training [538/700]: mean_loss=0.01792979473248124
Online_Training [539/700]: mean_loss=0.011904555256478488
Online_Training [540/700]: mean_loss=0.03222727729007602
Online_Training [541/700]: mean_loss=0.1303200852125883
Online_Training [542/700]: mean_loss=0.01373769761994481
Online_Training [543/700]: mean_loss=0.014942082110792398
Online_Training [544/700]: mean_loss=0.010610083001665771
Online_Training [545/700]: mean_loss=0.04014165932312608
Online_Training [546/700]: mean_loss=0.010133939213119447
Online_Training [547/700]: mean_loss=0.028180678142234683
Online_Training [548/700]: mean_loss=0.030870449729263783
Online_Training [549/700]: mean_loss=0.010283940937370062
Online_Training [550/700]: mean_loss=0.06963347736746073
Online_Training [551/700]: mean_loss=0.03226226195693016
Online_Training [552/700]: mean_loss=0.05649908958002925
Online_Training [553/700]: mean_loss=0.03991844458505511
Online_Training [554/700]: mean_loss=0.02142127091065049
Online_Training [555/700]: mean_loss=0.022788157453760505
Online_Training [556/700]: mean_loss=0.016866248566657305
Online_Training [557/700]: mean_loss=0.018571958178654313
Online_Training [558/700]: mean_loss=0.004777072404976934
Online_Training [559/700]: mean_loss=0.009179063024930656
Online_Training [560/700]: mean_loss=0.018723615910857916
Online_Training [561/700]: mean_loss=0.024635755456984043
Online_Training [562/700]: mean_loss=0.03910457715392113
Online_Training [563/700]: mean_loss=0.03278128430247307
Online_Training [564/700]: mean_loss=0.011480049113743007
Online_Training [565/700]: mean_loss=0.040162079967558384
Online_Training [566/700]: mean_loss=0.03930123010650277
Online_Training [567/700]: mean_loss=0.018875838024541736
Online_Training [568/700]: mean_loss=0.016806008061394095
Online_Training [569/700]: mean_loss=0.023913584416732192
Online_Training [570/700]: mean_loss=0.018057862296700478
Online_Training [571/700]: mean_loss=0.04877775814384222
Online_Training [572/700]: mean_loss=0.02291039377450943
Online_Training [573/700]: mean_loss=0.021486791549250484
Online_Training [574/700]: mean_loss=0.05610231636092067
Online_Training [575/700]: mean_loss=0.06200183881446719
Online_Training [576/700]: mean_loss=0.017133925342932343
Online_Training [577/700]: mean_loss=0.028625020058825612
Online_Training [578/700]: mean_loss=0.013287790468893945
Online_Training [579/700]: mean_loss=0.022440318716689944
Online_Training [580/700]: mean_loss=0.03525816462934017
Online_Training [581/700]: mean_loss=0.012369703035801649
Online_Training [582/700]: mean_loss=0.02236418821848929
Online_Training [583/700]: mean_loss=0.011774334940128028
Online_Training [584/700]: mean_loss=0.02785290009342134
Online_Training [585/700]: mean_loss=0.023113183677196503
Online_Training [586/700]: mean_loss=0.09707781113684177
Online_Training [587/700]: mean_loss=0.042578847613185644
Online_Training [588/700]: mean_loss=0.017796250758692622
Online_Training [589/700]: mean_loss=0.025709656067192554
Online_Training [590/700]: mean_loss=0.023176990216597915
Online_Training [591/700]: mean_loss=0.023274860810488462
Online_Training [592/700]: mean_loss=0.02460022014565766
Online_Training [593/700]: mean_loss=0.046749279368668795
Online_Training [594/700]: mean_loss=0.06161395041272044
Online_Training [595/700]: mean_loss=0.05824398575350642
Online_Training [596/700]: mean_loss=0.014351276564411819
Online_Training [597/700]: mean_loss=0.009105231147259474
Online_Training [598/700]: mean_loss=0.019980319309979677
Online_Training [599/700]: mean_loss=0.02458878350444138
Online_Training [600/700]: mean_loss=0.014342567417770624
Online_Training [601/700]: mean_loss=0.03167702886275947
Online_Training [602/700]: mean_loss=0.018453952157869935
Online_Training [603/700]: mean_loss=0.019556560553610325
Online_Training [604/700]: mean_loss=0.02717691333964467
Online_Training [605/700]: mean_loss=0.017498031724244356
Online_Training [606/700]: mean_loss=0.015695046866312623
Online_Training [607/700]: mean_loss=0.015038410667330027
Online_Training [608/700]: mean_loss=0.01765592268202454
Online_Training [609/700]: mean_loss=0.016540584852918983
Online_Training [610/700]: mean_loss=0.020236200420185924
Online_Training [611/700]: mean_loss=0.010713702416978776
Online_Training [612/700]: mean_loss=1.2125740870833397
Online_Training [613/700]: mean_loss=0.048143396619707346
Online_Training [614/700]: mean_loss=0.03562597697600722
Online_Training [615/700]: mean_loss=0.02621883014217019
Online_Training [616/700]: mean_loss=0.07504080049693584
Online_Training [617/700]: mean_loss=0.03639704920351505
Online_Training [618/700]: mean_loss=0.02422419423237443
Online_Training [619/700]: mean_loss=0.010515879024751484
Online_Training [620/700]: mean_loss=0.08912005461752415
Online_Training [621/700]: mean_loss=0.012860245886258781
Online_Training [622/700]: mean_loss=0.0463660336099565
Online_Training [623/700]: mean_loss=0.04784870333969593
Online_Training [624/700]: mean_loss=0.019481511088088155
Online_Training [625/700]: mean_loss=0.013404672732576728
Online_Training [626/700]: mean_loss=0.03390309843234718
Online_Training [627/700]: mean_loss=0.006807138095609844
Online_Training [628/700]: mean_loss=0.009899936383590102
Online_Training [629/700]: mean_loss=0.04807150503620505
Online_Training [630/700]: mean_loss=0.03790056332945824
Online_Training [631/700]: mean_loss=0.0250040078535676
Online_Training [632/700]: mean_loss=0.021353699266910553
Online_Training [633/700]: mean_loss=0.015286173322238028
Online_Training [634/700]: mean_loss=0.030752685386687517
Online_Training [635/700]: mean_loss=0.02697787224315107
Online_Training [636/700]: mean_loss=0.011330406181514263
Online_Training [637/700]: mean_loss=0.029574970481917262
Online_Training [638/700]: mean_loss=0.04164090193808079
Online_Training [639/700]: mean_loss=0.01615979033522308
Online_Training [640/700]: mean_loss=0.006466591381467879
Online_Training [641/700]: mean_loss=0.01814120332710445
Online_Training [642/700]: mean_loss=0.029626914067193866
Online_Training [643/700]: mean_loss=0.010785524034872651
Online_Training [644/700]: mean_loss=0.06927445530891418
Online_Training [645/700]: mean_loss=0.018456036923453212
Online_Training [646/700]: mean_loss=0.04983780346810818
Online_Training [647/700]: mean_loss=0.009107999037951231
Online_Training [648/700]: mean_loss=0.009324963320977986
Online_Training [649/700]: mean_loss=0.017439766437746584
Online_Training [650/700]: mean_loss=0.026125898584723473
Online_Training [651/700]: mean_loss=0.021086820866912603
Online_Training [652/700]: mean_loss=0.010696826735511422
Online_Training [653/700]: mean_loss=0.10489953216165304
Online_Training [654/700]: mean_loss=0.02530968328937888
Online_Training [655/700]: mean_loss=0.021710284054279327
Online_Training [656/700]: mean_loss=0.020845203893259168
Online_Training [657/700]: mean_loss=0.01993760885670781
Online_Training [658/700]: mean_loss=0.01562138693407178
Online_Training [659/700]: mean_loss=0.05188992153853178
Online_Training [660/700]: mean_loss=0.021130821900442243
Online_Training [661/700]: mean_loss=0.03732692589983344
Online_Training [662/700]: mean_loss=0.04128975095227361
Online_Training [663/700]: mean_loss=0.028025209438055754
Online_Training [664/700]: mean_loss=0.004872679244726896
Online_Training [665/700]: mean_loss=0.049694971181452274
Online_Training [666/700]: mean_loss=0.027426871471107006
Online_Training [667/700]: mean_loss=0.007338544761296362
Online_Training [668/700]: mean_loss=0.017518598935566843
Online_Training [669/700]: mean_loss=0.006735488481353968
Online_Training [670/700]: mean_loss=0.01435079867951572
Online_Training [671/700]: mean_loss=0.025218915194272995
Online_Training [672/700]: mean_loss=0.030028063105419278
Online_Training [673/700]: mean_loss=0.014807332074269652
Online_Training [674/700]: mean_loss=0.02704452257603407
Online_Training [675/700]: mean_loss=0.031718517653644085
Online_Training [676/700]: mean_loss=0.03328566299751401
Online_Training [677/700]: mean_loss=0.04430511500686407
Online_Training [678/700]: mean_loss=0.024691859493032098
Online_Training [679/700]: mean_loss=0.024281261023133993
Online_Training [680/700]: mean_loss=0.04904966102913022
Online_Training [681/700]: mean_loss=0.01501616567838937
Online_Training [682/700]: mean_loss=0.012624243623577058
Online_Training [683/700]: mean_loss=0.018403171561658382
Online_Training [684/700]: mean_loss=0.033549999352544546
Online_Training [685/700]: mean_loss=0.031341408379375935
Online_Training [686/700]: mean_loss=0.018415754660964012
Online_Training [687/700]: mean_loss=0.0272049973718822
Online_Training [688/700]: mean_loss=0.05588492192327976
Online_Training [689/700]: mean_loss=0.02725434210151434
Online_Training [690/700]: mean_loss=0.013297283905558288
Online_Training [691/700]: mean_loss=0.014551263651810586
Online_Training [692/700]: mean_loss=0.03471938567236066
Online_Training [693/700]: mean_loss=0.03458385495468974
Online_Training [694/700]: mean_loss=0.03378845378756523
Online_Training [695/700]: mean_loss=0.014215395669452846
Online_Training [696/700]: mean_loss=0.026378509355708957
Online_Training [697/700]: mean_loss=0.004626154579455033
Online_Training [698/700]: mean_loss=0.005849663459230214
Online_Training [699/700]: mean_loss=0.07255107583478093
Online_Training [700/700]: mean_loss=0.0182293145917356
Q_Learning [1/300]: mean_loss=0.18415740318596363
Q_Learning [2/300]: mean_loss=0.21020318754017353
Q_Learning [3/300]: mean_loss=0.2120083887130022
Q_Learning [4/300]: mean_loss=0.08621179033070803
Q_Learning [5/300]: mean_loss=0.25450214371085167
Q_Learning [6/300]: mean_loss=0.13196709752082825
Q_Learning [7/300]: mean_loss=0.15103518404066563
Q_Learning [8/300]: mean_loss=0.08236797247081995
Q_Learning [9/300]: mean_loss=0.27335065603256226
Q_Learning [10/300]: mean_loss=0.16257077641785145
Q_Learning [11/300]: mean_loss=0.13127337396144867
Q_Learning [12/300]: mean_loss=0.10991739574819803
Q_Learning [13/300]: mean_loss=0.12722821347415447
Q_Learning [14/300]: mean_loss=0.1495661325752735
Q_Learning [15/300]: mean_loss=0.16194651275873184
Q_Learning [16/300]: mean_loss=0.13786480389535427
Q_Learning [17/300]: mean_loss=0.25439608469605446
Q_Learning [18/300]: mean_loss=0.2547351084649563
Q_Learning [19/300]: mean_loss=0.10445571597665548
Q_Learning [20/300]: mean_loss=0.14238866977393627
Q_Learning [21/300]: mean_loss=0.12156425788998604
Q_Learning [22/300]: mean_loss=0.15267547592520714
Q_Learning [23/300]: mean_loss=0.10084344912320375
Q_Learning [24/300]: mean_loss=0.07363895326852798
Q_Learning [25/300]: mean_loss=0.06170267704874277
Q_Learning [26/300]: mean_loss=0.15749397687613964
Q_Learning [27/300]: mean_loss=0.11306903325021267
Q_Learning [28/300]: mean_loss=0.09890285134315491
Q_Learning [29/300]: mean_loss=0.06967405136674643
Q_Learning [30/300]: mean_loss=0.07628094777464867
Q_Learning [31/300]: mean_loss=0.09518424980342388
Q_Learning [32/300]: mean_loss=0.12393823731690645
Q_Learning [33/300]: mean_loss=0.09497312642633915
Q_Learning [34/300]: mean_loss=0.13032128103077412
Q_Learning [35/300]: mean_loss=0.09141755569726229
Q_Learning [36/300]: mean_loss=0.11781756393611431
Q_Learning [37/300]: mean_loss=0.11762383114546537
Q_Learning [38/300]: mean_loss=0.07200425583869219
Q_Learning [39/300]: mean_loss=0.11890595685690641
Q_Learning [40/300]: mean_loss=0.052202648017555475
Q_Learning [41/300]: mean_loss=0.04975448874756694
Q_Learning [42/300]: mean_loss=0.060292404145002365
Q_Learning [43/300]: mean_loss=0.12150669284164906
Q_Learning [44/300]: mean_loss=0.1477843876928091
Q_Learning [45/300]: mean_loss=0.09110571816563606
Q_Learning [46/300]: mean_loss=0.056819253135472536
Q_Learning [47/300]: mean_loss=0.0926000876352191
Q_Learning [48/300]: mean_loss=0.07324112020432949
Q_Learning [49/300]: mean_loss=0.1200017025694251
Q_Learning [50/300]: mean_loss=0.38929658848792315
Q_Learning [51/300]: mean_loss=0.01973074907436967
Q_Learning [52/300]: mean_loss=0.19043386355042458
Q_Learning [53/300]: mean_loss=0.02578249853104353
Q_Learning [54/300]: mean_loss=0.11648807674646378
Q_Learning [55/300]: mean_loss=0.04941078554838896
Q_Learning [56/300]: mean_loss=0.04063196573406458
Q_Learning [57/300]: mean_loss=0.11055525206029415
Q_Learning [58/300]: mean_loss=0.3438953198492527
Q_Learning [59/300]: mean_loss=0.04438284831121564
Q_Learning [60/300]: mean_loss=0.07829502131789923
Q_Learning [61/300]: mean_loss=0.08156503271311522
Q_Learning [62/300]: mean_loss=0.08327269554138184
Q_Learning [63/300]: mean_loss=0.051042144652456045
Q_Learning [64/300]: mean_loss=0.003507135930703953
Q_Learning [65/300]: mean_loss=0.05657306686043739
Q_Learning [66/300]: mean_loss=0.04865662753582001
Q_Learning [67/300]: mean_loss=0.06783516751602292
Q_Learning [68/300]: mean_loss=0.06785981077700853
Q_Learning [69/300]: mean_loss=0.19095873087644577
Q_Learning [70/300]: mean_loss=0.035776982083916664
Q_Learning [71/300]: mean_loss=0.08367964159697294
Q_Learning [72/300]: mean_loss=0.06979736872017384
Q_Learning [73/300]: mean_loss=0.04095356771722436
Q_Learning [74/300]: mean_loss=0.039389022160321474
Q_Learning [75/300]: mean_loss=0.02623873110860586
Q_Learning [76/300]: mean_loss=0.06361054629087448
Q_Learning [77/300]: mean_loss=0.04695243947207928
Q_Learning [78/300]: mean_loss=0.09916193597018719
Q_Learning [79/300]: mean_loss=0.04965669149532914
Q_Learning [80/300]: mean_loss=0.03962818393483758
Q_Learning [81/300]: mean_loss=0.013742804760113358
Q_Learning [82/300]: mean_loss=0.03657637443393469
Q_Learning [83/300]: mean_loss=0.1325238086283207
Q_Learning [84/300]: mean_loss=0.03927581897005439
Q_Learning [85/300]: mean_loss=0.027809470426291227
Q_Learning [86/300]: mean_loss=0.09959785360842943
Q_Learning [87/300]: mean_loss=0.026292957831174135
Q_Learning [88/300]: mean_loss=0.019716688431799412
Q_Learning [89/300]: mean_loss=0.04375951737165451
Q_Learning [90/300]: mean_loss=0.04757545655593276
Q_Learning [91/300]: mean_loss=0.037422402296215296
Q_Learning [92/300]: mean_loss=0.04247623821720481
Q_Learning [93/300]: mean_loss=0.08731281477957964
Q_Learning [94/300]: mean_loss=0.06197208212688565
Q_Learning [95/300]: mean_loss=0.09551587980240583
Q_Learning [96/300]: mean_loss=0.028984188567847013
Q_Learning [97/300]: mean_loss=0.05200827633962035
Q_Learning [98/300]: mean_loss=0.05641655111685395
Q_Learning [99/300]: mean_loss=0.027812077663838863
Q_Learning [100/300]: mean_loss=0.13319982402026653
Q_Learning [101/300]: mean_loss=0.0816998640075326
Q_Learning [102/300]: mean_loss=0.05379939638078213
Q_Learning [103/300]: mean_loss=0.04154793452471495
Q_Learning [104/300]: mean_loss=0.05469122063368559
Q_Learning [105/300]: mean_loss=0.04305766988545656
Q_Learning [106/300]: mean_loss=0.019278874387964606
Q_Learning [107/300]: mean_loss=0.022651240462437272
Q_Learning [108/300]: mean_loss=0.04317611642181873
Q_Learning [109/300]: mean_loss=0.028337674215435982
Q_Learning [110/300]: mean_loss=0.09449645597487688
Q_Learning [111/300]: mean_loss=0.02958931471221149
Q_Learning [112/300]: mean_loss=0.17050674557685852
Q_Learning [113/300]: mean_loss=0.09198035579174757
Q_Learning [114/300]: mean_loss=0.1266921330243349
Q_Learning [115/300]: mean_loss=0.0306284308899194
Q_Learning [116/300]: mean_loss=0.07658884208649397
Q_Learning [117/300]: mean_loss=0.0598671268671751
Q_Learning [118/300]: mean_loss=0.04508984927088022
Q_Learning [119/300]: mean_loss=0.11555963847786188
Q_Learning [120/300]: mean_loss=0.24165236577391624
Q_Learning [121/300]: mean_loss=0.1788093037903309
Q_Learning [122/300]: mean_loss=0.07785330433398485
Q_Learning [123/300]: mean_loss=0.026285341940820217
Q_Learning [124/300]: mean_loss=0.018432630691677332
Q_Learning [125/300]: mean_loss=0.3831009678542614
Q_Learning [126/300]: mean_loss=0.05548944929614663
Q_Learning [127/300]: mean_loss=0.08294092305004597
Q_Learning [128/300]: mean_loss=0.030687025748193264
Q_Learning [129/300]: mean_loss=0.04347841488197446
Q_Learning [130/300]: mean_loss=0.08069045655429363
Q_Learning [131/300]: mean_loss=0.02671747747808695
Q_Learning [132/300]: mean_loss=0.0872300686314702
Q_Learning [133/300]: mean_loss=0.022270104382187128
Q_Learning [134/300]: mean_loss=0.021715149749070406
Q_Learning [135/300]: mean_loss=0.1368673350661993
Q_Learning [136/300]: mean_loss=0.028206097427755594
Q_Learning [137/300]: mean_loss=0.03799223294481635
Q_Learning [138/300]: mean_loss=0.04832793306559324
Q_Learning [139/300]: mean_loss=0.07563101127743721
Q_Learning [140/300]: mean_loss=0.027394264237955213
Q_Learning [141/300]: mean_loss=0.022247182205319405
Q_Learning [142/300]: mean_loss=0.025986476568505168
Q_Learning [143/300]: mean_loss=0.02565062139183283
Q_Learning [144/300]: mean_loss=0.018987172283232212
Q_Learning [145/300]: mean_loss=0.06245507439598441
Q_Learning [146/300]: mean_loss=0.02581906388513744
Q_Learning [147/300]: mean_loss=0.01965065090917051
Q_Learning [148/300]: mean_loss=0.04748529149219394
Q_Learning [149/300]: mean_loss=0.10812858399003744
Q_Learning [150/300]: mean_loss=0.26286525651812553
Q_Learning [151/300]: mean_loss=0.023738981690257788
Q_Learning [152/300]: mean_loss=0.018704890040680766
Q_Learning [153/300]: mean_loss=0.025004076305776834
Q_Learning [154/300]: mean_loss=0.030965629499405622
Q_Learning [155/300]: mean_loss=0.07060715928673744
Q_Learning [156/300]: mean_loss=0.016436448087915778
Q_Learning [157/300]: mean_loss=0.16402109526097775
Q_Learning [158/300]: mean_loss=0.0760850291699171
Q_Learning [159/300]: mean_loss=0.043242355808615685
Q_Learning [160/300]: mean_loss=0.04259243607521057
Q_Learning [161/300]: mean_loss=0.03926023421809077
Q_Learning [162/300]: mean_loss=0.027952590957283974
Q_Learning [163/300]: mean_loss=0.05612594401463866
Q_Learning [164/300]: mean_loss=0.027350328397005796
Q_Learning [165/300]: mean_loss=0.01247081602923572
Q_Learning [166/300]: mean_loss=0.02000560867600143
Q_Learning [167/300]: mean_loss=0.04534992063418031
Q_Learning [168/300]: mean_loss=0.04662563418969512
Q_Learning [169/300]: mean_loss=0.056106236297637224
Q_Learning [170/300]: mean_loss=0.19719980284571648
Q_Learning [171/300]: mean_loss=0.026363892713561654
Q_Learning [172/300]: mean_loss=0.026429722551256418
Q_Learning [173/300]: mean_loss=0.05823471490293741
Q_Learning [174/300]: mean_loss=0.022891289088875055
Q_Learning [175/300]: mean_loss=0.02556531853042543
Q_Learning [176/300]: mean_loss=0.01040133647620678
Q_Learning [177/300]: mean_loss=0.03776507102884352
Q_Learning [178/300]: mean_loss=0.03963142540305853
Q_Learning [179/300]: mean_loss=0.03217500261962414
Q_Learning [180/300]: mean_loss=0.036293976940214634
Q_Learning [181/300]: mean_loss=0.04035315616056323
Q_Learning [182/300]: mean_loss=0.032058473909273744
Q_Learning [183/300]: mean_loss=0.012385036679916084
Q_Learning [184/300]: mean_loss=0.010327705997042358
Q_Learning [185/300]: mean_loss=0.15663630329072475
Q_Learning [186/300]: mean_loss=0.07768480945378542
Q_Learning [187/300]: mean_loss=0.033570620231330395
Q_Learning [188/300]: mean_loss=0.033853369764983654
Q_Learning [189/300]: mean_loss=0.06704862136393785
Q_Learning [190/300]: mean_loss=0.03229457186535001
Q_Learning [191/300]: mean_loss=0.14918880350887775
Q_Learning [192/300]: mean_loss=0.028483428759500384
Q_Learning [193/300]: mean_loss=0.03238546987995505
Q_Learning [194/300]: mean_loss=0.01489063142798841
Q_Learning [195/300]: mean_loss=0.021316530648618937
Q_Learning [196/300]: mean_loss=0.025243994081392884
Q_Learning [197/300]: mean_loss=0.06516189593821764
Q_Learning [198/300]: mean_loss=0.014967868686653674
Q_Learning [199/300]: mean_loss=0.09897407609969378
Q_Learning [200/300]: mean_loss=0.02072647539898753
Q_Learning [201/300]: mean_loss=0.04141970071941614
Q_Learning [202/300]: mean_loss=0.040179778821766376
Q_Learning [203/300]: mean_loss=0.010313344420865178
Q_Learning [204/300]: mean_loss=0.013106460683047771
Q_Learning [205/300]: mean_loss=0.08636308368295431
Q_Learning [206/300]: mean_loss=0.023195221787318587
Q_Learning [207/300]: mean_loss=0.047885931096971035
Q_Learning [208/300]: mean_loss=0.06693768408149481
Q_Learning [209/300]: mean_loss=0.051767359022051096
Q_Learning [210/300]: mean_loss=0.03150754841044545
Q_Learning [211/300]: mean_loss=0.029389566276222467
Q_Learning [212/300]: mean_loss=0.11262820474803448
Q_Learning [213/300]: mean_loss=0.07295697322115302
Q_Learning [214/300]: mean_loss=0.021195807494223118
Q_Learning [215/300]: mean_loss=0.04577447334304452
Q_Learning [216/300]: mean_loss=0.056463356129825115
Q_Learning [217/300]: mean_loss=0.013291709590703249
Q_Learning [218/300]: mean_loss=0.009283898863941431
Q_Learning [219/300]: mean_loss=0.08146010618656874
Q_Learning [220/300]: mean_loss=0.01806727470830083
Q_Learning [221/300]: mean_loss=0.052888079546391964
Q_Learning [222/300]: mean_loss=0.03436394454911351
Q_Learning [223/300]: mean_loss=0.031692855758592486
Q_Learning [224/300]: mean_loss=0.005710058496333659
Q_Learning [225/300]: mean_loss=0.03553985944017768
Q_Learning [226/300]: mean_loss=0.034711613319814205
Q_Learning [227/300]: mean_loss=0.018559159245342016
Q_Learning [228/300]: mean_loss=0.02848357823677361
Q_Learning [229/300]: mean_loss=0.06611433438956738
Q_Learning [230/300]: mean_loss=0.016293602879159153
Q_Learning [231/300]: mean_loss=0.021017286693677306
Q_Learning [232/300]: mean_loss=0.026118582813069224
Q_Learning [233/300]: mean_loss=0.04495381098240614
Q_Learning [234/300]: mean_loss=0.042643962893635035
Q_Learning [235/300]: mean_loss=0.11373152863234282
Q_Learning [236/300]: mean_loss=0.11348151415586472
Q_Learning [237/300]: mean_loss=0.02276589465327561
Q_Learning [238/300]: mean_loss=0.11653109639883041
Q_Learning [239/300]: mean_loss=0.2388252206146717
Q_Learning [240/300]: mean_loss=0.014412832679226995
Q_Learning [241/300]: mean_loss=0.02642323332838714
Q_Learning [242/300]: mean_loss=0.015000519575551152
Q_Learning [243/300]: mean_loss=0.0320639091078192
Q_Learning [244/300]: mean_loss=0.04247637651860714
Q_Learning [245/300]: mean_loss=0.06828565895557404
Q_Learning [246/300]: mean_loss=0.03765290044248104
Q_Learning [247/300]: mean_loss=0.010965306777507067
Q_Learning [248/300]: mean_loss=0.0892624482512474
Q_Learning [249/300]: mean_loss=0.0826129075139761
Q_Learning [250/300]: mean_loss=0.009960348717868328
Q_Learning [251/300]: mean_loss=0.015325323212891817
Q_Learning [252/300]: mean_loss=0.017801058245822787
Q_Learning [253/300]: mean_loss=0.02177732577547431
Q_Learning [254/300]: mean_loss=0.02075887005776167
Q_Learning [255/300]: mean_loss=0.06121403304859996
Q_Learning [256/300]: mean_loss=0.016596695058979094
Q_Learning [257/300]: mean_loss=0.04087739810347557
Q_Learning [258/300]: mean_loss=0.021700507728382945
Q_Learning [259/300]: mean_loss=0.027597478590905666
Q_Learning [260/300]: mean_loss=0.03916238620877266
Q_Learning [261/300]: mean_loss=0.026385489385575056
Q_Learning [262/300]: mean_loss=0.0493724150583148
Q_Learning [263/300]: mean_loss=0.012053447659127414
Q_Learning [264/300]: mean_loss=0.02975702565163374
Q_Learning [265/300]: mean_loss=0.030977202346548438
Q_Learning [266/300]: mean_loss=0.013984033954329789
Q_Learning [267/300]: mean_loss=0.030386973405256867
Q_Learning [268/300]: mean_loss=0.01165759318973869
Q_Learning [269/300]: mean_loss=0.03333047730848193
Q_Learning [270/300]: mean_loss=0.016573263565078378
Q_Learning [271/300]: mean_loss=0.03108109626919031
Q_Learning [272/300]: mean_loss=0.005729757132939994
Q_Learning [273/300]: mean_loss=0.019794275052845478
Q_Learning [274/300]: mean_loss=0.049855971708893776
Q_Learning [275/300]: mean_loss=0.019264814211055636
Q_Learning [276/300]: mean_loss=0.0350640076212585
Q_Learning [277/300]: mean_loss=0.08539539016783237
Q_Learning [278/300]: mean_loss=0.0192495237570256
Q_Learning [279/300]: mean_loss=0.0349235194735229
Q_Learning [280/300]: mean_loss=0.02870017569512129
Q_Learning [281/300]: mean_loss=0.03312551509588957
Q_Learning [282/300]: mean_loss=0.03155523864552379
Q_Learning [283/300]: mean_loss=0.02249749400652945
Q_Learning [284/300]: mean_loss=0.018875234527513385
Q_Learning [285/300]: mean_loss=0.027905585942789912
Q_Learning [286/300]: mean_loss=0.03175269393250346
Q_Learning [287/300]: mean_loss=0.01693293801508844
Q_Learning [288/300]: mean_loss=0.013602620223537087
Q_Learning [289/300]: mean_loss=0.04293343983590603
Q_Learning [290/300]: mean_loss=0.008742886944673955
Q_Learning [291/300]: mean_loss=0.014036210486665368
Q_Learning [292/300]: mean_loss=0.007872082700487226
Q_Learning [293/300]: mean_loss=0.023977060336619616
Q_Learning [294/300]: mean_loss=0.03693482419475913
Q_Learning [295/300]: mean_loss=0.04130682907998562
Q_Learning [296/300]: mean_loss=0.040801689960062504
Q_Learning [297/300]: mean_loss=0.030335639836266637
Q_Learning [298/300]: mean_loss=0.016612554900348186
Q_Learning [299/300]: mean_loss=0.050367404241114855
Q_Learning [300/300]: mean_loss=0.05758880265057087
Number of Samples after Autoencoder testing: 300
First Spike after testing: [ 0.85715926 -2.184251  ]
[2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 0]
[0, 1, 2, 3, 1, 4, 3, 4, 0, 5, 2, 6, 1, 7, 7, 8, 0, 5, 9, 10, 11, 7, 12, 0, 10, 13, 6, 8, 11, 14, 0, 0, 1, 0, 8, 10, 13, 3, 0, 15, 16, 7, 0, 17, 11, 10, 5, 7, 0, 16, 8, 7, 10, 18, 12, 13, 19, 13, 17, 8, 18, 19, 6, 2, 20, 16, 0, 3, 0, 2, 8, 1, 6, 0, 16, 2, 3, 8, 3, 10, 2, 21, 8, 15, 5, 0, 5, 11, 17, 3, 5, 12, 0, 12, 1, 13, 17, 22, 0, 16, 11, 17, 2, 10, 13, 0, 0, 11, 23, 16, 1, 10, 24, 15, 18, 13, 17, 3, 23, 23, 23, 0, 18, 3, 12, 21, 10, 12, 23, 6, 25, 2, 0, 22, 16, 21, 26, 13, 27, 10, 2, 12, 18, 7, 7, 10, 24, 8, 22, 21, 0, 16, 28, 28, 13, 2, 23, 24, 24, 7, 0, 7, 7, 17, 16, 16, 28, 28, 25, 0, 10, 16, 10, 7, 28, 7, 3, 25, 2, 3, 13, 8, 10, 24, 8, 11, 28, 10, 7, 23, 29, 10, 25, 0, 19, 14, 5, 4, 0, 7, 24, 22, 8, 18, 25, 14, 22, 27, 3, 0, 13, 24, 30, 30, 19, 21, 10, 18, 10, 16, 0, 0, 16, 6, 14, 4, 0, 3, 23, 17, 14, 0, 25, 25, 0, 31, 7, 4, 32, 33, 19, 16, 17, 24, 8, 0, 2, 0, 10, 0, 0, 31, 0, 0, 3, 23, 12, 1, 16, 24, 29, 18, 16, 6, 27, 19, 16, 8, 25, 2, 34, 17, 10, 0, 12, 26, 33, 0, 3, 12, 35, 14, 18, 9, 23, 0, 18, 36, 2, 37, 38, 15, 16, 3, 0, 23, 34, 39, 6, 37]
Centroids: [[-4.067502, -9.530552], [-2.2686884, -7.0315833], [0.6856276, -2.466068]]
Centroids: [[0.72019315, -2.1747131], [-3.7231984, -6.245451], [-4.691055, -8.977407], [0.8605033, -0.56095403], [-2.6194005, -5.458161], [-3.6553955, -11.488546], [-1.8108125, -6.163476], [-1.6964915, -7.4573426], [-2.6066005, -8.493421], [-3.4726806, -13.136225], [0.67732024, -3.4664555], [-2.3118453, -10.212286], [-0.90661556, -5.581411], [-3.6819735, -8.71915], [-5.0203443, -9.937212], [-3.42522, -3.3504424], [-3.3682377, -9.957482], [-2.6292794, -6.9958], [0.38968056, -4.397758], [-1.0313, -6.7372403], [-0.5241157, -0.14895868], [-5.3559594, -8.065893], [-2.9401414, -11.2929535], [-3.7647254, -7.529462], [-4.9603915, -11.431106], [-1.3878697, -4.508066], [-6.762667, -12.634218], [-3.9532402, -4.922987], [0.58084124, -2.528333], [-0.8030758, -2.4123197], [-6.5967116, -13.673377], [-4.8158092, -7.01845], [-4.790552, -18.105837], [0.9444282, -5.768217], [-1.5312061, -9.909464], [-4.645831, -12.995982], [-1.074178, -8.359222], [-6.4072104, -7.92762], [-2.1765203, -12.218663], [-5.989618, -10.535269]]
Contingency Matrix: 
[[ 0  4 13  0  0  7  0  1  4  1  0  2  0 11  6  0 15  2  0  0  0  5  3  9
   8  0  2  1  0  0  1  2  1  0  1  1  0  1  1  1]
 [ 0  4  1  0  5  0  8 15 10  1  0  5 10  0  0  4  3  8  0  6  0  0  2  2
   1  8  0  2  0  1  1  0  0  0  1  0  1  1  0  0]
 [41  0  0 16  0  0  0  0  0  0 20  0  0  0  0  0  0  0 10  0  1  0  0  0
   0  0  0  0  6  1  0  0  0  2  0  0  0  0  0  0]]
[[0, 4, 13, 0, 0, 7, 0, 1, 4, 1, 0, 2, 0, 11, 6, 0, 15, 2, 0, 0, 0, 5, 3, 9, 8, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1], [0, 4, 1, 0, 5, 0, 8, 15, 10, 1, 0, 5, 10, 0, 0, 4, 3, 8, 0, 6, 0, 0, 2, 2, 1, 8, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], [41, 0, 0, 16, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0]]
[[0, 4, 13, 0, 0, 7, 0, 1, 4, 1, 0, 2, 0, 11, 6, 0, 15, 2, 0, 0, 0, 5, 3, 9, 8, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1], [0, 4, 1, 0, 5, 0, 8, 15, 10, 1, 0, 5, 10, 0, 0, 4, 3, 8, 0, 6, 0, 0, 2, 2, 1, 8, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], [41, 0, 0, 16, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 10, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0]]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]
[[-1, 4, 13, 0, 0, 7, 0, 1, 4, 1, 0, 2, 0, 11, 6, 0, 15, 2, 0, 0, 0, 5, 3, 9, 8, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1], [-1, 4, 1, 0, 5, 0, 8, 15, 10, 1, 0, 5, 10, 0, 0, 4, 3, 8, 0, 6, 0, 0, 2, 2, 1, 8, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 4, 1, 0, 5, 0, 8, 15, 10, 1, 0, 5, 10, 0, 0, 4, -1, 8, 0, 6, 0, 0, 2, 2, 1, 8, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
[[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]
Match_Labels: {2: 0, 0: 16, 1: 7}
New Contingency Matrix: 
[[15  1  0  4 13  0  0  7  0  4  1  0  2  0 11  6  0  2  0  0  0  5  3  9
   8  0  2  1  0  0  1  2  1  0  1  1  0  1  1  1]
 [ 3 15  0  4  1  0  5  0  8 10  1  0  5 10  0  0  4  8  0  6  0  0  2  2
   1  8  0  2  0  1  1  0  0  0  1  0  1  1  0  0]
 [ 0  0 41  0  0 16  0  0  0  0  0 20  0  0  0  0  0  0 10  0  1  0  0  0
   0  0  0  0  6  1  0  0  0  2  0  0  0  0  0  0]]
New Clustered Label Sequence: [16, 7, 0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]
Diagonal_Elements: [15, 15, 41], Sum: 71
All_Elements: [15, 1, 0, 4, 13, 0, 0, 7, 0, 4, 1, 0, 2, 0, 11, 6, 0, 2, 0, 0, 0, 5, 3, 9, 8, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 3, 15, 0, 4, 1, 0, 5, 0, 8, 10, 1, 0, 5, 10, 0, 0, 4, 8, 0, 6, 0, 0, 2, 2, 1, 8, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 41, 0, 0, 16, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 10, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], Sum: 300
Accuracy: 0.23666666666666666
