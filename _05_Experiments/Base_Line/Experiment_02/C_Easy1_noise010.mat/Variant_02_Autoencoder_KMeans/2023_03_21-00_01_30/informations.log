Experiment_path: Base_Line/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise010.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise010.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Base_Line/Experiment_02/C_Easy1_noise010.mat/Variant_02_Autoencoder_KMeans/2023_03_21-00_01_30
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001DE9AE65748>
Sampling rate: 24000.0
Raw: [ 0.01223885  0.0148803   0.02156532 ... -0.02666729 -0.01215068
  0.01031338]
Times: [   1012    1333    1523 ... 1438660 1438690 1439287]
Cluster: [1 3 3 ... 3 1 3]
Number of different clusters:  3
Number of Spikes: 3522
First aligned Spike Frame: [-0.12579972 -0.1620207  -0.18573939 -0.18961714 -0.17315203 -0.1396561
 -0.09426159 -0.04496221  0.00734136  0.05943689  0.09448878  0.07601101
  0.00811529  0.09446653  0.55421698  1.03008495  0.90195967  0.23116337
 -0.37857386 -0.59030761 -0.52695739 -0.40967661 -0.32471334 -0.26000903
 -0.19839489 -0.13975054 -0.09692457 -0.08223204 -0.09147337 -0.10695261
 -0.11338461 -0.10883018 -0.09915766 -0.08637804 -0.06514771 -0.03537735
 -0.00695045  0.01307529  0.02539335  0.03607991  0.04814655  0.05257424
  0.04538721  0.03512231  0.03354714  0.04141478  0.0511991 ]
Cluster 0, Occurrences: 1151
Cluster 1, Occurrences: 1134
Cluster 2, Occurrences: 1237
<torch.utils.data.dataloader.DataLoader object at 0x000001DE9A183278>
Epoch 1
-------------------------------
loss: 0.124909  [    0/ 3522]
loss: 0.130948  [  100/ 3522]
loss: 0.050602  [  200/ 3522]
loss: 0.041802  [  300/ 3522]
loss: 0.011215  [  400/ 3522]
loss: 0.009511  [  500/ 3522]
loss: 0.116363  [  600/ 3522]
loss: 0.042146  [  700/ 3522]
loss: 0.030316  [  800/ 3522]
loss: 0.009195  [  900/ 3522]
loss: 0.005338  [ 1000/ 3522]
loss: 0.006375  [ 1100/ 3522]
loss: 0.085378  [ 1200/ 3522]
loss: 0.015842  [ 1300/ 3522]
loss: 0.003566  [ 1400/ 3522]
loss: 0.005850  [ 1500/ 3522]
loss: 0.010833  [ 1600/ 3522]
loss: 0.007043  [ 1700/ 3522]
loss: 0.010522  [ 1800/ 3522]
loss: 0.015129  [ 1900/ 3522]
loss: 0.011423  [ 2000/ 3522]
loss: 0.014844  [ 2100/ 3522]
loss: 0.004259  [ 2200/ 3522]
loss: 0.006731  [ 2300/ 3522]
loss: 0.006180  [ 2400/ 3522]
loss: 0.005828  [ 2500/ 3522]
loss: 0.073386  [ 2600/ 3522]
loss: 0.010668  [ 2700/ 3522]
loss: 0.003207  [ 2800/ 3522]
loss: 0.004363  [ 2900/ 3522]
loss: 0.006529  [ 3000/ 3522]
loss: 0.010347  [ 3100/ 3522]
loss: 0.015069  [ 3200/ 3522]
loss: 0.007760  [ 3300/ 3522]
loss: 0.010489  [ 3400/ 3522]
loss: 0.007206  [ 3500/ 3522]
Epoch 2
-------------------------------
loss: 0.010819  [    0/ 3522]
loss: 0.007765  [  100/ 3522]
loss: 0.004967  [  200/ 3522]
loss: 0.051569  [  300/ 3522]
loss: 0.007186  [  400/ 3522]
loss: 0.008275  [  500/ 3522]
loss: 0.098900  [  600/ 3522]
loss: 0.015023  [  700/ 3522]
loss: 0.012391  [  800/ 3522]
loss: 0.006176  [  900/ 3522]
loss: 0.005296  [ 1000/ 3522]
loss: 0.004165  [ 1100/ 3522]
loss: 0.084762  [ 1200/ 3522]
loss: 0.016686  [ 1300/ 3522]
loss: 0.003061  [ 1400/ 3522]
loss: 0.003060  [ 1500/ 3522]
loss: 0.010649  [ 1600/ 3522]
loss: 0.006261  [ 1700/ 3522]
loss: 0.010294  [ 1800/ 3522]
loss: 0.015560  [ 1900/ 3522]
loss: 0.011079  [ 2000/ 3522]
loss: 0.012859  [ 2100/ 3522]
loss: 0.004487  [ 2200/ 3522]
loss: 0.006093  [ 2300/ 3522]
loss: 0.005771  [ 2400/ 3522]
loss: 0.005212  [ 2500/ 3522]
loss: 0.073558  [ 2600/ 3522]
loss: 0.008266  [ 2700/ 3522]
loss: 0.003376  [ 2800/ 3522]
loss: 0.004684  [ 2900/ 3522]
loss: 0.007579  [ 3000/ 3522]
loss: 0.008977  [ 3100/ 3522]
loss: 0.015653  [ 3200/ 3522]
loss: 0.007858  [ 3300/ 3522]
loss: 0.011547  [ 3400/ 3522]
loss: 0.006984  [ 3500/ 3522]
Epoch 3
-------------------------------
loss: 0.010537  [    0/ 3522]
loss: 0.007080  [  100/ 3522]
loss: 0.004696  [  200/ 3522]
loss: 0.050770  [  300/ 3522]
loss: 0.007615  [  400/ 3522]
loss: 0.008782  [  500/ 3522]
loss: 0.102472  [  600/ 3522]
loss: 0.014188  [  700/ 3522]
loss: 0.010918  [  800/ 3522]
loss: 0.005615  [  900/ 3522]
loss: 0.004274  [ 1000/ 3522]
loss: 0.004242  [ 1100/ 3522]
loss: 0.082792  [ 1200/ 3522]
loss: 0.014163  [ 1300/ 3522]
loss: 0.002759  [ 1400/ 3522]
loss: 0.003303  [ 1500/ 3522]
loss: 0.011015  [ 1600/ 3522]
loss: 0.005802  [ 1700/ 3522]
loss: 0.012272  [ 1800/ 3522]
loss: 0.011657  [ 1900/ 3522]
loss: 0.010680  [ 2000/ 3522]
loss: 0.010221  [ 2100/ 3522]
loss: 0.003853  [ 2200/ 3522]
loss: 0.006058  [ 2300/ 3522]
loss: 0.004897  [ 2400/ 3522]
loss: 0.004963  [ 2500/ 3522]
loss: 0.075211  [ 2600/ 3522]
loss: 0.005472  [ 2700/ 3522]
loss: 0.003235  [ 2800/ 3522]
loss: 0.004765  [ 2900/ 3522]
loss: 0.007661  [ 3000/ 3522]
loss: 0.008535  [ 3100/ 3522]
loss: 0.015389  [ 3200/ 3522]
loss: 0.007575  [ 3300/ 3522]
loss: 0.013780  [ 3400/ 3522]
loss: 0.007984  [ 3500/ 3522]
Epoch 4
-------------------------------
loss: 0.010270  [    0/ 3522]
loss: 0.006934  [  100/ 3522]
loss: 0.004796  [  200/ 3522]
loss: 0.051516  [  300/ 3522]
loss: 0.006139  [  400/ 3522]
loss: 0.009339  [  500/ 3522]
loss: 0.097913  [  600/ 3522]
loss: 0.013747  [  700/ 3522]
loss: 0.009089  [  800/ 3522]
loss: 0.004877  [  900/ 3522]
loss: 0.004355  [ 1000/ 3522]
loss: 0.004167  [ 1100/ 3522]
loss: 0.077541  [ 1200/ 3522]
loss: 0.013179  [ 1300/ 3522]
loss: 0.002632  [ 1400/ 3522]
loss: 0.003370  [ 1500/ 3522]
loss: 0.010749  [ 1600/ 3522]
loss: 0.005445  [ 1700/ 3522]
loss: 0.012463  [ 1800/ 3522]
loss: 0.010953  [ 1900/ 3522]
loss: 0.010343  [ 2000/ 3522]
loss: 0.008761  [ 2100/ 3522]
loss: 0.003645  [ 2200/ 3522]
loss: 0.006634  [ 2300/ 3522]
loss: 0.004168  [ 2400/ 3522]
loss: 0.004677  [ 2500/ 3522]
loss: 0.076410  [ 2600/ 3522]
loss: 0.006029  [ 2700/ 3522]
loss: 0.003577  [ 2800/ 3522]
loss: 0.004620  [ 2900/ 3522]
loss: 0.006391  [ 3000/ 3522]
loss: 0.008591  [ 3100/ 3522]
loss: 0.013351  [ 3200/ 3522]
loss: 0.007134  [ 3300/ 3522]
loss: 0.012936  [ 3400/ 3522]
loss: 0.008167  [ 3500/ 3522]
Epoch 5
-------------------------------
loss: 0.009657  [    0/ 3522]
loss: 0.006822  [  100/ 3522]
loss: 0.005410  [  200/ 3522]
loss: 0.053963  [  300/ 3522]
loss: 0.005230  [  400/ 3522]
loss: 0.009255  [  500/ 3522]
loss: 0.091432  [  600/ 3522]
loss: 0.013583  [  700/ 3522]
loss: 0.008362  [  800/ 3522]
loss: 0.005369  [  900/ 3522]
loss: 0.004984  [ 1000/ 3522]
loss: 0.004163  [ 1100/ 3522]
loss: 0.066850  [ 1200/ 3522]
loss: 0.013016  [ 1300/ 3522]
loss: 0.002796  [ 1400/ 3522]
loss: 0.002249  [ 1500/ 3522]
loss: 0.010362  [ 1600/ 3522]
loss: 0.004533  [ 1700/ 3522]
loss: 0.011549  [ 1800/ 3522]
loss: 0.011012  [ 1900/ 3522]
loss: 0.009834  [ 2000/ 3522]
loss: 0.007792  [ 2100/ 3522]
loss: 0.003282  [ 2200/ 3522]
loss: 0.007446  [ 2300/ 3522]
loss: 0.004372  [ 2400/ 3522]
loss: 0.004152  [ 2500/ 3522]
loss: 0.076641  [ 2600/ 3522]
loss: 0.007496  [ 2700/ 3522]
loss: 0.003787  [ 2800/ 3522]
loss: 0.004676  [ 2900/ 3522]
loss: 0.004915  [ 3000/ 3522]
loss: 0.009493  [ 3100/ 3522]
loss: 0.008693  [ 3200/ 3522]
loss: 0.006703  [ 3300/ 3522]
loss: 0.011742  [ 3400/ 3522]
loss: 0.008512  [ 3500/ 3522]
Epoch 6
-------------------------------
loss: 0.008666  [    0/ 3522]
loss: 0.008168  [  100/ 3522]
loss: 0.004585  [  200/ 3522]
loss: 0.049821  [  300/ 3522]
loss: 0.004891  [  400/ 3522]
loss: 0.009294  [  500/ 3522]
loss: 0.088262  [  600/ 3522]
loss: 0.013020  [  700/ 3522]
loss: 0.007385  [  800/ 3522]
loss: 0.006545  [  900/ 3522]
loss: 0.005337  [ 1000/ 3522]
loss: 0.004162  [ 1100/ 3522]
loss: 0.059104  [ 1200/ 3522]
loss: 0.013099  [ 1300/ 3522]
loss: 0.003032  [ 1400/ 3522]
loss: 0.001870  [ 1500/ 3522]
loss: 0.009656  [ 1600/ 3522]
loss: 0.004726  [ 1700/ 3522]
loss: 0.011077  [ 1800/ 3522]
loss: 0.011180  [ 1900/ 3522]
loss: 0.009481  [ 2000/ 3522]
loss: 0.007539  [ 2100/ 3522]
loss: 0.003193  [ 2200/ 3522]
loss: 0.008108  [ 2300/ 3522]
loss: 0.004535  [ 2400/ 3522]
loss: 0.003773  [ 2500/ 3522]
loss: 0.076793  [ 2600/ 3522]
loss: 0.008151  [ 2700/ 3522]
loss: 0.003549  [ 2800/ 3522]
loss: 0.004473  [ 2900/ 3522]
loss: 0.004455  [ 3000/ 3522]
loss: 0.007354  [ 3100/ 3522]
loss: 0.006268  [ 3200/ 3522]
loss: 0.006567  [ 3300/ 3522]
loss: 0.011515  [ 3400/ 3522]
loss: 0.008399  [ 3500/ 3522]
Epoch 7
-------------------------------
loss: 0.008672  [    0/ 3522]
loss: 0.008744  [  100/ 3522]
loss: 0.004495  [  200/ 3522]
loss: 0.042424  [  300/ 3522]
loss: 0.004611  [  400/ 3522]
loss: 0.009477  [  500/ 3522]
loss: 0.085609  [  600/ 3522]
loss: 0.012764  [  700/ 3522]
loss: 0.006724  [  800/ 3522]
loss: 0.007325  [  900/ 3522]
loss: 0.005262  [ 1000/ 3522]
loss: 0.004140  [ 1100/ 3522]
loss: 0.058348  [ 1200/ 3522]
loss: 0.012938  [ 1300/ 3522]
loss: 0.003029  [ 1400/ 3522]
loss: 0.001798  [ 1500/ 3522]
loss: 0.009405  [ 1600/ 3522]
loss: 0.005634  [ 1700/ 3522]
loss: 0.011290  [ 1800/ 3522]
loss: 0.011106  [ 1900/ 3522]
loss: 0.009353  [ 2000/ 3522]
loss: 0.007469  [ 2100/ 3522]
loss: 0.003262  [ 2200/ 3522]
loss: 0.008211  [ 2300/ 3522]
loss: 0.004509  [ 2400/ 3522]
loss: 0.003612  [ 2500/ 3522]
loss: 0.076537  [ 2600/ 3522]
loss: 0.008097  [ 2700/ 3522]
loss: 0.003445  [ 2800/ 3522]
loss: 0.004371  [ 2900/ 3522]
loss: 0.004516  [ 3000/ 3522]
loss: 0.006508  [ 3100/ 3522]
loss: 0.005576  [ 3200/ 3522]
loss: 0.006432  [ 3300/ 3522]
loss: 0.011775  [ 3400/ 3522]
loss: 0.008257  [ 3500/ 3522]
Epoch 8
-------------------------------
loss: 0.008727  [    0/ 3522]
loss: 0.009254  [  100/ 3522]
loss: 0.004512  [  200/ 3522]
loss: 0.037565  [  300/ 3522]
loss: 0.004584  [  400/ 3522]
loss: 0.009558  [  500/ 3522]
loss: 0.084549  [  600/ 3522]
loss: 0.012484  [  700/ 3522]
loss: 0.006185  [  800/ 3522]
loss: 0.007849  [  900/ 3522]
loss: 0.005218  [ 1000/ 3522]
loss: 0.004074  [ 1100/ 3522]
loss: 0.058871  [ 1200/ 3522]
loss: 0.012934  [ 1300/ 3522]
loss: 0.003001  [ 1400/ 3522]
loss: 0.001863  [ 1500/ 3522]
loss: 0.009300  [ 1600/ 3522]
loss: 0.005748  [ 1700/ 3522]
loss: 0.011330  [ 1800/ 3522]
loss: 0.011104  [ 1900/ 3522]
loss: 0.009311  [ 2000/ 3522]
loss: 0.007474  [ 2100/ 3522]
loss: 0.003323  [ 2200/ 3522]
loss: 0.008079  [ 2300/ 3522]
loss: 0.004546  [ 2400/ 3522]
loss: 0.003533  [ 2500/ 3522]
loss: 0.076470  [ 2600/ 3522]
loss: 0.007913  [ 2700/ 3522]
loss: 0.003339  [ 2800/ 3522]
loss: 0.004312  [ 2900/ 3522]
loss: 0.004618  [ 3000/ 3522]
loss: 0.005748  [ 3100/ 3522]
loss: 0.005235  [ 3200/ 3522]
loss: 0.006411  [ 3300/ 3522]
loss: 0.012089  [ 3400/ 3522]
loss: 0.008290  [ 3500/ 3522]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3522
First Spike after testing: [-0.5366512  0.6851283]
[0 2 2 ... 2 0 2]
[2 0 0 ... 0 2 0]
Cluster 0 Occurrences: 1151; KMEANS: 1248
Cluster 1 Occurrences: 1134; KMEANS: 1126
Cluster 2 Occurrences: 1237; KMEANS: 1148
Centroids: [[-0.3762684, 0.553642], [0.80417824, -2.0589993], [1.4433105, 1.024161]]
Centroids: [[1.4380554, 1.0255091], [0.81325847, -2.0768907], [-0.38867053, 0.54701]]
Contingency Matrix: 
[[  10    0 1141]
 [   4 1123    7]
 [1234    3    0]]
[[-1, 0, 1141], [-1, 1123, 7], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1123, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1141    0   10]
 [   7 1123    4]
 [   0    3 1234]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1141, 1123, 1234], Sum: 3498
All_Elements: [1141, 0, 10, 7, 1123, 4, 0, 3, 1234], Sum: 3522
Accuracy: 0.9931856899488927
Done!
