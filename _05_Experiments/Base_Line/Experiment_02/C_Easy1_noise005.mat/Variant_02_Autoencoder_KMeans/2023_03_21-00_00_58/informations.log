Experiment_path: Base_Line/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Easy1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Easy1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Base_Line/Experiment_02/C_Easy1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_21-00_00_58
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001DE9A129D68>
Sampling rate: 24000.0
Raw: [-0.05265172 -0.03124187 -0.00282162 ...  0.01798155  0.01678863
  0.0119459 ]
Times: [    283     469    1484 ... 1438285 1438773 1439067]
Cluster: [2 1 3 ... 2 1 2]
Number of different clusters:  3
Number of Spikes: 3514
First aligned Spike Frame: [-2.11647214e-02 -2.00144278e-02 -2.48166304e-02 -2.70972753e-02
 -1.11241704e-02  1.86904987e-02  3.99716833e-02  4.40400999e-02
  4.38833221e-02  5.06364129e-02  6.02243042e-02  3.59622148e-02
 -9.64451652e-02 -3.71359573e-01 -6.92987060e-01 -8.74449953e-01
 -7.13363902e-01 -1.84182190e-01  4.08997970e-01  7.26119515e-01
  7.19977210e-01  5.61000789e-01  4.04007238e-01  2.96025242e-01
  2.22861462e-01  1.69209408e-01  1.33269005e-01  1.11481721e-01
  9.67043158e-02  8.35988040e-02  6.87571423e-02  5.74871826e-02
  5.26722178e-02  4.53956038e-02  3.31356602e-02  2.21250606e-02
  1.35048482e-02 -4.41592673e-04 -2.31921908e-02 -4.69576347e-02
 -6.03503288e-02 -6.27551095e-02 -6.19812766e-02 -6.37499251e-02
 -6.42747873e-02 -5.93586264e-02 -5.06150772e-02]
Cluster 0, Occurrences: 1165
Cluster 1, Occurrences: 1157
Cluster 2, Occurrences: 1192
<torch.utils.data.dataloader.DataLoader object at 0x000001DE9A183208>
Epoch 1
-------------------------------
loss: 0.127304  [    0/ 3514]
loss: 0.108257  [  100/ 3514]
loss: 0.036151  [  200/ 3514]
loss: 0.062516  [  300/ 3514]
loss: 0.007019  [  400/ 3514]
loss: 0.006991  [  500/ 3514]
loss: 0.009079  [  600/ 3514]
loss: 0.003394  [  700/ 3514]
loss: 0.008144  [  800/ 3514]
loss: 0.009396  [  900/ 3514]
loss: 0.006598  [ 1000/ 3514]
loss: 0.093199  [ 1100/ 3514]
loss: 0.004752  [ 1200/ 3514]
loss: 0.002171  [ 1300/ 3514]
loss: 0.064577  [ 1400/ 3514]
loss: 0.001391  [ 1500/ 3514]
loss: 0.007118  [ 1600/ 3514]
loss: 0.005501  [ 1700/ 3514]
loss: 0.253706  [ 1800/ 3514]
loss: 0.007939  [ 1900/ 3514]
loss: 0.002114  [ 2000/ 3514]
loss: 0.005834  [ 2100/ 3514]
loss: 0.000875  [ 2200/ 3514]
loss: 0.001991  [ 2300/ 3514]
loss: 0.002519  [ 2400/ 3514]
loss: 0.007194  [ 2500/ 3514]
loss: 0.003938  [ 2600/ 3514]
loss: 0.003329  [ 2700/ 3514]
loss: 0.007227  [ 2800/ 3514]
loss: 0.002370  [ 2900/ 3514]
loss: 0.006394  [ 3000/ 3514]
loss: 0.001713  [ 3100/ 3514]
loss: 0.001709  [ 3200/ 3514]
loss: 0.007102  [ 3300/ 3514]
loss: 0.006089  [ 3400/ 3514]
loss: 0.003244  [ 3500/ 3514]
Epoch 2
-------------------------------
loss: 0.005199  [    0/ 3514]
loss: 0.002798  [  100/ 3514]
loss: 0.007984  [  200/ 3514]
loss: 0.003544  [  300/ 3514]
loss: 0.004306  [  400/ 3514]
loss: 0.002767  [  500/ 3514]
loss: 0.007153  [  600/ 3514]
loss: 0.003017  [  700/ 3514]
loss: 0.001257  [  800/ 3514]
loss: 0.004090  [  900/ 3514]
loss: 0.006290  [ 1000/ 3514]
loss: 0.091933  [ 1100/ 3514]
loss: 0.003015  [ 1200/ 3514]
loss: 0.002042  [ 1300/ 3514]
loss: 0.069796  [ 1400/ 3514]
loss: 0.000999  [ 1500/ 3514]
loss: 0.006712  [ 1600/ 3514]
loss: 0.005453  [ 1700/ 3514]
loss: 0.225506  [ 1800/ 3514]
loss: 0.007017  [ 1900/ 3514]
loss: 0.001957  [ 2000/ 3514]
loss: 0.005398  [ 2100/ 3514]
loss: 0.000820  [ 2200/ 3514]
loss: 0.001690  [ 2300/ 3514]
loss: 0.002392  [ 2400/ 3514]
loss: 0.006670  [ 2500/ 3514]
loss: 0.004965  [ 2600/ 3514]
loss: 0.002543  [ 2700/ 3514]
loss: 0.007638  [ 2800/ 3514]
loss: 0.001702  [ 2900/ 3514]
loss: 0.004331  [ 3000/ 3514]
loss: 0.001255  [ 3100/ 3514]
loss: 0.001829  [ 3200/ 3514]
loss: 0.005941  [ 3300/ 3514]
loss: 0.006242  [ 3400/ 3514]
loss: 0.003109  [ 3500/ 3514]
Epoch 3
-------------------------------
loss: 0.003312  [    0/ 3514]
loss: 0.002064  [  100/ 3514]
loss: 0.008190  [  200/ 3514]
loss: 0.003638  [  300/ 3514]
loss: 0.004113  [  400/ 3514]
loss: 0.003264  [  500/ 3514]
loss: 0.006848  [  600/ 3514]
loss: 0.003145  [  700/ 3514]
loss: 0.001219  [  800/ 3514]
loss: 0.004090  [  900/ 3514]
loss: 0.006363  [ 1000/ 3514]
loss: 0.091717  [ 1100/ 3514]
loss: 0.002232  [ 1200/ 3514]
loss: 0.002164  [ 1300/ 3514]
loss: 0.073605  [ 1400/ 3514]
loss: 0.001086  [ 1500/ 3514]
loss: 0.008553  [ 1600/ 3514]
loss: 0.005500  [ 1700/ 3514]
loss: 0.205287  [ 1800/ 3514]
loss: 0.006316  [ 1900/ 3514]
loss: 0.001393  [ 2000/ 3514]
loss: 0.005477  [ 2100/ 3514]
loss: 0.000910  [ 2200/ 3514]
loss: 0.001554  [ 2300/ 3514]
loss: 0.002283  [ 2400/ 3514]
loss: 0.006086  [ 2500/ 3514]
loss: 0.005212  [ 2600/ 3514]
loss: 0.002187  [ 2700/ 3514]
loss: 0.007875  [ 2800/ 3514]
loss: 0.001554  [ 2900/ 3514]
loss: 0.003904  [ 3000/ 3514]
loss: 0.001137  [ 3100/ 3514]
loss: 0.001800  [ 3200/ 3514]
loss: 0.005397  [ 3300/ 3514]
loss: 0.005682  [ 3400/ 3514]
loss: 0.003159  [ 3500/ 3514]
Epoch 4
-------------------------------
loss: 0.002906  [    0/ 3514]
loss: 0.001856  [  100/ 3514]
loss: 0.007531  [  200/ 3514]
loss: 0.003512  [  300/ 3514]
loss: 0.003989  [  400/ 3514]
loss: 0.003302  [  500/ 3514]
loss: 0.006445  [  600/ 3514]
loss: 0.003122  [  700/ 3514]
loss: 0.001295  [  800/ 3514]
loss: 0.004079  [  900/ 3514]
loss: 0.006349  [ 1000/ 3514]
loss: 0.091903  [ 1100/ 3514]
loss: 0.001819  [ 1200/ 3514]
loss: 0.002209  [ 1300/ 3514]
loss: 0.069406  [ 1400/ 3514]
loss: 0.000971  [ 1500/ 3514]
loss: 0.008943  [ 1600/ 3514]
loss: 0.005366  [ 1700/ 3514]
loss: 0.194628  [ 1800/ 3514]
loss: 0.005852  [ 1900/ 3514]
loss: 0.001123  [ 2000/ 3514]
loss: 0.005343  [ 2100/ 3514]
loss: 0.000866  [ 2200/ 3514]
loss: 0.001464  [ 2300/ 3514]
loss: 0.002146  [ 2400/ 3514]
loss: 0.005906  [ 2500/ 3514]
loss: 0.005145  [ 2600/ 3514]
loss: 0.002097  [ 2700/ 3514]
loss: 0.007555  [ 2800/ 3514]
loss: 0.001660  [ 2900/ 3514]
loss: 0.003096  [ 3000/ 3514]
loss: 0.001083  [ 3100/ 3514]
loss: 0.001783  [ 3200/ 3514]
loss: 0.005590  [ 3300/ 3514]
loss: 0.005491  [ 3400/ 3514]
loss: 0.003092  [ 3500/ 3514]
Epoch 5
-------------------------------
loss: 0.003483  [    0/ 3514]
loss: 0.001763  [  100/ 3514]
loss: 0.007284  [  200/ 3514]
loss: 0.003487  [  300/ 3514]
loss: 0.004031  [  400/ 3514]
loss: 0.003052  [  500/ 3514]
loss: 0.006096  [  600/ 3514]
loss: 0.003103  [  700/ 3514]
loss: 0.001402  [  800/ 3514]
loss: 0.004075  [  900/ 3514]
loss: 0.006522  [ 1000/ 3514]
loss: 0.092565  [ 1100/ 3514]
loss: 0.001601  [ 1200/ 3514]
loss: 0.002260  [ 1300/ 3514]
loss: 0.069478  [ 1400/ 3514]
loss: 0.000914  [ 1500/ 3514]
loss: 0.009404  [ 1600/ 3514]
loss: 0.005494  [ 1700/ 3514]
loss: 0.183940  [ 1800/ 3514]
loss: 0.005543  [ 1900/ 3514]
loss: 0.001016  [ 2000/ 3514]
loss: 0.005229  [ 2100/ 3514]
loss: 0.000863  [ 2200/ 3514]
loss: 0.001472  [ 2300/ 3514]
loss: 0.002097  [ 2400/ 3514]
loss: 0.005884  [ 2500/ 3514]
loss: 0.004758  [ 2600/ 3514]
loss: 0.002252  [ 2700/ 3514]
loss: 0.007438  [ 2800/ 3514]
loss: 0.001813  [ 2900/ 3514]
loss: 0.002354  [ 3000/ 3514]
loss: 0.001085  [ 3100/ 3514]
loss: 0.001770  [ 3200/ 3514]
loss: 0.006456  [ 3300/ 3514]
loss: 0.005431  [ 3400/ 3514]
loss: 0.003139  [ 3500/ 3514]
Epoch 6
-------------------------------
loss: 0.003523  [    0/ 3514]
loss: 0.001683  [  100/ 3514]
loss: 0.006978  [  200/ 3514]
loss: 0.003443  [  300/ 3514]
loss: 0.004102  [  400/ 3514]
loss: 0.002888  [  500/ 3514]
loss: 0.005726  [  600/ 3514]
loss: 0.003160  [  700/ 3514]
loss: 0.001432  [  800/ 3514]
loss: 0.004099  [  900/ 3514]
loss: 0.005980  [ 1000/ 3514]
loss: 0.093348  [ 1100/ 3514]
loss: 0.001404  [ 1200/ 3514]
loss: 0.002281  [ 1300/ 3514]
loss: 0.070906  [ 1400/ 3514]
loss: 0.000898  [ 1500/ 3514]
loss: 0.009962  [ 1600/ 3514]
loss: 0.005571  [ 1700/ 3514]
loss: 0.175512  [ 1800/ 3514]
loss: 0.005454  [ 1900/ 3514]
loss: 0.000912  [ 2000/ 3514]
loss: 0.005115  [ 2100/ 3514]
loss: 0.000850  [ 2200/ 3514]
loss: 0.001458  [ 2300/ 3514]
loss: 0.002014  [ 2400/ 3514]
loss: 0.005848  [ 2500/ 3514]
loss: 0.004537  [ 2600/ 3514]
loss: 0.002489  [ 2700/ 3514]
loss: 0.007377  [ 2800/ 3514]
loss: 0.001812  [ 2900/ 3514]
loss: 0.001682  [ 3000/ 3514]
loss: 0.001030  [ 3100/ 3514]
loss: 0.001799  [ 3200/ 3514]
loss: 0.005972  [ 3300/ 3514]
loss: 0.005433  [ 3400/ 3514]
loss: 0.003134  [ 3500/ 3514]
Epoch 7
-------------------------------
loss: 0.003176  [    0/ 3514]
loss: 0.001543  [  100/ 3514]
loss: 0.006359  [  200/ 3514]
loss: 0.003418  [  300/ 3514]
loss: 0.003985  [  400/ 3514]
loss: 0.002858  [  500/ 3514]
loss: 0.005237  [  600/ 3514]
loss: 0.002992  [  700/ 3514]
loss: 0.001574  [  800/ 3514]
loss: 0.003989  [  900/ 3514]
loss: 0.005756  [ 1000/ 3514]
loss: 0.094521  [ 1100/ 3514]
loss: 0.001205  [ 1200/ 3514]
loss: 0.002258  [ 1300/ 3514]
loss: 0.069816  [ 1400/ 3514]
loss: 0.000933  [ 1500/ 3514]
loss: 0.009581  [ 1600/ 3514]
loss: 0.005625  [ 1700/ 3514]
loss: 0.175901  [ 1800/ 3514]
loss: 0.005110  [ 1900/ 3514]
loss: 0.000865  [ 2000/ 3514]
loss: 0.005127  [ 2100/ 3514]
loss: 0.000896  [ 2200/ 3514]
loss: 0.001426  [ 2300/ 3514]
loss: 0.002036  [ 2400/ 3514]
loss: 0.005859  [ 2500/ 3514]
loss: 0.004421  [ 2600/ 3514]
loss: 0.002586  [ 2700/ 3514]
loss: 0.007515  [ 2800/ 3514]
loss: 0.001877  [ 2900/ 3514]
loss: 0.001269  [ 3000/ 3514]
loss: 0.001127  [ 3100/ 3514]
loss: 0.001799  [ 3200/ 3514]
loss: 0.006192  [ 3300/ 3514]
loss: 0.005545  [ 3400/ 3514]
loss: 0.003072  [ 3500/ 3514]
Epoch 8
-------------------------------
loss: 0.002955  [    0/ 3514]
loss: 0.001446  [  100/ 3514]
loss: 0.005795  [  200/ 3514]
loss: 0.003389  [  300/ 3514]
loss: 0.003571  [  400/ 3514]
loss: 0.002897  [  500/ 3514]
loss: 0.004727  [  600/ 3514]
loss: 0.002758  [  700/ 3514]
loss: 0.001563  [  800/ 3514]
loss: 0.003892  [  900/ 3514]
loss: 0.005696  [ 1000/ 3514]
loss: 0.094693  [ 1100/ 3514]
loss: 0.001134  [ 1200/ 3514]
loss: 0.002223  [ 1300/ 3514]
loss: 0.070266  [ 1400/ 3514]
loss: 0.000981  [ 1500/ 3514]
loss: 0.009571  [ 1600/ 3514]
loss: 0.005355  [ 1700/ 3514]
loss: 0.173575  [ 1800/ 3514]
loss: 0.004937  [ 1900/ 3514]
loss: 0.000830  [ 2000/ 3514]
loss: 0.005231  [ 2100/ 3514]
loss: 0.000933  [ 2200/ 3514]
loss: 0.001405  [ 2300/ 3514]
loss: 0.002089  [ 2400/ 3514]
loss: 0.005985  [ 2500/ 3514]
loss: 0.004250  [ 2600/ 3514]
loss: 0.003147  [ 2700/ 3514]
loss: 0.007460  [ 2800/ 3514]
loss: 0.002093  [ 2900/ 3514]
loss: 0.001011  [ 3000/ 3514]
loss: 0.001287  [ 3100/ 3514]
loss: 0.001784  [ 3200/ 3514]
loss: 0.006062  [ 3300/ 3514]
loss: 0.005669  [ 3400/ 3514]
loss: 0.002839  [ 3500/ 3514]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3514
First Spike after testing: [ 0.7429665 -1.5407778]
[1 0 2 ... 1 0 1]
[1 0 2 ... 1 0 1]
Cluster 0 Occurrences: 1165; KMEANS: 1153
Cluster 1 Occurrences: 1157; KMEANS: 1144
Cluster 2 Occurrences: 1192; KMEANS: 1217
Centroids: [[-0.48427367, 0.8368684], [0.53979564, -1.4858433], [1.4383782, 1.5644011]]
Centroids: [[-0.5029673, 0.8239566], [0.532972, -1.5089628], [1.4339465, 1.5586102]]
Contingency Matrix: 
[[1148    2   15]
 [   5 1141   11]
 [   0    1 1191]]
[[1148, 2, -1], [5, 1141, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1141, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 2, 0: 0, 1: 1}
New Contingency Matrix: 
[[1148    2   15]
 [   5 1141   11]
 [   0    1 1191]]
New Clustered Label Sequence: [0, 1, 2]
Diagonal_Elements: [1148, 1141, 1191], Sum: 3480
All_Elements: [1148, 2, 15, 5, 1141, 11, 0, 1, 1191], Sum: 3514
Accuracy: 0.9903244166192373
Done!
