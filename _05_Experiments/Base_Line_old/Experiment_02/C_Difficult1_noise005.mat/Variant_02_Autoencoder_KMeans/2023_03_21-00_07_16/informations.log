Experiment_path: Base_Line/Experiment_02
Dataset_Path: ../_00_Datasets/03_SimDaten_Quiroga2020/C_Difficult1_noise005.mat
Dataset_name: ['03_SimDaten_Quiroga2020', 'C_Difficult1_noise005.mat']
Variant_name: Variant_02_Autoencoder_KMeans
Visualisation_Path: Base_Line/Experiment_02/C_Difficult1_noise005.mat/Variant_02_Autoencoder_KMeans/2023_03_21-00_07_16
<_01_LoadDataset.ExternCode.spike_class.spike_dataclass object at 0x000001DF00308DD8>
Sampling rate: 24000.0
Raw: [-0.02396372 -0.02524464 -0.02236968 ... -0.00445509 -0.00436778
 -0.00470578]
Times: [    634     868    2584 ... 1437994 1438740 1439460]
Cluster: [3 2 3 ... 1 2 3]
Number of different clusters:  3
Number of Spikes: 3383
First aligned Spike Frame: [ 0.00503762 -0.00373478 -0.02417005 -0.05492281 -0.07823403 -0.07649548
 -0.06285267 -0.06865366 -0.09676273 -0.11004904 -0.09516198 -0.02689536
  0.18218225  0.56508663  0.95357316  1.00263054  0.57634096 -0.04324787
 -0.47305592 -0.6155027  -0.61852552 -0.60964372 -0.60484482 -0.57289026
 -0.52334621 -0.49235523 -0.47468281 -0.4416077  -0.40763637 -0.38725194
 -0.36627613 -0.33462257 -0.30781191 -0.30310449 -0.30176569 -0.28764362
 -0.27487686 -0.27588822 -0.27512317 -0.25186462 -0.21649826 -0.18877803
 -0.16831802 -0.15216626 -0.15550926 -0.17919117 -0.19056035]
Cluster 0, Occurrences: 1115
Cluster 1, Occurrences: 1113
Cluster 2, Occurrences: 1155
<torch.utils.data.dataloader.DataLoader object at 0x000001DE9A183208>
Epoch 1
-------------------------------
loss: 0.196284  [    0/ 3383]
loss: 0.029382  [  100/ 3383]
loss: 0.012441  [  200/ 3383]
loss: 0.008619  [  300/ 3383]
loss: 0.005284  [  400/ 3383]
loss: 0.010266  [  500/ 3383]
loss: 0.010530  [  600/ 3383]
loss: 0.016656  [  700/ 3383]
loss: 0.009216  [  800/ 3383]
loss: 0.008216  [  900/ 3383]
loss: 0.095892  [ 1000/ 3383]
loss: 0.053623  [ 1100/ 3383]
loss: 0.027267  [ 1200/ 3383]
loss: 0.012682  [ 1300/ 3383]
loss: 0.006509  [ 1400/ 3383]
loss: 0.015686  [ 1500/ 3383]
loss: 0.008982  [ 1600/ 3383]
loss: 0.001880  [ 1700/ 3383]
loss: 0.013092  [ 1800/ 3383]
loss: 0.013568  [ 1900/ 3383]
loss: 0.010696  [ 2000/ 3383]
loss: 0.003924  [ 2100/ 3383]
loss: 0.010938  [ 2200/ 3383]
loss: 0.010524  [ 2300/ 3383]
loss: 0.003702  [ 2400/ 3383]
loss: 0.024468  [ 2500/ 3383]
loss: 0.008789  [ 2600/ 3383]
loss: 0.003320  [ 2700/ 3383]
loss: 0.006792  [ 2800/ 3383]
loss: 0.003887  [ 2900/ 3383]
loss: 0.004065  [ 3000/ 3383]
loss: 0.004388  [ 3100/ 3383]
loss: 0.039709  [ 3200/ 3383]
loss: 0.005957  [ 3300/ 3383]
Epoch 2
-------------------------------
loss: 0.003967  [    0/ 3383]
loss: 0.008233  [  100/ 3383]
loss: 0.008837  [  200/ 3383]
loss: 0.002994  [  300/ 3383]
loss: 0.002999  [  400/ 3383]
loss: 0.006809  [  500/ 3383]
loss: 0.002382  [  600/ 3383]
loss: 0.002900  [  700/ 3383]
loss: 0.007461  [  800/ 3383]
loss: 0.001776  [  900/ 3383]
loss: 0.093795  [ 1000/ 3383]
loss: 0.058658  [ 1100/ 3383]
loss: 0.023042  [ 1200/ 3383]
loss: 0.009184  [ 1300/ 3383]
loss: 0.005085  [ 1400/ 3383]
loss: 0.014790  [ 1500/ 3383]
loss: 0.003207  [ 1600/ 3383]
loss: 0.001666  [ 1700/ 3383]
loss: 0.012005  [ 1800/ 3383]
loss: 0.013173  [ 1900/ 3383]
loss: 0.003404  [ 2000/ 3383]
loss: 0.003628  [ 2100/ 3383]
loss: 0.008665  [ 2200/ 3383]
loss: 0.001822  [ 2300/ 3383]
loss: 0.004161  [ 2400/ 3383]
loss: 0.027656  [ 2500/ 3383]
loss: 0.001439  [ 2600/ 3383]
loss: 0.002853  [ 2700/ 3383]
loss: 0.006253  [ 2800/ 3383]
loss: 0.005235  [ 2900/ 3383]
loss: 0.004201  [ 3000/ 3383]
loss: 0.004773  [ 3100/ 3383]
loss: 0.065481  [ 3200/ 3383]
loss: 0.002350  [ 3300/ 3383]
Epoch 3
-------------------------------
loss: 0.003824  [    0/ 3383]
loss: 0.005548  [  100/ 3383]
loss: 0.005489  [  200/ 3383]
loss: 0.003052  [  300/ 3383]
loss: 0.002879  [  400/ 3383]
loss: 0.004411  [  500/ 3383]
loss: 0.001174  [  600/ 3383]
loss: 0.002757  [  700/ 3383]
loss: 0.007021  [  800/ 3383]
loss: 0.001951  [  900/ 3383]
loss: 0.091780  [ 1000/ 3383]
loss: 0.057491  [ 1100/ 3383]
loss: 0.022092  [ 1200/ 3383]
loss: 0.008647  [ 1300/ 3383]
loss: 0.003934  [ 1400/ 3383]
loss: 0.015075  [ 1500/ 3383]
loss: 0.002745  [ 1600/ 3383]
loss: 0.001748  [ 1700/ 3383]
loss: 0.010689  [ 1800/ 3383]
loss: 0.012187  [ 1900/ 3383]
loss: 0.003132  [ 2000/ 3383]
loss: 0.003295  [ 2100/ 3383]
loss: 0.008001  [ 2200/ 3383]
loss: 0.001793  [ 2300/ 3383]
loss: 0.003466  [ 2400/ 3383]
loss: 0.029172  [ 2500/ 3383]
loss: 0.001464  [ 2600/ 3383]
loss: 0.002904  [ 2700/ 3383]
loss: 0.006128  [ 2800/ 3383]
loss: 0.005214  [ 2900/ 3383]
loss: 0.004281  [ 3000/ 3383]
loss: 0.004493  [ 3100/ 3383]
loss: 0.063784  [ 3200/ 3383]
loss: 0.002411  [ 3300/ 3383]
Epoch 4
-------------------------------
loss: 0.003890  [    0/ 3383]
loss: 0.005024  [  100/ 3383]
loss: 0.004699  [  200/ 3383]
loss: 0.002677  [  300/ 3383]
loss: 0.002489  [  400/ 3383]
loss: 0.004098  [  500/ 3383]
loss: 0.001135  [  600/ 3383]
loss: 0.002443  [  700/ 3383]
loss: 0.006740  [  800/ 3383]
loss: 0.002090  [  900/ 3383]
loss: 0.091899  [ 1000/ 3383]
loss: 0.057625  [ 1100/ 3383]
loss: 0.019761  [ 1200/ 3383]
loss: 0.008612  [ 1300/ 3383]
loss: 0.003727  [ 1400/ 3383]
loss: 0.015179  [ 1500/ 3383]
loss: 0.002613  [ 1600/ 3383]
loss: 0.001599  [ 1700/ 3383]
loss: 0.009654  [ 1800/ 3383]
loss: 0.012079  [ 1900/ 3383]
loss: 0.002938  [ 2000/ 3383]
loss: 0.003223  [ 2100/ 3383]
loss: 0.006942  [ 2200/ 3383]
loss: 0.001799  [ 2300/ 3383]
loss: 0.003608  [ 2400/ 3383]
loss: 0.024520  [ 2500/ 3383]
loss: 0.001525  [ 2600/ 3383]
loss: 0.002796  [ 2700/ 3383]
loss: 0.005977  [ 2800/ 3383]
loss: 0.004658  [ 2900/ 3383]
loss: 0.004259  [ 3000/ 3383]
loss: 0.004536  [ 3100/ 3383]
loss: 0.064599  [ 3200/ 3383]
loss: 0.002342  [ 3300/ 3383]
Epoch 5
-------------------------------
loss: 0.003531  [    0/ 3383]
loss: 0.004499  [  100/ 3383]
loss: 0.004307  [  200/ 3383]
loss: 0.002427  [  300/ 3383]
loss: 0.002328  [  400/ 3383]
loss: 0.003609  [  500/ 3383]
loss: 0.001027  [  600/ 3383]
loss: 0.002755  [  700/ 3383]
loss: 0.006731  [  800/ 3383]
loss: 0.002452  [  900/ 3383]
loss: 0.092454  [ 1000/ 3383]
loss: 0.058001  [ 1100/ 3383]
loss: 0.020238  [ 1200/ 3383]
loss: 0.008048  [ 1300/ 3383]
loss: 0.003641  [ 1400/ 3383]
loss: 0.015034  [ 1500/ 3383]
loss: 0.002508  [ 1600/ 3383]
loss: 0.001660  [ 1700/ 3383]
loss: 0.008756  [ 1800/ 3383]
loss: 0.011768  [ 1900/ 3383]
loss: 0.002791  [ 2000/ 3383]
loss: 0.003024  [ 2100/ 3383]
loss: 0.006140  [ 2200/ 3383]
loss: 0.001904  [ 2300/ 3383]
loss: 0.003425  [ 2400/ 3383]
loss: 0.024069  [ 2500/ 3383]
loss: 0.001548  [ 2600/ 3383]
loss: 0.002589  [ 2700/ 3383]
loss: 0.005927  [ 2800/ 3383]
loss: 0.004220  [ 2900/ 3383]
loss: 0.004250  [ 3000/ 3383]
loss: 0.004487  [ 3100/ 3383]
loss: 0.063658  [ 3200/ 3383]
loss: 0.002388  [ 3300/ 3383]
Epoch 6
-------------------------------
loss: 0.003939  [    0/ 3383]
loss: 0.003711  [  100/ 3383]
loss: 0.003856  [  200/ 3383]
loss: 0.002542  [  300/ 3383]
loss: 0.002165  [  400/ 3383]
loss: 0.003196  [  500/ 3383]
loss: 0.001015  [  600/ 3383]
loss: 0.002776  [  700/ 3383]
loss: 0.006505  [  800/ 3383]
loss: 0.002500  [  900/ 3383]
loss: 0.089854  [ 1000/ 3383]
loss: 0.058391  [ 1100/ 3383]
loss: 0.020185  [ 1200/ 3383]
loss: 0.007377  [ 1300/ 3383]
loss: 0.003547  [ 1400/ 3383]
loss: 0.014781  [ 1500/ 3383]
loss: 0.002462  [ 1600/ 3383]
loss: 0.001712  [ 1700/ 3383]
loss: 0.008071  [ 1800/ 3383]
loss: 0.011584  [ 1900/ 3383]
loss: 0.002721  [ 2000/ 3383]
loss: 0.002885  [ 2100/ 3383]
loss: 0.005424  [ 2200/ 3383]
loss: 0.001901  [ 2300/ 3383]
loss: 0.003287  [ 2400/ 3383]
loss: 0.024010  [ 2500/ 3383]
loss: 0.001675  [ 2600/ 3383]
loss: 0.002597  [ 2700/ 3383]
loss: 0.005881  [ 2800/ 3383]
loss: 0.003778  [ 2900/ 3383]
loss: 0.004257  [ 3000/ 3383]
loss: 0.004548  [ 3100/ 3383]
loss: 0.063549  [ 3200/ 3383]
loss: 0.002410  [ 3300/ 3383]
Epoch 7
-------------------------------
loss: 0.003729  [    0/ 3383]
loss: 0.002918  [  100/ 3383]
loss: 0.003179  [  200/ 3383]
loss: 0.002266  [  300/ 3383]
loss: 0.002058  [  400/ 3383]
loss: 0.002832  [  500/ 3383]
loss: 0.000939  [  600/ 3383]
loss: 0.002908  [  700/ 3383]
loss: 0.006170  [  800/ 3383]
loss: 0.002368  [  900/ 3383]
loss: 0.088895  [ 1000/ 3383]
loss: 0.058108  [ 1100/ 3383]
loss: 0.020889  [ 1200/ 3383]
loss: 0.006815  [ 1300/ 3383]
loss: 0.003435  [ 1400/ 3383]
loss: 0.014383  [ 1500/ 3383]
loss: 0.002473  [ 1600/ 3383]
loss: 0.001793  [ 1700/ 3383]
loss: 0.007451  [ 1800/ 3383]
loss: 0.011531  [ 1900/ 3383]
loss: 0.002680  [ 2000/ 3383]
loss: 0.002797  [ 2100/ 3383]
loss: 0.004412  [ 2200/ 3383]
loss: 0.001906  [ 2300/ 3383]
loss: 0.003294  [ 2400/ 3383]
loss: 0.025878  [ 2500/ 3383]
loss: 0.001580  [ 2600/ 3383]
loss: 0.002417  [ 2700/ 3383]
loss: 0.005668  [ 2800/ 3383]
loss: 0.003637  [ 2900/ 3383]
loss: 0.004719  [ 3000/ 3383]
loss: 0.004494  [ 3100/ 3383]
loss: 0.062390  [ 3200/ 3383]
loss: 0.002434  [ 3300/ 3383]
Epoch 8
-------------------------------
loss: 0.003647  [    0/ 3383]
loss: 0.002035  [  100/ 3383]
loss: 0.002618  [  200/ 3383]
loss: 0.002340  [  300/ 3383]
loss: 0.001917  [  400/ 3383]
loss: 0.002459  [  500/ 3383]
loss: 0.000932  [  600/ 3383]
loss: 0.002874  [  700/ 3383]
loss: 0.006158  [  800/ 3383]
loss: 0.002082  [  900/ 3383]
loss: 0.087933  [ 1000/ 3383]
loss: 0.057915  [ 1100/ 3383]
loss: 0.021101  [ 1200/ 3383]
loss: 0.006403  [ 1300/ 3383]
loss: 0.003382  [ 1400/ 3383]
loss: 0.013715  [ 1500/ 3383]
loss: 0.002464  [ 1600/ 3383]
loss: 0.001853  [ 1700/ 3383]
loss: 0.006591  [ 1800/ 3383]
loss: 0.011202  [ 1900/ 3383]
loss: 0.002713  [ 2000/ 3383]
loss: 0.002541  [ 2100/ 3383]
loss: 0.003726  [ 2200/ 3383]
loss: 0.002044  [ 2300/ 3383]
loss: 0.003157  [ 2400/ 3383]
loss: 0.026001  [ 2500/ 3383]
loss: 0.001425  [ 2600/ 3383]
loss: 0.002267  [ 2700/ 3383]
loss: 0.005747  [ 2800/ 3383]
loss: 0.003824  [ 2900/ 3383]
loss: 0.005179  [ 3000/ 3383]
loss: 0.004321  [ 3100/ 3383]
loss: 0.059751  [ 3200/ 3383]
loss: 0.002447  [ 3300/ 3383]
Number of Clusters: 3
Number of Samples after Autoencoder testing: 3383
First Spike after testing: [0.17191255 0.68224186]
[2 1 2 ... 0 1 2]
[0 1 0 ... 2 1 0]
Cluster 0 Occurrences: 1115; KMEANS: 1191
Cluster 1 Occurrences: 1113; KMEANS: 1096
Cluster 2 Occurrences: 1155; KMEANS: 1096
Centroids: [[-0.36273772, 0.27072713], [0.4145921, -0.33337626], [0.43885857, 0.5890174]]
Centroids: [[0.44612277, 0.5973499], [0.41386434, -0.35563383], [-0.38417646, 0.26410484]]
Contingency Matrix: 
[[  22    4 1089]
 [  22 1087    4]
 [1147    5    3]]
[[-1, 4, 1089], [-1, 1087, 4], [-1, -1, -1]]
[[-1, -1, -1], [-1, 1087, -1], [-1, -1, -1]]
[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]
Match_Labels: {2: 0, 0: 2, 1: 1}
New Contingency Matrix: 
[[1089    4   22]
 [   4 1087   22]
 [   3    5 1147]]
New Clustered Label Sequence: [2, 1, 0]
Diagonal_Elements: [1089, 1087, 1147], Sum: 3323
All_Elements: [1089, 4, 22, 4, 1087, 22, 3, 5, 1147], Sum: 3383
Accuracy: 0.9822642624889152
Done!
